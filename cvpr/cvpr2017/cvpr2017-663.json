"{\"abstract\":\"Problems at the intersection of vision and language are of significant importance both as challenging research questions and for the rich set of applications they enable. However, inherent structure in our world and bias in our language tend to be a simpler signal for learning than visual modalities, resulting in models that ignore visual information, leading to an inflated sense of their capability. We propose to counter these language priors for the task of Visual Question Answering (VQA) and make vision (the V in VQA) matter! Specifically, we balance the popular VQA dataset (Antol et al., ICCV 2015) by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question. Our dataset is by construction more balanced than the original VQA dataset and has approximately twice the number of image-question pairs. Our complete balanced dataset is publicly available at http://visualqa.org/ as part of the 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA v2.0). We further benchmark a number of state-of-art VQA models on our balanced dataset. All models perform significantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language priors. This finding provides the first concrete empirical evidence for what seems to be a qualitative sense among practitioners. Finally, our data collection protocol for identifying complementary images enables us to develop a novel interpretable model, which in addition to providing an answer to the given (image, question) pair, also provides a counter-example based explanation. Specifically, it identifies an image that is similar to the original image, but it believes has a different answer to the same question. This can help in building trust for machines among their users.\",\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\",\"url\":\"https://www.semanticscholar.org/author/37226164\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\",\"url\":\"https://www.semanticscholar.org/author/7595427\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\",\"url\":\"https://www.semanticscholar.org/author/1403432120\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/145054147\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"}],\"citationVelocity\":210,\"citations\":[{\"arxivId\":\"1808.05326\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/D18-1009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5c4b80fbf847f69a202ba5a780a3dd18c1a027\",\"title\":\"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\",\"url\":\"https://www.semanticscholar.org/paper/af5c4b80fbf847f69a202ba5a780a3dd18c1a027\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150156999\",\"name\":\"J. Park\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d78eaf500f06764f635da3924a252490232f451e\",\"title\":\"GRE: Evaluating computer vision models on Generalizability, Robustness, and Extensibility\",\"url\":\"https://www.semanticscholar.org/paper/d78eaf500f06764f635da3924a252490232f451e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.03626\",\"authors\":[{\"authorId\":\"46477844\",\"name\":\"Jianing Yang\"},{\"authorId\":\"4375156\",\"name\":\"Yuying Zhu\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"1796308073\",\"name\":\"Ruitao Yi\"},{\"authorId\":\"2960619\",\"name\":\"A. Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbe147910b53fbae66836e132024e70f0c988334\",\"title\":\"What Gives the Answer Away? Question Answering Bias Analysis on Video QA Datasets\",\"url\":\"https://www.semanticscholar.org/paper/cbe147910b53fbae66836e132024e70f0c988334\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.06794\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"24263694\",\"name\":\"J. Zhang\"},{\"authorId\":\"144978189\",\"name\":\"Hang Zhang\"},{\"authorId\":\"145159522\",\"name\":\"Ahmed Elgammal\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9024c8d6e80b111d94d570262b387f2ff4699d0\",\"title\":\"2nd Place Solution to the GQA Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/a9024c8d6e80b111d94d570262b387f2ff4699d0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.12440\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1609/aaai.v33i01.33018076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"634161e4759616dbe06f0b1465999d3df122f366\",\"title\":\"TallyQA: Answering Complex Counting Questions\",\"url\":\"https://www.semanticscholar.org/paper/634161e4759616dbe06f0b1465999d3df122f366\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.00578\",\"authors\":[{\"authorId\":\"50424875\",\"name\":\"Shruti Bhargava\"},{\"authorId\":\"144016260\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d1735a875eb2b3dfd0f281492c9b28b16f72bc9\",\"title\":\"Exposing and Correcting the Gender Bias in Image Captioning Datasets and Models\",\"url\":\"https://www.semanticscholar.org/paper/5d1735a875eb2b3dfd0f281492c9b28b16f72bc9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9408144\",\"name\":\"P. Wu\"},{\"authorId\":\"30796549\",\"name\":\"Saikrishna Rallabandi\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"},{\"authorId\":\"144287919\",\"name\":\"Eric Nyberg\"}],\"doi\":\"10.21437/interspeech.2019-2278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17b674d628358864ae2548eaf41ff1c9cd384d59\",\"title\":\"Ordinal Triplet Loss: Investigating Sleepiness Detection from Speech\",\"url\":\"https://www.semanticscholar.org/paper/17b674d628358864ae2548eaf41ff1c9cd384d59\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1812.07023\",\"authors\":[{\"authorId\":\"5298478\",\"name\":\"T. D. Nguyen\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d252759ea411343f274a92276bf7bd8f9d43db8c\",\"title\":\"From FiLM to Video: Multi-turn Question Answering with Multi-modal Context\",\"url\":\"https://www.semanticscholar.org/paper/d252759ea411343f274a92276bf7bd8f9d43db8c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.13471\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"title\":\"On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints\",\"url\":\"https://www.semanticscholar.org/paper/1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.03063\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.3233/FAIA200412\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9336a1be4fc269a987656aab16d2791515917f\",\"title\":\"Weak Supervision helps Emergence of Word-Object Alignment and improves Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/3e9336a1be4fc269a987656aab16d2791515917f\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8020f05b18ed434009b5d56398c57456c7dcde\",\"title\":\"Disentangling neural network representations for improved generalization\",\"url\":\"https://www.semanticscholar.org/paper/dc8020f05b18ed434009b5d56398c57456c7dcde\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"144064571\",\"name\":\"I. Pitas\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1016/j.image.2017.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"title\":\"Big Media Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":\"1803.09374\",\"authors\":[{\"authorId\":\"40807486\",\"name\":\"Brendan Duke\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CRV.2018.00016\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3d83aa3f1ed743d80b472a660102cb0ce21622ab\",\"title\":\"Generalized Hadamard-Product Fusion Operators for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3d83aa3f1ed743d80b472a660102cb0ce21622ab\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"48567083\",\"name\":\"Zheng Yu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/icme46284.2020.9102814\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fef6c56e474fa99e907b478f17f1becd50900f21\",\"title\":\"Rankvqa: Answer Re-Ranking For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fef6c56e474fa99e907b478f17f1becd50900f21\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1808.07290\",\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145131956\",\"name\":\"Lei Wang\"},{\"authorId\":\"144556892\",\"name\":\"N. Xu\"},{\"authorId\":\"21526180\",\"name\":\"B. Dai\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2914054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a810362ca5284e5894b07abb76b8f647802fe32c\",\"title\":\"The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem Solvers\",\"url\":\"https://www.semanticscholar.org/paper/a810362ca5284e5894b07abb76b8f647802fe32c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1910.14599\",\"authors\":[{\"authorId\":\"40383658\",\"name\":\"Yixin Nie\"},{\"authorId\":\"81840293\",\"name\":\"Adina Williams\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"}],\"doi\":\"10.18653/v1/2020.acl-main.441\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d87300892911275520a4f7a5e5abf4f1c002fec\",\"title\":\"Adversarial NLI: A New Benchmark for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/9d87300892911275520a4f7a5e5abf4f1c002fec\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1812.01280\",\"authors\":[{\"authorId\":\"2551640\",\"name\":\"Atsushi Kanehira\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2019.00880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4a948952c68cd6ae0024bc60bc12c642fb44fc3\",\"title\":\"Learning to Explain With Complemental Examples\",\"url\":\"https://www.semanticscholar.org/paper/c4a948952c68cd6ae0024bc60bc12c642fb44fc3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.02358\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"1837923\",\"name\":\"Taehoon Kim\"},{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b80f128830114896df94999b4104cb75408e657e\",\"title\":\"Transfer Learning via Unsupervised Task Discovery for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b80f128830114896df94999b4104cb75408e657e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582890834\",\"name\":\"Zekun Yang\"},{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1748743\",\"name\":\"H. Takemura\"}],\"doi\":\"10.1109/WACV45572.2020.9093596\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39b2d8b8233a53dc7eadb819c52213369dff8648\",\"title\":\"BERT Representations for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/39b2d8b8233a53dc7eadb819c52213369dff8648\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993611266\",\"name\":\"Guohao Li\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"title\":\"Boosting Visual Question Answering with Context-aware Knowledge Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1811.00613\",\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"}],\"doi\":\"10.18653/v1/N19-1197\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b033400e9a80915a928f4603582e5e8bf7656a85\",\"title\":\"Shifting the Baseline: Single Modality Performance on Visual Navigation & QA\",\"url\":\"https://www.semanticscholar.org/paper/b033400e9a80915a928f4603582e5e8bf7656a85\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1902.05660\",\"authors\":[{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2019.00681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"title\":\"Cycle-Consistency for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.02719\",\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"143986795\",\"name\":\"D. Sun\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1609/aaai.v33i01.33017136\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae61187c6603eef740e221a439a0c51b03989607\",\"title\":\"What If We Simply Swap the Two Text Fragments? A Straightforward yet Effective Way to Test the Robustness of Methods to Confounding Signals in Nature Language Inference Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ae61187c6603eef740e221a439a0c51b03989607\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2001.05840\",\"authors\":[{\"authorId\":\"36325868\",\"name\":\"L. Shi\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"51263928\",\"name\":\"Songxiang Liu\"},{\"authorId\":\"153933134\",\"name\":\"Peng Gao\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad6500f4e4548be232e8027cfa648577e8e0ca4b\",\"title\":\"Multi-Layer Content Interaction Through Quaternion Product for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad6500f4e4548be232e8027cfa648577e8e0ca4b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"48669907\",\"name\":\"X. Xu\"},{\"authorId\":\"145496508\",\"name\":\"J. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be63949be4151ed73503b3eb218aa9175233661b\",\"title\":\"Question-Led object attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/be63949be4151ed73503b3eb218aa9175233661b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49116303\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"144410256\",\"name\":\"Ryota Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"}],\"doi\":\"10.1007/978-3-030-50334-5_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee2dc587ff68e353fc47e0b2ad25e402fe87c57f\",\"title\":\"Multi-view Visual Question Answering Dataset for Real Environment Applications\",\"url\":\"https://www.semanticscholar.org/paper/ee2dc587ff68e353fc47e0b2ad25e402fe87c57f\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22225752\",\"name\":\"F. Brad\"}],\"doi\":\"10.1109/ICCVW.2019.00560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"title\":\"Scene Graph Contextualization in Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363901\",\"name\":\"Rabeeh Karimi Mahabadi\"},{\"authorId\":\"144915758\",\"name\":\"James Henderson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"82923dbd7eca1b22de222eb8766cb48f8d25a89e\",\"title\":\"Simple but effective techniques to reduce biases\",\"url\":\"https://www.semanticscholar.org/paper/82923dbd7eca1b22de222eb8766cb48f8d25a89e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145382463\",\"name\":\"T. Zhao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01258-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"380d50f3ccc07fa4f41282395a78c51e33985c39\",\"title\":\"Deep Attention Neural Tensor Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/380d50f3ccc07fa4f41282395a78c51e33985c39\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33035592\",\"name\":\"V. Sharma\"},{\"authorId\":\"49761595\",\"name\":\"A. Kalra\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"be74309535f4d4318332f39f3cb29d96e1c69f7f\",\"title\":\"Induced Attention Invariance: Defending VQA Models against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/be74309535f4d4318332f39f3cb29d96e1c69f7f\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1912.09589\",\"authors\":[{\"authorId\":\"3040891\",\"name\":\"Denis A. Gudovskiy\"},{\"authorId\":\"1470477472\",\"name\":\"Gyuri Han\"},{\"authorId\":\"50169969\",\"name\":\"T. Yamaguchi\"},{\"authorId\":\"2328731\",\"name\":\"S. Tsukizawa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c56ebee9d3890b6e5a28b6d34c2f11680fa0773b\",\"title\":\"Smart Home Appliances: Chat with Your Fridge\",\"url\":\"https://www.semanticscholar.org/paper/c56ebee9d3890b6e5a28b6d34c2f11680fa0773b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.04606\",\"authors\":[{\"authorId\":\"22205368\",\"name\":\"Akshay Chaturvedi\"},{\"authorId\":\"1804457\",\"name\":\"Utpal Garain\"}],\"doi\":\"10.1109/TNNLS.2020.2984972\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6417f6b7cdb85c31ffae34736ed9c75aead13d03\",\"title\":\"Mimic and Fool: A Task Agnostic Adversarial Attack\",\"url\":\"https://www.semanticscholar.org/paper/6417f6b7cdb85c31ffae34736ed9c75aead13d03\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.07059\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"title\":\"Accuracy vs. Complexity: A Trade-off in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00431\",\"authors\":[{\"authorId\":\"46650151\",\"name\":\"Kamran Alipour\"},{\"authorId\":\"32330143\",\"name\":\"Jurgen P. Schulze\"},{\"authorId\":\"1400198856\",\"name\":\"Yi Yao\"},{\"authorId\":\"6052800\",\"name\":\"Avi Ziskind\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2ac44701f41067f75285e939ca6425b1dc306b8\",\"title\":\"A Study on Multimodal and Interactive Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e2ac44701f41067f75285e939ca6425b1dc306b8\",\"venue\":\"SafeAI@AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152163039\",\"name\":\"June\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"acf13c52c86a3b38642ba0c6cbcd1b771778965c\",\"title\":\"NAACL HLT 2018 Generalization in the Age of Deep Learning Proceedings of the Workshop\",\"url\":\"https://www.semanticscholar.org/paper/acf13c52c86a3b38642ba0c6cbcd1b771778965c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32102885\",\"name\":\"Rachel Gardner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad707fc8b36a8f3daf8742cf92fcf099de434cec\",\"title\":\"A Deep Learning Approach for Identification of Confusion in Unstructured Crowdsourced Annotations\",\"url\":\"https://www.semanticscholar.org/paper/ad707fc8b36a8f3daf8742cf92fcf099de434cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1710.11601\",\"authors\":[{\"authorId\":\"2875615\",\"name\":\"Lea Frermann\"},{\"authorId\":\"40146204\",\"name\":\"Shay B. Cohen\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1162/tacl_a_00001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6dd15b7e674755b01fe605efb42d03d920ebcde\",\"title\":\"Whodunnit? Crime Drama as a Case for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f6dd15b7e674755b01fe605efb42d03d920ebcde\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1906.00513\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":\"10.18653/v1/P19-1348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b16da6786f799de7d31786fbbf5dafa1979a2c64\",\"title\":\"Generating Question Relevant Captions to Aid Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b16da6786f799de7d31786fbbf5dafa1979a2c64\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1910.10706\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1609/AAAI.V34I07.6713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"title\":\"KnowIT VQA: Answering Knowledge-Based Questions about Videos\",\"url\":\"https://www.semanticscholar.org/paper/12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2006.05121\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221\",\"title\":\"Roses Are Red, Violets Are Blue... but Should Vqa Expect Them To?\",\"url\":\"https://www.semanticscholar.org/paper/95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00398\",\"authors\":[{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b40bfcf339de3f0dba08fabb2b58b9368ff4c51a\",\"title\":\"DocVQA: A Dataset for VQA on Document Images\",\"url\":\"https://www.semanticscholar.org/paper/b40bfcf339de3f0dba08fabb2b58b9368ff4c51a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1745798\",\"name\":\"B. D. Eugenio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"91412f8e920ed226b44b5fad195c2b8bd080e837\",\"title\":\"A Corpus for Visual Question Answering Annotated with Frame Semantic Information\",\"url\":\"https://www.semanticscholar.org/paper/91412f8e920ed226b44b5fad195c2b8bd080e837\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1908.08960\",\"authors\":[{\"authorId\":\"51232396\",\"name\":\"Wojciech Kryscinski\"},{\"authorId\":\"2844898\",\"name\":\"N. Keskar\"},{\"authorId\":\"143775536\",\"name\":\"B. McCann\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.18653/v1/D19-1051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af93e1accba69994cdc36254ef93584af307fd8a\",\"title\":\"Neural Text Summarization: A Critical Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/af93e1accba69994cdc36254ef93584af307fd8a\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1904.02865\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00204\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51932dc1148566040fdb0df6ed66d8d2a0712933\",\"title\":\"Actively Seeking and Learning From Live Data\",\"url\":\"https://www.semanticscholar.org/paper/51932dc1148566040fdb0df6ed66d8d2a0712933\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.10354\",\"authors\":[{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc4598d636b599c4752a376cc074541c5a0ec97a\",\"title\":\"Unsupervised Keyword Extraction for Full-sentence VQA\",\"url\":\"https://www.semanticscholar.org/paper/fc4598d636b599c4752a376cc074541c5a0ec97a\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.11883\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c7faa44bde54f017e164ad8e687bd1963005988\",\"title\":\"Revisiting Modulated Convolutions for Visual Counting and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/6c7faa44bde54f017e164ad8e687bd1963005988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06666\",\"authors\":[{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1932edb4e5b2aae30ec1e7344b16d6110f52ef4\",\"title\":\"VirTex: Learning Visual Representations from Textual Annotations\",\"url\":\"https://www.semanticscholar.org/paper/b1932edb4e5b2aae30ec1e7344b16d6110f52ef4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1707.04968\",\"authors\":[{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00729\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"title\":\"Visual Question Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66353591\",\"name\":\"Amaia Salvador Aguilera\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"title\":\"Computer vision beyond the visible : image understanding through language\",\"url\":\"https://www.semanticscholar.org/paper/4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"46848045\",\"name\":\"S. Ghosh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"080a2805853cc0e5a8cba05af1fb7a65ace8f6d7\",\"title\":\"LANGUAGE MODELS MORE GROUNDED\",\"url\":\"https://www.semanticscholar.org/paper/080a2805853cc0e5a8cba05af1fb7a65ace8f6d7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.01678\",\"authors\":[{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"1388323535\",\"name\":\"Hadar Averbuch-Elor\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/2020.acl-main.234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff80f56fe0977836fdb232a058fbebc1c2d5bbac\",\"title\":\"What is Learned in Visually Grounded Neural Syntax Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/ff80f56fe0977836fdb232a058fbebc1c2d5bbac\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50627194\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"143924106\",\"name\":\"R. Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.3390/s20174761\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4f1217919ef803a0549822039f5328ea78f80ff\",\"title\":\"Indoor Scene Change Captioning Based on Multimodality Data\",\"url\":\"https://www.semanticscholar.org/paper/c4f1217919ef803a0549822039f5328ea78f80ff\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2004.00849\",\"authors\":[{\"authorId\":\"47272083\",\"name\":\"Zhicheng Huang\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1453953482\",\"name\":\"Bei Liu\"},{\"authorId\":\"143890169\",\"name\":\"Dongmei Fu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c188874316557d501369e611a96cafc8058dffa\",\"title\":\"Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/5c188874316557d501369e611a96cafc8058dffa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02032\",\"authors\":[{\"authorId\":\"1381855534\",\"name\":\"Hammad A. Ayyubi\"},{\"authorId\":\"35631602\",\"name\":\"Md. Mehrab Tanjim\"},{\"authorId\":\"35660011\",\"name\":\"Julian McAuley\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c12fe78517a7ec091916d5e2514aa7e4f4b52a03\",\"title\":\"Generating Rationales in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c12fe78517a7ec091916d5e2514aa7e4f4b52a03\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.04405\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2019.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dc698077cb178286c737484dcf67c5ab19314d0\",\"title\":\"Language-Conditioned Graph Networks for Relational Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2dc698077cb178286c737484dcf67c5ab19314d0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1806.08409\",\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICASSP.2019.8682583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"title\":\"End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features\",\"url\":\"https://www.semanticscholar.org/paper/85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711219\",\"name\":\"Juzheng Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"47672848\",\"name\":\"Siyu Wang\"},{\"authorId\":\"145803573\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f783d93b983841804a9633a37dfbc624bf5d9bfb\",\"title\":\"Textbook Question Answering Under Instructor Guidance with Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/f783d93b983841804a9633a37dfbc624bf5d9bfb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2005.09241\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"1692540612\",\"name\":\"Christopher Kanan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad322ec0617a9bdf1dabd2a51e626a9c474ed9e3\",\"title\":\"On the Value of Out-of-Distribution Testing: An Example of Goodhart's Law\",\"url\":\"https://www.semanticscholar.org/paper/ad322ec0617a9bdf1dabd2a51e626a9c474ed9e3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.13681\",\"authors\":[{\"authorId\":\"20657367\",\"name\":\"A. Mani\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"},{\"authorId\":\"2029244392\",\"name\":\"Nobline Yoo\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"title\":\"Point and Ask: Incorporating Pointing into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.01499\",\"authors\":[{\"authorId\":\"90475778\",\"name\":\"Qing Li\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"151261268\",\"name\":\"Yining Hong\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58536-5_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2d6fee1cc06354fdb3811aaa06910f4e34cd4a7\",\"title\":\"A Competence-aware Curriculum for Visual Concepts Learning via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2d6fee1cc06354fdb3811aaa06910f4e34cd4a7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.03755\",\"authors\":[{\"authorId\":\"27549522\",\"name\":\"Goonmeet Bajaj\"},{\"authorId\":\"153100367\",\"name\":\"B. Bandyopadhyay\"},{\"authorId\":\"144545992\",\"name\":\"D. Schmidt\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"32264523\",\"name\":\"Christopher W. Myers\"},{\"authorId\":\"143724543\",\"name\":\"S. Parthasarathy\"}],\"doi\":\"10.1109/CVPRW50498.2020.00201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"title\":\"Understanding Knowledge Gaps in Visual Question Answering: Implications for Gap Identification and Testing\",\"url\":\"https://www.semanticscholar.org/paper/e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49039966\",\"name\":\"W. Zhang\"},{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1492131589\",\"name\":\"Yue Hu\"}],\"doi\":\"10.1016/j.knosys.2020.106150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14663f521f8c2590d94cb00094ae1353558f2585\",\"title\":\"Cross-modal learning with prior visual relation knowledge\",\"url\":\"https://www.semanticscholar.org/paper/14663f521f8c2590d94cb00094ae1353558f2585\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2003.04679\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"}],\"doi\":\"10.1145/3366423.3380191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab771b7431f5d3dce4372a18555f4216528ace7\",\"title\":\"Learning to Respond with Stickers: A Framework of Unifying Multi-Modality in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/3ab771b7431f5d3dce4372a18555f4216528ace7\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"2004.14025\",\"authors\":[{\"authorId\":\"79778234\",\"name\":\"Sungjin Park\"},{\"authorId\":\"89016637\",\"name\":\"T. Whang\"},{\"authorId\":\"3037023\",\"name\":\"Y. Yoon\"},{\"authorId\":\"1450703435\",\"name\":\"Hueiseok Lim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"title\":\"Multi-View Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10802\",\"authors\":[{\"authorId\":\"2239880\",\"name\":\"I. Gat\"},{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"da5dde64865d7620079e0f50ef27b32bbebef7af\",\"title\":\"Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies\",\"url\":\"https://www.semanticscholar.org/paper/da5dde64865d7620079e0f50ef27b32bbebef7af\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"title\":\"IGURE QA : A N A NNOTATED F IGURE D ATASET FOR V ISUAL R EASONING\",\"url\":\"https://www.semanticscholar.org/paper/cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.01810\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708631\",\"name\":\"Bailin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tpami.2019.2943456\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"title\":\"Interpretable Visual Question Answering by Reasoning on Dependency Trees\",\"url\":\"https://www.semanticscholar.org/paper/97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2008.12520\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"82729121\",\"name\":\"Chentao Ye\"},{\"authorId\":\"9071958\",\"name\":\"Zihua Liu\"},{\"authorId\":\"32104754\",\"name\":\"Qingtao Hu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"title\":\"A Dataset and Baselines for Visual Question Answering on Art\",\"url\":\"https://www.semanticscholar.org/paper/fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47127499\",\"name\":\"R. Rao\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"144478564\",\"name\":\"Elnaz Nouri\"},{\"authorId\":\"1780951\",\"name\":\"Debadeepta Dey\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":\"10.1109/CVPRW50498.2020.00486\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b9c8fa914be1c59f3d5ad1a5e7e41164e4ca5b2\",\"title\":\"Quality and Relevance Metrics for Selection of Multimodal Pretraining Data\",\"url\":\"https://www.semanticscholar.org/paper/0b9c8fa914be1c59f3d5ad1a5e7e41164e4ca5b2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961846\",\"name\":\"Y. Wu\"},{\"authorId\":\"32435488\",\"name\":\"Huiyi Gao\"},{\"authorId\":\"47818720\",\"name\":\"L. Chen\"}],\"doi\":\"10.1117/12.2574575\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a5a567cc381c97c73144a1c36ba0b0c27df78ec\",\"title\":\"Improving visual question answering with pre-trained language modeling\",\"url\":\"https://www.semanticscholar.org/paper/9a5a567cc381c97c73144a1c36ba0b0c27df78ec\",\"venue\":\"International Workshop on Pattern Recognition\",\"year\":2020},{\"arxivId\":\"2008.09105\",\"authors\":[{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V34I07.6737\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"title\":\"Location-Aware Graph Convolutional Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37438942\",\"name\":\"Masayasu Muraoka\"},{\"authorId\":\"22312240\",\"name\":\"Ryosuke Kohita\"},{\"authorId\":\"38524906\",\"name\":\"Etsuko Ishii\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"157308295063f4a5d8bcb90c5828ad696bc3cf17\",\"title\":\"Image Position Prediction in Multimodal Documents\",\"url\":\"https://www.semanticscholar.org/paper/157308295063f4a5d8bcb90c5828ad696bc3cf17\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1909.08453\",\"authors\":[{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"7533195\",\"name\":\"Desen Zhou\"},{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"2332078\",\"name\":\"Rongjie Li\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/ICCV.2019.00956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"title\":\"Pose-Aware Multi-Level Feature Network for Human Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1712.08697\",\"authors\":[{\"authorId\":\"3545259\",\"name\":\"A. Trott\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"title\":\"Interpretable Counting for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.02673\",\"authors\":[{\"authorId\":\"72825141\",\"name\":\"M. Nazarczuk\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/ICRA40945.2020.9197332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bea5f30c145a0675418d04941b2eee77f4e9008\",\"title\":\"SHOP-VRB: A Visual Reasoning Benchmark for Object Perception\",\"url\":\"https://www.semanticscholar.org/paper/1bea5f30c145a0675418d04941b2eee77f4e9008\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"7187373\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"49112842\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-20887-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"title\":\"Answer Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49530191\",\"name\":\"S. Bhattacharya\"},{\"authorId\":\"2757153\",\"name\":\"Rajeev Agrawal\"},{\"authorId\":\"1812598\",\"name\":\"Neal Wagner\"}],\"doi\":\"10.1145/3281375.3281405\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a84b972b385109fc9eb76522de8344a5d495763\",\"title\":\"Application of deep learning and geo-knowledge bases to scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/7a84b972b385109fc9eb76522de8344a5d495763\",\"venue\":\"MEDES\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490966079\",\"name\":\"A. Calabrese\"},{\"authorId\":\"143802044\",\"name\":\"Michele Bevilacqua\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.18653/v1/2020.acl-main.425\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"36d7e8c618bbc5e59ba3d13d7cce7e94d829eea5\",\"title\":\"Fatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts\",\"url\":\"https://www.semanticscholar.org/paper/36d7e8c618bbc5e59ba3d13d7cce7e94d829eea5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1812.00500\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.01074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"title\":\"Multi-Task Learning of Hierarchical Vision-Language Representation\",\"url\":\"https://www.semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88999446\",\"name\":\"Lovish Chum\"},{\"authorId\":\"37390198\",\"name\":\"A. Subramanian\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1007/s41745-019-0099-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"title\":\"Beyond Supervised Learning: A Computer Vision Perspective\",\"url\":\"https://www.semanticscholar.org/paper/d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"venue\":\"Journal of the Indian Institute of Science\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47220354\",\"name\":\"Pingping Huang\"},{\"authorId\":\"47513298\",\"name\":\"J. Huang\"},{\"authorId\":\"46791647\",\"name\":\"Y. Guo\"},{\"authorId\":\"49605671\",\"name\":\"M. Qiao\"},{\"authorId\":\"143756111\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.18653/v1/P19-1349\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"144f4d5dcd0b13935ff0d0890c2ec37aa40039b1\",\"title\":\"Multi-grained Attention with Object-level Grounding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/144f4d5dcd0b13935ff0d0890c2ec37aa40039b1\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1912.12394\",\"authors\":[{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4aa5454addde1542e0d01cfc68e6f5129630964d\",\"title\":\"All-in-One Image-Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/4aa5454addde1542e0d01cfc68e6f5129630964d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.14973\",\"authors\":[{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"},{\"authorId\":\"3445289\",\"name\":\"Ayush Shrivastava\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/978-3-030-58539-6_16\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1ac487f21829ef56c8ffdcd37ea414bce68c809\",\"title\":\"Improving Vision-and-Language Navigation with Image-Text Pairs from the Web\",\"url\":\"https://www.semanticscholar.org/paper/d1ac487f21829ef56c8ffdcd37ea414bce68c809\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.14545\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"46933964\",\"name\":\"Gabrielle Ras\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73055bab69d4f0d3b337bf83bae6ad5cc7604d7b\",\"title\":\"Explainable Deep Learning: A Field Guide for the Uninitiated\",\"url\":\"https://www.semanticscholar.org/paper/73055bab69d4f0d3b337bf83bae6ad5cc7604d7b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.12763\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145160922\",\"name\":\"Bryan Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e12a3e3f3f383f222b5d2007802d7b7944364301\",\"title\":\"Temporal Localization of Moments in Video Collections with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/e12a3e3f3f383f222b5d2007802d7b7944364301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1709.08203\",\"authors\":[{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"2462516\",\"name\":\"Shagun Sodhani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e23229289b1fbea14bc425718bc0a227d100b8e\",\"title\":\"Survey of Recent Advances in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0e23229289b1fbea14bc425718bc0a227d100b8e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2010.07212\",\"authors\":[{\"authorId\":\"2852125\",\"name\":\"Debajyoti Datta\"},{\"authorId\":\"38179236\",\"name\":\"Shashwat Kumar\"},{\"authorId\":\"1771388\",\"name\":\"L. Barnes\"},{\"authorId\":\"1952684760\",\"name\":\"Tom Fletcher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32e96910a8a76f1e037f18c01f89c6367491153d\",\"title\":\"Geometry matters: Exploring language examples at the decision boundary\",\"url\":\"https://www.semanticscholar.org/paper/32e96910a8a76f1e037f18c01f89c6367491153d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.10079\",\"authors\":[{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"title\":\"Overcoming Statistical Shortcuts for Open-ended Visual Counting\",\"url\":\"https://www.semanticscholar.org/paper/b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.02164\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1387254703\",\"name\":\"Giuseppe Carenini\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"title\":\"An Improved Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1482482570\",\"name\":\"Jing Yu\"},{\"authorId\":\"153482287\",\"name\":\"Tao Wan\"}],\"doi\":\"10.1109/ICIP40778.2020.9190771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce990e1eb9879f71c4af25381d7a5949e538c019\",\"title\":\"Prior Visual Relationship Reasoning For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ce990e1eb9879f71c4af25381d7a5949e538c019\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1807.09956\",\"authors\":[{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"36c3972569a6949ecca90bfa6f8e99883e092845\",\"title\":\"Pythia v0.1: the Winning Entry to the VQA Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/36c3972569a6949ecca90bfa6f8e99883e092845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"50262380\",\"name\":\"Yu Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6dedf6d25df2a5cd727a019b613953afc9a0300\",\"title\":\"Pythia-A platform for vision & language research\",\"url\":\"https://www.semanticscholar.org/paper/d6dedf6d25df2a5cd727a019b613953afc9a0300\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2376695\",\"name\":\"A. Patil\"},{\"authorId\":\"52225414\",\"name\":\"Amrita Behera\"},{\"authorId\":\"144515161\",\"name\":\"P. Anusha\"},{\"authorId\":\"1455644032\",\"name\":\"Mitali Seth\"},{\"authorId\":\"1455386475\",\"name\":\"Prabhuling\"}],\"doi\":\"10.1109/TENCON.2019.8929263\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"73156fde14fdaa27de466a8f39b92a41a4b876cc\",\"title\":\"Speech Enabled Visual Question Answering using LSTM and CNN with Real Time Image Capturing for assisting the Visually Impaired\",\"url\":\"https://www.semanticscholar.org/paper/73156fde14fdaa27de466a8f39b92a41a4b876cc\",\"venue\":\"TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1908.03289\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"title\":\"Question-Agnostic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577606322\",\"name\":\"Shrey Nahar\"},{\"authorId\":\"1576127863\",\"name\":\"S. Naik\"},{\"authorId\":\"15488883\",\"name\":\"Niti H Shah\"},{\"authorId\":\"49485385\",\"name\":\"Saumya Shah\"},{\"authorId\":\"9079986\",\"name\":\"Lakshmi Kurup\"}],\"doi\":\"10.1007/978-3-030-38445-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bac534a3a2672297db2a76a4491b275e464bdbd\",\"title\":\"Automated Question Generation and Answer Verification Using Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/1bac534a3a2672297db2a76a4491b275e464bdbd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.05406\",\"authors\":[{\"authorId\":\"4631835\",\"name\":\"Mingzhe Li\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"47357425\",\"name\":\"S. Gao\"},{\"authorId\":\"51177175\",\"name\":\"Zhangming Chan\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ed35a45f0d912afe37b915a30e2b254b946e10d\",\"title\":\"VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles\",\"url\":\"https://www.semanticscholar.org/paper/3ed35a45f0d912afe37b915a30e2b254b946e10d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.08163\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2018.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"title\":\"DVQA: Understanding Data Visualizations via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.18653/v1/P18-5004\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"532837c431617d37c03361ba5a7d5fdb082c55f4\",\"title\":\"Connecting Language and Vision to Actions\",\"url\":\"https://www.semanticscholar.org/paper/532837c431617d37c03361ba5a7d5fdb082c55f4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2007.09592\",\"authors\":[{\"authorId\":\"47043894\",\"name\":\"Ruixue Tang\"},{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1007/978-3-030-58529-7_26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff560bbf5c11894379d7e808683d553e3d1f08c2\",\"title\":\"Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ff560bbf5c11894379d7e808683d553e3d1f08c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1902.04955\",\"authors\":[{\"authorId\":\"74437294\",\"name\":\"Sk. Arif Ahmed\"},{\"authorId\":\"3320759\",\"name\":\"D. P. Dogra\"},{\"authorId\":\"32614479\",\"name\":\"S. Kar\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"}],\"doi\":\"10.1016/j.patcog.2020.107412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b494a6f745d5601bd37f02a82fda2f15c90c71c1\",\"title\":\"Can We Automate Diagrammatic Reasoning?\",\"url\":\"https://www.semanticscholar.org/paper/b494a6f745d5601bd37f02a82fda2f15c90c71c1\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2012.14891\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Japsimar Singh Wahi\"},{\"authorId\":\"1557382867\",\"name\":\"Siyao Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32cdd9d0d4d462a2ca781f0c7cdbc053f6a07938\",\"title\":\"Detecting Hate Speech in Multi-modal Memes\",\"url\":\"https://www.semanticscholar.org/paper/32cdd9d0d4d462a2ca781f0c7cdbc053f6a07938\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103567595\",\"name\":\"Shayan Hassantabar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"880760777e3671593ba50b7a17b0d30b655fc86d\",\"title\":\"Visual Question Answering : Datasets , Methods , Challenges and Oppurtunities\",\"url\":\"https://www.semanticscholar.org/paper/880760777e3671593ba50b7a17b0d30b655fc86d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50826496\",\"name\":\"Jiannan Fang\"},{\"authorId\":\"74213550\",\"name\":\"Lingling Sun\"},{\"authorId\":null,\"name\":\"Yaqi Wang\"}],\"doi\":\"10.1117/12.2539615\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e077e28cadfc36eda163a01702deb795824d939\",\"title\":\"Video question answering by frame attention\",\"url\":\"https://www.semanticscholar.org/paper/6e077e28cadfc36eda163a01702deb795824d939\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47111044\",\"name\":\"Mingqin Chen\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"145675052\",\"name\":\"Shan Chen\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"}],\"doi\":\"10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00167\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"title\":\"Counting Attention Based on Classification Confidence for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"venue\":\"2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2596437\",\"name\":\"S. W. Kim\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffe11e74e99e152964fc64f7387b5a944a76983b\",\"title\":\"Progressive Reasoning by Module Composition\",\"url\":\"https://www.semanticscholar.org/paper/ffe11e74e99e152964fc64f7387b5a944a76983b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.02257\",\"authors\":[{\"authorId\":\"1414497291\",\"name\":\"Edgar Margffoy-Tuay\"},{\"authorId\":\"152978592\",\"name\":\"Juan C. P\\u00e9rez\"},{\"authorId\":\"51049657\",\"name\":\"E. Botero\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"}],\"doi\":\"10.1007/978-3-030-01252-6_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"title\":\"Dynamic Multimodal Instance Segmentation guided by natural language queries\",\"url\":\"https://www.semanticscholar.org/paper/810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"title\":\"Mind Your Language: Learning Visually Grounded Dialog in a Multi-Agent Setting\",\"url\":\"https://www.semanticscholar.org/paper/bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450120\",\"name\":\"Phung Lai\"},{\"authorId\":\"11032760\",\"name\":\"Nhathai Phan\"},{\"authorId\":\"2325975\",\"name\":\"D. Newman\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"},{\"authorId\":\"1603029692\",\"name\":\"Anuja Badeti\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b6c3f0aa1f5c70c99d8486e5eb65f3c48e421bc\",\"title\":\"Ontology-based Interpretable Machine Learning with Learnable Anchors\",\"url\":\"https://www.semanticscholar.org/paper/6b6c3f0aa1f5c70c99d8486e5eb65f3c48e421bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1705.00464\",\"authors\":[{\"authorId\":\"9586147\",\"name\":\"Ted Zhang\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dc3b8a5fdceaea4b32df8552cbb5a22ef83c197\",\"title\":\"Speech-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6dc3b8a5fdceaea4b32df8552cbb5a22ef83c197\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.09073\",\"authors\":[{\"authorId\":\"49869982\",\"name\":\"J. Kruk\"},{\"authorId\":\"104128958\",\"name\":\"Jonah Lubin\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.18653/v1/D19-1469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75e40feb1d09c9bcfe8e6b080f40e6a6ffd03800\",\"title\":\"Integrating Text and Image: Determining Multimodal Document Intent in Instagram Posts\",\"url\":\"https://www.semanticscholar.org/paper/75e40feb1d09c9bcfe8e6b080f40e6a6ffd03800\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145280977\",\"name\":\"Cheng Shi\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"24545031\",\"name\":\"Jiayin Cai\"},{\"authorId\":\"41017837\",\"name\":\"Zhuobin Zheng\"},{\"authorId\":\"16129585\",\"name\":\"Yangyang Cheng\"},{\"authorId\":\"1754924\",\"name\":\"Zhihui Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42152899eecae52cbf2f3f3459a7d4eaefda6978\",\"title\":\"Conditional Kronecker Batch Normalization for Compositional Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/42152899eecae52cbf2f3f3459a7d4eaefda6978\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"},{\"authorId\":\"145380213\",\"name\":\"B. He\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207058\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99a01a687f7959de4c86102342d4bcfec6382aa8\",\"title\":\"Multi-Channel Co-Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99a01a687f7959de4c86102342d4bcfec6382aa8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2001.06927\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"title\":\"SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":\"10.18653/v1/2020.acl-main.469\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"title\":\"What Does BERT with Vision Look At?\",\"url\":\"https://www.semanticscholar.org/paper/cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1909.03683\",\"authors\":[{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/D19-1418\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba783d92d0eaf6a7bff6ced7660150ce38016bbc\",\"title\":\"Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases\",\"url\":\"https://www.semanticscholar.org/paper/ba783d92d0eaf6a7bff6ced7660150ce38016bbc\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/W19-2912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4036759404c6fa54a040b69bcfd4996083cb3aa\",\"title\":\"Quantifiers in a Multimodal World: Hallucinating Vision with Language and Sound\",\"url\":\"https://www.semanticscholar.org/paper/f4036759404c6fa54a040b69bcfd4996083cb3aa\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.06409\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"title\":\"Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.09964\",\"authors\":[{\"authorId\":\"3167650\",\"name\":\"Sai Krishna Rallabandi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e2f2cbe81d1af3bc5c7fb11d92c728308f9832e\",\"title\":\"On Controlled DeEntanglement for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/3e2f2cbe81d1af3bc5c7fb11d92c728308f9832e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.04380\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"48926630\",\"name\":\"Adam Poliak\"},{\"authorId\":\"1692491\",\"name\":\"S. Shieber\"},{\"authorId\":\"7536576\",\"name\":\"Benjamin Van Durme\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":\"10.18653/v1/P19-1084\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6540ee01a87c3b3435da73f4e3297489d525c151\",\"title\":\"Don't Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/6540ee01a87c3b3435da73f4e3297489d525c151\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1811.12354\",\"authors\":[{\"authorId\":\"27936309\",\"name\":\"Howard Chen\"},{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"31498163\",\"name\":\"Dipendra Kumar Misra\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.1109/CVPR.2019.01282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5cc6634724b2238c88bcc324ec01a2c91c1b909\",\"title\":\"TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments\",\"url\":\"https://www.semanticscholar.org/paper/b5cc6634724b2238c88bcc324ec01a2c91c1b909\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.02088\",\"authors\":[{\"authorId\":\"145659406\",\"name\":\"Y. Shi\"},{\"authorId\":\"2426872\",\"name\":\"T. Furlanello\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":\"10.1007/978-3-030-01225-0_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"title\":\"Question Type Guided Attention in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.02453\",\"authors\":[{\"authorId\":\"28458352\",\"name\":\"S. Kim\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f27b833c4a0dcb809215b185e8e2601aef6e7fb8\",\"title\":\"Visual Reasoning by Progressive Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/f27b833c4a0dcb809215b185e8e2601aef6e7fb8\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2002.04108\",\"authors\":[{\"authorId\":\"39227408\",\"name\":\"Ronan Le Bras\"},{\"authorId\":\"2705113\",\"name\":\"Swabha Swayamdipta\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"39139825\",\"name\":\"Matthew E. Peters\"},{\"authorId\":\"48229640\",\"name\":\"A. Sabharwal\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7845c424b541c6d608fd052b6345607bcc113fc3\",\"title\":\"Adversarial Filters of Dataset Biases\",\"url\":\"https://www.semanticscholar.org/paper/7845c424b541c6d608fd052b6345607bcc113fc3\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122822134\",\"name\":\"Gregory Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"145901595\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2b840276017c04e090058e281431379d35de88b\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Security Video\",\"url\":\"https://www.semanticscholar.org/paper/a2b840276017c04e090058e281431379d35de88b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1908.06306\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/ICCV.2019.00754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"title\":\"U-CAM: Visual Explanation Using Uncertainty Based Class Activation Maps\",\"url\":\"https://www.semanticscholar.org/paper/5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"46264474\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICDAR.2019.00156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1097cf8cf5961589ff693b069002e7181e24e631\",\"title\":\"OCR-VQA: Visual Question Answering by Reading Text in Images\",\"url\":\"https://www.semanticscholar.org/paper/1097cf8cf5961589ff693b069002e7181e24e631\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8d37d9522d57df506a6eda88953bd97c009ea29\",\"title\":\"Characterizing how Visual Question Answering models scale with the world\",\"url\":\"https://www.semanticscholar.org/paper/e8d37d9522d57df506a6eda88953bd97c009ea29\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.11543\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPRW.2018.00279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1808.02559\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"153188107\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-01234-2_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8befcd91c24038e5c26df0238d26e2311b21719a\",\"title\":\"A Joint Sequence Fusion Model for Video Question Answering and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8befcd91c24038e5c26df0238d26e2311b21719a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1902.00038\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1609/aaai.v33i01.33018102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"title\":\"BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2007.02833\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"title\":\"Eliminating Catastrophic Interference with Biased Competition\",\"url\":\"https://www.semanticscholar.org/paper/07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50627194\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"143924106\",\"name\":\"R. Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.3390/s20082281\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"779a14591ce143820a3d8c7661e04454329e3abc\",\"title\":\"Multi-View Visual Question Answering with Active Viewpoint Selection\",\"url\":\"https://www.semanticscholar.org/paper/779a14591ce143820a3d8c7661e04454329e3abc\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2003.13962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01276\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"title\":\"Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text\",\"url\":\"https://www.semanticscholar.org/paper/c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1417435649\",\"name\":\"D. Garc\\u00eda-Retuerta\"},{\"authorId\":\"1410144123\",\"name\":\"Roberto Casado-Vara\"},{\"authorId\":\"1398089247\",\"name\":\"J. Calvo-Rolle\"},{\"authorId\":\"1400332875\",\"name\":\"H\\u00e9ctor Quinti\\u00e1n-Pardo\"},{\"authorId\":\"104469761\",\"name\":\"Javier Prieto\"}],\"doi\":\"10.1007/978-3-030-61705-9_58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ac65fb356153e1a5817192445b77e3912be9b91\",\"title\":\"Deep Learning for House Categorisation, a Proposal Towards Automation in Land Registry\",\"url\":\"https://www.semanticscholar.org/paper/4ac65fb356153e1a5817192445b77e3912be9b91\",\"venue\":\"HAIS\",\"year\":2020},{\"arxivId\":\"1904.02794\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"93155387\",\"name\":\"Karan Jariwala\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/N19-1194\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f17f7590a6b4488921f046112bc8fdb82d513914\",\"title\":\"VQD: Visual Query Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/f17f7590a6b4488921f046112bc8fdb82d513914\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.07280\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"12139064\",\"name\":\"Jake Bruce\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00387\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bd9642470ff8c2089427f7a6392cd17d213a334\",\"title\":\"Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\",\"url\":\"https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.00313\",\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab88c48e7829029c47ac6deea5c0ccbff3614c5c\",\"title\":\"Rethinking Visual Relationships for High-level Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ab88c48e7829029c47ac6deea5c0ccbff3614c5c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2004.07790\",\"authors\":[{\"authorId\":\"1637185408\",\"name\":\"Joe Stacey\"},{\"authorId\":\"3051815\",\"name\":\"Pasquale Minervini\"},{\"authorId\":\"2026652\",\"name\":\"Haim Dubossarsky\"},{\"authorId\":\"48662861\",\"name\":\"Sebastian Riedel\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1def7b029df7d37962fd684ea5ae7a7d7e99491\",\"title\":\"There is Strength in Numbers: Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/a1def7b029df7d37962fd684ea5ae7a7d7e99491\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.acl-main.644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4887113b68c6b9dfda201019c99bcb99b18d642e\",\"title\":\"Refer360\\u2218: A Referring Expression Recognition Dataset in 360: A Referring Expression Recognition Dataset in 360\\u2218 Images Images\",\"url\":\"https://www.semanticscholar.org/paper/4887113b68c6b9dfda201019c99bcb99b18d642e\",\"venue\":\"ACL 2020\",\"year\":2020},{\"arxivId\":\"2004.13606\",\"authors\":[{\"authorId\":\"50177485\",\"name\":\"Xiang Zhou\"},{\"authorId\":\"40383658\",\"name\":\"Yixin Nie\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82a44fbe798d514c81439c90c655975a32c2af10\",\"title\":\"The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions\",\"url\":\"https://www.semanticscholar.org/paper/82a44fbe798d514c81439c90c655975a32c2af10\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51151974\",\"name\":\"Prakruthi Prabhakar\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b56b001dff2e13f8b6488a9473163fff31f2953f\",\"title\":\"Question Relevance in VisualQuestion Answering\",\"url\":\"https://www.semanticscholar.org/paper/b56b001dff2e13f8b6488a9473163fff31f2953f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1903.06994\",\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"7573997\",\"name\":\"Huayi Zhan\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"67250414\",\"name\":\"B. Sinha\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2019.00855\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"title\":\"Visual Query Answering by Entity-Attribute Graph Matching and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb4fc76dc335f89d258f38676ea6e92c9ddf66c6\",\"title\":\"Multimodal Learning and Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb4fc76dc335f89d258f38676ea6e92c9ddf66c6\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2959229\",\"name\":\"Fran\\u00e7ois Plesse\"},{\"authorId\":\"46176716\",\"name\":\"Alexandru Ginsca\"},{\"authorId\":\"1770571\",\"name\":\"Bertrand Delezoide\"},{\"authorId\":\"1699611762\",\"name\":\"Fran\\u00e7oise Pr\\u00eateux\"}],\"doi\":\"10.1109/WACV45572.2020.9093605\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f827c7fbabdba9d34023570998d021729e78ad69\",\"title\":\"Focusing Visual Relation Detection on Relevant Relations with Prior Potentials\",\"url\":\"https://www.semanticscholar.org/paper/f827c7fbabdba9d34023570998d021729e78ad69\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1711.01732\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b72e34bc281b44a7d4edc990dcb781c89afc28\",\"title\":\"Active Learning for Visual Question Answering: An Empirical Study\",\"url\":\"https://www.semanticscholar.org/paper/52b72e34bc281b44a7d4edc990dcb781c89afc28\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50414739\",\"name\":\"S. Sun\"},{\"authorId\":\"144204682\",\"name\":\"Francisco Guzm\\u00e1n\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/2020.acl-main.558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29aceafb7d5a593bd08ce4d7628a0cc8aa9ace3a\",\"title\":\"Are we Estimating or Guesstimating Translation Quality?\",\"url\":\"https://www.semanticscholar.org/paper/29aceafb7d5a593bd08ce4d7628a0cc8aa9ace3a\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1808.00300\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"}],\"doi\":\"10.1007/978-3-030-01231-1_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afe3a0d463e2f099305c745ddbf943844583795d\",\"title\":\"Learning Visual Question Answering by Bootstrapping Hard Attention\",\"url\":\"https://www.semanticscholar.org/paper/afe3a0d463e2f099305c745ddbf943844583795d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317148\",\"name\":\"Z. Zhang\"},{\"authorId\":null,\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213537\",\"name\":\"X. Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7937ad963f18675d2dc802d94f672180c037fde\",\"title\":\"Color dark Taxonomy nightdress Length short Material cotton Type casual Color beige Taxonomy nightdress Length mini Material silk Type patchwork Color dark Taxonomy nightdress Length\",\"url\":\"https://www.semanticscholar.org/paper/a7937ad963f18675d2dc802d94f672180c037fde\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40430910\",\"name\":\"Xue-bo Jin\"},{\"authorId\":\"2847804\",\"name\":\"Tingli Su\"},{\"authorId\":\"26434105\",\"name\":\"Jian-Lei Kong\"},{\"authorId\":\"49953758\",\"name\":\"Y. Bai\"},{\"authorId\":\"2762520\",\"name\":\"Bei-bei Miao\"},{\"authorId\":\"47168401\",\"name\":\"Chao Dou\"}],\"doi\":\"10.3390/APP8030379\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c98c4eed7a9ce6fc79b2824c989525262726aae\",\"title\":\"State-of-the-Art Mobile Intelligence: Enabling Robots to Move Like Humans by Estimating Mobility with Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/3c98c4eed7a9ce6fc79b2824c989525262726aae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.04926\",\"authors\":[{\"authorId\":\"9264826\",\"name\":\"Divyansh Kaushik\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"}],\"doi\":\"10.18653/v1/D18-1546\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c66240239263f16159eef166a391d3939ae2d5\",\"title\":\"How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks\",\"url\":\"https://www.semanticscholar.org/paper/e0c66240239263f16159eef166a391d3939ae2d5\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1802.00209\",\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b66dababebd800e95d23a1fde299d44a52e98ed\",\"title\":\"Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7b66dababebd800e95d23a1fde299d44a52e98ed\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"11882893\",\"name\":\"A. Yang\"},{\"authorId\":\"29343468\",\"name\":\"Yichang Zhang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"1709595\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"38385080\",\"name\":\"Hongxia Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee4918cc9b1dc28007454490fbe8366ec017b33d\",\"title\":\"InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/ee4918cc9b1dc28007454490fbe8366ec017b33d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.11457\",\"authors\":[{\"authorId\":\"51230998\",\"name\":\"Alceu Bissoto\"},{\"authorId\":\"145487017\",\"name\":\"E. Valle\"},{\"authorId\":\"145773463\",\"name\":\"S. Avila\"}],\"doi\":\"10.1109/cvprw50498.2020.00378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd9cc3707fe1e1f85c1fa3963378c745bc75ba86\",\"title\":\"Debiasing Skin Lesion Datasets and Models? Not So Fast\",\"url\":\"https://www.semanticscholar.org/paper/dd9cc3707fe1e1f85c1fa3963378c745bc75ba86\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"14898006\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"145947071\",\"name\":\"Jing Qin\"}],\"doi\":\"10.1109/TNNLS.2019.2933439\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"title\":\"Exploring Duality in Visual Question-Driven Top-Down Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1909.02097\",\"authors\":[{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"144865339\",\"name\":\"Bo Pang\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/D19-1155\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3b6e6822eabe2f64192a1965c23e38043866319c\",\"title\":\"Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic Labels Improve Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3b6e6822eabe2f64192a1965c23e38043866319c\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350993\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"title\":\"Erasing-based Attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30486913\",\"name\":\"Yuelian Wang\"},{\"authorId\":\"144282470\",\"name\":\"W. Pan\"}],\"doi\":\"10.1007/978-981-10-7305-2_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77a5b9e9b0fd15687601ddc83d1a0e309dc13400\",\"title\":\"Scene Recognition with Sequential Object Context\",\"url\":\"https://www.semanticscholar.org/paper/77a5b9e9b0fd15687601ddc83d1a0e309dc13400\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"2012.01634\",\"authors\":[{\"authorId\":\"47989608\",\"name\":\"Ankit Goyal\"},{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"150084688\",\"name\":\"Dawei Yang\"},{\"authorId\":\"2026954992\",\"name\":\"Jia Deng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4d3f7ee5ccfefe8e132d5f394a683034b2eeec7\",\"title\":\"Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D\",\"url\":\"https://www.semanticscholar.org/paper/c4d3f7ee5ccfefe8e132d5f394a683034b2eeec7\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1904.01410\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"title\":\"Context and Attribute Grounded Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.1016/j.csl.2020.101095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"661f04ecc734ced906e16980a6143c814ce085ed\",\"title\":\"Hierarchical multimodal attention for end-to-end audio-visual scene-aware dialogue response generation\",\"url\":\"https://www.semanticscholar.org/paper/661f04ecc734ced906e16980a6143c814ce085ed\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dzmitry Bahdanau\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2eb710b446570f48377b25eb279295648d05f65d\",\"title\":\"On sample efficiency and systematic generalization of grounded language understanding with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/2eb710b446570f48377b25eb279295648d05f65d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.09034\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-58607-2_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29121a31e4d684839cfd0bb358f33ea1266cece5\",\"title\":\"Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision\",\"url\":\"https://www.semanticscholar.org/paper/29121a31e4d684839cfd0bb358f33ea1266cece5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4012d85408a97d6c0878da0932e81b6022d96c08\",\"title\":\"Insensibility of Question Word Order in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4012d85408a97d6c0878da0932e81b6022d96c08\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"51487414\",\"name\":\"Yunshan Ma\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8384387a3739280b15d38f39429aadb7c9bd620f\",\"title\":\"Knowledge-aware Multimodal Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/8384387a3739280b15d38f39429aadb7c9bd620f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1811.06529\",\"authors\":[{\"authorId\":\"79805467\",\"name\":\"Vincent Marois\"},{\"authorId\":\"2545727\",\"name\":\"T. S. Jayram\"},{\"authorId\":\"80859684\",\"name\":\"Vincent Albouy\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"81321492\",\"name\":\"Younes Bouhadjar\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12386a0d1be0877c8707aeef7196b1bc49628397\",\"title\":\"On transfer learning using a MAC model variant\",\"url\":\"https://www.semanticscholar.org/paper/12386a0d1be0877c8707aeef7196b1bc49628397\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1704.02923\",\"authors\":[{\"authorId\":\"1947259\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"145040726\",\"name\":\"Raffaella Bernardi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49af582b8e96cd69986ff21223e3fa331081d7d5\",\"title\":\"Pay Attention to Those Sets! Learning Quantification from Images\",\"url\":\"https://www.semanticscholar.org/paper/49af582b8e96cd69986ff21223e3fa331081d7d5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a212be7ec1ff75ecfee52c7c49c73d7244a87eb7\",\"title\":\"Video Scene-Aware Dialog Track in DSTC 7\",\"url\":\"https://www.semanticscholar.org/paper/a212be7ec1ff75ecfee52c7c49c73d7244a87eb7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144272754\",\"name\":\"Shi Feng\"},{\"authorId\":\"2910734\",\"name\":\"Eric S. Wallace\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c3523a2d0508ac07359d164c3e359f1c3a61b98\",\"title\":\"Old Premise Animals are running New Premise Entailment Hypothesis Animals are outdoors Label\",\"url\":\"https://www.semanticscholar.org/paper/1c3523a2d0508ac07359d164c3e359f1c3a61b98\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2455036\",\"name\":\"Kevin Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e86bf3a31ff3f55b8dae4741ee3642a82f8e6680\",\"title\":\"Learning to Caption Images by Asking Natural Language Questions\",\"url\":\"https://www.semanticscholar.org/paper/e86bf3a31ff3f55b8dae4741ee3642a82f8e6680\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669004\",\"name\":\"P. Hawkins\"},{\"authorId\":\"1737645\",\"name\":\"F. Maire\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"3019028\",\"name\":\"M. Baktash\"}],\"doi\":\"10.1109/DICTA47822.2019.8946101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b842f2d3979662ef236cbf4e5c46b707ed7052c4\",\"title\":\"Object Graph Networks for Spatial Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b842f2d3979662ef236cbf4e5c46b707ed7052c4\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1911.06352\",\"authors\":[{\"authorId\":\"49106606\",\"name\":\"J. Pan\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf43d6343076451d861561ba61f20dc5b6cf2ed\",\"title\":\"Question-Conditioned Counterfactual Image Generation for VQA\",\"url\":\"https://www.semanticscholar.org/paper/1cf43d6343076451d861561ba61f20dc5b6cf2ed\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1906.06216\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1351\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8501712706efa6f314438143de18507471781060\",\"title\":\"Improving Visual Question Answering by Referring to Generated Paragraph Captions\",\"url\":\"https://www.semanticscholar.org/paper/8501712706efa6f314438143de18507471781060\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362476\",\"name\":\"Liming Zhan\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"145451510\",\"name\":\"L. Fan\"},{\"authorId\":\"145905368\",\"name\":\"Jiaxin Chen\"},{\"authorId\":\"1772198\",\"name\":\"X. Wu\"}],\"doi\":\"10.1145/3394171.3413761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8d5b853f2212cbb48a43f1edec9b96d76d388ec\",\"title\":\"Medical Visual Question Answering via Conditional Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/b8d5b853f2212cbb48a43f1edec9b96d76d388ec\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2020.2969791\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"title\":\"Multimedia Intelligence: When Multimedia Meets Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07333\",\"authors\":[{\"authorId\":\"7754251\",\"name\":\"Sylvain Lobry\"},{\"authorId\":\"144173388\",\"name\":\"D. Marcos\"},{\"authorId\":\"1409495574\",\"name\":\"J. Murray\"},{\"authorId\":\"1404577763\",\"name\":\"D. Tuia\"}],\"doi\":\"10.1109/TGRS.2020.2988782\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b3ddddefee26c686da2e1088d21e69c594f1c3d\",\"title\":\"RSVQA: Visual Question Answering for Remote Sensing Data\",\"url\":\"https://www.semanticscholar.org/paper/0b3ddddefee26c686da2e1088d21e69c594f1c3d\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"3055431\",\"name\":\"Marco T\\u00falio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":\"10.1109/CVPR42600.2020.01002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cea494961a45d6a0687c75248fd078999d9a43\",\"title\":\"SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/27cea494961a45d6a0687c75248fd078999d9a43\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490966079\",\"name\":\"A. Calabrese\"},{\"authorId\":\"143802044\",\"name\":\"Michele Bevilacqua\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.24963/ijcai.2020/67\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"366c3f0c35ddce5e10a7e262f09c1f1518b58e27\",\"title\":\"EViLBERT: Learning Task-Agnostic Multimodal Sense Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/366c3f0c35ddce5e10a7e262f09c1f1518b58e27\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2012.11528\",\"authors\":[{\"authorId\":\"46875376\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"9228892\",\"name\":\"P. Zhang\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2020/151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0714f88deda344c87bf78569de68d9e1f0b377a7\",\"title\":\"Overcoming Language Priors with Self-supervised Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0714f88deda344c87bf78569de68d9e1f0b377a7\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2009.11278\",\"authors\":[{\"authorId\":\"2706729\",\"name\":\"Jaemin Cho\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"title\":\"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.08744\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"title\":\"Are we pretraining it right? Digging deeper into visio-linguistic pretraining\",\"url\":\"https://www.semanticscholar.org/paper/43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07214\",\"authors\":[{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"},{\"authorId\":\"48374479\",\"name\":\"Marcos Treviso\"},{\"authorId\":\"1748971692\",\"name\":\"Ant'onio Farinhas\"},{\"authorId\":\"2114966\",\"name\":\"Vlad Niculae\"},{\"authorId\":\"35129010\",\"name\":\"M. A. Figueiredo\"},{\"authorId\":\"35537344\",\"name\":\"P. Aguiar\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"09e69bf0926e55cd277a3ef5b1450ba083719cb9\",\"title\":\"Sparse and Continuous Attention Mechanisms\",\"url\":\"https://www.semanticscholar.org/paper/09e69bf0926e55cd277a3ef5b1450ba083719cb9\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29545186\",\"name\":\"M. Hosseinzadeh\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef6db51cb736116266025eb1eab2fb4f36b75310\",\"title\":\"Composed Query Image Retrieval Using Locally Bounded Features\",\"url\":\"https://www.semanticscholar.org/paper/ef6db51cb736116266025eb1eab2fb4f36b75310\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2625271\",\"name\":\"Mengfei Li\"},{\"authorId\":\"143628183\",\"name\":\"Li Gu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"title\":\"Text-Guided Dual-Branch Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1904.04792\",\"authors\":[{\"authorId\":\"145009056\",\"name\":\"Pedro Rodriguez\"},{\"authorId\":\"144588144\",\"name\":\"Shi Feng\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"91070223\",\"name\":\"He He\"},{\"authorId\":\"1389036863\",\"name\":\"Jordan L. Boyd-Graber\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"596b46dbe4fa8eee72e517ea9fd5f8ef83c9c64e\",\"title\":\"Quizbowl: The Case for Incremental Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/596b46dbe4fa8eee72e517ea9fd5f8ef83c9c64e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8193c52c32b7620c6b12dfe2643ff8c1360e38dd\",\"title\":\"A Bayesian approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8193c52c32b7620c6b12dfe2643ff8c1360e38dd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sunny Katiyar\"},{\"authorId\":\"88294723\",\"name\":\"M. Wakode\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0881b665590ac2aba58a5b3b7db93c1c4f6af15\",\"title\":\"A Survey On Visual Questioning Answering : Datasets, Approaches And Models\",\"url\":\"https://www.semanticscholar.org/paper/a0881b665590ac2aba58a5b3b7db93c1c4f6af15\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"49761595\",\"name\":\"A. Kalra\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"1764061\",\"name\":\"Sumedha Chaudhary\"},{\"authorId\":\"22267101\",\"name\":\"L. Patel\"},{\"authorId\":\"69948163\",\"name\":\"Louis-Phillippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e975bbb6cbd8216cfb920e0a1861079d0ac3535c\",\"title\":\"Attend and Attack : Attention Guided Adversarial Attacks on Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/e975bbb6cbd8216cfb920e0a1861079d0ac3535c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403486895\",\"name\":\"Diana Galv\\u00e1n-Sosa\"},{\"authorId\":\"3643976\",\"name\":\"J. Suzuki\"},{\"authorId\":\"2006479562\",\"name\":\"Kyosuke Nishida\"},{\"authorId\":\"49221941\",\"name\":\"Koji Matsuda\"},{\"authorId\":\"3040648\",\"name\":\"Kentaro Inui\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c888b7f6134f54fadd90511f32dbf0a70d6d363c\",\"title\":\"Seeing the World through Text: Evaluating Image Descriptions for Commonsense Reasoning in Machine Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c888b7f6134f54fadd90511f32dbf0a70d6d363c\",\"venue\":\"LANTERN\",\"year\":2020},{\"arxivId\":\"2003.02756\",\"authors\":[{\"authorId\":\"1500520681\",\"name\":\"Tianyu Liu\"},{\"authorId\":\"1430762233\",\"name\":\"Xin Zheng\"},{\"authorId\":\"102457636\",\"name\":\"Baobao Chang\"},{\"authorId\":\"9145566\",\"name\":\"Z. Sui\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d8dcf5e99557c7d6b7015a280e4043439ecd1a5\",\"title\":\"HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/1d8dcf5e99557c7d6b7015a280e4043439ecd1a5\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shivam Garg\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1049/iet-cvi.2018.5226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4bb5303fd5e26f411bdfa3db063acd6cff90a1\",\"title\":\"Object sequences: encoding categorical and spatial information for a yes/no visual question answering task\",\"url\":\"https://www.semanticscholar.org/paper/9a4bb5303fd5e26f411bdfa3db063acd6cff90a1\",\"venue\":\"IET Comput. Vis.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144729307\",\"name\":\"F. S\\u00e1nchez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"61c0fdfb0567cecaf48c6d4cb46c962a2b3e5b65\",\"title\":\"Visual Question Answering 2.0\",\"url\":\"https://www.semanticscholar.org/paper/61c0fdfb0567cecaf48c6d4cb46c962a2b3e5b65\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493665\",\"name\":\"Dafang He\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"1745900\",\"name\":\"Alexander N. Gorban\"},{\"authorId\":\"39099960\",\"name\":\"Derrall Heath\"},{\"authorId\":\"46920727\",\"name\":\"J. Ibarz\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1852261\",\"name\":\"D. Kifer\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"title\":\"Guided Attention for Large Scale Scene Text Verification\",\"url\":\"https://www.semanticscholar.org/paper/b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1910.00058\",\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/D19-1154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b3b563f6611f60af8ca96624191ff66b27a8f9\",\"title\":\"Multi-Head Attention with Diversity for Learning Grounded Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/99b3b563f6611f60af8ca96624191ff66b27a8f9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1007/978-3-030-58526-6_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"007ca8ca7a68451c32da034c72a06238434843c1\",\"title\":\"Learning to Learn Words from Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/007ca8ca7a68451c32da034c72a06238434843c1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1705.01359\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"13597291\",\"name\":\"Yauhen Klimovich\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/P17-1024\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"title\":\"FOIL it! Find One mismatch between Image and Language caption\",\"url\":\"https://www.semanticscholar.org/paper/c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22199114\",\"name\":\"Panos Achlioptas\"},{\"authorId\":\"30628940\",\"name\":\"Ahmed Abdelreheem\"},{\"authorId\":\"66562670\",\"name\":\"F. Xia\"},{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1007/978-3-030-58452-8_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53794499a3830c3ebb365ecc57f0e8c8a20a682d\",\"title\":\"ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes\",\"url\":\"https://www.semanticscholar.org/paper/53794499a3830c3ebb365ecc57f0e8c8a20a682d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.07310\",\"authors\":[{\"authorId\":\"1701219797\",\"name\":\"Jize Cao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"46700583\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1007/978-3-030-58539-6_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26cfb57a9722599b361858d454ec816420723e36\",\"title\":\"Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models\",\"url\":\"https://www.semanticscholar.org/paper/26cfb57a9722599b361858d454ec816420723e36\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2009.09796\",\"authors\":[{\"authorId\":\"145868671\",\"name\":\"M. Crawshaw\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"title\":\"Multi-Task Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/cvpr42600.2020.00305\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"title\":\"Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.04312\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2129412\",\"name\":\"D. Wijaya\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1007/978-3-030-58548-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"title\":\"Learning to Scale Multilingual Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8804979\",\"name\":\"Siddhesh Khandelwal\"}],\"doi\":\"10.14288/1.0384602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0217b35a52d1e6b29ab734fe8b637ddad66cbe89\",\"title\":\"Enforcing structure in visual attention\",\"url\":\"https://www.semanticscholar.org/paper/0217b35a52d1e6b29ab734fe8b637ddad66cbe89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395925001\",\"name\":\"Bj\\u00f6rn Wahle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"title\":\"Grounding semantics in robots for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48071615\",\"name\":\"Huda Alamri\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"title\":\"Audio Visual Scene-aware dialog (AVSD) Track for Natural Language Generation in DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2001.08034\",\"authors\":[{\"authorId\":\"153060461\",\"name\":\"Darryl Hannan\"},{\"authorId\":\"50658802\",\"name\":\"Akshay Jain\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6294\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b578fe40abc9ec29424d342a8d676c88a98b921\",\"title\":\"ManyModalQA: Modality Disambiguation and QA over Diverse Inputs\",\"url\":\"https://www.semanticscholar.org/paper/6b578fe40abc9ec29424d342a8d676c88a98b921\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2001.08730\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1490642986\",\"name\":\"Shivansh Pate\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a487065408c44d387aa1cf7836cd58405f945983\",\"title\":\"Robust Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a487065408c44d387aa1cf7836cd58405f945983\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1907.01166\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/P19-1564\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"title\":\"Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2010.12831\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"2513111\",\"name\":\"Zhecan Wang\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16f82c1dae2f6e5149c1be95165d7081f08298b6\",\"title\":\"Weakly-supervised VisualBERT: Pre-training without Parallel Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/16f82c1dae2f6e5149c1be95165d7081f08298b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1810.02338\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d15ebe3f5aaf32a9f835f88703241461324c35b\",\"title\":\"Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/9d15ebe3f5aaf32a9f835f88703241461324c35b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1704.03162\",\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"2544590\",\"name\":\"Ali Elqursh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d674b540dcd968bc302ea4360df3f4e85e994b55\",\"title\":\"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d674b540dcd968bc302ea4360df3f4e85e994b55\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1805.07952\",\"authors\":[{\"authorId\":\"33299173\",\"name\":\"Ozan Arkan Can\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b4a24ee122cac55b3a8b6a1cf7080244cbdf4ba\",\"title\":\"A new dataset and model for learning to understand navigational instructions\",\"url\":\"https://www.semanticscholar.org/paper/6b4a24ee122cac55b3a8b6a1cf7080244cbdf4ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.08174\",\"authors\":[{\"authorId\":\"2462516\",\"name\":\"Shagun Sodhani\"},{\"authorId\":\"7591930\",\"name\":\"Vardaan Pahuja\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0dd42c0d049b05b5d3c37cb2e64d8a307862b196\",\"title\":\"Reproducibility Report for \\\"Learning To Count Objects In Natural Images For Visual Question Answering\\\"\",\"url\":\"https://www.semanticscholar.org/paper/0dd42c0d049b05b5d3c37cb2e64d8a307862b196\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123420477\",\"name\":\"Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"346580379d4c2a962ac77dbc3a233f324252c5e8\",\"title\":\"Bilinear Pooling and Co-Attention Inspired Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/346580379d4c2a962ac77dbc3a233f324252c5e8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1806.10269\",\"authors\":[{\"authorId\":\"48571362\",\"name\":\"L. Zhang\"},{\"authorId\":\"50989204\",\"name\":\"Chenghan Fu\"},{\"authorId\":\"46275685\",\"name\":\"J. Li\"}],\"doi\":\"10.1145/3240508.3240540\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59d88030c99de99d18d16dd5ffab7c0bcf6ac58e\",\"title\":\"Collaborative Annotation of Semantic Objects in Images with Multi-granularity Supervisions\",\"url\":\"https://www.semanticscholar.org/paper/59d88030c99de99d18d16dd5ffab7c0bcf6ac58e\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1805.05492\",\"authors\":[{\"authorId\":\"2235894\",\"name\":\"Pramod Kaushik Mudrakarta\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"30740726\",\"name\":\"M. Sundararajan\"},{\"authorId\":\"1696833\",\"name\":\"K. Dhamdhere\"}],\"doi\":\"10.18653/v1/P18-1176\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4a9831e5fec549edee454709048a51997ef60fb7\",\"title\":\"Did the Model Understand the Question?\",\"url\":\"https://www.semanticscholar.org/paper/4a9831e5fec549edee454709048a51997ef60fb7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30670181\",\"name\":\"Thilini Cooray\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"153022029\",\"name\":\"W. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00479\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb8aea99913099a3496dcbc8af49d7f99edf77d2\",\"title\":\"Attention-Based Context Aware Reasoning for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb8aea99913099a3496dcbc8af49d7f99edf77d2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.00124\",\"authors\":[{\"authorId\":\"5007179\",\"name\":\"Jihyeon Janel Lee\"},{\"authorId\":\"32576042\",\"name\":\"S. Arora\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11f84eaa4eed54fe37f33e7b31f5781843ec05da\",\"title\":\"A Free Lunch in Generating Datasets: Building a VQG and VQA System with Attention and Humans in the Loop\",\"url\":\"https://www.semanticscholar.org/paper/11f84eaa4eed54fe37f33e7b31f5781843ec05da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144689860\",\"name\":\"Wei Deng\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1145/3278198.3278207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09f1980e370fd5f4e1974baf7b943d26971ea219\",\"title\":\"Flexible Sentence Analysis Model for Visual Question Answering Network\",\"url\":\"https://www.semanticscholar.org/paper/09f1980e370fd5f4e1974baf7b943d26971ea219\",\"venue\":\"ICBEB 2018\",\"year\":2018},{\"arxivId\":\"1911.09655\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":\"10.1109/TASLP.2020.3010650\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfa437129daef8533708924c395c3fd0c5c3bf81\",\"title\":\"Temporal Reasoning via Audio Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bfa437129daef8533708924c395c3fd0c5c3bf81\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774112\",\"name\":\"F. Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"57417c4a523d93801c8901d6f3c3740eaa65c9ae\",\"title\":\"Inverse Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/57417c4a523d93801c8901d6f3c3740eaa65c9ae\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1911.04058\",\"authors\":[{\"authorId\":\"48615049\",\"name\":\"Y. Xu\"},{\"authorId\":\"46308159\",\"name\":\"L. Chen\"},{\"authorId\":\"120235436\",\"name\":\"Zhongwei Cheng\"},{\"authorId\":\"71138167\",\"name\":\"Lixin Duan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.34\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"title\":\"Open-Ended Visual Question Answering by Multi-Modal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.08012\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"1882516497\",\"name\":\"Kancheti Sai Srinivas\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"title\":\"Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"title\":\"Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2004.04963\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1587/transinf.2020EDP7089\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"title\":\"Rephrasing visual questions by specifying the entropy of the answer distribution\",\"url\":\"https://www.semanticscholar.org/paper/d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1574421683\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"40282454\",\"name\":\"Y. Li\"},{\"authorId\":\"50218711\",\"name\":\"Z. Wang\"},{\"authorId\":\"15696552\",\"name\":\"Bin Wang\"}],\"doi\":\"10.1007/s11042-020-08790-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"title\":\"Object-difference drived graph convolutional networks for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144128023\",\"name\":\"Youcai Zhang\"},{\"authorId\":\"47470404\",\"name\":\"Jiayan Cao\"},{\"authorId\":null,\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1109/ACCESS.2018.2881997\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"152bb56b4d7f78fefd4e20c50c5aedc48a5fc78b\",\"title\":\"Learning Cross-Modal Aligned Representation With Graph Embedding\",\"url\":\"https://www.semanticscholar.org/paper/152bb56b4d7f78fefd4e20c50c5aedc48a5fc78b\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2004.06698\",\"authors\":[{\"authorId\":\"71119060\",\"name\":\"Gi-Cheon Kang\"},{\"authorId\":\"1755502\",\"name\":\"Junseok Park\"},{\"authorId\":\"2294014\",\"name\":\"Hwaran Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"},{\"authorId\":\"153188145\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"36642cb0c60047846ccc9bb670a63f6884e976d1\",\"title\":\"DialGraph: Sparse Graph Learning Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/36642cb0c60047846ccc9bb670a63f6884e976d1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1812.05917\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s11263-020-01295-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e50c32f7244e3556eb879f24b7de8410f3177f6\",\"title\":\"Visual Social Relationship Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e50c32f7244e3556eb879f24b7de8410f3177f6\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"32113652\",\"name\":\"G. Gandolfi\"},{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.248\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"title\":\"Be Different to Be Better! A Benchmark to Leverage the Complementarity of Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1704.00717\",\"authors\":[{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5539585e0b3831e1b14219cd9a9ac07810220765\",\"title\":\"It Takes Two to Tango: Towards Theory of AI's Mind\",\"url\":\"https://www.semanticscholar.org/paper/5539585e0b3831e1b14219cd9a9ac07810220765\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1907.12133\",\"authors\":[{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"113737386\",\"name\":\"D. Xuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"title\":\"An Empirical Study on Leveraging Scene Graphs for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52152408\",\"name\":\"Zihan Guo\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20236758\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"title\":\"Multi-Modal Explicit Sparse Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.03322\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"9072379\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"336cad600d15832243f4228b351c638630d64cb7\",\"title\":\"Learning to Respond with Your Favorite Stickers: A Framework of Unifying Multi-Modality and User Preference in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/336cad600d15832243f4228b351c638630d64cb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.04359\",\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"title\":\"Community Regularization of Visually-Grounded Dialog\",\"url\":\"https://www.semanticscholar.org/paper/79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.12871\",\"authors\":[{\"authorId\":\"1751661088\",\"name\":\"Phillip Lippe\"},{\"authorId\":\"1661217828\",\"name\":\"Nithin Holla\"},{\"authorId\":\"1879340965\",\"name\":\"Shantanu Chandra\"},{\"authorId\":\"1723418777\",\"name\":\"Santhosh Rajamanickam\"},{\"authorId\":\"33537528\",\"name\":\"G. Antoniou\"},{\"authorId\":\"2362276\",\"name\":\"Ekaterina Shutova\"},{\"authorId\":\"2169553\",\"name\":\"H. Yannakoudakis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"76e266d5220f963886cf30ae747d72fdf8c84378\",\"title\":\"A Multimodal Framework for the Detection of Hateful Memes\",\"url\":\"https://www.semanticscholar.org/paper/76e266d5220f963886cf30ae747d72fdf8c84378\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06351\",\"authors\":[{\"authorId\":\"17866105\",\"name\":\"Fuli Luo\"},{\"authorId\":\"46709826\",\"name\":\"Pengcheng Yang\"},{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d9b7620f9b9653ada1a7ce36b0d6617f5979fff2\",\"title\":\"CAPT: Contrastive Pre-Training for Learning Denoised Sequence Representations\",\"url\":\"https://www.semanticscholar.org/paper/d9b7620f9b9653ada1a7ce36b0d6617f5979fff2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.00753\",\"authors\":[{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"title\":\"Structured Multimodal Attentions for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"113720743\",\"name\":\"Amin Parvaneh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR42600.2020.01006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"title\":\"Counterfactual Vision and Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"1752876325\",\"name\":\"Yi Cai\"},{\"authorId\":\"150068355\",\"name\":\"Changmeng Zheng\"},{\"authorId\":\"47740571\",\"name\":\"J. Chen\"},{\"authorId\":\"1701688\",\"name\":\"Ho-fung Leung\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"}],\"doi\":\"10.18653/v1/2020.acl-main.642\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ede49ec0dd27849e57152d5116770bcbe3e01874\",\"title\":\"Aligned Dual Channel Graph Convolutional Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ede49ec0dd27849e57152d5116770bcbe3e01874\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32791167\",\"name\":\"Chenchen Jing\"},{\"authorId\":\"150352923\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6776\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"title\":\"Overcoming Language Priors in VQA via Decomposed Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1909.04696\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":\"10.18653/v1/D19-1596\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"title\":\"Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1806.03724\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00569\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"title\":\"Learning Answer Embeddings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9254311\",\"name\":\"Yuansheng Song\"},{\"authorId\":\"2110377\",\"name\":\"Ping Jian\"}],\"doi\":\"10.1007/978-3-030-60450-9_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a81751ea4350cd67f9bd1d81b9410c64c22527e\",\"title\":\"Deep Hierarchical Attention Flow for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/5a81751ea4350cd67f9bd1d81b9410c64c22527e\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1910.04964\",\"authors\":[{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"}],\"doi\":\"10.1109/TCSVT.2019.2940647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"title\":\"Multi-Modal Deep Analysis for Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2012.08673\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c8f6878dac0c5c99c192ded715d2e864eed7302\",\"title\":\"A Closer Look at the Robustness of Vision-and-Language Pre-trained Models\",\"url\":\"https://www.semanticscholar.org/paper/3c8f6878dac0c5c99c192ded715d2e864eed7302\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.09192\",\"authors\":[{\"authorId\":\"7591930\",\"name\":\"Vardaan Pahuja\"},{\"authorId\":\"145016608\",\"name\":\"Jie Fu\"},{\"authorId\":\"1972076\",\"name\":\"Christopher Joseph Pal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d83d9cce9c55057fbe45736dc5931a2f6afed9eb\",\"title\":\"Learning Sparse Mixture of Experts for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d83d9cce9c55057fbe45736dc5931a2f6afed9eb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7361508\",\"name\":\"Zhiqiang Wan\"},{\"authorId\":\"144996615\",\"name\":\"Haibo He\"}],\"doi\":\"10.1109/TBDATA.2018.2884486\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"title\":\"AnswerNet: Learning to Answer Questions\",\"url\":\"https://www.semanticscholar.org/paper/8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"venue\":\"IEEE Transactions on Big Data\",\"year\":2019},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150112916\",\"name\":\"Gabino Luis\"},{\"authorId\":\"47756806\",\"name\":\"D. Suarez\"},{\"authorId\":\"145940020\",\"name\":\"A. Mateos\"}],\"doi\":\"10.14201/ADCAIJ2018741726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dcf93dde3488d42e244999f6be62a1bb9732521\",\"title\":\"Multi-Agent Word Guessing Game\",\"url\":\"https://www.semanticscholar.org/paper/0dcf93dde3488d42e244999f6be62a1bb9732521\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.03343\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"1388031809\",\"name\":\"Antoine Maiorca\"},{\"authorId\":\"1388031811\",\"name\":\"Nathan Hubens\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd8e7ed46ca883e7e6f897f25715d50220eaca30\",\"title\":\"Modulated Self-attention Convolutional Network for VQA\",\"url\":\"https://www.semanticscholar.org/paper/fd8e7ed46ca883e7e6f897f25715d50220eaca30\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49116303\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"144410256\",\"name\":\"Ryota Suzuki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1109/3DV.2019.00088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c03f85185134c3c5c0f0874dc6d5538ae529059\",\"title\":\"Incorporating 3D Information Into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3c03f85185134c3c5c0f0874dc6d5538ae529059\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145865760\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3240508.3240527\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81b3cfd55ca84802cdcc971410e633ed40e04980\",\"title\":\"Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/81b3cfd55ca84802cdcc971410e633ed40e04980\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arka Sadhu\"},{\"authorId\":\"1716207091\",\"name\":\"Xuefeng Hu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9147121ab65d3ace2d32afe123500f1b4ee18edd\",\"title\":\"Joint Learning of Scene Graph Generation and Reasoning for Visual Question Answering Mid-term report\",\"url\":\"https://www.semanticscholar.org/paper/9147121ab65d3ace2d32afe123500f1b4ee18edd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152553572\",\"name\":\"Huan Shao\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-36802-9_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f21cba46085eba47b299fbff283515284bed7189\",\"title\":\"Intra-Modality Feature Interaction Using Self-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f21cba46085eba47b299fbff283515284bed7189\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1905.09400\",\"authors\":[{\"authorId\":\"8804979\",\"name\":\"Siddhesh Khandelwal\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3805f0058ac3b320016ca518a98de358aca9823\",\"title\":\"AttentionRNN: A Structured Spatial Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/f3805f0058ac3b320016ca518a98de358aca9823\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1706.01322\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":\"10.18653/v1/W18-1003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3884d98977c12a2fbd2f5a8a7e955a55652a8fd\",\"title\":\"Deep learning evaluation using deep linguistic processing\",\"url\":\"https://www.semanticscholar.org/paper/e3884d98977c12a2fbd2f5a8a7e955a55652a8fd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1905.09998\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7336b10298798985eaa842da38609a3fd0700be3\",\"title\":\"Self-Critical Reasoning for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7336b10298798985eaa842da38609a3fd0700be3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2009.08395\",\"authors\":[{\"authorId\":\"4852522\",\"name\":\"Tariq Habib Afridi\"},{\"authorId\":\"47686775\",\"name\":\"Aftab Alam\"},{\"authorId\":\"1645748271\",\"name\":\"M. N. Khan\"},{\"authorId\":\"1649689679\",\"name\":\"Jawad Khan\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0903f184dfccc813d8165d0f69c87f79520014e\",\"title\":\"A Multimodal Memes Classification: A Survey and Open Research Issues\",\"url\":\"https://www.semanticscholar.org/paper/b0903f184dfccc813d8165d0f69c87f79520014e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32349340\",\"name\":\"Ryan McCaffrey\"},{\"authorId\":null,\"name\":\"Ioannis Christos Karakozis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b2d4ed138816c671c3f698290557d26600377025\",\"title\":\"Image Caption Validation\",\"url\":\"https://www.semanticscholar.org/paper/b2d4ed138816c671c3f698290557d26600377025\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"title\":\"Research Statement Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.04289\",\"authors\":[{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2019.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"title\":\"Multi-Modality Latent Interaction Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arne J. Supp\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a92b610d2eed67b934ef2075264e243e6e1ea91\",\"title\":\"Learning Multi-Modal Navigation for Unmanned Ground Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/2a92b610d2eed67b934ef2075264e243e6e1ea91\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104200851\",\"name\":\"Shaodong Chen\"},{\"authorId\":\"50980383\",\"name\":\"Y. Liu\"}],\"doi\":\"10.2112/JCR-SI104-051.1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c44d04f03547fd0b181e3eeb71d8d973f0c19f9c\",\"title\":\"Migration Learning Based on Computer Vision and Its Application in Ocean Image Processing\",\"url\":\"https://www.semanticscholar.org/paper/c44d04f03547fd0b181e3eeb71d8d973f0c19f9c\",\"venue\":\"Journal of Coastal Research\",\"year\":2020},{\"arxivId\":\"2012.06946\",\"authors\":[{\"authorId\":\"46583603\",\"name\":\"J. Wang\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"41171e9024d0082c2a57f4887bac93131669b881\",\"title\":\"MiniVLM: A Smaller and Faster Vision-Language Model\",\"url\":\"https://www.semanticscholar.org/paper/41171e9024d0082c2a57f4887bac93131669b881\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.07789\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00979\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"title\":\"Explicit Bias Discovery in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.00490\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICDAR.2019.00251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"title\":\"ICDAR 2019 Competition on Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":\"1810.12366\",\"authors\":[{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D18-1128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d71a6e630d8086d38cd17c0cc8ecc38f7a52f60\",\"title\":\"Do explanations make VQA models more predictable to a human?\",\"url\":\"https://www.semanticscholar.org/paper/2d71a6e630d8086d38cd17c0cc8ecc38f7a52f60\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"}],\"doi\":\"10.18653/v1/P19-1621\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2723f54b4f5ed2d3f3a47c1b6749bbf5d8c660fd\",\"title\":\"Are Red Roses Red? Evaluating Consistency of Question-Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/2723f54b4f5ed2d3f3a47c1b6749bbf5d8c660fd\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1806.03379\",\"authors\":[{\"authorId\":\"3236503\",\"name\":\"Li-Chi Huang\"},{\"authorId\":\"40222634\",\"name\":\"K. Kulkarni\"},{\"authorId\":\"32001668\",\"name\":\"A. Jha\"},{\"authorId\":\"1890366\",\"name\":\"S. Lohit\"},{\"authorId\":\"39131476\",\"name\":\"S. Jayasuriya\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"}],\"doi\":\"10.1109/ICIP.2018.8451445\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2791b9ccf025f8447903f5bdf13ac89674cd781\",\"title\":\"CS-VQA: Visual Question Answering with Compressively Sensed Images\",\"url\":\"https://www.semanticscholar.org/paper/a2791b9ccf025f8447903f5bdf13ac89674cd781\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aaron Honculada\"},{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"466d1584cb9fad5eeb4b3b3a54cc4a4f338eaff4\",\"title\":\"Visual Question Answering on Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/466d1584cb9fad5eeb4b3b3a54cc4a4f338eaff4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1802.08129\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2018.00915\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"title\":\"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.08527\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2019.00752\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"title\":\"ViCo: Word Embeddings From Visual Co-Occurrences\",\"url\":\"https://www.semanticscholar.org/paper/ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947259\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1017/S1351324918000128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e7533da3833a1e89c14f6c7d948c44331d9f815\",\"title\":\"Learning quantification from images: A structured neural architecture\",\"url\":\"https://www.semanticscholar.org/paper/4e7533da3833a1e89c14f6c7d948c44331d9f815\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1804.00298\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/CVPR.2018.00801\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"title\":\"Differential Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.08105\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-01267-0_14\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a742c64f14b145b9e653ef30819520c5ce5e0123\",\"title\":\"Visual Question Answering as a Meta Learning Task\",\"url\":\"https://www.semanticscholar.org/paper/a742c64f14b145b9e653ef30819520c5ce5e0123\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2181063\",\"name\":\"Qiqi Hou\"},{\"authorId\":\"32014778\",\"name\":\"J. Wang\"},{\"authorId\":\"1787575\",\"name\":\"Ruibin Bai\"},{\"authorId\":\"3373601\",\"name\":\"Sanping Zhou\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"}],\"doi\":\"10.1016/j.patcog.2017.09.028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a37f9914c95e64bc0b85e6efa15003fd8852ae8\",\"title\":\"Face alignment recurrent network\",\"url\":\"https://www.semanticscholar.org/paper/9a37f9914c95e64bc0b85e6efa15003fd8852ae8\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7535a97bcb06b78531f95b7443671a2c0d319476\",\"title\":\"Combining Knowledge and Reasoning through Probabilistic Soft Logic for Image Puzzle Solving\",\"url\":\"https://www.semanticscholar.org/paper/7535a97bcb06b78531f95b7443671a2c0d319476\",\"venue\":\"UAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031180\",\"name\":\"Xiaofeng Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"2753987\",\"name\":\"Fengmao Lv\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":\"10.1007/978-3-030-58589-1_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"title\":\"TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.10038\",\"authors\":[{\"authorId\":\"31340289\",\"name\":\"Sameer Dharur\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"title\":\"SOrT-ing VQA Models : Contrastive Gradient Learning for Improved Consistency\",\"url\":\"https://www.semanticscholar.org/paper/997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01725\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1859082176\",\"name\":\"Salman Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"title\":\"Attention Guided Semantic Relationship Parsing for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9095876\",\"name\":\"Jipeng Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43965cdc9f84a32d3c7e89ee79a2e4d5dc8954ae\",\"title\":\"Word Embedding GRU ! \\\" # Image CNN Caption Generation Word Embedding Caption Embedding ! $ # Answer Prediction Question Phase\",\"url\":\"https://www.semanticscholar.org/paper/43965cdc9f84a32d3c7e89ee79a2e4d5dc8954ae\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66520980\",\"name\":\"Yasufumi Moriya\"},{\"authorId\":null,\"name\":\"Ramon Sanabria\"},{\"authorId\":null,\"name\":\"Florian Metze\"},{\"authorId\":\"143723939\",\"name\":\"G. Jones\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"159a962a5af1c3cce5d08865b57f8ccf2f6591cd\",\"title\":\"MediaEval 2019: Eyes and Ears Together\",\"url\":\"https://www.semanticscholar.org/paper/159a962a5af1c3cce5d08865b57f8ccf2f6591cd\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"49890870\",\"name\":\"Yan-Ning Zhang\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"49725227\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/j.image.2019.115648\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db67ace5932bbae9b141e0d05ba5dfcb80e94d6a\",\"title\":\"Visual question answering model based on visual relationship detection\",\"url\":\"https://www.semanticscholar.org/paper/db67ace5932bbae9b141e0d05ba5dfcb80e94d6a\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.08618\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1609/AAAI.V34I07.6858\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"title\":\"Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA\",\"url\":\"https://www.semanticscholar.org/paper/dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1fa9c5af78b3ca04476f4ee6910684dc19008f5e\",\"title\":\"Supplementary Material : Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1fa9c5af78b3ca04476f4ee6910684dc19008f5e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.10128\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cede1c63336de84344922876e6ee23617e2afb3\",\"title\":\"Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network\",\"url\":\"https://www.semanticscholar.org/paper/4cede1c63336de84344922876e6ee23617e2afb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034270322\",\"name\":\"Liyana Sahir Kallooriyakath\"},{\"authorId\":\"2034269084\",\"name\":\"Jithin M V\"},{\"authorId\":\"81431088\",\"name\":\"B. V\"},{\"authorId\":\"2034269088\",\"name\":\"Adith P P\"}],\"doi\":\"10.1109/ICSTCEE49637.2020.9277374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea0ab46474037363b0a52b758538e61ccb90ecec\",\"title\":\"Visual Question Answering: Methodologies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/ea0ab46474037363b0a52b758538e61ccb90ecec\",\"venue\":\"2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1109/CCIS.2018.8691361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e074ccab7b7c46b48d643c1026e71e563878885f\",\"title\":\"Sequential Visual Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e074ccab7b7c46b48d643c1026e71e563878885f\",\"venue\":\"2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)\",\"year\":2018},{\"arxivId\":\"2010.03160\",\"authors\":[{\"authorId\":\"1557299630\",\"name\":\"Xiaoyu Zeng\"},{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"3428457\",\"name\":\"Tai-Yin Chiu\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1145/3415220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72f5a58ac11e98a15e96c413178198b6f1b6e736\",\"title\":\"Vision Skills Needed to Answer Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/72f5a58ac11e98a15e96c413178198b6f1b6e736\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47963068\",\"name\":\"N. Vyas\"},{\"authorId\":\"3167650\",\"name\":\"Sai Krishna Rallabandi\"},{\"authorId\":\"117576986\",\"name\":\"Lalitesh Morishetti\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.1109/ICASSP.2019.8683370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39bb2e79980f70cdbeb3d1d06c6329700ea00c9d\",\"title\":\"Learning Disentangled Representation in Latent Stochastic Models: A Case Study with Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39bb2e79980f70cdbeb3d1d06c6329700ea00c9d\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"27563697\",\"name\":\"Pabitra Lenka\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"title\":\"A Unified Framework for Multilingual and Code-Mixed Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2006.04315\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"112957699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"title\":\"Counterfactual VQA: A Cause-Effect Look at Language Bias\",\"url\":\"https://www.semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07526\",\"authors\":[{\"authorId\":\"3451494\",\"name\":\"Ana Marasovi\\u0107\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"39227408\",\"name\":\"Ronan Le Bras\"},{\"authorId\":\"1685669\",\"name\":\"N. A. Smith\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.253\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9940a17504a3b83bd1e9d613b095ddb204d2ad0\",\"title\":\"Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs\",\"url\":\"https://www.semanticscholar.org/paper/c9940a17504a3b83bd1e9d613b095ddb204d2ad0\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.10604\",\"authors\":[{\"authorId\":\"8010189\",\"name\":\"Xinjie Fan\"},{\"authorId\":\"1515867113\",\"name\":\"Shujian Zhang\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83243b3639bbb42566bc300b4999db9a2b7a93c3\",\"title\":\"Bayesian Attention Modules\",\"url\":\"https://www.semanticscholar.org/paper/83243b3639bbb42566bc300b4999db9a2b7a93c3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.03127\",\"authors\":[{\"authorId\":\"80927455\",\"name\":\"Takuma Udagawa\"},{\"authorId\":\"48342111\",\"name\":\"T. Yamazaki\"},{\"authorId\":\"1705519\",\"name\":\"A. Aizawa\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ee340c37a60d20dd8ebe19bc6fa614b981c2060\",\"title\":\"A Linguistic Analysis of Visually Grounded Dialogues Based on Spatial Expressions\",\"url\":\"https://www.semanticscholar.org/paper/6ee340c37a60d20dd8ebe19bc6fa614b981c2060\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.07780\",\"authors\":[{\"authorId\":\"1949747\",\"name\":\"Robert Geirhos\"},{\"authorId\":\"134172524\",\"name\":\"Jorn-Henrik Jacobsen\"},{\"authorId\":\"40899528\",\"name\":\"Claudio Michaelis\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":\"10.1038/s42256-020-00257-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f9826db03c83a069d9d0c939d8b539b2dfd4a94\",\"title\":\"Shortcut Learning in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f9826db03c83a069d9d0c939d8b539b2dfd4a94\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"37187331\",\"name\":\"Sadid A. Hasan\"},{\"authorId\":\"1878942\",\"name\":\"V. Datla\"},{\"authorId\":\"2217579\",\"name\":\"J. Liu\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"},{\"authorId\":\"143664290\",\"name\":\"H. M\\u00fcller\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9eeeb23546d3d2bbc73959bffc6819f2335f3c83\",\"title\":\"VQA-Med: Overview of the Medical Visual Question Answering Task at ImageCLEF 2019\",\"url\":\"https://www.semanticscholar.org/paper/9eeeb23546d3d2bbc73959bffc6819f2335f3c83\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"1911.08769\",\"authors\":[{\"authorId\":\"1420563786\",\"name\":\"Syeda Noor Jaha Azim\"},{\"authorId\":\"14216593\",\"name\":\"Md. Aminur Rab Ratul\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d41ef65be97eaba8a2c3fe5a8c7492865e2c998\",\"title\":\"Inspect Transfer Learning Architecture with Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/1d41ef65be97eaba8a2c3fe5a8c7492865e2c998\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.11737\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":\"10.18653/v1/W19-4806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f45e8e9c56e4fc3f132072ee4867a89f927687d\",\"title\":\"The meaning of \\\"most\\\" for visual question answering models\",\"url\":\"https://www.semanticscholar.org/paper/3f45e8e9c56e4fc3f132072ee4867a89f927687d\",\"venue\":\"ACL 2019\",\"year\":2018},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930287\",\"name\":\"L. Zhang\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1145/3382507.3418886\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c43909efc347aab615a8688e0329d5b3d2cc1b62\",\"title\":\"Temporal Attention and Consistency Measuring for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c43909efc347aab615a8688e0329d5b3d2cc1b62\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"1909.00997\",\"authors\":[{\"authorId\":\"1388048026\",\"name\":\"Nitesh Methani\"},{\"authorId\":\"2409493\",\"name\":\"Pritha Ganguly\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"46638795\",\"name\":\"Pratyush Kumar\"}],\"doi\":\"10.1109/WACV45572.2020.9093523\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a9dcb7a9511968219c422d824e3bac69dc45832\",\"title\":\"PlotQA: Reasoning over Scientific Plots\",\"url\":\"https://www.semanticscholar.org/paper/9a9dcb7a9511968219c422d824e3bac69dc45832\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1472939182\",\"name\":\"Sayedshayan Hashemi Hosseinabad\"},{\"authorId\":\"2179339\",\"name\":\"M. Safayani\"},{\"authorId\":\"145238808\",\"name\":\"A. Mirzaei\"}],\"doi\":\"10.1007/s00371-019-01786-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1072c09f843ba976803ea14b8bf2c4e932ac56d\",\"title\":\"Multiple answers to a question: a new approach for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/c1072c09f843ba976803ea14b8bf2c4e932ac56d\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1911.11237\",\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45e5ce07582b9f500ec7de8e28286eccc639a0a7\",\"title\":\"Learning to Learn Words from Narrated Video\",\"url\":\"https://www.semanticscholar.org/paper/45e5ce07582b9f500ec7de8e28286eccc639a0a7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145268319\",\"name\":\"Qiang Sun\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":\"10.1145/3323873.3325044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c6f05eac12622146fec4868735daa78f79f80a\",\"title\":\"Stacked Self-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33c6f05eac12622146fec4868735daa78f79f80a\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.05556\",\"authors\":[{\"authorId\":\"144869806\",\"name\":\"Pedro Henrique Martins\"},{\"authorId\":\"2114966\",\"name\":\"Vlad Niculae\"},{\"authorId\":\"2566656\",\"name\":\"Zita Marinho\"},{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e627eb9f17369770f2cef5d71360c93c8494785\",\"title\":\"Sparse and Structured Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e627eb9f17369770f2cef5d71360c93c8494785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14602\",\"authors\":[{\"authorId\":\"22670284\",\"name\":\"Miyoung Ko\"},{\"authorId\":\"65798870\",\"name\":\"Jinhyuk Lee\"},{\"authorId\":\"153761147\",\"name\":\"Hyunjae Kim\"},{\"authorId\":\"1390543205\",\"name\":\"Gangwoo Kim\"},{\"authorId\":\"144323862\",\"name\":\"Jaewoo Kang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.84\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e14aad3423e454254c4d90c5de0ad7d965f328ee\",\"title\":\"Look at the First Sentence: Position Bias in Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e14aad3423e454254c4d90c5de0ad7d965f328ee\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"1388031809\",\"name\":\"Antoine Maiorca\"},{\"authorId\":\"1388031811\",\"name\":\"Nathan Hubens\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2960fd63507253d1d6a19802068666de478bfc0\",\"title\":\"C V ] 8 O ct 2 01 9 Modulated Self-attention Convolutional Network for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b2960fd63507253d1d6a19802068666de478bfc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charades-STA\"},{\"authorId\":null,\"name\":\"ActivityNet\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"title\":\"End-to-End Multimodal Dialog Systems with Hierarchical Multimodal Attention on Video Features\",\"url\":\"https://www.semanticscholar.org/paper/fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.12750\",\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1410551459\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1005e3d5584fc25d1aa42922d78033c50719bfa\",\"title\":\"Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data\",\"url\":\"https://www.semanticscholar.org/paper/d1005e3d5584fc25d1aa42922d78033c50719bfa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.14953\",\"authors\":[{\"authorId\":\"50120446\",\"name\":\"Stanislav Frolov\"},{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"120996558\",\"name\":\"J. Hees\"},{\"authorId\":\"153402269\",\"name\":\"Andreas Dengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba2c4ae6b7970f5f703e86e02feaf34bb260123f\",\"title\":\"Leveraging Visual Question Answering to Improve Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/ba2c4ae6b7970f5f703e86e02feaf34bb260123f\",\"venue\":\"LANTERN\",\"year\":2020},{\"arxivId\":\"1907.07804\",\"authors\":[{\"authorId\":\"51011359\",\"name\":\"S. Pramanik\"},{\"authorId\":\"7421228\",\"name\":\"Priyanka Agrawal\"},{\"authorId\":\"145374365\",\"name\":\"Aman Hussain\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"title\":\"OmniNet: A unified architecture for multi-modal multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143694682\",\"name\":\"A. Bellini\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"168de54915fa45d8bd0d33b53ed54eb0cef33463\",\"title\":\"Towards open-ended VQA models using transformers\",\"url\":\"https://www.semanticscholar.org/paper/168de54915fa45d8bd0d33b53ed54eb0cef33463\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40474403\",\"name\":\"J. J. Lau\"},{\"authorId\":\"29948554\",\"name\":\"Soumya Gayen\"},{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":\"10.1038/sdata.2018.251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"title\":\"A dataset of clinically generated visual questions and answers about radiology images\",\"url\":\"https://www.semanticscholar.org/paper/18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"venue\":\"Scientific Data\",\"year\":2018},{\"arxivId\":\"1909.03493\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1609/AAAI.V34I07.6785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77802591c3f5b3f654bb5b68ad62ed056769320f\",\"title\":\"MULE: Multimodal Universal Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/77802591c3f5b3f654bb5b68ad62ed056769320f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1909.11512\",\"authors\":[{\"authorId\":\"1742235\",\"name\":\"S. Nikolenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9022cfe07451593ea39b8e58fea3c2d4c529cbef\",\"title\":\"Synthetic Data for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/9022cfe07451593ea39b8e58fea3c2d4c529cbef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.09718\",\"authors\":[{\"authorId\":\"35358246\",\"name\":\"Mikyas T. Desta\"},{\"authorId\":\"2230576\",\"name\":\"Larry Chen\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"}],\"doi\":\"10.1109/WACV.2018.00201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23d6bb8edcd86f8439072f932f414329b393473b\",\"title\":\"Object-Based Reasoning in VQA\",\"url\":\"https://www.semanticscholar.org/paper/23d6bb8edcd86f8439072f932f414329b393473b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2007.13135\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"47527626\",\"name\":\"Peng Su\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"title\":\"Contrastive Visual-Linguistic Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.04790\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"152422011\",\"name\":\"Aravind Mohan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"1389630028\",\"name\":\"Davide Testuggine\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"51b461040c381cb1489e55ea4b9686c709818b10\",\"title\":\"The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes\",\"url\":\"https://www.semanticscholar.org/paper/51b461040c381cb1489e55ea4b9686c709818b10\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.14451\",\"authors\":[{\"authorId\":\"21771052\",\"name\":\"Allen Nie\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.173\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"88c86523d500d636f453647385ddaa04085b5f1b\",\"title\":\"Pragmatic Issue-Sensitive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88c86523d500d636f453647385ddaa04085b5f1b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.03044\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"8716902\",\"name\":\"Huiyuan Xie\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":\"10.1007/978-3-030-11018-5_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c792eebc581a3acf387aaa13626173032f79b706\",\"title\":\"How clever is the FiLM model, and how clever can it be?\",\"url\":\"https://www.semanticscholar.org/paper/c792eebc581a3acf387aaa13626173032f79b706\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"143720148\",\"name\":\"Jinwoo Shin\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7adef3d0200207baec75e39bbb852cacfaf8268b\",\"title\":\"Learning to Specialize with Knowledge Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7adef3d0200207baec75e39bbb852cacfaf8268b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"title\":\"Removing the i\\u2019s from i.i.d : Testing generalization on hard datasets\",\"url\":\"https://www.semanticscholar.org/paper/41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1608.08974\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"title\":\"Towards Transparent AI Systems: Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1809.00812\",\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.18653/v1/D18-1166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c581686edbd7227e9eb4a0841cce16728ca27369\",\"title\":\"RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes\",\"url\":\"https://www.semanticscholar.org/paper/c581686edbd7227e9eb4a0841cce16728ca27369\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"51069511\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/JSTSP.2020.2989701\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b3478e680e957672c4fbc8e1da559588997b325\",\"title\":\"Learning to Recognize Visual Concepts for Visual Question Answering With Structural Label Space\",\"url\":\"https://www.semanticscholar.org/paper/5b3478e680e957672c4fbc8e1da559588997b325\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1901.00850\",\"authors\":[{\"authorId\":\"9326827\",\"name\":\"Runtao Liu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00431\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9695676deace8c05d4e95274b92f20ed1e97470c\",\"title\":\"CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9695676deace8c05d4e95274b92f20ed1e97470c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.03821\",\"authors\":[{\"authorId\":\"36251013\",\"name\":\"Wei Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09bb33837609afd9f90a9ba418ca3550926e8495\",\"title\":\"Knowing Where to Look? Analysis on Attention of Visual Question Answering System\",\"url\":\"https://www.semanticscholar.org/paper/09bb33837609afd9f90a9ba418ca3550926e8495\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1712.09923\",\"authors\":[{\"authorId\":\"1749801\",\"name\":\"A. Holzinger\"},{\"authorId\":\"31565315\",\"name\":\"Chris Biemann\"},{\"authorId\":\"1716947\",\"name\":\"C. Pattichis\"},{\"authorId\":\"10217996\",\"name\":\"D. Kell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c194307b9dda7f53a0c639319d2ec1c23b86e6a6\",\"title\":\"What do we need to build explainable AI systems for the medical domain?\",\"url\":\"https://www.semanticscholar.org/paper/c194307b9dda7f53a0c639319d2ec1c23b86e6a6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2009.11118\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"47787551\",\"name\":\"Binh X. Nguyen\"},{\"authorId\":\"1981175\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"31534280\",\"name\":\"Q. D. Tran\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30173e8b551c0655e2036aba7fedf354f1ef5658\",\"title\":\"Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/30173e8b551c0655e2036aba7fedf354f1ef5658\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/cvpr42600.2020.01001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.07538\",\"authors\":[{\"authorId\":\"48189355\",\"name\":\"V. Agarwal\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/cvpr42600.2020.00971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"title\":\"Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing\",\"url\":\"https://www.semanticscholar.org/paper/d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.11666\",\"authors\":[{\"authorId\":\"47902700\",\"name\":\"Wonjae Kim\"},{\"authorId\":\"5076961\",\"name\":\"Y. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fc594c1ced000ea6ae36d28242cf50b4aec502f\",\"title\":\"Learning Dynamics of Attention: Human Prior for Interpretable Machine Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/4fc594c1ced000ea6ae36d28242cf50b4aec502f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1905.05778\",\"authors\":[{\"authorId\":\"144588144\",\"name\":\"Shi Feng\"},{\"authorId\":\"145217343\",\"name\":\"Eric Wallace\"},{\"authorId\":\"1389036863\",\"name\":\"Jordan L. Boyd-Graber\"}],\"doi\":\"10.18653/v1/P19-1554\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9daf0c137f182763a6ec001f4f2d41a517fe595\",\"title\":\"Misleading Failures of Partial-input Baselines\",\"url\":\"https://www.semanticscholar.org/paper/a9daf0c137f182763a6ec001f4f2d41a517fe595\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2004.10966\",\"authors\":[{\"authorId\":\"1389550960\",\"name\":\"Tasmia Tasrin\"},{\"authorId\":\"1381931976\",\"name\":\"Md Sultan Al Nahian\"},{\"authorId\":\"34442699\",\"name\":\"B. Harrison\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"title\":\"Visual Question Answering Using Semantic Information from Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.07586\",\"authors\":[{\"authorId\":\"145708789\",\"name\":\"X. Han\"},{\"authorId\":\"153676682\",\"name\":\"P. Schulz\"},{\"authorId\":\"143620680\",\"name\":\"Trevor Cohn\"}],\"doi\":\"10.18653/v1/D19-1158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a4c49d14f58db3ff2bd29866893536d8548c064\",\"title\":\"Grounding learning of modifier dynamics: An application to color naming\",\"url\":\"https://www.semanticscholar.org/paper/8a4c49d14f58db3ff2bd29866893536d8548c064\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2012.11134\",\"authors\":[{\"authorId\":\"2018700866\",\"name\":\"Chao Yang\"},{\"authorId\":\"145030306\",\"name\":\"S. Feng\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"2476503\",\"name\":\"H. Shen\"},{\"authorId\":\"50248868\",\"name\":\"Guoqing Wang\"},{\"authorId\":\"1796274181\",\"name\":\"Bin Jiang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e30790690231e7730eb6f903a722a54091fc4967\",\"title\":\"Learning content and context with language bias for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e30790690231e7730eb6f903a722a54091fc4967\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.00900\",\"authors\":[{\"authorId\":\"46650151\",\"name\":\"Kamran Alipour\"},{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"148376021\",\"name\":\"Xiao Lin\"},{\"authorId\":\"32330143\",\"name\":\"Jurgen P. Schulze\"},{\"authorId\":\"1400198856\",\"name\":\"Yi Yao\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":\"10.1109/HCCAI49649.2020.00010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f45cc95e7412bf8989a6c8f043d5fc69eecb910c\",\"title\":\"The Impact of Explanations on AI Competency Prediction in VQA\",\"url\":\"https://www.semanticscholar.org/paper/f45cc95e7412bf8989a6c8f043d5fc69eecb910c\",\"venue\":\"2020 IEEE International Conference on Humanized Computing and Communication with Artificial Intelligence (HCCAI)\",\"year\":2020},{\"arxivId\":\"2008.01392\",\"authors\":[{\"authorId\":\"1413822807\",\"name\":\"Mert Bulent Sariyildiz\"},{\"authorId\":\"144781195\",\"name\":\"J. Perez\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"}],\"doi\":\"10.1007/978-3-030-58598-3_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0181353f32b1ad3ac6bc59838c69b0e5c64137a\",\"title\":\"Learning Visual Representations with Caption Annotations\",\"url\":\"https://www.semanticscholar.org/paper/b0181353f32b1ad3ac6bc59838c69b0e5c64137a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.06576\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/cvpr42600.2020.01081\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc08d90005b12f66a12798fd79959a8f7f8c4885\",\"title\":\"Counterfactual Samples Synthesizing for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/dc08d90005b12f66a12798fd79959a8f7f8c4885\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.15124\",\"authors\":[{\"authorId\":\"83574123\",\"name\":\"Emanuele Bugliarello\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"title\":\"Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs\",\"url\":\"https://www.semanticscholar.org/paper/82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49268056\",\"name\":\"J. Hu\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1145/3339363.3339389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"title\":\"Semantic BI-Embedded GRU for Fill-in-the-Blank Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"venue\":\"CSSE 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1905.10226\",\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46433486\",\"name\":\"Yanzhao Zhou\"},{\"authorId\":\"103515844\",\"name\":\"Gen Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"39483833\",\"name\":\"Duyu Tang\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cda975be6f9fb55813bb6813b8c7c417331de7bd\",\"title\":\"Deep Reason: A Strong Baseline for Real-World Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cda975be6f9fb55813bb6813b8c7c417331de7bd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Elizabeth Coppock\"},{\"authorId\":null,\"name\":\"Danielle Dionne\"},{\"authorId\":\"1994754478\",\"name\":\"Nathanial Graham\"},{\"authorId\":\"1994755542\",\"name\":\"Elias Ganem\"},{\"authorId\":\"1957250044\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"35025843\",\"name\":\"S. Lin\"},{\"authorId\":\"49663231\",\"name\":\"Wenxing Liu\"},{\"authorId\":null,\"name\":\"Derry Wijaya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4769896d37963f4609c394736184e92b6d82fcb\",\"title\":\"Informativity in Image Captions vs. Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/d4769896d37963f4609c394736184e92b6d82fcb\",\"venue\":\"PAM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"144738250\",\"name\":\"E. Erdem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79cba2b3d3b4289c19e324b0e833c3abeab0325e\",\"title\":\"2 RecipeQA Dataset The Recipe Question Answering ( RecipeQA ) dataset is a challenging multimodal dataset\",\"url\":\"https://www.semanticscholar.org/paper/79cba2b3d3b4289c19e324b0e833c3abeab0325e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"title\":\"AiR: Attention with Reasoning Capability (Supplementary Materials)\",\"url\":\"https://www.semanticscholar.org/paper/456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1709.07871\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cfa5c97164129ce3630511f639040d28db1d4b7\",\"title\":\"FiLM: Visual Reasoning with a General Conditioning Layer\",\"url\":\"https://www.semanticscholar.org/paper/7cfa5c97164129ce3630511f639040d28db1d4b7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144454465\",\"name\":\"L. Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"153028349\",\"name\":\"Xiao Wu\"},{\"authorId\":\"83672162\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3343031.3350925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"title\":\"CRA-Net: Composed Relation Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145654605\",\"name\":\"Correia Ribeiro\"},{\"authorId\":\"51281748\",\"name\":\"M. T\\u00falio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9ade1cb5278876e2ee6cf4adf1adadabf8ca40ca\",\"title\":\"Model-Agnostic Explanations and Evaluation of Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ade1cb5278876e2ee6cf4adf1adadabf8ca40ca\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.09997\",\"authors\":[{\"authorId\":\"49528192\",\"name\":\"Haohan Wang\"},{\"authorId\":\"1681339\",\"name\":\"P. Zhang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7a1c8da1b8163f5bbd4d12e58cad5002947105e\",\"title\":\"Word Shape Matters: Robust Machine Translation with Visual Embedding\",\"url\":\"https://www.semanticscholar.org/paper/d7a1c8da1b8163f5bbd4d12e58cad5002947105e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1016/j.cviu.2019.05.001\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"title\":\"DRAU: Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327281\",\"name\":\"Fabr\\u00edcio F. de Faria\"},{\"authorId\":\"2370666\",\"name\":\"Ricardo Usbeck\"},{\"authorId\":\"40974493\",\"name\":\"Alessio Sarullo\"},{\"authorId\":\"1695158\",\"name\":\"Tingting Mu\"},{\"authorId\":\"145528474\",\"name\":\"Andr\\u00e9 Freitas\"}],\"doi\":\"10.1145/3184558.3192318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e41775bd0eb9649bb361c60b8fb45f0b9e44618a\",\"title\":\"Question Answering Mediated by Visual Clues and Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/e41775bd0eb9649bb361c60b8fb45f0b9e44618a\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2009.08043\",\"authors\":[{\"authorId\":\"46207897\",\"name\":\"Seonhoon Kim\"},{\"authorId\":\"1946727719\",\"name\":\"Seohyeong Jeong\"},{\"authorId\":\"93705260\",\"name\":\"Eun-Byul Kim\"},{\"authorId\":\"34693670\",\"name\":\"Inho Kang\"},{\"authorId\":\"71494716\",\"name\":\"Nojun Kwak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"626f0d48747f919be2d282cca125f8ded96e500b\",\"title\":\"Self-supervised pre-training and contrastive representation learning for multiple-choice video QA\",\"url\":\"https://www.semanticscholar.org/paper/626f0d48747f919be2d282cca125f8ded96e500b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08299\",\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"152333274\",\"name\":\"Seunghyun Yoon\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"153586399\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccc78b88920a1f2825bcf969fc23f95aeb4bffc5\",\"title\":\"DSTC8-AVSD: Multimodal Semantic Transformer Network with Retrieval Style Word Generator\",\"url\":\"https://www.semanticscholar.org/paper/ccc78b88920a1f2825bcf969fc23f95aeb4bffc5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12153206\",\"name\":\"Shengyan Liu\"},{\"authorId\":\"2025671\",\"name\":\"Haiyan Ding\"},{\"authorId\":\"47155070\",\"name\":\"Xiaobing Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5d250b1d69d36131e4848969f1ff9dd69486c44\",\"title\":\"Shengyan at VQA-Med 2020: An Encoder-Decoder Model for Medical Domain Visual Question Answering Task\",\"url\":\"https://www.semanticscholar.org/paper/e5d250b1d69d36131e4848969f1ff9dd69486c44\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003641204\",\"name\":\"Bumjun Jung\"},{\"authorId\":\"144204227\",\"name\":\"Lin Gu\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2834564e95feaf1ff5bbba786c0cbcc94a333ae5\",\"title\":\"bumjun_jung at VQA-Med 2020: VQA Model Based on Feature Extraction and Multi-modal Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/2834564e95feaf1ff5bbba786c0cbcc94a333ae5\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49303626\",\"name\":\"K. Su\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"104545113\",\"name\":\"J. Li\"},{\"authorId\":\"1557387379\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.3389/frobt.2020.00109\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"22e2a19bef88c30a37402da5b54fac34655d77ea\",\"title\":\"Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/22e2a19bef88c30a37402da5b54fac34655d77ea\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"2004.05704\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/2020.acl-main.727\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f4a012aa325cdee5a5c779fe2133e146616a5d5\",\"title\":\"A negative case analysis of visual grounding methods for VQA\",\"url\":\"https://www.semanticscholar.org/paper/2f4a012aa325cdee5a5c779fe2133e146616a5d5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2004.13073\",\"authors\":[{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8d117d098ac59d90bf7814d889e814b52637f22\",\"title\":\"A Novel Attention-based Aggregation Function to Combine Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/e8d117d098ac59d90bf7814d889e814b52637f22\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":\"1906.09635\",\"authors\":[{\"authorId\":\"145511547\",\"name\":\"Shawn Tan\"},{\"authorId\":\"2305979\",\"name\":\"Yikang Shen\"},{\"authorId\":\"48908331\",\"name\":\"C. Huang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7a21d9359a4e1e4e9ce6063f6110c00593bcad3\",\"title\":\"Investigating Biases in Textual Entailment Datasets\",\"url\":\"https://www.semanticscholar.org/paper/a7a21d9359a4e1e4e9ce6063f6110c00593bcad3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.03570\",\"authors\":[{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"2781522\",\"name\":\"T. Singh\"},{\"authorId\":\"49148034\",\"name\":\"Akash Jain\"},{\"authorId\":\"8518719\",\"name\":\"S. Singh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d96ac48e92b6b42737276a319f48d9d27080fce\",\"title\":\"EvalAI: Towards Better Evaluation Systems for AI Agents\",\"url\":\"https://www.semanticscholar.org/paper/0d96ac48e92b6b42737276a319f48d9d27080fce\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.07583\",\"authors\":[{\"authorId\":\"1388780256\",\"name\":\"Yaser Alwatter\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"}],\"doi\":\"10.22215/etd/2019-13929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48795928eb87d1e8a038063b3aebee180e424d04\",\"title\":\"Inverse Visual Question Answering with Multi-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/48795928eb87d1e8a038063b3aebee180e424d04\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49039449\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1703234\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TMM.2020.2972830\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"title\":\"Reasoning on the Relation: Enhancing Visual Representation for Visual Question Answering and Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2010.06087\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"32587693\",\"name\":\"A. Moudgil\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ead5088bc1922526be9a503dd42b15d467b962\",\"title\":\"Contrast and Classify: Alternate Training for Robust VQA\",\"url\":\"https://www.semanticscholar.org/paper/35ead5088bc1922526be9a503dd42b15d467b962\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.03777\",\"authors\":[{\"authorId\":\"34711488\",\"name\":\"Tian-Yu Liu\"},{\"authorId\":\"1430762233\",\"name\":\"Xin Zheng\"},{\"authorId\":\"32630474\",\"name\":\"Xiaoan Ding\"},{\"authorId\":\"102457636\",\"name\":\"Baobao Chang\"},{\"authorId\":\"49575302\",\"name\":\"Zhifang Sui\"}],\"doi\":\"10.18653/v1/2020.conll-1.48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff070fc5eff18a737545a0f96a068e9ab5a0f234\",\"title\":\"An Empirical Study on Model-agnostic Debiasing Strategies for Robust Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/ff070fc5eff18a737545a0f96a068e9ab5a0f234\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":\"2007.04792\",\"authors\":[{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e8c9e907f9be0c098d90eec387da88dd0111238\",\"title\":\"Targeting the Benchmark: On Methodology in Current Natural Language Processing Research\",\"url\":\"https://www.semanticscholar.org/paper/8e8c9e907f9be0c098d90eec387da88dd0111238\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.03615\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01028\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"title\":\"In Defense of Grid Features for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.07724\",\"authors\":[{\"authorId\":\"34271280\",\"name\":\"J. Singh\"},{\"authorId\":\"40699843\",\"name\":\"Vincent Ying\"},{\"authorId\":\"46386672\",\"name\":\"Alex Nutkiewicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90d855f22d324f40230832a47e32f958a24b4aac\",\"title\":\"Attention on Attention: Architectures for Visual Question Answering (VQA)\",\"url\":\"https://www.semanticscholar.org/paper/90d855f22d324f40230832a47e32f958a24b4aac\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143912737\",\"name\":\"Heather Riley\"},{\"authorId\":\"1714890\",\"name\":\"M. Sridharan\"}],\"doi\":\"10.3389/frobt.2019.00125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9ae2f99dd2ae29f4bfd220446175bb854db2008\",\"title\":\"Integrating Non-monotonic Logical Reasoning and Inductive Learning With Deep Learning for Explainable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9ae2f99dd2ae29f4bfd220446175bb854db2008\",\"venue\":\"Front. Robot. AI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22205368\",\"name\":\"Akshay Chaturvedi\"},{\"authorId\":\"48421321\",\"name\":\"U. Garain\"}],\"doi\":\"10.1109/TETCI.2020.2977695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d266a25416cfb8184c56c981beb5ca322b38ede\",\"title\":\"Attacking VQA Systems via Adversarial Background Noise\",\"url\":\"https://www.semanticscholar.org/paper/8d266a25416cfb8184c56c981beb5ca322b38ede\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":\"2004.14797\",\"authors\":[{\"authorId\":\"1908728\",\"name\":\"Yevgeni Berzak\"},{\"authorId\":\"3274291\",\"name\":\"Jonathan Malmaud\"},{\"authorId\":\"143643015\",\"name\":\"R. Levy\"}],\"doi\":\"10.18653/v1/2020.acl-main.507\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fbdb1a7962572e428cf5b06582db85cbb6a3f492\",\"title\":\"STARC: Structured Annotations for Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/fbdb1a7962572e428cf5b06582db85cbb6a3f492\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1805.08389\",\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"91956c41190231eefd2186f21b79d1ca1495a68e\",\"title\":\"Joint Image Captioning and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91956c41190231eefd2186f21b79d1ca1495a68e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.00584\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e390a6a6d783bc0898915dc48f7f1844db5137c\",\"title\":\"A Simple Loss Function for Improving the Convergence and Accuracy of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/6e390a6a6d783bc0898915dc48f7f1844db5137c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"144889898\",\"name\":\"Mengqi Jiang\"},{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"46351963\",\"name\":\"Weixin Zhou\"},{\"authorId\":\"2181606\",\"name\":\"K. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2908035\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0734fd670605a578b9e4b908e58b63e4142625e\",\"title\":\"Co-Attention Network With Question Type for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f0734fd670605a578b9e4b908e58b63e4142625e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782578\",\"name\":\"Chun-Ju Yang\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"title\":\"Visual Question Answer Diversity\",\"url\":\"https://www.semanticscholar.org/paper/91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"venue\":\"HCOMP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39214752\",\"name\":\"Z. Zhang\"},{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213540\",\"name\":\"Xiaoyan Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3308558.3313598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"title\":\"Neural Multimodal Belief Tracker with Adaptive Attention for Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"101489041\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"title\":\"Reason Label Description Issues with the Question-Image ( QI ) pair Low Quality\",\"url\":\"https://www.semanticscholar.org/paper/6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.01050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db717d20dc699f4b402db0ddf923135108a9e686\",\"title\":\"VrR-VG: Refocusing Visually-Relevant Relationships\",\"url\":\"https://www.semanticscholar.org/paper/db717d20dc699f4b402db0ddf923135108a9e686\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"50784825\",\"name\":\"A. Roy\"},{\"authorId\":\"6052800\",\"name\":\"Avi Ziskind\"},{\"authorId\":\"1400198856\",\"name\":\"Yi Yao\"},{\"authorId\":\"47977519\",\"name\":\"A. Divakaran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a244062ca3d00dbc7a4b6ba6d3953238ee1cf177\",\"title\":\"Make Up Your Mind: Towards Consistent Answer Predictions in VQA Models\",\"url\":\"https://www.semanticscholar.org/paper/a244062ca3d00dbc7a4b6ba6d3953238ee1cf177\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.12377\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e5d203efae1f0838bb59e31026ce3e7511f87\",\"title\":\"Perceive, Transform, and Act: Multi-Modal Attention Networks for Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/bb4e5d203efae1f0838bb59e31026ce3e7511f87\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"48567083\",\"name\":\"Zheng Yu\"},{\"authorId\":\"3116943\",\"name\":\"Jiange Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190828\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"316f057e36cf432ece4ba4e2d167a84aef700aee\",\"title\":\"VC-VQA: Visual Calibration Mechanism For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/316f057e36cf432ece4ba4e2d167a84aef700aee\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"7413674\",\"name\":\"S. Kapoor\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.257\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"683b1230f53eddb0c03f4ad656579269eae2227d\",\"title\":\"Can Pre-training help VQA with Lexical Variations?\",\"url\":\"https://www.semanticscholar.org/paper/683b1230f53eddb0c03f4ad656579269eae2227d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2959229\",\"name\":\"Fran\\u00e7ois Plesse\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"108acfe359acf6875e3ab10fad0be45f6c777ecb\",\"title\":\"Int\\u00e9gration de Connaissances aux Mod\\u00e8les Neuronaux pour la D\\u00e9tection de Relations Visuelles Rares. (Knowledge Integration into Neural Networks for the purposes of Rare Visual Relation Detection)\",\"url\":\"https://www.semanticscholar.org/paper/108acfe359acf6875e3ab10fad0be45f6c777ecb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.09853\",\"authors\":[{\"authorId\":\"150257726\",\"name\":\"P. Bongini\"},{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1088/1757-899X/949/1/012074\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a08cb38aa4a5a4bc2f6fa0c4d379d23e874c0b7\",\"title\":\"Visual Question Answering for Cultural Heritage\",\"url\":\"https://www.semanticscholar.org/paper/0a08cb38aa4a5a4bc2f6fa0c4d379d23e874c0b7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.15484\",\"authors\":[{\"authorId\":null,\"name\":\"Kiran Ramnath\"},{\"authorId\":null,\"name\":\"Mark Hasegawa-Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f02cc0d8266d41acb8e1040384b2db1d665c81\",\"title\":\"Seeing is Knowing! Fact-based Visual Question Answering using Knowledge Graph Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/c7f02cc0d8266d41acb8e1040384b2db1d665c81\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120828339\",\"name\":\"Binghua Li\"},{\"authorId\":\"1971112\",\"name\":\"Chaofeng Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"47359248\",\"name\":\"N. Zheng\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"}],\"doi\":\"10.1007/978-3-030-58586-0_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"title\":\"TPFN: Applying Outer Product Along Time to Multimodal Sentiment Analysis Fusion on Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.01239\",\"authors\":[{\"authorId\":\"114180826\",\"name\":\"Violetta Shevchenko\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8a3c338551f9c512868bc89217f95bbce69b1a8\",\"title\":\"Visual Question Answering with Prior Class Semantics\",\"url\":\"https://www.semanticscholar.org/paper/b8a3c338551f9c512868bc89217f95bbce69b1a8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.00163\",\"authors\":[{\"authorId\":\"15401738\",\"name\":\"Zekang Li\"},{\"authorId\":\"115419547\",\"name\":\"Zongjia Li\"},{\"authorId\":\"27672597\",\"name\":\"Jinchao Zhang\"},{\"authorId\":\"49771779\",\"name\":\"Yang Feng\"},{\"authorId\":\"150954670\",\"name\":\"Cheng Niu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4e0723e048941ea73c77a7c69dbb731ef8de750\",\"title\":\"Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f4e0723e048941ea73c77a7c69dbb731ef8de750\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11894\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"title\":\"Unshuffling Data for Improved Generalization\",\"url\":\"https://www.semanticscholar.org/paper/fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.10309\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"title\":\"Uncertainty based Class Activation Maps for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409929082\",\"name\":\"Jordan L. Boyd-Graber\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d292f19bc06ba3c00802ba4a8016c11b1ee8258c\",\"title\":\"Old Premise Animals are running New Premise Entailment Hypothesis Animals are outdoors Label\",\"url\":\"https://www.semanticscholar.org/paper/d292f19bc06ba3c00802ba4a8016c11b1ee8258c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50498297\",\"name\":\"Liang Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"}],\"doi\":\"10.1007/s11042-018-6389-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"713dd629c183056202f31c2a98e5e37e0d83efa4\",\"title\":\"Word-to-region attention network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/713dd629c183056202f31c2a98e5e37e0d83efa4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1709.07192\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"47353404\",\"name\":\"X. Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00640\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47aff6477f05ec32fc163e1943fe9464a8379552\",\"title\":\"Visual Question Generation as Dual Task of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47aff6477f05ec32fc163e1943fe9464a8379552\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.02324\",\"authors\":[{\"authorId\":\"40895369\",\"name\":\"Suchin Gururangan\"},{\"authorId\":\"2705113\",\"name\":\"Swabha Swayamdipta\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"3644767\",\"name\":\"Samuel R. Bowman\"},{\"authorId\":\"144365875\",\"name\":\"Noah A. Smith\"}],\"doi\":\"10.18653/v1/N18-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2997b26ffb8c291ce478bd8a6e47979d5a55c466\",\"title\":\"Annotation Artifacts in Natural Language Inference Data\",\"url\":\"https://www.semanticscholar.org/paper/2997b26ffb8c291ce478bd8a6e47979d5a55c466\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1710.03370\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2018.00898\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a565aa547e2bdf278ad3d1fce1f1da8e70c38a1\",\"title\":\"iVQA: Inverse Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a565aa547e2bdf278ad3d1fce1f1da8e70c38a1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.00857\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"31408089\",\"name\":\"Aron Szanto\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a9135976912d4169a4490c641561ed0867a306c\",\"title\":\"On the Flip Side: Identifying Counterexamples in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2a9135976912d4169a4490c641561ed0867a306c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1704.04517\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"02218fcd3aece5a7bd19255d74b12f63dfa5c1a7\",\"title\":\"ShapeWorld - A new test methodology for multimodal language understanding\",\"url\":\"https://www.semanticscholar.org/paper/02218fcd3aece5a7bd19255d74b12f63dfa5c1a7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.09681\",\"authors\":[{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"49402458\",\"name\":\"J. Yu\"},{\"authorId\":null,\"name\":\"Chenghao Yang\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"48483709\",\"name\":\"Y. Hu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd2f6fe2cd8e96ca62a9c1c9e12973b8e13d5609\",\"title\":\"Multi-modal Learning with Prior Visual Relation Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/dd2f6fe2cd8e96ca62a9c1c9e12973b8e13d5609\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1801.07853\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"48032659\",\"name\":\"Xiaoyi Liu\"},{\"authorId\":\"49330599\",\"name\":\"Liangjian Chen\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/WACV.2018.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"title\":\"Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003689892\",\"name\":\"Hideo Umada\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20a52008ecd5a1396d1501545f96fe3c17f63863\",\"title\":\"kdevqa at VQA-Med 2020: Focusing on GLU-based Classification\",\"url\":\"https://www.semanticscholar.org/paper/20a52008ecd5a1396d1501545f96fe3c17f63863\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733076573\",\"name\":\"Tianrui Niu\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"103314054\",\"name\":\"Lingxuan Li\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1145/3372278.3390684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f87d4df4fbd971aae721c761b0ebf6b3f662eb20\",\"title\":\"Image Synthesis from Locally Related Texts\",\"url\":\"https://www.semanticscholar.org/paper/f87d4df4fbd971aae721c761b0ebf6b3f662eb20\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2009.14308\",\"authors\":[{\"authorId\":\"145534763\",\"name\":\"N. Ding\"},{\"authorId\":\"8010189\",\"name\":\"Xinjie Fan\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"50319359\",\"name\":\"D. Schuurmans\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4bf4ea600f32ceb4b2d005b1b039320cd698f37\",\"title\":\"Attention that does not Explain Away\",\"url\":\"https://www.semanticscholar.org/paper/a4bf4ea600f32ceb4b2d005b1b039320cd698f37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.10286\",\"authors\":[{\"authorId\":\"9268397\",\"name\":\"Xuehai He\"},{\"authorId\":\"2018071\",\"name\":\"Yichen Zhang\"},{\"authorId\":\"37756359\",\"name\":\"Luntian Mou\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"40526720\",\"name\":\"Pengtao Xie\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc0b46a0f3720e6c29c1a913aaa3de4a0699f713\",\"title\":\"PathVQA: 30000+ Questions for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fc0b46a0f3720e6c29c1a913aaa3de4a0699f713\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"49336556\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3350923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7b13eff8ecec771e91a814b598fa33a24980f03\",\"title\":\"Multimodal Dialog System: Generating Responses via Adaptive Decoders\",\"url\":\"https://www.semanticscholar.org/paper/f7b13eff8ecec771e91a814b598fa33a24980f03\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e464187b1cee23117a0b1b1b86a479bee011d991\",\"title\":\"Project on Visual Commonsense Reasoning Anonymous ACL submission\",\"url\":\"https://www.semanticscholar.org/paper/e464187b1cee23117a0b1b1b86a479bee011d991\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.04166\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TIP.2020.2967584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866908141e1db5d6b278984072303a0e14423bcc\",\"title\":\"Revisiting EmbodiedQA: A Simple Baseline and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/866908141e1db5d6b278984072303a0e14423bcc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1812.03928\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8083cfb0e76358ab54f92eedbe13ed6a874a48e5\",\"title\":\"Learning Representations of Sets through Optimized Permutations\",\"url\":\"https://www.semanticscholar.org/paper/8083cfb0e76358ab54f92eedbe13ed6a874a48e5\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"119883554\",\"name\":\"J. Yu\"},{\"authorId\":null,\"name\":\"Zengchang Qin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"490a9ee7c995140136d2c5054081c08429ebc171\",\"title\":\"Scene Graph Reasoning with Prior Visual Relationship for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/490a9ee7c995140136d2c5054081c08429ebc171\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152902853\",\"name\":\"Vedant Singh\"},{\"authorId\":\"144833581\",\"name\":\"V. Doshi\"},{\"authorId\":\"66507017\",\"name\":\"Mitali Dave\"},{\"authorId\":\"144301613\",\"name\":\"A. Desai\"},{\"authorId\":\"1729588200\",\"name\":\"Smith Agrawal\"},{\"authorId\":\"144791188\",\"name\":\"J. Shah\"},{\"authorId\":\"9272713\",\"name\":\"P. Kanani\"}],\"doi\":\"10.1007/978-981-15-4451-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5730053fd973426028fa3b47a55be9d7fd2938d\",\"title\":\"Answering Questions in Natural Language About Images Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/e5730053fd973426028fa3b47a55be9d7fd2938d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.05054\",\"authors\":[{\"authorId\":\"114577307\",\"name\":\"C. Alberti\"},{\"authorId\":\"50602231\",\"name\":\"Jeffrey Ling\"},{\"authorId\":\"123052390\",\"name\":\"Michael Collins\"},{\"authorId\":\"1781409\",\"name\":\"D. Reitter\"}],\"doi\":\"10.18653/v1/D19-1219\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"title\":\"Fusion of Detected Objects in Text for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"48079221\",\"name\":\"Sungho Park\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1016/j.neucom.2020.03.098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e48298519b5ff583e585a65eeea3ac10556adf\",\"title\":\"Selective residual learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e48298519b5ff583e585a65eeea3ac10556adf\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2006.05726\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7454abbee8f92dd0fd893c8039c03d66e9a5f032\",\"title\":\"Estimating semantic structure for the VQA answer space\",\"url\":\"https://www.semanticscholar.org/paper/7454abbee8f92dd0fd893c8039c03d66e9a5f032\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144485908\",\"name\":\"Y. Long\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"47390553\",\"name\":\"Zhihua Wei\"},{\"authorId\":\"73723234\",\"name\":\"Jinjing Gu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1016/j.ins.2020.04.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb8f7cb96782c422fdf67c48bcfef10b635cd6f0\",\"title\":\"RepeatPadding: Balancing words and sentence length for language comprehension in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/eb8f7cb96782c422fdf67c48bcfef10b635cd6f0\",\"venue\":\"Inf. Sci.\",\"year\":2020},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.01263\",\"authors\":[{\"authorId\":\"2551640\",\"name\":\"Atsushi Kanehira\"},{\"authorId\":\"3124509\",\"name\":\"Kentaro Takemoto\"},{\"authorId\":\"52176168\",\"name\":\"Sho Inayoshi\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2019.00879\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b016ff1148e8bf8ffa1beb5c8cd89c644825edf2\",\"title\":\"Multimodal Explanations by Predicting Counterfactuality in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b016ff1148e8bf8ffa1beb5c8cd89c644825edf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2009.13862\",\"authors\":[{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3287827\",\"name\":\"Guangluan Xu\"},{\"authorId\":\"7413451\",\"name\":\"Daoyu Lin\"},{\"authorId\":\"1379498558\",\"name\":\"Wei Dai\"},{\"authorId\":\"48607717\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/JSTSP.2020.2987729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"title\":\"Where is the Model Looking At? \\u2013 Concentrate and Explain the Network Attention\",\"url\":\"https://www.semanticscholar.org/paper/7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"2002.10215\",\"authors\":[{\"authorId\":\"48631626\",\"name\":\"Xinyu Wang\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"46668045\",\"name\":\"Chun Chet Ng\"},{\"authorId\":\"30099960\",\"name\":\"Canjie Luo\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"46699480\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"35462302\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01014\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"title\":\"On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/D18-1329\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32a64831c7a50e9c9b082cc4ee0e5ca4a92630b2\",\"title\":\"Adversarial Evaluation of Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/32a64831c7a50e9c9b082cc4ee0e5ca4a92630b2\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1807.08435\",\"authors\":[{\"authorId\":\"51151974\",\"name\":\"Prakruthi Prabhakar\"},{\"authorId\":\"51115915\",\"name\":\"Nitish Kulkarni\"},{\"authorId\":\"2145765\",\"name\":\"Linghao Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a838a1184cb9ca86ae910509bb318266101ae656\",\"title\":\"Question Relevance in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a838a1184cb9ca86ae910509bb318266101ae656\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1707.03017\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f57134b42638cbd57d0d8c4437e8b6b6a8bac4\",\"title\":\"Learning Visual Reasoning Without Strong Priors\",\"url\":\"https://www.semanticscholar.org/paper/15f57134b42638cbd57d0d8c4437e8b6b6a8bac4\",\"venue\":\"ICML 2017\",\"year\":2017},{\"arxivId\":\"1902.01876\",\"authors\":[{\"authorId\":\"8780591\",\"name\":\"S. Mueller\"},{\"authorId\":\"1701142\",\"name\":\"R. Hoffman\"},{\"authorId\":\"1703064\",\"name\":\"W. Clancey\"},{\"authorId\":\"68975512\",\"name\":\"Abigail Emrey\"},{\"authorId\":\"145555383\",\"name\":\"G. Klein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c3a72f47ed8d58c0554210828af1ce4bbf2dbcd\",\"title\":\"Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI\",\"url\":\"https://www.semanticscholar.org/paper/5c3a72f47ed8d58c0554210828af1ce4bbf2dbcd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145764583\",\"name\":\"F. Liu\"},{\"authorId\":\"40628473\",\"name\":\"Jing Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2019/122\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"title\":\"Densely Connected Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1908.04342\",\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"48933740\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/ICCV.2019.00437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cae43b28757e0c37a05156ed063dcc3bb652809\",\"title\":\"Why Does a Visual Question Have Different Answers?\",\"url\":\"https://www.semanticscholar.org/paper/4cae43b28757e0c37a05156ed063dcc3bb652809\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493849\",\"name\":\"Dejiang Kong\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1007/978-3-030-00776-8_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89e982f1a1cda786062f4044391a67d6739804cd\",\"title\":\"Visual Dialog with Multi-turn Attentional Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/89e982f1a1cda786062f4044391a67d6739804cd\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2001.05876\",\"authors\":[{\"authorId\":\"46659203\",\"name\":\"L. Wang\"},{\"authorId\":\"1486057423\",\"name\":\"Zechen Bai\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1609/aaai.v34i07.6898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85079d64d6fdd0ba5318fda119d152f2d2946391\",\"title\":\"Show, Recall, and Tell: Image Captioning with Recall Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/85079d64d6fdd0ba5318fda119d152f2d2946391\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":\"1910.03230\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"152876475\",\"name\":\"William W. J. Wang\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0bbae624efbfeee01bd38185c6d754c08417de7\",\"title\":\"Meta Module Network for Compositional Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/d0bbae624efbfeee01bd38185c6d754c08417de7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10747\",\"authors\":[{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171bb0f4359090e09fd5f528e3817e7f35873753\",\"title\":\"Language Tasks and Language Games: On Methodology in Current Natural Language Processing Research\",\"url\":\"https://www.semanticscholar.org/paper/171bb0f4359090e09fd5f528e3817e7f35873753\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.00260\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2017.452\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"title\":\"Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2008.06254\",\"authors\":[{\"authorId\":\"49291879\",\"name\":\"Y. Liu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1145/3394171.3413600\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"125b3bbe2850627d15283dbbfb10373c0d1fafba\",\"title\":\"ConsNet: Learning Consistency Graph for Zero-Shot Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/125b3bbe2850627d15283dbbfb10373c0d1fafba\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82117909\",\"name\":\"Sanket Shah\"},{\"authorId\":\"39719398\",\"name\":\"Anand Mishra\"},{\"authorId\":\"46202814\",\"name\":\"N. Yadati\"},{\"authorId\":\"2408872\",\"name\":\"P. Talukdar\"}],\"doi\":\"10.1609/aaai.v33i01.33018876\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d0818dac77eee5b970736e57a478bcedfb1b15fe\",\"title\":\"KVQA: Knowledge-Aware Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d0818dac77eee5b970736e57a478bcedfb1b15fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1802.05766\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"30a3eee5e9302108416f6234d739373dde68d373\",\"title\":\"Learning to Count Objects in Natural Images for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/30a3eee5e9302108416f6234d739373dde68d373\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"184002001b3b514f432e538f872aebce3c7db060\",\"title\":\"Chain of Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/184002001b3b514f432e538f872aebce3c7db060\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143912737\",\"name\":\"Heather Riley\"},{\"authorId\":\"1714890\",\"name\":\"M. Sridharan\"}],\"doi\":\"10.1145/3284432.3284456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a53ba48dba8dfb2d49e75e1160cee5b3201e020\",\"title\":\"Non-monotonic Logical Reasoning and Deep Learning for Explainable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4a53ba48dba8dfb2d49e75e1160cee5b3201e020\",\"venue\":\"HAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008208163\",\"name\":\"Fran\\u00e7ois Gard\\u00e8res\"},{\"authorId\":\"1824096\",\"name\":\"M. Ziaeefard\"},{\"authorId\":\"7816815\",\"name\":\"Baptiste Abeloos\"},{\"authorId\":\"1863173\",\"name\":\"F. L\\u00e9cu\\u00e9\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9958887e8dd5f84595818c50fb734b566996541a\",\"title\":\"ConceptBert: Concept-Aware Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9958887e8dd5f84595818c50fb734b566996541a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.01045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.04293\",\"authors\":[{\"authorId\":\"32856839\",\"name\":\"T. Ates\"},{\"authorId\":\"2033380403\",\"name\":\"Muhammed Samil Atesoglu\"},{\"authorId\":\"2033381520\",\"name\":\"Cagatay Yigit\"},{\"authorId\":\"116865200\",\"name\":\"Ilker Kesen\"},{\"authorId\":\"2033382593\",\"name\":\"Mert Kobas\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"81703837\",\"name\":\"T. Goksun\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b2397185ef6315ce346180d505df00550d6b08d\",\"title\":\"CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions\",\"url\":\"https://www.semanticscholar.org/paper/9b2397185ef6315ce346180d505df00550d6b08d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13406\",\"authors\":[{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"97671685\",\"name\":\"H. Wu\"},{\"authorId\":\"51135899\",\"name\":\"Yi Ren Fung\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1904c5389a70a905019d5429f09bc7f669bdc898\",\"title\":\"Learning from Lexical Perturbations for Consistent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1904c5389a70a905019d5429f09bc7f669bdc898\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06637\",\"authors\":[{\"authorId\":\"1742328079\",\"name\":\"Shaunak Halbe\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"title\":\"Exploring Weaknesses of VQA Models through Attribution Driven Insights\",\"url\":\"https://www.semanticscholar.org/paper/274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.15015\",\"authors\":[{\"authorId\":\"65844131\",\"name\":\"Yuxian Meng\"},{\"authorId\":\"1845298604\",\"name\":\"Shuhe Wang\"},{\"authorId\":\"5439717\",\"name\":\"Qinghong Han\"},{\"authorId\":\"48304805\",\"name\":\"Xiaofei Sun\"},{\"authorId\":\"93192602\",\"name\":\"Fei Wu\"},{\"authorId\":null,\"name\":\"Rui Yan\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3470e15ae52baae8b8560dd59c616da9820cf43a\",\"title\":\"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/3470e15ae52baae8b8560dd59c616da9820cf43a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1803.06936\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/TPAMI.2018.2880185\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8927117cba0d82d59a35f099b47acb291c6567e3\",\"title\":\"Inverse Visual Question Answering: A New Benchmark and VQA Diagnosis Tool\",\"url\":\"https://www.semanticscholar.org/paper/8927117cba0d82d59a35f099b47acb291c6567e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"title\":\"Refer360$^\\\\circ$: A Referring Expression Recognition Dataset in 360$^\\\\circ$ Images\",\"url\":\"https://www.semanticscholar.org/paper/6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66935500\",\"name\":\"P. Deshmukh\"},{\"authorId\":\"51502239\",\"name\":\"Rani S. Lande\"}],\"doi\":\"10.1109/ICICT48043.2020.9112454\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"title\":\"Convolutional Neural Network based Review System for Automatic Past Event Search using Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":\"1705.08923\",\"authors\":[{\"authorId\":\"144137447\",\"name\":\"Tao Zhou\"},{\"authorId\":\"1998918\",\"name\":\"Muhao Chen\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"},{\"authorId\":\"1750924\",\"name\":\"Demetri Terzopoulos\"}],\"doi\":\"10.1109/CVPRW.2017.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92d5fd4ef31cf86a650c7b01c26f0ac93304f98a\",\"title\":\"Attention-Based Natural Language Person Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/92d5fd4ef31cf86a650c7b01c26f0ac93304f98a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1901.05531\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3851b38bb6ec949c7bc5b3eb3334c3a6d50e5d2\",\"title\":\"Response to \\\"Visual Dialogue without Vision or Dialogue\\\" (Massiceti et al., 2018)\",\"url\":\"https://www.semanticscholar.org/paper/f3851b38bb6ec949c7bc5b3eb3334c3a6d50e5d2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.14603\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.24963/ijcai.2020/114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6b2bd7d4c9535174788dca2e7e6b2fe26fe2b1e\",\"title\":\"Dynamic Language Binding in Relational Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/c6b2bd7d4c9535174788dca2e7e6b2fe26fe2b1e\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144905355\",\"name\":\"Chao Ma\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145950894\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"title\":\"Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7484d9e753ccc529018f8c01027bfef304dc1b9\",\"title\":\"An Interpretable (Conversational) VQA model using Attention based Weighted Contextual Features\",\"url\":\"https://www.semanticscholar.org/paper/d7484d9e753ccc529018f8c01027bfef304dc1b9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388048026\",\"name\":\"Nitesh Methani\"},{\"authorId\":\"2409493\",\"name\":\"Pritha Ganguly\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"46638795\",\"name\":\"Pratyush Kumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33f950b8b4eb741e6a96063304923821bcfea790\",\"title\":\"Data Interpretation over Plots\",\"url\":\"https://www.semanticscholar.org/paper/33f950b8b4eb741e6a96063304923821bcfea790\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9185907\",\"name\":\"Dongchen Yu\"},{\"authorId\":\"145193127\",\"name\":\"Xing Gao\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":\"10.1109/ICIP.2018.8451516\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d323ddfa71598dddf18d82995c28a1ff8c217965\",\"title\":\"Structured Semantic Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d323ddfa71598dddf18d82995c28a1ff8c217965\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1907.09815\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"145371954\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"title\":\"Graph Reasoning Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10899\",\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Surveillance Video\",\"url\":\"https://www.semanticscholar.org/paper/8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1910.11033\",\"authors\":[{\"authorId\":\"73659073\",\"name\":\"T. Hascoet\"},{\"authorId\":\"12658654\",\"name\":\"Xue-jiao Deng\"},{\"authorId\":\"46932377\",\"name\":\"K. Tai\"},{\"authorId\":\"14425978\",\"name\":\"M. Sugiyama\"},{\"authorId\":\"48715900\",\"name\":\"Y. Adachi\"},{\"authorId\":\"47046257\",\"name\":\"S. Nakamura\"},{\"authorId\":\"1678564\",\"name\":\"Y. Ariki\"},{\"authorId\":\"49604548\",\"name\":\"T. Hayashi\"},{\"authorId\":\"1388661285\",\"name\":\"Tetusya Takiguchi\"}],\"doi\":\"10.1109/ICCVW.2019.00519\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"94705d9bc8580c3d0c64000689c3389dae6e2755\",\"title\":\"Assisting human experts in the interpretation of their visual process: A case study on assessing copper surface adhesive potency\",\"url\":\"https://www.semanticscholar.org/paper/94705d9bc8580c3d0c64000689c3389dae6e2755\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1906.08430\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":\"10.18653/v1/W19-1801\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"title\":\"Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects\",\"url\":\"https://www.semanticscholar.org/paper/a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.07512\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"89942851\",\"name\":\"Abhishek Kadian\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2019.00111\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"980d6820831d5cadfd0f1699b06145efa975f9fd\",\"title\":\"SplitNet: Sim2Sim and Task2Task Transfer for Embodied Visual Navigation\",\"url\":\"https://www.semanticscholar.org/paper/980d6820831d5cadfd0f1699b06145efa975f9fd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"50444302\",\"name\":\"Q. Li\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"46317592\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2019.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"title\":\"VizWiz-Priv: A Dataset for Recognizing the Presence and Purpose of Private Visual Information in Images Taken by Blind People\",\"url\":\"https://www.semanticscholar.org/paper/8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a7501eb6d58b1f347140402171df7b3291496ab2\",\"title\":\"Connective Cognition Network for Directional Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a7501eb6d58b1f347140402171df7b3291496ab2\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1704.05526\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a396a6febdacb84340d139096455e67049ac1e22\",\"title\":\"Learning to Reason: End-to-End Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a396a6febdacb84340d139096455e67049ac1e22\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1812.01880\",\"authors\":[{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00678\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe\",\"title\":\"Learning to Compose Dynamic Tree Structures for Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1901.06706\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"1868193\",\"name\":\"Farley Lai\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c54b796cc10cb530f77caa4d18e1c80ac863822\",\"title\":\"Visual Entailment: A Novel Task for Fine-Grained Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3c54b796cc10cb530f77caa4d18e1c80ac863822\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.07243\",\"authors\":[{\"authorId\":\"1410126033\",\"name\":\"Will Norcliffe-Brown\"},{\"authorId\":\"2019087\",\"name\":\"Efstathios Vafeias\"},{\"authorId\":\"1398036715\",\"name\":\"Sarah Parisot\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ac33d3dcecbed17580509a34bccdff2425f7ed8\",\"title\":\"Learning Conditioned Graph Structures for Interpretable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ac33d3dcecbed17580509a34bccdff2425f7ed8\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1909.10650\",\"authors\":[{\"authorId\":\"143912737\",\"name\":\"Heather Riley\"},{\"authorId\":\"1714890\",\"name\":\"M. Sridharan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb2fb0462a1e8cf01e2ddf4ff7029d1edb3a8d58\",\"title\":\"Non-monotonic Logical Reasoning Guiding Deep Learning for Explainable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bb2fb0462a1e8cf01e2ddf4ff7029d1edb3a8d58\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.05710\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"title\":\"Look Before you Speak: Visually Contextualized Utterances\",\"url\":\"https://www.semanticscholar.org/paper/b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.04726\",\"authors\":[{\"authorId\":\"1380616323\",\"name\":\"Jeff Da\"},{\"authorId\":\"39191185\",\"name\":\"M. Forbes\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"90390316\",\"name\":\"Anthony Zheng\"},{\"authorId\":\"2012510\",\"name\":\"Jena D. Hwang\"},{\"authorId\":\"2691021\",\"name\":\"Antoine Bosselut\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c5d597e5f34a01809f1bf4fd6e0f3475f59fb4d\",\"title\":\"Edited Media Understanding: Reasoning About Implications of Manipulated Images\",\"url\":\"https://www.semanticscholar.org/paper/7c5d597e5f34a01809f1bf4fd6e0f3475f59fb4d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2009.00325\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"48679036\",\"name\":\"J. Heikkila\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13160\",\"authors\":[{\"authorId\":\"145251354\",\"name\":\"Xin Hong\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"70414094\",\"name\":\"J. Guo\"},{\"authorId\":\"30857876\",\"name\":\"Xueqi Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"825363a518902f3e44d61bd9a10262d0e527be60\",\"title\":\"Transformation Driven Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/825363a518902f3e44d61bd9a10262d0e527be60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.06225\",\"authors\":[{\"authorId\":\"7412048\",\"name\":\"Moloud Abdar\"},{\"authorId\":\"1866603\",\"name\":\"Farhad Pourpanah\"},{\"authorId\":\"1833049320\",\"name\":\"Sadiq Hussain\"},{\"authorId\":\"1404229235\",\"name\":\"D. Rezazadegan\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"103809454\",\"name\":\"Mohammad Ghavamzadeh\"},{\"authorId\":\"93660405\",\"name\":\"P. Fieguth\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"145434104\",\"name\":\"Abbas Khosravi\"},{\"authorId\":\"144076869\",\"name\":\"U. Acharya\"},{\"authorId\":\"144531494\",\"name\":\"V. Makarenkov\"},{\"authorId\":\"98613453\",\"name\":\"S. Nahavandi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"497d5002f41feb2e4729a171cdc5c9f22ee403df\",\"title\":\"A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/497d5002f41feb2e4729a171cdc5c9f22ee403df\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.06249\",\"authors\":[{\"authorId\":\"3322871\",\"name\":\"Zhuosheng Zhang\"},{\"authorId\":\"47941144\",\"name\":\"Hai Zhao\"},{\"authorId\":\"108085542\",\"name\":\"Rui Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa9c6d43b36a55b34c2e9207355d355fd94691af\",\"title\":\"Machine Reading Comprehension: The Role of Contextualized Language Models and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/aa9c6d43b36a55b34c2e9207355d355fd94691af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3126686.3126695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"title\":\"Generative Attention Model with Adversarial Self-learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.00265\",\"authors\":[{\"authorId\":\"2373307\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/WACV.2019.00043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"title\":\"Interpretable Visual Question Answering by Visual Grounding From Attention Supervision Mining\",\"url\":\"https://www.semanticscholar.org/paper/b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1811.10582\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"1868193\",\"name\":\"Farley Lai\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0955252cd57db8503a2ed9e56f195fa44b1bc0d4\",\"title\":\"Visual Entailment Task for Visually-Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/0955252cd57db8503a2ed9e56f195fa44b1bc0d4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582025078\",\"name\":\"Ronja Utescher\"}],\"doi\":\"10.18653/v1/W19-0602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bec9ed1973b02bf75e17d643b56612c7ce8b220\",\"title\":\"Visual TTR - Modelling Visual Question Answering in Type Theory with Records\",\"url\":\"https://www.semanticscholar.org/paper/3bec9ed1973b02bf75e17d643b56612c7ce8b220\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.02985\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64d1b545f586d930cbe67402e853ab26a8f6e18d\",\"title\":\"Embodied Vision-and-Language Navigation with Dynamic Convolutional Filters\",\"url\":\"https://www.semanticscholar.org/paper/64d1b545f586d930cbe67402e853ab26a8f6e18d\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2764826\",\"name\":\"H. Degen\"},{\"authorId\":\"1399251774\",\"name\":\"L. Reinerman-Jones\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50334-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e82d446b3bfcbded4a212bf25db36bea9b62dad7\",\"title\":\"Artificial Intelligence in HCI: First International Conference, AI-HCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19\\u201324, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/e82d446b3bfcbded4a212bf25db36bea9b62dad7\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31760501\",\"name\":\"K. Yoo\"},{\"authorId\":\"32021996\",\"name\":\"H. S. Jo\"},{\"authorId\":\"3305330\",\"name\":\"Hanbit Lee\"},{\"authorId\":\"122200203\",\"name\":\"Jeeseung Han\"},{\"authorId\":\"3013044\",\"name\":\"Sanggoo Lee\"}],\"doi\":\"10.1109/ICCVW.2019.00105\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93c7e48355ff86a79d95682e3d97acabaccd3928\",\"title\":\"Stochastic Relational Network\",\"url\":\"https://www.semanticscholar.org/paper/93c7e48355ff86a79d95682e3d97acabaccd3928\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1805.11818\",\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"}],\"doi\":\"10.18653/v1/N18-2123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72d7c465ef199a9670b3da7a318b0227f5cc3229\",\"title\":\"Visual Referring Expression Recognition: What Do Systems Actually Learn?\",\"url\":\"https://www.semanticscholar.org/paper/72d7c465ef199a9670b3da7a318b0227f5cc3229\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28458352\",\"name\":\"S. Kim\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7af4a37e6e63b5f06e7bfb6e7c8910322774efb9\",\"title\":\"PROGRESSIVE MODULE NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/7af4a37e6e63b5f06e7bfb6e7c8910322774efb9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653799\",\"name\":\"W. Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":\"10.18653/v1/2020.alvr-1.2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30f86e15b4fd7936b9812d476976a6ff579b9036\",\"title\":\"Toward General Scene Graph: Integration of Visual Semantic Knowledge with Entity Synset Alignment\",\"url\":\"https://www.semanticscholar.org/paper/30f86e15b4fd7936b9812d476976a6ff579b9036\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"48696362\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894845\",\"name\":\"Fei Wu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3394171.3413745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"title\":\"Photo Stream Question Answer\",\"url\":\"https://www.semanticscholar.org/paper/a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.00235\",\"authors\":[{\"authorId\":\"1516206362\",\"name\":\"Tingke Shen\"},{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2019.01049\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b4cb0a7617212eb40c537f4053d571faa4b8227c\",\"title\":\"Learning to Caption Images Through a Lifetime by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/b4cb0a7617212eb40c537f4053d571faa4b8227c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48941288\",\"name\":\"T. Akter\"},{\"authorId\":\"1909948\",\"name\":\"Bryan Dosono\"},{\"authorId\":\"1927977\",\"name\":\"T. Ahmed\"},{\"authorId\":\"145728136\",\"name\":\"Apu Kapadia\"},{\"authorId\":\"1403688897\",\"name\":\"Bryan Semaan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb4ecdbbf691e9827d5452ae1cd524ba1d017dd\",\"title\":\"\\\"I am uncomfortable sharing what I can't see\\\": Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications\",\"url\":\"https://www.semanticscholar.org/paper/0eb4ecdbbf691e9827d5452ae1cd524ba1d017dd\",\"venue\":\"USENIX Security Symposium\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741390809\",\"name\":\"Weidong Tian\"},{\"authorId\":\"1657469716\",\"name\":\"Rencai Zhou\"},{\"authorId\":\"151481257\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"title\":\"Cascading Top-Down Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2005.06035\",\"authors\":[{\"authorId\":\"46882405\",\"name\":\"Chen Zheng\"},{\"authorId\":\"144919537\",\"name\":\"Quan Guo\"},{\"authorId\":\"2190934\",\"name\":\"Parisa Kordjamshidi\"}],\"doi\":\"10.18653/v1/2020.acl-main.683\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b293e4fd06e8a0f3ea7e46c4dafb575b288515e2\",\"title\":\"Cross-Modality Relevance for Reasoning on Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/b293e4fd06e8a0f3ea7e46c4dafb575b288515e2\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"1716207091\",\"name\":\"Xuefeng Hu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3801644100f6f7e521b3f28c2785a2d151988f4\",\"title\":\"Joint Learning of Scene Graph Generation and Reasoning for Visual Question Answering Project Survey\",\"url\":\"https://www.semanticscholar.org/paper/c3801644100f6f7e521b3f28c2785a2d151988f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007669688\",\"name\":\"Zujie Liang\"},{\"authorId\":\"49408562\",\"name\":\"Weitao Jiang\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"47054782\",\"name\":\"Jiaying Zhu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.265\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f5dffcc47a08ef74e93077583b0e8a11662bf02\",\"title\":\"Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5f5dffcc47a08ef74e93077583b0e8a11662bf02\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1811.12772\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":\"10.1016/j.imavis.2020.103985\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a678b68abd4047d5342f64725f57a04647a47711\",\"title\":\"From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/a678b68abd4047d5342f64725f57a04647a47711\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145986708\",\"name\":\"Bo Sun\"},{\"authorId\":\"14701865\",\"name\":\"Z. Yao\"},{\"authorId\":\"48380350\",\"name\":\"Yinghui Zhang\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"}],\"doi\":\"10.1016/j.jvcir.2020.102762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86475be7965eebb5edba838788d26c9272f14a3b\",\"title\":\"Local relation network with multilevel attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/86475be7965eebb5edba838788d26c9272f14a3b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1908.06917\",\"authors\":[{\"authorId\":\"40306284\",\"name\":\"Svitlana Vakulenko\"},{\"authorId\":\"117857085\",\"name\":\"J. D. F. Garc\\u00eda\"},{\"authorId\":\"1708607\",\"name\":\"A. Polleres\"},{\"authorId\":\"1696030\",\"name\":\"M. Rijke\"},{\"authorId\":\"1708906\",\"name\":\"Michael Cochez\"}],\"doi\":\"10.1145/3357384.3358026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8e40d1bf3c97dd91d3631203801ebeb453311d8\",\"title\":\"Message Passing for Complex Question Answering over Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/a8e40d1bf3c97dd91d3631203801ebeb453311d8\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1707.00683\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"title\":\"Modulating early visual processing by language\",\"url\":\"https://www.semanticscholar.org/paper/feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1812.01855\",\"authors\":[{\"authorId\":\"2522647\",\"name\":\"Jiaxin Shi\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"8549842\",\"name\":\"Juan-Zi Li\"}],\"doi\":\"10.1109/CVPR.2019.00857\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ca1a2b86d39495be5524a0e39b663f7c423a0397\",\"title\":\"Explainable and Explicit Visual Reasoning Over Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/ca1a2b86d39495be5524a0e39b663f7c423a0397\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.10210\",\"authors\":[{\"authorId\":\"108630954\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"2455565\",\"name\":\"S. Xiao\"},{\"authorId\":\"115718758\",\"name\":\"A. Mclean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"title\":\"On modality bias in the TVQA dataset.\",\"url\":\"https://www.semanticscholar.org/paper/6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.12352\",\"authors\":[{\"authorId\":\"1845867134\",\"name\":\"Letitia Parcalabescu\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"143876555\",\"name\":\"A. Frank\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"title\":\"Seeing past words: Testing the cross-modal capabilities of pretrained V&L models\",\"url\":\"https://www.semanticscholar.org/paper/1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2692127\",\"name\":\"Mourad Sarrouti\"},{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":\"10.18653/v1/2020.alvr-1.3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d77a71c94e688d92a3fa10fb7f7feda2c306b9dc\",\"title\":\"Visual Question Generation from Radiology Images\",\"url\":\"https://www.semanticscholar.org/paper/d77a71c94e688d92a3fa10fb7f7feda2c306b9dc\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":\"2006.11524\",\"authors\":[{\"authorId\":\"1961237\",\"name\":\"S. Amizadeh\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"2636739\",\"name\":\"Oleksandr Polozov\"},{\"authorId\":\"153268415\",\"name\":\"Y. Huang\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb62c82e469a265d986a164ba56d96d130937fd7\",\"title\":\"Neuro-Symbolic Visual Reasoning: Disentangling \\\"Visual\\\" from \\\"Reasoning\\\"\",\"url\":\"https://www.semanticscholar.org/paper/fb62c82e469a265d986a164ba56d96d130937fd7\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"152187759\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"title\":\"Dataset Paper Videos Hours Classes Description Charades Hollywood in Homes : Crowdsourcing Data Collection for Activity Understanding 9848\",\"url\":\"https://www.semanticscholar.org/paper/aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"title\":\"A Simple Baseline for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279549\",\"name\":\"Xiao Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"title\":\"Leveraging Multimodal Perspectives to Learn Common Sense for Vision and Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Wang\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.5555/3398761.3399067\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d309b15d13361257ab3099fb9af6908284fce52\",\"title\":\"An Interpretable Multimodal Visual Question Answering System using Attention-based Weighted Contextual Features\",\"url\":\"https://www.semanticscholar.org/paper/2d309b15d13361257ab3099fb9af6908284fce52\",\"venue\":\"AAMAS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"title\":\"Bilinear Graph Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26161085\",\"name\":\"Kalpesh Krishna\"},{\"authorId\":null,\"name\":\"Videsh Suman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a1bcf3c84607f7aeb0601658845ca2083059f43\",\"title\":\"Semi-Supervised Learning for Vision-and-Language Tasks using MixMatch\",\"url\":\"https://www.semanticscholar.org/paper/7a1bcf3c84607f7aeb0601658845ca2083059f43\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1904.08920\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00851\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af1f7739283bdbd2b7a94903041f6d6afd991907\",\"title\":\"Towards VQA Models That Can Read\",\"url\":\"https://www.semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.08556\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-030-01234-2_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c611b9c82e234b344a232bcbbe5436e06da69f0b\",\"title\":\"Explainable Neural Computation via Stack Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/c611b9c82e234b344a232bcbbe5436e06da69f0b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36053954\",\"name\":\"Philipp Harzig\"},{\"authorId\":\"1832927\",\"name\":\"C. Eggert\"},{\"authorId\":\"144739319\",\"name\":\"R. Lienhart\"}],\"doi\":\"10.1145/3206025.3206054\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ec21434615f72267d26d8e2d8cb7671561d26fc6\",\"title\":\"Visual Question Answering With a Hybrid Convolution Recurrent Model\",\"url\":\"https://www.semanticscholar.org/paper/ec21434615f72267d26d8e2d8cb7671561d26fc6\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1804.00105\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708223\",\"name\":\"B. Li\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00757\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"title\":\"Visual Question Reasoning on General Dependency Tree\",\"url\":\"https://www.semanticscholar.org/paper/eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.02660\",\"authors\":[{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"145124903\",\"name\":\"J. Deng\"}],\"doi\":\"10.1109/ICCV.2019.00214\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"title\":\"SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1712.05558\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68773df340498768e88487abe8f7fbac5fcb52d\",\"title\":\"CoDraw: Visual Dialog for Collaborative Drawing\",\"url\":\"https://www.semanticscholar.org/paper/b68773df340498768e88487abe8f7fbac5fcb52d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2018.00008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.04422\",\"authors\":[{\"authorId\":\"1802508687\",\"name\":\"Vatsal Goel\"},{\"authorId\":\"1802505447\",\"name\":\"Mohit Chandak\"},{\"authorId\":\"47583481\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"title\":\"IQ-VQA: Intelligent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66898506\",\"name\":\"Jae-Won Jung\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"}],\"doi\":\"10.4218/etrij.2019-0093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38fd47f4b27e0189d80cfa405fd24df081adb5de\",\"title\":\"Improving visual relationship detection using linguistic and spatial cues\",\"url\":\"https://www.semanticscholar.org/paper/38fd47f4b27e0189d80cfa405fd24df081adb5de\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12076788\",\"name\":\"Zhihao Cao\"},{\"authorId\":\"1781579\",\"name\":\"S. Mu\"},{\"authorId\":\"153607578\",\"name\":\"Mengping Dong\"}],\"doi\":\"10.1007/s00371-019-01763-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59cb04b1ac489b1120d430ccb9f58691628990bf\",\"title\":\"Two-attribute e-commerce image classification based on a convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/59cb04b1ac489b1120d430ccb9f58691628990bf\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1710.07300\",\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"title\":\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16726627\",\"name\":\"C. Liu\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1007/978-3-030-20876-9_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1687d0120e937d5efe2022cbeab19b38edba0608\",\"title\":\"A2A: Attention to Attention Reasoning for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1687d0120e937d5efe2022cbeab19b38edba0608\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.11532\",\"authors\":[{\"authorId\":\"7591930\",\"name\":\"Vardaan Pahuja\"},{\"authorId\":\"145016608\",\"name\":\"J. Fu\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":\"10.18653/v1/D19-6401\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"857b81e7c21cb878781d90ddcaa72ced83cb177c\",\"title\":\"Structure Learning for Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/857b81e7c21cb878781d90ddcaa72ced83cb177c\",\"venue\":\"LANTERN@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"49728738\",\"name\":\"T. Serre\"}],\"doi\":\"10.1111/nyas.14320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"title\":\"Beyond the feedforward sweep: feedback computations in the visual cortex\",\"url\":\"https://www.semanticscholar.org/paper/83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"venue\":\"Annals of the New York Academy of Sciences\",\"year\":2020},{\"arxivId\":\"2002.12204\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"title\":\"Visual Commonsense R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3343031.3350894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"title\":\"Annotation Efficient Cross-Modal Retrieval with Adversarial Attentive Alignment\",\"url\":\"https://www.semanticscholar.org/paper/b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2011.03856\",\"authors\":[{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.272\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55188532ea9ea4d4a4872ebe79fc3add14cd34dd\",\"title\":\"Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles\",\"url\":\"https://www.semanticscholar.org/paper/55188532ea9ea4d4a4872ebe79fc3add14cd34dd\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1912.06859\",\"authors\":[{\"authorId\":\"40306284\",\"name\":\"Svitlana Vakulenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a79533ac3e781e26aced841d258b05c5226a88a\",\"title\":\"Knowledge-based Conversational Search\",\"url\":\"https://www.semanticscholar.org/paper/8a79533ac3e781e26aced841d258b05c5226a88a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48079662\",\"name\":\"Sungho Park\"},{\"authorId\":\"145864562\",\"name\":\"Sunhee Hwang\"},{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1109/ACCESS.2020.3041503\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"title\":\"Fair-VQA: Fairness-Aware Visual Question Answering Through Sensitive Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.13262\",\"authors\":[{\"authorId\":\"39209233\",\"name\":\"Siwen Luo\"},{\"authorId\":\"2046142\",\"name\":\"S. Han\"},{\"authorId\":\"33053279\",\"name\":\"Kaiyuan Sun\"},{\"authorId\":\"48422087\",\"name\":\"Josiah Poon\"}],\"doi\":\"10.1007/978-3-030-63830-6_44\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"title\":\"REXUP: I REason, I EXtract, I UPdate with Structured Compositional Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2010.12435\",\"authors\":[{\"authorId\":\"9268397\",\"name\":\"Xuehai He\"},{\"authorId\":\"48569200\",\"name\":\"Zhuo Cai\"},{\"authorId\":\"1629217804\",\"name\":\"Wenlan Wei\"},{\"authorId\":\"49890963\",\"name\":\"Yichen Zhang\"},{\"authorId\":\"37756359\",\"name\":\"Luntian Mou\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"40526720\",\"name\":\"Pengtao Xie\"}],\"doi\":\"10.36227/techrxiv.13127537.v1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72e0dccf59f126a64f970fe9f4712b3221a3be8c\",\"title\":\"Pathological Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e0dccf59f126a64f970fe9f4712b3221a3be8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08070\",\"authors\":[{\"authorId\":\"29909347\",\"name\":\"S. Longpre\"},{\"authorId\":\"1653890520\",\"name\":\"Yi Lu\"},{\"authorId\":\"46435365\",\"name\":\"C. DuBois\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2facbd54b2f8527018453a89e0bb0eb69ae53df1\",\"title\":\"On the Transferability of Minimal Prediction Preserving Inputs in Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2facbd54b2f8527018453a89e0bb0eb69ae53df1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00204\",\"authors\":[{\"authorId\":\"3450120\",\"name\":\"Phung Lai\"},{\"authorId\":\"11032760\",\"name\":\"Nhathai Phan\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"},{\"authorId\":\"1603029692\",\"name\":\"Anuja Badeti\"},{\"authorId\":\"2325975\",\"name\":\"D. Newman\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206753\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21d502c84df9d9d699a3cac71f13885ef8a345d4\",\"title\":\"Ontology-based Interpretable Machine Learning for Textual Data\",\"url\":\"https://www.semanticscholar.org/paper/21d502c84df9d9d699a3cac71f13885ef8a345d4\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2002.08325\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1007/978-3-030-58589-1_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558984f821c4b9fb9aacf7441cf9ca6d303be836\",\"title\":\"VQA-LOL: Visual Question Answering under the Lens of Logic\",\"url\":\"https://www.semanticscholar.org/paper/558984f821c4b9fb9aacf7441cf9ca6d303be836\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":8081284,\"doi\":\"10.1109/CVPR.2017.670\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":156,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"X. Lin\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Deeper LSTM and normalized CNN Visual Question Answering model\",\"url\":\"\",\"venue\":\"https:// github.com/VT-vision-lab/VQA_LSTM_CNN\",\"year\":2015},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"P. Wang\"},{\"authorId\":null,\"name\":\"C. Shen\"},{\"authorId\":null,\"name\":\"A. van den Hengel\"},{\"authorId\":null,\"name\":\"A. R. Dick\"},{\"authorId\":null,\"name\":\"C. Xiong\"},{\"authorId\":null,\"name\":\"S. Merity\"},{\"authorId\":null,\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"plicit knowledge - based reasoning for visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.08974\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"title\":\"Towards Transparent AI Systems: Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Yang J. Lu\"},{\"authorId\":null,\"name\":\"D. Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hierarchical QuestionImage CoAttention for Visual Question Answer\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Saito\"},{\"authorId\":null,\"name\":\"A. Shin\"},{\"authorId\":null,\"name\":\"Y. Ushiku\"},{\"authorId\":null,\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Dualnet: Domaininvariant network for visual question answering\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1606.06108\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/W16-3203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbaa92c289f4f5ff9a57b19a2725036a92311f5\",\"title\":\"Focused Evaluation for Image Description with Binary Forced-Choice Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ecbaa92c289f4f5ff9a57b19a2725036a92311f5\",\"venue\":\"VL@ACL\",\"year\":2016},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.06622\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb859d4184476bd80d5f2090b3401c702f66135\",\"title\":\"Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions\",\"url\":\"https://www.semanticscholar.org/paper/0eb859d4184476bd80d5f2090b3401c702f66135\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1609.06657\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbccfd4f5ec4bf6a45bc48caf13c11161f9c2da3\",\"title\":\"The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)\",\"url\":\"https://www.semanticscholar.org/paper/bbccfd4f5ec4bf6a45bc48caf13c11161f9c2da3\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"title\":\"Deep Compositional Question Answering with Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"J. Yang\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Hierarchical QuestionImage Co-Attention for Visual Question Answering\",\"url\":\"\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2011.5995347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0302bb2d5476540cfb21467473f5eca843caf90b\",\"title\":\"Unbiased look at dataset bias\",\"url\":\"https://www.semanticscholar.org/paper/0302bb2d5476540cfb21467473f5eca843caf90b\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Fritz.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hierarchical QuestionImage CoAttention for Visual Question Answer\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1602.04938\",\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.1145/2939672.2939778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5091316bb1c6db6c6a813f4391911a5c311fdfe0\",\"title\":\"\\\"Why Should I Trust You?\\\": Explaining the Predictions of Any Classifier\",\"url\":\"https://www.semanticscholar.org/paper/5091316bb1c6db6c6a813f4391911a5c311fdfe0\",\"venue\":\"HLT-NAACL Demos\",\"year\":2016},{\"arxivId\":\"1704.05526\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a396a6febdacb84340d139096455e67049ac1e22\",\"title\":\"Learning to Reason: End-to-End Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a396a6febdacb84340d139096455e67049ac1e22\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attend and Answer : Exploring Question - Guided Spatial Attention for Visual Question Answering\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1603.08507\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46493-0_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"title\":\"Generating Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Yang\"},{\"authorId\":null,\"name\":\"X. He\"},{\"authorId\":null,\"name\":\"J. Gao\"},{\"authorId\":null,\"name\":\"L. Deng\"},{\"authorId\":null,\"name\":\"A. Smola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attend and Answer : Exploring Question - Guided Spatial Attention for Visual Question Answering\",\"url\":\"\",\"venue\":\"In ECCV\",\"year\":2016},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2016.538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1145/2185520.2185597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d913b9d742b99119d96ad2b661f3e7e7c2fa5e2b\",\"title\":\"What makes Paris look like Paris?\",\"url\":\"https://www.semanticscholar.org/paper/d913b9d742b99119d96ad2b661f3e7e7c2fa5e2b\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d76a09aa363685bc0f04a502ed853dc09a574e2\",\"title\":\"Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization\",\"url\":\"https://www.semanticscholar.org/paper/7d76a09aa363685bc0f04a502ed853dc09a574e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1606.06108\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICME.2017.8019436\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"121a9a160f1f2819a01edbe522024b58dbfee798\",\"title\":\"DualNet: Domain-invariant network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/121a9a160f1f2819a01edbe522024b58dbfee798\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479304\",\"name\":\"T. Berg\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"}],\"doi\":\"10.1109/ICCV.2013.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1086d524f9c33eb802145c83d0518034974d4fe4\",\"title\":\"How Do You Tell a Blackbird from a Crow?\",\"url\":\"https://www.semanticscholar.org/paper/1086d524f9c33eb802145c83d0518034974d4fe4\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. H. Kim\"},{\"authorId\":null,\"name\":\"K. W. On\"},{\"authorId\":null,\"name\":\"W. Lim\"},{\"authorId\":null,\"name\":\"J. Kim\"},{\"authorId\":null,\"name\":\"J. W. Ha\"},{\"authorId\":null,\"name\":\"B. T. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1703.04730\",\"authors\":[{\"authorId\":\"2572525\",\"name\":\"Pang Wei Koh\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08ad8fad21f6ec4cda4d56be1ca5e146b7c913a1\",\"title\":\"Understanding Black-box Predictions via Influence Functions\",\"url\":\"https://www.semanticscholar.org/paper/08ad8fad21f6ec4cda4d56be1ca5e146b7c913a1\",\"venue\":\"ICML\",\"year\":2017}],\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Mental model\",\"topicId\":\"4542\",\"url\":\"https://www.semanticscholar.org/topic/4542\"},{\"topic\":\"ICCV\",\"topicId\":\"785155\",\"url\":\"https://www.semanticscholar.org/topic/785155\"},{\"topic\":\"Iteration\",\"topicId\":\"11823\",\"url\":\"https://www.semanticscholar.org/topic/11823\"},{\"topic\":\"Autostereogram\",\"topicId\":\"99453\",\"url\":\"https://www.semanticscholar.org/topic/99453\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Our World\",\"topicId\":\"979981\",\"url\":\"https://www.semanticscholar.org/topic/979981\"},{\"topic\":\"Decibel\",\"topicId\":\"17933\",\"url\":\"https://www.semanticscholar.org/topic/17933\"},{\"topic\":\"Amazon Web Services\",\"topicId\":\"8552\",\"url\":\"https://www.semanticscholar.org/topic/8552\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"}],\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"