"{\"abstract\":\"We present a system that demonstrates how the compositional structure of events, in concert with the compositional structure of language, can interplay with the underlying focusing mechanisms in video action recognition, providing a medium for top-down and bottom-up integration as well as multi-modal integration between vision and language. We show how the roles played by participants (nouns), their characteristics (adjectives), the actions performed (verbs), the manner of such actions (adverbs), and changing spatial relations between participants (prepositions), in the form of whole-sentence descriptions mediated by a grammar, guides the activity-recognition process. Further, the utility and expressiveness of our framework is demonstrated by performing three separate tasks in the domain of multi-activity video: sentence-guided focus of attention, generation of sentential description, and query-based search, simply by leveraging the framework in different manners.\",\"arxivId\":\"1308.4189\",\"authors\":[{\"authorId\":\"40155668\",\"name\":\"N. Siddharth\",\"url\":\"https://www.semanticscholar.org/author/40155668\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\",\"url\":\"https://www.semanticscholar.org/author/21570451\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\",\"url\":\"https://www.semanticscholar.org/author/1737754\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1309.5174\",\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1109/TPAMI.2015.2505297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ab036b680e8408ec74f78a918f3ffbf6c906d70\",\"title\":\"Saying What You're Looking For: Linguistics Meets Video Search\",\"url\":\"https://www.semanticscholar.org/paper/3ab036b680e8408ec74f78a918f3ffbf6c906d70\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1904.13003\",\"authors\":[{\"authorId\":\"143714141\",\"name\":\"H. Chen\"},{\"authorId\":\"1778107\",\"name\":\"G. Chirikjian\"}],\"doi\":\"10.1109/CVPRW50498.2020.00437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f91bdd76a8f50241fba9341c0eb67ed5a03b71f\",\"title\":\"Curvature: A signature for Action Recognition in Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3f91bdd76a8f50241fba9341c0eb67ed5a03b71f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1603.08079\",\"authors\":[{\"authorId\":\"1908728\",\"name\":\"Yevgeni Berzak\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"38872009\",\"name\":\"Daniel Harari\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.18653/v1/D15-1172\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3244699e06b145ffa65d0fbddb2ce6e5da889418\",\"title\":\"Do You See What I Mean? Visual Resolution of Linguistic Ambiguities\",\"url\":\"https://www.semanticscholar.org/paper/3244699e06b145ffa65d0fbddb2ce6e5da889418\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1613/jair.4556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083d1055f81dd7c9b41233a92b9768a857d1db58\",\"title\":\"A Compositional Framework for Grounding Language Inference, Generation, and Acquisition in Video\",\"url\":\"https://www.semanticscholar.org/paper/083d1055f81dd7c9b41233a92b9768a857d1db58\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382419\",\"name\":\"P. Narayana\"},{\"authorId\":\"143905691\",\"name\":\"J. Beveridge\"},{\"authorId\":\"1694404\",\"name\":\"B. Draper\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10ffdfdbc0aafb89d94528f359425de0c7a81986\",\"title\":\"Interacting HiddenMarkovModels for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/10ffdfdbc0aafb89d94528f359425de0c7a81986\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"},{\"authorId\":\"143868576\",\"name\":\"A. Srivastava\"},{\"authorId\":\"2422388\",\"name\":\"Jingyong Su\"}],\"doi\":\"10.1007/s11263-016-0913-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17724a4f885b5e56670bcecd00fc6add218e5dd8\",\"title\":\"Spatially Coherent Interpretations of Videos Using Pattern Theory\",\"url\":\"https://www.semanticscholar.org/paper/17724a4f885b5e56670bcecd00fc6add218e5dd8\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51519704\",\"name\":\"Candace Ross\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"1908728\",\"name\":\"Yevgeni Berzak\"},{\"authorId\":\"80666086\",\"name\":\"Battushig Myanganbayar\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":\"10.18653/v1/D18-1285\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"58000e8b38b31e073bd6c8e5c056adddd05de211\",\"title\":\"Grounding language acquisition by training semantic parsers using captioned videos\",\"url\":\"https://www.semanticscholar.org/paper/58000e8b38b31e073bd6c8e5c056adddd05de211\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"150963621\",\"name\":\"Dalitso Banda\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":\"10.1016/J.PATREC.2019.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4efdf79751faf6475222fdfd1906a4ab07852f5d\",\"title\":\"Deep video-to-video transformations for accessibility with an application to photosensitivity\",\"url\":\"https://www.semanticscholar.org/paper/4efdf79751faf6475222fdfd1906a4ab07852f5d\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2464284\",\"name\":\"Scott Alan Bronikowski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1276546f5ee026ff2bf4b33394fbab4eb8e5839\",\"title\":\"Grounding robot motion in natural language and visual perception\",\"url\":\"https://www.semanticscholar.org/paper/e1276546f5ee026ff2bf4b33394fbab4eb8e5839\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3619154\",\"name\":\"R. Paul\"},{\"authorId\":\"36854588\",\"name\":\"Jacob Arkin\"},{\"authorId\":\"2761699\",\"name\":\"Derya Aksaray\"},{\"authorId\":\"143724999\",\"name\":\"N. Roy\"},{\"authorId\":\"35452905\",\"name\":\"T. M. Howard\"}],\"doi\":\"10.1177/0278364918777627\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c49d48268bf93061e308f2a3c320176a0407567\",\"title\":\"Efficient grounding of abstract spatial concepts for natural language interaction with robot platforms\",\"url\":\"https://www.semanticscholar.org/paper/1c49d48268bf93061e308f2a3c320176a0407567\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2018},{\"arxivId\":\"1706.00400\",\"authors\":[{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"2885717\",\"name\":\"Brooks Paige\"},{\"authorId\":\"3237420\",\"name\":\"Jan-Willem van de Meent\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2347189\",\"name\":\"F. Wood\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.17863/CAM.42159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"097889e0b93591d75de08f9da661ff882a1532f6\",\"title\":\"Learning Disentangled Representations with Semi-Supervised Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/097889e0b93591d75de08f9da661ff882a1532f6\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1810.00804\",\"authors\":[{\"authorId\":\"1947473\",\"name\":\"Yen-Ling Kuo\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":\"10.1109/IROS.2018.8593947\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51aa54e14983f4e17a542f459fc8f9e062958aa0\",\"title\":\"Deep Sequential Models for Sampling-Based Planning\",\"url\":\"https://www.semanticscholar.org/paper/51aa54e14983f4e17a542f459fc8f9e062958aa0\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1403.6173\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"113090874\",\"name\":\"W. Qiu\"},{\"authorId\":\"33985877\",\"name\":\"Annemarie Friedrich\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"889e723cd6d581e120ee6776b231fdf69707ab50\",\"title\":\"Coherent Multi-sentence Video Description with Variable Level of Detail\",\"url\":\"https://www.semanticscholar.org/paper/889e723cd6d581e120ee6776b231fdf69707ab50\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"124561dd9b4ae3b48847547afc2f366a8439aa76\",\"title\":\"Learning to Describe Video with Weak Supervision by Exploiting Negative Sentential Information\",\"url\":\"https://www.semanticscholar.org/paper/124561dd9b4ae3b48847547afc2f366a8439aa76\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2511655\",\"name\":\"Michael C. Burl\"},{\"authorId\":\"143939175\",\"name\":\"Russell L. Knight\"},{\"authorId\":\"144728727\",\"name\":\"Anthony C. Barrett\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc45ac8939300973c4ab4dcc42837fea012a964d\",\"title\":\"Visual Intelligence: Toward Machine Understanding of Video Content\",\"url\":\"https://www.semanticscholar.org/paper/cc45ac8939300973c4ab4dcc42837fea012a964d\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1508.06161\",\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"2464284\",\"name\":\"Scott Alan Bronikowski\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52a71d99e5f69b5702734333708ef1bbea8c89ec\",\"title\":\"Robot Language Learning, Generation, and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/52a71d99e5f69b5702734333708ef1bbea8c89ec\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.05914\",\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1007/s00138-016-0768-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a348493e0a3bd6b35cf02de9e71da675062841d\",\"title\":\"Collecting and annotating the large continuous action dataset\",\"url\":\"https://www.semanticscholar.org/paper/6a348493e0a3bd6b35cf02de9e71da675062841d\",\"venue\":\"Machine Vision and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf66e88fd2db751fb9e54211ca465355258b9bd0\",\"title\":\"Language-driven video retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bf66e88fd2db751fb9e54211ca465355258b9bd0\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118338493\",\"name\":\"Cheahuychou Mao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a39957371ad04a564dcea9347fc31c314462b88e\",\"title\":\"Understanding language through visual imagination\",\"url\":\"https://www.semanticscholar.org/paper/a39957371ad04a564dcea9347fc31c314462b88e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145102294\",\"name\":\"Moreira de Souza\"},{\"authorId\":\"123900281\",\"name\":\"Fillipe Dias\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"title\":\"Semantic Description of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1411.4064\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb077ee3b1cfd2f4e0f9ccf7733d299f7d9dbac1\",\"title\":\"A Faster Method for Tracking and Scoring Videos Corresponding to Sentences\",\"url\":\"https://www.semanticscholar.org/paper/fb077ee3b1cfd2f4e0f9ccf7733d299f7d9dbac1\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1109/TCSVT.2015.2502839\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e90a7b290ec3540f33054517a3f886be27007bd\",\"title\":\"Action Recognition by Time Series of Retinotopic Appearance and Motion Features\",\"url\":\"https://www.semanticscholar.org/paper/0e90a7b290ec3540f33054517a3f886be27007bd\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707726\",\"name\":\"J. Pustejovsky\"},{\"authorId\":\"1699960\",\"name\":\"I. V. D. Sluis\"},{\"authorId\":\"1792458\",\"name\":\"A. Belz\"},{\"authorId\":\"3461596\",\"name\":\"Johan Bos\"},{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"976fe1534c7121562b235302079e908bde3674b7\",\"title\":\"LREC 2018 Workshop AREA Annotation , Recognition and Evaluation of Actions PROCEEDINGS\",\"url\":\"https://www.semanticscholar.org/paper/976fe1534c7121562b235302079e908bde3674b7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51519704\",\"name\":\"Candace Ross\"},{\"authorId\":\"118338493\",\"name\":\"Cheahuychou Mao\"},{\"authorId\":\"1908728\",\"name\":\"Yevgeni Berzak\"},{\"authorId\":\"143912599\",\"name\":\"B. Katz\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e73812e3ea773fecfe3a1fda2106e612bfd2e35\",\"title\":\"Learning Language from Vision\",\"url\":\"https://www.semanticscholar.org/paper/4e73812e3ea773fecfe3a1fda2106e612bfd2e35\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33784036\",\"name\":\"X. Ban\"},{\"authorId\":\"47845415\",\"name\":\"Di Zhang\"},{\"authorId\":\"49991427\",\"name\":\"Jinsheng Sun\"},{\"authorId\":\"1583552872\",\"name\":\"Jingu Yang\"}],\"doi\":\"10.1007/s00779-019-01279-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d73d3b2cee047c0532ca37a7db98daa8e84aa51\",\"title\":\"An action identification method based on FSM and limb dry weight\",\"url\":\"https://www.semanticscholar.org/paper/9d73d3b2cee047c0532ca37a7db98daa8e84aa51\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1601.01006\",\"authors\":[{\"authorId\":\"144845024\",\"name\":\"Fei Han\"},{\"authorId\":\"144755330\",\"name\":\"Brian Reily\"},{\"authorId\":\"143790090\",\"name\":\"W. Hoff\"},{\"authorId\":\"38952862\",\"name\":\"Hao Zhang\"}],\"doi\":\"10.1016/j.cviu.2017.01.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7385f998caf17b2c6ae9f8808b6fd3a05205b438\",\"title\":\"Space-Time Representation of People Based on 3D Skeletal Data: A Review\",\"url\":\"https://www.semanticscholar.org/paper/7385f998caf17b2c6ae9f8808b6fd3a05205b438\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1704.07945\",\"authors\":[{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2017.162\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06184106c9a5dc602cac98f162b991707aaa4a80\",\"title\":\"Spatio-Temporal Person Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/06184106c9a5dc602cac98f162b991707aaa4a80\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2527581\",\"name\":\"C. Crispim\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"2148342\",\"name\":\"S. Cosar\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/AVSS.2016.7738029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81e82ef6bde267712cd1c2e31c250b6cf15acb9b\",\"title\":\"Semi-supervised understanding of complex activities from temporal concepts\",\"url\":\"https://www.semanticscholar.org/paper/81e82ef6bde267712cd1c2e31c250b6cf15acb9b\",\"venue\":\"2016 13th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1145/3009906\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e60536c847ac25dba4c1c071e0355e5537fe061\",\"title\":\"Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061\",\"venue\":\"ACM Comput. Surv.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2225767\",\"name\":\"G. Borchardt\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"},{\"authorId\":\"116820753\",\"name\":\"H. Nguyen\"},{\"authorId\":\"1724731\",\"name\":\"Sue Felshin\"},{\"authorId\":\"70062266\",\"name\":\"K. Senne\"},{\"authorId\":\"145364753\",\"name\":\"A. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74b91e3957b55aee2f0b0fd90e25e875a8150390\",\"title\":\"An Analyst's Assistant for the Interpretation of Vehicle Track Data\",\"url\":\"https://www.semanticscholar.org/paper/74b91e3957b55aee2f0b0fd90e25e875a8150390\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eec326ea0a1a1044b011c2b454fe8b7ce1240a30\",\"title\":\"Learning in vision and robotics\",\"url\":\"https://www.semanticscholar.org/paper/eec326ea0a1a1044b011c2b454fe8b7ce1240a30\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1906.02890\",\"authors\":[{\"authorId\":\"8815141\",\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"1700980\",\"name\":\"Kevin Gimpel\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.18653/v1/P19-1180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"708f8c0eb5032edd6f31663a27febbb0529cbcf3\",\"title\":\"Visually Grounded Neural Syntax Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/708f8c0eb5032edd6f31663a27febbb0529cbcf3\",\"venue\":\"ACL\",\"year\":2019}],\"corpusId\":1202699,\"doi\":\"10.1109/CVPR.2014.99\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6c8653e7d237891044fb7b9f886db5b57bbc94cf\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3288381\",\"name\":\"A. Gupta\"},{\"authorId\":\"2169614\",\"name\":\"Yashaswi Verma\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ba87571341beaf6a5c9a30e049be7b1fc9a4c60\",\"title\":\"Choosing Linguistics over Vision to Describe Images\",\"url\":\"https://www.semanticscholar.org/paper/0ba87571341beaf6a5c9a30e049be7b1fc9a4c60\",\"venue\":\"AAAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jie Luo\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a2b5d227f70780c24ca379fadda2644dbc39b94\",\"title\":\"Who's Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation\",\"url\":\"https://www.semanticscholar.org/paper/0a2b5d227f70780c24ca379fadda2644dbc39b94\",\"venue\":\"NIPS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"34898999\",\"name\":\"Genliang Guan\"},{\"authorId\":\"49116471\",\"name\":\"Y. Qiu\"},{\"authorId\":\"145210913\",\"name\":\"L. Zhuo\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1007/s11042-012-1060-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f106ef565a390348a4888b293bef7133b58a693f\",\"title\":\"Semantic context based refinement for news video annotation\",\"url\":\"https://www.semanticscholar.org/paper/f106ef565a390348a4888b293bef7133b58a693f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2012},{\"arxivId\":\"1204.2742\",\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"48540451\",\"name\":\"Alexander Bridge\"},{\"authorId\":\"3190146\",\"name\":\"Zachary Burchill\"},{\"authorId\":\"49081881\",\"name\":\"D. Coroian\"},{\"authorId\":\"1779136\",\"name\":\"S. Dickinson\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"38414598\",\"name\":\"A. Michaux\"},{\"authorId\":\"2587937\",\"name\":\"Sam Mussman\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"2968009\",\"name\":\"D. Salvi\"},{\"authorId\":\"50269497\",\"name\":\"Lara Schmidt\"},{\"authorId\":\"2060623\",\"name\":\"Jiangnan Shangguan\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"},{\"authorId\":\"32655613\",\"name\":\"J. Waggoner\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"},{\"authorId\":\"2223764\",\"name\":\"Jinlian Wei\"},{\"authorId\":\"1813304\",\"name\":\"Yifan Yin\"},{\"authorId\":\"48806246\",\"name\":\"Zhiqi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"793c1c908672ea71aef9e1b41a46272aa27598f7\",\"title\":\"Video In Sentences Out\",\"url\":\"https://www.semanticscholar.org/paper/793c1c908672ea71aef9e1b41a46272aa27598f7\",\"venue\":\"UAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96a0320ef14877038906947b684011cf7378c440\",\"title\":\"Grounded Language Learning from Video Described with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/96a0320ef14877038906947b684011cf7378c440\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2201386\",\"name\":\"C. Tena\"},{\"authorId\":\"2014533\",\"name\":\"Pau Baiget\"},{\"authorId\":\"143987772\",\"name\":\"F. Roca\"},{\"authorId\":\"1763726\",\"name\":\"J. Gonz\\u00e1lez\"}],\"doi\":\"10.1007/978-3-540-74565-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"777f75afaa04a7136ff4cd692eb3fb5bce921028\",\"title\":\"Natural Language Descriptions of Human Behavior from Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/777f75afaa04a7136ff4cd692eb3fb5bce921028\",\"venue\":\"KI\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2193802\",\"name\":\"M. U. Khan\"},{\"authorId\":\"1703592\",\"name\":\"Y. Gotoh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9076183dcdb28ebb3e547f7ffd3f9d5d0faec531\",\"title\":\"Describing Video Contents in Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/9076183dcdb28ebb3e547f7ffd3f9d5d0faec531\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144664658\",\"name\":\"J. Wolf\"},{\"authorId\":\"2803351\",\"name\":\"A. M. Viterbi\"},{\"authorId\":\"72140028\",\"name\":\"G. Dixon\"}],\"doi\":\"10.1109/7.18692\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d701b38d3a92678aea2abee294fde24838857d74\",\"title\":\"Finding the best set of K paths through a trellis with application to multitarget tracking\",\"url\":\"https://www.semanticscholar.org/paper/d701b38d3a92678aea2abee294fde24838857d74\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2003.1238663\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"642e328cae81c5adb30069b680cf60ba6b475153\",\"title\":\"Video Google: a text retrieval approach to object matching in videos\",\"url\":\"https://www.semanticscholar.org/paper/642e328cae81c5adb30069b680cf60ba6b475153\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1204.2741\",\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"38414598\",\"name\":\"A. Michaux\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47f7b1bc0fe49678bd628bf3519d52e22df9664a\",\"title\":\"Simultaneous Object Detection, Tracking, and Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47f7b1bc0fe49678bd628bf3519d52e22df9664a\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72701791\",\"name\":\"K. X. M. Tzeng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"643fe282b794ac665d84aba4054fc33b3fe8b8b6\",\"title\":\"Convolutional Codes and 'Their Performance in Communication Systems\",\"url\":\"https://www.semanticscholar.org/paper/643fe282b794ac665d84aba4054fc33b3fe8b8b6\",\"venue\":\"\",\"year\":1971},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2193560\",\"name\":\"Piji Li\"},{\"authorId\":\"143974412\",\"name\":\"Jun Ma\"}],\"doi\":\"10.1109/ACPR.2011.6166555\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3bc0498e31d1f2fabde1c42500aed406cb50bdc\",\"title\":\"What is happening in a still picture?\",\"url\":\"https://www.semanticscholar.org/paper/e3bc0498e31d1f2fabde1c42500aed406cb50bdc\",\"venue\":\"The First Asian Conference on Pattern Recognition\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49693392\",\"name\":\"A. Kojima\"},{\"authorId\":\"46526487\",\"name\":\"Takeshi Tamura\"},{\"authorId\":\"145950023\",\"name\":\"K. Fukunaga\"}],\"doi\":\"10.1023/A:1020346032608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d53a97a3dd7760b193c0d9a5293b60feff239059\",\"title\":\"Natural Language Description of Human Activities from Video Images Based on Concept Hierarchy of Actions\",\"url\":\"https://www.semanticscholar.org/paper/d53a97a3dd7760b193c0d9a5293b60feff239059\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685089\",\"name\":\"Pedro F. Felzenszwalb\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"}],\"doi\":\"10.1109/CVPR.2010.5539906\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"657a403fa4d37ef13493ec88276ea5c5017cda2f\",\"title\":\"Cascade object detection with deformable part models\",\"url\":\"https://www.semanticscholar.org/paper/657a403fa4d37ef13493ec88276ea5c5017cda2f\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010}],\"title\":\"Seeing What You're Told: Sentence-Guided Activity Recognition in Video\",\"topics\":[{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Lexicon\",\"topicId\":\"33018\",\"url\":\"https://www.semanticscholar.org/topic/33018\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Trash (computing)\",\"topicId\":\"1263837\",\"url\":\"https://www.semanticscholar.org/topic/1263837\"},{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"},{\"topic\":\"Finite-state machine\",\"topicId\":\"4280\",\"url\":\"https://www.semanticscholar.org/topic/4280\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Description\",\"topicId\":\"501\",\"url\":\"https://www.semanticscholar.org/topic/501\"},{\"topic\":\"Numerous\",\"topicId\":\"16861\",\"url\":\"https://www.semanticscholar.org/topic/16861\"},{\"topic\":\"Question (inquiry)\",\"topicId\":\"99949\",\"url\":\"https://www.semanticscholar.org/topic/99949\"}],\"url\":\"https://www.semanticscholar.org/paper/6c8653e7d237891044fb7b9f886db5b57bbc94cf\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014}\n"