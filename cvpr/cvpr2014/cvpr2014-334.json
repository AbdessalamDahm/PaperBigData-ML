"{\"abstract\":\"Existing methods on video-based action recognition are generally view-dependent, i.e., performing recognition from the same views seen in the training data. We present a novel multiview spatio-temporal and-or graph (MST-AOG) representation for cross-view action recognition, i.e., the recognition is performed on the video from an unknown and unseen view. As a compositional model, MST-AOG compactly represents the hierarchical combinatorial structures of cross-view actions by explicitly modeling the geometry, appearance and motion variations. This paper proposes effective methods to learn the structure and parameters of MST-AOG. The inference based on MST-AOG enables action recognition from novel views. The training of MST-AOG takes advantage of the 3D human skeleton data obtained from Kinect cameras to avoid annotating enormous multi-view video frames, which is error-prone and time-consuming, but the recognition does not need 3D information and is based on 2D video input. A new Multiview Action3D dataset has been created and will be released. Extensive experiments have demonstrated that this new action representation significantly improves the accuracy and robustness for cross-view action recognition on 2D videos.\",\"arxivId\":\"1405.2941\",\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\",\"url\":\"https://www.semanticscholar.org/author/40579682\"},{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\",\"url\":\"https://www.semanticscholar.org/author/34792176\"},{\"authorId\":\"49289914\",\"name\":\"Y. Xia\",\"url\":\"https://www.semanticscholar.org/author/49289914\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\",\"url\":\"https://www.semanticscholar.org/author/50118130\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\",\"url\":\"https://www.semanticscholar.org/author/145380991\"}],\"citationVelocity\":49,\"citations\":[{\"arxivId\":\"1409.6813\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/TPAMI.2016.2533389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9198c4ff576343fb489d8f4c4b759e73413d8ee3\",\"title\":\"Histogram of Oriented Principal Components for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9198c4ff576343fb489d8f4c4b759e73413d8ee3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82234635\",\"name\":\"X. Liu\"},{\"authorId\":\"2720195\",\"name\":\"Y. Li\"},{\"authorId\":\"31280147\",\"name\":\"Rongjie Xia\"}],\"doi\":\"10.1007/s11760-020-01644-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d06a1e03e04f61f8c69d9b319292ece7847ae82\",\"title\":\"Rotation-based spatial\\u2013temporal feature learning from skeleton sequences for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d06a1e03e04f61f8c69d9b319292ece7847ae82\",\"venue\":\"Signal Image Video Process.\",\"year\":2020},{\"arxivId\":\"1704.07160\",\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":null,\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TCYB.2017.2756840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cec1d16a4d848fad0e92081294a1fde94a4d9f88\",\"title\":\"Body Joint Guided 3-D Deep Convolutional Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cec1d16a4d848fad0e92081294a1fde94a4d9f88\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49029424\",\"name\":\"K. Krishnan\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/SPCOM.2016.7746614\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9bf56072760c1264956de70c3eb079245fe8ad34\",\"title\":\"ARRNET: Action recognition through recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9bf56072760c1264956de70c3eb079245fe8ad34\",\"venue\":\"2016 International Conference on Signal Processing and Communications (SPCOM)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772962\",\"name\":\"Emre Dogan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc5c9f5528b873bc53a33c33e79352787d60acab\",\"title\":\"Human pose estimation and action recognition by multi-robot systems\",\"url\":\"https://www.semanticscholar.org/paper/dc5c9f5528b873bc53a33c33e79352787d60acab\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"title\":\"View-Invariant Deep Architecture for Human Action Recognition Using Two-Stream Motion and Shape Temporal Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.12447\",\"authors\":[{\"authorId\":\"1492114961\",\"name\":\"Jie Li\"},{\"authorId\":\"48218979\",\"name\":\"B. Li\"},{\"authorId\":\"145327672\",\"name\":\"Min Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86bb83997e7d5809bd937e52d9f2b6997553e576\",\"title\":\"Skeleton-based Approaches based on Machine Vision: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/86bb83997e7d5809bd937e52d9f2b6997553e576\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16208828\",\"name\":\"Wei Liang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d79121a03584123fad02c4f2607f0e63d08ff7c2\",\"title\":\"Tracking Occluded Objects and Recovering Incomplete Trajectories by Reasoning About Containment Relations and Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/d79121a03584123fad02c4f2607f0e63d08ff7c2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"12902632\",\"name\":\"G. Zhang\"},{\"authorId\":\"144131729\",\"name\":\"H. Zhang\"},{\"authorId\":\"153447500\",\"name\":\"Y. Xue\"},{\"authorId\":\"2615851\",\"name\":\"G. Xu\"}],\"doi\":\"10.1016/j.neucom.2016.01.126\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"534159e498e9cc61ea10917347637a59af38142d\",\"title\":\"3D human action recognition model based on image set and regularized multi-task leaning\",\"url\":\"https://www.semanticscholar.org/paper/534159e498e9cc61ea10917347637a59af38142d\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1812.05770\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"47775885\",\"name\":\"Liang Xu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"143864262\",\"name\":\"Manyu Chang\"},{\"authorId\":null,\"name\":\"Junjie Huang\"},{\"authorId\":\"143986385\",\"name\":\"G. Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38d0dd93755b83b2390815fda926866f7ec624ce\",\"title\":\"Action Machine: Rethinking Action Recognition in Trimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/38d0dd93755b83b2390815fda926866f7ec624ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438978\",\"name\":\"Geoffrey Vaquette\"},{\"authorId\":\"19258632\",\"name\":\"A. Orcesi\"},{\"authorId\":\"1885717\",\"name\":\"L. Lucat\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":\"10.1109/FG.2017.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35c3dead77e705132762006e588984ef36ee3604\",\"title\":\"The DAily Home LIfe Activity Dataset: A High Semantic Activity Dataset for Online Recognition\",\"url\":\"https://www.semanticscholar.org/paper/35c3dead77e705132762006e588984ef36ee3604\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"2196194\",\"name\":\"H. Zhang\"},{\"authorId\":\"38187621\",\"name\":\"D. Cao\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1049/iet-cvi.2016.0252\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"854ccabb2e581d862e7941973e5abc41f68ae7ff\",\"title\":\"Meta-action descriptor for action recognition in RGBD video\",\"url\":\"https://www.semanticscholar.org/paper/854ccabb2e581d862e7941973e5abc41f68ae7ff\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"2010.05599\",\"authors\":[{\"authorId\":\"1994058218\",\"name\":\"Lilang Lin\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"48211108\",\"name\":\"J. Liu\"}],\"doi\":\"10.1145/3394171.3413548\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"529b1098b9753d736b2eb47cf4e1726362467215\",\"title\":\"MS2L: Multi-Task Self-Supervised Learning for Skeleton Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/529b1098b9753d736b2eb47cf4e1726362467215\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2031492977\",\"name\":\"Zhihong Liang\"},{\"authorId\":\"2031468916\",\"name\":\"Xiaoshan Shi\"},{\"authorId\":\"144395862\",\"name\":\"Yanxin Zhang\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3035659\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c2e78e8ea1ebf7a226302555f9d06c2e6b7f433\",\"title\":\"A Discriminative Dual-Stream Model With a Novel Sustained Attention Mechanism for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c2e78e8ea1ebf7a226302555f9d06c2e6b7f433\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9521309\",\"name\":\"Reem Alfaifi\"},{\"authorId\":\"46845102\",\"name\":\"A M Artoli\"}],\"doi\":\"10.1007/s42979-020-00293-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"title\":\"Human Action Prediction with 3D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3206025.3206041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"title\":\"Recognizing Actions in Wearable-Camera Videos by Training Classifiers on Fixed-Camera Videos\",\"url\":\"https://www.semanticscholar.org/paper/b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16208828\",\"name\":\"Wei Liang\"},{\"authorId\":\"1757665\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74b4511c18bca69b354e284c8b81531c48bb4d0d\",\"title\":\"What Is Where: Inferring Containment Relations from Videos\",\"url\":\"https://www.semanticscholar.org/paper/74b4511c18bca69b354e284c8b81531c48bb4d0d\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36304959\",\"name\":\"Sebastien Mambou\"},{\"authorId\":\"1755574\",\"name\":\"O. Krejcar\"},{\"authorId\":\"144733650\",\"name\":\"K. Ku\\u010da\"},{\"authorId\":\"1749862\",\"name\":\"A. Selamat\"}],\"doi\":\"10.1007/978-3-319-76081-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"551259850480842147de53448350cdc46368e4cb\",\"title\":\"Novel Human Action Recognition in RGB-D Videos Based on Powerful View Invariant Features Technique\",\"url\":\"https://www.semanticscholar.org/paper/551259850480842147de53448350cdc46368e4cb\",\"venue\":\"ACIIDS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1872087\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"7824818\",\"name\":\"X. Li\"},{\"authorId\":\"2930187\",\"name\":\"Xiangyin Zhang\"}],\"doi\":\"10.1117/1.JEI.27.1.013021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ff85791b84e146c47e5b0e3828d34b47d5edf4c\",\"title\":\"Weighted score-level feature fusion based on Dempster\\u2013Shafer evidence theory for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ff85791b84e146c47e5b0e3828d34b47d5edf4c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19188327\",\"name\":\"Nghia Pham Trong\"},{\"authorId\":\"50852670\",\"name\":\"Anh Truong Minh\"},{\"authorId\":\"29916690\",\"name\":\"H. Nguyen\"},{\"authorId\":\"30973841\",\"name\":\"Kotani Kazunori\"},{\"authorId\":\"31129589\",\"name\":\"Bac Le Hoai\"}],\"doi\":\"10.23919/SICE.2017.8105762\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8ccfcfa30dd12b0164263c7b617d4350c2823c7\",\"title\":\"A survey about view-invariant human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8ccfcfa30dd12b0164263c7b617d4350c2823c7\",\"venue\":\"2017 56th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\",\"year\":2017},{\"arxivId\":\"1804.07453\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/TPAMI.2019.2896631\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a58027f532153b9f9c6ad884d85a175862fc16e6\",\"title\":\"View Adaptive Neural Networks for High Performance Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a58027f532153b9f9c6ad884d85a175862fc16e6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1604.00999\",\"authors\":[{\"authorId\":\"144096365\",\"name\":\"M. Firman\"}],\"doi\":\"10.1109/CVPRW.2016.88\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3dd5b947394e0eb51f15baf2ea8c87f3dcbb3a9\",\"title\":\"RGBD Datasets: Past, Present and Future\",\"url\":\"https://www.semanticscholar.org/paper/d3dd5b947394e0eb51f15baf2ea8c87f3dcbb3a9\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845863027\",\"name\":\"Qiang Nie\"},{\"authorId\":\"49293505\",\"name\":\"Z. Liu\"},{\"authorId\":\"145594296\",\"name\":\"Yunhui Liu\"}],\"doi\":\"10.1007/978-3-030-58529-7_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f7e6750b3bcc60c0a6869b121e35a9fee15b63a\",\"title\":\"Unsupervised 3D Human Pose Representation with Viewpoint and Pose Disentanglement\",\"url\":\"https://www.semanticscholar.org/paper/5f7e6750b3bcc60c0a6869b121e35a9fee15b63a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10618\",\"authors\":[{\"authorId\":\"9121191\",\"name\":\"Mingyu Yin\"},{\"authorId\":\"144622635\",\"name\":\"L. Sun\"},{\"authorId\":\"1409762090\",\"name\":\"Q. Li\"}],\"doi\":\"10.1007/978-3-030-58604-1_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad39a11dfbd3ea4edf3fd20cacd81420a13c0c58\",\"title\":\"Novel View Synthesis on Unpaired Data by Conditional Deformable Variational Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/ad39a11dfbd3ea4edf3fd20cacd81420a13c0c58\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"}],\"doi\":\"10.32657/10356/69072\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"e175109d071cdc8a77f0887f14293a3f9e813563\",\"title\":\"Activity recognition in depth videos\",\"url\":\"https://www.semanticscholar.org/paper/e175109d071cdc8a77f0887f14293a3f9e813563\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151178129\",\"name\":\"Quan Kong\"},{\"authorId\":\"151480716\",\"name\":\"Ziming Wu\"},{\"authorId\":\"90812043\",\"name\":\"Z. Deng\"},{\"authorId\":\"2411436\",\"name\":\"Martin Klinkigt\"},{\"authorId\":\"145910244\",\"name\":\"Bin Tong\"},{\"authorId\":\"2668511\",\"name\":\"T. Murakami\"}],\"doi\":\"10.1109/ICCV.2019.00875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d5fd1c40604ebbda2de58b29fbdaa97745ce7d6\",\"title\":\"MMAct: A Large-Scale Dataset for Cross Modal Human Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6d5fd1c40604ebbda2de58b29fbdaa97745ce7d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145677760\",\"name\":\"H. Fan\"},{\"authorId\":\"16128606\",\"name\":\"Li Meng-jun\"},{\"authorId\":\"52534547\",\"name\":\"Li Jin-jiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4510f65a17dd7e76761205abb1f04bd696373ad7\",\"title\":\"Action Parsing Based on Bag-of-words \\u22c6\",\"url\":\"https://www.semanticscholar.org/paper/4510f65a17dd7e76761205abb1f04bd696373ad7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2002.05907\",\"authors\":[{\"authorId\":\"153108483\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"},{\"authorId\":\"10114692\",\"name\":\"Hong Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"title\":\"A Survey on 3D Skeleton-Based Action Recognition Using Learning Method\",\"url\":\"https://www.semanticscholar.org/paper/0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49458649\",\"name\":\"Jiaqi Dong\"},{\"authorId\":\"145742515\",\"name\":\"Zeyang Xia\"},{\"authorId\":\"2491000\",\"name\":\"W. Yan\"},{\"authorId\":\"1717533\",\"name\":\"Qunfei Zhao\"}],\"doi\":\"10.1016/J.JVCIR.2019.102583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61fe3e70cce878a803c3b309cfd98a2dc8265683\",\"title\":\"Dynamic gesture recognition by directional pulse coupled neural networks for human-robot interaction in real time\",\"url\":\"https://www.semanticscholar.org/paper/61fe3e70cce878a803c3b309cfd98a2dc8265683\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1904.12602\",\"authors\":[{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"145125621\",\"name\":\"B. Sun\"},{\"authorId\":\"4056993\",\"name\":\"J. P. Robinson\"},{\"authorId\":\"113933538\",\"name\":\"Taotao Jing\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f0fb321619915a20b29452f19697dbfa2cf6d2\",\"title\":\"EV-Action: Electromyography-Vision Multi-Modal Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/15f0fb321619915a20b29452f19697dbfa2cf6d2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395630131\",\"name\":\"Teja Kiran Kumar Maddala\"},{\"authorId\":\"144186020\",\"name\":\"P.V.V. Kishore\"},{\"authorId\":\"79324299\",\"name\":\"Kiran Kumar Eepuri\"},{\"authorId\":\"1391281467\",\"name\":\"Anil Kumar Dande\"}],\"doi\":\"10.1109/TMM.2019.2904880\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83ce339720315b653239d40f06e6c5cf375c0527\",\"title\":\"YogaNet: 3-D Yoga Asana Recognition Using Joint Angular Displacement Maps With ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/83ce339720315b653239d40f06e6c5cf375c0527\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"46317361\",\"name\":\"Yibiao Zhao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/TPAMI.2016.2574712\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"475034ca17f22aad2bc075c368d224d46826cf4f\",\"title\":\"Modeling 4D Human-Object Interactions for Joint Event Segmentation, Recognition, and Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/475034ca17f22aad2bc075c368d224d46826cf4f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/ICCV.2019.00092\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c17f395738bc3494974283ba9460c516a948f7ef\",\"title\":\"Toyota Smarthome: Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/c17f395738bc3494974283ba9460c516a948f7ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695223\",\"name\":\"L. Wang\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1007/978-3-319-16199-0_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbaf89ca98dda2c99157c46abd136ace5bdc33b3\",\"title\":\"Nonlinear Cross-View Sample Enrichment for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dbaf89ca98dda2c99157c46abd136ace5bdc33b3\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1814260\",\"name\":\"Enjie Ghorbel\"},{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"152741061\",\"name\":\"Himadri Pathak\"},{\"authorId\":\"2878772\",\"name\":\"Girum G. Demisse\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.5220/0007524405730582\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e205941d8439631f36a0d48ad342984c05c0fb34\",\"title\":\"A View-invariant Framework for Fast Skeleton-based Action Recognition using a Single RGB Camera\",\"url\":\"https://www.semanticscholar.org/paper/e205941d8439631f36a0d48ad342984c05c0fb34\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49538681\",\"name\":\"Z. Gao\"},{\"authorId\":\"48379401\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1682921\",\"name\":\"H. Zhang\"},{\"authorId\":\"144286222\",\"name\":\"G. Xu\"},{\"authorId\":\"143692834\",\"name\":\"Y. Xue\"}],\"doi\":\"10.1007/978-3-319-27671-7_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17fd60158cc3ecf2148c4e5fd2a304365a73d95f\",\"title\":\"Reverse Testing Image Set Model Based Multi-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17fd60158cc3ecf2148c4e5fd2a304365a73d95f\",\"venue\":\"MMM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48386255\",\"name\":\"Yun Han\"},{\"authorId\":\"36479497\",\"name\":\"Sheng-Luen Chung\"}],\"doi\":\"10.1109/SMC.2015.484\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9be785de675ed9a0c90a71794d04ca98af2fbea\",\"title\":\"Activity Recognition Based on Relative Positional Relationship of Human Joints\",\"url\":\"https://www.semanticscholar.org/paper/c9be785de675ed9a0c90a71794d04ca98af2fbea\",\"venue\":\"2015 IEEE International Conference on Systems, Man, and Cybernetics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"40245471\",\"name\":\"Haibo Wang\"},{\"authorId\":\"48513221\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1177/1729881417709079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c8992f255e06081a2e651e370ffe42589143b70\",\"title\":\"Collecting public RGB-D datasets for human daily activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/0c8992f255e06081a2e651e370ffe42589143b70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"1398305251\",\"name\":\"C. Dartigues-Pallez\"},{\"authorId\":\"70023327\",\"name\":\"M. Riveill\"}],\"doi\":\"10.1007/978-3-030-59413-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"986712869037687f9f1eb3ce3e1932c3606d5d5d\",\"title\":\"Supervised Learning for Human Action Recognition from Multiple Kinects\",\"url\":\"https://www.semanticscholar.org/paper/986712869037687f9f1eb3ce3e1932c3606d5d5d\",\"venue\":\"DASFAA\",\"year\":2020},{\"arxivId\":\"1809.01844\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"589bdd7f68dea73564329589344c102b585ef15a\",\"title\":\"Unsupervised Learning of View-invariant Action Representations\",\"url\":\"https://www.semanticscholar.org/paper/589bdd7f68dea73564329589344c102b585ef15a\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720195\",\"name\":\"Y. Li\"},{\"authorId\":\"31280147\",\"name\":\"Rongjie Xia\"},{\"authorId\":\"153201672\",\"name\":\"X. Liu\"},{\"authorId\":\"145298369\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00187\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ee87ffc78d944e25a1cf5f4f68d06b05f0baacb\",\"title\":\"Learning Shape-Motion Representations from Geometric Algebra Spatio-Temporal Model for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ee87ffc78d944e25a1cf5f4f68d06b05f0baacb\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1707.00823\",\"authors\":[{\"authorId\":\"79993273\",\"name\":\"Jian Liu\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/s11263-019-01192-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57ba391f7462d2f6b7957d30682670c7f833009d\",\"title\":\"Learning Human Pose Models from Synthesized Data for Robust RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57ba391f7462d2f6b7957d30682670c7f833009d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cae857e2d133ce92553ed90b0a1c421c88d6649\",\"title\":\"Supplementary Toyota Smarthome : Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/6cae857e2d133ce92553ed90b0a1c421c88d6649\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1145/3132734.3132739\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0be49fc1e0c9a6a50e449015945dd1cf92ccd07e\",\"title\":\"PKU-MMD: A Large Scale Benchmark for Skeleton-Based Human Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0be49fc1e0c9a6a50e449015945dd1cf92ccd07e\",\"venue\":\"VSCC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384028873\",\"name\":\"Guyue Hu\"},{\"authorId\":\"8566649\",\"name\":\"B. Cui\"},{\"authorId\":\"14216506\",\"name\":\"S. Yu\"}],\"doi\":\"10.1109/TMM.2019.2953325\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6c170f86aa90a8229f78a01a43adff7c76e54a4\",\"title\":\"Joint Learning in the Spatio-Temporal and Frequency Domains for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6c170f86aa90a8229f78a01a43adff7c76e54a4\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"Mahmoud Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Yanyan Yang\"},{\"authorId\":\"105033173\",\"name\":\"David Ndzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"title\":\"UWS Academic Portal Deep learning of fuzzy weighted multi-resolution depth motion maps with spatial feature fusion for action recognition Al-Faris,\",\"url\":\"https://www.semanticscholar.org/paper/728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148426228\",\"name\":\"Zhanxiang Feng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"46397019\",\"name\":\"X. Xie\"}],\"doi\":\"10.1109/TIP.2019.2928126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4db7ff14ae6099d6a823a25a876eaca28bf821a\",\"title\":\"Learning Modality-Specific Representations for Visible-Infrared Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/b4db7ff14ae6099d6a823a25a876eaca28bf821a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1872087\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"2930187\",\"name\":\"Xiangyin Zhang\"},{\"authorId\":\"7824818\",\"name\":\"X. Li\"}],\"doi\":\"10.1117/1.JEI.27.5.053049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c19ba3d8d9eb5e4c2304df5cb365d171fdb95dc6\",\"title\":\"Saliency-based foreground trajectory extraction using multiscale hybrid masks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c19ba3d8d9eb5e4c2304df5cb365d171fdb95dc6\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7531875\",\"name\":\"Cuiwei Liu\"},{\"authorId\":\"26991003\",\"name\":\"Yaguang Lu\"},{\"authorId\":\"3085797\",\"name\":\"Xiangbin Shi\"},{\"authorId\":\"2287601\",\"name\":\"D. Zhang\"},{\"authorId\":\"36913287\",\"name\":\"F. Liu\"}],\"doi\":\"10.23940/ijpe.18.01.p11.101110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28256b985a2caa45a070bd2aa9aa001116d585a3\",\"title\":\"A Novel Double-Layer Framework for Joint Segmentation and Recognition of Multiple Actions\",\"url\":\"https://www.semanticscholar.org/paper/28256b985a2caa45a070bd2aa9aa001116d585a3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1897232\",\"name\":\"Q. Nie\"},{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"40066725\",\"name\":\"X. Wang\"},{\"authorId\":\"46398631\",\"name\":\"Yunhui Liu\"}],\"doi\":\"10.1109/TIP.2019.2907048\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fbe869403b2d1b781843df663563c416322a062\",\"title\":\"View-Invariant Human Action Recognition Based on a 3D Bio-Constrained Skeleton Model\",\"url\":\"https://www.semanticscholar.org/paper/4fbe869403b2d1b781843df663563c416322a062\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2416958\",\"name\":\"Guanghui Lu\"},{\"authorId\":\"47655718\",\"name\":\"Bo Liu\"},{\"authorId\":\"1720010\",\"name\":\"Yanshan Xiao\"}],\"doi\":\"10.1109/FSKD.2017.8393129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28d6a96ced82e1d8a7a5dca7b59a5ee8e349e8cd\",\"title\":\"Cross-angle behavior recognition via supervised dictionary learning\",\"url\":\"https://www.semanticscholar.org/paper/28d6a96ced82e1d8a7a5dca7b59a5ee8e349e8cd\",\"venue\":\"2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33347316\",\"name\":\"Tommi Kerola\"},{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1016/j.cviu.2016.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba742e934393efdcca68f81e759f87c6c6f81961\",\"title\":\"Cross-view human action recognition from depth maps using spectral graph sequences\",\"url\":\"https://www.semanticscholar.org/paper/ba742e934393efdcca68f81e759f87c6c6f81961\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623626\",\"name\":\"Chien-Quang Le\"},{\"authorId\":\"3080041\",\"name\":\"T. Ngo\"},{\"authorId\":\"1802416\",\"name\":\"D. Le\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"2258974\",\"name\":\"D. Duong\"}],\"doi\":\"10.1109/MMSP.2015.7340879\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43ead1774af711e3b3f36054f6cff6e60577f9aa\",\"title\":\"Human Action recognition from depth videos using multi-projection based representation\",\"url\":\"https://www.semanticscholar.org/paper/43ead1774af711e3b3f36054f6cff6e60577f9aa\",\"venue\":\"2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patrec.2018.07.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"403f756f9f18948994e7a650ccb0be359d695530\",\"title\":\"Joint spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/403f756f9f18948994e7a650ccb0be359d695530\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Liu\"},{\"authorId\":\"46951056\",\"name\":\"Zhaoyang Lu\"},{\"authorId\":null,\"name\":\"Jing Li\"},{\"authorId\":\"115063987\",\"name\":\"T. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45e135167a763f3dd49cfd90b088699378e56790\",\"title\":\"a bipartite-graph-based method to bridge the domain shift across view-dependent vocabularies\",\"url\":\"https://www.semanticscholar.org/paper/45e135167a763f3dd49cfd90b088699378e56790\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/WACV45572.2020.9093575\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8cdc241f90d578a1dd79db11081f291211986ac9\",\"title\":\"Looking deeper into Time for Activities of Daily Living Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc241f90d578a1dd79db11081f291211986ac9\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31573550\",\"name\":\"Alejandro Hernandez Ruiz\"},{\"authorId\":\"3202308\",\"name\":\"L. Porzi\"},{\"authorId\":\"2145174\",\"name\":\"S. R. Bul\\u00f2\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"}],\"doi\":\"10.1145/3123266.3123299\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c066754b84fb15f7ea09abdcd7279bb88c36e01d\",\"title\":\"3D CNNs on Distance Matrices for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c066754b84fb15f7ea09abdcd7279bb88c36e01d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36304959\",\"name\":\"Sebastien Mambou\"},{\"authorId\":\"1755574\",\"name\":\"O. Krejcar\"},{\"authorId\":\"144733650\",\"name\":\"K. Ku\\u010da\"},{\"authorId\":\"1749862\",\"name\":\"A. Selamat\"}],\"doi\":\"10.3390/fi10090089\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9c34f28fa85f68e31c3d3fe9c58e80876700af1\",\"title\":\"Novel Cross-View Human Action Model Recognition Based on the Powerful View-Invariant Features Technique\",\"url\":\"https://www.semanticscholar.org/paper/c9c34f28fa85f68e31c3d3fe9c58e80876700af1\",\"venue\":\"Future Internet\",\"year\":2018},{\"arxivId\":\"1904.06074\",\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Y. Yang\"},{\"authorId\":\"49152746\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.1007/s10044-020-00886-5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c36c598afc9217b8e6f4da7601a9695bf2000fd\",\"title\":\"Multi-view region-adaptive multi-temporal DMM and RGB action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c36c598afc9217b8e6f4da7601a9695bf2000fd\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414148\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2836323\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ecc2e1284f1cb19cafe723b25be3705f26609679\",\"title\":\"Action Recognition From Arbitrary Views Using Transferable Dictionary Learning\",\"url\":\"https://www.semanticscholar.org/paper/ecc2e1284f1cb19cafe723b25be3705f26609679\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f66086e4cbb22c5736c836614830489f9594b91\",\"title\":\"Action Recognition with Joints-Pooled 3D Deep Convolutional Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2f66086e4cbb22c5736c836614830489f9594b91\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1810.08437\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/TPAMI.2019.2929038\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67d0a881e0c580acc7770c212396171cc64aa76c\",\"title\":\"Learning with Privileged Information via Adversarial Discriminative Modality Distillation\",\"url\":\"https://www.semanticscholar.org/paper/67d0a881e0c580acc7770c212396171cc64aa76c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1909.03466\",\"authors\":[{\"authorId\":\"14370059\",\"name\":\"M. U. Khalid\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/ICPR.2018.8546131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59478365451b82f5227bc4b694a2ff319025cc33\",\"title\":\"Multi-Modal Three-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/59478365451b82f5227bc4b694a2ff319025cc33\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"49308434\",\"name\":\"Y. Yang\"},{\"authorId\":\"2092709\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.3390/jimaging5100082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"title\":\"Deep Learning of Fuzzy Weighted Multi-Resolution Depth Motion Maps with Spatial Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"venue\":\"J. Imaging\",\"year\":2019},{\"arxivId\":\"2010.14982\",\"authors\":[{\"authorId\":\"1478813684\",\"name\":\"Rui Dai\"},{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a99a0f24b71f8048f4d30a4ca27dafca3fa7ac24\",\"title\":\"Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/a99a0f24b71f8048f4d30a4ca27dafca3fa7ac24\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47282782\",\"name\":\"D. Miki\"},{\"authorId\":\"98498116\",\"name\":\"S. Chen\"},{\"authorId\":\"2357866\",\"name\":\"K. Demachi\"}],\"doi\":\"10.1109/WACV45572.2020.9093551\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5625a113457bfba7a1ad242a808277cda9c160e0\",\"title\":\"Weakly Supervised Graph Convolutional Neural Network for Human Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/5625a113457bfba7a1ad242a808277cda9c160e0\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.373\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3ad5304072264ef0419b810d6ed0c69a109d5a5\",\"title\":\"Monocular 3D Human Pose Estimation by Predicting Depth on Joints\",\"url\":\"https://www.semanticscholar.org/paper/b3ad5304072264ef0419b810d6ed0c69a109d5a5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"1814260\",\"name\":\"Enjie Ghorbel\"},{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"2878772\",\"name\":\"Girum G. Demisse\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.1109/ICASSP.2019.8682904\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c37f1d439fcf4a22c20b384a31d7b754961df8b\",\"title\":\"View-invariant Action Recognition from RGB Data via 3D Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/5c37f1d439fcf4a22c20b384a31d7b754961df8b\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"37069895\",\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/CVPR.2018.00020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b908d99fbf779b85c35a2255abf76b52966070c\",\"title\":\"Multistage Adversarial Losses for Pose-Based Human Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/5b908d99fbf779b85c35a2255abf76b52966070c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40072752\",\"name\":\"Wenjun Wu\"},{\"authorId\":\"7607552\",\"name\":\"Y. Yang\"},{\"authorId\":\"2059283\",\"name\":\"Ruishan Liu\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1145/2808492.2808535\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01f3d1379049d2b1c5142dcc7ae2a7c8b79daa29\",\"title\":\"Joint-based multi-task sparse learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01f3d1379049d2b1c5142dcc7ae2a7c8b79daa29\",\"venue\":\"ICIMCS '15\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"9355577\",\"name\":\"Shangqian Gao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"}],\"doi\":\"10.1109/TMM.2016.2626959\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"202f562509cfa2cd54296662a2bba7be43f0e500\",\"title\":\"Discriminative Multi-instance Multitask Learning for 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/202f562509cfa2cd54296662a2bba7be43f0e500\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1912.10982\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"16040476\",\"name\":\"S. A. Bargal\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"846fca8fa98753223f464b187cb59b02a8a1ccae\",\"title\":\"DMCL: Distillation Multiple Choice Learning for Multimodal Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/846fca8fa98753223f464b187cb59b02a8a1ccae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"title\":\"LSTM with Hand-crafted View-Invariant and Differential Cues (HVDC) for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aneesh Euprazia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e383572d361e2a18788099ef0bf09ea6a910b6b\",\"title\":\"International Journal of Innovative Technology and Exploring Engineering (IJITEE)\",\"url\":\"https://www.semanticscholar.org/paper/7e383572d361e2a18788099ef0bf09ea6a910b6b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2017.2696786\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fef87e55a090fe0f1ec5cdaf24c8a37e8174dfb7\",\"title\":\"Deeply Learned View-Invariant Features for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fef87e55a090fe0f1ec5cdaf24c8a37e8174dfb7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607552\",\"name\":\"Y. Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"},{\"authorId\":\"1753384\",\"name\":\"S. Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"}],\"doi\":\"10.1109/TCYB.2016.2519448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b160dbfa97fcb84344c3da7ff47091669da910\",\"title\":\"Latent Max-Margin Multitask Learning With Skelets for 3-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/70b160dbfa97fcb84344c3da7ff47091669da910\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398956065\",\"name\":\"T. D'Orazio\"},{\"authorId\":\"40374274\",\"name\":\"R. Marani\"},{\"authorId\":\"2946935\",\"name\":\"V. Ren\\u00f3\"},{\"authorId\":\"2938192\",\"name\":\"G. Cicirelli\"}],\"doi\":\"10.1016/j.imavis.2016.05.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7988614d38e528403f2b1062cbe5b78fee4c3de\",\"title\":\"Recent trends in gesture recognition: how depth data has improved classical approaches\",\"url\":\"https://www.semanticscholar.org/paper/f7988614d38e528403f2b1062cbe5b78fee4c3de\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":\"1912.03632\",\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41d621492203f42a52317163b4091670a360324b\",\"title\":\"View-invariant Deep Architecture for Human Action Recognition using late fusion\",\"url\":\"https://www.semanticscholar.org/paper/41d621492203f42a52317163b4091670a360324b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623626\",\"name\":\"Chien-Quang Le\"},{\"authorId\":\"3080041\",\"name\":\"Thanh Duc Ngo\"},{\"authorId\":\"1802416\",\"name\":\"D. Le\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"2258974\",\"name\":\"D. Duong\"}],\"doi\":\"10.1007/978-3-319-29451-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f98c169dc78a2ea36fe817704232da72cd44a919\",\"title\":\"Cross-View Action Recognition by Projection-Based Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/f98c169dc78a2ea36fe817704232da72cd44a919\",\"venue\":\"PSIVT\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/3343031.3350959\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"478243c224e641951fe12b8ddf7aa3a97f93c0e9\",\"title\":\"Attention Transfer (ANT) Network for View-invariant Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/478243c224e641951fe12b8ddf7aa3a97f93c0e9\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631862\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/s11042-019-7700-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad6493b57050955d9686b3c1fc84a19195852f8c\",\"title\":\"Computer vision based working environment monitoring to analyze Generalized Anxiety Disorder (GAD)\",\"url\":\"https://www.semanticscholar.org/paper/ad6493b57050955d9686b3c1fc84a19195852f8c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"48093650\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"}],\"doi\":\"10.1145/3365212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f6ca119c719cd9f9362a160fb15af2b895095f\",\"title\":\"A Benchmark Dataset and Comparison Study for Multi-modal Human Action Analytics\",\"url\":\"https://www.semanticscholar.org/paper/76f6ca119c719cd9f9362a160fb15af2b895095f\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"2492513\",\"name\":\"Jinyu Gao\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"}],\"doi\":\"10.1109/TCSVT.2014.2382984\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f9ebe5baa6d02fb80f7a12b091a595a02d83e71\",\"title\":\"Cross-View Action Recognition Based on a Statistical Translation Framework\",\"url\":\"https://www.semanticscholar.org/paper/7f9ebe5baa6d02fb80f7a12b091a595a02d83e71\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47424035\",\"name\":\"Chengkun Zhang\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/ACCESS.2018.2815611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"301d70a4b38071c222ea8b095c42a09494fc9d88\",\"title\":\"Cross-View Action Recognition Based on Hierarchical View-Shared Dictionary Learning\",\"url\":\"https://www.semanticscholar.org/paper/301d70a4b38071c222ea8b095c42a09494fc9d88\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153825264\",\"name\":\"Tao Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e38114f470f09fadeac4e9e403fb3b1a9e9e940\",\"title\":\"A Cognition Platform for Joint Inference of 3D Geometry, Object States, and Human Belief\",\"url\":\"https://www.semanticscholar.org/paper/4e38114f470f09fadeac4e9e403fb3b1a9e9e940\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145042308\",\"name\":\"U. Iqbal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ea3421243d8edb4fbe8b4962c1566d8b9ce42e1\",\"title\":\"Articulated Human Pose Estimation in Unconstrained Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/6ea3421243d8edb4fbe8b4962c1566d8b9ce42e1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49538681\",\"name\":\"Z. Gao\"},{\"authorId\":\"47319814\",\"name\":\"S. Li\"},{\"authorId\":\"145040307\",\"name\":\"Y. Zhu\"},{\"authorId\":\"39631916\",\"name\":\"C. Wang\"},{\"authorId\":\"1682921\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/j.jvcir.2017.03.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3478bde28fdc1b208c513ba6bd2fe42a18432c29\",\"title\":\"Collaborative sparse representation leaning model for RGBD action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3478bde28fdc1b208c513ba6bd2fe42a18432c29\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"1909.01939\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/TIP.2019.2937724\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d0b8606483d6d9c1cdb5b8953bf61773bf633db\",\"title\":\"EleAtt-RNN: Adding Attentiveness to Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d0b8606483d6d9c1cdb5b8953bf61773bf633db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9122942\",\"name\":\"Fangqiang Hu\"},{\"authorId\":\"16040763\",\"name\":\"Qianyu Wu\"},{\"authorId\":\"50202676\",\"name\":\"Sai Zhang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"3379173\",\"name\":\"Y. Bao\"}],\"doi\":\"10.1117/1.JEI.28.4.043018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5c7651d3482d3dfe5fa852ab6dfb7aa95309031\",\"title\":\"Pose-based multisource networks using convolutional neural network and long short-term memory for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a5c7651d3482d3dfe5fa852ab6dfb7aa95309031\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1709.05087\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"3003408\",\"name\":\"Mian M. Ajmal\"}],\"doi\":\"10.1109/ACCESS.2018.2880231\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"title\":\"Viewpoint Invariant Action Recognition Using RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40494138\",\"name\":\"H. Neher\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b68d5c017722c72647b8f0dede25d283a080900\",\"title\":\"Hockey Pose Estimation and Action Recognition using Convolutional Neural Networks to Ice Hockey\",\"url\":\"https://www.semanticscholar.org/paper/7b68d5c017722c72647b8f0dede25d283a080900\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80558539\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"2059283\",\"name\":\"Ruishan Liu\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"}],\"doi\":\"10.1016/j.sigpro.2015.10.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26916e0a03d920be83ad77a3c26bcfe3c0b6c244\",\"title\":\"Multi-task human action recognition via exploring super-category\",\"url\":\"https://www.semanticscholar.org/paper/26916e0a03d920be83ad77a3c26bcfe3c0b6c244\",\"venue\":\"Signal Process.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1806.11269\",\"authors\":[{\"authorId\":\"144209663\",\"name\":\"Y. Xiao\"},{\"authorId\":\"98894244\",\"name\":\"Jun Chen\"},{\"authorId\":\"144762660\",\"name\":\"Zhiguo Cao\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.ins.2018.12.050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4508789311f47bf6f6bb348d001b9ab370b71de\",\"title\":\"Action Recognition for Depth Video using Multi-view Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/e4508789311f47bf6f6bb348d001b9ab370b71de\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49538681\",\"name\":\"Z. Gao\"},{\"authorId\":\"47319814\",\"name\":\"S. Li\"},{\"authorId\":\"41171114\",\"name\":\"G. T. Zhang\"},{\"authorId\":\"145040307\",\"name\":\"Y. Zhu\"},{\"authorId\":\"39631916\",\"name\":\"C. Wang\"},{\"authorId\":\"1682921\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1007/s11042-017-4384-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31fd16f8669e3dd11a6b3ff02473ecb8991a49b1\",\"title\":\"Evaluation of regularized multi-task leaning algorithms for single/multi-view human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/31fd16f8669e3dd11a6b3ff02473ecb8991a49b1\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720195\",\"name\":\"Y. Li\"},{\"authorId\":\"31280147\",\"name\":\"Rongjie Xia\"},{\"authorId\":\"82234635\",\"name\":\"X. Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa712a0fbaf53e518509876afbcc9049807a7c1a\",\"title\":\"Learning shape and motion representations for view invariant skeleton-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa712a0fbaf53e518509876afbcc9049807a7c1a\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144755330\",\"name\":\"Brian Reily\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ee4a540b3a2bbfe263573852d2a5f6231002145\",\"title\":\"Human activity recognition and gymnastics analysis through depth imagery\",\"url\":\"https://www.semanticscholar.org/paper/4ee4a540b3a2bbfe263573852d2a5f6231002145\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33961149\",\"name\":\"Georgios Th. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"Petros Daras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6782f6646d407055dc2661aa6661306946734f84\",\"title\":\"Human Action Recognition Using 3 D Reconstruction Data\",\"url\":\"https://www.semanticscholar.org/paper/6782f6646d407055dc2661aa6661306946734f84\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"97474510\",\"name\":\"L. Xu\"},{\"authorId\":\"153940079\",\"name\":\"Guan Huang\"}],\"doi\":\"10.1109/LSP.2019.2942739\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"title\":\"Action Machine: Toward Person-Centric Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16077215\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"48570960\",\"name\":\"Lining Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2836323\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ef9280d59388c359abb1127297db2b255cceadf\",\"title\":\"Arbitrary view action recognition via transfer dictionary learning on synthetic training data\",\"url\":\"https://www.semanticscholar.org/paper/6ef9280d59388c359abb1127297db2b255cceadf\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":\"2003.07564\",\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":\"48986077\",\"name\":\"D. Yan\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"133839875\",\"name\":\"D. Li\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24ea00bd9e737c7dd0d66f1e2706ad97841eb9c8\",\"title\":\"Feedback Graph Convolutional Network for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24ea00bd9e737c7dd0d66f1e2706ad97841eb9c8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153328465\",\"name\":\"M. A. R. Ahad\"},{\"authorId\":\"51932099\",\"name\":\"Anindya Das Antar\"},{\"authorId\":\"97753168\",\"name\":\"Omar Shahid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f57bd24c962f9a06d5d3dfdd013e34cfa1d05307\",\"title\":\"Vision-based Action Understanding for Assistive Healthcare: A Short Review\",\"url\":\"https://www.semanticscholar.org/paper/f57bd24c962f9a06d5d3dfdd013e34cfa1d05307\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"39271955\",\"name\":\"Zhiwen Fang\"}],\"doi\":\"10.1117/12.2285518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"title\":\"Action recognition in depth video from RGB perspective: A knowledge transfer manner\",\"url\":\"https://www.semanticscholar.org/paper/e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3358065\",\"name\":\"Xikun Zhang\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1007/978-3-030-58589-1_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ffdf00fe678d6b0785dbf49db8bc980f61be058\",\"title\":\"On Dropping Clusters to Regularize Graph Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4ffdf00fe678d6b0785dbf49db8bc980f61be058\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978834728\",\"name\":\"Mejdi Dallel\"},{\"authorId\":\"49663796\",\"name\":\"Vincent Havard\"},{\"authorId\":\"1382268375\",\"name\":\"David Baudry\"},{\"authorId\":\"2094302\",\"name\":\"X. Savatier\"}],\"doi\":\"10.1109/ICHMS49158.2020.9209531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5ad762854d05fa4347a50e31620e8da15926e03\",\"title\":\"InHARD - Industrial Human Action Recognition Dataset in the Context of Industrial Collaborative Robotics\",\"url\":\"https://www.semanticscholar.org/paper/d5ad762854d05fa4347a50e31620e8da15926e03\",\"venue\":\"2020 IEEE International Conference on Human-Machine Systems (ICHMS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"2646598\",\"name\":\"F. Hu\"},{\"authorId\":\"84175736\",\"name\":\"Qianyu Wu\"},{\"authorId\":\"50025538\",\"name\":\"Y. Li\"}],\"doi\":\"10.1117/1.JEI.29.4.043025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd4ae0706b11408070ef88390215b9237f58a0fe\",\"title\":\"Two-stream spatial-temporal neural networks for pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd4ae0706b11408070ef88390215b9237f58a0fe\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144985898\",\"name\":\"B. Su\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"145507765\",\"name\":\"X. Ding\"},{\"authorId\":\"47095827\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TIP.2017.2745212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab0981d1da654f37620ca39c6b42de21d7eb58eb\",\"title\":\"Unsupervised Hierarchical Dynamic Parsing and Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab0981d1da654f37620ca39c6b42de21d7eb58eb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"2006.06911\",\"authors\":[{\"authorId\":\"1492114642\",\"name\":\"Jingyuan Li\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf31f1b70e9714a5eb64a40be84daaf9fcf6f0ad\",\"title\":\"Iterate & Cluster: Iterative Semi-Supervised Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bf31f1b70e9714a5eb64a40be84daaf9fcf6f0ad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.11333\",\"authors\":[{\"authorId\":\"148426228\",\"name\":\"Zhanxiang Feng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"46397019\",\"name\":\"X. Xie\"}],\"doi\":\"10.1109/TIP.2018.2818438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15b7247b23442d5eadb21ec86a6e371e39aac973\",\"title\":\"Learning View-Specific Deep Networks for Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/15b7247b23442d5eadb21ec86a6e371e39aac973\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/JSEN.2019.2903645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"title\":\"A Robust Framework for Abnormal Human Action Recognition Using $\\\\boldsymbol{\\\\mathcal{R}}$ -Transform and Zernike Moments in Depth Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"venue\":\"IEEE Sensors Journal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998966851\",\"name\":\"Ke Cheng\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"145770647\",\"name\":\"Lei Shi\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1694235\",\"name\":\"Hanqing Lu\"}],\"doi\":\"10.1007/978-3-030-58586-0_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8ee043f14f7de72128f14bb391b24e18fbf25f3\",\"title\":\"Decoupling GCN with DropGraph Module for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8ee043f14f7de72128f14bb391b24e18fbf25f3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49538681\",\"name\":\"Z. Gao\"},{\"authorId\":\"48379401\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1682921\",\"name\":\"H. Zhang\"},{\"authorId\":\"143692834\",\"name\":\"Y. Xue\"},{\"authorId\":\"144286222\",\"name\":\"G. Xu\"}],\"doi\":\"10.1016/j.neucom.2016.01.113\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba92d17b47ecd65af0655a0ca452d52ff9d0a863\",\"title\":\"Multi-dimensional human action recognition model based on image set and group sparisty\",\"url\":\"https://www.semanticscholar.org/paper/ba92d17b47ecd65af0655a0ca452d52ff9d0a863\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38796462\",\"name\":\"Imen Jegham\"},{\"authorId\":\"31259963\",\"name\":\"Anouar Ben Khalifa\"},{\"authorId\":\"2880991\",\"name\":\"Ihsen Alouani\"},{\"authorId\":\"1707715\",\"name\":\"M. Mahjoub\"}],\"doi\":\"10.1016/j.fsidi.2019.200901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b3316944b07e1fb77c9edfa0b716a0ea9e2052\",\"title\":\"Vision-based human action recognition: An overview and real world challenges\",\"url\":\"https://www.semanticscholar.org/paper/46b3316944b07e1fb77c9edfa0b716a0ea9e2052\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2016.167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"title\":\"3D Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1807.04445\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-01240-3_9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"04791b727d0b0820d110288546fa5d3fb5528a63\",\"title\":\"Adding Attentiveness to the Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/04791b727d0b0820d110288546fa5d3fb5528a63\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2015.7298734\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb4291452a25ff2f84f5af6de36b04c1d4d81b12\",\"title\":\"Joint action recognition and pose estimation from video\",\"url\":\"https://www.semanticscholar.org/paper/bb4291452a25ff2f84f5af6de36b04c1d4d81b12\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438978\",\"name\":\"Geoffrey Vaquette\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"},{\"authorId\":\"1885717\",\"name\":\"L. Lucat\"}],\"doi\":\"10.5220/0005725604230430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9eaf58c580a445cd438331520ab09ab00acd86b2\",\"title\":\"Information Fusion for Action Recognition with Deeply Optimised Hough Transform Paradigm\",\"url\":\"https://www.semanticscholar.org/paper/9eaf58c580a445cd438331520ab09ab00acd86b2\",\"venue\":\"VISIGRAPP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2603501\",\"name\":\"Wanchen Sui\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1016/j.neucom.2016.01.051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"378912704f9c73c103fcfb49d8ab75189afa5b13\",\"title\":\"Heterogeneous discriminant analysis for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/378912704f9c73c103fcfb49d8ab75189afa5b13\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3085797\",\"name\":\"Xiangbin Shi\"},{\"authorId\":\"26991003\",\"name\":\"Yaguang Lu\"},{\"authorId\":\"7531875\",\"name\":\"Cuiwei Liu\"},{\"authorId\":\"143714402\",\"name\":\"Deyuan Zhang\"},{\"authorId\":\"144000906\",\"name\":\"Fang Liu\"}],\"doi\":\"10.1109/ICVRV.2017.00017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59b0e691abd307e5844791d15aeb34189ec121a0\",\"title\":\"A Novel Unsupervised Method for Temporal Segmentation of Videos\",\"url\":\"https://www.semanticscholar.org/paper/59b0e691abd307e5844791d15aeb34189ec121a0\",\"venue\":\"2017 International Conference on Virtual Reality and Visualization (ICVRV)\",\"year\":2017},{\"arxivId\":\"1604.02808\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.115\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"title\":\"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.patcog.2018.03.030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9824ed569997a405c71ae7907f8da97c540cf92a\",\"title\":\"Learning content and style: Joint action recognition and person identification from human skeletons\",\"url\":\"https://www.semanticscholar.org/paper/9824ed569997a405c71ae7907f8da97c540cf92a\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1904.01189\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/CVPR42600.2020.00119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f057477421de2d6464690d66c61c8b3e649605a\",\"title\":\"Semantics-Guided Neural Networks for Efficient Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3f057477421de2d6464690d66c61c8b3e649605a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1103/PHYSREVD.94.065007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"edbdb4de4367d245cb5f78d77de68464f9bdcde1\",\"title\":\"Learning a Deep Model for Human Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/edbdb4de4367d245cb5f78d77de68464f9bdcde1\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6759\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e648faa3fb229b52fb97bfc9016d3419fae45de\",\"title\":\"Part-Level Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0e648faa3fb229b52fb97bfc9016d3419fae45de\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1701.03869\",\"authors\":[{\"authorId\":\"50759119\",\"name\":\"Wenwen Ding\"},{\"authorId\":\"49599759\",\"name\":\"Kai Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4cdeea6d1b61d7f9a663840bb35e743f87a50bf\",\"title\":\"Learning Linear Dynamical Systems with High-Order Tensor Data for Skeleton based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4cdeea6d1b61d7f9a663840bb35e743f87a50bf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718226\",\"name\":\"C. Li\"},{\"authorId\":\"3128157\",\"name\":\"Ruofeng Tong\"},{\"authorId\":\"50627816\",\"name\":\"Min Tang\"}],\"doi\":\"10.1007/S13369-018-3189-Z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0b7c8345d065f7326f3835fe022e43d020ce050\",\"title\":\"Modelling Human Body Pose for Action Recognition Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0b7c8345d065f7326f3835fe022e43d020ce050\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1601.05511\",\"authors\":[{\"authorId\":\"47539715\",\"name\":\"Jing Zhang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"}],\"doi\":\"10.1016/j.patcog.2016.05.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a52a2d27a0d6f7f5508941998344df692216f4d\",\"title\":\"RGB-D-based action recognition datasets: A survey\",\"url\":\"https://www.semanticscholar.org/paper/6a52a2d27a0d6f7f5508941998344df692216f4d\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8824176\",\"name\":\"Y. Li\"},{\"authorId\":\"47158096\",\"name\":\"X. Xu\"},{\"authorId\":\"46372471\",\"name\":\"J. Xu\"},{\"authorId\":\"146596908\",\"name\":\"Enyu Du\"}],\"doi\":\"10.1117/1.JEI.28.3.033016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"195e9abc3ffa45d7424dfa660968d81b11e3f1f8\",\"title\":\"Bilayer model for cross-view human action recognition based on transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/195e9abc3ffa45d7424dfa660968d81b11e3f1f8\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2656603\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/DICTA.2017.8227505\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"title\":\"Viewpoint Invariant RGB-D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"2007.15244\",\"authors\":[{\"authorId\":\"1841089935\",\"name\":\"Mahdi Davoodikakhki\"},{\"authorId\":\"153505292\",\"name\":\"KangKang Yin\"}],\"doi\":\"10.1007/978-3-030-64556-4_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0359520036f33beea638b979d515c170420ac37b\",\"title\":\"Hierarchical Action Classification with Network Pruning\",\"url\":\"https://www.semanticscholar.org/paper/0359520036f33beea638b979d515c170420ac37b\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"66350669\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"11619361\",\"name\":\"Liuyun Wang\"}],\"doi\":\"10.1007/978-3-030-34120-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a31eda86039b62acee64423208bf313b9081cd02\",\"title\":\"Hierarchical Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a31eda86039b62acee64423208bf313b9081cd02\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"2007.03056\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1007/978-3-030-58545-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"title\":\"VPN: Learning Video-Pose Embedding for Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49326834\",\"name\":\"Q. Zuo\"},{\"authorId\":\"11857395\",\"name\":\"Lian Zou\"},{\"authorId\":\"73313375\",\"name\":\"Cien Fan\"},{\"authorId\":\"1657188730\",\"name\":\"Dongqian Li\"},{\"authorId\":\"143891653\",\"name\":\"Hao Jiang\"},{\"authorId\":\"47909275\",\"name\":\"Yifeng Liu\"}],\"doi\":\"10.3390/s20247149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c29f728df66434210f115cba745d6ec63a772e3\",\"title\":\"Whole and Part Adaptive Fusion Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c29f728df66434210f115cba745d6ec63a772e3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2018.2865885\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b11ac2a99acdab0060309d15f78a6fb86008505\",\"title\":\"Dual Low-Rank Decompositions for Robust Cross-View Learning\",\"url\":\"https://www.semanticscholar.org/paper/4b11ac2a99acdab0060309d15f78a6fb86008505\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN.2017.7966210\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"title\":\"Recent advances in video-based human action recognition using deep learning: A review\",\"url\":\"https://www.semanticscholar.org/paper/c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"47052503\",\"name\":\"W. Zou\"},{\"authorId\":null,\"name\":\"Liang Xu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"46637801\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"41170509\",\"name\":\"Manyu Chang\"},{\"authorId\":\"47513708\",\"name\":\"Junjie Huang\"},{\"authorId\":\"143986381\",\"name\":\"Guan Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cd457efa63de3e9810f08cc5f0b57442c670c04\",\"title\":\"Typing Video frames after person detection Pose Tube 2 D Deconv Score fusion RGB action recognition Pose action recognition Pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/3cd457efa63de3e9810f08cc5f0b57442c670c04\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623626\",\"name\":\"Chien-Quang Le\"},{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"3080041\",\"name\":\"Thanh Duc Ngo\"},{\"authorId\":\"1802416\",\"name\":\"D. Le\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"2258974\",\"name\":\"D. Duong\"}],\"doi\":\"10.1587/TRANSINF.2015EDP7430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a5c8d136f2c9e2684884d82cce5cb18b0de0e40\",\"title\":\"Human Action Recognition from Depth Videos Using Pool of Multiple Projections with Greedy Selection\",\"url\":\"https://www.semanticscholar.org/paper/9a5c8d136f2c9e2684884d82cce5cb18b0de0e40\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2016},{\"arxivId\":\"1703.09783\",\"authors\":[{\"authorId\":\"8122333\",\"name\":\"R. Zhao\"},{\"authorId\":\"50340227\",\"name\":\"H. Ali\"},{\"authorId\":\"145403330\",\"name\":\"Patrick van der Smagt\"}],\"doi\":\"10.1109/IROS.2017.8206288\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba76761f551a044d3d1bebefc5cb3faccf77b27\",\"title\":\"Two-stream RNN/CNN for action recognition in 3D videos\",\"url\":\"https://www.semanticscholar.org/paper/1ba76761f551a044d3d1bebefc5cb3faccf77b27\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1602.00828\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2017.2691768\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e777c6a5f57e51d77b78d8eb04184a71951bd8e8\",\"title\":\"Learning a Deep Model for Human Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/e777c6a5f57e51d77b78d8eb04184a71951bd8e8\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438978\",\"name\":\"Geoffrey Vaquette\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"},{\"authorId\":\"1885717\",\"name\":\"L. Lucat\"}],\"doi\":\"10.1007/s11554-016-0660-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f738ff26fdc2bce00862c8256641ba1b945281a3\",\"title\":\"Robust information fusion in the DOHT paradigm for real-time action detection\",\"url\":\"https://www.semanticscholar.org/paper/f738ff26fdc2bce00862c8256641ba1b945281a3\",\"venue\":\"Journal of Real-Time Image Processing\",\"year\":2016},{\"arxivId\":\"1711.05941\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b11d14c5812e5f41348beebceaca84b46cc55346\",\"title\":\"Skepxels: Spatio-temporal Image Representation of Human Skeleton Joints for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b11d14c5812e5f41348beebceaca84b46cc55346\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1709.05436\",\"authors\":[{\"authorId\":\"47935745\",\"name\":\"Hang Qi\"},{\"authorId\":\"2762640\",\"name\":\"Yuanlu Xu\"},{\"authorId\":\"48580157\",\"name\":\"Tao Yuan\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"145380991\",\"name\":\"Song-Chun Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e7ac344b17d97267ec80681aeded17e3e6d786\",\"title\":\"Joint Parsing of Cross-view Scenes with Spatio-temporal Semantic Parse Graphs\",\"url\":\"https://www.semanticscholar.org/paper/39e7ac344b17d97267ec80681aeded17e3e6d786\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31573550\",\"name\":\"Alejandro Hernandez Ruiz\"},{\"authorId\":\"3202308\",\"name\":\"Lorenzo Porzi\"},{\"authorId\":\"2145174\",\"name\":\"Samuel Rota Bul\\u00f2\"},{\"authorId\":\"1397181875\",\"name\":\"Francesc Moreno-Noguer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f2a89f22981e332bc4a47a3ba74f0d202aec64e\",\"title\":\"CNNs on Distance Matrices for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f2a89f22981e332bc4a47a3ba74f0d202aec64e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1703.07475\",\"authors\":[{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b673ffe63c5d0723009042f0f922f19f093b7e34\",\"title\":\"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b673ffe63c5d0723009042f0f922f19f093b7e34\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1145/3240508.3240675\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f888a870545af2735118bbd6358ffa68f1e386f\",\"title\":\"A Large-scale RGB-D Database for Arbitrary-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f888a870545af2735118bbd6358ffa68f1e386f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1902.09130\",\"authors\":[{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"39445422\",\"name\":\"W. Chen\"},{\"authorId\":\"38700603\",\"name\":\"Wei Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/CVPR.2019.00132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"074611d0c9f527bc0ad06f00df779f3361e38b83\",\"title\":\"An Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/074611d0c9f527bc0ad06f00df779f3361e38b83\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"38905965\",\"name\":\"Arpit Chaudhary\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1109/WACV.2019.00015\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"title\":\"Where to Focus on for Human Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30065390\",\"name\":\"Manh-Quan Bui\"},{\"authorId\":\"2345136\",\"name\":\"V. Duong\"},{\"authorId\":\"4604855\",\"name\":\"Tzu-Chiang Tai\"},{\"authorId\":\"3205648\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICIP.2018.8451232\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa41626f52e9940dfe839ec9ceff2ae72ec5fdf7\",\"title\":\"Depth Human Action Recognition Based on Convolution Neural Networks and Principal Component Analysis\",\"url\":\"https://www.semanticscholar.org/paper/aa41626f52e9940dfe839ec9ceff2ae72ec5fdf7\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2015.7298860\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"641f3b3cf91e11f77210447fe67375fdf350e983\",\"title\":\"Learning a non-linear knowledge transfer model for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/641f3b3cf91e11f77210447fe67375fdf350e983\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414148\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"47059752\",\"name\":\"Lining Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICRA.2016.7487309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0513fb9d82f00058f41803ae67c78d3cbd9b0b07\",\"title\":\"Arbitrary view action recognition via transfer dictionary learning on synthetic training data\",\"url\":\"https://www.semanticscholar.org/paper/0513fb9d82f00058f41803ae67c78d3cbd9b0b07\",\"venue\":\"ICRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599734\",\"name\":\"I. Lee\"},{\"authorId\":\"8307027\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"72490873\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/TMM.2020.2978637\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df84818634b8d82a10faf6a35f2775be002f1a6f\",\"title\":\"3-D Human Behavior Understanding Using Generalized TS-LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/df84818634b8d82a10faf6a35f2775be002f1a6f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"Dinesh Kumar Vishwakarma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"title\":\"A Robust Framework for Abnormal Human Action Recognition Using <inline-formula> <tex-math notation=\\\"LaTeX\\\">$\\\\boldsymbol{\\\\mathcal{R}}$ </tex-math></inline-formula>-Transform and Zernike Moments in Depth Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-3-030-01240-3_28\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"d2003d6e1de789b7fe60819257d8dfd54d267517\",\"title\":\"Dividing and Aggregating Network for Multi-view Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2003d6e1de789b7fe60819257d8dfd54d267517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":\"10.1109/TCSVT.2016.2643161\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02c8488cebeaca0905114016fbbe2179175fabb0\",\"title\":\"Human Action Recognition Using 3D Reconstruction Data\",\"url\":\"https://www.semanticscholar.org/paper/02c8488cebeaca0905114016fbbe2179175fabb0\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"2012.01405\",\"authors\":[{\"authorId\":\"2013369805\",\"name\":\"Long Zhao\"},{\"authorId\":null,\"name\":\"Yuxiao Wang\"},{\"authorId\":\"7818121\",\"name\":\"Jiaping Zhao\"},{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"13700560\",\"name\":\"J. J. Sun\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"},{\"authorId\":\"1965047031\",\"name\":\"Dimitris Metaxas\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"933f59d5fed53f06843f8eb12b94862bf45a5d62\",\"title\":\"Learning View-Disentangled Human Pose Representation by Contrastive Cross-View Mutual Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/933f59d5fed53f06843f8eb12b94862bf45a5d62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50759119\",\"name\":\"W. Ding\"},{\"authorId\":\"49599759\",\"name\":\"Kai Liu\"},{\"authorId\":\"144717380\",\"name\":\"E. Belyaev\"},{\"authorId\":\"47900774\",\"name\":\"Fei Cheng\"}],\"doi\":\"10.1016/j.patcog.2017.12.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25a784695e5b0e33d3de81b09fbaf9d8500f9bac\",\"title\":\"Tensor-based linear dynamical systems for action recognition from 3D skeletons\",\"url\":\"https://www.semanticscholar.org/paper/25a784695e5b0e33d3de81b09fbaf9d8500f9bac\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1904.10681\",\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"21029564f3072ab3ff2368069001ba7cb2bd6a3f\",\"title\":\"A Large-scale Varying-view RGB-D Action Dataset for Arbitrary-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21029564f3072ab3ff2368069001ba7cb2bd6a3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1897232\",\"name\":\"Q. Nie\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2950492\",\"name\":\"M. Wang\"},{\"authorId\":\"46398631\",\"name\":\"Yunhui Liu\"}],\"doi\":\"10.1109/ROBIO.2018.8665218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e74a8733df90f95411c7e481ce8e4d5757df318\",\"title\":\"A child caring robot for the dangerous behavior detection based on the object recognition and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e74a8733df90f95411c7e481ce8e4d5757df318\",\"venue\":\"2018 IEEE International Conference on Robotics and Biomimetics (ROBIO)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"114320931\",\"name\":\"Hai-Zhen Xuan\"},{\"authorId\":\"41189853\",\"name\":\"H. Zhang\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"2840539\",\"name\":\"Kim-Kwang Raymond Choo\"}],\"doi\":\"10.1109/JIOT.2019.2911669\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"title\":\"Adaptive Fusion and Category-Level Dictionary Learning Model for Multiview Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2019},{\"arxivId\":\"2012.01740\",\"authors\":[{\"authorId\":\"1492114642\",\"name\":\"Jingyuan Li\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0991030f3882974f57e35ff41ee5161f6febec0e\",\"title\":\"Sparse Semi-Supervised Action Recognition with Active Learning\",\"url\":\"https://www.semanticscholar.org/paper/0991030f3882974f57e35ff41ee5161f6febec0e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9185373\",\"name\":\"Pongsagorn Chalearnnetkul\"},{\"authorId\":\"2783760\",\"name\":\"N. Suvonvorn\"}],\"doi\":\"10.1155/2018/9032945\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1aa8ea65cd58c8b8c97ddcbc2949d243c5673ab5\",\"title\":\"Multiview Layer Fusion Model for Action Recognition Using RGBD Images\",\"url\":\"https://www.semanticscholar.org/paper/1aa8ea65cd58c8b8c97ddcbc2949d243c5673ab5\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1892194091\",\"name\":\"Chongyang Ding\"},{\"authorId\":\"120448891\",\"name\":\"K. Liu\"},{\"authorId\":\"145293271\",\"name\":\"F. Cheng\"},{\"authorId\":\"1387195069\",\"name\":\"Evgeny Belyaev\"}],\"doi\":\"10.1007/s10489-020-01803-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e6cbd945de5858b5af0c0d96a41a436609bb3ae\",\"title\":\"Spatio-temporal attention on manifold space for 3D human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e6cbd945de5858b5af0c0d96a41a436609bb3ae\",\"venue\":\"Applied Intelligence\",\"year\":2020},{\"arxivId\":\"1805.08484\",\"authors\":[{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"47539600\",\"name\":\"Jinjin Zhang\"},{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1694200f2fe0676985a8cfe467f9ae010eb3e57\",\"title\":\"Pose-Based Two-Stream Relational Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d1694200f2fe0676985a8cfe467f9ae010eb3e57\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.07743\",\"authors\":[{\"authorId\":\"1749326359\",\"name\":\"Adrian Sanchez-Caballero\"},{\"authorId\":\"143645592\",\"name\":\"S. Diz\"},{\"authorId\":\"1406742079\",\"name\":\"David Fuentes-Jim\\u00e9nez\"},{\"authorId\":\"1637432258\",\"name\":\"Cristina Losada-Guti\\u00e9rrez\"},{\"authorId\":\"39343700\",\"name\":\"Marta Marr\\u00f3n Romera\"},{\"authorId\":\"1415064936\",\"name\":\"David Casillas-P\\u00e9rez\"},{\"authorId\":\"134470377\",\"name\":\"Mohammad Ibrahim Sarker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f613f166ec26e3e01e996f7f04ed1d747081d9c\",\"title\":\"3DFCNN: Real-Time Action Recognition using 3D Deep Neural Networks with Raw Depth Information\",\"url\":\"https://www.semanticscholar.org/paper/6f613f166ec26e3e01e996f7f04ed1d747081d9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35035828\",\"name\":\"A. Ulhaq\"},{\"authorId\":\"49665006\",\"name\":\"Xiaoxia Yin\"},{\"authorId\":\"49122246\",\"name\":\"Jing He\"},{\"authorId\":\"34853026\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2765821\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2d890c3b1055c363fc6fa98ae20b1fdb1e5c80e\",\"title\":\"On Space-Time Filtering Framework for Matching Human Actions Across Different Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/a2d890c3b1055c363fc6fa98ae20b1fdb1e5c80e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46397014\",\"name\":\"X. Xie\"},{\"authorId\":\"3440176\",\"name\":\"H. Liu\"},{\"authorId\":\"37156109\",\"name\":\"Mark Edmonds\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICRA.2018.8461214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71f8d3b423a0a91913fd6b567469f6c119d61130\",\"title\":\"Unsupervised Learning of Hierarchical Models for Hand-Object Interactions\",\"url\":\"https://www.semanticscholar.org/paper/71f8d3b423a0a91913fd6b567469f6c119d61130\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145483621\",\"name\":\"R. Li\"},{\"authorId\":\"144977049\",\"name\":\"Hong Fu\"},{\"authorId\":\"2330090\",\"name\":\"W. Lo\"},{\"authorId\":\"8590720\",\"name\":\"Z. Chi\"},{\"authorId\":\"73741985\",\"name\":\"Zongxi Song\"},{\"authorId\":\"47027262\",\"name\":\"Desheng Wen\"}],\"doi\":\"10.1109/ACCESS.2019.2954744\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"81b746600233bd63e0b09da17317f2fbde8ef440\",\"title\":\"Skeleton-Based Action Recognition With Key-Segment Descriptor and Temporal Step Matrix Model\",\"url\":\"https://www.semanticscholar.org/paper/81b746600233bd63e0b09da17317f2fbde8ef440\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2011.07236\",\"authors\":[{\"authorId\":\"51307583\",\"name\":\"Shihao Xu\"},{\"authorId\":\"1810691540\",\"name\":\"Haocong Rao\"},{\"authorId\":\"1718919\",\"name\":\"Xiping Hu\"},{\"authorId\":\"145721647\",\"name\":\"Bin Hu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1a733bdf40980abd76ecbd25b277f09cae7e2c1\",\"title\":\"Prototypical Contrast and Reverse Prediction: Unsupervised Skeleton Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c1a733bdf40980abd76ecbd25b277f09cae7e2c1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13399\",\"authors\":[{\"authorId\":\"151136071\",\"name\":\"Mattia Segu\"},{\"authorId\":\"1781788981\",\"name\":\"Federico Pirovano\"},{\"authorId\":\"2029237675\",\"name\":\"Gianmario Fumagalli\"},{\"authorId\":\"1557389943\",\"name\":\"Amedeo Fabris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"title\":\"Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal Heatmaps\",\"url\":\"https://www.semanticscholar.org/paper/ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750931828\",\"name\":\"Ke Cheng\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48535072\",\"name\":\"X. He\"},{\"authorId\":\"26390637\",\"name\":\"Wei-Han Chen\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00026\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1d41090ba8e597380e7353b6b1f42d6a7d9f83b4\",\"title\":\"Skeleton-Based Action Recognition With Shift Graph Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/1d41090ba8e597380e7353b6b1f42d6a7d9f83b4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626118657\",\"name\":\"H. Naeem\"},{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1007/s13369-020-04481-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bab9c955262300b2a88e64c68a60e5ad66073578\",\"title\":\"Multiple Batches of Motion History Images (MB-MHIs) for Multi-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bab9c955262300b2a88e64c68a60e5ad66073578\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.07053\",\"authors\":[{\"authorId\":\"1897232\",\"name\":\"Q. Nie\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c28f1c05a0e773ec433ac307b21d15fb469df71\",\"title\":\"Unsupervised Human 3D Pose Representation with Viewpoint and Pose Disentanglement\",\"url\":\"https://www.semanticscholar.org/paper/4c28f1c05a0e773ec433ac307b21d15fb469df71\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"145327287\",\"name\":\"Y. Jing\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2020.107511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fa2bda10a3dd6d3662d2b63af4b27daabd876dd\",\"title\":\"Skeleton-based action recognition with hierarchical spatial reasoning and temporal stack learning network\",\"url\":\"https://www.semanticscholar.org/paper/7fa2bda10a3dd6d3662d2b63af4b27daabd876dd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845863027\",\"name\":\"Qiang Nie\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s11263-020-01354-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe1109bce3325850a339023efaf5daf56a95340b\",\"title\":\"View Transfer on Human Skeleton Pose: Automatically Disentangle the View-Variant and View-Invariant Information for Pose Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/fe1109bce3325850a339023efaf5daf56a95340b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739290263\",\"name\":\"Jin-Gong Jia\"},{\"authorId\":\"1739154076\",\"name\":\"Yuanfeng Zhou\"},{\"authorId\":\"2569938\",\"name\":\"Xingwei Hao\"},{\"authorId\":\"49515937\",\"name\":\"F. Li\"},{\"authorId\":\"1739646\",\"name\":\"Christian Desrosiers\"},{\"authorId\":\"39549162\",\"name\":\"CaiMing Zhang\"}],\"doi\":\"10.1007/s11390-020-0405-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"93c98dc4b2e5465306e90b2a69288c4099b7b039\",\"title\":\"Two-Stream Temporal Convolutional Networks for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93c98dc4b2e5465306e90b2a69288c4099b7b039\",\"venue\":\"Journal of Computer Science and Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TCYB.2016.2582918\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ed617d14dbc53b20287d3405b14c68d8dad3965\",\"title\":\"Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ed617d14dbc53b20287d3405b14c68d8dad3965\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"title\":\"Action Recognition in Multi-view Videos\",\"url\":\"https://www.semanticscholar.org/paper/ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"3417987\",\"name\":\"F. Boussaid\"}],\"doi\":\"10.1109/TIP.2018.2812099\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef761435c1af2b3e5caba5e8bbbf5aeab69d934e\",\"title\":\"Learning Clip Representations for Skeleton-Based 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ef761435c1af2b3e5caba5e8bbbf5aeab69d934e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1809.00421\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"1950475\",\"name\":\"Z. Lu\"},{\"authorId\":\"1723081\",\"name\":\"J. Li\"},{\"authorId\":\"144954293\",\"name\":\"T. Yang\"}],\"doi\":\"10.1109/TCSVT.2018.2868123\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55efe8e34da21765f8a078dc11da71b56bccdf70\",\"title\":\"Hierarchically Learned View-Invariant Representations for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/55efe8e34da21765f8a078dc11da71b56bccdf70\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34752724\",\"name\":\"A. Gabriel\"},{\"authorId\":\"2148342\",\"name\":\"S. Cosar\"},{\"authorId\":\"1709606\",\"name\":\"N. Bellotto\"},{\"authorId\":\"143997370\",\"name\":\"P. Baxter\"}],\"doi\":\"10.1007/978-3-030-23807-0_30\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b662f49666373648289602e334ec47d34d658800\",\"title\":\"A Dataset for Action Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/b662f49666373648289602e334ec47d34d658800\",\"venue\":\"TAROS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"title\":\"Part-aligned pose-guided recurrent network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2878772\",\"name\":\"Girum G. Demisse\"},{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.1109/CVPRW.2018.00056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51b618cb1e7b5b53e3abb794ee41060963aae832\",\"title\":\"Pose Encoding for Robust Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51b618cb1e7b5b53e3abb794ee41060963aae832\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3322642\",\"name\":\"Fairouz Hussein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"25d2cd5221b97b8990d48f3727be1f69578246d8\",\"title\":\"Action recognition and video summarisation by submodular inference\",\"url\":\"https://www.semanticscholar.org/paper/25d2cd5221b97b8990d48f3727be1f69578246d8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"145081305\",\"name\":\"L. Zhu\"},{\"authorId\":\"38079143\",\"name\":\"H. Zhang\"},{\"authorId\":\"38930487\",\"name\":\"Yinglong Wang\"}],\"doi\":\"10.1109/ACCESS.2018.2878313\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"title\":\"Exploring the Cross-Domain Action Recognition Problem by Deep Feature Learning and Cross-Domain Learning\",\"url\":\"https://www.semanticscholar.org/paper/5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395615456\",\"name\":\"Elena Nicora\"},{\"authorId\":\"2442124\",\"name\":\"Gaurvi Goyal\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"2511943\",\"name\":\"A. Vignolo\"},{\"authorId\":\"1961676436\",\"name\":\"Alessandra Sciutti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"}],\"doi\":\"10.1038/s41597-020-00776-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"title\":\"The MoCA dataset, kinematic and multi-view visual streams of fine-grained cooking actions\",\"url\":\"https://www.semanticscholar.org/paper/bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"venue\":\"Scientific data\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2774166\",\"name\":\"M. Fani\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2017.17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41e085d52e85a224a66e6b0884f053c05f285877\",\"title\":\"Hockey Action Recognition via Integrated Stacked Hourglass Network\",\"url\":\"https://www.semanticscholar.org/paper/41e085d52e85a224a66e6b0884f053c05f285877\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1814260\",\"name\":\"Enjie Ghorbel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4ea51ddbdbfdb2cbdbca39eb844647cb98fcd04\",\"title\":\"Fast and accurate human action recognition using RGB-D cameras\",\"url\":\"https://www.semanticscholar.org/paper/c4ea51ddbdbfdb2cbdbca39eb844647cb98fcd04\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"33185308\",\"name\":\"Hong-Cheu Liu\"},{\"authorId\":\"46992328\",\"name\":\"Yong-Sheng Liang\"},{\"authorId\":\"29556621\",\"name\":\"Juanhui Tu\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"}],\"doi\":\"10.1109/TIP.2019.2913544\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b16a42f372ea1d03e7fafd2b5e96d62995403174\",\"title\":\"Sample Fusion Network: An End-to-End Data Augmentation Network for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b16a42f372ea1d03e7fafd2b5e96d62995403174\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2005.05501\",\"authors\":[{\"authorId\":null,\"name\":\"Yancheng Wang\"},{\"authorId\":\"1409958726\",\"name\":\"Yang Xiao\"},{\"authorId\":\"5181059\",\"name\":\"F. Xiong\"},{\"authorId\":\"1406126531\",\"name\":\"Wenxiang Jiang\"},{\"authorId\":\"144762660\",\"name\":\"Zhiguo Cao\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/cvpr42600.2020.00059\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a29fc09d4b6a093b39d370ff47fa84bb2d405cf\",\"title\":\"3DV: 3D Dynamic Voxel for Action Recognition in Depth Video\",\"url\":\"https://www.semanticscholar.org/paper/6a29fc09d4b6a093b39d370ff47fa84bb2d405cf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.13979\",\"authors\":[{\"authorId\":\"48317098\",\"name\":\"Bruce X. B. Yu\"},{\"authorId\":\"49422024\",\"name\":\"Y. Liu\"},{\"authorId\":\"145003402\",\"name\":\"K. C. Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"title\":\"Skeleton Focused Human Activity Recognition in RGB Video\",\"url\":\"https://www.semanticscholar.org/paper/ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"2010.14742\",\"authors\":[{\"authorId\":\"51115810\",\"name\":\"Hochul Hwang\"},{\"authorId\":\"1831882\",\"name\":\"C. Jang\"},{\"authorId\":\"51311609\",\"name\":\"Geonwoo Park\"},{\"authorId\":\"1679356768\",\"name\":\"Junghyun Cho\"},{\"authorId\":\"49596689\",\"name\":\"Ig-Jae Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"title\":\"ElderSim: A Synthetic Data Generation Platform for Human Action Recognition in Eldercare Applications\",\"url\":\"https://www.semanticscholar.org/paper/06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145371571\",\"name\":\"J. Ren\"},{\"authorId\":\"1783269\",\"name\":\"N. Reyes\"},{\"authorId\":\"3312622\",\"name\":\"A. Barczak\"},{\"authorId\":\"1775137\",\"name\":\"C. Scogings\"},{\"authorId\":\"47842373\",\"name\":\"M. Liu\"}],\"doi\":\"10.1117/1.JEI.27.4.043040\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3376f077b2767740a5896b25c78d5181df1fb44a\",\"title\":\"Toward three-dimensional human action recognition using a convolutional neural network with correctness-vigilant regularizer\",\"url\":\"https://www.semanticscholar.org/paper/3376f077b2767740a5896b25c78d5181df1fb44a\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"2196194\",\"name\":\"H. Zhang\"},{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"41135049\",\"name\":\"Dong-Ying Gong\"},{\"authorId\":\"38187621\",\"name\":\"D. Cao\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"}],\"doi\":\"10.1016/j.neucom.2018.02.056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9577c5d16a95e7e9d0d7cbae01dccdc8ab076c6a\",\"title\":\"Discriminative parts learning for 3D human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9577c5d16a95e7e9d0d7cbae01dccdc8ab076c6a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47935745\",\"name\":\"Hang Qi\"},{\"authorId\":\"2762640\",\"name\":\"Yuanlu Xu\"},{\"authorId\":\"48580157\",\"name\":\"T. Yuan\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d75d644fcce8d2d4576e149febade5c5b8259a95\",\"title\":\"Scene-Centric Joint Parsing of Cross-View Videos\",\"url\":\"https://www.semanticscholar.org/paper/d75d644fcce8d2d4576e149febade5c5b8259a95\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"48447152\",\"name\":\"H. Liu\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.patcog.2017.02.030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"928742fae8f5f6e3142cdab1976e9198e21092c6\",\"title\":\"Enhanced skeleton visualization for view invariant human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/928742fae8f5f6e3142cdab1976e9198e21092c6\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1601.01006\",\"authors\":[{\"authorId\":\"144845024\",\"name\":\"Fei Han\"},{\"authorId\":\"144755330\",\"name\":\"Brian Reily\"},{\"authorId\":\"143790090\",\"name\":\"W. Hoff\"},{\"authorId\":\"38952862\",\"name\":\"Hao Zhang\"}],\"doi\":\"10.1016/j.cviu.2017.01.011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7385f998caf17b2c6ae9f8808b6fd3a05205b438\",\"title\":\"Space-Time Representation of People Based on 3D Skeletal Data: A Review\",\"url\":\"https://www.semanticscholar.org/paper/7385f998caf17b2c6ae9f8808b6fd3a05205b438\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1603.04037\",\"authors\":[{\"authorId\":\"145042308\",\"name\":\"U. Iqbal\"},{\"authorId\":\"3370510\",\"name\":\"Martin Garbade\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/FG.2017.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5c48fb5d8f1403f8aa5392045fcdfd79b37a934\",\"title\":\"Pose for Action - Action for Pose\",\"url\":\"https://www.semanticscholar.org/paper/c5c48fb5d8f1403f8aa5392045fcdfd79b37a934\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"2009.06599\",\"authors\":[{\"authorId\":\"153802755\",\"name\":\"Y. Bai\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"1491247995\",\"name\":\"Lichen Wang\"},{\"authorId\":\"72917175\",\"name\":\"Sheng Li\"},{\"authorId\":\"49546023\",\"name\":\"Yu Yin\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"014b9e84932ca45e48452980667683f56d0deadb\",\"title\":\"Collaborative Attention Mechanism for Multi-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/014b9e84932ca45e48452980667683f56d0deadb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2475715\",\"name\":\"Chengkun Zhang\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"}],\"doi\":\"10.1117/1.JEI.27.4.043044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec5dfae45af33f32bd784fc172f4d42dc78bf6ba\",\"title\":\"Dual-codebook learning and hierarchical transfer for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec5dfae45af33f32bd784fc172f4d42dc78bf6ba\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7531875\",\"name\":\"Cuiwei Liu\"},{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1007/s11042-018-6189-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41354411c62be3f66608c9beadb2b2d269179809\",\"title\":\"A discriminative structural model for joint segmentation and recognition of human actions\",\"url\":\"https://www.semanticscholar.org/paper/41354411c62be3f66608c9beadb2b2d269179809\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"2009.00638\",\"authors\":[{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"}],\"doi\":\"10.1007/978-3-030-03243-2_878-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"078a36e823ea23d9ea756d449ad0074812dbb0b3\",\"title\":\"View-invariant action recognition\",\"url\":\"https://www.semanticscholar.org/paper/078a36e823ea23d9ea756d449ad0074812dbb0b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49963740\",\"name\":\"Y. Du\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2016.2552404\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de420f342b15087515d9750a6fccec1909173d96\",\"title\":\"Representation Learning of Temporal Dynamics for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de420f342b15087515d9750a6fccec1909173d96\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"144061516\",\"name\":\"L. Tao\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1109/WACV.2017.20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b3aaa685bcfe24081f33005b3be051f079a5411\",\"title\":\"Deep Moving Poselets for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3aaa685bcfe24081f33005b3be051f079a5411\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082568\",\"name\":\"Liangliang Wang\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.jvcir.2016.06.023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d723ecf23071dabe135fb8902327e95f208f003a\",\"title\":\"Gradient-layer feature transform for action detection and recognition\",\"url\":\"https://www.semanticscholar.org/paper/d723ecf23071dabe135fb8902327e95f208f003a\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144441983\",\"name\":\"Sivaram Prasad Mudunuri\"},{\"authorId\":\"145702363\",\"name\":\"S. Biswas\"}],\"doi\":\"10.1016/j.patrec.2015.12.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61449a2a919a2e9a9b4a685f6651dac16673d5d\",\"title\":\"A coupled discriminative dictionary and transformation learning approach with applications to cross domain matching\",\"url\":\"https://www.semanticscholar.org/paper/e61449a2a919a2e9a9b4a685f6651dac16673d5d\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772962\",\"name\":\"Emre Dogan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fe41a944a16c744f64d4686b6e9296290550ed5\",\"title\":\"Estimation de pose humaine et reconnaissance d'action par un syst\\u00e8me multi-robots. (Human pose estimation and action recognition by multi-robot systems)\",\"url\":\"https://www.semanticscholar.org/paper/5fe41a944a16c744f64d4686b6e9296290550ed5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-58583-9_26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"title\":\"Multi-view Action Recognition Using Cross-View Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.12409\",\"authors\":[{\"authorId\":\"47791841\",\"name\":\"K. Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":\"10.1109/CVPR42600.2020.00965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8551461aa62394ea9934a810108d4acef047a52\",\"title\":\"PREDICT & CLUSTER: Unsupervised Skeleton Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8551461aa62394ea9934a810108d4acef047a52\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1802.07898\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CVPR.2018.00056\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ab45ab887b7c1379bba4179579568296448d16d6\",\"title\":\"Glimpse Clouds: Human Activity Recognition from Unstructured Feature Points\",\"url\":\"https://www.semanticscholar.org/paper/ab45ab887b7c1379bba4179579568296448d16d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"152813675\",\"name\":\"Tao-tao Han\"},{\"authorId\":\"39389412\",\"name\":\"H. Zhang\"},{\"authorId\":\"1902532\",\"name\":\"Y. Xue\"},{\"authorId\":\"2615851\",\"name\":\"G. Xu\"}],\"doi\":\"10.1007/s11042-018-5833-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea8bf8924e15607d959ae822f428815a9d435f3b\",\"title\":\"MMA: a multi-view and multi-modality benchmark dataset for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea8bf8924e15607d959ae822f428815a9d435f3b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"2007.05934\",\"authors\":[{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"35785179\",\"name\":\"Xuecheng Nie\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-58571-6_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8684daa869e50df9b03d7d0a356f2cbd5b47a7fe\",\"title\":\"Adversarial Self-Supervised Learning for Semi-Supervised 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8684daa869e50df9b03d7d0a356f2cbd5b47a7fe\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":2239612,\"doi\":\"10.1109/CVPR.2014.339\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":48,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"5de214630011554bd07b41ec5bd493c7f65c532e\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"143774737\",\"name\":\"J. Shotton\"},{\"authorId\":\"34824003\",\"name\":\"T. Sharp\"},{\"authorId\":\"40016803\",\"name\":\"A. Kipman\"},{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"2848295\",\"name\":\"M. Finocchio\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"},{\"authorId\":\"40636177\",\"name\":\"Mat Cook\"},{\"authorId\":\"144564063\",\"name\":\"R. Moore\"}],\"doi\":\"10.1145/2398356.2398381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2915510a39448503ee873f9693cd3808ca74bd81\",\"title\":\"Real-time human pose recognition in parts from single depth images\",\"url\":\"https://www.semanticscholar.org/paper/2915510a39448503ee873f9693cd3808ca74bd81\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144647868\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1683416\",\"name\":\"Chunheng Wang\"},{\"authorId\":\"2658590\",\"name\":\"B. Xiao\"},{\"authorId\":\"145387913\",\"name\":\"W. Zhou\"},{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"1959339\",\"name\":\"C. Shi\"}],\"doi\":\"10.1109/CVPR.2013.347\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2023bbd150d4134acc54214ee87b8492f4232ae1\",\"title\":\"Cross-View Action Recognition via a Continuous Virtual Path\",\"url\":\"https://www.semanticscholar.org/paper/2023bbd150d4134acc54214ee87b8492f4232ae1\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33458360\",\"name\":\"R. Li\"},{\"authorId\":\"1713451\",\"name\":\"Todd E. Zickler\"}],\"doi\":\"10.1109/CVPR.2012.6248011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0aa318aea7fdd011167e22baed3c7be2a6e3dd0d\",\"title\":\"Discriminative virtual views for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/0aa318aea7fdd011167e22baed3c7be2a6e3dd0d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685089\",\"name\":\"Pedro F. Felzenszwalb\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/TPAMI.2009.167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e79272fe3d65197100eae8be9fec6469107969ae\",\"title\":\"Object Detection with Discriminatively Trained Part Based Models\",\"url\":\"https://www.semanticscholar.org/paper/e79272fe3d65197100eae8be9fec6469107969ae\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807123\",\"name\":\"Zhangzhang Si\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/TPAMI.2013.35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f8f64382681fb92da07bac2d7b5bdd136c6f1fe\",\"title\":\"Learning AND-OR Templates for Object Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/1f8f64382681fb92da07bac2d7b5bdd136c6f1fe\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1697116\",\"name\":\"Imran N. Junejo\"},{\"authorId\":\"31613810\",\"name\":\"Emilie Dexter\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1007/978-3-540-88688-4_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bf76af16ac6f56c62f3d1fdd8064bb59c359532\",\"title\":\"Cross-View Action Recognition from Temporal Self-similarities\",\"url\":\"https://www.semanticscholar.org/paper/3bf76af16ac6f56c62f3d1fdd8064bb59c359532\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144031869\",\"name\":\"A. Yao\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-012-0532-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5bee31cc0c2e5a3149b366b36bd3f7fbcc45f7a8\",\"title\":\"Coupled Action Recognition and Pose Estimation from Multiple Views\",\"url\":\"https://www.semanticscholar.org/paper/5bee31cc0c2e5a3149b366b36bd3f7fbcc45f7a8\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750163\",\"name\":\"B. Li\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":\"10.1109/CVPR.2012.6247822\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46d2f1a6393c99da2997f35ff8d3860ee44f4b6d\",\"title\":\"Cross-view activity recognition using Hankelets\",\"url\":\"https://www.semanticscholar.org/paper/46d2f1a6393c99da2997f35ff8d3860ee44f4b6d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-33765-9_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"178a09f4e45b1d428292868ea2d4c53401fc1717\",\"title\":\"Action Recognition with Exemplar Based 2.5D Graph Matching\",\"url\":\"https://www.semanticscholar.org/paper/178a09f4e45b1d428292868ea2d4c53401fc1717\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2011.5995631\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"12fe91ab616b797e22543ae6c2afa7866dbc9a49\",\"title\":\"Action recognition from a distributed representation of pose and appearance\",\"url\":\"https://www.semanticscholar.org/paper/12fe91ab616b797e22543ae6c2afa7866dbc9a49\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"},{\"authorId\":\"145585296\",\"name\":\"B. Kuipers\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/CVPR.2011.5995729\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5de73a9334fc34873030be8bab2be21fc8ddae69\",\"title\":\"Cross-view action recognition via view knowledge transfer\",\"url\":\"https://www.semanticscholar.org/paper/5de73a9334fc34873030be8bab2be21fc8ddae69\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948848\",\"name\":\"S. Sadanand\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247806\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"title\":\"Action bank: A high-level representation of activity in video\",\"url\":\"https://www.semanticscholar.org/paper/d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3130645\",\"name\":\"Mostafa Kamali Tabrizi\"}],\"doi\":\"10.1007/978-3-540-88682-2_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af50372a852edfc12c8273fdaeb106dfca72ea04\",\"title\":\"Learning to Recognize Activities from the Wrong View Point\",\"url\":\"https://www.semanticscholar.org/paper/af50372a852edfc12c8273fdaeb106dfca72ea04\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2098925\",\"name\":\"Joerg Liebelt\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2010.5539836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29306620dd921b7d3c2f368962ae40d3c43c32a2\",\"title\":\"Multi-view object class detection with a 3D geometric model\",\"url\":\"https://www.semanticscholar.org/paper/29306620dd921b7d3c2f368962ae40d3c43c32a2\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B. Yao\"},{\"authorId\":null,\"name\":\"X. Nie\"},{\"authorId\":null,\"name\":\"Z. Liu\"},{\"authorId\":null,\"name\":\"S.-C. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Animated pose templates for modelling and detecting human\",\"url\":\"\",\"venue\":\"actions. PAMI,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14933480\",\"name\":\"V. Parameswaran\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/s11263-005-3671-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b549d86bd129d3d8e5822dcd244b75b891516673\",\"title\":\"View Invariance for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b549d86bd129d3d8e5822dcd244b75b891516673\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/TMM.2012.2187180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6098aa34918a8d01bd265690e3677fd474ba17d\",\"title\":\"Web-Based Classifiers for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e6098aa34918a8d01bd265690e3677fd474ba17d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40277674\",\"name\":\"C. Desai\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1007/978-3-642-33765-9_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eec68953568b1a184d6a6c41f1241fc95d4347b6\",\"title\":\"Detecting Actions, Poses, and Objects with Relational Phraselets\",\"url\":\"https://www.semanticscholar.org/paper/eec68953568b1a184d6a6c41f1241fc95d4347b6\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47713710\",\"name\":\"Benjamin Z. Yao\"},{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/TPAMI.2013.144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbd41d94206e532649ae539de54b95ce6d8457db\",\"title\":\"Animated Pose Templates for Modeling and Detecting Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/cbd41d94206e532649ae539de54b95ce6d8457db\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2012.6247813\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"321f519e2876e1fa086b36e1b3f91b1efe2ea532\",\"title\":\"Mining actionlet ensemble for action recognition with depth cameras\",\"url\":\"https://www.semanticscholar.org/paper/321f519e2876e1fa086b36e1b3f91b1efe2ea532\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Yang\"},{\"authorId\":null,\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Articulated pose estimation with flexible mixturesof-parts resenting shape\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1779136\",\"name\":\"S. Dickinson\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6566818205366e7419bca0155918444ebd06671c\",\"title\":\"3D Object Detection and Viewpoint Estimation with a Deformable 3D Cuboid Model\",\"url\":\"https://www.semanticscholar.org/paper/6566818205366e7419bca0155918444ebd06671c\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47713710\",\"name\":\"Benjamin Z. Yao\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2009.5459277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b98486ca13c09f29fbbc3ffd8888b32d488cf9bd\",\"title\":\"Learning deformable action templates from cluttered videos\",\"url\":\"https://www.semanticscholar.org/paper/b98486ca13c09f29fbbc3ffd8888b32d488cf9bd\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009}],\"title\":\"Cross-View Action Modeling, Learning, and Recognition\",\"topics\":[{\"topic\":\"Kinect\",\"topicId\":\"98440\",\"url\":\"https://www.semanticscholar.org/topic/98440\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Minimum spanning tree\",\"topicId\":\"10357\",\"url\":\"https://www.semanticscholar.org/topic/10357\"},{\"topic\":\"Cognitive dimensions of notations\",\"topicId\":\"261452\",\"url\":\"https://www.semanticscholar.org/topic/261452\"}],\"url\":\"https://www.semanticscholar.org/paper/5de214630011554bd07b41ec5bd493c7f65c532e\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014}\n"