"{\"abstract\":\"Saliency prediction typically relies on hand-crafted (multiscale) features that are combined in different ways to form a \\\"master\\\" saliency map, which encodes local image conspicuity. Recent improvements to the state of the art on standard benchmarks such as MIT1003 have been achieved mostly by incrementally adding more and more hand-tuned features (such as car or face detectors) to existing models. In contrast, we here follow an entirely automatic data-driven approach that performs a large-scale search for optimal features. We identify those instances of a richly-parameterized bio-inspired model family (hierarchical neuromorphic networks) that successfully predict image saliency. Because of the high dimensionality of this parameter space, we use automated hyperparameter optimization to efficiently guide the search. The optimal blend of such multilayer features combined with a simple linear classifier achieves excellent performance on several image saliency benchmarks. Our models outperform the state of the art on MIT1003, on which features and classifiers are learned. Without additional training, these models generalize well to two other image saliency data sets, Toronto and NUSEF, despite their different image content. Finally, our algorithm scores best of all the 23 models evaluated to date on the MIT300 saliency challenge, which uses a hidden test set to facilitate an unbiased comparison.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\",\"url\":\"https://www.semanticscholar.org/author/2286630\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\",\"url\":\"https://www.semanticscholar.org/author/1944405\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\",\"url\":\"https://www.semanticscholar.org/author/2042941\"}],\"citationVelocity\":58,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"150073770\",\"name\":\"Dongyue Chen\"},{\"authorId\":\"48024542\",\"name\":\"Tong Jia\"},{\"authorId\":\"9012081\",\"name\":\"C. Wu\"}],\"doi\":\"10.1016/j.image.2016.03.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3904fc1c9e4da0c71856800b102450baa3bbcc28\",\"title\":\"Visual saliency detection: From space to frequency\",\"url\":\"https://www.semanticscholar.org/paper/3904fc1c9e4da0c71856800b102450baa3bbcc28\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2016},{\"arxivId\":\"1609.00072\",\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08f1e9e14775757298afd9039f46ec56e80677f9\",\"title\":\"Attentional Push: Augmenting Salience with Shared Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/08f1e9e14775757298afd9039f46ec56e80677f9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144063510\",\"name\":\"Yuchen Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9912e5b1b72fbc14a682de397fabaec1bd1d4028\",\"title\":\"Advanced Visual Computing for Image Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/9912e5b1b72fbc14a682de397fabaec1bd1d4028\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50543166\",\"name\":\"Anne-Flore Perrin\"},{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1007/978-3-030-29888-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"title\":\"How Well Current Saliency Prediction Models Perform on UAVs Videos?\",\"url\":\"https://www.semanticscholar.org/paper/3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"venue\":\"CAIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/ICCV.2017.513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70400461\",\"name\":\"P. Pinto\"},{\"authorId\":\"1773609\",\"name\":\"A. Tom\\u00e9\"},{\"authorId\":\"145649879\",\"name\":\"V. Santos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48216b1e2a952eb03185edfc8257ae03e9558614\",\"title\":\"FCT- Formula\\u0301rio de candidatura a Bolsas\",\"url\":\"https://www.semanticscholar.org/paper/48216b1e2a952eb03185edfc8257ae03e9558614\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48926031\",\"name\":\"Chen Xia\"},{\"authorId\":\"145877494\",\"name\":\"J. Han\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"}],\"doi\":\"10.1109/TIP.2019.2897966\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed56acb6964af0c814266f289d46859c33b8b5be\",\"title\":\"Predicting Human Saccadic Scanpaths Based on Iterative Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/ed56acb6964af0c814266f289d46859c33b8b5be\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1612.04335\",\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"title\":\"How do people explore virtual environments\",\"url\":\"https://www.semanticscholar.org/paper/c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1809.00567\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1007/978-3-030-11021-5_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"title\":\"PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1709.05307\",\"authors\":[{\"authorId\":\"2004177\",\"name\":\"F. Murabito\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"3403160\",\"name\":\"Konstantin Pogorelov\"},{\"authorId\":\"1410046696\",\"name\":\"Michael Riegler\"}],\"doi\":\"10.1016/j.cviu.2018.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"706f314f3b66f0ede47ec9ca7157426915739244\",\"title\":\"Top-Down Saliency Detection Driven by Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/706f314f3b66f0ede47ec9ca7157426915739244\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19382329\",\"name\":\"Saman Zadtootaghaj\"},{\"authorId\":\"144107509\",\"name\":\"Steven Schmidt\"},{\"authorId\":\"143840790\",\"name\":\"H. Ahmadi\"},{\"authorId\":\"145733288\",\"name\":\"S. M\\u00f6ller\"}],\"doi\":\"10.1109/NetGames.2017.7991542\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2de0e6333dfbc43ccfaf494bfd357cef560ad2d5\",\"title\":\"Towards improving visual attention models using influencing factors in a video gaming context\",\"url\":\"https://www.semanticscholar.org/paper/2de0e6333dfbc43ccfaf494bfd357cef560ad2d5\",\"venue\":\"2017 15th Annual Workshop on Network and Systems Support for Games (NetGames)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37503295\",\"name\":\"J. Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"102937546\",\"name\":\"Weimin Wu\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"17668082\",\"name\":\"Baiyan Zhang\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802611\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"title\":\"Saliency Detection via Topological Feature Modulated Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1704.08615\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebe8e8f2196fd947c091db64b1035737a072b496\",\"title\":\"Saliency Benchmarking: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/ebe8e8f2196fd947c091db64b1035737a072b496\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1882027\",\"name\":\"Henny Admoni\"},{\"authorId\":\"1752197\",\"name\":\"S. Srinivasa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"690a95f65038492a8385fe2663d187c8f7b7e9c4\",\"title\":\"Predicting User Intent Through Eye Gaze for Shared Autonomy\",\"url\":\"https://www.semanticscholar.org/paper/690a95f65038492a8385fe2663d187c8f7b7e9c4\",\"venue\":\"AAAI Fall Symposia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51149716\",\"name\":\"Taiki Oyama\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1109/ACPR.2017.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d702248cf46124600c680608a510e03a30b4d63b\",\"title\":\"Fully Convolutional DenseNet for Saliency-Map Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d702248cf46124600c680608a510e03a30b4d63b\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2330182\",\"name\":\"S. Wen\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"}],\"doi\":\"10.1109/CVPR.2015.7298633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"title\":\"Predicting eye fixations using convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5586734\",\"name\":\"X. Deng\"},{\"authorId\":\"35099667\",\"name\":\"C. Cui\"},{\"authorId\":\"145246510\",\"name\":\"H. Liu\"},{\"authorId\":\"3082612\",\"name\":\"Xiushan Nie\"},{\"authorId\":\"1770004\",\"name\":\"X. Xi\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":\"10.1145/3240876.3240906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffdbf01c0c62fcab8e35473af2b8128e37b1d5e8\",\"title\":\"Automatic image cropping with a single fully convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/ffdbf01c0c62fcab8e35473af2b8128e37b1d5e8\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":\"1710.08014\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/ICCV.2017.240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"title\":\"Deep Cropping via Attention Box Prediction and Aesthetics Assessment\",\"url\":\"https://www.semanticscholar.org/paper/b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"title\":\"EML-NET : An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1472873014\",\"name\":\"Soonbin Lee\"},{\"authorId\":\"19377484\",\"name\":\"D. Jang\"},{\"authorId\":\"51299242\",\"name\":\"J. Jeong\"},{\"authorId\":\"2267529\",\"name\":\"E. Ryu\"}],\"doi\":\"10.1145/3304112.3325614\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd88bdd3e7dae5a751c3ece62eb729f3f91e58a5\",\"title\":\"Motion-constrained tile set based 360-degree video streaming using saliency map prediction\",\"url\":\"https://www.semanticscholar.org/paper/dd88bdd3e7dae5a751c3ece62eb729f3f91e58a5\",\"venue\":\"NOSSDAV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50633779\",\"name\":\"Vipul Sharma\"},{\"authorId\":\"21555088\",\"name\":\"R. N. Mir\"}],\"doi\":\"10.1016/J.COSREV.2020.100301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73d091d1739b8eed35f23ab334aa6cb0641fd099\",\"title\":\"A comprehensive and systematic look up into deep learning based object detection techniques: A review\",\"url\":\"https://www.semanticscholar.org/paper/73d091d1739b8eed35f23ab334aa6cb0641fd099\",\"venue\":\"Comput. Sci. Rev.\",\"year\":2020},{\"arxivId\":\"1605.01101\",\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1915908\",\"name\":\"Anirban Santara\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c73f015ab7c90f4cc97efad29c27361cec87d351\",\"title\":\"WEPSAM: Weakly Pre-Learnt Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/c73f015ab7c90f4cc97efad29c27361cec87d351\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dc540300335e27773e2b5f16c481476448d5b83\",\"title\":\"An Integrated Model for Effective Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8dc540300335e27773e2b5f16c481476448d5b83\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-70169-1_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"title\":\"Attentive Models in Vision: Computing Saliency Maps in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"venue\":\"AI*IA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"275e09dfebd01409ddb38da8972ae4d53aed06a5\",\"title\":\"Saliency and Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/275e09dfebd01409ddb38da8972ae4d53aed06a5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181816\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"3106442\",\"name\":\"F. Malmberg\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-030-04831-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe42d3f45bdbb518df01d6e33b9dbd3f56d54a19\",\"title\":\"Visual Saliency: From Pixel-Level to Object-Level Analysis\",\"url\":\"https://www.semanticscholar.org/paper/fe42d3f45bdbb518df01d6e33b9dbd3f56d54a19\",\"venue\":\"Springer International Publishing\",\"year\":2019},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46507535\",\"name\":\"T. S. Murray\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f95557a3ae5c45c1ef282ed8d0711033d86c2172\",\"title\":\"Human Action Recognition from Active Acoustics: Physics Modelling for Representation Learning and Inference Using Generative Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/f95557a3ae5c45c1ef282ed8d0711033d86c2172\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50436294\",\"name\":\"C. Xia\"},{\"authorId\":\"50426894\",\"name\":\"Rong Quan\"}],\"doi\":\"10.1109/ACCESS.2020.2966628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7281b31ad8f47a0fa2cd8fa20b3bc247a79f5bb5\",\"title\":\"Predicting Saccadic Eye Movements in Free Viewing of Webpages\",\"url\":\"https://www.semanticscholar.org/paper/7281b31ad8f47a0fa2cd8fa20b3bc247a79f5bb5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"151469503\",\"name\":\"Yifan Zhao\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"}],\"doi\":\"10.1109/MIPR49039.2020.00011\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"title\":\"Cross-Domain Visual Attention Model Adaption with One-Shot GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181816\",\"name\":\"Jianming Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3676c29babe1563ee64a1149d2ae2f9f1369fe25\",\"title\":\"Visual saliency computation for image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3676c29babe1563ee64a1149d2ae2f9f1369fe25\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144539624\",\"name\":\"B. Yan\"},{\"authorId\":\"1789710\",\"name\":\"Haoqian Wang\"},{\"authorId\":\"3291129\",\"name\":\"X. Wang\"},{\"authorId\":\"5094646\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICIP.2017.8296700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d1d71e0149bc601363f7e24825b06b36af13f5f\",\"title\":\"An accurate saliency prediction method based on generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/6d1d71e0149bc601363f7e24825b06b36af13f5f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398421283\",\"name\":\"U. Markowska-Kaczmar\"},{\"authorId\":\"153318273\",\"name\":\"H. Kwasnicka\"}],\"doi\":\"10.1007/978-3-319-73891-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"title\":\"Deep Learning\\u2014A New Era in Bridging the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2274798\",\"name\":\"F. Stentiford\"}],\"doi\":\"10.1007/978-1-4939-3435-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4a8c2acf15f6dd9846b0eca01eae3a01bff6e7d\",\"title\":\"Bottom-Up Visual Attention for Still Images: A Global View\",\"url\":\"https://www.semanticscholar.org/paper/a4a8c2acf15f6dd9846b0eca01eae3a01bff6e7d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"},{\"authorId\":\"1760309\",\"name\":\"S. Melacci\"},{\"authorId\":\"145467467\",\"name\":\"M. Gori\"}],\"doi\":\"10.1109/TPAMI.2019.2920636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6b847b4c63be4b0414583a4d1a42ad0f3e61736\",\"title\":\"Gravitational Laws of Focus of Attention\",\"url\":\"https://www.semanticscholar.org/paper/e6b847b4c63be4b0414583a4d1a42ad0f3e61736\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120317507\",\"name\":\"Makhmudov Farrukh\"},{\"authorId\":\"152325076\",\"name\":\"H. Ge\"}],\"doi\":\"10.1109/ICIST.2019.8836755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4c9b96e7ebe25b03d6478640b141dfd250d8a5\",\"title\":\"Saliency Detection in Images with Complex Background by End-to-End Sparse Maxout CNN\",\"url\":\"https://www.semanticscholar.org/paper/3d4c9b96e7ebe25b03d6478640b141dfd250d8a5\",\"venue\":\"2019 9th International Conference on Information Science and Technology (ICIST)\",\"year\":2019},{\"arxivId\":\"1801.05787\",\"authors\":[{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"46400982\",\"name\":\"I. Korshunova\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"title\":\"Faster gaze prediction with dense networks and Fisher pruning\",\"url\":\"https://www.semanticscholar.org/paper/d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"8189996\",\"name\":\"Jingxian Liu\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TMM.2017.2767784\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"title\":\"Saliency Detection in Face Videos: A Data-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/TMM.2015.2483370\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c0e5f4a89befc58b305ae6fa0461f7f6301266e\",\"title\":\"Predicting Eye Fixations on Webpage With an Ensemble of Early Features and High-Level Representations from Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/5c0e5f4a89befc58b305ae6fa0461f7f6301266e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40257358\",\"name\":\"He Tang\"},{\"authorId\":\"2500502\",\"name\":\"Chuanbo Chen\"},{\"authorId\":\"31564288\",\"name\":\"Xiaobing Pei\"}],\"doi\":\"10.1007/s11042-016-4248-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2fa9a636794c9e1a353d883c08fd1b9af799171\",\"title\":\"Saliency detection from one time sampling for eye fixation prediction\",\"url\":\"https://www.semanticscholar.org/paper/d2fa9a636794c9e1a353d883c08fd1b9af799171\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34636768\",\"name\":\"L. Matzen\"},{\"authorId\":\"34560661\",\"name\":\"M. Haass\"},{\"authorId\":\"3424845\",\"name\":\"Kristin M. Divis\"},{\"authorId\":\"34913431\",\"name\":\"Z. Wang\"},{\"authorId\":\"145771264\",\"name\":\"A. Wilson\"}],\"doi\":\"10.1109/TVCG.2017.2743939\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6587631a579de49695ff3f4b8d8f60f7e8ad4105\",\"title\":\"Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/6587631a579de49695ff3f4b8d8f60f7e8ad4105\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"title\":\"Computational modeling for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"46363837\",\"name\":\"K. Aizawa\"},{\"authorId\":\"144990548\",\"name\":\"Go Irie\"}],\"doi\":\"10.1007/s11042-020-09474-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"title\":\"Computational attention model for children, adults and the elderly\",\"url\":\"https://www.semanticscholar.org/paper/ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4800511\",\"name\":\"Don Adjeroh\"},{\"authorId\":\"49014513\",\"name\":\"T. Bell\"},{\"authorId\":\"143887818\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"143783379\",\"name\":\"Yonina C. Eldar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"edd9d3323c451b1b25da1d624324f45024e17075\",\"title\":\"Foundations and Trends R \\u00a9 in Signal Processing\",\"url\":\"https://www.semanticscholar.org/paper/edd9d3323c451b1b25da1d624324f45024e17075\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145302718\",\"name\":\"L. Qi\"},{\"authorId\":\"3082125\",\"name\":\"P. Yin\"},{\"authorId\":\"2319012\",\"name\":\"Xiayuan Huang\"},{\"authorId\":\"48543280\",\"name\":\"Ken Chen\"},{\"authorId\":\"145158703\",\"name\":\"Hong Qiao\"}],\"doi\":\"10.1109/WCICA.2016.7578543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927f86a6498e2a528f025e86782ce4ede317ae0b\",\"title\":\"Transfer classification for distinct manifestations with shared information\",\"url\":\"https://www.semanticscholar.org/paper/927f86a6498e2a528f025e86782ce4ede317ae0b\",\"venue\":\"2016 12th World Congress on Intelligent Control and Automation (WCICA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39879254\",\"name\":\"J. Zhang\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":null,\"name\":\"Jun Gao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1145/3107956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c53d869a767acb7f25488dbb00668c8c9f72466d\",\"title\":\"Saliency Detection on Light Field\",\"url\":\"https://www.semanticscholar.org/paper/c53d869a767acb7f25488dbb00668c8c9f72466d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556862\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"145849768\",\"name\":\"J. Qin\"}],\"doi\":\"10.1117/1.JEI.28.3.033033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07abe8e63d233a9e8cb5c8267df1d2024d179270\",\"title\":\"Evaluation of bottom-up saliency model using deep features pretrained by deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/07abe8e63d233a9e8cb5c8267df1d2024d179270\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1601.02852\",\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"225058b5b34c8ac42b07edaaf59186d440961f90\",\"title\":\"Human Attention Estimation for Natural Images: An Automatic Gaze Refinement Approach\",\"url\":\"https://www.semanticscholar.org/paper/225058b5b34c8ac42b07edaaf59186d440961f90\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766762\",\"name\":\"W. Bischof\"},{\"authorId\":\"115677025\",\"name\":\"Nicola C Anderson\"},{\"authorId\":\"3124688\",\"name\":\"A. Kingstone\"}],\"doi\":\"10.1007/978-3-030-20085-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"659cff5fd1047907d12af1ee825ea796afef72ff\",\"title\":\"Temporal Methods for Eye Movement Analysis\",\"url\":\"https://www.semanticscholar.org/paper/659cff5fd1047907d12af1ee825ea796afef72ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1512.07108\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"1859486\",\"name\":\"Jason Kuen\"},{\"authorId\":\"2139431\",\"name\":\"Lianyang Ma\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"66506222\",\"name\":\"T. Liu\"},{\"authorId\":\"50141018\",\"name\":\"X. Wang\"},{\"authorId\":\"50248285\",\"name\":\"Gang Wang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"6955999\",\"name\":\"T. Chen\"}],\"doi\":\"10.1016/j.patcog.2017.10.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1193317829bfcc9b9dffa5ae85a2e2114254b37e\",\"title\":\"Recent advances in convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/1193317829bfcc9b9dffa5ae85a2e2114254b37e\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1807.10576\",\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"},{\"authorId\":\"145467467\",\"name\":\"M. Gori\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6fcfc9458dbb045a886d9ad185edeb210932148\",\"title\":\"Visual Attention driven by Convolutional Features\",\"url\":\"https://www.semanticscholar.org/paper/a6fcfc9458dbb045a886d9ad185edeb210932148\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2267017\",\"name\":\"M. Stengel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0aa74ae2e0a09953e7278c7ebec424eda156b1be\",\"title\":\"Gaze-contingent Computer Graphics\",\"url\":\"https://www.semanticscholar.org/paper/0aa74ae2e0a09953e7278c7ebec424eda156b1be\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"8152707\",\"name\":\"J. Lee\"},{\"authorId\":\"17822951\",\"name\":\"Wen-Chih Lo\"},{\"authorId\":\"2194011\",\"name\":\"C. Huang\"},{\"authorId\":\"6270307\",\"name\":\"Kuan-Ta Chen\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17bdb86d52e43cd96b50c45c50052861bbe4e4d5\",\"title\":\"Fixation Prediction for 360 \\u00b0 Video Streaming to Head-Mounted Displays\",\"url\":\"https://www.semanticscholar.org/paper/17bdb86d52e43cd96b50c45c50052861bbe4e4d5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2017.370\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"title\":\"Attentional Push: A Deep Convolutional Network for Augmenting Image Salience with Shared Attention Modeling in Social Scenes\",\"url\":\"https://www.semanticscholar.org/paper/9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"Lorenzo Baraldi\"},{\"authorId\":\"145518528\",\"name\":\"G. Serra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"title\":\"1 Paying More A ention to Saliency : Image Captioning with Saliency and Context A ention\",\"url\":\"https://www.semanticscholar.org/paper/96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"9284635\",\"name\":\"Hongmei Song\"},{\"authorId\":\"152836879\",\"name\":\"Shuyang Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/CVPR.2019.00318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f53761ea6276df40089753a4e008d1283f28e768\",\"title\":\"Learning Unsupervised Video Object Segmentation Through Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f53761ea6276df40089753a4e008d1283f28e768\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.01432\",\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"145140331\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"150344105\",\"name\":\"Xiaofu Jin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"title\":\"An End-to-End Neural Network for Image Cropping by Learning Composition from Aesthetic Photos\",\"url\":\"https://www.semanticscholar.org/paper/dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2017.354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"034cf7f98153dada78bcffc72ed5a13890482a94\",\"title\":\"Learning Visual Attention to Identify People with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/034cf7f98153dada78bcffc72ed5a13890482a94\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144985887\",\"name\":\"Y. Hu\"},{\"authorId\":\"1715231\",\"name\":\"Zenghai Chen\"},{\"authorId\":\"8590720\",\"name\":\"Z. Chi\"},{\"authorId\":\"144977049\",\"name\":\"Hong Fu\"}],\"doi\":\"10.1109/SMC.2015.310\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec86df26be0a6d147f9235ae3c9f35caaad661f9\",\"title\":\"Learning to Detect Saliency with Deep Structure\",\"url\":\"https://www.semanticscholar.org/paper/ec86df26be0a6d147f9235ae3c9f35caaad661f9\",\"venue\":\"2015 IEEE International Conference on Systems, Man, and Cybernetics\",\"year\":2015},{\"arxivId\":\"2009.06886\",\"authors\":[{\"authorId\":\"1492115154\",\"name\":\"Jinquan Li\"},{\"authorId\":\"1486405312\",\"name\":\"Ling Pei\"},{\"authorId\":\"71078457\",\"name\":\"Danping Zou\"},{\"authorId\":\"1944162339\",\"name\":\"Songpengcheng Xia\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"153051030\",\"name\":\"T. Li\"},{\"authorId\":\"145522783\",\"name\":\"Z. Sun\"},{\"authorId\":\"1969144\",\"name\":\"W. Yu\"}],\"doi\":\"10.1109/jsen.2020.3038432\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c902ed986820670e7a929ab5d20b732a8b4ef47\",\"title\":\"Attention-SLAM: A Visual Monocular SLAM Learning from Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/3c902ed986820670e7a929ab5d20b732a8b4ef47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1411.1045\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"title\":\"Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet\",\"url\":\"https://www.semanticscholar.org/paper/652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24962320\",\"name\":\"T. Uejima\"},{\"authorId\":\"1491180171\",\"name\":\"Ernst Niebur\"},{\"authorId\":\"1398026219\",\"name\":\"R. Etienne-Cummings\"}],\"doi\":\"10.3389/fncom.2020.541581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d800b1df83ab5408c4cb2c84edbd679fb5970473\",\"title\":\"Proto-Object Based Saliency Model With Texture Detection Channel\",\"url\":\"https://www.semanticscholar.org/paper/d800b1df83ab5408c4cb2c84edbd679fb5970473\",\"venue\":\"Frontiers in Computational Neuroscience\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"51266101\",\"name\":\"Nimol Thuon\"},{\"authorId\":\"9289244\",\"name\":\"Seng Kheang\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"}],\"doi\":\"10.1109/ICIP.2018.8451809\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"262ca560946e754c24d7072fe50ad2f2d630b058\",\"title\":\"Do Deep-Learning Saliency Models Really Model Saliency?\",\"url\":\"https://www.semanticscholar.org/paper/262ca560946e754c24d7072fe50ad2f2d630b058\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774497\",\"name\":\"D. Sen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s11045-016-0456-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1ba697bf5cc98687a4f7801d7b66a105f1bc876\",\"title\":\"Early biological vision inspired system for salience computation in images\",\"url\":\"https://www.semanticscholar.org/paper/f1ba697bf5cc98687a4f7801d7b66a105f1bc876\",\"venue\":\"Multidimens. Syst. Signal Process.\",\"year\":2018},{\"arxivId\":\"1807.05511\",\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"144528245\",\"name\":\"P. Zheng\"},{\"authorId\":\"51132438\",\"name\":\"Shou-tao Xu\"},{\"authorId\":\"1748808\",\"name\":\"X. Wu\"}],\"doi\":\"10.1109/TNNLS.2018.2876865\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7998468d99ab07bb982294d1c9b53a3bf3934fa6\",\"title\":\"Object Detection With Deep Learning: A Review\",\"url\":\"https://www.semanticscholar.org/paper/7998468d99ab07bb982294d1c9b53a3bf3934fa6\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406772141\",\"name\":\"Andre V Harrison\"},{\"authorId\":\"50153678\",\"name\":\"M. Green\"},{\"authorId\":\"1971623\",\"name\":\"C. Hung\"},{\"authorId\":\"19251475\",\"name\":\"A. Raglin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a051a445915f700e3147529285622013effef5bc\",\"title\":\"The Consistency of Visual Search Models on High Dynamic Range and Tone Mapped Images\",\"url\":\"https://www.semanticscholar.org/paper/a051a445915f700e3147529285622013effef5bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1709.04595\",\"authors\":[{\"authorId\":\"46599199\",\"name\":\"Debang Li\"},{\"authorId\":\"9947552\",\"name\":\"Huikai Wu\"},{\"authorId\":\"2086001\",\"name\":\"Junge Zhang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f77ac7fa6cb2f25f3867cefca82452ec04ffef06\",\"title\":\"A2-RL: Aesthetics Aware Reinforcement Learning for Automatic Image Cropping\",\"url\":\"https://www.semanticscholar.org/paper/f77ac7fa6cb2f25f3867cefca82452ec04ffef06\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3486445\",\"name\":\"Guillaume Lio\"},{\"authorId\":\"5615932\",\"name\":\"R. Fadda\"},{\"authorId\":\"3804703\",\"name\":\"G. Doneddu\"},{\"authorId\":\"50117547\",\"name\":\"J. Duhamel\"},{\"authorId\":\"2643325\",\"name\":\"A. Sirigu\"}],\"doi\":\"10.1038/s41467-019-13285-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddfa5afa2f18715619946bf0b99633849412d89d\",\"title\":\"Digit-tracking as a new tactile interface for visual perception analysis\",\"url\":\"https://www.semanticscholar.org/paper/ddfa5afa2f18715619946bf0b99633849412d89d\",\"venue\":\"Nature Communications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"776f18ba98b7028b72dccc579b2771f1aeff199f\",\"title\":\"Emergence of Proto-Object Representations via Fixations in Low-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/776f18ba98b7028b72dccc579b2771f1aeff199f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152347102\",\"name\":\"F. Yu\"},{\"authorId\":\"30490097\",\"name\":\"Haonan Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3343031.3350931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47e8c51d8293eb59416456179c606cb3ae08692\",\"title\":\"Instance of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/c47e8c51d8293eb59416456179c606cb3ae08692\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"94395930\",\"name\":\"Francois Tison\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"},{\"authorId\":\"1961187\",\"name\":\"A. Zemmari\"}],\"doi\":\"10.1007/s11042-017-4796-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10b67a5d0be144b7b4f0086709653dd8f2583b8f\",\"title\":\"Prediction of visual attention with deep CNN on artificially degraded videos for studies of attention of patients with Dementia\",\"url\":\"https://www.semanticscholar.org/paper/10b67a5d0be144b7b4f0086709653dd8f2583b8f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"},{\"authorId\":\"145467467\",\"name\":\"M. Gori\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b524d278dd11eecd2bbd156d3c014cd8575c4036\",\"title\":\"Variational Laws of Visual Attention for Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b524d278dd11eecd2bbd156d3c014cd8575c4036\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47196521\",\"name\":\"Zhiyuan Wang\"},{\"authorId\":\"2516392\",\"name\":\"Simona Buetti\"},{\"authorId\":\"3224888\",\"name\":\"A. Lleras\"}],\"doi\":\"10.1525/COLLABRA.53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eac220b2b0dfc969a5ac0b46ca9cff1e2088a3e0\",\"title\":\"Predicting Search Performance in Heterogeneous Visual Search Scenes with Real-World Objects\",\"url\":\"https://www.semanticscholar.org/paper/eac220b2b0dfc969a5ac0b46ca9cff1e2088a3e0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1805.01047\",\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":\"10.1016/j.imavis.2020.103887\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"title\":\"EML-NET: An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904707\",\"name\":\"T. Foulsham\"}],\"doi\":\"10.1007/978-3-030-20085-5_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1735da3648759becea03fb3e8d4bc09c943e28d6\",\"title\":\"Scenes, saliency maps and scanpaths\",\"url\":\"https://www.semanticscholar.org/paper/1735da3648759becea03fb3e8d4bc09c943e28d6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.03571\",\"authors\":[{\"authorId\":\"144545126\",\"name\":\"S. Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TMM.2019.2947352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"023b11c04e5ea605fe999b015cbf62502cab068b\",\"title\":\"A Dilated Inception Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/023b11c04e5ea605fe999b015cbf62502cab068b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763785\",\"name\":\"Luming Zhang\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"1780668\",\"name\":\"Yingjie Xia\"}],\"doi\":\"10.1109/TCYB.2015.2400821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5120c8e0e2ce4bdce8a5474b55f5b5297e68170b\",\"title\":\"Weakly Supervised Human Fixations Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5120c8e0e2ce4bdce8a5474b55f5b5297e68170b\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"title\":\"Attentive Models in Vision 3 Input Image Human Fixation Map Loss Function Final Convolutional Layers Learned Prior Low , Medium and High Level Features Predicted Saliency Map Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1901.04908\",\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"}],\"doi\":\"10.1371/journal.pone.0224306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c5965c95288ed05f220ee3250b85391ee7016aa\",\"title\":\"Rapid visual categorization is not guided by early salience-based selection\",\"url\":\"https://www.semanticscholar.org/paper/8c5965c95288ed05f220ee3250b85391ee7016aa\",\"venue\":\"PloS one\",\"year\":2019},{\"arxivId\":\"2012.11863\",\"authors\":[{\"authorId\":\"1739174065\",\"name\":\"Ke Wang\"},{\"authorId\":\"1400359889\",\"name\":\"Sai Ma\"},{\"authorId\":\"1740146246\",\"name\":\"Junlan Chen\"},{\"authorId\":\"49301701\",\"name\":\"Jianbo Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"title\":\"Salient Bundle Adjustment for Visual SLAM\",\"url\":\"https://www.semanticscholar.org/paper/4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388070721\",\"name\":\"Alexander Makrigiorgos\"},{\"authorId\":\"144793784\",\"name\":\"Aldo Faisal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"867c8a5b96962d674e2f2978ad016e2fc86a468f\",\"title\":\"Improving Autonomous Driving Agents using Bio-Inspired Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/867c8a5b96962d674e2f2978ad016e2fc86a468f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1709.02495\",\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"145669352\",\"name\":\"Jun Qin\"},{\"authorId\":\"39333164\",\"name\":\"G. Crosby\"}],\"doi\":\"10.1109/TCDS.2019.2894561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c69f5261edb4dde001fcea4d32b06fdf9dd9358a\",\"title\":\"DeepFeat: A Bottom-Up and Top-Down Saliency Model Based on Deep Features of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c69f5261edb4dde001fcea4d32b06fdf9dd9358a\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153385438\",\"name\":\"A. Mane\"},{\"authorId\":\"151440546\",\"name\":\"S. Mali\"},{\"authorId\":\"90315386\",\"name\":\"Priyanka D. Mali\"},{\"authorId\":\"151426605\",\"name\":\"Sonam Mulik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9066cd93949c29c0197f4e4fceaf00888532f46d\",\"title\":\"International Journal of Scientific Research in Computer Science, Engineering and Information Technology\",\"url\":\"https://www.semanticscholar.org/paper/9066cd93949c29c0197f4e4fceaf00888532f46d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1412.7242\",\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef8560da3f8b9d52bce512c5084c1dd6430577e4\",\"title\":\"Learning of Proto-object Representations via Fixations on Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/ef8560da3f8b9d52bce512c5084c1dd6430577e4\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774497\",\"name\":\"D. Sen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.image.2015.02.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8395c4f5b005d0358e90063d3ce1ff41d5848baf\",\"title\":\"Salience computation in images based on perceptual distinctness\",\"url\":\"https://www.semanticscholar.org/paper/8395c4f5b005d0358e90063d3ce1ff41d5848baf\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":\"1409.7686\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"39928067\",\"name\":\"T. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.15496/PUBLIKATION-4858\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abfd3d1fb0c0117905978a470897db053dc7afbb\",\"title\":\"How close are we to understanding image-based saliency?\",\"url\":\"https://www.semanticscholar.org/paper/abfd3d1fb0c0117905978a470897db053dc7afbb\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1811.03736\",\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"title\":\"Semantic and Contrast-Aware Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50602193\",\"name\":\"J. Ling\"},{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"48379249\",\"name\":\"Yingxue Zhang\"},{\"authorId\":\"33413258\",\"name\":\"D. Yang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.image.2018.03.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ef7078b23d9e6f856ff082a82e0dc076219a5da\",\"title\":\"A saliency prediction model on 360 degree images using color dictionary based sparse representation\",\"url\":\"https://www.semanticscholar.org/paper/7ef7078b23d9e6f856ff082a82e0dc076219a5da\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1c0b216bd1b319e63a61c61501995e959e15af4\",\"title\":\"Modelling of Human Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/e1c0b216bd1b319e63a61c61501995e959e15af4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8443337\",\"name\":\"Xinsheng Zhang\"},{\"authorId\":\"47242215\",\"name\":\"Teng Gao\"},{\"authorId\":\"2611471\",\"name\":\"Dongdong Gao\"}],\"doi\":\"10.1007/s10617-018-9209-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e94ad50b60653b28c878a96883d6a253473960b4\",\"title\":\"A new deep spatial transformer convolutional neural network for image saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/e94ad50b60653b28c878a96883d6a253473960b4\",\"venue\":\"Des. Autom. Embed. Syst.\",\"year\":2018},{\"arxivId\":\"1604.08010\",\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2803728\",\"name\":\"O. Hadar\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"05d1e0ee52c5796aa58d16f176721348e6317e41\",\"title\":\"Deep Learning for Saliency Prediction in Natural Video\",\"url\":\"https://www.semanticscholar.org/paper/05d1e0ee52c5796aa58d16f176721348e6317e41\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"3332324\",\"name\":\"X. Zhao\"},{\"authorId\":\"47378234\",\"name\":\"R. Mo\"}],\"doi\":\"10.1007/978-3-030-00563-4_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"title\":\"Bottom-Up Saliency Prediction by Simulating End-Stopping with Log-Gabor\",\"url\":\"https://www.semanticscholar.org/paper/bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":\"2005.06583\",\"authors\":[{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f003e9630253d6f94708b10492ce747c7dfca13c\",\"title\":\"Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations\",\"url\":\"https://www.semanticscholar.org/paper/f003e9630253d6f94708b10492ce747c7dfca13c\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2019.2905607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"title\":\"Inferring Salient Objects from Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47783938\",\"name\":\"Navid Rabbani\"},{\"authorId\":\"145520808\",\"name\":\"B. Nazari\"},{\"authorId\":\"33380997\",\"name\":\"S. Sadri\"},{\"authorId\":\"6963036\",\"name\":\"Reyhaneh Rikhtehgaran\"}],\"doi\":\"10.1049/iet-ipr.2017.0267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa6440bfe84a6d79e470e41ac9e56c2e7b2243e8\",\"title\":\"Efficient Bayesian approach to saliency detection based on Dirichlet process mixture\",\"url\":\"https://www.semanticscholar.org/paper/aa6440bfe84a6d79e470e41ac9e56c2e7b2243e8\",\"venue\":\"IET Image Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"40351264\",\"name\":\"M. Waldner\"},{\"authorId\":\"1736888\",\"name\":\"I. Viola\"},{\"authorId\":\"3059024\",\"name\":\"P. Kapec\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"}],\"doi\":\"10.1016/j.cag.2018.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4bd14734b58cfb788755201b46bb61394773b57\",\"title\":\"Exploring visual attention and saliency modeling for task-based visual analysis\",\"url\":\"https://www.semanticscholar.org/paper/b4bd14734b58cfb788755201b46bb61394773b57\",\"venue\":\"Comput. Graph.\",\"year\":2018},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47956948\",\"name\":\"X. Zhang\"},{\"authorId\":\"143675266\",\"name\":\"Di Xiao\"},{\"authorId\":\"49298335\",\"name\":\"Jianhua Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/j.sigpro.2018.01.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0803a863fef31babeb193ad4b9ac66ecf92c9454\",\"title\":\"Predicting human gaze with multi-level information\",\"url\":\"https://www.semanticscholar.org/paper/0803a863fef31babeb193ad4b9ac66ecf92c9454\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145638781\",\"name\":\"R. Zhao\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2015.7298731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd126c7db89f1a66b17a6ef1152412876f4c0cbe\",\"title\":\"Saliency detection by multi-context deep learning\",\"url\":\"https://www.semanticscholar.org/paper/cd126c7db89f1a66b17a6ef1152412876f4c0cbe\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70123445\",\"name\":\"Duzhen Zhang\"},{\"authorId\":\"143814710\",\"name\":\"Z. Ali\"}],\"doi\":\"10.1142/S1469026819500093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dd268d78209640485160518b12f5f9a7f51f60f\",\"title\":\"Top-Down Saliency Detection Based on Deep-Learned Features\",\"url\":\"https://www.semanticscholar.org/paper/5dd268d78209640485160518b12f5f9a7f51f60f\",\"venue\":\"Int. J. Comput. Intell. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47474137\",\"name\":\"Ming Zhang\"},{\"authorId\":\"144987742\",\"name\":\"Yu Pang\"},{\"authorId\":\"50117961\",\"name\":\"Yun-He Wu\"},{\"authorId\":\"145669564\",\"name\":\"Yue Du\"},{\"authorId\":\"145959473\",\"name\":\"H. Sun\"},{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"}],\"doi\":\"10.1016/j.jvcir.2018.01.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f1e6730ab5679c05d480310e6b831bb0b90e8c6\",\"title\":\"Saliency detection via local structure propagation\",\"url\":\"https://www.semanticscholar.org/paper/2f1e6730ab5679c05d480310e6b831bb0b90e8c6\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48147500\",\"name\":\"R. Fong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7612cfd16038e90f633bb0d6836d39c775296c43\",\"title\":\"Leveraging Human Brain Activity to Improve Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/7612cfd16038e90f633bb0d6836d39c775296c43\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1412.6885\",\"authors\":[{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee89b903af1d8f26a8894a3773915c74f038883e\",\"title\":\"Half-CNN: A General Framework for Whole-Image Regression\",\"url\":\"https://www.semanticscholar.org/paper/ee89b903af1d8f26a8894a3773915c74f038883e\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"title\":\"Related Work 2 . 1 Visual Saliency Prediction Saliency maps\",\"url\":\"https://www.semanticscholar.org/paper/504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1807.10657\",\"authors\":[{\"authorId\":\"51149716\",\"name\":\"Taiki Oyama\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1049/TRIT.2018.1012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5df11c59e3b47189486445f5833675bf08359bfe\",\"title\":\"Influence of Image Classification Accuracy on Saliency Map Estimation\",\"url\":\"https://www.semanticscholar.org/paper/5df11c59e3b47189486445f5833675bf08359bfe\",\"venue\":\"CAAI Trans. Intell. Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"46275685\",\"name\":\"J. Li\"}],\"doi\":\"10.4018/IJMDEM.2018040101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23e9027929a40d78b19ad3371331e19d8a3a9435\",\"title\":\"A Randomized Framework for Estimating Image Saliency Through Sparse Signal Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/23e9027929a40d78b19ad3371331e19d8a3a9435\",\"venue\":\"Int. J. Multim. Data Eng. Manag.\",\"year\":2018},{\"arxivId\":\"1703.00152\",\"authors\":[{\"authorId\":\"1830032\",\"name\":\"N. Imamoglu\"},{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"},{\"authorId\":\"49359527\",\"name\":\"Wataru Shimoda\"},{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"35580784\",\"name\":\"Boxin Shi\"}],\"doi\":\"10.1109/ICIP.2017.8296317\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00a3cc3b431f3deed91d5b3b06c3ecc9e21c9fcd\",\"title\":\"Saliency detection by forward and backward cues in deep-CNN\",\"url\":\"https://www.semanticscholar.org/paper/00a3cc3b431f3deed91d5b3b06c3ecc9e21c9fcd\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1882027\",\"name\":\"Henny Admoni\"},{\"authorId\":\"1798776\",\"name\":\"Thomas Weng\"},{\"authorId\":\"1792053\",\"name\":\"B. Scassellati\"}],\"doi\":\"10.1109/ICRA.2016.7487510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d94472e619f5ccec9eac93bc774037720acecec\",\"title\":\"Modeling communicative behaviors for object references in human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/2d94472e619f5ccec9eac93bc774037720acecec\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2018.00250\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"title\":\"SAM: Pushing the Limits of Saliency Prediction Models\",\"url\":\"https://www.semanticscholar.org/paper/cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"102316342\",\"name\":\"Guizhong Fu\"},{\"authorId\":\"2491927\",\"name\":\"Jiangxin Yang\"},{\"authorId\":\"2035529\",\"name\":\"Yanlong Cao\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"}],\"doi\":\"10.1016/J.IMAGE.2019.06.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc7f41b7047a139134dbad04b8fa8f86d1b9946b\",\"title\":\"Accurate salient object detection via dense recurrent connections and residual-based hierarchical feature integration\",\"url\":\"https://www.semanticscholar.org/paper/cc7f41b7047a139134dbad04b8fa8f86d1b9946b\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2016.2628878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf18c239a819dc179d4261fdfb39d16f0356b8d3\",\"title\":\"Learning to Predict Eye Fixations via Multiresolution Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cf18c239a819dc179d4261fdfb39d16f0356b8d3\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.3233/IA-170033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"title\":\"Attentive models in vision: Computing saliency maps in the deep learning era\",\"url\":\"https://www.semanticscholar.org/paper/9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"venue\":\"Intelligenza Artificiale\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31891434\",\"name\":\"M. Weier\"},{\"authorId\":\"2267017\",\"name\":\"M. Stengel\"},{\"authorId\":\"39564547\",\"name\":\"T. Roth\"},{\"authorId\":\"3307078\",\"name\":\"P. Didyk\"},{\"authorId\":\"1737690\",\"name\":\"E. Eisemann\"},{\"authorId\":\"1701306\",\"name\":\"M. Eisemann\"},{\"authorId\":\"2860857\",\"name\":\"S. Grogorick\"},{\"authorId\":\"1759479\",\"name\":\"Andr\\u00e9 Hinkenjann\"},{\"authorId\":\"2339768\",\"name\":\"E. Kruijff\"},{\"authorId\":\"1686739\",\"name\":\"M. Magnor\"},{\"authorId\":\"1790911\",\"name\":\"K. Myszkowski\"},{\"authorId\":\"143673845\",\"name\":\"P. Slusallek\"}],\"doi\":\"10.1111/cgf.13150\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09cea76619fcf634a6fed58f36a057165e006958\",\"title\":\"Perception\\u2010driven Accelerated Rendering\",\"url\":\"https://www.semanticscholar.org/paper/09cea76619fcf634a6fed58f36a057165e006958\",\"venue\":\"Comput. Graph. Forum\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1809.00644\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"title\":\"Learning Saliency Prediction From Sparse Fixation Pixel Map\",\"url\":\"https://www.semanticscholar.org/paper/155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145931655\",\"name\":\"Jianmin Jiang\"}],\"doi\":\"10.1109/TIP.2020.2985531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"917666c6ff2993f75dd77009ca41e69c81369707\",\"title\":\"Learning to Explore Saliency for Stereoscopic Videos Via Component-Based Interaction\",\"url\":\"https://www.semanticscholar.org/paper/917666c6ff2993f75dd77009ca41e69c81369707\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1811.10004\",\"authors\":[{\"authorId\":\"21319564\",\"name\":\"J. Li\"},{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"title\":\"Visual Attention on the Sun: What Do Existing Models Actually Predict?\",\"url\":\"https://www.semanticscholar.org/paper/6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/TPAMI.2018.2840724\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"title\":\"A Deep Network Solution for Attention and Aesthetics Aware Photo Cropping\",\"url\":\"https://www.semanticscholar.org/paper/55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1007/S00500-017-2931-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ecf109e9292f040bce121086065f48391739999\",\"title\":\"A soft-computing-based approach to artificial visual attention using human eye-fixation paradigm: toward a human-like skill in robot vision\",\"url\":\"https://www.semanticscholar.org/paper/0ecf109e9292f040bce121086065f48391739999\",\"venue\":\"Soft Comput.\",\"year\":2019},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1007/978-3-319-19258-1_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c3e8c5618846e88cd2edb59cc93ca3c00a8c4b\",\"title\":\"From Human Eye Fixation to Human-like Autonomous Artificial Vision\",\"url\":\"https://www.semanticscholar.org/paper/51c3e8c5618846e88cd2edb59cc93ca3c00a8c4b\",\"venue\":\"IWANN\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46614560\",\"name\":\"A. Verma\"},{\"authorId\":\"144774497\",\"name\":\"D. Sen\"}],\"doi\":\"10.23919/EUSIPCO.2019.8902643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46e752ef221c95dd367ce28165d198d179bba5dc\",\"title\":\"HMM-based Convolutional LSTM for Visual Scanpath Prediction\",\"url\":\"https://www.semanticscholar.org/paper/46e752ef221c95dd367ce28165d198d179bba5dc\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":\"1504.06755\",\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"2507239\",\"name\":\"Y. Zhang\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"1697413\",\"name\":\"S. Kulkarni\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3433627f803953280b66ae1576d083fc9a68385a\",\"title\":\"TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking\",\"url\":\"https://www.semanticscholar.org/paper/3433627f803953280b66ae1576d083fc9a68385a\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1812.08848\",\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3211787\",\"name\":\"Toni Kunic\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"52349494\",\"name\":\"Ramin Fahimi\"},{\"authorId\":\"27737461\",\"name\":\"Nicholas Frosst\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b8a26d45c8f1c058a4454792d7c43c05ca5f76a\",\"title\":\"SMILER: Saliency Model Implementation Library for Experimental Research\",\"url\":\"https://www.semanticscholar.org/paper/6b8a26d45c8f1c058a4454792d7c43c05ca5f76a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1882027\",\"name\":\"Henny Admoni\"}],\"doi\":\"10.1145/3008665.3008669\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7da6245f822c4bf9a7c8e44f10cef7f1dd1f495\",\"title\":\"Nonverbal communication in socially assistive human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/e7da6245f822c4bf9a7c8e44f10cef7f1dd1f495\",\"venue\":\"SIGAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145656562\",\"name\":\"M. Liang\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/TIP.2015.2395713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca0834f09dd62c17d6742a42a36cb006c45d480f\",\"title\":\"Predicting Eye Fixations With Higher-Level Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/ca0834f09dd62c17d6742a42a36cb006c45d480f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":\"1710.03011\",\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"},{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"46380769\",\"name\":\"Jingyi Yu\"}],\"doi\":\"10.1109/TPAMI.2018.2866563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"title\":\"Personalized Saliency and Its Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1472873014\",\"name\":\"Soonbin Lee\"},{\"authorId\":\"1384054834\",\"name\":\"Dongmin Jang\"},{\"authorId\":\"51299242\",\"name\":\"J. Jeong\"},{\"authorId\":\"3388495\",\"name\":\"Sangsoon Lee\"},{\"authorId\":\"2267529\",\"name\":\"E. Ryu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d545af4fb2cff72a6405ef57df1fd573a46d702\",\"title\":\"Tile-Based 360 Degree Video Streaming System with User\\u2019s gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/2d545af4fb2cff72a6405ef57df1fd573a46d702\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"}],\"doi\":\"10.1101/207076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbbdef149409f8805d414f129d3e3530e92871c9\",\"title\":\"Meaning Guides Attention in Real-World Scene Images: Evidence from Eye Movements and Meaning Maps\",\"url\":\"https://www.semanticscholar.org/paper/dbbdef149409f8805d414f129d3e3530e92871c9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1704.01761\",\"authors\":[{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"145621995\",\"name\":\"S. Barthelm\\u00e9\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"}],\"doi\":\"10.1167/19.6.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14a0c4ea64ab1953f97382dc177d12cf340eb042\",\"title\":\"Spatial statistics for gaze patterns in scene viewing: Effects of repeated viewing.\",\"url\":\"https://www.semanticscholar.org/paper/14a0c4ea64ab1953f97382dc177d12cf340eb042\",\"venue\":\"Journal of vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763785\",\"name\":\"Luming Zhang\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144833357\",\"name\":\"L. Hong\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TMM.2015.2451954\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c63785382c6b75d673c553bae09bfe505aef8be\",\"title\":\"Retargeting Semantically-Rich Photos\",\"url\":\"https://www.semanticscholar.org/paper/7c63785382c6b75d673c553bae09bfe505aef8be\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700619\",\"name\":\"Jing Liu\"},{\"authorId\":\"3493187\",\"name\":\"Jincheng Lv\"},{\"authorId\":\"2026992233\",\"name\":\"Min Yuan\"},{\"authorId\":\"50560979\",\"name\":\"J. Zhang\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/LSP.2020.3035065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"title\":\"ABSNet: Aesthetics-Based Saliency Network Using Multi-Task Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a654db1b4955fb58930f292716a60214113e159a\",\"title\":\"Early Salient Region Selection Does Not Drive Rapid Visual Categorization\",\"url\":\"https://www.semanticscholar.org/paper/a654db1b4955fb58930f292716a60214113e159a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1807.01532\",\"authors\":[{\"authorId\":\"1830032\",\"name\":\"N. Imamoglu\"},{\"authorId\":\"49359527\",\"name\":\"Wataru Shimoda\"},{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"},{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"},{\"authorId\":\"48762248\",\"name\":\"Y. Nishida\"}],\"doi\":\"10.1007/s11760-017-1159-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e751f0f984a421a0a2b8e96584dbe1a7da9e82e4\",\"title\":\"An integration of bottom-up and top-down salient cues on RGB-D data: saliency from objectness versus non-objectness\",\"url\":\"https://www.semanticscholar.org/paper/e751f0f984a421a0a2b8e96584dbe1a7da9e82e4\",\"venue\":\"Signal Image Video Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50562082\",\"name\":\"J. Zhang\"},{\"authorId\":\"3106442\",\"name\":\"F. Malmberg\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-030-04831-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5628b41a109510d8c04c127a384b48c51afacb2\",\"title\":\"Boolean Map Saliency: A Surprisingly Simple Method\",\"url\":\"https://www.semanticscholar.org/paper/e5628b41a109510d8c04c127a384b48c51afacb2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.13839\",\"authors\":[{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ba67b0734477ff392367f52542ad2dab179da83\",\"title\":\"Saliency Prediction with External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/4ba67b0734477ff392367f52542ad2dab179da83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33676410\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1763785\",\"name\":\"Luming Zhang\"},{\"authorId\":null,\"name\":\"Chao Zhang\"},{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TIP.2017.2779272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddc17537f7895464523b5aff77d41d756a12bf18\",\"title\":\"Perceptually Aware Image Retargeting for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/ddc17537f7895464523b5aff77d41d756a12bf18\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29398271\",\"name\":\"Keigo Ishikura\"},{\"authorId\":\"29418459\",\"name\":\"N. Kurita\"},{\"authorId\":\"13113212\",\"name\":\"D. Chandler\"},{\"authorId\":\"2014433\",\"name\":\"G. Ohashi\"}],\"doi\":\"10.1109/TIP.2017.2767288\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"107c6f258986e8574f2924d119518f60b57b019b\",\"title\":\"Saliency Detection Based on Multiscale Extrema of Local Perceptual Color Differences\",\"url\":\"https://www.semanticscholar.org/paper/107c6f258986e8574f2924d119518f60b57b019b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"315511e474b59b6469f5697e8b4e4abd14663b66\",\"title\":\"Human attention simulation on nature scenes in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/315511e474b59b6469f5697e8b4e4abd14663b66\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32202794\",\"name\":\"Johanna Elisa Silberg\"},{\"authorId\":\"3363882\",\"name\":\"I. Agtzidis\"},{\"authorId\":\"3387551\",\"name\":\"M. Startsev\"},{\"authorId\":\"32018004\",\"name\":\"Teresa Fasshauer\"},{\"authorId\":\"6491939\",\"name\":\"Karen Silling\"},{\"authorId\":\"145300422\",\"name\":\"A. Sprenger\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2028168\",\"name\":\"R. Lencer\"}],\"doi\":\"10.1007/s00406-017-0863-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18a78e1bd806a2a91ddda4bc35696aa21f0234f3\",\"title\":\"Free visual exploration of natural movies in schizophrenia\",\"url\":\"https://www.semanticscholar.org/paper/18a78e1bd806a2a91ddda4bc35696aa21f0234f3\",\"venue\":\"European Archives of Psychiatry and Clinical Neuroscience\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34570209\",\"name\":\"Kshitij Dwivedi\"},{\"authorId\":\"145729589\",\"name\":\"Nitin Singh\"},{\"authorId\":\"1392783891\",\"name\":\"Sabari R. Shanmugham\"},{\"authorId\":\"153792660\",\"name\":\"M. Kumar\"}],\"doi\":\"10.1007/978-981-32-9291-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"title\":\"DeepAttent: Saliency Prediction with Deep Multi-scale Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6271074\",\"name\":\"Kirsten A Dalrymple\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"3048594\",\"name\":\"J. Elison\"}],\"doi\":\"10.1038/s41598-019-42764-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5920514d8807b434fed19cb938c9a434b6979265\",\"title\":\"Machine learning accurately classifies age of toddlers based on eye tracking\",\"url\":\"https://www.semanticscholar.org/paper/5920514d8807b434fed19cb938c9a434b6979265\",\"venue\":\"Scientific Reports\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351052\",\"name\":\"Milind S. Gide\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1561/2000000055\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"783296b4846ca4dbc2ee5aa11319bfc86e1acbcd\",\"title\":\"Computational Visual Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/783296b4846ca4dbc2ee5aa11319bfc86e1acbcd\",\"venue\":\"Found. Trends Signal Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771700\",\"name\":\"K. Wang\"},{\"authorId\":\"1883826\",\"name\":\"S. Wang\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1145/2857491.2857515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71faaa29079862320e2417d87f3109ca88916238\",\"title\":\"Deep eye fixation map learning for calibration-free eye gaze tracking\",\"url\":\"https://www.semanticscholar.org/paper/71faaa29079862320e2417d87f3109ca88916238\",\"venue\":\"ETRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679171\",\"name\":\"T. Mauthner\"},{\"authorId\":\"1720811\",\"name\":\"Horst Possegger\"},{\"authorId\":\"1903921\",\"name\":\"Georg Waltner\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1109/CVPR.2015.7298864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb1ea76ebb2653816fe2a48e4b224424b25fca20\",\"title\":\"Encoding based saliency detection for videos and images\",\"url\":\"https://www.semanticscholar.org/paper/cb1ea76ebb2653816fe2a48e4b224424b25fca20\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.04972\",\"authors\":[{\"authorId\":\"1739108\",\"name\":\"Chuan-Yung Tsai\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"78436256ff8f2e448b28e854ebec5e8d8306cf21\",\"title\":\"Measuring and Understanding Sensory Representations within Deep Networks Using a Numerical Optimization Framework\",\"url\":\"https://www.semanticscholar.org/paper/78436256ff8f2e448b28e854ebec5e8d8306cf21\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1507.01422\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b37efd3987c1e625b063a6998bd6b282c844915\",\"title\":\"End-to-end Convolutional Network for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4b37efd3987c1e625b063a6998bd6b282c844915\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/TPAMI.2015.2473844\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"title\":\"Exploiting Surroundedness for Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27651985\",\"name\":\"Austin Le\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"title\":\"Predicting Visual Saliency : Where Do People Look ?\",\"url\":\"https://www.semanticscholar.org/paper/0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c89d3b0945d60697dbfd2a93e2dba30f767eb0a4\",\"title\":\"UNDERSTANDING AND PREDICTING HUMAN VISUAL ATTENTION\",\"url\":\"https://www.semanticscholar.org/paper/c89d3b0945d60697dbfd2a93e2dba30f767eb0a4\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3126965\",\"name\":\"Xiaoxu Cai\"},{\"authorId\":\"2059604\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1117/12.2306421\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58b67c9d88c5a9ff8c9235e153b85c75e2ad54d7\",\"title\":\"Saliency detection by conditional generative adversarial network\",\"url\":\"https://www.semanticscholar.org/paper/58b67c9d88c5a9ff8c9235e153b85c75e2ad54d7\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"injiang Wanga\"},{\"authorId\":null,\"name\":\"Yulin Maa\"},{\"authorId\":null,\"name\":\"Laibin Zhanga\"},{\"authorId\":null,\"name\":\"Robert X. Gaob\"},{\"authorId\":null,\"name\":\"Dazhong Wuc\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"96d3ab6aea753c9f1393b7b9ea7e3f0351d739c1\",\"title\":\"eep learning for smart manufacturing : Methods and applications\",\"url\":\"https://www.semanticscholar.org/paper/96d3ab6aea753c9f1393b7b9ea7e3f0351d739c1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49637078\",\"name\":\"W. Shan\"},{\"authorId\":\"2272337\",\"name\":\"Guangling Sun\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"}],\"doi\":\"10.1007/978-3-319-67777-4_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d6b7f92c05161ac3d65ad9e10571ab2bf507945\",\"title\":\"Two-Stage Transfer Learning of End-to-End Convolutional Neural Networks for Webpage Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4d6b7f92c05161ac3d65ad9e10571ab2bf507945\",\"venue\":\"IScIDE\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40108647\",\"name\":\"B. Yang\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"144423422\",\"name\":\"L. Chen\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/TBC.2016.2617291\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4a0dbfec5e4a2f10dfc0ecf9c99e6e23aa77fd1\",\"title\":\"Principal Component Analysis-Based Visual Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/f4a0dbfec5e4a2f10dfc0ecf9c99e6e23aa77fd1\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2018.00785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"title\":\"Emotional Attention: A Study of Image Sentiment and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1073/pnas.1510393112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01058e4aabd61571da9e43a618834c90aabaf691\",\"title\":\"Information-theoretic model comparison unifies saliency metrics\",\"url\":\"https://www.semanticscholar.org/paper/01058e4aabd61571da9e43a618834c90aabaf691\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/CVPR.2016.617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"560ae4902c7e4a5a72edf629669439bd48ae46de\",\"title\":\"Exemplar-Driven Top-Down Saliency Detection via Deep Association\",\"url\":\"https://www.semanticscholar.org/paper/560ae4902c7e4a5a72edf629669439bd48ae46de\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2470063\",\"name\":\"Yuzhu Ji\"},{\"authorId\":\"2427559\",\"name\":\"H. Zhang\"},{\"authorId\":\"1750296\",\"name\":\"K. Tseng\"},{\"authorId\":\"144134805\",\"name\":\"T. Chow\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1016/j.neucom.2018.09.081\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91f0e1376667025d230af6d5bb8592ef28a2396d\",\"title\":\"Graph model-based salient object detection using objectness and multiple saliency cues\",\"url\":\"https://www.semanticscholar.org/paper/91f0e1376667025d230af6d5bb8592ef28a2396d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1803.00127\",\"authors\":[{\"authorId\":\"3345547\",\"name\":\"Huai-Jen Liang\"},{\"authorId\":\"9217768\",\"name\":\"N. J. Sanket\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1109/TASE.2019.2900980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52e19729230252b7f77b20a644921949f755aa37\",\"title\":\"SalientDSO: Bringing Attention to Direct Sparse Odometry\",\"url\":\"https://www.semanticscholar.org/paper/52e19729230252b7f77b20a644921949f755aa37\",\"venue\":\"IEEE Transactions on Automation Science and Engineering\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-54407-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa804644b886535440db045117a1375b47536c76\",\"title\":\"Bottom-Up Fixation Prediction Using Unsupervised Hierarchical Models\",\"url\":\"https://www.semanticscholar.org/paper/aa804644b886535440db045117a1375b47536c76\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"2011.10432\",\"authors\":[{\"authorId\":\"30718292\",\"name\":\"G. Pantazis\"},{\"authorId\":\"2494584\",\"name\":\"G. Dimas\"},{\"authorId\":\"143932347\",\"name\":\"D. Iakovidis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"198a8cba6c8692a3526ed7f1c2bfa276fa0c5adc\",\"title\":\"SalSum: Saliency-based Video Summarization using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/198a8cba6c8692a3526ed7f1c2bfa276fa0c5adc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.05759\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1da3e74e10b8fe2708c81ddabb480e8d7929a589\",\"title\":\"Salient Region Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1da3e74e10b8fe2708c81ddabb480e8d7929a589\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00184\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"41aa48241071f8fa15145c3452679aa91c13459e\",\"title\":\"Salient Object Detection Driven by Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/41aa48241071f8fa15145c3452679aa91c13459e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.05002\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"title\":\"Light-weighted Saliency Detection with Distinctively Lower Memory Cost and Model Size\",\"url\":\"https://www.semanticscholar.org/paper/8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"49446198\",\"name\":\"M. Mitrea\"}],\"doi\":\"10.1109/IPTA.2017.8310116\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df50d71178c13b6e26fd926cbf0ae2bccd0c669c\",\"title\":\"Extraction of saliency in images and video: Problems, methods and applications. A survey\",\"url\":\"https://www.semanticscholar.org/paper/df50d71178c13b6e26fd926cbf0ae2bccd0c669c\",\"venue\":\"2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"},{\"authorId\":\"46382323\",\"name\":\"Hao Li\"}],\"doi\":\"10.1109/ACCESS.2019.2915630\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75405582ec7883539fd15ceedb999a569f77ce93\",\"title\":\"A Convolutional Encoder-Decoder Network With Skip Connections for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/75405582ec7883539fd15ceedb999a569f77ce93\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1905.10150\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"1693839\",\"name\":\"X. Mou\"}],\"doi\":\"10.1117/1.JEI.28.2.023025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d73395602a9242d26fdc91611f80618b629571d\",\"title\":\"Saliency detection based on structural dissimilarity induced by image quality assessment model\",\"url\":\"https://www.semanticscholar.org/paper/0d73395602a9242d26fdc91611f80618b629571d\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1702.00372\",\"authors\":[{\"authorId\":\"143635238\",\"name\":\"Samuel F. Dodge\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/TIP.2018.2834826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fc290cec880b22ca61544eca84157821ea7b0c6\",\"title\":\"Visual Saliency Prediction Using a Mixture of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fc290cec880b22ca61544eca84157821ea7b0c6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1610.06449\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1016/j.neucom.2017.03.018\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9995d891a5d6737eadd7b386de23fbd7aef77903\",\"title\":\"Exploiting inter-image similarity and ensemble of extreme learners for fixation prediction using deep features\",\"url\":\"https://www.semanticscholar.org/paper/9995d891a5d6737eadd7b386de23fbd7aef77903\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819851387\",\"name\":\"Alessandro Bruno\"},{\"authorId\":\"27053388\",\"name\":\"Francesco Gugliuzza\"},{\"authorId\":\"1720275\",\"name\":\"R. Pirrone\"},{\"authorId\":\"98705023\",\"name\":\"E. Ardizzone\"}],\"doi\":\"10.1109/ACCESS.2020.3006700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a4a5c24c2ee500819b81da6dd07483ef4112846\",\"title\":\"A Multi-Scale Colour and Keypoint Density-Based Approach for Visual Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/1a4a5c24c2ee500819b81da6dd07483ef4112846\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2911844\",\"name\":\"C\\u00e9line Craye\"},{\"authorId\":\"1771194\",\"name\":\"David Filliat\"},{\"authorId\":\"3411801\",\"name\":\"Jean-Francois Goudou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e2394ec2932987474afdc4326b32c3cc2517bba\",\"title\":\"Apprentissage incr\\u00e9mental de la saillance visuelle pour des applications robotique\",\"url\":\"https://www.semanticscholar.org/paper/9e2394ec2932987474afdc4326b32c3cc2517bba\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117020602\",\"name\":\"R. Li\"},{\"authorId\":\"120931191\",\"name\":\"Chi-Hao Wu\"},{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"3065597\",\"name\":\"Guangfu Wang\"},{\"authorId\":\"1624153165\",\"name\":\"Guanghui Liu\"},{\"authorId\":\"108249855\",\"name\":\"Bing Zeng\"}],\"doi\":\"10.1109/TIP.2020.3036754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"040c24003b439194f1efcb4c08e4ca41ecf65536\",\"title\":\"SDP-GAN: Saliency Detail Preservation Generative Adversarial Networks for High Perceptual Quality Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/040c24003b439194f1efcb4c08e4ca41ecf65536\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1601.06615\",\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.3389/frobt.2015.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"412b3ef02c85087e5f1721176114672c722b17a4\",\"title\":\"A Taxonomy of Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/412b3ef02c85087e5f1721176114672c722b17a4\",\"venue\":\"Front. Robot. AI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423668854\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"47319689\",\"name\":\"Shuai Li\"},{\"authorId\":\"46674323\",\"name\":\"Yunfeng Sui\"},{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"143754861\",\"name\":\"Ce Zhu\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023127\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"540bdbf95acdeb1a05102b995b4ffc3d3a04bf51\",\"title\":\"Integrating Action-aware Features for Saliency Prediction via Weakly Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/540bdbf95acdeb1a05102b995b4ffc3d3a04bf51\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"94395930\",\"name\":\"Francois Tison\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1109/CBMI.2016.7500243\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d0c49d8559354ac67e170a8c48e006528126afc\",\"title\":\"Prediction of visual attention with Deep CNN for studies of neurodegenerative diseases\",\"url\":\"https://www.semanticscholar.org/paper/9d0c49d8559354ac67e170a8c48e006528126afc\",\"venue\":\"2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591128418\",\"name\":\"Yaqing Zhang\"},{\"authorId\":\"50079717\",\"name\":\"X. Li\"},{\"authorId\":\"1502878557\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/AGENTS.2019.8929167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb105392cf0f4e7ef4c179ee5aa0eb5c03705263\",\"title\":\"Photo Cropping via Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/cb105392cf0f4e7ef4c179ee5aa0eb5c03705263\",\"venue\":\"2019 IEEE International Conference on Agents (ICA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"501b619a0c321aee8d9506e318e5c8f22d563f2f\",\"title\":\"Contribution to Perception and Artificial Bio-inspired Visual Attention for Acquisition and Conceptualization of Knowledge in Autonomous Robotics. (Contribution \\u00e0 la perception et l'attention visuelle artificielle bio-inspir\\u00e9e pour acquisition et conceptualisation de la connaissance en robotique aut\",\"url\":\"https://www.semanticscholar.org/paper/501b619a0c321aee8d9506e318e5c8f22d563f2f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"7503327\",\"name\":\"Vennela Gudisa\"},{\"authorId\":\"2313878\",\"name\":\"Jaley H. Dholakiya\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/CVPR.2016.623\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ca43c217aceabea4cff14bff1d81df2debe058f\",\"title\":\"Saliency Unified: A Deep Architecture for simultaneous Eye Fixation Prediction and Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1ca43c217aceabea4cff14bff1d81df2debe058f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41133681\",\"name\":\"Jayachandra Chilukamari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1697e396a20aa5a421cb79b7ed2e626b5c28133\",\"title\":\"A computational model of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/c1697e396a20aa5a421cb79b7ed2e626b5c28133\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41ec7222ad2583ae88ee2f91f4e7c2e98432765f\",\"title\":\"OOSTING SALIENCY PREDICTION WITH FEATURE MAPS TRAINED ON I MAGE N ET\",\"url\":\"https://www.semanticscholar.org/paper/41ec7222ad2583ae88ee2f91f4e7c2e98432765f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20823563\",\"name\":\"H. Takimoto\"},{\"authorId\":\"24785136\",\"name\":\"Syuhei Hitomi\"},{\"authorId\":\"47739449\",\"name\":\"H. Yamauchi\"},{\"authorId\":\"1763187\",\"name\":\"M. Kishihara\"},{\"authorId\":\"2288024\",\"name\":\"K. Okubo\"}],\"doi\":\"10.1587/TRANSINF.2016EDP7413\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b9f2fc7e5cd3ec8ae8c1f106fe2edde0baecba4\",\"title\":\"Image Modification Based on Spatial Frequency Components for Visual Attention Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/3b9f2fc7e5cd3ec8ae8c1f106fe2edde0baecba4\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144272947\",\"name\":\"Chen Xia\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/j.neucom.2018.09.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbeede6ad49a09a6c72031d55454f0fff767ffcb\",\"title\":\"Stereoscopic saliency estimation with background priors based deep reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/bbeede6ad49a09a6c72031d55454f0fff767ffcb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1961187\",\"name\":\"A. Zemmari\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1007/978-3-319-57687-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25a4355c69e90f0ebd182a90e4748742721a4b1b\",\"title\":\"Deep Saliency: Prediction of Interestingness in Video with CNN\",\"url\":\"https://www.semanticscholar.org/paper/25a4355c69e90f0ebd182a90e4748742721a4b1b\",\"venue\":\"Visual Content Indexing and Retrieval with Psycho-Visual Models\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67321830\",\"name\":\"Weijie Wei\"},{\"authorId\":\"3211706\",\"name\":\"Zhusong Liu\"},{\"authorId\":\"47033364\",\"name\":\"Lijin Huang\"},{\"authorId\":\"1395583740\",\"name\":\"Alexis Nebout\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"153913573\",\"name\":\"T. Zhang\"},{\"authorId\":\"7897836\",\"name\":\"J. Wang\"},{\"authorId\":\"119556705\",\"name\":\"Li-hua Xu\"}],\"doi\":\"10.1016/j.neucom.2020.06.125\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce2cf6e39d5c03d7d224eda614ad803a1347d145\",\"title\":\"Predicting atypical visual saliency for autism spectrum disorder via scale-adaptive inception module and discriminative region enhancement loss\",\"url\":\"https://www.semanticscholar.org/paper/ce2cf6e39d5c03d7d224eda614ad803a1347d145\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004798009\",\"name\":\"V. V. Babenko\"},{\"authorId\":\"6461856\",\"name\":\"D. Yavna\"},{\"authorId\":\"2036518579\",\"name\":\"E. G. Rodionov\"}],\"doi\":\"10.1007/s11055-020-00994-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30988b8bec915b744ea7686bfbfc91014644d1b3\",\"title\":\"Contributions of Different Spatial Modulations of Brightness Gradients to the Control of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/30988b8bec915b744ea7686bfbfc91014644d1b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9228892\",\"name\":\"P. Zhang\"},{\"authorId\":\"47155200\",\"name\":\"X. Hua\"},{\"authorId\":\"50141120\",\"name\":\"X. Wang\"},{\"authorId\":\"34668628\",\"name\":\"Ting Rui\"},{\"authorId\":\"49724535\",\"name\":\"H. Zhang\"},{\"authorId\":\"51294540\",\"name\":\"Faming Shao\"},{\"authorId\":\"24981485\",\"name\":\"Dong Wang\"}],\"doi\":\"10.1109/access.2020.3012185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc6450c2444a642f0204786828ce1472f2737bea\",\"title\":\"VSA-CGAN: An Intelligent Generation Model for Deep Learning Sample Database Construction\",\"url\":\"https://www.semanticscholar.org/paper/bc6450c2444a642f0204786828ce1472f2737bea\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144272947\",\"name\":\"Chen Xia\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1109/TNNLS.2015.2512898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9e633203204193616bac34294e127b9665927b\",\"title\":\"Bottom\\u2013Up Visual Saliency Estimation With Deep Autoencoder-Based Sparse Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/9d9e633203204193616bac34294e127b9665927b\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"46962451\",\"name\":\"Chuan Yang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TPAMI.2016.2609426\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5733d1b65ded6ebf2c35802966e637218b529aaa\",\"title\":\"Ranking Saliency\",\"url\":\"https://www.semanticscholar.org/paper/5733d1b65ded6ebf2c35802966e637218b529aaa\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2018.00783\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a2fae46c67189fb2aea33f12091772e635361f1\",\"title\":\"Going from Image to Video Saliency: Augmenting Image Salience with Dynamic Attentional Push\",\"url\":\"https://www.semanticscholar.org/paper/9a2fae46c67189fb2aea33f12091772e635361f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"47320103\",\"name\":\"Shi-kai Li\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/CVPR.2019.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"title\":\"Learning to Explore Intrinsic Saliency for Stereoscopic Video\",\"url\":\"https://www.semanticscholar.org/paper/273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94988120\",\"name\":\"Xinchen Lin\"},{\"authorId\":\"145515779\",\"name\":\"Y. Tang\"},{\"authorId\":\"1915936\",\"name\":\"H. Tianfield\"},{\"authorId\":\"145757340\",\"name\":\"F. Qian\"},{\"authorId\":\"3387804\",\"name\":\"W. Zhong\"}],\"doi\":\"10.1016/J.NEUCOM.2019.01.041\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79690bcb1d4360fa509173fe17af7dd4bb74f13f\",\"title\":\"A novel approach to reconstruction based saliency detection via convolutional neural network stacked with auto-encoder\",\"url\":\"https://www.semanticscholar.org/paper/79690bcb1d4360fa509173fe17af7dd4bb74f13f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9493344\",\"name\":\"E. Parcham\"},{\"authorId\":\"9731849\",\"name\":\"Neda Mandami\"},{\"authorId\":\"3075960\",\"name\":\"A. Washington\"},{\"authorId\":\"144211100\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/CSCI.2016.0161\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64b8c8bc0cebe4b45569d0ef09da9471aab3f5b0\",\"title\":\"Facial Expression Recognition Based on Fuzzy Networks\",\"url\":\"https://www.semanticscholar.org/paper/64b8c8bc0cebe4b45569d0ef09da9471aab3f5b0\",\"venue\":\"2016 International Conference on Computational Science and Computational Intelligence (CSCI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32278120\",\"name\":\"S. S. Naqvi\"},{\"authorId\":\"2309030\",\"name\":\"W. Browne\"},{\"authorId\":\"1923642\",\"name\":\"C. Hollitt\"}],\"doi\":\"10.1109/TIP.2016.2587359\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"802f6a704b93291aa049e80c16af7d2bce7dd92c\",\"title\":\"Feature Quality-Based Dynamic Feature Selection for Improving Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/802f6a704b93291aa049e80c16af7d2bce7dd92c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1109/IDAACS.2015.7340736\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afec02b655ec444fcb8160eede8e841578dd4757\",\"title\":\"Visual saliency based approach to object detection in computer vision systems: Real life applications\",\"url\":\"https://www.semanticscholar.org/paper/afec02b655ec444fcb8160eede8e841578dd4757\",\"venue\":\"2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)\",\"year\":2015},{\"arxivId\":\"1610.01708\",\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2817047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"title\":\"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"8152707\",\"name\":\"J. Lee\"},{\"authorId\":\"17822951\",\"name\":\"Wen-Chih Lo\"},{\"authorId\":\"2194011\",\"name\":\"C. Huang\"},{\"authorId\":\"6270307\",\"name\":\"Kuan-Ta Chen\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":\"10.1145/3083165.3083180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"663c55b25eebdb9a922a9ac8046dd7500495bd6d\",\"title\":\"Fixation Prediction for 360\\u00b0 Video Streaming in Head-Mounted Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/663c55b25eebdb9a922a9ac8046dd7500495bd6d\",\"venue\":\"NOSSDAV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"},{\"authorId\":\"145467467\",\"name\":\"M. Gori\"},{\"authorId\":\"2713157\",\"name\":\"A. Rufa\"}],\"doi\":\"10.1016/BS.PBR.2019.01.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad1bcb7258ba63265d8aaaeff6e2e96b904740e0\",\"title\":\"A unified computational framework for visual attention dynamics.\",\"url\":\"https://www.semanticscholar.org/paper/ad1bcb7258ba63265d8aaaeff6e2e96b904740e0\",\"venue\":\"Progress in brain research\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2088899\",\"name\":\"Daria Stefic\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":\"10.1016/j.imavis.2016.06.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3898c085d2f72b516c072f083a45a31fb2b9415f\",\"title\":\"Action recognition using saliency learned from recorded human gaze\",\"url\":\"https://www.semanticscholar.org/paper/3898c085d2f72b516c072f083a45a31fb2b9415f\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":\"1511.02872\",\"authors\":[{\"authorId\":\"47192865\",\"name\":\"H. Kato\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"597123ebb110fa887a53dcf455fd63c5a8df1c70\",\"title\":\"Visual Language Modeling on CNN Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/597123ebb110fa887a53dcf455fd63c5a8df1c70\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"50708949\",\"name\":\"Mei Su\"},{\"authorId\":\"37777082\",\"name\":\"M. Schlesinger\"},{\"authorId\":\"47901325\",\"name\":\"J. Qin\"}],\"doi\":\"10.1109/TCDS.2017.2696439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6546a9b48810edfb527e3af45cb5ee36f573cf5a\",\"title\":\"A Comparison Study of Saliency Models for Fixation Prediction on Infants and Adults\",\"url\":\"https://www.semanticscholar.org/paper/6546a9b48810edfb527e3af45cb5ee36f573cf5a\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2018},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27343041\",\"name\":\"Ayesha Gurnani\"},{\"authorId\":\"23922616\",\"name\":\"Vandit Gajjar\"},{\"authorId\":\"22239413\",\"name\":\"Viraj Mavani\"},{\"authorId\":\"26425477\",\"name\":\"Yash Khandhediya\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6c691b772822881c5c52b779100928f0d54fdd7\",\"title\":\"Using Visual Saliency to Improve Human Detection with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c6c691b772822881c5c52b779100928f0d54fdd7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1803.03354\",\"authors\":[{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/WACV.2018.00172\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"347ffaaf78ac976ee5c4ee0de358f9fc00262d6b\",\"title\":\"Task Specific Visual Saliency Prediction with Memory Augmented Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/347ffaaf78ac976ee5c4ee0de358f9fc00262d6b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"173edc84319ad918cddca75de022f740bf155847\",\"title\":\"Towards Laws of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/173edc84319ad918cddca75de022f740bf155847\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121216817\",\"name\":\"Ming-hao Ning\"},{\"authorId\":\"50815695\",\"name\":\"C. Lu\"},{\"authorId\":\"1804482\",\"name\":\"Jianwei Gong\"}],\"doi\":\"10.1109/ITSC.2019.8917337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8207fd1d0c27b3a979ef7aeb0466fa9c11623662\",\"title\":\"An Efficient Model for Driving Focus of Attention Prediction using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8207fd1d0c27b3a979ef7aeb0466fa9c11623662\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2572b08d5745f4e112e38aa42130e55eb7518f21\",\"title\":\"Etude et pr\\u00e9diction d'attention visuelle avec les outils d'apprentissage profond en vue d'\\u00e9valuation des patients atteints des maladies neuro-d\\u00e9g\\u00e9n\\u00e9ratives. (Study and prediction of visual attention with deep learning networks in view of assessment of patients with neurodegenerative diseases)\",\"url\":\"https://www.semanticscholar.org/paper/2572b08d5745f4e112e38aa42130e55eb7518f21\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"Mengmi Zhang\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"144889909\",\"name\":\"M. Jiang\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da7db2567a81df22ede6396cb88649c42cc9b5e0\",\"title\":\"Deep Scanpath: Predicting Human Sequences of Eye-Fixations using Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/da7db2567a81df22ede6396cb88649c42cc9b5e0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.13227\",\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7dd07f677210aa27defdd0f471771860566f674\",\"title\":\"A Compact Deep Architecture for Real-time Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b7dd07f677210aa27defdd0f471771860566f674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"47901325\",\"name\":\"J. Qin\"}],\"doi\":\"10.1016/j.jvcir.2019.102662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ce8857aa18acd253aa33b618e37cc0bab58e23d\",\"title\":\"An extensive evaluation of deep featuresof convolutional neural networks for saliency prediction of human visual attention\",\"url\":\"https://www.semanticscholar.org/paper/4ce8857aa18acd253aa33b618e37cc0bab58e23d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14998948\",\"name\":\"D. Li\"},{\"authorId\":\"9947552\",\"name\":\"Huikai Wu\"},{\"authorId\":\"2086001\",\"name\":\"Junge Zhang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00855\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5ac3c258bcadc0766e29638aa95e14058f6adf0\",\"title\":\"A2-RL: Aesthetics Aware Reinforcement Learning for Image Cropping\",\"url\":\"https://www.semanticscholar.org/paper/b5ac3c258bcadc0766e29638aa95e14058f6adf0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1702.00503\",\"authors\":[{\"authorId\":\"2855457\",\"name\":\"Y. Chen\"},{\"authorId\":\"145722211\",\"name\":\"Jan Klopp\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"1733505\",\"name\":\"S. Chien\"},{\"authorId\":\"1707383\",\"name\":\"K. Ma\"}],\"doi\":\"10.1145/3123266.3123274\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfb36d4e3c027212de6f08f6d7be9cffb52f9ca7\",\"title\":\"Learning to Compose with Professional Photographs on the Web\",\"url\":\"https://www.semanticscholar.org/paper/dfb36d4e3c027212de6f08f6d7be9cffb52f9ca7\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"47291418\",\"name\":\"Yi Fang\"},{\"authorId\":\"144509573\",\"name\":\"Lei Fan\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"}],\"doi\":\"10.1145/3337066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e01f0475ac9a96da307b2b10778ab6c9283381fb\",\"title\":\"Visual Attention Analysis and Prediction on Human Faces for Children with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/e01f0475ac9a96da307b2b10778ab6c9283381fb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1511.04192\",\"authors\":[{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"46457997\",\"name\":\"Lingbo Liu\"},{\"authorId\":\"144361019\",\"name\":\"Xiaonan Luo\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2015.2506664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a964ca2a17f53c254192d497e2a3a1bd33271307\",\"title\":\"DISC: Deep Image Saliency Computing via Progressive Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a964ca2a17f53c254192d497e2a3a1bd33271307\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759015\",\"name\":\"Mark A. Livingston\"},{\"authorId\":\"34636768\",\"name\":\"L. Matzen\"},{\"authorId\":\"20583827\",\"name\":\"Andre Harrison\"},{\"authorId\":\"1901135519\",\"name\":\"Alex Lulushi\"},{\"authorId\":\"1895155414\",\"name\":\"Mikaila Daniel\"},{\"authorId\":\"1901134743\",\"name\":\"Megan Dass\"},{\"authorId\":\"7976026\",\"name\":\"D. Brock\"},{\"authorId\":\"1920307\",\"name\":\"J. Decker\"}],\"doi\":\"10.1145/3385955.3407931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc410a50a9f05e9601fa7e222c59720105215114\",\"title\":\"A Study of Perceptual and Cognitive Models Applied to Prediction of Eye Gaze within Statistical Graphs\",\"url\":\"https://www.semanticscholar.org/paper/dc410a50a9f05e9601fa7e222c59720105215114\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147552063\",\"name\":\"M. L. Nguy\\u1ec5n\"},{\"authorId\":\"2847306\",\"name\":\"Prarinya Siritanawan\"},{\"authorId\":\"1791753\",\"name\":\"K. Kotani\"}],\"doi\":\"10.23919/SICE.2019.8859898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edb5a343d72e65072e967401f4ac508a31df3ac7\",\"title\":\"Saliency Map Extraction in Human Crowd RGB Data\",\"url\":\"https://www.semanticscholar.org/paper/edb5a343d72e65072e967401f4ac508a31df3ac7\",\"venue\":\"2019 58th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2733405\",\"name\":\"H. Li\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/J.JVCIR.2019.102611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"title\":\"A multiscale dilated dense convolutional network for saliency prediction with instance-level attention competition\",\"url\":\"https://www.semanticscholar.org/paper/6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112355\",\"name\":\"Daniel S. Ferreira\"},{\"authorId\":\"2005560\",\"name\":\"G. Ramalho\"},{\"authorId\":\"89658165\",\"name\":\"D. Torres\"},{\"authorId\":\"143948090\",\"name\":\"A. H. G. Tobias\"},{\"authorId\":\"31434323\",\"name\":\"M. T. Rezende\"},{\"authorId\":\"145730933\",\"name\":\"F. Medeiros\"},{\"authorId\":\"49667365\",\"name\":\"Andrea G. C. Bianchi\"},{\"authorId\":\"143717689\",\"name\":\"C. Carneiro\"},{\"authorId\":\"1811543\",\"name\":\"D. Ushizima\"}],\"doi\":\"10.1016/j.cmpb.2019.105053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2a5e8b15e5efa4ad54db2c4c3d6767cea6f2fb\",\"title\":\"Saliency-driven system models for cell analysis with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/1a2a5e8b15e5efa4ad54db2c4c3d6767cea6f2fb\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2019},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166380\",\"name\":\"J. Wang\"},{\"authorId\":\"50032257\",\"name\":\"Yulin Ma\"},{\"authorId\":\"1784352\",\"name\":\"L. Zhang\"},{\"authorId\":\"1700762\",\"name\":\"R. Gao\"},{\"authorId\":\"48198404\",\"name\":\"D. Wu\"}],\"doi\":\"10.1016/J.JMSY.2018.01.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"354923bc917ac774438a048b87db9fabed4d757e\",\"title\":\"Deep learning for smart manufacturing: Methods and applications\",\"url\":\"https://www.semanticscholar.org/paper/354923bc917ac774438a048b87db9fabed4d757e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26374549\",\"name\":\"Tengfei Zhan\"},{\"authorId\":\"92818919\",\"name\":\"M. Ye\"},{\"authorId\":\"8679450\",\"name\":\"Wen-wen Jiang\"},{\"authorId\":\"51262970\",\"name\":\"Yong-Jie Li\"},{\"authorId\":\"2105451\",\"name\":\"Kaifu Yang\"}],\"doi\":\"10.1109/SSCI44817.2019.9002897\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"64bc24ff9a4328b21e8b7af995a977d9e1cd8f19\",\"title\":\"Fixation Prediction based on Scene Contours\",\"url\":\"https://www.semanticscholar.org/paper/64bc24ff9a4328b21e8b7af995a977d9e1cd8f19\",\"venue\":\"2019 IEEE Symposium Series on Computational Intelligence (SSCI)\",\"year\":2019},{\"arxivId\":\"1710.10755\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2858783\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"title\":\"Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"title\":\"How Drones Look: Crowdsourced Knowledge Transfer for Aerial Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145021810\",\"name\":\"Shu Fang\"},{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"33610144\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/TNNLS.2016.2522440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0e9ce0aa191f1db366457f1efeeaba4dec996b\",\"title\":\"Learning Discriminative Subspaces on Random Contrasts for Image Saliency Analysis\",\"url\":\"https://www.semanticscholar.org/paper/2d0e9ce0aa191f1db366457f1efeeaba4dec996b\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90357138\",\"name\":\"Marta Coll Pol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"be0947fa430a3bf16436d20239550c39d1425d08\",\"title\":\"The importance of time in visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/be0947fa430a3bf16436d20239550c39d1425d08\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1604.03227\",\"authors\":[{\"authorId\":\"1859486\",\"name\":\"Jason Kuen\"},{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84fc1b09365197299c6a72196022d09f014ae039\",\"title\":\"Recurrent Attentional Networks for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/84fc1b09365197299c6a72196022d09f014ae039\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1882027\",\"name\":\"Henny Admoni\"},{\"authorId\":\"1798776\",\"name\":\"Thomas Weng\"},{\"authorId\":\"30325272\",\"name\":\"Bradley Hayes\"},{\"authorId\":\"1792053\",\"name\":\"B. Scassellati\"}],\"doi\":\"10.1109/HRI.2016.7451733\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53b2059229871b7ec17a13e6ecda079861713919\",\"title\":\"Robot nonverbal behavior improves task performance in difficult collaborations\",\"url\":\"https://www.semanticscholar.org/paper/53b2059229871b7ec17a13e6ecda079861713919\",\"venue\":\"2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"2243473\",\"name\":\"Athanasios Katsamanis\"},{\"authorId\":\"46788705\",\"name\":\"A. Vatakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"title\":\"A behaviorally inspired fusion approach for computational audiovisual saliency modeling\",\"url\":\"https://www.semanticscholar.org/paper/5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"1607.03333\",\"authors\":[{\"authorId\":\"2960342\",\"name\":\"Liangqiong Qu\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"47540407\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"1774000\",\"name\":\"Jiandong Tian\"},{\"authorId\":\"1684088\",\"name\":\"Y. Tang\"},{\"authorId\":\"1777434\",\"name\":\"Q. Yang\"}],\"doi\":\"10.1109/TIP.2017.2682981\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0ca5c9dbdf515778affc7636ae2268b239b57b9\",\"title\":\"RGBD Salient Object Detection via Deep Fusion\",\"url\":\"https://www.semanticscholar.org/paper/e0ca5c9dbdf515778affc7636ae2268b239b57b9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4c02e071432a9a986501b7317b524f216e87ec8\",\"title\":\"Visual saliency prediction using deep learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/b4c02e071432a9a986501b7317b524f216e87ec8\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1805.11374\",\"authors\":[{\"authorId\":\"3503889\",\"name\":\"Yu Li\"},{\"authorId\":\"2910574\",\"name\":\"Ya Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a320538e0ea0a2e013f5730e8c72e26b76544efd\",\"title\":\"Webpage Saliency Prediction with Two-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a320538e0ea0a2e013f5730e8c72e26b76544efd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"04a37151ce74b63f99863c84f24738c32b1225ae\",\"title\":\"Boolean Maps Attention Maps Mean Attention Map \\u03a3 Input Image Activation\",\"url\":\"https://www.semanticscholar.org/paper/04a37151ce74b63f99863c84f24738c32b1225ae\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36465167\",\"name\":\"F. Leit\\u00e3o\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"title\":\"Predicting Eye Fixations with a Deep Reconstruction-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47835189\",\"name\":\"Qi Zhang\"},{\"authorId\":\"153239184\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1117/12.2503058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9c4688fb7a80f9f479203d7e3a0eccd2ff2ff0e\",\"title\":\"Dynamic saliency detection via CNN and spatial-temporal fusion\",\"url\":\"https://www.semanticscholar.org/paper/c9c4688fb7a80f9f479203d7e3a0eccd2ff2ff0e\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34560661\",\"name\":\"M. Haass\"},{\"authorId\":\"145771264\",\"name\":\"A. Wilson\"},{\"authorId\":\"34636768\",\"name\":\"L. Matzen\"},{\"authorId\":\"3424845\",\"name\":\"Kristin M. Divis\"}],\"doi\":\"10.1007/978-3-319-39907-2_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd9e2d0f2a07b07cb6382dcc39e143f4891d6a07\",\"title\":\"Modeling Human Comprehension of Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/fd9e2d0f2a07b07cb6382dcc39e143f4891d6a07\",\"venue\":\"HCI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693461\",\"name\":\"Ping Hu\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"},{\"authorId\":\"144106250\",\"name\":\"K. Lu\"}],\"doi\":\"10.1109/TIP.2016.2594489\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09a4bcf284c3390ce5c7ab054326b0805dd6a0bd\",\"title\":\"Detecting Salient Objects via Color and Texture Compactness Hypotheses\",\"url\":\"https://www.semanticscholar.org/paper/09a4bcf284c3390ce5c7ab054326b0805dd6a0bd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1711.03726\",\"authors\":[{\"authorId\":\"46479926\",\"name\":\"Prakhar Gupta\"},{\"authorId\":\"28823342\",\"name\":\"Shubh Gupta\"},{\"authorId\":\"30039163\",\"name\":\"Ajaykrishnan Jayagopal\"},{\"authorId\":\"143775710\",\"name\":\"S. Pal\"},{\"authorId\":\"2703103\",\"name\":\"R. Sinha\"}],\"doi\":\"10.1109/WACV.2018.00171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"329836fe1afe6d3ee48c901175a0219756dd2927\",\"title\":\"Saliency Prediction for Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/329836fe1afe6d3ee48c901175a0219756dd2927\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1701.01480\",\"authors\":[{\"authorId\":\"2855457\",\"name\":\"Y. Chen\"},{\"authorId\":\"1956472\",\"name\":\"Tzu-Wei Huang\"},{\"authorId\":\"50734056\",\"name\":\"Kai-Han Chang\"},{\"authorId\":\"46269379\",\"name\":\"Yu-Chen Tsai\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1733344\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2017.32\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a841c23e6964882ca4a9d8362a95a5ae5c4de70\",\"title\":\"Quantitative Analysis of Automatic Image Cropping Algorithms: A Dataset and Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/9a841c23e6964882ca4a9d8362a95a5ae5c4de70\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shree Nath Dutt Sharma\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"35217367\",\"name\":\"Niranjan Balasubramanian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"385c9cb10e5f46af0057c8103edccd9062bc721a\",\"title\":\"Ordering Salient Objects in Images\",\"url\":\"https://www.semanticscholar.org/paper/385c9cb10e5f46af0057c8103edccd9062bc721a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":\"1505.05753\",\"authors\":[{\"authorId\":\"3300424\",\"name\":\"Iaroslav Shcherbatyi\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d3d9380d58f07246a5ffc5c0bcae8551c7ab795\",\"title\":\"GazeDPM: Early Integration of Gaze Information in Deformable Part Models\",\"url\":\"https://www.semanticscholar.org/paper/5d3d9380d58f07246a5ffc5c0bcae8551c7ab795\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48984885\",\"name\":\"Felipe Vera\"},{\"authorId\":\"32124610\",\"name\":\"V. Cort\\u00e9s\"},{\"authorId\":\"32830698\",\"name\":\"Gabriel Iturrra\"},{\"authorId\":\"145323794\",\"name\":\"J. Vel\\u00e1squez\"},{\"authorId\":\"145132845\",\"name\":\"P. Maldonado\"},{\"authorId\":\"5842513\",\"name\":\"A. Couve\"}],\"doi\":\"10.1109/ICDMW.2017.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82256e82e9ae58538f8b68f2f6cd1e667818cb18\",\"title\":\"Akori: A Tool Based in Eye-Tracking Techniques for Analyzing Web User Behaviour on a Web Site\",\"url\":\"https://www.semanticscholar.org/paper/82256e82e9ae58538f8b68f2f6cd1e667818cb18\",\"venue\":\"2017 IEEE International Conference on Data Mining Workshops (ICDMW)\",\"year\":2017},{\"arxivId\":\"1607.01232\",\"authors\":[{\"authorId\":\"1715361\",\"name\":\"Giuseppe Boccignone\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f8e7de72a0fb415e2463b3efed4cbea325ed996\",\"title\":\"A probabilistic tour of visual attention and gaze shift computational models\",\"url\":\"https://www.semanticscholar.org/paper/0f8e7de72a0fb415e2463b3efed4cbea325ed996\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32278120\",\"name\":\"S. S. Naqvi\"},{\"authorId\":\"2309030\",\"name\":\"W. Browne\"},{\"authorId\":\"1923642\",\"name\":\"C. Hollitt\"}],\"doi\":\"10.1016/j.patcog.2015.09.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0764b158aaab3cd077d81e772eb4867841981a7f\",\"title\":\"Salient object detection via spectral matting\",\"url\":\"https://www.semanticscholar.org/paper/0764b158aaab3cd077d81e772eb4867841981a7f\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":\"1902.06634\",\"authors\":[{\"authorId\":\"144373348\",\"name\":\"A. Kroner\"},{\"authorId\":\"2581474\",\"name\":\"Mario Senden\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"},{\"authorId\":\"145960031\",\"name\":\"R. Goebel\"}],\"doi\":\"10.1016/j.neunet.2020.05.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa6aac2143c713561603083a5f953c395ba2131\",\"title\":\"Contextual Encoder-Decoder Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4fa6aac2143c713561603083a5f953c395ba2131\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":\"1603.03669\",\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"2161276\",\"name\":\"Tristan Swedish\"},{\"authorId\":\"1398734187\",\"name\":\"E. Bayro-Corrochano\"},{\"authorId\":\"145711633\",\"name\":\"R. Raskar\"}],\"doi\":\"10.1109/ICCV.2017.188\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"ca1ff286ad8eba2aa6bc442f0f8321572fd0b090\",\"title\":\"Learning Gaze Transitions from Depth to Improve Video Saliency Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ca1ff286ad8eba2aa6bc442f0f8321572fd0b090\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2705801\",\"name\":\"Si Liu\"},{\"authorId\":\"145314998\",\"name\":\"Z. Wei\"},{\"authorId\":\"143725619\",\"name\":\"Yao Sun\"},{\"authorId\":\"2456308\",\"name\":\"Xinyu Ou\"},{\"authorId\":\"2090292\",\"name\":\"Junyu Lin\"},{\"authorId\":\"49166933\",\"name\":\"B. Liu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2018.2836313\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71659a32d6be503572e27c1c32755c91ae370271\",\"title\":\"Composing Semantic Collage for Image Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/71659a32d6be503572e27c1c32755c91ae370271\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40311083\",\"name\":\"Yan Kong\"},{\"authorId\":\"38690089\",\"name\":\"Weiming Dong\"},{\"authorId\":\"143700357\",\"name\":\"X. Mei\"},{\"authorId\":\"1797422\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"39945992\",\"name\":\"Tong-Yee Lee\"},{\"authorId\":\"1794837\",\"name\":\"Siwei Lyu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145358975\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/TVCG.2016.2515614\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07ad5267bd6140cf8dd3344d028cd3bcc97055ca\",\"title\":\"Measuring and Predicting Visual Importance of Similar Objects\",\"url\":\"https://www.semanticscholar.org/paper/07ad5267bd6140cf8dd3344d028cd3bcc97055ca\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-48881-3_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"title\":\"Multi-level Net: A Visual Saliency Prediction Model\",\"url\":\"https://www.semanticscholar.org/paper/874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46599199\",\"name\":\"Debang Li\"},{\"authorId\":\"2086001\",\"name\":\"Junge Zhang\"},{\"authorId\":\"65902149\",\"name\":\"Kai-Qi Huang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fab02771ab66f7597c7378ab7faf6b1f94bd608\",\"title\":\"Composing Good Shots by Exploiting Mutual Relations\",\"url\":\"https://www.semanticscholar.org/paper/5fab02771ab66f7597c7378ab7faf6b1f94bd608\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1109/ICIP.2016.7532629\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f5c5b5be74b6ce35f51722b40cdf94ef4cc7bab\",\"title\":\"Transfer learning with deep networks for saliency prediction in natural video\",\"url\":\"https://www.semanticscholar.org/paper/9f5c5b5be74b6ce35f51722b40cdf94ef4cc7bab\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"}],\"doi\":\"10.1167/18.6.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5882b08cd2968d8d10dbc6f7cbe69bb1cdb383b6\",\"title\":\"Meaning guides attention in real-world scene images: Evidence from eye movements and meaning maps\",\"url\":\"https://www.semanticscholar.org/paper/5882b08cd2968d8d10dbc6f7cbe69bb1cdb383b6\",\"venue\":\"Journal of vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-01270-0_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9a484f6ffd5fc006401dee749493142623ba4c9\",\"title\":\"Saliency Benchmarking Made Easy: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/d9a484f6ffd5fc006401dee749493142623ba4c9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152645158\",\"name\":\"Kecheng Zhang\"},{\"authorId\":\"9272728\",\"name\":\"Xinbo Zhao\"},{\"authorId\":\"81076835\",\"name\":\"R. Mo\"}],\"doi\":\"10.1051/jnwpu/20193730503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77aa186a4a97ccc047b1d71652a5d22cfa1f3507\",\"title\":\"A Bioinspired Visual Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/77aa186a4a97ccc047b1d71652a5d22cfa1f3507\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"144785138\",\"name\":\"P. Li\"},{\"authorId\":\"145312326\",\"name\":\"Y. Han\"},{\"authorId\":\"145233508\",\"name\":\"Lei Wu\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"9315669\",\"name\":\"Weimin Wu\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e6b579a40169e2158858f75e36b1be54969cf4\",\"title\":\"Saliency prediction by Mahalanobis distance of topological feature on deep color components\",\"url\":\"https://www.semanticscholar.org/paper/d7e6b579a40169e2158858f75e36b1be54969cf4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aee37b02ab674c87a8348d6267bb40af64323813\",\"title\":\"ChaboNet : Design of a deep CNN for prediction of visual saliency in natural video\",\"url\":\"https://www.semanticscholar.org/paper/aee37b02ab674c87a8348d6267bb40af64323813\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1709.06505\",\"authors\":[{\"authorId\":\"145030054\",\"name\":\"R. Monroy\"},{\"authorId\":\"32882525\",\"name\":\"S. Lutz\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1016/j.image.2018.05.005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"title\":\"SalNet360: Saliency Maps for omni-directional images with CNN\",\"url\":\"https://www.semanticscholar.org/paper/b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":\"1506.07194\",\"authors\":[{\"authorId\":\"1715361\",\"name\":\"Giuseppe Boccignone\"}],\"doi\":\"10.1007/978-3-030-20085-5_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baf3d7bbdf3129f10b584eaf2f6e0a4af7fb3132\",\"title\":\"Advanced statistical methods for eye movement analysis and modeling: a gentle introduction\",\"url\":\"https://www.semanticscholar.org/paper/baf3d7bbdf3129f10b584eaf2f6e0a4af7fb3132\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1716997\",\"name\":\"T. Dean\"}],\"doi\":\"10.1016/j.cub.2014.08.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b56f1ea5df4a7933fbca6f6f409d1f8135181cd6\",\"title\":\"Neural Networks and Neuroscience-Inspired Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/b56f1ea5df4a7933fbca6f6f409d1f8135181cd6\",\"venue\":\"Current Biology\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2772489\",\"name\":\"Eghbal G. Mansoori\"},{\"authorId\":\"145105283\",\"name\":\"M. Yazdi\"}],\"doi\":\"10.1016/J.JVCIR.2020.102931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"title\":\"Exploiting object features in deep gaze prediction models\",\"url\":\"https://www.semanticscholar.org/paper/20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410115885\",\"name\":\"Miguel-\\u00c1ngel Fern\\u00e1ndez-Torres\"},{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"1397907559\",\"name\":\"F. D\\u00edaz-de-Mar\\u00eda\"}],\"doi\":\"10.1109/TCSVT.2019.2909427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08a33526d8777104a2c2766d5df51299a504f8a7\",\"title\":\"Probabilistic Topic Model for Context-Driven Visual Attention Understanding\",\"url\":\"https://www.semanticscholar.org/paper/08a33526d8777104a2c2766d5df51299a504f8a7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020}],\"corpusId\":1948756,\"doi\":\"10.1109/CVPR.2014.358\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":16,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1007/978-3-642-04697-1_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"title\":\"Decorrelation and Distinctiveness Provide with Human-Like Saliency\",\"url\":\"https://www.semanticscholar.org/paper/749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"venue\":\"ACIVS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T Judd\"},{\"authorId\":null,\"name\":\"F Durand\"},{\"authorId\":null,\"name\":\"A Torralba\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"MIT saliency benchmark\",\"url\":\"\",\"venue\":\"MIT saliency benchmark\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T Judd\"},{\"authorId\":null,\"name\":\"F Durand\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Tor- ralba. MIT saliency benchmark\",\"url\":\"\",\"venue\":\"Tor- ralba. MIT saliency benchmark\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-642-15561-1_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"title\":\"An Eye Fixation Database for Saliency Detection in Images\",\"url\":\"https://www.semanticscholar.org/paper/ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2012.6247706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5817841d769baa45122ba0bf38af8cab3aeb5dd4\",\"title\":\"Boosting bottom-up and top-down visual features for saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/5817841d769baa45122ba0bf38af8cab3aeb5dd4\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502152\",\"name\":\"A. Treisman\"},{\"authorId\":\"46475250\",\"name\":\"G. Gelade\"}],\"doi\":\"10.1016/0010-0285(80)90005-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76361a44e145732a39dbc68d9418871038c83be2\",\"title\":\"A feature-integration theory of attention\",\"url\":\"https://www.semanticscholar.org/paper/76361a44e145732a39dbc68d9418871038c83be2\",\"venue\":\"Cognitive Psychology\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803391\",\"name\":\"Y. Lu\"},{\"authorId\":\"47528349\",\"name\":\"W. Zhang\"},{\"authorId\":\"145020730\",\"name\":\"C. Jin\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2012.6247785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8327ee7d5210db511672735da983a5e137996796\",\"title\":\"Learning attention map from images\",\"url\":\"https://www.semanticscholar.org/paper/8327ee7d5210db511672735da983a5e137996796\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"563e821bb5ea825efb56b77484f5287f08cf3753\",\"title\":\"Convolutional networks for images, speech, and time series\",\"url\":\"https://www.semanticscholar.org/paper/563e821bb5ea825efb56b77484f5287f08cf3753\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"272c089ca09bb8c4603578c8e262885f1a7276c7\",\"title\":\"Learning High-Level Concepts by Training A Deep Network on Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/272c089ca09bb8c4603578c8e262885f1a7276c7\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/CVPR.2010.5539929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32e072aa603a64ca5b40fdc6b4c94c951166a310\",\"title\":\"Context-aware saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/32e072aa603a64ca5b40fdc6b4c94c951166a310\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007359\",\"name\":\"W. Kienzle\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"30541601\",\"name\":\"M. Franz\"}],\"doi\":\"10.7551/mitpress/7503.003.0091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40cd3cd0d1da27297ad84fb8750d906ade0b1f6f\",\"title\":\"A Nonparametric Approach to Bottom-Up Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/40cd3cd0d1da27297ad84fb8750d906ade0b1f6f\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145521470\",\"name\":\"G. Rees\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8419ec7c5587924208322d1bc72bfae87bd96025\",\"title\":\"Neurobiology of Attention\",\"url\":\"https://www.semanticscholar.org/paper/8419ec7c5587924208322d1bc72bfae87bd96025\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716301\",\"name\":\"R. Schapire\"}],\"doi\":\"10.1007/978-0-387-21579-2_9\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"84bb60b83f82ad847e19d96403ad0011abfc888f\",\"title\":\"The Boosting Approach to Machine Learning An Overview\",\"url\":\"https://www.semanticscholar.org/paper/84bb60b83f82ad847e19d96403ad0011abfc888f\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123788780\",\"name\":\"Nicolas Pinto\"},{\"authorId\":\"3250342\",\"name\":\"D. Doukhan\"},{\"authorId\":\"34409560\",\"name\":\"James J. DiCarlo\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1371/journal.pcbi.1000579\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d46fd54609e09bcd135fd28750003185a5ee4125\",\"title\":\"A High-Throughput Screening Approach to Discovering Good Forms of Biologically Inspired Visual Representation\",\"url\":\"https://www.semanticscholar.org/paper/d46fd54609e09bcd135fd28750003185a5ee4125\",\"venue\":\"PLoS Comput. Biol.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1007/978-3-642-21227-7_62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0161777b4419411a4d2c5971a22683ee8691643f\",\"title\":\"Fast and Efficient Saliency Detection Using Sparse Sampling and Kernel Density Estimation\",\"url\":\"https://www.semanticscholar.org/paper/0161777b4419411a4d2c5971a22683ee8691643f\",\"venue\":\"SCIA\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/11.3.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b380725466e69717ab4c2520c80cff4bba2cc05c\",\"title\":\"Learning a saliency map using fixated locations in natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/b380725466e69717ab4c2520c80cff4bba2cc05c\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"30017846\",\"name\":\"Nicolas Pinto\"}],\"doi\":\"10.1109/FG.2011.5771385\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1128c5607a19af6022be723d10dbf8fad3ca26ab\",\"title\":\"Beyond simple features: A large-scale feature search approach to unconstrained face recognition\",\"url\":\"https://www.semanticscholar.org/paper/1128c5607a19af6022be723d10dbf8fad3ca26ab\",\"venue\":\"Face and Gesture 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602925\",\"name\":\"Boris Schauerte\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-642-33709-3_9\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a0d596ef86c7563c0907c052273113f51006479\",\"title\":\"Quaternion-Based Spectral Saliency Detection for Eye Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5a0d596ef86c7563c0907c052273113f51006479\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"2103302\",\"name\":\"R. Bardenet\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"143674326\",\"name\":\"B. K\\u00e9gl\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03911c85305d42aa2eeb02be82ef6fb7da644dd0\",\"title\":\"Algorithms for Hyper-Parameter Optimization\",\"url\":\"https://www.semanticscholar.org/paper/03911c85305d42aa2eeb02be82ef6fb7da644dd0\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036170\",\"name\":\"Dashan Gao\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/ICCV.2007.4408851\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3288b051e5555a62438af00e9497cf653b6d15\",\"title\":\"Bottom-up saliency is a discriminant process\",\"url\":\"https://www.semanticscholar.org/paper/2c3288b051e5555a62438af00e9497cf653b6d15\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L Itti\"},{\"authorId\":null,\"name\":\"G Rees\"},{\"authorId\":null,\"name\":\"J K Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neurobiology of Attention. Elsevier\",\"url\":\"\",\"venue\":\"Neurobiology of Attention. Elsevier\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46837630\",\"name\":\"Po-He Tseng\"},{\"authorId\":\"34414200\",\"name\":\"R. Carmi\"},{\"authorId\":\"145777626\",\"name\":\"I. G. Cameron\"},{\"authorId\":\"144440243\",\"name\":\"D. Munoz\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/9.7.4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe311d83782515767e5584c4fa0239daee14075c\",\"title\":\"Quantifying center bias of observers in free viewing of dynamic natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/fe311d83782515767e5584c4fa0239daee14075c\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"2292273\",\"name\":\"Daniel Yamins\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29935173af73aef20336db72d608e0ef5b0e0c16\",\"title\":\"Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures\",\"url\":\"https://www.semanticscholar.org/paper/29935173af73aef20336db72d608e0ef5b0e0c16\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":\"1206.5538\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145467703\",\"name\":\"P. Vincent\"}],\"doi\":\"10.1109/TPAMI.2013.50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"184ac0766262312ba76bbdece4e7ffad0aa8180b\",\"title\":\"Representation Learning: A Review and New Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/184ac0766262312ba76bbdece4e7ffad0aa8180b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1167/13.4.11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9896b03aeb17e06181c1842773fec4b742d7c51f\",\"title\":\"Visual saliency estimation by nonlinearly integrating features using region covariances.\",\"url\":\"https://www.semanticscholar.org/paper/9896b03aeb17e06181c1842773fec4b742d7c51f\",\"venue\":\"Journal of vision\",\"year\":2013}],\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"topics\":[{\"topic\":\"Linear classifier\",\"topicId\":\"223706\",\"url\":\"https://www.semanticscholar.org/topic/223706\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Neuromorphic engineering\",\"topicId\":\"59674\",\"url\":\"https://www.semanticscholar.org/topic/59674\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Test set\",\"topicId\":\"24168\",\"url\":\"https://www.semanticscholar.org/topic/24168\"},{\"topic\":\"British Informatics Olympiad\",\"topicId\":\"3621618\",\"url\":\"https://www.semanticscholar.org/topic/3621618\"}],\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014}\n"