"{\"abstract\":\"Time-lapse videos usually perform eye-catching appearances but are often hard to create. In this paper, we propose a self-supervised end-to-end model to generate the time-lapse video from a single image and a reference video. Our key idea is to extract both the style and the features of temporal variation from the reference video, and transfer them onto the input image. To ensure both the temporal consistency and realness of our resultant videos, we introduce several novel designs in our architecture, including classwise NoiseAdaIN, flow loss, and the video discriminator. In comparison to the baselines of state-of-the-art style transfer approaches, our proposed method is not only efficient in computation but also able to create more realistic and temporally smooth time-lapse video of a still image, with its temporal variation consistent to the reference.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"103664864\",\"name\":\"Chia-chi Cheng\",\"url\":\"https://www.semanticscholar.org/author/103664864\"},{\"authorId\":\"40846050\",\"name\":\"Hungyu Chen\",\"url\":\"https://www.semanticscholar.org/author/40846050\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\",\"url\":\"https://www.semanticscholar.org/author/37811787\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2006.12247\",\"authors\":[{\"authorId\":\"1753619419\",\"name\":\"Eran Segalis\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4728dce54c69fc51238c0b53bcc5f8e4ae92fd09\",\"title\":\"Disrupting Deepfakes with an Adversarial Attack that Survives Training\",\"url\":\"https://www.semanticscholar.org/paper/4728dce54c69fc51238c0b53bcc5f8e4ae92fd09\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.15128\",\"authors\":[{\"authorId\":\"118300344\",\"name\":\"Aleksander Holynski\"},{\"authorId\":\"1396759259\",\"name\":\"Brian Curless\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"title\":\"Animating Pictures with Eulerian Motion Fields\",\"url\":\"https://www.semanticscholar.org/paper/a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219635063,\"doi\":\"10.1109/cvpr42600.2020.00568\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"references\":[{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144430305\",\"name\":\"Jean-Fran\\u00e7ois Lalonde\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1779052\",\"name\":\"S. Narasimhan\"}],\"doi\":\"10.1145/1661412.1618477\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b533b9116f8b95d22397bd66489ee69321c07e47\",\"title\":\"Webcam clip art: appearance and illuminant transfer from time-lapse sequences\",\"url\":\"https://www.semanticscholar.org/paper/b533b9116f8b95d22397bd66489ee69321c07e47\",\"venue\":\"SIGGRAPH Asia '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"35130187\",\"name\":\"Xiaolong Zhu\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2017.745\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"title\":\"Real-Time Neural Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.06868\",\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/ICCV.2017.167\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"be0ef77fb0345c5851bb5d297f3ed84ae3c581ee\",\"title\":\"Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization\",\"url\":\"https://www.semanticscholar.org/paper/be0ef77fb0345c5851bb5d297f3ed84ae3c581ee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1709.07592\",\"authors\":[{\"authorId\":\"39272336\",\"name\":\"W. Xiong\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2018.00251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87a818723a2ada66a1193baf17b0383d9766781b\",\"title\":\"Learning to Generate Time-Lapse Videos Using Multi-stage Dynamic Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/87a818723a2ada66a1193baf17b0383d9766781b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.04537\",\"authors\":[{\"authorId\":\"2816471\",\"name\":\"Xueting Li\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"91bd017c1b19c36e430a22929d8de3af0795dfa4\",\"title\":\"Learning Linear Transformations for Fast Arbitrary Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/91bd017c1b19c36e430a22929d8de3af0795dfa4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.07511\",\"authors\":[{\"authorId\":\"13981526\",\"name\":\"Fu-jun Luan\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144374926\",\"name\":\"K. Bala\"}],\"doi\":\"10.1109/CVPR.2017.740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b5253c8159ffa7cca12901af26a0a0897b45cda\",\"title\":\"Deep Photo Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/8b5253c8159ffa7cca12901af26a0a0897b45cda\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.09210\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/CVPR.2017.296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e803dbe3c2a3b7f7a5017c48c7531ed3532ee4f5\",\"title\":\"StyleBank: An Explicit Representation for Neural Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/e803dbe3c2a3b7f7a5017c48c7531ed3532ee4f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1608.07724\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46484-8_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bf3b2a5591f2a2f0c648dc5a1f4ff3bd6b9102a\",\"title\":\"Learning Temporal Transformations from Time-Lapse Videos\",\"url\":\"https://www.semanticscholar.org/paper/5bf3b2a5591f2a2f0c648dc5a1f4ff3bd6b9102a\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1703.06953\",\"authors\":[{\"authorId\":\"46702541\",\"name\":\"H. Zhang\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-11018-5_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a525cb3779d5eb19880faf8aa7a34a34cfbdef40\",\"title\":\"Multi-style Generative Network for Real-time Transfer\",\"url\":\"https://www.semanticscholar.org/paper/a525cb3779d5eb19880faf8aa7a34a34cfbdef40\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1705.08086\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"83083c5760bd1b58e5f827e57415e5ed676ef3bc\",\"title\":\"Universal Style Transfer via Feature Transforms\",\"url\":\"https://www.semanticscholar.org/paper/83083c5760bd1b58e5f827e57415e5ed676ef3bc\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1904.00680\",\"authors\":[{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\"},{\"authorId\":\"1797422\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"48858384\",\"name\":\"William Brendel\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/CVPR.2019.00150\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54efdd4c03e47a11db7ef710b8dc87c70d34e529\",\"title\":\"End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image\",\"url\":\"https://www.semanticscholar.org/paper/54efdd4c03e47a11db7ef710b8dc87c70d34e529\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1608.05442\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"51333271\",\"name\":\"H. Zhao\"},{\"authorId\":\"143872936\",\"name\":\"Xavier Puig\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"3081640\",\"name\":\"Adela Barriuso\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/s11263-018-1140-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88512be44744615f4baa8e14f600f036db4c2433\",\"title\":\"Semantic Understanding of Scenes Through the ADE20K Dataset\",\"url\":\"https://www.semanticscholar.org/paper/88512be44744615f4baa8e14f600f036db4c2433\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1701.02096\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":\"10.1109/CVPR.2017.437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722ff8967633d0806298c22d25a845da222615f3\",\"title\":\"Improved Texture Networks: Maximizing Quality and Diversity in Feed-Forward Stylization and Texture Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/722ff8967633d0806298c22d25a845da222615f3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1802.06474\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2816471\",\"name\":\"Xueting Li\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1007/978-3-030-01219-9_28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eadac91600c67ee2343e7ce76934e92b1796e60e\",\"title\":\"A Closed-form Solution to Photorealistic Image Stylization\",\"url\":\"https://www.semanticscholar.org/paper/eadac91600c67ee2343e7ce76934e92b1796e60e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1701.08893\",\"authors\":[{\"authorId\":\"31663839\",\"name\":\"Pierre Wilmot\"},{\"authorId\":\"2178086\",\"name\":\"E. Risser\"},{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02b01b4ea3dce27400d6479cb4a6dc188b4eae04\",\"title\":\"Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses\",\"url\":\"https://www.semanticscholar.org/paper/02b01b4ea3dce27400d6479cb4a6dc188b4eae04\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.03417\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"47606739\",\"name\":\"V. Lebedev\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"title\":\"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images\",\"url\":\"https://www.semanticscholar.org/paper/ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1805.03857\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1967781\",\"name\":\"Ziyi Lin\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00860\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0df8fe29381154c06b6b488cf32b6f6627b394f\",\"title\":\"Avatar-Net: Multi-scale Zero-Shot Style Transfer by Feature Decoration\",\"url\":\"https://www.semanticscholar.org/paper/e0df8fe29381154c06b6b488cf32b6f6627b394f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.04382\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1007/978-3-319-46487-9_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"102a2096ba2e2947dc252445f764e7583b557680\",\"title\":\"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/102a2096ba2e2947dc252445f764e7583b557680\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34872975\",\"name\":\"Yi-Chang Shih\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/2508363.2508419\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8a44b6b3511073c1c0f8cb86f3848f3a7390d875\",\"title\":\"Data-driven hallucination of different times of day from a single outdoor photo\",\"url\":\"https://www.semanticscholar.org/paper/8a44b6b3511073c1c0f8cb86f3848f3a7390d875\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":\"1705.06830\",\"authors\":[{\"authorId\":\"1898210\",\"name\":\"G. Ghiasi\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"}],\"doi\":\"10.5244/C.31.114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7821cfd68b0b67e3c20dcbc82a71e77af9e09931\",\"title\":\"Exploring the structure of a real-time, arbitrary neural artistic stylization network\",\"url\":\"https://www.semanticscholar.org/paper/7821cfd68b0b67e3c20dcbc82a71e77af9e09931\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34872975\",\"name\":\"Yi-Chang Shih\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1145/2601097.2601137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cd92cebf0d14e0c8fcd6650b7b3166104d54cf4\",\"title\":\"Style transfer for headshot portraits\",\"url\":\"https://www.semanticscholar.org/paper/0cd92cebf0d14e0c8fcd6650b7b3166104d54cf4\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":\"1612.01895\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2177528\",\"name\":\"Geoffrey Oxholm\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/CVPR.2017.759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38ef32149e8a72c9c800b21faef29980be97d739\",\"title\":\"Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/38ef32149e8a72c9c800b21faef29980be97d739\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.08861\",\"authors\":[{\"authorId\":\"10753214\",\"name\":\"Aliaksandr Siarohin\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2019.00248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edce7f037c840b7db2612f47c35ae374c4a80e3a\",\"title\":\"Animating Arbitrary Objects via Deep Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/edce7f037c840b7db2612f47c35ae374c4a80e3a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1604.08610\",\"authors\":[{\"authorId\":\"37003547\",\"name\":\"M. Ruder\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-45886-1_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5181a9c3c9a36672a3890321dcc0faf4f8ea658e\",\"title\":\"Artistic Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/5181a9c3c9a36672a3890321dcc0faf4f8ea658e\",\"venue\":\"GCPR\",\"year\":2016},{\"arxivId\":\"1903.09760\",\"authors\":[{\"authorId\":\"8351571\",\"name\":\"Jaejun Yoo\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"2647582\",\"name\":\"Sanghyuk Chun\"},{\"authorId\":\"153798418\",\"name\":\"Byeongkyu Kang\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"}],\"doi\":\"10.1109/ICCV.2019.00913\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"d42c6d60e984880ca5528159f465f4b4ca2a03b5\",\"title\":\"Photorealistic Style Transfer via Wavelet Transforms\",\"url\":\"https://www.semanticscholar.org/paper/d42c6d60e984880ca5528159f465f4b4ca2a03b5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1611.07865\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"}],\"doi\":\"10.1109/CVPR.2017.397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acc529f6f65fbdbae1aff14682168b5132143f28\",\"title\":\"Controlling Perceptual Factors in Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/acc529f6f65fbdbae1aff14682168b5132143f28\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.04337\",\"authors\":[{\"authorId\":\"11126631\",\"name\":\"Tian Qi Chen\"},{\"authorId\":\"144314176\",\"name\":\"M. Schmidt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"790ca7b0a0076d1bb5a8161713f79ab1aef725b6\",\"title\":\"Fast Patch-based Style Transfer of Arbitrary Style\",\"url\":\"https://www.semanticscholar.org/paper/790ca7b0a0076d1bb5a8161713f79ab1aef725b6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2095748\",\"name\":\"Oriel Frigo\"},{\"authorId\":\"144797922\",\"name\":\"Neus Sabater\"},{\"authorId\":\"2816842\",\"name\":\"J. Delon\"},{\"authorId\":\"1806880\",\"name\":\"P. Hellier\"}],\"doi\":\"10.1109/CVPR.2016.66\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a760130b345fdce8cb7f463a17c8e8e662dcbc69\",\"title\":\"Split and Match: Example-Based Adaptive Patch Sampling for Unsupervised Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/a760130b345fdce8cb7f463a17c8e8e662dcbc69\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.09211\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2017.126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5b4144124f47a6357e6390dc6c0f8806ac54f5\",\"title\":\"Coherent Online Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/2d5b4144124f47a6357e6390dc6c0f8806ac54f5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Time Flies: Animating a Still Image With Time-Lapse Video As Reference\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"