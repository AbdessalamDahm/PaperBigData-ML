"{\"abstract\":\"Close-up talking heads are among the most common and salient object in video contents, such as face-to-face conversations in social media, teleconferences, news broadcasting, talk shows, etc. Due to the high sensitivity of human visual system to faces, compression distortions in talking heads videos are highly visible and annoying. To address this problem, we present a novel deep convolutional neural network (DCNN) method for very low bit rate video reconstruction of talking heads. The key innovation is a new DCNN architecture that can exploit the audio-video correlations to repair compression defects in the face region. We further improve reconstruction quality by embedding into our DCNN the encoder information of the video compression standards and introducing a constraining projection module in the network. Extensive experiments demonstrate that the proposed DCNN method outperforms the existing state-of-the-art methods on videos of talking heads.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"102356614\",\"name\":\"X. Zhang\",\"url\":\"https://www.semanticscholar.org/author/102356614\"},{\"authorId\":\"66653936\",\"name\":\"X. Wu\",\"url\":\"https://www.semanticscholar.org/author/66653936\"},{\"authorId\":\"103972572\",\"name\":\"Xinliang Zhai\",\"url\":\"https://www.semanticscholar.org/author/103972572\"},{\"authorId\":\"2163652\",\"name\":\"Xianye Ben\",\"url\":\"https://www.semanticscholar.org/author/2163652\"},{\"authorId\":\"40480346\",\"name\":\"C. Tu\",\"url\":\"https://www.semanticscholar.org/author/40480346\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"102356614\",\"name\":\"X. Zhang\"},{\"authorId\":\"28393867\",\"name\":\"Xiaolin Wu\"}],\"doi\":\"10.1109/TIP.2020.3040074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ec06c006dc2db532e83f314bd3163fb8c64c68a\",\"title\":\"Ultra High Fidelity Deep Image Decompression With l\\u221e-Constrained Compression\",\"url\":\"https://www.semanticscholar.org/paper/0ec06c006dc2db532e83f314bd3163fb8c64c68a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2011.15126\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f8974f6f9bc2febfb88ed3ffe12dfc9c441808\",\"title\":\"One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing\",\"url\":\"https://www.semanticscholar.org/paper/88f8974f6f9bc2febfb88ed3ffe12dfc9c441808\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219633603,\"doi\":\"10.1109/CVPR42600.2020.01235\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"3ac827181a5d1d4e27eb662c2547fd2d6eb87c3b\",\"references\":[{\"arxivId\":\"1705.02966\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.31.109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8632cf6c1ef4319966564328d187876d3bef363\",\"title\":\"You said that?\",\"url\":\"https://www.semanticscholar.org/paper/a8632cf6c1ef4319966564328d187876d3bef363\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1807.10550\",\"authors\":[{\"authorId\":\"8792285\",\"name\":\"Olivia Wiles\"},{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ea992f009492888c482d5f4006281eaa8b758e7\",\"title\":\"X2Face: A network for controlling face generation by using images, audio, and pose codes\",\"url\":\"https://www.semanticscholar.org/paper/9ea992f009492888c482d5f4006281eaa8b758e7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51462355\",\"name\":\"Xiongfei Zhang\"},{\"authorId\":\"28393867\",\"name\":\"Xiaolin Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58a3e96c29df4cb835560e7cc1960910594df455\",\"title\":\"Ultra High Fidelity Image Compression with \\ud835\\udcc1\\u221e-constrained Encoding and Deep Decoding\",\"url\":\"https://www.semanticscholar.org/paper/58a3e96c29df4cb835560e7cc1960910594df455\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.02898\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00342\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02c6f4bb3adb4ce080575c122eb6430d2dc2a8ef\",\"title\":\"TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/02c6f4bb3adb4ce080575c122eb6430d2dc2a8ef\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144273442\",\"name\":\"Guo Lu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-3-030-01264-9_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"36b2b8ede289ddd53e8afc8c066d9463969d40a2\",\"title\":\"Deep Kalman Filtering Network for Video Compression Artifact Reduction\",\"url\":\"https://www.semanticscholar.org/paper/36b2b8ede289ddd53e8afc8c066d9463969d40a2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3054554\",\"name\":\"N. Ketkar\"}],\"doi\":\"10.1007/978-1-4842-2766-4_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be0c539bec5c2d379ab1884e61a5bb8ccb91dc30\",\"title\":\"Introduction to PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/be0c539bec5c2d379ab1884e61a5bb8ccb91dc30\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49390793\",\"name\":\"A. Foi\"},{\"authorId\":\"1718100\",\"name\":\"V. Katkovnik\"},{\"authorId\":\"1683084\",\"name\":\"K. Egiazarian\"}],\"doi\":\"10.1109/TIP.2007.891788\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60e7d2cf0aa8088a9ba7a01b0aad19a61e441e0c\",\"title\":\"Pointwise Shape-Adaptive DCT for High-Quality Denoising and Deblocking of Grayscale and Color Images\",\"url\":\"https://www.semanticscholar.org/paper/60e7d2cf0aa8088a9ba7a01b0aad19a61e441e0c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47958020\",\"name\":\"X. Zhang\"},{\"authorId\":\"39529395\",\"name\":\"X. Wu\"}],\"doi\":\"10.1109/DCC.2019.00011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd72fca3e34ff7b46cc9987249fa9a4619ae1d92\",\"title\":\"Near-Lossless \\u2113\\u221e-Constrained Image Decompression via Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/fd72fca3e34ff7b46cc9987249fa9a4619ae1d92\",\"venue\":\"2019 Data Compression Conference (DCC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648413\",\"name\":\"Md. Sahidullah\"},{\"authorId\":\"143667260\",\"name\":\"G. Saha\"}],\"doi\":\"10.1016/J.SPECOM.2011.11.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e91b46e093ca2014e74fb0e7f490327ff00b0e7\",\"title\":\"Design, analysis and experimental evaluation of block based transformation in MFCC computation for speaker recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e91b46e093ca2014e74fb0e7f490327ff00b0e7\",\"venue\":\"Speech Commun.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tianfan Xue\"},{\"authorId\":null,\"name\":\"Baian Chen\"},{\"authorId\":null,\"name\":\"Jiajun Wu\"},{\"authorId\":null,\"name\":\"Donglai Wei\"},{\"authorId\":null,\"name\":\"William T Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video enhancement with taskoriented flow\",\"url\":\"\",\"venue\":\"International Journal of Computer Vision,\",\"year\":2019},{\"arxivId\":\"1611.04994\",\"authors\":[{\"authorId\":null,\"name\":\"Jun Guo\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"}],\"doi\":\"10.1109/CVPR.2017.517\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08c33f3d4a0d173e569d4dc67f462abc0eaf0e02\",\"title\":\"One-To-Many Network for Visually Pleasing Compression Artifacts Reduction\",\"url\":\"https://www.semanticscholar.org/paper/08c33f3d4a0d173e569d4dc67f462abc0eaf0e02\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1905.02716\",\"authors\":[{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"47841301\",\"name\":\"K. Yu\"},{\"authorId\":\"144964867\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPRW.2019.00247\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"28b3833743ab00904da1f4a30cd6c771cc164c0d\",\"title\":\"EDVR: Video Restoration With Enhanced Deformable Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/28b3833743ab00904da1f4a30cd6c771cc164c0d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1812.00101\",\"authors\":[{\"authorId\":\"144273442\",\"name\":\"Guo Lu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"8674725\",\"name\":\"C. Cai\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/CVPR.2019.01126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab995c4273111cde3e31ff7347c475aace10f1a5\",\"title\":\"DVC: An End-To-End Deep Video Compression Framework\",\"url\":\"https://www.semanticscholar.org/paper/ab995c4273111cde3e31ff7347c475aace10f1a5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.02518\",\"authors\":[{\"authorId\":\"9741214\",\"name\":\"L. Galteri\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"1801509\",\"name\":\"M. Bertini\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1109/ICCV.2017.517\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd9673c39a14aa5ac6898c8e132247e47fc81aaa\",\"title\":\"Deep Generative Adversarial Compression Artifact Removal\",\"url\":\"https://www.semanticscholar.org/paper/cd9673c39a14aa5ac6898c8e132247e47fc81aaa\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46781563\",\"name\":\"R. Yang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/ICME.2017.8019299\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d90e789ca4e1817a7a2edd0608753a1701850fcf\",\"title\":\"Decoder-side HEVC quality enhancement with scalable convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/d90e789ca4e1817a7a2edd0608753a1701850fcf\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1605.00366\",\"authors\":[{\"authorId\":\"47071858\",\"name\":\"P. Svoboda\"},{\"authorId\":\"1700956\",\"name\":\"Michal Hradi\\u0161\"},{\"authorId\":\"1977196\",\"name\":\"David Barina\"},{\"authorId\":\"1722571\",\"name\":\"P. Zem\\u010d\\u00edk\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d175d2bd607f7e749484be7696ca5f8f78d8b01d\",\"title\":\"Compression Artifacts Removal Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d175d2bd607f7e749484be7696ca5f8f78d8b01d\",\"venue\":\"J. WSCG\",\"year\":2016},{\"arxivId\":\"1806.05622\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1929\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8875ae233bc074f5cd6c4ebba447b536a7e847a5\",\"title\":\"VoxCeleb2: Deep Speaker Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8875ae233bc074f5cd6c4ebba447b536a7e847a5\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34591003\",\"name\":\"Huibin Chang\"},{\"authorId\":\"143620719\",\"name\":\"M. Ng\"},{\"authorId\":\"40227204\",\"name\":\"Tieyong Zeng\"}],\"doi\":\"10.1109/TSP.2013.2290508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"615fafc71d30e65ccf39b0eb39924ca2e6370291\",\"title\":\"Reducing Artifacts in JPEG Decompression Via a Learned Dictionary\",\"url\":\"https://www.semanticscholar.org/paper/615fafc71d30e65ccf39b0eb39924ca2e6370291\",\"venue\":\"IEEE Transactions on Signal Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48531638\",\"name\":\"T. Wiegand\"},{\"authorId\":\"1732207\",\"name\":\"G. Sullivan\"},{\"authorId\":\"66302887\",\"name\":\"Gisle Bj\\u00f8ntegaard\"},{\"authorId\":\"2402670\",\"name\":\"A. Luthra\"}],\"doi\":\"10.1109/TCSVT.2003.815165\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa8183ac0429f9b0240c0e21eb534b21ace08bb7\",\"title\":\"Overview of the H.264/AVC video coding standard\",\"url\":\"https://www.semanticscholar.org/paper/aa8183ac0429f9b0240c0e21eb534b21ace08bb7\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":2003},{\"arxivId\":\"1908.05717\",\"authors\":[{\"authorId\":\"3000952\",\"name\":\"A. Habibian\"},{\"authorId\":\"1388073495\",\"name\":\"T. V. Rozendaal\"},{\"authorId\":\"1849327\",\"name\":\"J. Tomczak\"},{\"authorId\":\"2056266\",\"name\":\"T. Cohen\"}],\"doi\":\"10.1109/ICCV.2019.00713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"341bce2c88f26f1d17b59730c5db993f6d19c31f\",\"title\":\"Video Compression With Rate-Distortion Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/341bce2c88f26f1d17b59730c5db993f6d19c31f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732207\",\"name\":\"G. Sullivan\"},{\"authorId\":\"145758269\",\"name\":\"J. Ohm\"},{\"authorId\":\"33906477\",\"name\":\"W. Han\"},{\"authorId\":\"1745395\",\"name\":\"T. Wiegand\"}],\"doi\":\"10.1109/TCSVT.2012.2221191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d94750bc374747d3e90c99e25ab2e238882f46ae\",\"title\":\"Overview of the High Efficiency Video Coding (HEVC) Standard\",\"url\":\"https://www.semanticscholar.org/paper/d94750bc374747d3e90c99e25ab2e238882f46ae\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2012},{\"arxivId\":\"1504.06993\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"48362742\",\"name\":\"Yubin Deng\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2015.73\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09642681d46282e76fd9d1336001ef6473b72ec8\",\"title\":\"Compression Artifacts Reduction by a Deep Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/09642681d46282e76fd9d1336001ef6473b72ec8\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51299945\",\"name\":\"Longtao Feng\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"49417698\",\"name\":\"Y. Wang\"},{\"authorId\":\"51130683\",\"name\":\"S. Ma\"}],\"doi\":\"10.1109/ICIP.2019.8803398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"931d579736907ae3f953065eb9d2f4c478effc13\",\"title\":\"Coding Prior Based High Efficiency Restoration for Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/931d579736907ae3f953065eb9d2f4c478effc13\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Thomas Wiegand\"},{\"authorId\":null,\"name\":\"Gary J Sullivan\"},{\"authorId\":null,\"name\":\"Gisle Bjontegaard\"},{\"authorId\":null,\"name\":\"Ajay Luthra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Overview of the h. 264/avc video coding stan- 12343 dard\",\"url\":\"\",\"venue\":\"IEEE Transactions on circuits and systems for video technology,\",\"year\":2003},{\"arxivId\":\"1805.09313\",\"authors\":[{\"authorId\":\"2160245\",\"name\":\"Konstantinos Vougioukas\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f722b0a7a9b7709d693b9d39195c779832a943fe\",\"title\":\"End-to-End Speech-Driven Facial Animation with Temporal GANs\",\"url\":\"https://www.semanticscholar.org/paper/f722b0a7a9b7709d693b9d39195c779832a943fe\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1712.09382\",\"authors\":[{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1411184751\",\"name\":\"Hayden Schoen\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1109/CVPR.2018.00790\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6d60aaad68fa78c914ee34c26bceab033a88622\",\"title\":\"Audio to Body Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/c6d60aaad68fa78c914ee34c26bceab033a88622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1805.03894\",\"authors\":[{\"authorId\":\"48535139\",\"name\":\"Xiaoyi He\"},{\"authorId\":\"152280946\",\"name\":\"Qiang Hu\"},{\"authorId\":\"2257769\",\"name\":\"Xintong Han\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICIP.2018.8451086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"874396290d59db23e7f47c76156aad428d18e0ae\",\"title\":\"Enhancing HEVC Compressed Videos with a Partition-Masked Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/874396290d59db23e7f47c76156aad428d18e0ae\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1905.03820\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4053196\",\"name\":\"Ross K. Maddox\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2019.00802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0852cd9a026bc90168fa85fa422cb0e48f98394\",\"title\":\"Hierarchical Cross-Modal Talking Face Generation With Dynamic Pixel-Wise Loss\",\"url\":\"https://www.semanticscholar.org/paper/a0852cd9a026bc90168fa85fa422cb0e48f98394\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xi Zhang\"},{\"authorId\":null,\"name\":\"Xiaolin Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Near-lossless l\\u221e-constrained image decompression via deep neural network\",\"url\":\"\",\"venue\":\"Data Compression Conference (DCC),\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amirhossein Habibian\"},{\"authorId\":null,\"name\":\"Ties van Rozendaal\"},{\"authorId\":null,\"name\":\"Jakub M Tomczak\"},{\"authorId\":null,\"name\":\"Taco S Cohen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video compression with ratedistortion autoencoders\",\"url\":\"\",\"venue\":\"In Proceedings of the IEEE International Conference on Computer Vision,\",\"year\":2019},{\"arxivId\":\"1803.04680\",\"authors\":[{\"authorId\":\"46781563\",\"name\":\"R. Yang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"47268256\",\"name\":\"T. Li\"}],\"doi\":\"10.1109/CVPR.2018.00697\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7a81d62767c12e72e8ba0ea427921f57ce67c78\",\"title\":\"Multi-frame Quality Enhancement for Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/c7a81d62767c12e72e8ba0ea427921f57ce67c78\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37016781\",\"name\":\"Supasorn Suwajanakorn\"},{\"authorId\":\"1396612598\",\"name\":\"Steven M. Seitz\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1145/3072959.3073640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"title\":\"Synthesizing Obama\",\"url\":\"https://www.semanticscholar.org/paper/7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2315694\",\"name\":\"F. Bossen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d5157f99ee53e2786c0d676d0e5d50fc58dbee9\",\"title\":\"Common test conditions and software reference configurations\",\"url\":\"https://www.semanticscholar.org/paper/1d5157f99ee53e2786c0d676d0e5d50fc58dbee9\",\"venue\":\"\",\"year\":2010},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145093159\",\"name\":\"M. Xu\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144029642\",\"name\":\"L. Chia\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-540-30543-9_71\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc8511a97dcf8031c4936a7f9790021fa6227e00\",\"title\":\"HMM-Based Audio Keyword Generation\",\"url\":\"https://www.semanticscholar.org/paper/cc8511a97dcf8031c4936a7f9790021fa6227e00\",\"venue\":\"PCM\",\"year\":2004},{\"arxivId\":\"1706.08612\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2017-950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a26431833b0ea8659ef1d24bff3ac9e56dcfcd0\",\"title\":\"VoxCeleb: A Large-Scale Speaker Identification Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8a26431833b0ea8659ef1d24bff3ac9e56dcfcd0\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"145419122\",\"name\":\"R. Xiong\"},{\"authorId\":\"1800904\",\"name\":\"X. Fan\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TIP.2013.2274386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf676ccd45746182c6553c391ab834f34f072da5\",\"title\":\"Compression Artifact Reduction by Overlapped-Block Transform Coefficient Estimation With Block Similarity\",\"url\":\"https://www.semanticscholar.org/paper/bf676ccd45746182c6553c391ab834f34f072da5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":\"1510.09041\",\"authors\":[{\"authorId\":\"34151629\",\"name\":\"Y. Dar\"},{\"authorId\":\"143610924\",\"name\":\"A. Bruckstein\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"},{\"authorId\":\"2711839\",\"name\":\"Raja Giryes\"}],\"doi\":\"10.1109/TIP.2016.2558825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e458ef5a1515f5273e0c950f61826ad7161b363\",\"title\":\"Postprocessing of Compressed Images via Sequential Denoising\",\"url\":\"https://www.semanticscholar.org/paper/4e458ef5a1515f5273e0c950f61826ad7161b363\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1804.04121\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"title\":\"The Conversation: Deep Audio-Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3503889\",\"name\":\"Y. Li\"},{\"authorId\":\"144801182\",\"name\":\"Fangfang Guo\"},{\"authorId\":\"1726720\",\"name\":\"R. Tan\"},{\"authorId\":\"143955418\",\"name\":\"M. S. Brown\"}],\"doi\":\"10.1007/978-3-319-10605-2_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60a6ef171462ac1b0d7ef1e6c54e33f54da2c2b\",\"title\":\"A Contrast Enhancement Framework with JPEG Artifacts Suppression\",\"url\":\"https://www.semanticscholar.org/paper/e60a6ef171462ac1b0d7ef1e6c54e33f54da2c2b\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1703.06211\",\"authors\":[{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"7217794\",\"name\":\"Haozhi Qi\"},{\"authorId\":\"3372084\",\"name\":\"Y. Xiong\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"46266081\",\"name\":\"Guodong Zhang\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/ICCV.2017.89\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a73a1840945e87583d89ca0216a2c449d50a4a3\",\"title\":\"Deformable Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/4a73a1840945e87583d89ca0216a2c449d50a4a3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1910.12286\",\"authors\":[{\"authorId\":\"153018917\",\"name\":\"Y. Xu\"},{\"authorId\":\"3036495\",\"name\":\"Longwen Gao\"},{\"authorId\":\"47853648\",\"name\":\"Kai Tian\"},{\"authorId\":\"1788230\",\"name\":\"Shuigeng Zhou\"},{\"authorId\":\"52177693\",\"name\":\"Huyang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76b76aeb4add1f2f6a59e08b4c6b2ca3dc7685b8\",\"title\":\"Non-Local ConvLSTM for Video Compression Artifact Reduction\",\"url\":\"https://www.semanticscholar.org/paper/76b76aeb4add1f2f6a59e08b4c6b2ca3dc7685b8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Thomas Wiegand\"},{\"authorId\":null,\"name\":\"Gary J Sullivan\"},{\"authorId\":null,\"name\":\"Gisle Bjontegaard\"},{\"authorId\":null,\"name\":\"Ajay Luthra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Overview of the h. 264/avc video coding stan- 12340 dard\",\"url\":\"\",\"venue\":\"IEEE Transactions on circuits and systems for video technology,\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144089337\",\"name\":\"T. Sikora\"}],\"doi\":\"10.1109/76.554415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97f3c27be4f11207172c711e762da5d75999e314\",\"title\":\"The MPEG-4 video standard verification model\",\"url\":\"https://www.semanticscholar.org/paper/97f3c27be4f11207172c711e762da5d75999e314\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":1997},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018}],\"title\":\"DAVD-Net: Deep Audio-Aided Video Decompression of Talking Heads\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/3ac827181a5d1d4e27eb662c2547fd2d6eb87c3b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"