"{\"abstract\":\"Scene, as the crucial unit of storytelling in movies, contains complex activities of actors and their interactions in a physical environment. Identifying the composition of scenes serves as a critical step towards semantic understanding of movies. This is very challenging \\u2013 compared to the videos studied in conventional vision problems, e.g. action recognition, as scenes in movies usually contain much richer temporal structures and more complex semantic information. Towards this goal, we scale up the scene segmentation task by building a large-scale video dataset MovieScenes, which contains 21K annotated scene segments from 150 movies. We further propose a local-to-global scene segmentation framework, which integrates multi-modal information across three levels, i.e. clip, segment, and movie. This framework is able to distill complex semantics from hierarchical temporal structures over a long movie, providing top-down guidance for scene segmentation. Our experiments show that the proposed network is able to segment a movie into scenes with high accuracy, consistently outperforming previous methods. We also found that pretraining on our MovieScenes can bring significant improvements to the existing approaches.\",\"arxivId\":\"2004.02678\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\",\"url\":\"https://www.semanticscholar.org/author/36290866\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\",\"url\":\"https://www.semanticscholar.org/author/150196512\"},{\"authorId\":\"145984816\",\"name\":\"Y. Xiong\",\"url\":\"https://www.semanticscholar.org/author/145984816\"},{\"authorId\":\"48048546\",\"name\":\"Guo-dong Xu\",\"url\":\"https://www.semanticscholar.org/author/48048546\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\",\"url\":\"https://www.semanticscholar.org/author/39360892\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\",\"url\":\"https://www.semanticscholar.org/author/145291669\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\",\"url\":\"https://www.semanticscholar.org/author/1807606\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"92091076\",\"name\":\"F. Yu\"},{\"authorId\":\"40562866\",\"name\":\"Dandan Wang\"},{\"authorId\":\"46824108\",\"name\":\"Bei-Bei Zhang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"}],\"doi\":\"10.1145/3394171.3416303\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4bea43910441bfdb2e3f4223c6f30269128fccf\",\"title\":\"Deep Relationship Analysis in Video with Multimodal Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/a4bea43910441bfdb2e3f4223c6f30269128fccf\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"1807515831\",\"name\":\"Lei Yang\"},{\"authorId\":\"2837671\",\"name\":\"Huaiyi Huang\"},{\"authorId\":\"150325884\",\"name\":\"T. Wu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58520-4_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2dd5b397c86da5bc916b1a0c5b96d9a87ab8e52d\",\"title\":\"Caption-Supervised Face Recognition: Training a State-of-the-Art Face Model Without Manual Annotation\",\"url\":\"https://www.semanticscholar.org/paper/2dd5b397c86da5bc916b1a0c5b96d9a87ab8e52d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443763209\",\"name\":\"Morgan Freeman\"},{\"authorId\":\"144255428\",\"name\":\"W. Sadler\"},{\"authorId\":null,\"name\":\"Larry Brandenburg\"},{\"authorId\":null,\"name\":\"Neil Giuntoli\"},{\"authorId\":null,\"name\":\"Brian Libby\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ea81dc0cedefcc547927b790a3062ea239df9be\",\"title\":\"Caption-Supervised Face Recognition: Training a State-of-the-Art Face Model without Manual Annotation\",\"url\":\"https://www.semanticscholar.org/paper/0ea81dc0cedefcc547927b790a3062ea239df9be\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.10937\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58548-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0732df185bdfcb9c908ec30bb441252593f58875\",\"title\":\"MovieNet: A Holistic Dataset for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0732df185bdfcb9c908ec30bb441252593f58875\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.03548\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"80180784\",\"name\":\"Xuekun Jiang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58621-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"title\":\"A Unified Framework for Shot Type Classification Based on Subject Centric Lens\",\"url\":\"https://www.semanticscholar.org/paper/49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.04208\",\"authors\":[{\"authorId\":\"153000035\",\"name\":\"M. Bain\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"152853748\",\"name\":\"A. Brown\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"title\":\"Condensed Movies: Story Based Retrieval with Contextual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03546\",\"authors\":[{\"authorId\":\"1657277123\",\"name\":\"J. Xia\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"49320456\",\"name\":\"Jiangtao Wen\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58610-2_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e71db960a43bf26d9de3515652f04579952ab6ff\",\"title\":\"Online Multi-modal Person Search in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e71db960a43bf26d9de3515652f04579952ab6ff\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.03777\",\"authors\":[{\"authorId\":\"1500388631\",\"name\":\"Huai-Yi Huang\"},{\"authorId\":\"1591146277\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"92138570\",\"name\":\"Z. Guo\"},{\"authorId\":\"3173957\",\"name\":\"Z. Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58589-1_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8a8dcb20f7836da0578fb4f14e15cb569956502\",\"title\":\"Placepedia: Comprehensive Place Understanding with Multi-Faceted Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d8a8dcb20f7836da0578fb4f14e15cb569956502\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.09843\",\"authors\":[{\"authorId\":\"2829330\",\"name\":\"Georgios Pavlakos\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3b7f93faa93034ea9425964a7696a5f9ecc1b0e\",\"title\":\"Human Mesh Recovery from Multiple Shots\",\"url\":\"https://www.semanticscholar.org/paper/c3b7f93faa93034ea9425964a7696a5f9ecc1b0e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.08802\",\"authors\":[{\"authorId\":\"1807515831\",\"name\":\"Lei Yang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"1500388631\",\"name\":\"Huai-Yi Huang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4c52a81246b2d4458d29ba231a6c211c19e370b\",\"title\":\"Learn to Propagate Reliably on Noisy Affinity Graphs\",\"url\":\"https://www.semanticscholar.org/paper/e4c52a81246b2d4458d29ba231a6c211c19e370b\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":214802984,\"doi\":\"10.1109/cvpr42600.2020.01016\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"3214f9ed95d89c04ebc16c3a142c2ece98d66e75\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3040550\",\"name\":\"Vasileios Chasanis\"},{\"authorId\":\"1717776\",\"name\":\"A. Likas\"},{\"authorId\":\"143949487\",\"name\":\"N. Galatsanos\"}],\"doi\":\"10.1109/TMM.2008.2008924\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c5f53ee0cf3aa8b27af3e375c63c52bdc10e0633\",\"title\":\"Scene Detection in Videos Using Shot Clustering and Sequence Alignment\",\"url\":\"https://www.semanticscholar.org/paper/c5f53ee0cf3aa8b27af3e375c63c52bdc10e0633\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143869248\",\"name\":\"C. Liang\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-642-10467-1_82\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88beeb7e13709444a49c2b4021f8599e3cd475dd\",\"title\":\"A Novel Role-Based Movie Scene Segmentation Method\",\"url\":\"https://www.semanticscholar.org/paper/88beeb7e13709444a49c2b4021f8599e3cd475dd\",\"venue\":\"PCM\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"36547202\",\"name\":\"D. Porat\"},{\"authorId\":\"3243379\",\"name\":\"G. Ashour\"}],\"doi\":\"10.1142/S1793351X17400086\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"013b7c1a36b4a0414409d5044868bffd33a904e7\",\"title\":\"Optimal Sequential Grouping for Robust Video Scene Detection Using Multiple Modalities\",\"url\":\"https://www.semanticscholar.org/paper/013b7c1a36b4a0414409d5044868bffd33a904e7\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"123371831\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2723009\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f986968735459e789890f24b6b277b0920a9725d\",\"title\":\"Places: A 10 Million Image Database for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f986968735459e789890f24b6b277b0920a9725d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"title\":\"Situation Recognition: Visual Semantic Role Labeling for Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1712.06761\",\"authors\":[{\"authorId\":\"2039154\",\"name\":\"Paul Vicol\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523574aca71d8981b4122cce8d132f22391ef26e\",\"title\":\"MovieGraphs: Towards Understanding Human-Centric Situations from Videos\",\"url\":\"https://www.semanticscholar.org/paper/523574aca71d8981b4122cce8d132f22391ef26e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143980328\",\"name\":\"J. Roth\"},{\"authorId\":\"1680841\",\"name\":\"S. Chaudhuri\"},{\"authorId\":\"3285011\",\"name\":\"Ondrej Klejch\"},{\"authorId\":\"47260264\",\"name\":\"R. Marvin\"},{\"authorId\":\"50716462\",\"name\":\"A. Gallagher\"},{\"authorId\":\"51211970\",\"name\":\"Liat Kaver\"},{\"authorId\":\"114997760\",\"name\":\"S. Ramaswamy\"},{\"authorId\":\"3272173\",\"name\":\"Arkadiusz Stopczynski\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"37669762\",\"name\":\"Zhonghua Xi\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a70f2f1a25015c93a2f354cc8225a7b3363e0b0e\",\"title\":\"Ava Active Speaker: An Audio-Visual Dataset for Active Speaker Detection\",\"url\":\"https://www.semanticscholar.org/paper/a70f2f1a25015c93a2f354cc8225a7b3363e0b0e\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"40085065\",\"name\":\"Percy Liang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-10590-1_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0a083c7bb23db507a40a736953b1cca5a33b16d\",\"title\":\"Linking People in Videos with \\\"Their\\\" Names Using Coreference Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a0a083c7bb23db507a40a736953b1cca5a33b16d\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143956471\",\"name\":\"Z. Rasheed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2003.1211489\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e757dddc31a08dd8e6b3624ec67e761355893bc\",\"title\":\"Scene detection in Hollywood movies and TV shows\",\"url\":\"https://www.semanticscholar.org/paper/5e757dddc31a08dd8e6b3624ec67e761355893bc\",\"venue\":\"2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145788741\",\"name\":\"S. Umesh\"},{\"authorId\":\"144049712\",\"name\":\"L. Cohen\"},{\"authorId\":\"1774571\",\"name\":\"D. Nelson\"}],\"doi\":\"10.1109/ICASSP.1999.758101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be162e210736a292f433cb66129f66558bfe0f47\",\"title\":\"Fitting the Mel scale\",\"url\":\"https://www.semanticscholar.org/paper/be162e210736a292f433cb66129f66558bfe0f47\",\"venue\":\"1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145683466\",\"name\":\"Stanislav Protasov\"},{\"authorId\":\"1714762\",\"name\":\"A. Khan\"},{\"authorId\":\"26433379\",\"name\":\"Konstantin Sozykin\"},{\"authorId\":\"145958195\",\"name\":\"Muhammad Ahmad\"}],\"doi\":\"10.1007/s11760-018-1244-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6490168437aee407474704c947316fb92716ff4a\",\"title\":\"Using deep features for video scene detection and annotation\",\"url\":\"https://www.semanticscholar.org/paper/6490168437aee407474704c947316fb92716ff4a\",\"venue\":\"Signal Image Video Process.\",\"year\":2018},{\"arxivId\":\"1501.05703\",\"authors\":[{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"}],\"doi\":\"10.1109/CVPR.2015.7299113\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2150d110c1147155dab519150f4175830d5a9f1\",\"title\":\"Beyond frontal faces: Improving Person Recognition using multiple cues\",\"url\":\"https://www.semanticscholar.org/paper/d2150d110c1147155dab519150f4175830d5a9f1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Brandon Castellano\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pyscenedetect: Intelligent scene cut detection and video splitting tool. https:// pyscenedetect.readthedocs.io/en/latest/, 2018\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"},{\"authorId\":\"144156242\",\"name\":\"S. Mehrotra\"}],\"doi\":\"10.1109/MMCS.1998.693648\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fe7a97e211a35042fc5b5eae38c883376986991\",\"title\":\"Exploring video structure beyond the shots\",\"url\":\"https://www.semanticscholar.org/paper/9fe7a97e211a35042fc5b5eae38c883376986991\",\"venue\":\"Proceedings. IEEE International Conference on Multimedia Computing and Systems (Cat. No.98TB100241)\",\"year\":1998},{\"arxivId\":\"1510.08893\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1705203\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/2733373.2806316\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ae0a11ddb84856a27c7ee2b854711a59db9d22e\",\"title\":\"A Deep Siamese Network for Scene Detection in Broadcast Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ae0a11ddb84856a27c7ee2b854711a59db9d22e\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Brandon Castellano\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pyscenedetect: Intelligent scene cut detection and video splitting tool\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.10555\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"159bff6787ea1a034d1eedaae60d4d55cb0284d0\",\"title\":\"Naver at ActivityNet Challenge 2019 - Task B Active Speaker Detection (AVA)\",\"url\":\"https://www.semanticscholar.org/paper/159bff6787ea1a034d1eedaae60d4d55cb0284d0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"1931707\",\"name\":\"M. B\\u00e4uml\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2014.111\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"beed70985ea523474fe0903fbb1dbae98b7fbe73\",\"title\":\"StoryGraphs: Visualizing Character Interactions as a Timeline\",\"url\":\"https://www.semanticscholar.org/paper/beed70985ea523474fe0903fbb1dbae98b7fbe73\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.04474\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c5f9f5083b9fca4dcdbc4b122099ac1f630728b\",\"title\":\"Visual Semantic Role Labeling\",\"url\":\"https://www.semanticscholar.org/paper/0c5f9f5083b9fca4dcdbc4b122099ac1f630728b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2013.283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d766bb9364326fbca3d3b40606c6ed5db54f081\",\"title\":\"Finding Actors and Actions in Movies\",\"url\":\"https://www.semanticscholar.org/paper/4d766bb9364326fbca3d3b40606c6ed5db54f081\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143956471\",\"name\":\"Z. Rasheed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TMM.2005.858392\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7b6bf532f7e2b32b332116c66b8a4eab3da8136f\",\"title\":\"Detection and representation of scenes in videos\",\"url\":\"https://www.semanticscholar.org/paper/7b6bf532f7e2b32b332116c66b8a4eab3da8136f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2005},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1016/j.neunet.2005.06.042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2f83f6e1afadf0963153974968af6b8342775d82\",\"title\":\"Framewise phoneme classification with bidirectional LSTM and other neural network architectures\",\"url\":\"https://www.semanticscholar.org/paper/2f83f6e1afadf0963153974968af6b8342775d82\",\"venue\":\"Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bo Han\"},{\"authorId\":\"144771250\",\"name\":\"Weiguo Wu\"}],\"doi\":\"10.1109/ICME.2011.6012001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5664603236c524282e67452435e330c94898ea83\",\"title\":\"Video scene segmentation using a novel boundary evaluation criterion and dynamic programming\",\"url\":\"https://www.semanticscholar.org/paper/5664603236c524282e67452435e330c94898ea83\",\"venue\":\"2011 IEEE International Conference on Multimedia and Expo\",\"year\":2011},{\"arxivId\":\"1806.03084\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00236\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2fe7105ef8e61330a3ddc7f7b35955ca62fc1ab3\",\"title\":\"Unifying Identification and Context Learning for Person Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2fe7105ef8e61330a3ddc7f7b35955ca62fc1ab3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726550\",\"name\":\"P. Sidiropoulos\"},{\"authorId\":\"1737436\",\"name\":\"V. Mezaris\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"},{\"authorId\":\"1748419\",\"name\":\"H. Meinedo\"},{\"authorId\":\"1678804\",\"name\":\"M. Bugalho\"},{\"authorId\":\"1691021\",\"name\":\"I. Trancoso\"}],\"doi\":\"10.1109/TCSVT.2011.2138830\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"494a01c87311a62aedafba3742ed227e36798ed3\",\"title\":\"Temporal Video Segmentation to Scenes Using High-Level Audiovisual Features\",\"url\":\"https://www.semanticscholar.org/paper/494a01c87311a62aedafba3742ed227e36798ed3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2011}],\"title\":\"A Local-to-Global Approach to Multi-Modal Movie Scene Segmentation\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"}],\"url\":\"https://www.semanticscholar.org/paper/3214f9ed95d89c04ebc16c3a142c2ece98d66e75\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"