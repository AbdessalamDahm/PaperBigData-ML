"{\"abstract\":\"Much of vision-and-language research focuses on a small but diverse set of independent tasks and supporting datasets often studied in isolation; however, the visually-grounded language understanding skills required for success at these tasks overlap significantly. In this work, we investigate these relationships between vision-and-language tasks by developing a large-scale, multi-task model. Our approach culminates in a single model on 12 datasets from four broad categories of task including visual question answering, caption-based image retrieval, grounding referring expressions, and multimodal verification. Compared to independently trained single-task models, this represents a reduction from approximately 3 billion parameters to 270 million while simultaneously improving performance by 2.05 points on average across tasks. We use our multi-task framework to perform in-depth analysis of the effect of joint training diverse tasks. Further, we show that finetuning task-specific models from our single multi-task model can lead to further improvements, achieving performance at or above the state-of-the-art.\",\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\",\"url\":\"https://www.semanticscholar.org/author/8553015\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\",\"url\":\"https://www.semanticscholar.org/author/28554843\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\",\"url\":\"https://www.semanticscholar.org/author/121944615\"}],\"citationVelocity\":18,\"citations\":[{\"arxivId\":\"2012.08673\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c8f6878dac0c5c99c192ded715d2e864eed7302\",\"title\":\"A Closer Look at the Robustness of Vision-and-Language Pre-trained Models\",\"url\":\"https://www.semanticscholar.org/paper/3c8f6878dac0c5c99c192ded715d2e864eed7302\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.06587\",\"authors\":[{\"authorId\":\"3440700\",\"name\":\"Bhanu Pratap Singh Rawat\"},{\"authorId\":\"2088565\",\"name\":\"Wei-Hung Weng\"},{\"authorId\":\"30088877\",\"name\":\"P. Raghavan\"},{\"authorId\":\"1679873\",\"name\":\"Peter Szolovits\"}],\"doi\":\"10.18653/v1/2020.bionlp-1.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18629f4edead8bcf07e5ef694914ba83dd1e9666\",\"title\":\"Entity-Enriched Neural Models for Clinical Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/18629f4edead8bcf07e5ef694914ba83dd1e9666\",\"venue\":\"BioNLP\",\"year\":2020},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40062064\",\"name\":\"Claudio Greco\"},{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fea5b24f57703f596fa01c188c3e445fa14994df\",\"title\":\"Which Turn do Neural Models Exploit the Most to Solve GuessWhat? Diving into the Dialogue History Encoding in Transformers and LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/fea5b24f57703f596fa01c188c3e445fa14994df\",\"venue\":\"NL4AI@AI*IA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01082\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"title\":\"Multi-Modal Open-Domain Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08895\",\"authors\":[{\"authorId\":\"40140266\",\"name\":\"Duc-Trong Le\"},{\"authorId\":\"2399573\",\"name\":\"Xuan-Son Vu\"},{\"authorId\":\"2037851165\",\"name\":\"Nhu-Dung To\"},{\"authorId\":\"47321130\",\"name\":\"Huu-Quang Nguyen\"},{\"authorId\":\"35112441\",\"name\":\"Thuy-Trinh Nguyen\"},{\"authorId\":\"143927897\",\"name\":\"L. Le\"},{\"authorId\":\"122285683\",\"name\":\"Anh-Tuan Nguyen\"},{\"authorId\":\"1388547137\",\"name\":\"Minh-Duc Hoang\"},{\"authorId\":\"6447563\",\"name\":\"Nghia T V Le\"},{\"authorId\":\"2155469\",\"name\":\"Huyen Nguyen\"},{\"authorId\":\"145862982\",\"name\":\"Hoang D. Nguyen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6da6519ab8e37cbe7ede0cf8f370bcaf590d9c4\",\"title\":\"ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites\",\"url\":\"https://www.semanticscholar.org/paper/f6da6519ab8e37cbe7ede0cf8f370bcaf590d9c4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.04638\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"46583994\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1882479\",\"name\":\"D. Flor\\u00eancio\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"145637095\",\"name\":\"Lei Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"title\":\"TAP: Text-Aware Pre-training for Text-VQA and Text-Caption\",\"url\":\"https://www.semanticscholar.org/paper/8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.12352\",\"authors\":[{\"authorId\":\"1845867134\",\"name\":\"Letitia Parcalabescu\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"143876555\",\"name\":\"A. Frank\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"title\":\"Seeing past words: Testing the cross-modal capabilities of pretrained V&L models\",\"url\":\"https://www.semanticscholar.org/paper/1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.09796\",\"authors\":[{\"authorId\":\"145868671\",\"name\":\"M. Crawshaw\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"title\":\"Multi-Task Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13866918\",\"name\":\"X. Wang\"},{\"authorId\":\"49816509\",\"name\":\"Xiaowen Sun\"},{\"authorId\":\"1518331899\",\"name\":\"Tan Yang\"},{\"authorId\":\"30865675\",\"name\":\"Hongbo Wang\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ff77ce37f8be50a7eb7ea7388f47d8e669d67beb\",\"title\":\"Building a Bridge: A Method for Image-Text Sarcasm Detection Without Pretraining on Image-Text Data\",\"url\":\"https://www.semanticscholar.org/paper/ff77ce37f8be50a7eb7ea7388f47d8e669d67beb\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"467ac47b2e01ce6ae74e8d70561ca0f8f66c7b8c\",\"title\":\"Probing Text Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/467ac47b2e01ce6ae74e8d70561ca0f8f66c7b8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08744\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"title\":\"Are we pretraining it right? Digging deeper into visio-linguistic pretraining\",\"url\":\"https://www.semanticscholar.org/paper/43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"49617533\",\"name\":\"P. Allen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"189b518d70ad34c8de6f613bf3bd5051077608bc\",\"title\":\"Probing Language Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/189b518d70ad34c8de6f613bf3bd5051077608bc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.08395\",\"authors\":[{\"authorId\":\"4852522\",\"name\":\"Tariq Habib Afridi\"},{\"authorId\":\"47686775\",\"name\":\"Aftab Alam\"},{\"authorId\":\"1645748271\",\"name\":\"M. N. Khan\"},{\"authorId\":\"1649689679\",\"name\":\"Jawad Khan\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0903f184dfccc813d8165d0f69c87f79520014e\",\"title\":\"A Multimodal Memes Classification: A Survey and Open Research Issues\",\"url\":\"https://www.semanticscholar.org/paper/b0903f184dfccc813d8165d0f69c87f79520014e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1912.12394\",\"authors\":[{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4aa5454addde1542e0d01cfc68e6f5129630964d\",\"title\":\"All-in-One Image-Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/4aa5454addde1542e0d01cfc68e6f5129630964d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.13922\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d16bce335338372c1927f69d4b1f667a330b59d2\",\"title\":\"A Recurrent Vision-and-Language BERT for Navigation\",\"url\":\"https://www.semanticscholar.org/paper/d16bce335338372c1927f69d4b1f667a330b59d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.02174\",\"authors\":[{\"authorId\":\"3444866\",\"name\":\"Alessandro Suglia\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"34742006\",\"name\":\"Andrea Vanzo\"},{\"authorId\":\"2972920\",\"name\":\"E. Bastianelli\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"}],\"doi\":\"10.18653/V1/2020.ACL-MAIN.682\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"title\":\"CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2005.07310\",\"authors\":[{\"authorId\":\"1701219797\",\"name\":\"Jize Cao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"46700583\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1007/978-3-030-58539-6_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26cfb57a9722599b361858d454ec816420723e36\",\"title\":\"Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models\",\"url\":\"https://www.semanticscholar.org/paper/26cfb57a9722599b361858d454ec816420723e36\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.01002\",\"authors\":[{\"authorId\":\"2030527923\",\"name\":\"Xiayu Zhong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0646fda8bd8003df23dcd53caec403c9fd840a7\",\"title\":\"Classification of Multimodal Hate Speech - The Winning Solution of Hateful Memes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/f0646fda8bd8003df23dcd53caec403c9fd840a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2011.15124\",\"authors\":[{\"authorId\":\"83574123\",\"name\":\"Emanuele Bugliarello\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"title\":\"Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs\",\"url\":\"https://www.semanticscholar.org/paper/82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.16934\",\"authors\":[{\"authorId\":\"40471592\",\"name\":\"Fei Yu\"},{\"authorId\":\"11713158\",\"name\":\"Jiji Tang\"},{\"authorId\":\"2318321\",\"name\":\"Weichong Yin\"},{\"authorId\":\"144825828\",\"name\":\"Y. Sun\"},{\"authorId\":null,\"name\":\"Hao Tian\"},{\"authorId\":\"120155201\",\"name\":\"Hua Wu\"},{\"authorId\":\"144270729\",\"name\":\"Haifeng Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e34cf702b9c90889e268380572bec782280b59c3\",\"title\":\"ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/e34cf702b9c90889e268380572bec782280b59c3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"152333274\",\"name\":\"Seunghyun Yoon\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"2007775508\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":\"10.18653/v1/2020.eval4nlp-1.4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2be4e374800a0db69695eb4c558a6653dd258fcd\",\"title\":\"ViLBERTScore: Evaluating Image Caption Using Vision-and-Language BERT\",\"url\":\"https://www.semanticscholar.org/paper/2be4e374800a0db69695eb4c558a6653dd258fcd\",\"venue\":\"EVAL4NLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"11882893\",\"name\":\"A. Yang\"},{\"authorId\":\"29343468\",\"name\":\"Yichang Zhang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"1709595\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"38385080\",\"name\":\"Hongxia Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee4918cc9b1dc28007454490fbe8366ec017b33d\",\"title\":\"InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/ee4918cc9b1dc28007454490fbe8366ec017b33d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.11740\",\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1007/978-3-030-58577-8_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"title\":\"UNITER: UNiversal Image-TExt Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.12146\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"},{\"authorId\":\"5153264\",\"name\":\"A. Schwing\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":\"10.1007/978-3-030-58545-7_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"title\":\"Spatially Aware Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.10731\",\"authors\":[{\"authorId\":\"151253861\",\"name\":\"Weixin Liang\"},{\"authorId\":\"7650020\",\"name\":\"Feiyang Niu\"},{\"authorId\":\"8856206\",\"name\":\"Aishwarya N. Reganti\"},{\"authorId\":\"2028300167\",\"name\":\"Govind Thattai\"},{\"authorId\":\"1748051\",\"name\":\"G. T\\u00fcr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86fdbc4540d146b0a2d7d61bf9f0109fa1331dac\",\"title\":\"LRTA: A Transparent Neural-Symbolic Reasoning Framework with Modular Supervision for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86fdbc4540d146b0a2d7d61bf9f0109fa1331dac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06087\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"32587693\",\"name\":\"A. Moudgil\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ead5088bc1922526be9a503dd42b15d467b962\",\"title\":\"Contrast and Classify: Alternate Training for Robust VQA\",\"url\":\"https://www.semanticscholar.org/paper/35ead5088bc1922526be9a503dd42b15d467b962\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.11278\",\"authors\":[{\"authorId\":\"2706729\",\"name\":\"Jaemin Cho\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.707\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"title\":\"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.00619\",\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"title\":\"Probing Contextual Language Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13198\",\"authors\":[{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"11882893\",\"name\":\"A. Yang\"},{\"authorId\":\"29343468\",\"name\":\"Yichang Zhang\"},{\"authorId\":\"1618186344\",\"name\":\"Jie Liu\"},{\"authorId\":\"1726030259\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"1712223662\",\"name\":\"Hongxia Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9779ddeb6a8a9de0f7e104d8742728aa14578d6\",\"title\":\"InterBERT: An Effective Multi-Modal Pretraining Approach via Vision-and-Language Interaction\",\"url\":\"https://www.semanticscholar.org/paper/b9779ddeb6a8a9de0f7e104d8742728aa14578d6\",\"venue\":\"\",\"year\":2020}],\"corpusId\":208637516,\"doi\":\"10.1109/cvpr42600.2020.01045\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1390156.1390177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57458bc1cffe5caa45a885af986d70f723f406b4\",\"title\":\"A unified architecture for natural language processing: deep neural networks with multitask learning\",\"url\":\"https://www.semanticscholar.org/paper/57458bc1cffe5caa45a885af986d70f723f406b4\",\"venue\":\"ICML '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kevin Clark\"},{\"authorId\":null,\"name\":\"Minh-Thang Luong\"},{\"authorId\":null,\"name\":\"Urvashi Khandelwal\"},{\"authorId\":null,\"name\":\"Christopher D Manning\"},{\"authorId\":null,\"name\":\"Quoc V Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bam! bornagain multi-task networks for natural language understanding\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1907.04829,\",\"year\":1907},{\"arxivId\":\"1907.11692\",\"authors\":[{\"authorId\":\"118656283\",\"name\":\"Y. Liu\"},{\"authorId\":\"40511414\",\"name\":\"Myle Ott\"},{\"authorId\":\"39589154\",\"name\":\"Naman Goyal\"},{\"authorId\":\"3048577\",\"name\":\"Jingfei Du\"},{\"authorId\":\"144863691\",\"name\":\"Mandar Joshi\"},{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1759422\",\"name\":\"Veselin Stoyanov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de\",\"title\":\"RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\"url\":\"https://www.semanticscholar.org/paper/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.06066\",\"authors\":[{\"authorId\":\"150112700\",\"name\":\"Gen Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"143795948\",\"name\":\"Yuejian Fang\"},{\"authorId\":\"71790825\",\"name\":\"Daxin Jiang\"},{\"authorId\":\"143849622\",\"name\":\"M. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I07.6795\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2bc1c8bd00bbf7401afcb5460277840fd8bab029\",\"title\":\"Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/2bc1c8bd00bbf7401afcb5460277840fd8bab029\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yee Teh\"},{\"authorId\":null,\"name\":\"Victor Bapst\"},{\"authorId\":null,\"name\":\"Wojciech M Czarnecki\"},{\"authorId\":null,\"name\":\"John Quan\"},{\"authorId\":null,\"name\":\"James Kirkpatrick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Distral : Robust multitask reinforcement learn\",\"url\":\"\",\"venue\":\"In ACL\",\"year\":null},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1907.04829\",\"authors\":[{\"authorId\":\"144358401\",\"name\":\"Kevin Clark\"},{\"authorId\":\"1707242\",\"name\":\"Minh-Thang Luong\"},{\"authorId\":\"3030219\",\"name\":\"Urvashi Khandelwal\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.18653/v1/P19-1595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef6948edae12eba6f1d486b8600108b9762f36ab\",\"title\":\"BAM! Born-Again Multi-Task Networks for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ef6948edae12eba6f1d486b8600108b9762f36ab\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1901.07291\",\"authors\":[{\"authorId\":\"1830914\",\"name\":\"Guillaume Lample\"},{\"authorId\":\"2480903\",\"name\":\"Alexis Conneau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc\",\"title\":\"Cross-lingual Language Model Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.11740\",\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1007/978-3-030-58577-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"title\":\"UNITER: UNiversal Image-TExt Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaodong Liu\"},{\"authorId\":null,\"name\":\"Jianfeng Gao\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Kevin Duh\"},{\"authorId\":null,\"name\":\"Ye-Yi Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Representation learning using multitask deep neural networks for semantic classification and information\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1611.08481\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/CVPR.2017.475\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bed7834ae7d371171977a590872f60d137c2f951\",\"title\":\"GuessWhat?! Visual Object Discovery through Multi-modal Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/bed7834ae7d371171977a590872f60d137c2f951\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1706.05098\",\"authors\":[{\"authorId\":\"2884561\",\"name\":\"Sebastian Ruder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d431f835c06afdea45dff6b24486bf301ebdef0\",\"title\":\"An Overview of Multi-Task Learning in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d431f835c06afdea45dff6b24486bf301ebdef0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.00500\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.01074\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"title\":\"Multi-Task Learning of Hierarchical Vision-Language Representation\",\"url\":\"https://www.semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1801.08186\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"title\":\"MAttNet: Modular Attention Network for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1907.07804\",\"authors\":[{\"authorId\":\"51011359\",\"name\":\"S. Pramanik\"},{\"authorId\":\"7421228\",\"name\":\"Priyanka Agrawal\"},{\"authorId\":\"145374365\",\"name\":\"Aman Hussain\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"title\":\"OmniNet: A unified architecture for multi-modal multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.07280\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"12139064\",\"name\":\"Jake Bruce\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd9642470ff8c2089427f7a6392cd17d213a334\",\"title\":\"Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\",\"url\":\"https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1901.11504\",\"authors\":[{\"authorId\":\"46522098\",\"name\":\"Xiaodong Liu\"},{\"authorId\":\"50462546\",\"name\":\"Pengcheng He\"},{\"authorId\":\"7307263\",\"name\":\"W. Chen\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P19-1441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"658721bc13b0fa97366d38c05a96bf0a9f4bb0ac\",\"title\":\"Multi-Task Deep Neural Networks for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/658721bc13b0fa97366d38c05a96bf0a9f4bb0ac\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P18-1238\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"title\":\"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.03539\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2016.433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f14325ec3041a73118bc4d819204cbbca07d5a71\",\"title\":\"Cross-Stitch Networks for Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/f14325ec3041a73118bc4d819204cbbca07d5a71\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1806.08730\",\"authors\":[{\"authorId\":\"143775536\",\"name\":\"B. McCann\"},{\"authorId\":\"2844898\",\"name\":\"N. Keskar\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"9784fbf77295860b2e412137b86356d70b25e3c0\",\"title\":\"The Natural Language Decathlon: Multitask Learning as Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9784fbf77295860b2e412137b86356d70b25e3c0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.10582\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"1868193\",\"name\":\"Farley Lai\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"0955252cd57db8503a2ed9e56f195fa44b1bc0d4\",\"title\":\"Visual Entailment Task for Visually-Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/0955252cd57db8503a2ed9e56f195fa44b1bc0d4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"2705801\",\"name\":\"Si Liu\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/s11263-012-0582-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c39f634edc2318a4b288bd29cf3880505e4ae711\",\"title\":\"Robust Visual Tracking via Structured Multi-Task Sparse Learning\",\"url\":\"https://www.semanticscholar.org/paper/c39f634edc2318a4b288bd29cf3880505e4ae711\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":\"1903.12117\",\"authors\":[{\"authorId\":\"3005262\",\"name\":\"Gjorgji Strezoski\"},{\"authorId\":\"2101470\",\"name\":\"Nanne van Noord\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":\"10.1109/ICCV.2019.00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"575fffa523c150e4e1f899a0d4db322a099afea9\",\"title\":\"Many Task Learning With Task Routing\",\"url\":\"https://www.semanticscholar.org/paper/575fffa523c150e4e1f899a0d4db322a099afea9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729368\",\"name\":\"X. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"1800354\",\"name\":\"Kevin Duh\"},{\"authorId\":\"30844359\",\"name\":\"Ye-Yi Wang\"}],\"doi\":\"10.3115/v1/N15-1092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3b8367a80181e28c95630b9b63060d895de08ff\",\"title\":\"Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c3b8367a80181e28c95630b9b63060d895de08ff\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1611.05397\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"144792148\",\"name\":\"W. Czarnecki\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"1700356\",\"name\":\"Joel Z. Leibo\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7bd6e3addd8bc8e2e154048300eea15f030ed33\",\"title\":\"Reinforcement Learning with Unsupervised Auxiliary Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d7bd6e3addd8bc8e2e154048300eea15f030ed33\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1910.10683\",\"authors\":[{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"145625142\",\"name\":\"Adam Roberts\"},{\"authorId\":\"3844009\",\"name\":\"Katherine Lee\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"1380243217\",\"name\":\"M. Matena\"},{\"authorId\":\"2389316\",\"name\":\"Yanqi Zhou\"},{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"35025299\",\"name\":\"Peter J. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cfb319689f06bf04c2e28399361f414ca32c4b3\",\"title\":\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\",\"url\":\"https://www.semanticscholar.org/paper/3cfb319689f06bf04c2e28399361f414ca32c4b3\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2020},{\"arxivId\":\"1908.09597\",\"authors\":[{\"authorId\":\"2971259\",\"name\":\"Felix J. S. Bragman\"},{\"authorId\":\"3480712\",\"name\":\"Ryutaro Tanno\"},{\"authorId\":\"50975019\",\"name\":\"S\\u00e9bastien Ourselin\"},{\"authorId\":\"143697638\",\"name\":\"D. Alexander\"},{\"authorId\":\"145244251\",\"name\":\"M. Jorge Cardoso\"}],\"doi\":\"10.1109/ICCV.2019.00147\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"914e4c95e3fbaa9d40a35efc5a4740a8cf10dc59\",\"title\":\"Stochastic Filter Groups for Multi-Task CNNs: Learning Specialist and Generalist Convolution Kernels\",\"url\":\"https://www.semanticscholar.org/paper/914e4c95e3fbaa9d40a35efc5a4740a8cf10dc59\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1905.07553\",\"authors\":[{\"authorId\":\"2046898\",\"name\":\"Trevor Scott Standley\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1924999\",\"name\":\"Dawn Chen\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"356941da708c6d5b06bce17463aca309fd33151a\",\"title\":\"Which Tasks Should Be Learned Together in Multi-task Learning?\",\"url\":\"https://www.semanticscholar.org/paper/356941da708c6d5b06bce17463aca309fd33151a\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553380\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8de174ab5419b9d3127695405efd079808e956e8\",\"title\":\"Curriculum learning\",\"url\":\"https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.04175\",\"authors\":[{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"},{\"authorId\":\"2603033\",\"name\":\"V. Bapst\"},{\"authorId\":\"144792148\",\"name\":\"W. Czarnecki\"},{\"authorId\":\"34660073\",\"name\":\"John Quan\"},{\"authorId\":\"143959037\",\"name\":\"J. Kirkpatrick\"},{\"authorId\":\"2315504\",\"name\":\"Raia Hadsell\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf90552b5d2e992e93ab838fd615e1c36618e31c\",\"title\":\"Distral: Robust multitask reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/cf90552b5d2e992e93ab838fd615e1c36618e31c\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1711.11543\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPRW.2018.00279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1609.02132\",\"authors\":[{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"}],\"doi\":\"10.1109/CVPR.2017.579\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"922197906907dc0a5e1b51fae40d3149333ecacf\",\"title\":\"UberNet: Training a Universal Convolutional Neural Network for Low-, Mid-, and High-Level Vision Using Diverse Datasets and Limited Memory\",\"url\":\"https://www.semanticscholar.org/paper/922197906907dc0a5e1b51fae40d3149333ecacf\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10599-4_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f500b1a7df00f67c417673e0538d86abb8a333fa\",\"title\":\"Facial Landmark Detection by Deep Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/f500b1a7df00f67c417673e0538d86abb8a333fa\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1906.08237\",\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"3422912\",\"name\":\"Zihang Dai\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"143712374\",\"name\":\"J. Carbonell\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c6abdbdecf04ffac65c440da77fb9d66bb474c\",\"title\":\"XLNet: Generalized Autoregressive Pretraining for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0c6abdbdecf04ffac65c440da77fb9d66bb474c\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1711.05101\",\"authors\":[{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45dfef0cc1ed96558c1c650432ce39d6a1050b6a\",\"title\":\"Fixing Weight Decay Regularization in Adam\",\"url\":\"https://www.semanticscholar.org/paper/45dfef0cc1ed96558c1c650432ce39d6a1050b6a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1511.06342\",\"authors\":[{\"authorId\":\"3166516\",\"name\":\"Emilio Parisotto\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1def5d3711ebd1d86787b1ed57c91832c5ddc90b\",\"title\":\"Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1def5d3711ebd1d86787b1ed57c91832c5ddc90b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":\"10.3115/1073445.1073478\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42a490cf4f186d3383c92963817d100afd81e2\",\"title\":\"Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network\",\"url\":\"https://www.semanticscholar.org/paper/eb42a490cf4f186d3383c92963817d100afd81e2\",\"venue\":\"HLT-NAACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"}],\"doi\":\"10.1007/978-1-4899-7687-1_100322\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47aaeb6dc682162dfe5659c2cad64e5d825ad910\",\"title\":\"Multitask Learning\",\"url\":\"https://www.semanticscholar.org/paper/47aaeb6dc682162dfe5659c2cad64e5d825ad910\",\"venue\":\"Encyclopedia of Machine Learning and Data Mining\",\"year\":1998},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1908.05054\",\"authors\":[{\"authorId\":\"114577307\",\"name\":\"C. Alberti\"},{\"authorId\":\"50602231\",\"name\":\"Jeffrey Ling\"},{\"authorId\":\"123052390\",\"name\":\"Michael Collins\"},{\"authorId\":\"1781409\",\"name\":\"D. Reitter\"}],\"doi\":\"10.18653/v1/D19-1219\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"title\":\"Fusion of Detected Objects in Text for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1911.03768\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.222\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3066ec95113636ca546cf4339772fbd495c27e4\",\"title\":\"The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/d3066ec95113636ca546cf4339772fbd495c27e4\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49889548\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1706370\",\"name\":\"Q. Yang\"}],\"doi\":\"10.1093/NSR/NWX105\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd49acefc8d51e324aa562e5337e1c2aff067053\",\"title\":\"An Overview of Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/cd49acefc8d51e324aa562e5337e1c2aff067053\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d07284a6811f1b2745d91bdb06b040b57f226882\",\"title\":\"Decoupled Weight Decay Regularization\",\"url\":\"https://www.semanticscholar.org/paper/d07284a6811f1b2745d91bdb06b040b57f226882\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1907.10529\",\"authors\":[{\"authorId\":\"144863691\",\"name\":\"Mandar Joshi\"},{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"118656283\",\"name\":\"Y. Liu\"},{\"authorId\":\"1780531\",\"name\":\"Daniel S. Weld\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"}],\"doi\":\"10.1162/tacl_a_00300\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81f5810fbbab9b7203b9556f4ce3c741875407bc\",\"title\":\"SpanBERT: Improving Pre-training by Representing and Predicting Spans\",\"url\":\"https://www.semanticscholar.org/paper/81f5810fbbab9b7203b9556f4ce3c741875407bc\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014}],\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"topics\":[{\"topic\":\"Computer multitasking\",\"topicId\":\"6968\",\"url\":\"https://www.semanticscholar.org/topic/6968\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Image retrieval\",\"topicId\":\"21846\",\"url\":\"https://www.semanticscholar.org/topic/21846\"},{\"topic\":\"Natural language understanding\",\"topicId\":\"18266\",\"url\":\"https://www.semanticscholar.org/topic/18266\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"}],\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"