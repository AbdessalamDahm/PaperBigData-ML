"{\"abstract\":\"Text-to-image synthesis is a challenging task that generates realistic images from a textual sequence, which usually contains limited information compared with the corresponding image and so is ambiguous and abstractive. The limited textual information only describes a scene partly, which will complicate the generation with complementing the other details implicitly and lead to low-quality images. To address this problem, we propose a novel rich feature generating text-to-image synthesis, called RiFeGAN, to enrich the given description. In order to provide additional visual details and avoid conflicting, RiFeGAN exploits an attention-based caption matching model to select and refine the compatible candidate captions from prior knowledge. Given enriched captions, RiFeGAN uses self-attentional embedding mixtures to extract features across them effectually and handle the diverging features further. Then it exploits multi-captions attentional generative adversarial networks to synthesize images from those features. The experiments conducted on widely-used datasets show that the models can generate images from enriched captions effectually and improve the results significantly.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1396748406\",\"name\":\"Jun Cheng\",\"url\":\"https://www.semanticscholar.org/author/1396748406\"},{\"authorId\":\"40362288\",\"name\":\"Fuxiang Wu\",\"url\":\"https://www.semanticscholar.org/author/40362288\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\",\"url\":\"https://www.semanticscholar.org/author/39402399\"},{\"authorId\":\"48170171\",\"name\":\"L. Wang\",\"url\":\"https://www.semanticscholar.org/author/48170171\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\",\"url\":\"https://www.semanticscholar.org/author/1701119\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.03308\",\"authors\":[{\"authorId\":\"50875615\",\"name\":\"W. Xia\"},{\"authorId\":\"3001727\",\"name\":\"Yujiu Yang\"},{\"authorId\":\"102528982\",\"name\":\"Jing-Hao Xue\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"faed82f8980af7ee8dbdb8bea732422f81e638e5\",\"title\":\"TediGAN: Text-Guided Diverse Image Generation and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/faed82f8980af7ee8dbdb8bea732422f81e638e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05865\",\"authors\":[{\"authorId\":\"49720954\",\"name\":\"M. Tao\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"1649368283\",\"name\":\"Songsong Wu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"49737751\",\"name\":\"Xiaoyuan Jing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efa82cc293ab3c700d86f987395d5c4f7479558f\",\"title\":\"DF-GAN: Deep Fusion Generative Adversarial Networks for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/efa82cc293ab3c700d86f987395d5c4f7479558f\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219965481,\"doi\":\"10.1109/cvpr42600.2020.01092\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"2751eed0574bb099b0a009efa01d2b1b9ec4697b\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367820\",\"name\":\"C. Wah\"},{\"authorId\":\"3251767\",\"name\":\"S. Branson\"},{\"authorId\":\"2930640\",\"name\":\"P. Welinder\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"c069629a51f6c1c301eb20ed77bc6b586c24ce32\",\"title\":\"The Caltech-UCSD Birds-200-2011 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/c069629a51f6c1c301eb20ed77bc6b586c24ce32\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1602.06359\",\"authors\":[{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"1777025\",\"name\":\"J. Guo\"},{\"authorId\":\"39474114\",\"name\":\"Jun Xu\"},{\"authorId\":\"2019211\",\"name\":\"Shengxian Wan\"},{\"authorId\":\"1717004\",\"name\":\"X. Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9e505fad7ffbb35bd30b7a2b63226291bfd857f\",\"title\":\"Text Matching as Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b9e505fad7ffbb35bd30b7a2b63226291bfd857f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1805.08318\",\"authors\":[{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"},{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"title\":\"Self-Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tao Xu\"},{\"authorId\":null,\"name\":\"Pengchuan Zhang\"},{\"authorId\":null,\"name\":\"Qiuyuan Huang\"},{\"authorId\":null,\"name\":\"Han Zhang\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Xiaolei Huang\"},{\"authorId\":null,\"name\":\"Xiaodong He\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Attngan: Finegrained text to image generation with attentional generative adversarial networks\",\"url\":\"\",\"venue\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,\",\"year\":2018},{\"arxivId\":\"1605.05396\",\"authors\":[{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2876316\",\"name\":\"L. Logeswaran\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"title\":\"Generative Adversarial Text to Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2017.2729019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51b2c1e750b1d3b893072829d012f2352d6bd373\",\"title\":\"Video Captioning With Attention-Based LSTM and Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/51b2c1e750b1d3b893072829d012f2352d6bd373\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yitong Li\"},{\"authorId\":\"31617773\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8f2ba261756ca551ba68940e08a9466c2602f79\",\"title\":\"Sequential Attention GAN for Interactive Image Editing via Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/b8f2ba261756ca551ba68940e08a9466c2602f79\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.06801\",\"authors\":[{\"authorId\":\"19209527\",\"name\":\"Mingkuan Yuan\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1145/3240508.3240559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b50b1d3e672ef727ed03b667bd08f46d1cd2f176\",\"title\":\"Text-to-image Synthesis via Symmetrical Distillation Networks\",\"url\":\"https://www.semanticscholar.org/paper/b50b1d3e672ef727ed03b667bd08f46d1cd2f176\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.01622\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"25445698\",\"name\":\"Agrim Gupta\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2018.00133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46b5d408d950287637dd21ce04772d9b2bacfd14\",\"title\":\"Image Generation from Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/46b5d408d950287637dd21ce04772d9b2bacfd14\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.05854\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"49050705\",\"name\":\"J. Zhang\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.00160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb\",\"title\":\"MirrorGAN: Learning Text-To-Image Generation by Redescription\",\"url\":\"https://www.semanticscholar.org/paper/5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.01310\",\"authors\":[{\"authorId\":\"145314938\",\"name\":\"Minfeng Zhu\"},{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/CVPR.2019.00595\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ab995f96722969a0dfc6dc9139eef4c9b13c0524\",\"title\":\"DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/ab995f96722969a0dfc6dc9139eef4c9b13c0524\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.00028\",\"authors\":[{\"authorId\":\"2708454\",\"name\":\"Ishaan Gulrajani\"},{\"authorId\":\"48496963\",\"name\":\"F. Ahmed\"},{\"authorId\":\"2877311\",\"name\":\"Mart\\u00edn Arjovsky\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edf73ab12595c6709f646f542a0d2b33eb20a3f4\",\"title\":\"Improved Training of Wasserstein GANs\",\"url\":\"https://www.semanticscholar.org/paper/edf73ab12595c6709f646f542a0d2b33eb20a3f4\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1803.04687\",\"authors\":[{\"authorId\":\"3282196\",\"name\":\"Abrar H. Abdulnabi\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"145084658\",\"name\":\"Z. Zuo\"},{\"authorId\":\"145662587\",\"name\":\"Lap-Pui Chau\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TMM.2017.2774007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edffc5d9add89a2bf1dfdd131dc1634423d02a02\",\"title\":\"Multimodal Recurrent Neural Networks With Information Transfer Layers for Indoor Scene Labeling\",\"url\":\"https://www.semanticscholar.org/paper/edffc5d9add89a2bf1dfdd131dc1634423d02a02\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1511.08277\",\"authors\":[{\"authorId\":\"2019211\",\"name\":\"Shengxian Wan\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"1777025\",\"name\":\"J. Guo\"},{\"authorId\":\"39474114\",\"name\":\"Jun Xu\"},{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"1717004\",\"name\":\"X. Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf76690e93fd06ba1f86cf029fd62ae3ac770968\",\"title\":\"A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations\",\"url\":\"https://www.semanticscholar.org/paper/bf76690e93fd06ba1f86cf029fd62ae3ac770968\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"46321465\",\"name\":\"Sheng Tang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"4303531\",\"name\":\"Lixi Deng\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TMM.2017.2751140\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"title\":\"GLA: Global\\u2013Local Attention for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Martin Arjovsky\"},{\"authorId\":null,\"name\":\"Vincent Dumoulin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Sherjil Ozair , Aaron Courville , and Yoshua Bengio . Generative adversarial nets\",\"url\":\"\",\"venue\":\"Proceed - ings of Advances in Neural Information Processing Systems , NeurIPS , pages 2672 \\u2013 2680\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"48099761\",\"name\":\"K. Paliwal\"}],\"doi\":\"10.1109/78.650093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"title\":\"Bidirectional recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":1997},{\"arxivId\":\"1606.03498\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"571b0750085ae3d939525e62af510ee2cee9d5ea\",\"title\":\"Improved Techniques for Training GANs\",\"url\":\"https://www.semanticscholar.org/paper/571b0750085ae3d939525e62af510ee2cee9d5ea\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2877311\",\"name\":\"Mart\\u00edn Arjovsky\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acd87843a451d18b4dc6474ddce1ae946429eaf1\",\"title\":\"Wasserstein Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/acd87843a451d18b4dc6474ddce1ae946429eaf1\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Min Yang\"},{\"authorId\":null,\"name\":\"Wei Zhao\"},{\"authorId\":null,\"name\":\"Wei Xu\"},{\"authorId\":null,\"name\":\"Yabing Feng\"},{\"authorId\":null,\"name\":\"Zhou Zhao\"},{\"authorId\":null,\"name\":\"Xiaojun Chen\"},{\"authorId\":null,\"name\":\"Kai Lei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multitask learning for crossdomain image captioning\",\"url\":\"\",\"venue\":\"IEEE Transactions on Multimedia,\",\"year\":2019},{\"arxivId\":\"1801.01973\",\"authors\":[{\"authorId\":\"3379664\",\"name\":\"S. Barratt\"},{\"authorId\":\"145740960\",\"name\":\"Rishi Sharma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da4e3270085fe5f59d9e89c072345c6600e7eb9a\",\"title\":\"A Note on the Inception Score\",\"url\":\"https://www.semanticscholar.org/paper/da4e3270085fe5f59d9e89c072345c6600e7eb9a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1802.09178\",\"authors\":[{\"authorId\":\"2476328\",\"name\":\"Zizhao Zhang\"},{\"authorId\":\"1877955\",\"name\":\"Yuanpu Xie\"},{\"authorId\":\"144890162\",\"name\":\"L. Yang\"}],\"doi\":\"10.1109/CVPR.2018.00649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aa17504b7fffd64df511c5e5fc1e5d4397de1b5\",\"title\":\"Photographic Text-to-Image Synthesis with a Hierarchically-Nested Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/6aa17504b7fffd64df511c5e5fc1e5d4397de1b5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.02784\",\"authors\":[{\"authorId\":\"50024168\",\"name\":\"Yitong Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"31617773\",\"name\":\"J. Liu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"145006559\",\"name\":\"L. Carin\"},{\"authorId\":\"144752689\",\"name\":\"David Edwin Carlson\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1109/CVPR.2019.00649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b87e795f1f501843f7f99e83e38f125f6af8600\",\"title\":\"StoryGAN: A Sequential Conditional GAN for Story Visualization\",\"url\":\"https://www.semanticscholar.org/paper/3b87e795f1f501843f7f99e83e38f125f6af8600\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1710.10916\",\"authors\":[{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1753384\",\"name\":\"S. Zhang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/TPAMI.2018.2856256\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ace72f12491a7c06967a6011c4bef004192d767\",\"title\":\"StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/4ace72f12491a7c06967a6011c4bef004192d767\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1802.08216\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"26412506\",\"name\":\"Dendi Suhubdy\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"174ddb6379b91a0e799e9988d0e522a5af18f91d\",\"title\":\"ChatPainter: Improving Text to Image Generation using Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/174ddb6379b91a0e799e9988d0e522a5af18f91d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1908.00300\",\"authors\":[{\"authorId\":\"41032210\",\"name\":\"Runqi Yang\"},{\"authorId\":\"1906161\",\"name\":\"Jianhai Zhang\"},{\"authorId\":\"145193127\",\"name\":\"Xing Gao\"},{\"authorId\":\"144642000\",\"name\":\"Feng Ji\"},{\"authorId\":\"2765043\",\"name\":\"Haiqing Chen\"}],\"doi\":\"10.18653/v1/p19-1465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7076b396c2cc8fe031de62138522051728bd5292\",\"title\":\"Simple and Effective Text Matching with Richer Alignment Features\",\"url\":\"https://www.semanticscholar.org/paper/7076b396c2cc8fe031de62138522051728bd5292\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646632\",\"name\":\"Maria-Elena Nilsback\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICVGIP.2008.47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02b28f3b71138a06e40dbd614abf8568420ae183\",\"title\":\"Automated Flower Classification over a Large Number of Classes\",\"url\":\"https://www.semanticscholar.org/paper/02b28f3b71138a06e40dbd614abf8568420ae183\",\"venue\":\"2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing\",\"year\":2008},{\"arxivId\":\"1809.01110\",\"authors\":[{\"authorId\":\"2218741\",\"name\":\"Fuwen Tan\"},{\"authorId\":\"145480864\",\"name\":\"Song Feng\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0b9205d0d19f96e3b75733611d6c88cf948036\",\"title\":\"Text2Scene: Generating Abstract Scenes from Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2d0b9205d0d19f96e3b75733611d6c88cf948036\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51121868\",\"name\":\"Xunjie Zhu\"},{\"authorId\":\"50289900\",\"name\":\"Tingfeng Li\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"}],\"doi\":\"10.18653/v1/P18-2100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be7aa1dd1812910b6b02b972eaeaff1b62621c1e\",\"title\":\"Exploring Semantic Properties of Sentence Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/be7aa1dd1812910b6b02b972eaeaff1b62621c1e\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1809.10238\",\"authors\":[{\"authorId\":\"144445177\",\"name\":\"K. J. Joseph\"},{\"authorId\":\"50200698\",\"name\":\"Arghya Pal\"},{\"authorId\":\"35635426\",\"name\":\"Sailaja Rajanala\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":\"10.1109/WACV.2019.00044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ba795dc7e6fb96fe89842d5365cd8d24d75768d\",\"title\":\"C4Synth: Cross-Caption Cycle-Consistent Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9ba795dc7e6fb96fe89842d5365cd8d24d75768d\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1806.06183\",\"authors\":[{\"authorId\":\"50992499\",\"name\":\"Ryan Y. Benmalek\"},{\"authorId\":\"1748501\",\"name\":\"Claire Cardie\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0e9064d59cb3b23b425bb954dd8c77fdc8637c8\",\"title\":\"The Neural Painter: Multi-Turn Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a0e9064d59cb3b23b425bb954dd8c77fdc8637c8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.11096\",\"authors\":[{\"authorId\":\"144588497\",\"name\":\"A. Brock\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22aab110058ebbd198edb1f1e7b4f69fb13c0613\",\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/22aab110058ebbd198edb1f1e7b4f69fb13c0613\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1807.03039\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21b786b3f870fc7fa247c143aa41de88b1fc6141\",\"title\":\"Glow: Generative Flow with Invertible 1x1 Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/21b786b3f870fc7fa247c143aa41de88b1fc6141\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148232854\",\"name\":\"Ting-ting Qiao\"},{\"authorId\":\"1519066969\",\"name\":\"Jing Zhang\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041f1a3921f37511937580ad6c0d4b5a5ba7960a\",\"title\":\"Learn, Imagine and Create: Text-to-Image Generation from Prior Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/041f1a3921f37511937580ad6c0d4b5a5ba7960a\",\"venue\":\"NeurIPS\",\"year\":2019}],\"title\":\"RiFeGAN: Rich Feature Generation for Text-to-Image Synthesis From Prior Knowledge\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/2751eed0574bb099b0a009efa01d2b1b9ec4697b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"