"{\"abstract\":\"Deep neural networks are vulnerable to adversarial examples, which becomes one of the most important research problems in the development of deep learning. While a lot of efforts have been made in recent years, it is of great significance to perform correct and complete evaluations of the adversarial attack and defense algorithms. In this paper, we establish a comprehensive, rigorous, and coherent benchmark to evaluate adversarial robustness on image classification tasks. After briefly reviewing plenty of representative attack and defense methods, we perform large-scale experiments with two robustness curves as the fair-minded evaluation criteria to fully understand the performance of these methods. Based on the evaluation results, we draw several important findings that can provide insights for future research, including: 1) The relative robustness between models can change across different attack configurations, thus it is encouraged to adopt the robustness curves to evaluate adversarial robustness; 2) As one of the most effective defense techniques, adversarial training can generalize across different threat models; 3) Randomization-based defenses are more robust to query-based black-box attacks.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\",\"url\":\"https://www.semanticscholar.org/author/3431029\"},{\"authorId\":\"122796274\",\"name\":\"Qi-An Fu\",\"url\":\"https://www.semanticscholar.org/author/122796274\"},{\"authorId\":\"2591451\",\"name\":\"X. Yang\",\"url\":\"https://www.semanticscholar.org/author/2591451\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\",\"url\":\"https://www.semanticscholar.org/author/19201674\"},{\"authorId\":null,\"name\":\"Hang Su\",\"url\":null},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\",\"url\":\"https://www.semanticscholar.org/author/9381483\"},{\"authorId\":\"1739163379\",\"name\":\"Jun Zhu\",\"url\":\"https://www.semanticscholar.org/author/1739163379\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2009.04131\",\"authors\":[{\"authorId\":\"34492022\",\"name\":\"L. Li\"},{\"authorId\":\"49192749\",\"name\":\"Linyi Li\"},{\"authorId\":\"7865162\",\"name\":\"Xiangyu Qi\"},{\"authorId\":\"40601191\",\"name\":\"T. Xie\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c071746aa31e852338df92089103f8f588d1c2b9\",\"title\":\"SoK: Certified Robustness for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c071746aa31e852338df92089103f8f588d1c2b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.05021\",\"authors\":[{\"authorId\":\"47009032\",\"name\":\"Xiaowei Yang\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"151495747\",\"name\":\"Hongyang Zhang\"},{\"authorId\":\"143772458\",\"name\":\"X. Ming\"},{\"authorId\":\"145254056\",\"name\":\"J. Zhu\"}],\"doi\":\"10.1007/978-3-030-58520-4_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b0dcfacd06a3e9aa87f9d62932caa3ec83b5560\",\"title\":\"Design and Interpretation of Universal Adversarial Patches in Face Detection\",\"url\":\"https://www.semanticscholar.org/paper/3b0dcfacd06a3e9aa87f9d62932caa3ec83b5560\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.05999\",\"authors\":[{\"authorId\":\"145114723\",\"name\":\"Z. Deng\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":null,\"name\":\"Hang Su\"},{\"authorId\":\"145254056\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"29cde68a09645f166cc582c99219e4452611dfef\",\"title\":\"Adversarial Distributional Training for Robust Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/29cde68a09645f166cc582c99219e4452611dfef\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2009.09497\",\"authors\":[{\"authorId\":\"40990475\",\"name\":\"Lukasz Korycki\"},{\"authorId\":\"3022672\",\"name\":\"B. Krawczyk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f531093e7b22abe27ae9af2ee67fbc43f2957705\",\"title\":\"Adversarial Concept Drift Detection under Poisoning Attacks for Robust Data Stream Mining\",\"url\":\"https://www.semanticscholar.org/paper/f531093e7b22abe27ae9af2ee67fbc43f2957705\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910832\",\"name\":\"Chengcheng Ma\"},{\"authorId\":\"35965884\",\"name\":\"Weiliang Meng\"},{\"authorId\":\"143905980\",\"name\":\"B. Wu\"},{\"authorId\":\"2779420\",\"name\":\"Shibiao Xu\"},{\"authorId\":\"21458018\",\"name\":\"Xiaopeng Zhang\"}],\"doi\":\"10.1145/3394171.3413875\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2adae46d8afc0d957bf6b8b37aa6eee514fc6832\",\"title\":\"Efficient Joint Gradient Based Attack Against SOR Defense for 3D Point Cloud Classification\",\"url\":\"https://www.semanticscholar.org/paper/2adae46d8afc0d957bf6b8b37aa6eee514fc6832\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.00467\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"98182791\",\"name\":\"Xian Yang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"1739163379\",\"name\":\"Jun Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"title\":\"Bag of Tricks for Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.09670\",\"authors\":[{\"authorId\":\"39171784\",\"name\":\"F. Croce\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"},{\"authorId\":\"3482535\",\"name\":\"V. Sehwag\"},{\"authorId\":\"2874440\",\"name\":\"Nicolas Flammarion\"},{\"authorId\":\"1864002076\",\"name\":\"Mung Chiang\"},{\"authorId\":\"143615341\",\"name\":\"P. Mittal\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4efc60e1b342f0164db5425076b1bc6196ea8bb5\",\"title\":\"RobustBench: a standardized adversarial robustness benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4efc60e1b342f0164db5425076b1bc6196ea8bb5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11922\",\"authors\":[{\"authorId\":\"2981441\",\"name\":\"Jiachen Sun\"},{\"authorId\":\"90050404\",\"name\":\"K. Koenig\"},{\"authorId\":\"1840795376\",\"name\":\"Yulong Cao\"},{\"authorId\":\"39645110\",\"name\":\"Q. Chen\"},{\"authorId\":\"3895596\",\"name\":\"Z. Morley Mao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d3c439cfa3c9be7bbffa1d37192c6b3d90ed8e0\",\"title\":\"On the Adversarial Robustness of 3D Point Cloud Classification\",\"url\":\"https://www.semanticscholar.org/paper/6d3c439cfa3c9be7bbffa1d37192c6b3d90ed8e0\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219964167,\"doi\":\"10.1109/CVPR42600.2020.00040\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"25e9fa483a048607131a5a0e3287e8f457fb4807\",\"references\":[{\"arxivId\":\"1810.01279\",\"authors\":[{\"authorId\":\"23979212\",\"name\":\"Xuanqing Liu\"},{\"authorId\":\"48514899\",\"name\":\"Y. Li\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1f76891bdfa07d9a61ad11a15de13b139b20d2a\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c1f76891bdfa07d9a61ad11a15de13b139b20d2a\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1905.10626\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"49343487\",\"name\":\"K. Xu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"144369497\",\"name\":\"Chao Du\"},{\"authorId\":\"144354006\",\"name\":\"N. Chen\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c68cd22de315a14587120e98bb02fdcf51edec46\",\"title\":\"Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/c68cd22de315a14587120e98bb02fdcf51edec46\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1904.02884\",\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bd795bcbf8eccd12957240127a087a34c54fb04\",\"title\":\"Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks\",\"url\":\"https://www.semanticscholar.org/paper/9bd795bcbf8eccd12957240127a087a34c54fb04\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1707.04131\",\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"title\":\"Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1809.03008\",\"authors\":[{\"authorId\":\"40656291\",\"name\":\"K. Xiao\"},{\"authorId\":\"29435934\",\"name\":\"Vincent Tjeng\"},{\"authorId\":\"84146411\",\"name\":\"Nur Muhammad Shafiullah\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de49430578bb3f8de3e610423255662c45f17610\",\"title\":\"Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability\",\"url\":\"https://www.semanticscholar.org/paper/de49430578bb3f8de3e610423255662c45f17610\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1808.01976\",\"authors\":[{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"51210353\",\"name\":\"Behar Veliqi\"},{\"authorId\":\"3046313\",\"name\":\"M. Salath\\u00e9\"},{\"authorId\":\"24178944\",\"name\":\"S. Mohanty\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-29135-8_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87254f4136a881faabe83e40a121ea7991356b8c\",\"title\":\"Adversarial Vision Challenge\",\"url\":\"https://www.semanticscholar.org/paper/87254f4136a881faabe83e40a121ea7991356b8c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1901.04684\",\"authors\":[{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"143825455\",\"name\":\"Z. Song\"},{\"authorId\":\"2766041\",\"name\":\"D. Boning\"},{\"authorId\":\"1783667\",\"name\":\"I. Dhillon\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7124df6df2eafa1527c76cd136ab35c176844d4\",\"title\":\"The Limitations of Adversarial Training and the Blind-Spot Attack\",\"url\":\"https://www.semanticscholar.org/paper/f7124df6df2eafa1527c76cd136ab35c176844d4\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1804.08598\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"32815692\",\"name\":\"Jessy Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"title\":\"Black-box Adversarial Attacks with Limited Queries and Information\",\"url\":\"https://www.semanticscholar.org/paper/b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"40285565\",\"name\":\"Reuben Feinman\"},{\"authorId\":\"145714154\",\"name\":\"A. Kurakin\"},{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"101451823\",\"name\":\"T. Brown\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"2139376\",\"name\":\"Alexander Matyasko\"},{\"authorId\":\"2641675\",\"name\":\"Vahid Behzadan\"},{\"authorId\":\"5641536\",\"name\":\"Karen Hambardzumyan\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"144458540\",\"name\":\"Yi-Lin Juang\"},{\"authorId\":\"40606092\",\"name\":\"Zhi Li\"},{\"authorId\":\"9541640\",\"name\":\"Ryan Sheatsley\"},{\"authorId\":\"145437002\",\"name\":\"Abhibhav Garg\"},{\"authorId\":\"9960452\",\"name\":\"Jonathan Uesato\"},{\"authorId\":\"145556052\",\"name\":\"Willi Gierke\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"39835551\",\"name\":\"David Berthelot\"},{\"authorId\":\"40146615\",\"name\":\"P. Hendricks\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"103423330\",\"name\":\"Rujun Long\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe628819916eef5009f1fb95500e4b6774d8e95\",\"title\":\"Technical Report on the CleverHans v2.1.0 Adversarial Examples Library\",\"url\":\"https://www.semanticscholar.org/paper/2fe628819916eef5009f1fb95500e4b6774d8e95\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1811.01057\",\"authors\":[{\"authorId\":\"2655157\",\"name\":\"Aditi Raghunathan\"},{\"authorId\":\"5164568\",\"name\":\"J. Steinhardt\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ad8c18994108a630c4564400f6137bf4d8b7818\",\"title\":\"Semidefinite relaxations for certifying robustness to adversarial examples\",\"url\":\"https://www.semanticscholar.org/paper/7ad8c18994108a630c4564400f6137bf4d8b7818\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1712.04248\",\"authors\":[{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"title\":\"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1903.10586\",\"authors\":[{\"authorId\":null,\"name\":\"Yuchen Zhang\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9212e9433607d3b09dadaa466006052a3279f457\",\"title\":\"Defending against Whitebox Adversarial Attacks via Randomized Discretization\",\"url\":\"https://www.semanticscholar.org/paper/9212e9433607d3b09dadaa466006052a3279f457\",\"venue\":\"AISTATS\",\"year\":2019},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.12514\",\"authors\":[{\"authorId\":\"145970408\",\"name\":\"E. Wong\"},{\"authorId\":\"143826285\",\"name\":\"F. Schmidt\"},{\"authorId\":\"2708564\",\"name\":\"J. H. Metzen\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20f85256555ad612148e52f9363e52f9d661728b\",\"title\":\"Scaling provable adversarial defenses\",\"url\":\"https://www.semanticscholar.org/paper/20f85256555ad612148e52f9363e52f9d661728b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1704.01155\",\"authors\":[{\"authorId\":\"50231973\",\"name\":\"Weilin Xu\"},{\"authorId\":\"145685504\",\"name\":\"David Evans\"},{\"authorId\":\"1791105\",\"name\":\"Y. Qi\"}],\"doi\":\"10.14722/ndss.2018.23198\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"title\":\"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1902.02918\",\"authors\":[{\"authorId\":\"39951470\",\"name\":\"Jeremy M. Cohen\"},{\"authorId\":\"49686853\",\"name\":\"Elan Rosenfeld\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed\",\"title\":\"Certified Adversarial Robustness via Randomized Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00853\",\"authors\":[{\"authorId\":\"2533850\",\"name\":\"G. Dziugaite\"},{\"authorId\":\"1744700\",\"name\":\"Zoubin Ghahramani\"},{\"authorId\":\"39331522\",\"name\":\"D. Roy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c00f744f103a528f5b45bf0482f54b5e6a9f7740\",\"title\":\"A study of the effect of JPG compression on adversarial images\",\"url\":\"https://www.semanticscholar.org/paper/c00f744f103a528f5b45bf0482f54b5e6a9f7740\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1710.10766\",\"authors\":[{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"1684887\",\"name\":\"Nate Kushman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"title\":\"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.11515\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":null,\"name\":\"Kun Xu\"},{\"authorId\":\"47055094\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1b9d5d4cf17f5ceaf2d6798ffd594fd1d017eaa\",\"title\":\"Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/e1b9d5d4cf17f5ceaf2d6798ffd594fd1d017eaa\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1904.12843\",\"authors\":[{\"authorId\":\"3246287\",\"name\":\"A. Shafahi\"},{\"authorId\":\"40465379\",\"name\":\"Mahyar Najibi\"},{\"authorId\":\"115752784\",\"name\":\"Amin Ghiasi\"},{\"authorId\":\"144897102\",\"name\":\"Zheng Xu\"},{\"authorId\":\"1718974\",\"name\":\"John P. Dickerson\"},{\"authorId\":\"1746575\",\"name\":\"Christoph Studer\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2189083\",\"name\":\"G. Taylor\"},{\"authorId\":\"1962083\",\"name\":\"T. Goldstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c92be891c5f8f0f60b6de206364f9a744612d1e8\",\"title\":\"Adversarial Training for Free!\",\"url\":\"https://www.semanticscholar.org/paper/c92be891c5f8f0f60b6de206364f9a744612d1e8\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1804.00097\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"145656562\",\"name\":\"M. Liang\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39421868\",\"name\":\"Sangxia Huang\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"40119836\",\"name\":\"Y. Zhao\"},{\"authorId\":\"46758154\",\"name\":\"Zhonglin Han\"},{\"authorId\":\"19262286\",\"name\":\"J. Long\"},{\"authorId\":\"41021078\",\"name\":\"Yerkebulan Berdibekov\"},{\"authorId\":\"2859858\",\"name\":\"Takuya Akiba\"},{\"authorId\":\"3117618\",\"name\":\"Seiya Tokui\"},{\"authorId\":\"153225382\",\"name\":\"M. Abe\"}],\"doi\":\"10.1007/978-3-319-94042-7_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca5642f522cd2cd44948c7e9f337c91e5f26fdcf\",\"title\":\"Adversarial Attacks and Defences Competition\",\"url\":\"https://www.semanticscholar.org/paper/ca5642f522cd2cd44948c7e9f337c91e5f26fdcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1901.08573\",\"authors\":[{\"authorId\":\"40975176\",\"name\":\"Hongyang Zhang\"},{\"authorId\":\"29001000\",\"name\":\"Yaodong Yu\"},{\"authorId\":\"2784735\",\"name\":\"J. Jiao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"1701847\",\"name\":\"L. Ghaoui\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"title\":\"Theoretically Principled Trade-off between Robustness and Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1705.08475\",\"authors\":[{\"authorId\":\"143610806\",\"name\":\"M. Hein\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"title\":\"Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1904.04433\",\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00790\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a75cda9341bbdcb9f370181e664508c66aee5d4\",\"title\":\"Efficient Decision-Based Black-Box Adversarial Attacks on Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4a75cda9341bbdcb9f370181e664508c66aee5d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08c588465b7d801ad912ef3e9107fa511ea0e403\",\"title\":\"Decision Boundary Analysis of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/08c588465b7d801ad912ef3e9107fa511ea0e403\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1801.02612\",\"authors\":[{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"39037167\",\"name\":\"M. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3c071dbbb4520ed5875f7e064a9da87240534db\",\"title\":\"Spatially Transformed Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/d3c071dbbb4520ed5875f7e064a9da87240534db\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1901.08846\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144968846\",\"name\":\"Kun Xu\"},{\"authorId\":\"144369497\",\"name\":\"Chao Du\"},{\"authorId\":\"144354006\",\"name\":\"N. Chen\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"676e40050453ddeb1387f8314478c0ac3681a8c6\",\"title\":\"Improving Adversarial Robustness via Promoting Ensemble Diversity\",\"url\":\"https://www.semanticscholar.org/paper/676e40050453ddeb1387f8314478c0ac3681a8c6\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1803.06978\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00284\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"title\":\"Improving Transferability of Adversarial Examples With Input Diversity\",\"url\":\"https://www.semanticscholar.org/paper/f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.08847\",\"authors\":[{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"title\":\"Parseval Networks: Improving Robustness to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2635549\",\"name\":\"A. Sinha\"},{\"authorId\":\"40281109\",\"name\":\"Hongseok Namkoong\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"818c52f4ba56cb8cf152ad614f2f4803057a5cfe\",\"title\":\"Certifying Some Distributional Robustness with Principled Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/818c52f4ba56cb8cf152ad614f2f4803057a5cfe\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.05666\",\"authors\":[{\"authorId\":\"9960452\",\"name\":\"Jonathan Uesato\"},{\"authorId\":\"1389654226\",\"name\":\"Brendan O'Donoghue\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4b434c3ab979ecdd71bbed894b34de77590c6dd\",\"title\":\"Adversarial Risk and the Dangers of Evaluating Against Weak Attacks\",\"url\":\"https://www.semanticscholar.org/paper/f4b434c3ab979ecdd71bbed894b34de77590c6dd\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonas Rauber\"},{\"authorId\":null,\"name\":\"Wieland Brendel\"},{\"authorId\":null,\"name\":\"Matthias Bethge. Foolbox v\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"8.0: A python toolbox to benchmark the robustness of machine learning models\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1707.04131,\",\"year\":2017},{\"arxivId\":\"1711.00851\",\"authors\":[{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"51026953\",\"name\":\"E. Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b23012689e0f17912fb38d4984775e567cff8d6\",\"title\":\"Provable defenses against adversarial examples via the convex outer adversarial polytope\",\"url\":\"https://www.semanticscholar.org/paper/4b23012689e0f17912fb38d4984775e567cff8d6\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1511.04508\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"37785191\",\"name\":\"Xi Wu\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/SP.2016.41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"title\":\"Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"venue\":\"2016 IEEE Symposium on Security and Privacy (SP)\",\"year\":2016},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1712.00673\",\"authors\":[{\"authorId\":\"23979212\",\"name\":\"Xuanqing Liu\"},{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1007/978-3-030-01234-2_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1cf361d02f5ad84567e48754f1a8f895653bc701\",\"title\":\"Towards Robust Neural Networks via Random Self-ensemble\",\"url\":\"https://www.semanticscholar.org/paper/1cf361d02f5ad84567e48754f1a8f895653bc701\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"78730080\",\"name\":\"B. Tran\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0314e777333a63aca5735ea136c74e113aa8801d\",\"title\":\"Exploring the Landscape of Spatial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/0314e777333a63aca5735ea136c74e113aa8801d\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1711.00117\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"2139712\",\"name\":\"Mayank Rana\"},{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"title\":\"Countering Adversarial Images using Input Transformations\",\"url\":\"https://www.semanticscholar.org/paper/e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1801.09344\",\"authors\":[{\"authorId\":\"2655157\",\"name\":\"Aditi Raghunathan\"},{\"authorId\":\"5164568\",\"name\":\"J. Steinhardt\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"title\":\"Certified Defenses against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1902.06705\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be94fe9f2414639cd3f6cef0fdeafd4a10d1b2e5\",\"title\":\"On Evaluating Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/be94fe9f2414639cd3f6cef0fdeafd4a10d1b2e5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":null,\"name\":\"Alexey Kurakin\"},{\"authorId\":null,\"name\":\"Nicolas Papernot\"},{\"authorId\":null,\"name\":\"Dan Boneh\"},{\"authorId\":null,\"name\":\"Patrick McDaniel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ensemble adversarial train- 327 ing: Attacks and defenses\",\"url\":\"\",\"venue\":\"In International Conference on Learning Representations (ICLR),\",\"year\":2018},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1805.07894\",\"authors\":[{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"1978777\",\"name\":\"Rui Shu\"},{\"authorId\":\"1684887\",\"name\":\"Nate Kushman\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5023544ad6fa49b35526a62f22207e43c4db870d\",\"title\":\"Constructing Unrestricted Adversarial Examples with Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/5023544ad6fa49b35526a62f22207e43c4db870d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1803.00404\",\"authors\":[{\"authorId\":\"3451543\",\"name\":\"Z. Yan\"},{\"authorId\":\"2527106\",\"name\":\"Yiwen Guo\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee95231783167baa4785a642e8ef563a572c5d63\",\"title\":\"Deep Defense: Training DNNs with Improved Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/ee95231783167baa4785a642e8ef563a572c5d63\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1711.09404\",\"authors\":[{\"authorId\":\"50683297\",\"name\":\"A. Ross\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"title\":\"Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients\",\"url\":\"https://www.semanticscholar.org/paper/ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1707.07397\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"143883029\",\"name\":\"Kevin Kwok\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"title\":\"Synthesizing Robust Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1807.04457\",\"authors\":[{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"145512402\",\"name\":\"Th\\u00f4ng L\\u00ea\"},{\"authorId\":\"153191364\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b862efa06baea0b032214675eb3c3645d5d69d46\",\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"url\":\"https://www.semanticscholar.org/paper/b862efa06baea0b032214675eb3c3645d5d69d46\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1712.02976\",\"authors\":[{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"151483845\",\"name\":\"Ming Liang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"48566726\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/CVPR.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"title\":\"Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\",\"url\":\"https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1803.01442\",\"authors\":[{\"authorId\":\"16404879\",\"name\":\"Guneet S. Dhillon\"},{\"authorId\":\"3371922\",\"name\":\"Kamyar Azizzadenesheli\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"38267634\",\"name\":\"J. Bernstein\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"19268451\",\"name\":\"A. Khanna\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"title\":\"Stochastic Activation Pruning for Robust Adversarial Defense\",\"url\":\"https://www.semanticscholar.org/paper/2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1906.06919\",\"authors\":[{\"authorId\":\"94727217\",\"name\":\"Shuyu Cheng\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edabab811aaf44b7b626efe5278a32bddd3bb77f\",\"title\":\"Improving Black-box Adversarial Attacks with a Transfer-based Prior\",\"url\":\"https://www.semanticscholar.org/paper/edabab811aaf44b7b626efe5278a32bddd3bb77f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94187ef33e34af2cdb42502083c6f9b4c3f5ba6b\",\"title\":\"Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/94187ef33e34af2cdb42502083c6f9b4c3f5ba6b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1905.00441\",\"authors\":[{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"50703694\",\"name\":\"L. Li\"},{\"authorId\":\"49681590\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7557a6512295ab7cfe8332b1d53ae40e675c9750\",\"title\":\"NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7557a6512295ab7cfe8332b1d53ae40e675c9750\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":null,\"name\":\"Alexey Kurakin\"},{\"authorId\":null,\"name\":\"Nicolas Papernot\"},{\"authorId\":null,\"name\":\"Dan Boneh\"},{\"authorId\":null,\"name\":\"Patrick McDaniel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ensemble adversarial train- 330 ing: Attacks and defenses\",\"url\":\"\",\"venue\":\"In International Conference on Learning Representations (ICLR),\",\"year\":2018}],\"title\":\"Benchmarking Adversarial Robustness on Image Classification\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/25e9fa483a048607131a5a0e3287e8f457fb4807\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"