"{\"abstract\":\"Recent progress on fine-grained visual recognition and visual question answering has featured Bilinear Pooling, which effectively models the 2nd order interactions across multi-modal inputs. Nevertheless, there has not been evidence in support of building such interactions concurrently with attention mechanism for image captioning. In this paper, we introduce a unified attention block --- X-Linear attention block, that fully employs bilinear pooling to selectively capitalize on visual information or perform multi-modal reasoning. Technically, X-Linear attention block simultaneously exploits both the spatial and channel-wise bilinear attention distributions to capture the 2$^{nd}$ order interactions between the input single-modal or multi-modal features. Higher and even infinity order feature interactions are readily modeled through stacking multiple X-Linear attention blocks and equipping the block with Exponential Linear Unit (ELU) in a parameter-free fashion, respectively. Furthermore, we present X-Linear Attention Networks (dubbed as X-LAN) that novelly integrates X-Linear attention block(s) into image encoder and sentence decoder of image captioning model to leverage higher order intra- and inter-modal interactions. The experiments on COCO benchmark demonstrate that our X-LAN obtains to-date the best published CIDEr performance of 132.0% on COCO Karpathy test split. When further endowing Transformer with X-Linear attention blocks, CIDEr is boosted up to 132.8%. Source code is available at https://github.com/Panda-Peter/image-captioning.\",\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\",\"url\":\"https://www.semanticscholar.org/author/3202968\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\",\"url\":\"https://www.semanticscholar.org/author/2053452\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\",\"url\":\"https://www.semanticscholar.org/author/3431141\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\",\"url\":\"https://www.semanticscholar.org/author/1490772804\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1799121\",\"name\":\"K. Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/ACCESS.2020.3042484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"832aafb4989c24211a8377f82228c31f7a90ef81\",\"title\":\"Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap\",\"url\":\"https://www.semanticscholar.org/paper/832aafb4989c24211a8377f82228c31f7a90ef81\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49251978\",\"name\":\"J. Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1145/3394171.3416291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"598ad06c164043c45c952dbde37e0c75991e66aa\",\"title\":\"VideoTRM: Pre-training for Video Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/598ad06c164043c45c952dbde37e0c75991e66aa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944765097\",\"name\":\"Beigeng Zhao\"}],\"doi\":\"10.1109/ACCESS.2020.3021312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"title\":\"DrunaliaCap: Image Captioning for Drug-Related Paraphernalia With Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"},{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"},{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1394465427\",\"name\":\"Qiuyu Cai\"}],\"doi\":\"10.1145/3394171.3416290\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93aed487e9b9f51bf05803ef69c92599001358ac\",\"title\":\"XlanV Model with Adaptively Multi-Modality Feature Fusing for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93aed487e9b9f51bf05803ef69c92599001358ac\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1910.11102\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15a3fe11886455ad6dfe15dd80f7733677c5be7c\",\"title\":\"Vatex Video Captioning Challenge 2020: Multi-View Features and Hybrid Reward Strategies for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/15a3fe11886455ad6dfe15dd80f7733677c5be7c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9304398\",\"name\":\"Jiawei Zuo\"},{\"authorId\":\"16098412\",\"name\":\"Y. Chen\"},{\"authorId\":\"40476136\",\"name\":\"L. Wang\"},{\"authorId\":\"51018452\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1917497790\",\"name\":\"Ting Yao\"},{\"authorId\":\"78646416\",\"name\":\"K. Wang\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3414453\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"title\":\"iDirector: An Intelligent Directing System for Live Broadcast\",\"url\":\"https://www.semanticscholar.org/paper/506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.03315\",\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"title\":\"Multi-modal Feature Fusion with Feature Attention for VATEX Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.13682\",\"authors\":[{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f147279c9d1edddda57f1f21f23b3b58998bad74\",\"title\":\"VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/f147279c9d1edddda57f1f21f23b3b58998bad74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07680\",\"authors\":[{\"authorId\":\"1477956290\",\"name\":\"Wenting Xu\"},{\"authorId\":\"2023765018\",\"name\":\"C. Qi\"},{\"authorId\":\"50070382\",\"name\":\"Zhenghua Xu\"},{\"authorId\":\"1690572\",\"name\":\"Thomas Lukasiewicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"504e7bba81083ebbc4e114e48938ebaffb5ba03c\",\"title\":\"Reinforced Medical Report Generation with X-Linear Attention and Repetition Penalty\",\"url\":\"https://www.semanticscholar.org/paper/504e7bba81083ebbc4e114e48938ebaffb5ba03c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.09742\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"title\":\"AutoCaption: Image Captioning with Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.07061\",\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"46491945\",\"name\":\"Yunpeng Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"40366236\",\"name\":\"Yue Gao\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"title\":\"Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.06225\",\"authors\":[{\"authorId\":\"7412048\",\"name\":\"Moloud Abdar\"},{\"authorId\":\"1866603\",\"name\":\"Farhad Pourpanah\"},{\"authorId\":\"1833049320\",\"name\":\"Sadiq Hussain\"},{\"authorId\":\"1404229235\",\"name\":\"D. Rezazadegan\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"103809454\",\"name\":\"Mohammad Ghavamzadeh\"},{\"authorId\":\"93660405\",\"name\":\"P. Fieguth\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"145434104\",\"name\":\"Abbas Khosravi\"},{\"authorId\":\"144076869\",\"name\":\"U. Acharya\"},{\"authorId\":\"144531494\",\"name\":\"V. Makarenkov\"},{\"authorId\":\"98613453\",\"name\":\"S. Nahavandi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"497d5002f41feb2e4729a171cdc5c9f22ee403df\",\"title\":\"A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/497d5002f41feb2e4729a171cdc5c9f22ee403df\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.02375\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"5891694\",\"name\":\"J. Luo\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"title\":\"Auto-captions on GIF: A Large-scale Video-sentence Dataset for Vision-language Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46507431\",\"name\":\"H. Wang\"},{\"authorId\":\"47673594\",\"name\":\"Shanshan Wang\"},{\"authorId\":\"2004369819\",\"name\":\"Zibo Qin\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48881709\",\"name\":\"Ruijiang Li\"},{\"authorId\":\"144344681\",\"name\":\"Y. Xia\"}],\"doi\":\"10.1016/j.media.2020.101846\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f90a98b0f837eb59dcb0eefe5e8de77d22e067a\",\"title\":\"Triple attention learning for classification of 14 thoracic diseases using chest radiography\",\"url\":\"https://www.semanticscholar.org/paper/0f90a98b0f837eb59dcb0eefe5e8de77d22e067a\",\"venue\":\"Medical Image Anal.\",\"year\":2021},{\"arxivId\":\"2011.02709\",\"authors\":[{\"authorId\":\"48806403\",\"name\":\"Zhenxing Zhang\"},{\"authorId\":\"52643489\",\"name\":\"L. Schomaker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fe68c8c970ba707e8767e5010c32b3cb1033063\",\"title\":\"DTGAN: Dual Attention Generative Adversarial Networks for Text-to-Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/6fe68c8c970ba707e8767e5010c32b3cb1033063\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10042\",\"authors\":[{\"authorId\":\"2965600\",\"name\":\"Y. Miura\"},{\"authorId\":\"49889487\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"2356307\",\"name\":\"C. Langlotz\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e90c17ef40404b79ad0f12d9b9c94656f12dfcd\",\"title\":\"Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e90c17ef40404b79ad0f12d9b9c94656f12dfcd\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":214727638,\"doi\":\"10.1109/cvpr42600.2020.01098\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"references\":[{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1507.01053\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1109/TMM.2015.2477044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"654a3e53fb41d8168798ee0ee61dfab73739b1ed\",\"title\":\"Describing Multimedia Content Using Attention-Based Encoder-Decoder Networks\",\"url\":\"https://www.semanticscholar.org/paper/654a3e53fb41d8168798ee0ee61dfab73739b1ed\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1807.09915\",\"authors\":[{\"authorId\":\"51150399\",\"name\":\"Chaojian Yu\"},{\"authorId\":\"144600390\",\"name\":\"X. Zhao\"},{\"authorId\":\"50320205\",\"name\":\"Qi Zheng\"},{\"authorId\":\"38769004\",\"name\":\"P. Zhang\"},{\"authorId\":\"1744228\",\"name\":\"Xinge You\"}],\"doi\":\"10.1007/978-3-030-01270-0_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d608b616efb2ae57669003b6c1067d1bb7c0b4c\",\"title\":\"Hierarchical Bilinear Pooling for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5d608b616efb2ae57669003b6c1067d1bb7c0b4c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jin-Hwa Kim\"},{\"authorId\":null,\"name\":\"Kyoung-Woon On\"},{\"authorId\":null,\"name\":\"Woosang Lim\"},{\"authorId\":null,\"name\":\"Jeonghee Kim\"},{\"authorId\":null,\"name\":\"Jung-Woo Ha\"},{\"authorId\":null,\"name\":\"Byoung-Tak Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"In ICLR,\",\"year\":2017},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"Andrej Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.07483\",\"authors\":[{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"339f052b22b1362c6e22b3e8db8eeebe6eebd49d\",\"title\":\"Continuously Differentiable Exponential Linear Units\",\"url\":\"https://www.semanticscholar.org/paper/339f052b22b1362c6e22b3e8db8eeebe6eebd49d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P18-1238\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"title\":\"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144792753\",\"name\":\"Y. Qin\"},{\"authorId\":\"151046769\",\"name\":\"Jiajun Du\"},{\"authorId\":\"48379418\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0c0ac3bb66203c32be81193fabeee44c3585582\",\"title\":\"Look Back and Predict Forward in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0c0ac3bb66203c32be81193fabeee44c3585582\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.00249\",\"authors\":[{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.24963/ijcai.2019/132\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"title\":\"Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1909.03918\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05106b86ec45914d1136719d311078182d437872\",\"title\":\"Hierarchy Parsing for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/05106b86ec45914d1136719d311078182d437872\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1511.06062\",\"authors\":[{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"3258919\",\"name\":\"Oscar Beijbom\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.41\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"title\":\"Compact Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"},{\"authorId\":\"145344139\",\"name\":\"Enhua Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2913372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df67d46e78aae0d2fccfb6212d101a342259c01b\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/df67d46e78aae0d2fccfb6212d101a342259c01b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1612.08083\",\"authors\":[{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"144270981\",\"name\":\"Angela Fan\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88caa4a0253a8b0076176745ebc072864eab66e1\",\"title\":\"Language Modeling with Gated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/88caa4a0253a8b0076176745ebc072864eab66e1\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kishore Papineni\"},{\"authorId\":null,\"name\":\"Salim Roukos\"},{\"authorId\":null,\"name\":\"Todd Ward\"},{\"authorId\":null,\"name\":\"Wei-Jing Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yuille . Explain images with multimodal recurrent neural networks\",\"url\":\"\",\"venue\":\"NIPS Workshop on Deep Learning\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1709.01507\",\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"}],\"doi\":\"10.1109/CVPR.2018.00745\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb37561499573109fc2cebb6a7b08f44917267dd\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/fb37561499573109fc2cebb6a7b08f44917267dd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Wei Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":null,\"name\":\"Jiang Wang\"},{\"authorId\":null,\"name\":\"L Alan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yuille . Explain images with multimodal recurrent neural networks\",\"url\":\"\",\"venue\":\"NIPS Workshop on Deep Learning\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005}],\"title\":\"X-Linear Attention Networks for Image Captioning\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Transformer\",\"topicId\":\"6977\",\"url\":\"https://www.semanticscholar.org/topic/6977\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Bilinear transform\",\"topicId\":\"397622\",\"url\":\"https://www.semanticscholar.org/topic/397622\"},{\"topic\":\"Stacking\",\"topicId\":\"100839\",\"url\":\"https://www.semanticscholar.org/topic/100839\"}],\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"