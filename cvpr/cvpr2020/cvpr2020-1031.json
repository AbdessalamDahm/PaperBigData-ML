"{\"abstract\":\"Methods for teaching machines to answer visual questions have made significant progress in recent years, but current methods still lack important human capabilities, including integrating new visual classes and concepts in a modular manner, providing explanations for the answers and handling new domains without explicit examples. We propose a novel method that consists of two main parts: generating a question graph representation, and an answering procedure, guided by the abstract structure of the question graph to invoke an extendable set of visual estimators. Training is performed for the language part and the visual part on their own, but unlike existing schemes, the method does not require any training using images with associated questions and answers. This approach is able to handle novel domains (extended question types and new object classes, properties and relations) as long as corresponding visual estimators are available. In addition, it can provide explanations to its answers and suggest alternatives when questions are not grounded in the image. We demonstrate that this approach achieves both high performance and domain extensibility without any questions-answers training.\",\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\",\"url\":\"https://www.semanticscholar.org/author/2909186\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\",\"url\":\"https://www.semanticscholar.org/author/1743045\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":53756412,\"doi\":\"10.1109/CVPR42600.2020.01039\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"references\":[{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.09815\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"145371954\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"title\":\"Graph Reasoning Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2143543\",\"name\":\"Y. Wang\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":\"10.3115/v1/P15-1129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25369f56a933e3bfb1d8e1588cdc6c50df93ecae\",\"title\":\"Building a Semantic Parser Overnight\",\"url\":\"https://www.semanticscholar.org/paper/25369f56a933e3bfb1d8e1588cdc6c50df93ecae\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1909.13471\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"title\":\"On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints\",\"url\":\"https://www.semanticscholar.org/paper/1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.01860\",\"authors\":[{\"authorId\":\"66275275\",\"name\":\"Yash Srivastava\"},{\"authorId\":\"152967610\",\"name\":\"Vaishnav Murali\"},{\"authorId\":\"34992579\",\"name\":\"S. Dubey\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"title\":\"Visual Question Answering using Deep Learning: A Survey and Performance Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/TPAMI.2018.2844175\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a0912bb76777469295bb2c059faee907e7f3258\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/1a0912bb76777469295bb2c059faee907e7f3258\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Linjie Li\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yu Cheng\"},{\"authorId\":null,\"name\":\"Jingjing Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Relationaware graph attention network for visual question answering\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1903.12314,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c7f922903ac2135abf40d40fa993cc9e5b3efae\",\"title\":\"Annotating the World Wide Web using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/9c7f922903ac2135abf40d40fa993cc9e5b3efae\",\"venue\":\"RIAO\",\"year\":1997},{\"arxivId\":\"1609.05600\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7d007ba376faddf0046930ea7375ed59600cee9\",\"title\":\"Graph-Structured Representations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c7d007ba376faddf0046930ea7375ed59600cee9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arijit Ray\"},{\"authorId\":null,\"name\":\"Karan Sikka\"},{\"authorId\":null,\"name\":\"Ajay Divakaran\"},{\"authorId\":null,\"name\":\"Stefan Lee\"},{\"authorId\":null,\"name\":\"Giedrius\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Burachas. Sunny and dark outside?! improving consistency in vqa through entailed question generation\",\"url\":\"\",\"venue\":\"In Conference on Empirical Methods in Natural Language Processing (EMNLP),\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1703.06907\",\"authors\":[{\"authorId\":\"46594794\",\"name\":\"J. Tobin\"},{\"authorId\":\"39492797\",\"name\":\"Rachel H Fong\"},{\"authorId\":\"6672240\",\"name\":\"Alex Ray\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":\"10.1109/IROS.2017.8202133\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d1864d759d272c5dc928b641d113527a3e81f99\",\"title\":\"Domain randomization for transferring deep neural networks from simulation to the real world\",\"url\":\"https://www.semanticscholar.org/paper/5d1864d759d272c5dc928b641d113527a3e81f99\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1606.03622\",\"authors\":[{\"authorId\":\"3422908\",\"name\":\"Robin Jia\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":\"10.18653/v1/P16-1002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7eac64a8410976759445cce235469163d23ee65\",\"title\":\"Data Recombination for Neural Semantic Parsing\",\"url\":\"https://www.semanticscholar.org/paper/b7eac64a8410976759445cce235469163d23ee65\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1710.07032\",\"authors\":[{\"authorId\":\"2895331\",\"name\":\"Michael Ringgaard\"},{\"authorId\":null,\"name\":\"Rahul Gupta\"},{\"authorId\":\"145366908\",\"name\":\"Fernando C Pereira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"860468e9ac4c314bfe30e21a7f35a0aad67d6b49\",\"title\":\"SLING: A framework for frame semantic parsing\",\"url\":\"https://www.semanticscholar.org/paper/860468e9ac4c314bfe30e21a7f35a0aad67d6b49\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.07871\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cfa5c97164129ce3630511f639040d28db1d4b7\",\"title\":\"FiLM: Visual Reasoning with a General Conditioning Layer\",\"url\":\"https://www.semanticscholar.org/paper/7cfa5c97164129ce3630511f639040d28db1d4b7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145696766\",\"name\":\"R. Speer\"},{\"authorId\":\"2232845\",\"name\":\"Catherine Havasi\"}],\"doi\":\"10.1007/978-3-642-35085-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1382e951677ae167638eb3c97054bb704e3bc359\",\"title\":\"ConceptNet 5: A Large Semantic Network for Relational Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/1382e951677ae167638eb3c97054bb704e3bc359\",\"venue\":\"The People's Web Meets NLP\",\"year\":2013},{\"arxivId\":\"1810.02338\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d15ebe3f5aaf32a9f835f88703241461324c35b\",\"title\":\"Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/9d15ebe3f5aaf32a9f835f88703241461324c35b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1704.05526\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.93\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a396a6febdacb84340d139096455e67049ac1e22\",\"title\":\"Learning to Reason: End-to-End Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a396a6febdacb84340d139096455e67049ac1e22\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1808.00300\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"}],\"doi\":\"10.1007/978-3-030-01231-1_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afe3a0d463e2f099305c745ddbf943844583795d\",\"title\":\"Learning Visual Question Answering by Bootstrapping Hard Attention\",\"url\":\"https://www.semanticscholar.org/paper/afe3a0d463e2f099305c745ddbf943844583795d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1906.06216\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8501712706efa6f314438143de18507471781060\",\"title\":\"Improving Visual Question Answering by Referring to Generated Paragraph Captions\",\"url\":\"https://www.semanticscholar.org/paper/8501712706efa6f314438143de18507471781060\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/1075096.1075150\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a600850ac0120cb09a0b7de7da80bb6a7a76de06\",\"title\":\"Accurate Unlexicalized Parsing\",\"url\":\"https://www.semanticscholar.org/paper/a600850ac0120cb09a0b7de7da80bb6a7a76de06\",\"venue\":\"ACL\",\"year\":2003},{\"arxivId\":\"1801.09718\",\"authors\":[{\"authorId\":\"35358246\",\"name\":\"Mikyas T. Desta\"},{\"authorId\":\"2230576\",\"name\":\"Larry Chen\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"}],\"doi\":\"10.1109/WACV.2018.00201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23d6bb8edcd86f8439072f932f414329b393473b\",\"title\":\"Object-Based Reasoning in VQA\",\"url\":\"https://www.semanticscholar.org/paper/23d6bb8edcd86f8439072f932f414329b393473b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1609.08144\",\"authors\":[{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144739074\",\"name\":\"Mohammad Norouzi\"},{\"authorId\":\"3153147\",\"name\":\"Wolfgang Macherey\"},{\"authorId\":\"2048712\",\"name\":\"M. Krikun\"},{\"authorId\":\"145144022\",\"name\":\"Yuan Cao\"},{\"authorId\":\"145312182\",\"name\":\"Q. Gao\"},{\"authorId\":\"113439369\",\"name\":\"Klaus Macherey\"},{\"authorId\":\"2367620\",\"name\":\"Jeff Klingner\"},{\"authorId\":\"145825976\",\"name\":\"Apurva Shah\"},{\"authorId\":\"145657834\",\"name\":\"M. Johnson\"},{\"authorId\":\"2600217\",\"name\":\"X. Liu\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"2776283\",\"name\":\"S. Gouws\"},{\"authorId\":\"2739610\",\"name\":\"Y. Kato\"},{\"authorId\":\"1765329\",\"name\":\"Taku Kudo\"},{\"authorId\":\"1754386\",\"name\":\"H. Kazawa\"},{\"authorId\":\"144077726\",\"name\":\"K. Stevens\"},{\"authorId\":\"35066890\",\"name\":\"G. Kurian\"},{\"authorId\":\"35173708\",\"name\":\"Nishant Patil\"},{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"39660914\",\"name\":\"C. Young\"},{\"authorId\":\"27070552\",\"name\":\"J. Smith\"},{\"authorId\":\"2909504\",\"name\":\"Jason Riesa\"},{\"authorId\":\"29951847\",\"name\":\"Alex Rudnick\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"48342565\",\"name\":\"Macduff Hughes\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dbde7dfa6cae81df8ac19ef500c42db96c3d1edd\",\"title\":\"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/dbde7dfa6cae81df8ac19ef500c42db96c3d1edd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1711.06794\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a6268d2bc1221ea154097feadea0c58f234d02f\",\"title\":\"Co-attending Free-form Regions and Detections with Multi-modal Multiplicative Feature Embedding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9a6268d2bc1221ea154097feadea0c58f234d02f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.03067\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"289fb3709475f5c87df8d97f129af54029d27fee\",\"title\":\"Compositional Attention Networks for Machine Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/289fb3709475f5c87df8d97f129af54029d27fee\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.11903\",\"authors\":[{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00648\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"title\":\"Visual Question Answering as Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1803.11361\",\"authors\":[{\"authorId\":\"144557910\",\"name\":\"J. Suarez\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3245752\",\"name\":\"Feifei Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bca81af424ebc50018a9e9337041e51a74e3722\",\"title\":\"DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer\",\"url\":\"https://www.semanticscholar.org/paper/0bca81af424ebc50018a9e9337041e51a74e3722\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.05386\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"title\":\"The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions\",\"url\":\"https://www.semanticscholar.org/paper/7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36813724\",\"name\":\"Gil Levi\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"}],\"doi\":\"10.1109/CVPRW.2015.7301352\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee21abcd21e010b53f2c6c21ba2bdd53abdcc40a\",\"title\":\"Age and gender classification using convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/ee21abcd21e010b53f2c6c21ba2bdd53abdcc40a\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1807.09956\",\"authors\":[{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"36c3972569a6949ecca90bfa6f8e99883e092845\",\"title\":\"Pythia v0.1: the Winning Entry to the VQA Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/36c3972569a6949ecca90bfa6f8e99883e092845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"2775151\",\"name\":\"Andreas Vlachos\"},{\"authorId\":\"144523372\",\"name\":\"Stephen Clark\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50c651e9f94f9d4927a726af0ef44818179d87da\",\"title\":\"Semantic Parsing as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/50c651e9f94f9d4927a726af0ef44818179d87da\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":\"1902.05660\",\"authors\":[{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2019.00681\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"title\":\"Cycle-Consistency for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Damien Teney\"},{\"authorId\":null,\"name\":\"Peter Anderson\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Anton van den Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Tips and tricks for visual question answering: Learnings\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11983029\",\"name\":\"Markus Mathias\"},{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-10593-2_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f91ef3b3f71196def8bee7a7bacdc62cd07b64c\",\"title\":\"Face Detection without Bells and Whistles\",\"url\":\"https://www.semanticscholar.org/paper/2f91ef3b3f71196def8bee7a7bacdc62cd07b64c\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1909.10128\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cede1c63336de84344922876e6ee23617e2afb3\",\"title\":\"Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network\",\"url\":\"https://www.semanticscholar.org/paper/4cede1c63336de84344922876e6ee23617e2afb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.07864\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cef77310f326bd30b172459dbecaedf228fc7b23\",\"title\":\"Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cef77310f326bd30b172459dbecaedf228fc7b23\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1808.02632\",\"authors\":[{\"authorId\":\"144579867\",\"name\":\"P. Gao\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"88479495\",\"name\":\"S. Li\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"391af839051826ec317a6ea61010734baf536551\",\"title\":\"Question-Guided Hybrid Convolution for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/391af839051826ec317a6ea61010734baf536551\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1608.00187\",\"authors\":[{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46448-0_51\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d9506257186023b78cf19ed4f9e77a4ae4fa0f0\",\"title\":\"Visual Relationship Detection with Language Priors\",\"url\":\"https://www.semanticscholar.org/paper/4d9506257186023b78cf19ed4f9e77a4ae4fa0f0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Minh-Thang Luong\"},{\"authorId\":null,\"name\":\"Eugene Brevdo\"},{\"authorId\":null,\"name\":\"Rui Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neural machine translation (seq2seq) tutorial, 2017\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707242\",\"name\":\"Minh-Thang Luong\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2826f9dccdcceb113b33ccf2841d488f1419bb30\",\"title\":\"Stanford Neural Machine Translation Systems for Spoken Language Domains\",\"url\":\"https://www.semanticscholar.org/paper/2826f9dccdcceb113b33ccf2841d488f1419bb30\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"title\":\"Bilinear Graph Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1712.00733\",\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23ed7f18100717ba814b2859196e10c5d4fed216\",\"title\":\"Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/23ed7f18100717ba814b2859196e10c5d4fed216\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1902.00038\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1609/aaai.v33i01.33018102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"title\":\"BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1905.09998\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7336b10298798985eaa842da38609a3fd0700be3\",\"title\":\"Self-Critical Reasoning for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7336b10298798985eaa842da38609a3fd0700be3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"48244232\",\"name\":\"A. Chou\"},{\"authorId\":\"34765463\",\"name\":\"Roy Frostig\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b29447ba499507a259ae9d8f685d60cc1597d7d3\",\"title\":\"Semantic Parsing on Freebase from Question-Answer Pairs\",\"url\":\"https://www.semanticscholar.org/paper/b29447ba499507a259ae9d8f685d60cc1597d7d3\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":\"10.21236/ada202227\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27056c1fe6d6a34f4a0086d7abac333ecbe43871\",\"title\":\"Using English for Indexing and Retrieving\",\"url\":\"https://www.semanticscholar.org/paper/27056c1fe6d6a34f4a0086d7abac333ecbe43871\",\"venue\":\"RIAO\",\"year\":1988},{\"arxivId\":\"1704.00260\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2017.452\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"title\":\"Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mikyas T Desta\"},{\"authorId\":null,\"name\":\"Larry Chen\"},{\"authorId\":null,\"name\":\"Tomasz Kornuta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Objectbased reasoning in vqa\",\"url\":\"\",\"venue\":\"In Winter Conference on Applications of Computer Vision, WACV\",\"year\":2018},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":null,\"name\":\"Jianping Fan\"},{\"authorId\":null,\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal factorized bilinear pooling with co-attention learning for visual question answering\",\"url\":\"\",\"venue\":\"In Proc. IEEE Int. Conf. Comp. Vis,\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Luong\"},{\"authorId\":null,\"name\":\"E. Brevdo\"},{\"authorId\":null,\"name\":\"R. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neural machine translation (seq2seq) tutorial. https://github.com/tensorflow/nmt, 2017\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.05268\",\"authors\":[{\"authorId\":\"3296335\",\"name\":\"D. Mascharka\"},{\"authorId\":\"46450184\",\"name\":\"Philip Tran\"},{\"authorId\":\"49902902\",\"name\":\"Ryan Soklaski\"},{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"}],\"doi\":\"10.1109/CVPR.2018.00519\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd0a7c58964905ccfddbad1614165320ccc56393\",\"title\":\"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cd0a7c58964905ccfddbad1614165320ccc56393\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1906.08430\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":\"10.18653/v1/W19-1801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"title\":\"Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects\",\"url\":\"https://www.semanticscholar.org/paper/a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D Teney\"},{\"authorId\":null,\"name\":\"P Anderson\"},{\"authorId\":null,\"name\":\"X He\"},{\"authorId\":null,\"name\":\"A V D Hengel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Tips and tricks for visual question answering\",\"url\":\"\",\"venue\":\"Learnings from the 2017 challenge\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M Luong\"},{\"authorId\":null,\"name\":\"E Brevdo\"},{\"authorId\":null,\"name\":\"R Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neural machine translation (seq2seq) tutorial\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1502.07411\",\"authors\":[{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/TPAMI.2015.2505283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c21b3ffdac5f2450b82dd6660ac69f72bb9018b\",\"title\":\"Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields\",\"url\":\"https://www.semanticscholar.org/paper/9c21b3ffdac5f2450b82dd6660ac69f72bb9018b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.04696\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":\"10.18653/v1/D19-1596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"title\":\"Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2517825\",\"name\":\"J. Krishnamurthy\"},{\"authorId\":\"2836353\",\"name\":\"T. Kollar\"}],\"doi\":\"10.1162/tacl_a_00220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5\",\"title\":\"Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World\",\"url\":\"https://www.semanticscholar.org/paper/c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"}],\"doi\":\"10.1109/CVPR.2007.383218\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a38768dabcd02539265c065a4d7ac445309ae96\",\"title\":\"Learning Color Names from Real-World Images\",\"url\":\"https://www.semanticscholar.org/paper/2a38768dabcd02539265c065a4d7ac445309ae96\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1709.08203\",\"authors\":[{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"2462516\",\"name\":\"Shagun Sodhani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e23229289b1fbea14bc425718bc0a227d100b8e\",\"title\":\"Survey of Recent Advances in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0e23229289b1fbea14bc425718bc0a227d100b8e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1803.08896\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c41d7cfadcdaa5a66694bd57fa5eaf807043ef9\",\"title\":\"Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c41d7cfadcdaa5a66694bd57fa5eaf807043ef9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.00513\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":\"10.18653/v1/P19-1348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b16da6786f799de7d31786fbbf5dafa1979a2c64\",\"title\":\"Generating Question Relevant Captions to Aid Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b16da6786f799de7d31786fbbf5dafa1979a2c64\",\"venue\":\"ACL\",\"year\":2019}],\"title\":\"VQA With No Questions-Answers Training\",\"topics\":[{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Graph (abstract data type)\",\"topicId\":\"199434\",\"url\":\"https://www.semanticscholar.org/topic/199434\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Extensibility\",\"topicId\":\"6036\",\"url\":\"https://www.semanticscholar.org/topic/6036\"},{\"topic\":\"HTTP 404\",\"topicId\":\"28678\",\"url\":\"https://www.semanticscholar.org/topic/28678\"}],\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"