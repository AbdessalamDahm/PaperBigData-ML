"{\"abstract\":\"Creating realistic human videos entails the challenge of being able to simultaneously generate both appearance, as well as motion. To tackle this challenge, we introduce G3AN, a novel spatio-temporal generative model, which seeks to capture the distribution of high dimensional video data and to model appearance and motion in disentangled manner. The latter is achieved by decomposing appearance and motion in a three-stream Generator, where the main stream aims to model spatio-temporal consistency, whereas the two auxiliary streams augment the main stream with multi-scale appearance and motion features, respectively. An extensive quantitative and qualitative analysis shows that our model systematically and significantly outperforms state-of-the-art methods on the facial expression datasets MUG and UvA-NEMO, as well as the Weizmann and UCF101 datasets on human action. Additional analysis on the learned latent representations confirms the successful decomposition of appearance and motion.\",\"arxivId\":\"1912.05523\",\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\",\"url\":null},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\",\"url\":\"https://www.semanticscholar.org/author/105070829\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\",\"url\":\"https://www.semanticscholar.org/author/69929964\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\",\"url\":\"https://www.semanticscholar.org/author/3299530\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.09071\",\"authors\":[{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"150936463\",\"name\":\"Benoit Lagadec\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38489e185cafc2a6ff87843984ed23f273a15f1f\",\"title\":\"Joint Generative and Contrastive Learning for Unsupervised Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/38489e185cafc2a6ff87843984ed23f273a15f1f\",\"venue\":\"\",\"year\":2020}],\"corpusId\":209202683,\"doi\":\"10.1109/CVPR42600.2020.00531\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"33392bb15145ba1c7681061ce891f2e49354ca17\",\"references\":[{\"arxivId\":\"1807.02635\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ec868ebe59918f94140bb2889b9027c55c09b65\",\"title\":\"Video Prediction with Appearance and Motion Conditions\",\"url\":\"https://www.semanticscholar.org/paper/5ec868ebe59918f94140bb2889b9027c55c09b65\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1705.00053\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2017.361\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"title\":\"The Pose Knows: Video Forecasting by Generating Pose Futures\",\"url\":\"https://www.semanticscholar.org/paper/3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723272\",\"name\":\"H. Dibeklioglu\"},{\"authorId\":\"1764521\",\"name\":\"A. A. Salah\"},{\"authorId\":\"1695527\",\"name\":\"T. Gevers\"}],\"doi\":\"10.1007/978-3-642-33712-3_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f3e49ee25a9046ae31fbd15100223aab5a3bf92\",\"title\":\"Are You Really Smiling at Me? Spontaneous versus Posed Enjoyment Smiles\",\"url\":\"https://www.semanticscholar.org/paper/1f3e49ee25a9046ae31fbd15100223aab5a3bf92\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1807.11152\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"40072288\",\"name\":\"Zhe Wang\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01249-6_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"da219d1f43cc00de6c5a411e47feca956f88645f\",\"title\":\"Pose Guided Human Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/da219d1f43cc00de6c5a411e47feca956f88645f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.10597\",\"authors\":[{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2879705\",\"name\":\"Hendrik Strobelt\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df7ad8eeb595da5f7774e91dae06075be952acff\",\"title\":\"GAN Dissection: Visualizing and Understanding Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/df7ad8eeb595da5f7774e91dae06075be952acff\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1908.06965\",\"authors\":[{\"authorId\":\"1988405\",\"name\":\"Md Mahfuzur Rahman Siddiquee\"},{\"authorId\":\"2198519\",\"name\":\"Zongwei Zhou\"},{\"authorId\":\"1930128\",\"name\":\"Nima Tajbakhsh\"},{\"authorId\":\"1726005\",\"name\":\"Ruibin Feng\"},{\"authorId\":\"143751204\",\"name\":\"Michael B. Gotway\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2674518\",\"name\":\"Jianming Liang\"}],\"doi\":\"10.1109/ICCV.2019.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abfab930a183a809b93993456ec8ca7e2478033f\",\"title\":\"Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization\",\"url\":\"https://www.semanticscholar.org/paper/abfab930a183a809b93993456ec8ca7e2478033f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1809.11096\",\"authors\":[{\"authorId\":\"144588497\",\"name\":\"A. Brock\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22aab110058ebbd198edb1f1e7b4f69fb13c0613\",\"title\":\"Large Scale GAN Training for High Fidelity Natural Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/22aab110058ebbd198edb1f1e7b4f69fb13c0613\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.02621\",\"authors\":[{\"authorId\":\"1847145\",\"name\":\"Liqian Ma\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"},{\"authorId\":\"3354258\",\"name\":\"S. Georgoulis\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/CVPR.2018.00018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7df0b3c8befa4263971d1b645545ebecdacec06\",\"title\":\"Disentangled Person Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/e7df0b3c8befa4263971d1b645545ebecdacec06\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50170517\",\"name\":\"Moshe Blank\"},{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/ICCV.2005.28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"title\":\"Actions as space-time shapes\",\"url\":\"https://www.semanticscholar.org/paper/1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":\"1903.04480\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":null,\"name\":\"Chengyu Wang\"},{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00385\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f66d531439f5847afa7b31f49db87a44b788690\",\"title\":\"Video Generation From Single Semantic Label Map\",\"url\":\"https://www.semanticscholar.org/paper/2f66d531439f5847afa7b31f49db87a44b788690\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andr\\u00e9s Romero\"},{\"authorId\":null,\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":null,\"name\":\"Luc Van Gool\"},{\"authorId\":null,\"name\":\"Radu Timofte. Smit\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Stochastic multi-label image-to-image translation\",\"url\":\"\",\"venue\":\"In ICCV Workshops,\",\"year\":2019},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1807.09951\",\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"6812347\",\"name\":\"Yu Tian\"},{\"authorId\":\"143980996\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-01267-0_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec5cdb68fa5a1dc011c9df01e45a0a1c4d59d110\",\"title\":\"Learning to Forecast and Refine Residual Motion for Image-to-Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/ec5cdb68fa5a1dc011c9df01e45a0a1c4d59d110\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1806.02978\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"8774293\",\"name\":\"Shuyang Dai\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"145153424\",\"name\":\"Ricardo Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b701f11ecf5d465c7d5c427914db2ad8c97bb8a9\",\"title\":\"JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/b701f11ecf5d465c7d5c427914db2ad8c97bb8a9\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39051054\",\"name\":\"I. Higgins\"},{\"authorId\":\"2367480\",\"name\":\"Lo\\u00efc Matthey\"},{\"authorId\":\"3422676\",\"name\":\"A. Pal\"},{\"authorId\":\"143641906\",\"name\":\"C. Burgess\"},{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"46378362\",\"name\":\"M. Botvinick\"},{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"},{\"authorId\":\"2289726\",\"name\":\"Alexander Lerchner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a90226c41b79f8b06007609f39f82757073641e2\",\"title\":\"beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework\",\"url\":\"https://www.semanticscholar.org/paper/a90226c41b79f8b06007609f39f82757073641e2\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1811.11389\",\"authors\":[{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"48153708\",\"name\":\"L. Meng\"},{\"authorId\":\"2167686\",\"name\":\"Weidong Yin\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2019.00878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4704d8698b9e50aee53a5970172bd046af58ec6\",\"title\":\"Image Generation From Layout\",\"url\":\"https://www.semanticscholar.org/paper/f4704d8698b9e50aee53a5970172bd046af58ec6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christian Ledig\"},{\"authorId\":null,\"name\":\"Lucas Theis\"},{\"authorId\":null,\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":null,\"name\":\"Jose Caballero\"},{\"authorId\":null,\"name\":\"Andrew Cunningham\"},{\"authorId\":null,\"name\":\"Alejandro Acosta\"},{\"authorId\":null,\"name\":\"Andrew P Aitken\"},{\"authorId\":null,\"name\":\"Alykhan Tejani\"},{\"authorId\":null,\"name\":\"Johannes Totz\"},{\"authorId\":null,\"name\":\"Zehan Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Photorealistic single image super-resolution using a generative adversarial network\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2017},{\"arxivId\":\"1802.05957\",\"authors\":[{\"authorId\":\"3213400\",\"name\":\"Takeru Miyato\"},{\"authorId\":\"1984831\",\"name\":\"T. Kataoka\"},{\"authorId\":\"2877296\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"51462146\",\"name\":\"Y. Yoshida\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84de7d27e2f6160f634a483e8548c499a2cda7fa\",\"title\":\"Spectral Normalization for Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/84de7d27e2f6160f634a483e8548c499a2cda7fa\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1808.07371\",\"authors\":[{\"authorId\":\"1715365\",\"name\":\"C. Chan\"},{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2019.00603\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"title\":\"Everybody Dance Now\",\"url\":\"https://www.semanticscholar.org/paper/e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Irina Higgins\"},{\"authorId\":null,\"name\":\"Loic Matthey\"},{\"authorId\":null,\"name\":\"Arka Pal\"},{\"authorId\":null,\"name\":\"Christopher Burgess\"},{\"authorId\":null,\"name\":\"Xavier Glorot\"},{\"authorId\":null,\"name\":\"Matthew Botvinick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual con\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1910.11328\",\"authors\":[{\"authorId\":\"23982870\",\"name\":\"Badour Albahar\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":\"10.1109/ICCV.2019.00911\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"835edabd9d30c245ebe4002e4fef17eaa208884a\",\"title\":\"Guided Image-to-Image Translation With Bi-Directional Feature Transformation\",\"url\":\"https://www.semanticscholar.org/paper/835edabd9d30c245ebe4002e4fef17eaa208884a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.03704\",\"authors\":[{\"authorId\":\"145848547\",\"name\":\"A. Romero\"},{\"authorId\":\"144115963\",\"name\":\"P. Arbel\\u00e1ez\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":\"10.1109/ICCVW.2019.00410\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"384ed183aa4dcde3bfaadeeb990ec9212eaca39a\",\"title\":\"SMIT: Stochastic Multi-Label Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/384ed183aa4dcde3bfaadeeb990ec9212eaca39a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1606.03657\",\"authors\":[{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35da0a2001eea88486a5de677ab97868c93d0824\",\"title\":\"InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/35da0a2001eea88486a5de677ab97868c93d0824\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1805.08318\",\"authors\":[{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"},{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"title\":\"Self-Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tao Xu\"},{\"authorId\":null,\"name\":\"Pengchuan Zhang\"},{\"authorId\":null,\"name\":\"Qiuyuan Huang\"},{\"authorId\":null,\"name\":\"Han Zhang\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Xiaolei Huang\"},{\"authorId\":null,\"name\":\"Xiaodong He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attngan: Finegrained text to image generation with attentional generative adversarial networks\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/WACV45572.2020.9093492\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"title\":\"ImaGINator: Conditional Spatio-Temporal GAN for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.03498\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"571b0750085ae3d939525e62af510ee2cee9d5ea\",\"title\":\"Improved Techniques for Training GANs\",\"url\":\"https://www.semanticscholar.org/paper/571b0750085ae3d939525e62af510ee2cee9d5ea\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795764\",\"name\":\"Niki Aifanti\"},{\"authorId\":\"144385012\",\"name\":\"C. Papachristou\"},{\"authorId\":\"143685457\",\"name\":\"A. Delopoulos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1af714b92372c8e606485a3982eab2f16772ad8\",\"title\":\"The MUG facial expression database\",\"url\":\"https://www.semanticscholar.org/paper/f1af714b92372c8e606485a3982eab2f16772ad8\",\"venue\":\"11th International Workshop on Image Analysis for Multimedia Interactive Services WIAMIS 10\",\"year\":2010},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1706.08500\",\"authors\":[{\"authorId\":\"2445103\",\"name\":\"Martin Heusel\"},{\"authorId\":\"19219270\",\"name\":\"Hubert Ramsauer\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"37082831\",\"name\":\"Bernhard Nessler\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"231af7dc01a166cac3b5b01ca05778238f796e41\",\"title\":\"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\",\"url\":\"https://www.semanticscholar.org/paper/231af7dc01a166cac3b5b01ca05778238f796e41\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1206.5538\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145467703\",\"name\":\"P. Vincent\"}],\"doi\":\"10.1109/TPAMI.2013.50\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"184ac0766262312ba76bbdece4e7ffad0aa8180b\",\"title\":\"Representation Learning: A Review and New Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/184ac0766262312ba76bbdece4e7ffad0aa8180b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1611.06624\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":\"10.1109/ICCV.2017.308\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"title\":\"Temporal Generative Adversarial Nets with Singular Value Clipping\",\"url\":\"https://www.semanticscholar.org/paper/062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Niki Aifanti\"},{\"authorId\":null,\"name\":\"Christos Papachristou\"},{\"authorId\":null,\"name\":\"Anastasios Delopoulos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The mug facial expression database. In Work- 5271 shop on Image analysis for multimedia interactive services (WIAMIS)\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":\"1703.07332\",\"authors\":[{\"authorId\":\"145245424\",\"name\":\"Adrian Bulat\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"}],\"doi\":\"10.1109/ICCV.2017.116\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aadf777ef924ac93317550fbdfb9649a10d8aa82\",\"title\":\"How Far are We from Solving the 2D & 3D Face Alignment Problem? (and a Dataset of 230,000 3D Facial Landmarks)\",\"url\":\"https://www.semanticscholar.org/paper/aadf777ef924ac93317550fbdfb9649a10d8aa82\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1710.10196\",\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"744fe47157477235032f7bb3777800f9f2f45e52\",\"title\":\"Progressive Growing of GANs for Improved Quality, Stability, and Variation\",\"url\":\"https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1905.01270\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"143963461\",\"name\":\"Hung-Yu Tseng\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"144688398\",\"name\":\"Maneesh Kumar Singh\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01246-5_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d5d9d8e74b215609eabba80ef79a35ebf460e49\",\"title\":\"Diverse Image-to-Image Translation via Disentangled Representations\",\"url\":\"https://www.semanticscholar.org/paper/3d5d9d8e74b215609eabba80ef79a35ebf460e49\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting-Chun Wang\"},{\"authorId\":null,\"name\":\"Ming-Yu Liu\"},{\"authorId\":null,\"name\":\"Jun-Yan Zhu\"},{\"authorId\":null,\"name\":\"Guilin Liu\"},{\"authorId\":null,\"name\":\"Andrew Tao\"},{\"authorId\":null,\"name\":\"Jan Kautz\"},{\"authorId\":null,\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video-tovideo synthesis\",\"url\":\"\",\"venue\":\"In NeurIPS,\",\"year\":2018},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1811.11155\",\"authors\":[{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"47284770\",\"name\":\"Utkarsh Ojha\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/CVPR.2019.00665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65ec3cca4d76a9db6dfd4b2e64c5b4c4beecf988\",\"title\":\"FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery\",\"url\":\"https://www.semanticscholar.org/paper/65ec3cca4d76a9db6dfd4b2e64c5b4c4beecf988\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.04948\",\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"}],\"doi\":\"10.1109/CVPR.2019.00453\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceb2ebef0b41e31c1a21b28c2734123900c005e2\",\"title\":\"A Style-Based Generator Architecture for Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ceb2ebef0b41e31c1a21b28c2734123900c005e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}],\"title\":\"G3AN: Disentangling Appearance and Motion for Video Generation\",\"topics\":[{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Image resolution\",\"topicId\":\"881\",\"url\":\"https://www.semanticscholar.org/topic/881\"}],\"url\":\"https://www.semanticscholar.org/paper/33392bb15145ba1c7681061ce891f2e49354ca17\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"