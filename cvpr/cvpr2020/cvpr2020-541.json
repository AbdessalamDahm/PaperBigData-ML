"{\"abstract\":\"Differentiable image sampling in the form of backward warping has seen broad adoption in tasks like depth estimation and optical flow prediction. In contrast, how to perform forward warping has seen less attention, partly due to additional challenges such as resolving the conflict of mapping multiple pixels to the same target location in a differentiable way. We propose softmax splatting to address this paradigm shift and show its effectiveness on the application of frame interpolation. Specifically, given two input frames, we forward-warp the frames and their feature pyramid representations based on an optical flow estimate using softmax splatting. In doing so, the softmax splatting seamlessly handles cases where multiple source pixels map to the same target location. We then use a synthesis network to predict the interpolation result from the warped representations. Our softmax splatting allows us to not only interpolate frames at an arbitrary time but also to fine tune the feature pyramid and the optical flow. We show that our synthesis approach, empowered by softmax splatting, achieves new state-of-the-art results for video frame interpolation.\",\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\",\"url\":\"https://www.semanticscholar.org/author/39644974\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\",\"url\":\"https://www.semanticscholar.org/author/98220548\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"101947437\",\"name\":\"J. Saric\"},{\"authorId\":\"3009751\",\"name\":\"M. Orsic\"},{\"authorId\":\"2111962\",\"name\":\"Tonci Antunovic\"},{\"authorId\":\"3237756\",\"name\":\"Sacha Vrazic\"},{\"authorId\":\"3166278\",\"name\":\"Sinisa Segvic\"}],\"doi\":\"10.1109/CVPR42600.2020.01066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"921faa221b44a3cac6587172866fb58073bbc3c0\",\"title\":\"Warp to the Future: Joint Forecasting of Features and Feature Motion\",\"url\":\"https://www.semanticscholar.org/paper/921faa221b44a3cac6587172866fb58073bbc3c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01484\",\"authors\":[{\"authorId\":\"1853653014\",\"name\":\"Jamie Watson\"},{\"authorId\":\"2918822\",\"name\":\"Oisin Mac Aodha\"},{\"authorId\":\"2810420\",\"name\":\"Daniyar Turmukhambetov\"},{\"authorId\":\"3309893\",\"name\":\"G. Brostow\"},{\"authorId\":\"144096365\",\"name\":\"M. Firman\"}],\"doi\":\"10.1007/978-3-030-58452-8_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"039154f8e22f55c5b53de1caf95825dd77708129\",\"title\":\"Learning Stereo from Single Images\",\"url\":\"https://www.semanticscholar.org/paper/039154f8e22f55c5b53de1caf95825dd77708129\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.00595\",\"authors\":[{\"authorId\":\"8177578\",\"name\":\"D. Rozumnyi\"},{\"authorId\":\"1821761\",\"name\":\"M. Oswald\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97bf233036e88bad4379a837638c11c0c79b9250\",\"title\":\"DeFMO: Deblurring and Shape Recovery of Fast Moving Objects\",\"url\":\"https://www.semanticscholar.org/paper/97bf233036e88bad4379a837638c11c0c79b9250\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.06294\",\"authors\":[{\"authorId\":\"14042304\",\"name\":\"Zhewei Huang\"},{\"authorId\":\"123437116\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"145577184\",\"name\":\"Wen Heng\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"35132667\",\"name\":\"Shuchang Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"title\":\"RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02177\",\"authors\":[{\"authorId\":\"2030985890\",\"name\":\"Arda Duzcceker\"},{\"authorId\":\"2762033\",\"name\":\"S. Galliani\"},{\"authorId\":\"31981082\",\"name\":\"C. Vogel\"},{\"authorId\":\"3344493\",\"name\":\"P. Speciale\"},{\"authorId\":\"24871970\",\"name\":\"Mihai Dusmanu\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6a930f1bac72d7a8117ea8449cc55b2c3b3e254\",\"title\":\"DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/a6a930f1bac72d7a8117ea8449cc55b2c3b3e254\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.15128\",\"authors\":[{\"authorId\":\"118300344\",\"name\":\"Aleksander Holynski\"},{\"authorId\":\"1396759259\",\"name\":\"Brian Curless\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"title\":\"Animating Pictures with Eulerian Motion Fields\",\"url\":\"https://www.semanticscholar.org/paper/a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13084\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13034a395d5c6728c9b11e777828d9998018cbf6\",\"title\":\"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/13034a395d5c6728c9b11e777828d9998018cbf6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09854\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70dbca5ab460fe95b2b81df09df0e95a40951f1a\",\"title\":\"Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/70dbca5ab460fe95b2b81df09df0e95a40951f1a\",\"venue\":\"\",\"year\":2020}],\"corpusId\":212675709,\"doi\":\"10.1109/CVPR42600.2020.00548\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"references\":[{\"arxivId\":\"1711.07837\",\"authors\":[{\"authorId\":\"24362273\",\"name\":\"S. Meister\"},{\"authorId\":\"2470340\",\"name\":\"Junhwa Hur\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e77b5157b0fa0f365808e26af287c3164e002f\",\"title\":\"UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss\",\"url\":\"https://www.semanticscholar.org/paper/43e77b5157b0fa0f365808e26af287c3164e002f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"}],\"doi\":\"10.1145/2980179.2982398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"title\":\"Temporally coherent completion of dynamic video\",\"url\":\"https://www.semanticscholar.org/paper/cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1611.05250\",\"authors\":[{\"authorId\":\"79382929\",\"name\":\"J. Caballero\"},{\"authorId\":\"1779917\",\"name\":\"C. Ledig\"},{\"authorId\":\"83015038\",\"name\":\"Andrew Aitken\"},{\"authorId\":\"145987822\",\"name\":\"A. Acosta\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"152554375\",\"name\":\"W. Shi\"}],\"doi\":\"10.1109/CVPR.2017.304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0584f25256c83f10349d6108fde1bccd82908d8f\",\"title\":\"Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation\",\"url\":\"https://www.semanticscholar.org/paper/0584f25256c83f10349d6108fde1bccd82908d8f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67103459\",\"name\":\"Y. Kuroki\"},{\"authorId\":\"50307128\",\"name\":\"H. Takahashi\"},{\"authorId\":\"3331089\",\"name\":\"M. Kusakabe\"},{\"authorId\":\"144955565\",\"name\":\"K. Yamakoshi\"}],\"doi\":\"10.1002/JSID.237\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1b98384a570a4241f13e9320634beb10aa8f453\",\"title\":\"Effects of motion image stimuli with normal and high frame rates on EEG power spectra: comparison with continuous motion image stimuli\",\"url\":\"https://www.semanticscholar.org/paper/e1b98384a570a4241f13e9320634beb10aa8f453\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1804.00884\",\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/CVPR.2018.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"title\":\"PhaseNet for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.10967\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"40405236\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2018.00183\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"65fadccad0fc743876a259c2b779622636c2ffde\",\"title\":\"Context-Aware Synthesis for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/65fadccad0fc743876a259c2b779622636c2ffde\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Jean Pouget - Abadie , Mehdi Mirza , Bing Xu , David Warde - Farley , Sherjil Ozair , Aaron C . Courville , and Yoshua Bengio . Generative Adversarial Nets\",\"url\":\"\",\"venue\":\"IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1704.07813\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"35238678\",\"name\":\"D. Lowe\"}],\"doi\":\"10.1109/CVPR.2017.700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3abf64d10a5d9a426d864bcfd68daed370d6904c\",\"title\":\"Unsupervised Learning of Depth and Ego-Motion from Video\",\"url\":\"https://www.semanticscholar.org/paper/3abf64d10a5d9a426d864bcfd68daed370d6904c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1711.06620\",\"authors\":[{\"authorId\":\"30176430\",\"name\":\"Xiaodong Cun\"},{\"authorId\":\"143979425\",\"name\":\"F. Xu\"},{\"authorId\":\"145956876\",\"name\":\"Chi-Man Pun\"},{\"authorId\":\"145990240\",\"name\":\"Hao Gao\"}],\"doi\":\"10.1145/3230744.3230789\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d55cf694dddc03039372d2a3bf0274c8e2c5dbd1\",\"title\":\"Depth-Assisted Full Resolution Network for Single Image-Based View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/d55cf694dddc03039372d2a3bf0274c8e2c5dbd1\",\"venue\":\"IEEE Computer Graphics and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaodong Cun\"},{\"authorId\":null,\"name\":\"Feng Xu\"},{\"authorId\":null,\"name\":\"Chi-Man Pun\"},{\"authorId\":null,\"name\":\"Hao Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Barron . Learning to Synthesize Motion Blur\",\"url\":\"\",\"venue\":\"IEEE Conference on Computer Vision and Pattern Recognition IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":null},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Simone Meyer\"},{\"authorId\":null,\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":null,\"name\":\"Brian McWilliams\"},{\"authorId\":null,\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":null,\"name\":\"H Markus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Gross . Deep Video Color Propagation\",\"url\":\"\",\"venue\":\"British Machine Vision Conference\",\"year\":null},{\"arxivId\":\"1802.05522\",\"authors\":[{\"authorId\":\"2071658\",\"name\":\"R. Mahjourian\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1109/CVPR.2018.00594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c33b61e4c4cae519fc65319ec0305e1b10d17219\",\"title\":\"Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints\",\"url\":\"https://www.semanticscholar.org/paper/c33b61e4c4cae519fc65319ec0305e1b10d17219\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.06077\",\"authors\":[{\"authorId\":\"8347541\",\"name\":\"Y. Blau\"},{\"authorId\":\"1880407\",\"name\":\"T. Michaeli\"}],\"doi\":\"10.1109/CVPR.2018.00652\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce05d5c066c1237c1399d3ccd69f2ea49a6d65c3\",\"title\":\"The Perception-Distortion Tradeoff\",\"url\":\"https://www.semanticscholar.org/paper/ce05d5c066c1237c1399d3ccd69f2ea49a6d65c3\",\"venue\":\"CVPR\",\"year\":2018},{\"arxivId\":\"1906.05928\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/ICCV.2019.00098\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"title\":\"Unsupervised Video Interpolation Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145467703\",\"name\":\"P. Vincent\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65d994fb778a8d9e0f632659fb33a082949a50d3\",\"title\":\"Visualizing Higher-Layer Features of a Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/65d994fb778a8d9e0f632659fb33a082949a50d3\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1809.08317\",\"authors\":[{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47b0e2fde37b3d1810a5b5a19597765fd76c691e\",\"title\":\"Temporal Interpolation as an Unsupervised Pretraining Task for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/47b0e2fde37b3d1810a5b5a19597765fd76c691e\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10678970\",\"name\":\"Joel Janai\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1109/CVPR.2017.154\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bd59b6111c21ca9f133b2ac9f0a8b102e344076\",\"title\":\"Slow Flow: Exploiting High-Speed Cameras for Accurate and Diverse Optical Flow Reference Data\",\"url\":\"https://www.semanticscholar.org/paper/8bd59b6111c21ca9f133b2ac9f0a8b102e344076\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1806.06575\",\"authors\":[{\"authorId\":\"1403663009\",\"name\":\"Thu Nguyen-Phuoc\"},{\"authorId\":\"145617881\",\"name\":\"C. Li\"},{\"authorId\":\"50988737\",\"name\":\"Stephen Balaban\"},{\"authorId\":\"6635795\",\"name\":\"Yongliang Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bafe32de309fb83b81c5b7d99e1df5b89f13eac\",\"title\":\"RenderNet: A deep convolutional network for differentiable rendering from 3D shapes\",\"url\":\"https://www.semanticscholar.org/paper/9bafe32de309fb83b81c5b7d99e1df5b89f13eac\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.07036\",\"authors\":[{\"authorId\":\"33385667\",\"name\":\"Tak-Wai Hui\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPR.2018.00936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"051b3763c2ad4e4271db712b0e9a4cfe298d05db\",\"title\":\"LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/051b3763c2ad4e4271db712b0e9a4cfe298d05db\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonas Wulff\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Black . Temporal Interpolation as an Unsupervised Pretraining Task for Optical Flow Estimation\",\"url\":\"\",\"venue\":\"German Conference on Pattern Recognition\",\"year\":null},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2769987\",\"name\":\"T. Aydin\"},{\"authorId\":\"3177518\",\"name\":\"N. Stefanoski\"},{\"authorId\":\"40477851\",\"name\":\"S. Croci\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1145/2661229.2661268\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"967f6c9fe1a4710071755e624f11bc40a0f9f562\",\"title\":\"Temporally coherent local tone mapping of HDR video\",\"url\":\"https://www.semanticscholar.org/paper/967f6c9fe1a4710071755e624f11bc40a0f9f562\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tak-Wai Hui\"},{\"authorId\":null,\"name\":\"Xiaoou Tang\"},{\"authorId\":null,\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Lite- FlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation\",\"url\":\"\",\"venue\":\"In IEEE Conference on Computer Vision and Pattern Recognition,\",\"year\":2018},{\"arxivId\":\"1609.03677\",\"authors\":[{\"authorId\":\"31082236\",\"name\":\"C. Godard\"},{\"authorId\":\"2918822\",\"name\":\"Oisin Mac Aodha\"},{\"authorId\":\"88167816\",\"name\":\"G. J. Brostow\"}],\"doi\":\"10.1109/CVPR.2017.699\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d\",\"title\":\"Unsupervised Monocular Depth Estimation with Left-Right Consistency\",\"url\":\"https://www.semanticscholar.org/paper/4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1808.03232\",\"authors\":[{\"authorId\":\"3230188\",\"name\":\"Simone Meyer\"},{\"authorId\":\"51217206\",\"name\":\"Victor Cornill\\u00e8re\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c40c6505c2133321f17c7d02c1bb356f581da89\",\"title\":\"Deep Video Color Propagation\",\"url\":\"https://www.semanticscholar.org/paper/0c40c6505c2133321f17c7d02c1bb356f581da89\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1804.06008\",\"authors\":[{\"authorId\":\"65795460\",\"name\":\"Miaomiao Liu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"}],\"doi\":\"10.1109/CVPR.2018.00485\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f2f111d098ee6bda1207d0d50d2ebcc2294dfe1\",\"title\":\"Geometry-Aware Deep Network for Single-Image Novel View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6f2f111d098ee6bda1207d0d50d2ebcc2294dfe1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.08768\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/tpami.2019.2941941\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d833c48334e906537f21757b6f9fa44da66f6c76\",\"title\":\"MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d833c48334e906537f21757b6f9fa44da66f6c76\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1711.05890\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"152124887\",\"name\":\"Liang Zhao\"},{\"authorId\":\"144174114\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2018.00513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b197f323e7d5514e5ada388858e38890dce0148\",\"title\":\"Occlusion Aware Unsupervised Learning of Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0b197f323e7d5514e5ada388858e38890dce0148\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.06919\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"40943290\",\"name\":\"Nayan Singhal\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1007/978-3-030-01237-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"title\":\"Video Compression through Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"39628969\",\"name\":\"Christopher Olah\"}],\"doi\":\"10.23915/DISTILL.00003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9dab7574d56ae81efe6c90c213c6509b36cf950\",\"title\":\"Deconvolution and Checkerboard Artifacts\",\"url\":\"https://www.semanticscholar.org/paper/d9dab7574d56ae81efe6c90c213c6509b36cf950\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67103459\",\"name\":\"Y. Kuroki\"},{\"authorId\":\"7935505\",\"name\":\"T. Nishi\"},{\"authorId\":\"153551637\",\"name\":\"S. Kobayashi\"},{\"authorId\":\"65768815\",\"name\":\"H. Oyaizu\"},{\"authorId\":\"13159221\",\"name\":\"S. Yoshimura\"}],\"doi\":\"10.1889/1.2451560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a27b0d53986643366149904a59fddc4dede9def\",\"title\":\"A psychophysical study of improvements in motion\\u2010image quality by using high frame rates\",\"url\":\"https://www.semanticscholar.org/paper/3a27b0d53986643366149904a59fddc4dede9def\",\"venue\":\"\",\"year\":2007},{\"arxivId\":\"1609.02974\",\"authors\":[{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1145/2980179.2980251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"title\":\"Learning-based view synthesis for light field cameras\",\"url\":\"https://www.semanticscholar.org/paper/8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1704.02738\",\"authors\":[{\"authorId\":\"37983219\",\"name\":\"X. Tao\"},{\"authorId\":\"2692838\",\"name\":\"H. Gao\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":\"10.1109/ICCV.2017.479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b5c2314b79e19205e4f0f91f7c8d8b12c337d7f\",\"title\":\"Detail-Revealing Deep Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/2b5c2314b79e19205e4f0f91f7c8d8b12c337d7f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2362189\",\"name\":\"L. Rak\\u00eat\"},{\"authorId\":\"3264146\",\"name\":\"Lars Roholm\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-642-33179-4_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"215332019795204eab7cdaae9bc9d8b4ac42e46a\",\"title\":\"Motion Compensated Frame Interpolation with a Symmetric Optical Flow Constraint\",\"url\":\"https://www.semanticscholar.org/paper/215332019795204eab7cdaae9bc9d8b4ac42e46a\",\"venue\":\"ISVC\",\"year\":2012},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1801.03924\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00068\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c468bbde6a22d961829e1970e6ad5795e05418d1\",\"title\":\"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\",\"url\":\"https://www.semanticscholar.org/paper/c468bbde6a22d961829e1970e6ad5795e05418d1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.07958\",\"authors\":[{\"authorId\":\"7838570\",\"name\":\"Damien Fourure\"},{\"authorId\":\"2003050\",\"name\":\"R. Emonet\"},{\"authorId\":\"1687778\",\"name\":\"\\u00c9lisa Fromont\"},{\"authorId\":\"1706185\",\"name\":\"D. Muselet\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.5244/C.31.181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fb5d9c589ea53f25b981673a7a750e854e7d687\",\"title\":\"Residual Conv-Deconv Grid Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1fb5d9c589ea53f25b981673a7a750e854e7d687\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1608.05842\",\"authors\":[{\"authorId\":\"97583830\",\"name\":\"J. J. Yu\"},{\"authorId\":\"34939798\",\"name\":\"Adam W. Harley\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"}],\"doi\":\"10.1007/978-3-319-49409-8_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"375b6972d4185ce275dcad51581c9bbb03fb3f4f\",\"title\":\"Back to Basics: Unsupervised Learning of Optical Flow via Brightness Constancy and Motion Smoothness\",\"url\":\"https://www.semanticscholar.org/paper/375b6972d4185ce275dcad51581c9bbb03fb3f4f\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1708.03088\",\"authors\":[{\"authorId\":\"2176869\",\"name\":\"Raghudeep Gadde\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"2871555\",\"name\":\"P. Gehler\"}],\"doi\":\"10.1109/ICCV.2017.477\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c33289788ca69a55c7eefe6e672c82a0cac5a299\",\"title\":\"Semantic Video CNNs Through Representation Warping\",\"url\":\"https://www.semanticscholar.org/paper/c33289788ca69a55c7eefe6e672c82a0cac5a299\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"35130187\",\"name\":\"Xiaolong Zhu\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2017.745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"title\":\"Real-Time Neural Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tinghui Zhou\"},{\"authorId\":null,\"name\":\"Shubham Tulsiani\"},{\"authorId\":null,\"name\":\"Weilun Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Efros . View Synthesis by Appearance Flow\",\"url\":\"\",\"venue\":\"European Conference on Computer Vision\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1811.11745\",\"authors\":[{\"authorId\":\"145661449\",\"name\":\"T. Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":\"10.1109/CVPR.2019.00700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c945dfec0137bcd7886898fa61f46705e00173dc\",\"title\":\"Learning to Synthesize Motion Blur\",\"url\":\"https://www.semanticscholar.org/paper/c945dfec0137bcd7886898fa61f46705e00173dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1709.02371\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00931\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"title\":\"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Simone Meyer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Gross , and Christopher Schroers . PhaseNet for Video Frame Interpolation\",\"url\":\"\",\"venue\":\"IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.00449\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01267-0_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"title\":\"Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"topics\":[{\"topic\":\"Softmax function\",\"topicId\":\"966784\",\"url\":\"https://www.semanticscholar.org/topic/966784\"},{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Rendering (computer graphics)\",\"topicId\":\"15667\",\"url\":\"https://www.semanticscholar.org/topic/15667\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Volume rendering\",\"topicId\":\"15655\",\"url\":\"https://www.semanticscholar.org/topic/15655\"}],\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"