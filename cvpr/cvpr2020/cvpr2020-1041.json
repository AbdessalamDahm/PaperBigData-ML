"{\"abstract\":\"Recent deep learning approaches have achieved impressive performance on visual sound separation tasks. However, these approaches are mostly built on appearance and optical flow like motion feature representations, which exhibit limited abilities to find the correlations between audio signals and visual points, especially when separating multiple instruments of the same types, such as multiple violins in a scene. To address this, we propose ``Music Gesture,\\\" a keypoint-based structured representation to explicitly model the body and finger movements of musicians when they perform music. We first adopt a context-aware graph network to integrate visual semantic context with body dynamics and then apply an audio-visual fusion model to associate body movements with the corresponding audio signals. Experimental results on three music performance datasets show: 1) strong improvements upon benchmark metrics for hetero-musical separation tasks (i.e. different instruments); 2) new ability for effective homo-musical separation for piano, flute, and trumpet duets, which to our best knowledge has never been achieved with alternative methods.\",\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\",\"url\":\"https://www.semanticscholar.org/author/144158271\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\",\"url\":\"https://www.semanticscholar.org/author/145592817\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\",\"url\":\"https://www.semanticscholar.org/author/47940821\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\",\"url\":\"https://www.semanticscholar.org/author/1763295\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805212\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49889937\",\"name\":\"Yimeng Zhang\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"1993581583\",\"name\":\"Bo Wu\"},{\"authorId\":\"30910424\",\"name\":\"A. Walid\"}],\"doi\":\"10.1145/3394171.3413527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"title\":\"Video Synthesis via Transform-Based Tensor Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.07984\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"title\":\"Separating Sounds from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.01143\",\"authors\":[{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"34654283\",\"name\":\"Scott T. Wisdom\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"2211633\",\"name\":\"Tal Remez\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"title\":\"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds\",\"url\":\"https://www.semanticscholar.org/paper/8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993657140\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3394171.3414025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bf257acf56fb214af71b123f1b734263242cc36\",\"title\":\"One-shot Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/2bf257acf56fb214af71b123f1b734263242cc36\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.07931\",\"authors\":[{\"authorId\":\"134192555\",\"name\":\"J. F. Montesinos\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1109/MMSP48831.2020.9287124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"title\":\"Solos: A Dataset for Audio-Visual Music Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.03478\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866ba646300961747ddc29ce57153858e2be588a\",\"title\":\"Multi-Instrumentalist Net: Unsupervised Generation of Music from Body Movements\",\"url\":\"https://www.semanticscholar.org/paper/866ba646300961747ddc29ce57153858e2be588a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04954\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"40256075\",\"name\":\"Jeremy I Schwartz\"},{\"authorId\":\"1753624613\",\"name\":\"Seth Alter\"},{\"authorId\":\"8551292\",\"name\":\"Martin Schrimpf\"},{\"authorId\":\"50690309\",\"name\":\"James Traer\"},{\"authorId\":\"145584238\",\"name\":\"J\\u00falian Let\\u00edcia de Freitas\"},{\"authorId\":\"2898540\",\"name\":\"J. Kubilius\"},{\"authorId\":\"150894502\",\"name\":\"Abhishek Bhandwaldar\"},{\"authorId\":\"49101800\",\"name\":\"N. Haber\"},{\"authorId\":\"27023509\",\"name\":\"M. Sano\"},{\"authorId\":\"1802442393\",\"name\":\"Kuno Kim\"},{\"authorId\":\"50844928\",\"name\":\"Elias Wang\"},{\"authorId\":\"2440995\",\"name\":\"Damian Mrowca\"},{\"authorId\":\"1802680741\",\"name\":\"Michael Lingelbach\"},{\"authorId\":\"1381602121\",\"name\":\"Aidan Curtis\"},{\"authorId\":\"19247947\",\"name\":\"Kevin T. Feigelis\"},{\"authorId\":\"29737051\",\"name\":\"Daniel M. Bear\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"145082769\",\"name\":\"David Cox\"},{\"authorId\":\"34409560\",\"name\":\"James J. DiCarlo\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"6772751\",\"name\":\"Daniel L. K. Yamins\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdd1ff22c3a35d9d7426ef6e6fd9a4775317f5a6\",\"title\":\"ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation\",\"url\":\"https://www.semanticscholar.org/paper/fdd1ff22c3a35d9d7426ef6e6fd9a4775317f5a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49507095\",\"name\":\"Haoming Xu\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"1443732549\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1145/3394171.3413581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"title\":\"Cross-Modal Relation-Aware Networks for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.12992\",\"authors\":[{\"authorId\":\"32025363\",\"name\":\"Yang Zhou\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"1399909799\",\"name\":\"Xintong Han\"},{\"authorId\":\"2808670\",\"name\":\"E. Kalogerakis\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"80452718\",\"name\":\"J. Echevarria\"}],\"doi\":\"10.1145/3414685.3417774\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"739497ec657d2c1e6ed7eb424951e0affe117be4\",\"title\":\"MakeItTalk: Speaker-Aware Talking Head Animation\",\"url\":\"https://www.semanticscholar.org/paper/739497ec657d2c1e6ed7eb424951e0affe117be4\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2008.00820\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"4506893\",\"name\":\"Hongdong Xiao\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2020.3009820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"title\":\"Generating Visually Aligned Sound From Videos\",\"url\":\"https://www.semanticscholar.org/paper/d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.12031\",\"authors\":[{\"authorId\":\"8319315\",\"name\":\"Zakaria Aldeneh\"},{\"authorId\":\"27006072\",\"name\":\"A. Kumar\"},{\"authorId\":\"115268571\",\"name\":\"Barry-John Theobald\"},{\"authorId\":\"1779097\",\"name\":\"E. Marchi\"},{\"authorId\":\"51311465\",\"name\":\"Sachin Kajarekar\"},{\"authorId\":\"100925254\",\"name\":\"Devang Naik\"},{\"authorId\":\"1694508\",\"name\":\"Ahmed Hussen Abdelaziz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"51247b4d037297cb0ba336304f3908c4ea32b362\",\"title\":\"Self-supervised Learning of Visual Speech Features with Audiovisual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/51247b4d037297cb0ba336304f3908c4ea32b362\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.06355\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1007/978-3-030-58565-5_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"title\":\"Multiple Sound Sources Localization from Coarse to Fine\",\"url\":\"https://www.semanticscholar.org/paper/53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":215827928,\"doi\":\"10.1109/CVPR42600.2020.01049\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144549270\",\"name\":\"M. Brand\"}],\"doi\":\"10.1145/311535.311537\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2062c4359e57b22789cc38d0a97cc12acb930f43\",\"title\":\"Voice puppetry\",\"url\":\"https://www.semanticscholar.org/paper/2062c4359e57b22789cc38d0a97cc12acb930f43\",\"venue\":\"SIGGRAPH '99\",\"year\":1999},{\"arxivId\":\"1904.07750\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00398\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"title\":\"Co-Separating Sounds of Visual Objects\",\"url\":\"https://www.semanticscholar.org/paper/7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1804.00326\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c75658b080a9baaac20db39af86016ffa36f6f0\",\"title\":\"Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching\",\"url\":\"https://www.semanticscholar.org/paper/2c75658b080a9baaac20db39af86016ffa36f6f0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1905.03244\",\"authors\":[{\"authorId\":\"113950826\",\"name\":\"Nikos Kolotouros\"},{\"authorId\":\"2829330\",\"name\":\"Georgios Pavlakos\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":\"10.1109/CVPR.2019.00463\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ce6d7373d307eb14f7ee76357e442f920be631a\",\"title\":\"Convolutional Mesh Regression for Single-Image Human Shape Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/9ce6d7373d307eb14f7ee76357e442f920be631a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.04160\",\"authors\":[{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\"},{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"51169014\",\"name\":\"Gefen Kohavi\"},{\"authorId\":\"1715365\",\"name\":\"C. Chan\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2019.00361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e609684188c842092ae7bcae81429471e422df4d\",\"title\":\"Learning Individual Styles of Conversational Gesture\",\"url\":\"https://www.semanticscholar.org/paper/e609684188c842092ae7bcae81429471e422df4d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1808.05561\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1145/3240508.3240578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"540831094fd9b80469c8dacb9320b7e342b50e03\",\"title\":\"Emotion Recognition in Speech using Cross-Modal Transfer in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/540831094fd9b80469c8dacb9320b7e342b50e03\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145683892\",\"name\":\"A. Cichocki\"},{\"authorId\":\"145942962\",\"name\":\"R. Zdunek\"},{\"authorId\":\"9377326\",\"name\":\"A. Phan\"},{\"authorId\":\"153803720\",\"name\":\"S. Amari\"}],\"doi\":\"10.1002/9780470747278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc613a2a208f241b38bc41f62b4fc4db7217c7\",\"title\":\"Nonnegative Matrix and Tensor Factorizations - Applications to Exploratory Multi-way Data Analysis and Blind Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/fddc613a2a208f241b38bc41f62b4fc4db7217c7\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"}],\"doi\":\"10.1016/j.cub.2009.09.005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69ad0088590f63fd921f9e7e7f6ed911375952a0\",\"title\":\"The cocktail party problem\",\"url\":\"https://www.semanticscholar.org/paper/69ad0088590f63fd921f9e7e7f6ed911375952a0\",\"venue\":\"Current Biology\",\"year\":2009},{\"arxivId\":\"1908.11602\",\"authors\":[{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"title\":\"Recursive Visual Sound Separation Using Minus-Plus Net\",\"url\":\"https://www.semanticscholar.org/paper/b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298872\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3de050d1707524512eeab99780df3cbdee09670c\",\"title\":\"DevNet: A Deep Event Network for multimedia event detection and evidence recounting\",\"url\":\"https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1910.11760\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"51333271\",\"name\":\"H. Zhao\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05c846b122dc64b6900c09b9210912615a3febb6\",\"title\":\"Self-Supervised Moving Vehicle Tracking With Stereo Sound\",\"url\":\"https://www.semanticscholar.org/paper/05c846b122dc64b6900c09b9210912615a3febb6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9034311\",\"name\":\"Pritish Chandna\"},{\"authorId\":\"144057160\",\"name\":\"M. Miron\"},{\"authorId\":\"2164118\",\"name\":\"J. Janer\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"}],\"doi\":\"10.1007/978-3-319-53547-0_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fedef8eedef76692d805a6a3380159a95b79b4de\",\"title\":\"Monoaural Audio Source Separation Using Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fedef8eedef76692d805a6a3380159a95b79b4de\",\"venue\":\"LVA/ICA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"3268101\",\"name\":\"Eric J. Humphrey\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"1899151\",\"name\":\"O. Nieto\"},{\"authorId\":\"1702877\",\"name\":\"Dawen Liang\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f\",\"title\":\"MIR_EVAL: A Transparent Implementation of Common MIR Metrics\",\"url\":\"https://www.semanticscholar.org/paper/6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f\",\"venue\":\"ISMIR\",\"year\":2014},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1607.00325\",\"authors\":[{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"3437492\",\"name\":\"Morten Kolb\\u00e6k\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.1109/ICASSP.2017.7952154\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4f62ffbf7c51a5ad01b89c6889c649bf48baac8\",\"title\":\"Permutation invariant training of deep models for speaker-independent multi-talker speech separation\",\"url\":\"https://www.semanticscholar.org/paper/d4f62ffbf7c51a5ad01b89c6889c649bf48baac8\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrzej Cichocki\"},{\"authorId\":null,\"name\":\"Rafal Zdunek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Anh Huy Phan, and Shunichi Amari. Nonnegative matrix and tensor factorizations: applications to exploratory multi-way data analysis and blind source separation\",\"url\":\"\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1712.09382\",\"authors\":[{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1411184751\",\"name\":\"Hayden Schoen\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1109/CVPR.2018.00790\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6d60aaad68fa78c914ee34c26bceab033a88622\",\"title\":\"Audio to Body Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/c6d60aaad68fa78c914ee34c26bceab033a88622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.05358\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"title\":\"Lip Reading Sentences in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.07809\",\"authors\":[{\"authorId\":\"145386542\",\"name\":\"Tomas Simon\"},{\"authorId\":\"7996087\",\"name\":\"Hanbyul Joo\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2017.494\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a85a0c49581665015f4ce760c45d4adb289d58d\",\"title\":\"Hand Keypoint Detection in Single Images Using Multiview Bootstrapping\",\"url\":\"https://www.semanticscholar.org/paper/7a85a0c49581665015f4ce760c45d4adb289d58d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143636342\",\"name\":\"Sarah L. Taylor\"},{\"authorId\":\"2066626\",\"name\":\"T. Kim\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"},{\"authorId\":\"30303590\",\"name\":\"M. Mahler\"},{\"authorId\":\"1988242\",\"name\":\"James Krahe\"},{\"authorId\":\"36969558\",\"name\":\"Anastasio Garcia Rodriguez\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":\"10.1145/3072959.3073699\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc63b9cf84b1fb0b3eca84372919f74a40b7c132\",\"title\":\"A deep learning approach for generalized speech animation\",\"url\":\"https://www.semanticscholar.org/paper/cc63b9cf84b1fb0b3eca84372919f74a40b7c132\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"2658133\",\"name\":\"Imran Saleemi\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TMM.2012.2228476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3118de593eee760242be45ceac0ae77d0831d31\",\"title\":\"Multimodal Analysis for Identification and Segmentation of Moving-Sounding Objects\",\"url\":\"https://www.semanticscholar.org/paper/e3118de593eee760242be45ceac0ae77d0831d31\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48642790\",\"name\":\"S. Dahl\"},{\"authorId\":\"1750247\",\"name\":\"F. Bevilacqua\"},{\"authorId\":\"2535114\",\"name\":\"Roberto Bresin\"},{\"authorId\":\"50745972\",\"name\":\"M. Clayton\"},{\"authorId\":\"3940898\",\"name\":\"Laura Leante\"},{\"authorId\":\"1802126\",\"name\":\"I. Poggi\"},{\"authorId\":\"1691222\",\"name\":\"N. Rasamimanana\"}],\"doi\":\"10.4324/9780203863411\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac71dfe40caf844d00213096bcfa8da10179945\",\"title\":\"Gestures in performance\",\"url\":\"https://www.semanticscholar.org/paper/6ac71dfe40caf844d00213096bcfa8da10179945\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744069\",\"name\":\"Zohar Barzelay\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"}],\"doi\":\"10.1109/CVPR.2007.383344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e309dfbae9d123f85223d398d4a400abee3ef393\",\"title\":\"Harmony in Motion\",\"url\":\"https://www.semanticscholar.org/paper/e309dfbae9d123f85223d398d4a400abee3ef393\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1508.04306\",\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"49865106\",\"name\":\"Z. Chen\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ICASSP.2016.7471631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3332dc72fbe3907e45e8a500c6a1202ad5092c0f\",\"title\":\"Deep clustering: Discriminative embeddings for segmentation and separation\",\"url\":\"https://www.semanticscholar.org/paper/3332dc72fbe3907e45e8a500c6a1202ad5092c0f\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"52090166\",\"name\":\"Gines Hidalgo\"},{\"authorId\":\"145386542\",\"name\":\"Tomas Simon\"},{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/TPAMI.2019.2929257\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30e85b1651b1d2b726e71e2747d09b187bbd045a\",\"title\":\"OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields\",\"url\":\"https://www.semanticscholar.org/paper/30e85b1651b1d2b726e71e2747d09b187bbd045a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113291641\",\"name\":\"R. I. God\\u00f8y\"},{\"authorId\":\"1712585\",\"name\":\"M. Leman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"161a622df5976a3956a454eaf2998cc858f5df7a\",\"title\":\"Musical gestures : sound, movement, and meaning\",\"url\":\"https://www.semanticscholar.org/paper/161a622df5976a3956a454eaf2998cc858f5df7a\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"3468872\",\"name\":\"Antti Herva\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":\"10.1145/3072959.3073658\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95b803d07c37e8349bd7b1318367d8237c76cbc0\",\"title\":\"Audio-driven facial animation by joint end-to-end learning of pose and emotion\",\"url\":\"https://www.semanticscholar.org/paper/95b803d07c37e8349bd7b1318367d8237c76cbc0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01150-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"title\":\"You Said That?: Synthesising Talking Faces from Audio\",\"url\":\"https://www.semanticscholar.org/paper/0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1912.11684\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":\"10.1109/ICRA40945.2020.9197008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a24996f14c194cd125fd69b5af32037d5abee1a\",\"title\":\"Look, Listen, and Act: Towards Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/3a24996f14c194cd125fd69b5af32037d5abee1a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1612.00137\",\"authors\":[{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"8483323\",\"name\":\"S. Xie\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/ICCV.2017.256\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c70c6dafc7276177225f4604cb285db07881aa6f\",\"title\":\"RMPE: Regional Multi-person Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/c70c6dafc7276177225f4604cb285db07881aa6f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"},{\"authorId\":\"1800748\",\"name\":\"M. Covell\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"}],\"doi\":\"10.1145/258734.258880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"title\":\"Video Rewrite: driving visual speech with audio\",\"url\":\"https://www.semanticscholar.org/paper/3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"venue\":\"SIGGRAPH '97\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"},{\"authorId\":\"50351185\",\"name\":\"J. Brown\"}],\"doi\":\"10.1109/ASPAA.2003.1285860\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34343b4ae08f6069d78b02c26d64c17f7c92a906\",\"title\":\"Non-negative matrix factorization for polyphonic music transcription\",\"url\":\"https://www.semanticscholar.org/paper/34343b4ae08f6069d78b02c26d64c17f7c92a906\",\"venue\":\"2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No.03TH8684)\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"1741200\",\"name\":\"J. Movellan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d1bb817691bb0566bc55fde01d12339625aa1c\",\"title\":\"Audio Vision: Using Audio-Visual Synchrony to Locate Sounds\",\"url\":\"https://www.semanticscholar.org/paper/00d1bb817691bb0566bc55fde01d12339625aa1c\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"}],\"doi\":\"10.1109/TASL.2006.885253\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe27cac60301c52397c1ce150abd7706afa007cd\",\"title\":\"Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria\",\"url\":\"https://www.semanticscholar.org/paper/fe27cac60301c52397c1ce150abd7706afa007cd\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73769459\",\"name\":\"Amit Moryossef\"},{\"authorId\":\"51131518\",\"name\":\"Yanai Elazar\"},{\"authorId\":\"79775260\",\"name\":\"Y. Goldberg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"de6ca9b9bf4af748c0986278cfcf492259f96e68\",\"title\":\"At Your Fingertips: Automatic Piano Fingering Detection\",\"url\":\"https://www.semanticscholar.org/paper/de6ca9b9bf4af748c0986278cfcf492259f96e68\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.02587\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"029490920cd736e91d6c57f3cfb850adddcf2725\",\"title\":\"Self-Supervised Generation of Spatial Audio for 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/029490920cd736e91d6c57f3cfb850adddcf2725\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1801.07455\",\"authors\":[{\"authorId\":\"1979911\",\"name\":\"S. Yan\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"title\":\"Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1904.09013\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICASSP.2019.8682467\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"title\":\"Self-supervised Audio-visual Co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1709.07871\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cfa5c97164129ce3630511f639040d28db1d4b7\",\"title\":\"FiLM: Visual Reasoning with a General Conditioning Layer\",\"url\":\"https://www.semanticscholar.org/paper/7cfa5c97164129ce3630511f639040d28db1d4b7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1612.08727\",\"authors\":[{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"8016212\",\"name\":\"Xinzhao Liu\"},{\"authorId\":\"27361710\",\"name\":\"K. Dinesh\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"145621177\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TMM.2018.2856090\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3af5e203368fa2c7959d035493571d181a8682af\",\"title\":\"Creating a Multitrack Classical Music Performance Dataset for Multimodal Music Analysis: Challenges, Insights, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/3af5e203368fa2c7959d035493571d181a8682af\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37016781\",\"name\":\"Supasorn Suwajanakorn\"},{\"authorId\":\"1396612598\",\"name\":\"Steven M. Seitz\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1145/3072959.3073640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"title\":\"Synthesizing Obama\",\"url\":\"https://www.semanticscholar.org/paper/7aa88dafb5d5fd5645c0ada2539e9eaf5b2fe949\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1504.04658\",\"authors\":[{\"authorId\":\"34979897\",\"name\":\"Andrew J. R. Simpson\"},{\"authorId\":\"35581798\",\"name\":\"G. Roma\"},{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"}],\"doi\":\"10.1007/978-3-319-22482-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a54a76f7c2b95bd2514b461253e239f8f1ea427\",\"title\":\"Deep Karaoke: Extracting Vocals from Musical Mixtures Using a Convolutional Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/8a54a76f7c2b95bd2514b461253e239f8f1ea427\",\"venue\":\"LVA/ICA\",\"year\":2015},{\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"title\":\"2.5D Visual Sound\",\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}],\"title\":\"Music Gesture for Visual Sound Separation\",\"topics\":[{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"IBM Research\",\"topicId\":\"265853\",\"url\":\"https://www.semanticscholar.org/topic/265853\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Source separation\",\"topicId\":\"39125\",\"url\":\"https://www.semanticscholar.org/topic/39125\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Minds and Machines\",\"topicId\":\"1003374\",\"url\":\"https://www.semanticscholar.org/topic/1003374\"}],\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"