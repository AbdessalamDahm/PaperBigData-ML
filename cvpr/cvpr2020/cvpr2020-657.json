"{\"abstract\":\"Dense 3D facial motion capture from only monocular in-the-wild pairs of RGB images is a highly challenging problem with numerous applications, ranging from facial expression recognition to facial reenactment. In this work, we propose DeepFaceFlow, a robust, fast, and highly-accurate framework for the dense estimation of 3D non-rigid facial flow between pairs of monocular images. Our DeepFaceFlow framework was trained and tested on two very large-scale facial video datasets, one of them of our own collection and annotation, with the aid of occlusion-aware and 3D-based loss function. We conduct comprehensive experiments probing different aspects of our approach and demonstrating its improved performance against state-of-the-art flow and 3D reconstruction methods. Furthermore, we incorporate our framework in a full-head state-of-the-art facial video synthesis method and demonstrate the ability of our method in better representing and capturing the facial dynamics, resulting in a highly-realistic facial video synthesis. Given registered pairs of images, our framework generates 3D flow maps at 60 fps.\",\"arxivId\":\"2005.07298\",\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\",\"url\":\"https://www.semanticscholar.org/author/46193344\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\",\"url\":\"https://www.semanticscholar.org/author/2931390\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\",\"url\":\"https://www.semanticscholar.org/author/1379747201\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2006.10199\",\"authors\":[{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43c1effcc2bbf90be4b67fbe961beb5c7c08c4af\",\"title\":\"Head2Head++: Deep Facial Attributes Re-Targeting\",\"url\":\"https://www.semanticscholar.org/paper/43c1effcc2bbf90be4b67fbe961beb5c7c08c4af\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":218665717,\"doi\":\"10.1109/cvpr42600.2020.00665\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"54e7234febaf8025168baa1167c0ff3e44a34b30\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47456718\",\"name\":\"J. Booth\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"47122406\",\"name\":\"A. Ponniah\"},{\"authorId\":\"143846306\",\"name\":\"D. Dunaway\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1007/s11263-017-1009-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3d9933c3519caea79f80965fa494371b8aefe63\",\"title\":\"Large Scale 3D Morphable Models\",\"url\":\"https://www.semanticscholar.org/paper/b3d9933c3519caea79f80965fa494371b8aefe63\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"James Booth\"},{\"authorId\":null,\"name\":\"Anastasios Roussos\"},{\"authorId\":null,\"name\":\"Evangelos Ververas\"},{\"authorId\":null,\"name\":\"Epameinondas Antonakos\"},{\"authorId\":null,\"name\":\"Stylianos Ploumpis\"},{\"authorId\":null,\"name\":\"Yannis Panagakis\"},{\"authorId\":null,\"name\":\"Stefanos Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"3d reconstruction of \\u201dinthe-wild\\u201d faces in images and videos\",\"url\":\"\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence,\",\"year\":2018},{\"arxivId\":\"1512.02134\",\"authors\":[{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2016.438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ced31e02234bc3d1092ffb2c7442ffbd51cb309\",\"title\":\"A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/1ced31e02234bc3d1092ffb2c7442ffbd51cb309\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407706\",\"name\":\"Vladislav Golyanik\"},{\"authorId\":\"3178628\",\"name\":\"Aman S. Mathur\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":\"10.5244/C.30.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81f8aba18d4cbf2cb2091d6ec79139eeccdad633\",\"title\":\"NRSfM-Flow: Recovering Non-Rigid Scene Flow from Monocular Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/81f8aba18d4cbf2cb2091d6ec79139eeccdad633\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"31243357\",\"name\":\"Evangelos Ververas\"},{\"authorId\":\"1754270\",\"name\":\"I. Kotsia\"},{\"authorId\":\"46904799\",\"name\":\"Jie Shen\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1007/s11263-018-1134-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e156ece0f070fae28254d8589dc9f8a5a4ac2a08\",\"title\":\"The Menpo Benchmark for Multi-pose 2D and 3D Facial Landmark Localisation and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/e156ece0f070fae28254d8589dc9f8a5a4ac2a08\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145864185\",\"name\":\"Shiyang Cheng\"},{\"authorId\":\"1754270\",\"name\":\"I. Kotsia\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/CVPR.2018.00537\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc249c9be803af3d4a5a6de495e1c85578fce84b\",\"title\":\"4DFAB: A Large Scale 4D Database for Facial Expression Analysis and Biometric Applications\",\"url\":\"https://www.semanticscholar.org/paper/bc249c9be803af3d4a5a6de495e1c85578fce84b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143814637\",\"name\":\"B. Horn\"},{\"authorId\":\"1717435\",\"name\":\"B. Schunck\"}],\"doi\":\"10.1016/0004-3702(81)90024-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cbe9176abf0c98c7abdfd136f53d58620f8acfec\",\"title\":\"Determining Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/cbe9176abf0c98c7abdfd136f53d58620f8acfec\",\"venue\":\"Artif. Intell.\",\"year\":1981},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/s11263-013-0644-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1850a106fad32010e2fae2f3c34d47e3237bb3f4\",\"title\":\"A Quantitative Analysis of Current Practices in Optical Flow Estimation and the Principles Behind Them\",\"url\":\"https://www.semanticscholar.org/paper/1850a106fad32010e2fae2f3c34d47e3237bb3f4\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114875892\",\"name\":\"S. Vedula\"},{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1885955\",\"name\":\"P. Rander\"},{\"authorId\":\"143980462\",\"name\":\"R. Collins\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"}],\"doi\":\"10.1109/TPAMI.2005.63\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f572bfbf7835203bd39af9cfab0bb9e376ff693f\",\"title\":\"Three-dimensional scene flow\",\"url\":\"https://www.semanticscholar.org/paper/f572bfbf7835203bd39af9cfab0bb9e376ff693f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2005},{\"arxivId\":\"1602.01125\",\"authors\":[{\"authorId\":\"39180407\",\"name\":\"A. Bas\"},{\"authorId\":\"145242734\",\"name\":\"W. Smith\"},{\"authorId\":\"1780750\",\"name\":\"Timo Bolkart\"},{\"authorId\":\"1792200\",\"name\":\"Stefanie Wuhrer\"}],\"doi\":\"10.1007/978-3-319-54427-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dccd119d9e348220d14bb2d7cd5296da53aad3ca\",\"title\":\"Fitting a 3D Morphable Model to Edges: A Comparison Between Hard and Soft Correspondences\",\"url\":\"https://www.semanticscholar.org/paper/dccd119d9e348220d14bb2d7cd5296da53aad3ca\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042417\",\"name\":\"Tali Basha\"},{\"authorId\":\"2957934\",\"name\":\"Y. Moses\"},{\"authorId\":\"1723625\",\"name\":\"N. Kiryati\"}],\"doi\":\"10.1007/s11263-012-0542-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d43df24d38e9db87c0c1a51d4552b960f2f8177\",\"title\":\"Multi-view Scene Flow Estimation: A View Centered Variational Approach\",\"url\":\"https://www.semanticscholar.org/paper/6d43df24d38e9db87c0c1a51d4552b960f2f8177\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1711.07837\",\"authors\":[{\"authorId\":\"24362273\",\"name\":\"S. Meister\"},{\"authorId\":\"2470340\",\"name\":\"Junhwa Hur\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43e77b5157b0fa0f365808e26af287c3164e002f\",\"title\":\"UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss\",\"url\":\"https://www.semanticscholar.org/paper/43e77b5157b0fa0f365808e26af287c3164e002f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1774162\",\"name\":\"\\u00c9. M\\u00e9min\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/83.668027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd824a3406cd176edef37888d0e5c74c0774b0c3\",\"title\":\"Dense estimation and object-based segmentation of the optical flow with robust techniques\",\"url\":\"https://www.semanticscholar.org/paper/cd824a3406cd176edef37888d0e5c74c0774b0c3\",\"venue\":\"IEEE Trans. Image Process.\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735269\",\"name\":\"T. Coleman\"},{\"authorId\":\"48513508\",\"name\":\"Y. Li\"}],\"doi\":\"10.1137/S1052623494240456\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89b4a575b65064e39f2360b267a25ef5a3f0c7b4\",\"title\":\"A Reflective Newton Method for Minimizing a Quadratic Function Subject to Bounds on Some of the Variables\",\"url\":\"https://www.semanticscholar.org/paper/89b4a575b65064e39f2360b267a25ef5a3f0c7b4\",\"venue\":\"SIAM J. Optim.\",\"year\":1996},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733000\",\"name\":\"S. Wang\"},{\"authorId\":\"1749881\",\"name\":\"Xukun Shen\"},{\"authorId\":\"46701222\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/ICIP.2018.8451742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e77acf4fa9e32135399ea72bda4790acf1bcba51\",\"title\":\"Dense Optical Flow Variation Based 3D Face Reconstruction from Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/e77acf4fa9e32135399ea72bda4790acf1bcba51\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1704.05519\",\"authors\":[{\"authorId\":\"10678970\",\"name\":\"Joel Janai\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"2443650\",\"name\":\"A. Behl\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1561/0600000079\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"572785b5d6f6fa4b174d79725f82c056b0fb4565\",\"title\":\"Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/572785b5d6f6fa4b174d79725f82c056b0fb4565\",\"venue\":\"Found. Trends Comput. Graph. Vis.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751013\",\"name\":\"R. Garg\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"}],\"doi\":\"10.1109/CVPR.2013.168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"600ae3860cb163510fc918b351219d1786e64031\",\"title\":\"Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/600ae3860cb163510fc918b351219d1786e64031\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.00177\",\"authors\":[{\"authorId\":\"1914886\",\"name\":\"Thiemo Alldieck\"},{\"authorId\":\"2646818\",\"name\":\"Marc Kassubeck\"},{\"authorId\":\"12698154\",\"name\":\"B. Wandt\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"},{\"authorId\":\"1686739\",\"name\":\"M. Magnor\"}],\"doi\":\"10.1007/978-3-319-66709-6_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da45430e38ddd2e985f5c70fbc0a35bbd26b8bc8\",\"title\":\"Optical Flow-Based 3D Human Motion Estimation from Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/da45430e38ddd2e985f5c70fbc0a35bbd26b8bc8\",\"venue\":\"GCPR\",\"year\":2017},{\"arxivId\":\"1908.06316\",\"authors\":[{\"authorId\":\"51306102\",\"name\":\"Fabian Brickwedde\"},{\"authorId\":\"39230600\",\"name\":\"Steffen Abraham\"},{\"authorId\":\"34824636\",\"name\":\"R. Mester\"}],\"doi\":\"10.1109/ICCV.2019.00287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbdb852e0610f4fab1160a29c8ca4381a7c8035c\",\"title\":\"Mono-SF: Multi-View Geometry Meets Single-View Depth for Monocular Scene Flow Estimation of Dynamic Traffic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/cbdb852e0610f4fab1160a29c8ca4381a7c8035c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1807.03464\",\"authors\":[{\"authorId\":\"48787858\",\"name\":\"R. Thakur\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1109/ICARCV.2018.8581172\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58771779f95434fa40dd17293b15405c92a3e1e7\",\"title\":\"SceneEDNet: A Deep Learning Approach for Scene Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/58771779f95434fa40dd17293b15405c92a3e1e7\",\"venue\":\"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)\",\"year\":2018},{\"arxivId\":\"1812.01936\",\"authors\":[{\"authorId\":\"3007274\",\"name\":\"J. Guo\"},{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"4091869\",\"name\":\"Niannan Xue\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40c5cfe274590ad2c11fbe4db1beb02132b6d737\",\"title\":\"Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/40c5cfe274590ad2c11fbe4db1beb02132b6d737\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1902.05978\",\"authors\":[{\"authorId\":\"2151914\",\"name\":\"Baris Gecer\"},{\"authorId\":\"2015036\",\"name\":\"Stylianos Ploumpis\"},{\"authorId\":\"1754270\",\"name\":\"I. Kotsia\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/CVPR.2019.00125\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6220cac2e0fbebea5c28d9e8b7d399eb5c375357\",\"title\":\"GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/6220cac2e0fbebea5c28d9e8b7d399eb5c375357\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31981082\",\"name\":\"C. Vogel\"},{\"authorId\":\"144810819\",\"name\":\"K. Schindler\"},{\"authorId\":\"49863424\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/ICCV.2011.6126381\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fbf16394084bea915af1632f4cc2a34fdb16901\",\"title\":\"3D scene flow estimation with a rigid motion prior\",\"url\":\"https://www.semanticscholar.org/paper/6fbf16394084bea915af1632f4cc2a34fdb16901\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"3706363\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145864185\",\"name\":\"Shiyang Cheng\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/FG.2018.00064\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66490b5869822b31d32af7108eaff193fbdb37b0\",\"title\":\"Cascade Multi-View Hourglass Model for Robust 3D Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/66490b5869822b31d32af7108eaff193fbdb37b0\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ralph Gross\"},{\"authorId\":null,\"name\":\"Iain Matthews\"},{\"authorId\":null,\"name\":\"Jeffrey Cohn\"},{\"authorId\":null,\"name\":\"Takeo Kanade\"},{\"authorId\":null,\"name\":\"Simon Baker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multi-pie. Image and Vision Computing\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting-Chun Wang\"},{\"authorId\":null,\"name\":\"Ming-Yu Liu\"},{\"authorId\":null,\"name\":\"Jun-Yan Zhu\"},{\"authorId\":null,\"name\":\"Guilin Liu\"},{\"authorId\":null,\"name\":\"Andrew Tao\"},{\"authorId\":null,\"name\":\"Jan Kautz\"},{\"authorId\":null,\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Video-tovideo synthesis\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1808.06601,\",\"year\":2018},{\"arxivId\":\"2005.05509\",\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"1692951594\",\"name\":\"Luma Alharbawee\"},{\"authorId\":\"1456139580\",\"name\":\"Giorgos Giannakakis\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8768dbb815443912e477d438dd049041ce593d07\",\"title\":\"Real-time Facial Expression Recognition \\\"In The Wild\\\" by Disentangling 3D Expression from Identity\",\"url\":\"https://www.semanticscholar.org/paper/8768dbb815443912e477d438dd049041ce593d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10954\",\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4a787b7177fec50da643a662a57db64ccc91ffc\",\"title\":\"Head2Head: Video-based Neural Head Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/e4a787b7177fec50da643a662a57db64ccc91ffc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"31243357\",\"name\":\"Evangelos Ververas\"},{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"2814229\",\"name\":\"George Trigeorgis\"}],\"doi\":\"10.1109/ICCVW.2017.16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7492c611b1df6bce895bee6ba33737e7fc7f60a6\",\"title\":\"The 3D Menpo Facial Landmark Tracking Challenge\",\"url\":\"https://www.semanticscholar.org/paper/7492c611b1df6bce895bee6ba33737e7fc7f60a6\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144518778\",\"name\":\"A. Wedel\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1109/ICCV.2009.5459375\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37c59708043e4ebcb1af711e4388c965bda1826\",\"title\":\"Structure- and motion-adaptive regularization for high accuracy optic flow\",\"url\":\"https://www.semanticscholar.org/paper/f37c59708043e4ebcb1af711e4388c965bda1826\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"145981906\",\"name\":\"P. Anandan\"}],\"doi\":\"10.1006/cviu.1996.0006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eee90c038f43370a29b07e46f38dfe6527143a2c\",\"title\":\"The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields\",\"url\":\"https://www.semanticscholar.org/paper/eee90c038f43370a29b07e46f38dfe6527143a2c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":1996},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1709.02371\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"title\":\"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644009656\",\"name\":\"PonsJean-Philippe\"},{\"authorId\":\"1644023061\",\"name\":\"KerivenRenaud\"},{\"authorId\":\"1643885163\",\"name\":\"FaugerasOlivier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3f3606d4c942d52775781b3f753b27d5fa88d9b\",\"title\":\"Multi-View Stereo Reconstruction and Scene Flow Estimation with a Global Image-Based Matching Score\",\"url\":\"https://www.semanticscholar.org/paper/f3f3606d4c942d52775781b3f753b27d5fa88d9b\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"}],\"doi\":\"10.1145/3278471.3278476\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c739631b30546158dbfb5e3e8d2f71f9c3523c8f\",\"title\":\"Combining dense nonrigid structure from motion and 3D morphable models for monocular 4D face reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/c739631b30546158dbfb5e3e8d2f71f9c3523c8f\",\"venue\":\"CVMP '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691654\",\"name\":\"Jean-Philippe Pons\"},{\"authorId\":\"1748053\",\"name\":\"Renaud Keriven\"},{\"authorId\":\"33726225\",\"name\":\"Olivier D. Faugeras\"}],\"doi\":\"10.1007/s11263-006-8671-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db47a9a47b83f2294ca89c90d643829b4a909cc6\",\"title\":\"Multi-View Stereo Reconstruction and Scene Flow Estimation with a Global Image-Based Matching Score\",\"url\":\"https://www.semanticscholar.org/paper/db47a9a47b83f2294ca89c90d643829b4a909cc6\",\"venue\":\"International Journal of Computer Vision\",\"year\":2006},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.07036\",\"authors\":[{\"authorId\":\"33385667\",\"name\":\"Tak-Wai Hui\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPR.2018.00936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"051b3763c2ad4e4271db712b0e9a4cfe298d05db\",\"title\":\"LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/051b3763c2ad4e4271db712b0e9a4cfe298d05db\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jan Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Three - dimensional scene flow 3 d scene flow estimation with a rigid motion prior Dense optical flow variation based 3 d face reconstruction from monocular video\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144518778\",\"name\":\"A. Wedel\"},{\"authorId\":\"25698183\",\"name\":\"C. Rabe\"},{\"authorId\":\"2768242\",\"name\":\"T. Vaudrey\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"145582788\",\"name\":\"Uwe Franke\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"}],\"doi\":\"10.1007/978-3-540-88682-2_56\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d564cec98eff7eb1de2ab35e398bbeda5da6a0c\",\"title\":\"Efficient Dense Scene Flow from Sparse or Dense Stereo Data\",\"url\":\"https://www.semanticscholar.org/paper/5d564cec98eff7eb1de2ab35e398bbeda5da6a0c\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2254686\",\"name\":\"Youding Zhu\"},{\"authorId\":\"35047644\",\"name\":\"K. Fujimura\"}],\"doi\":\"10.1109/IM.2003.1240252\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b915b84475dcf2cd4f04bbf3e761f05ae74d18c6\",\"title\":\"3D head pose estimation with optical flow and depth constraints\",\"url\":\"https://www.semanticscholar.org/paper/b915b84475dcf2cd4f04bbf3e761f05ae74d18c6\",\"venue\":\"Fourth International Conference on 3-D Digital Imaging and Modeling, 2003. 3DIM 2003. Proceedings.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691654\",\"name\":\"Jean-Philippe Pons\"},{\"authorId\":\"1748053\",\"name\":\"R. Keriven\"},{\"authorId\":\"33726225\",\"name\":\"O. Faugeras\"}],\"doi\":\"10.1007/s11263-006-8671-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db47a9a47b83f2294ca89c90d643829b4a909cc6\",\"title\":\"Multi-View Stereo Reconstruction and Scene Flow Estimation with a Global Image-Based Matching Score\",\"url\":\"https://www.semanticscholar.org/paper/db47a9a47b83f2294ca89c90d643829b4a909cc6\",\"venue\":\"International Journal of Computer Vision\",\"year\":2006}],\"title\":\"DeepFaceFlow: In-the-Wild Dense 3D Facial Motion Estimation\",\"topics\":[{\"topic\":\"Motion estimation\",\"topicId\":\"21398\",\"url\":\"https://www.semanticscholar.org/topic/21398\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"3D reconstruction\",\"topicId\":\"63486\",\"url\":\"https://www.semanticscholar.org/topic/63486\"},{\"topic\":\"Facial motion capture\",\"topicId\":\"200345\",\"url\":\"https://www.semanticscholar.org/topic/200345\"}],\"url\":\"https://www.semanticscholar.org/paper/54e7234febaf8025168baa1167c0ff3e44a34b30\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"