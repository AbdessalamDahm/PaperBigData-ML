"{\"abstract\":\"Recently, ensemble models have demonstrated empirical capabilities to alleviate the adversarial vulnerability. In this paper, we exploit first-order interactions within ensembles to formalize a reliable and practical defense. We introduce a scenario of interactions that certifiably improves the robustness according to the size of the ensemble, the diversity of the gradient directions, and the balance of the member's contribution to the robustness. We present a joint gradient phase and magnitude regularization (GPMR) as a vigorous approach to impose the desired scenario of interactions among members of the ensemble. Through extensive experiments, including gradient-based and gradient-free evaluations on several datasets and network architectures, we validate the practical effectiveness of the proposed approach compared to the previous methods. Furthermore, we demonstrate that GPMR is orthogonal to other defense strategies developed for single classifiers and their combination can further improve the robustness of ensembles.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"35477977\",\"name\":\"Ali Dabouei\",\"url\":\"https://www.semanticscholar.org/author/35477977\"},{\"authorId\":\"30319988\",\"name\":\"Sobhan Soleymani\",\"url\":\"https://www.semanticscholar.org/author/30319988\"},{\"authorId\":\"34708406\",\"name\":\"F. Taherkhani\",\"url\":\"https://www.semanticscholar.org/author/34708406\"},{\"authorId\":\"37583869\",\"name\":\"J. Dawson\",\"url\":\"https://www.semanticscholar.org/author/37583869\"},{\"authorId\":\"8147588\",\"name\":\"N. Nasrabadi\",\"url\":\"https://www.semanticscholar.org/author/8147588\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2011.08908\",\"authors\":[{\"authorId\":\"145535348\",\"name\":\"Thai Le\"},{\"authorId\":\"48651988\",\"name\":\"Noseong Park\"},{\"authorId\":\"40086529\",\"name\":\"Dongwon Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6f7f087d2c27d22597e6f584bebae67dc7a8ba6c\",\"title\":\"SIENA: Stochastic Multi-Expert Neural Patcher\",\"url\":\"https://www.semanticscholar.org/paper/6f7f087d2c27d22597e6f584bebae67dc7a8ba6c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.03790\",\"authors\":[{\"authorId\":\"34708406\",\"name\":\"F. Taherkhani\"},{\"authorId\":\"2700951\",\"name\":\"Hadi Kazemi\"},{\"authorId\":\"35477977\",\"name\":\"Ali Dabouei\"},{\"authorId\":\"37583869\",\"name\":\"J. Dawson\"},{\"authorId\":\"9385109\",\"name\":\"N. M. Nasrabadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13629d86f141f6e667722777788a00e4b5d74aaa\",\"title\":\"Matching Distributions via Optimal Transport for Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/13629d86f141f6e667722777788a00e4b5d74aaa\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219964094,\"doi\":\"10.1109/CVPR42600.2020.00120\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"e673cb0efb480ac6ef573c751e46f0a299a4145e\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951595\",\"name\":\"Zhihao Zheng\"},{\"authorId\":\"145595134\",\"name\":\"P. Hong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d29c2504c2c95909922d1955210fc656a47a75b\",\"title\":\"Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d29c2504c2c95909922d1955210fc656a47a75b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1704.01155\",\"authors\":[{\"authorId\":\"50231973\",\"name\":\"Weilin Xu\"},{\"authorId\":\"145685504\",\"name\":\"David Evans\"},{\"authorId\":\"1791105\",\"name\":\"Y. Qi\"}],\"doi\":\"10.14722/ndss.2018.23198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"title\":\"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":\"1802.04034\",\"authors\":[{\"authorId\":\"37708360\",\"name\":\"Yusuke Tsuzuku\"},{\"authorId\":\"73355331\",\"name\":\"I. Sato\"},{\"authorId\":\"67154907\",\"name\":\"Masashi Sugiyama\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0bd8c29a206c46dccca63c010a95734018c98d2e\",\"title\":\"Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bd8c29a206c46dccca63c010a95734018c98d2e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"},{\"authorId\":\"1715959\",\"name\":\"Stefano Soatto\"}],\"doi\":\"10.1109/CVPR.2018.00396\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5b4a134836f376fc368fb8cdb194c8ca2a8828e\",\"title\":\"Empirical Study of the Topology and Geometry of Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/e5b4a134836f376fc368fb8cdb194c8ca2a8828e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1011.1839\",\"authors\":[{\"authorId\":\"3092064\",\"name\":\"X. V. Doan\"},{\"authorId\":\"1692336\",\"name\":\"S. Vavasis\"}],\"doi\":\"10.1137/100814251\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fa661f15c90fcad8562d1dfb191862a7c8c6569\",\"title\":\"Finding Approximately Rank-One Submatrices with the Nuclear Norm and \\ud4c11-Norm\",\"url\":\"https://www.semanticscholar.org/paper/7fa661f15c90fcad8562d1dfb191862a7c8c6569\",\"venue\":\"SIAM J. Optim.\",\"year\":2013},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1712.07107\",\"authors\":[{\"authorId\":\"152162529\",\"name\":\"Xiaoyong Yuan\"},{\"authorId\":\"50462511\",\"name\":\"Pan He\"},{\"authorId\":\"22317545\",\"name\":\"Qile Zhu\"},{\"authorId\":\"47058258\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2018.2886017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03a507a0876c7e1a26608358b1a9dd39f1eb08e0\",\"title\":\"Adversarial Examples: Attacks and Defenses for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/03a507a0876c7e1a26608358b1a9dd39f1eb08e0\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1704.08847\",\"authors\":[{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"title\":\"Parseval Networks: Improving Robustness to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Samy Bengio\"},{\"authorId\":null,\"name\":\"Alexey Kurakin\"},{\"authorId\":null,\"name\":\"Ian Goodfellow\"},{\"authorId\":null,\"name\":\"Yinpeng Dong\"},{\"authorId\":null,\"name\":\"Fangzhou Liao\"},{\"authorId\":null,\"name\":\"Ming Liang\"},{\"authorId\":null,\"name\":\"Tianyu Pang\"},{\"authorId\":null,\"name\":\"Jun Zhu\"},{\"authorId\":null,\"name\":\"Xiaolin Hu\"},{\"authorId\":null,\"name\":\"Cihang Xie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"agenet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"Advances in neural information processing systems\",\"year\":2012},{\"arxivId\":\"1804.00097\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"145656562\",\"name\":\"M. Liang\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39421868\",\"name\":\"Sangxia Huang\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"40119836\",\"name\":\"Y. Zhao\"},{\"authorId\":\"46758154\",\"name\":\"Zhonglin Han\"},{\"authorId\":\"19262286\",\"name\":\"J. Long\"},{\"authorId\":\"41021078\",\"name\":\"Yerkebulan Berdibekov\"},{\"authorId\":\"2859858\",\"name\":\"Takuya Akiba\"},{\"authorId\":\"3117618\",\"name\":\"Seiya Tokui\"},{\"authorId\":\"153225382\",\"name\":\"M. Abe\"}],\"doi\":\"10.1007/978-3-319-94042-7_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca5642f522cd2cd44948c7e9f337c91e5f26fdcf\",\"title\":\"Adversarial Attacks and Defences Competition\",\"url\":\"https://www.semanticscholar.org/paper/ca5642f522cd2cd44948c7e9f337c91e5f26fdcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.08999\",\"authors\":[{\"authorId\":\"35477977\",\"name\":\"Ali Dabouei\"},{\"authorId\":\"30319988\",\"name\":\"Sobhan Soleymani\"},{\"authorId\":\"48870901\",\"name\":\"J. Dawson\"},{\"authorId\":\"8147588\",\"name\":\"N. Nasrabadi\"}],\"doi\":\"10.1109/WACV.2019.00215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23b23594224e4372fd7506bbe626e7ca1358692e\",\"title\":\"Fast Geometrically-Perturbed Adversarial Faces\",\"url\":\"https://www.semanticscholar.org/paper/23b23594224e4372fd7506bbe626e7ca1358692e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1901.10513\",\"authors\":[{\"authorId\":\"46516638\",\"name\":\"Nic Ford\"},{\"authorId\":\"2058362\",\"name\":\"J. Gilmer\"},{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"8132903\",\"name\":\"E. Cubuk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fef3f5bac9a7b859f0c113c1689596a1ab80cfa9\",\"title\":\"Adversarial Examples Are a Natural Consequence of Test Error in Noise\",\"url\":\"https://www.semanticscholar.org/paper/fef3f5bac9a7b859f0c113c1689596a1ab80cfa9\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1901.09981\",\"authors\":[{\"authorId\":\"51110538\",\"name\":\"S. Kariyappa\"},{\"authorId\":\"143904156\",\"name\":\"Moinuddin K. Qureshi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4473a41c9f7b4095599bec14ea0a88e7041e737\",\"title\":\"Improving Adversarial Robustness of Ensembles with Diversity Training\",\"url\":\"https://www.semanticscholar.org/paper/d4473a41c9f7b4095599bec14ea0a88e7041e737\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1711.09404\",\"authors\":[{\"authorId\":\"50683297\",\"name\":\"A. Ross\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"title\":\"Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients\",\"url\":\"https://www.semanticscholar.org/paper/ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1511.04508\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"37785191\",\"name\":\"Xi Wu\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/SP.2016.41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"title\":\"Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"venue\":\"2016 IEEE Symposium on Security and Privacy (SP)\",\"year\":2016},{\"arxivId\":\"1705.09064\",\"authors\":[{\"authorId\":\"24553949\",\"name\":\"Dongyu Meng\"},{\"authorId\":null,\"name\":\"Hao Chen\"}],\"doi\":\"10.1145/3133956.3134057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63a010c69f00e65c946a68b546bbd42cbed03564\",\"title\":\"MagNet: A Two-Pronged Defense against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/63a010c69f00e65c946a68b546bbd42cbed03564\",\"venue\":\"CCS\",\"year\":2017},{\"arxivId\":\"1705.08475\",\"authors\":[{\"authorId\":\"143610806\",\"name\":\"M. Hein\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"title\":\"Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":\"1910.03624\",\"authors\":[{\"authorId\":\"35477977\",\"name\":\"Ali Dabouei\"},{\"authorId\":\"30319988\",\"name\":\"Sobhan Soleymani\"},{\"authorId\":\"34708406\",\"name\":\"F. Taherkhani\"},{\"authorId\":\"37583869\",\"name\":\"J. Dawson\"},{\"authorId\":\"9385109\",\"name\":\"N. M. Nasrabadi\"}],\"doi\":\"10.1109/WACV45572.2020.9093429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23eba72325bd8a2568a373867f6063c9f27c3ef4\",\"title\":\"SmoothFool: An Efficient Framework for Computing Smooth Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/23eba72325bd8a2568a373867f6063c9f27c3ef4\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1901.08846\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144968846\",\"name\":\"Kun Xu\"},{\"authorId\":\"144369497\",\"name\":\"Chao Du\"},{\"authorId\":\"144354006\",\"name\":\"N. Chen\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"676e40050453ddeb1387f8314478c0ac3681a8c6\",\"title\":\"Improving Adversarial Robustness via Promoting Ensemble Diversity\",\"url\":\"https://www.semanticscholar.org/paper/676e40050453ddeb1387f8314478c0ac3681a8c6\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1702.06856\",\"authors\":[{\"authorId\":\"9204759\",\"name\":\"Mahdieh Abbasi\"},{\"authorId\":\"1712120\",\"name\":\"C. Gagn\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d9ff72fdf59a8dd791fc29db901be20de50ed6be\",\"title\":\"Robustness to Adversarial Examples through an Ensemble of Specialists\",\"url\":\"https://www.semanticscholar.org/paper/d9ff72fdf59a8dd791fc29db901be20de50ed6be\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1610.08401\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"145602557\",\"name\":\"Omar Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2017.17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16aa01ca0834a924c25faad5d8bfef3fd1acfcfe\",\"title\":\"Universal Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/16aa01ca0834a924c25faad5d8bfef3fd1acfcfe\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.00853\",\"authors\":[{\"authorId\":\"2533850\",\"name\":\"G. Dziugaite\"},{\"authorId\":\"1744700\",\"name\":\"Zoubin Ghahramani\"},{\"authorId\":\"39331522\",\"name\":\"D. Roy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c00f744f103a528f5b45bf0482f54b5e6a9f7740\",\"title\":\"A study of the effect of JPG compression on adversarial images\",\"url\":\"https://www.semanticscholar.org/paper/c00f744f103a528f5b45bf0482f54b5e6a9f7740\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Olvi L Mangasarian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Nonlinear programming. SIAM\",\"url\":\"\",\"venue\":\"\",\"year\":1994},{\"arxivId\":\"1801.07455\",\"authors\":[{\"authorId\":\"1979911\",\"name\":\"S. Yan\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"title\":\"Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1902.02918\",\"authors\":[{\"authorId\":\"39951470\",\"name\":\"Jeremy M. Cohen\"},{\"authorId\":\"49686853\",\"name\":\"Elan Rosenfeld\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed\",\"title\":\"Certified Adversarial Robustness via Randomized Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/MSP.2017.2740965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f1dc314680ab0e2b780c093546395b499bb2b67\",\"title\":\"The Robustness of Deep Networks: A Geometrical Perspective\",\"url\":\"https://www.semanticscholar.org/paper/8f1dc314680ab0e2b780c093546395b499bb2b67\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1709.04114\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"160a03c2890f3ef5436c25ef9b1758faa13807a0\",\"title\":\"EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/160a03c2890f3ef5436c25ef9b1758faa13807a0\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1707.07397\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"143883029\",\"name\":\"Kevin Kwok\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"title\":\"Synthesizing Robust Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747026\",\"name\":\"O. Mangasarian\"}],\"doi\":\"10.1016/S0167-6377(98)00049-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ac1fddab4caf22d1ce116d0712592dab8f4fb96\",\"title\":\"Arbitrary-norm separating plane\",\"url\":\"https://www.semanticscholar.org/paper/3ac1fddab4caf22d1ce116d0712592dab8f4fb96\",\"venue\":\"Oper. Res. Lett.\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1707.05572\",\"authors\":[{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"39957046\",\"name\":\"U. Garg\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.5244/C.31.30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21f360cce06ffdb3e7a8a56f7499cc79ff86405a\",\"title\":\"Fast Feature Fool: A data independent approach to universal adversarial perturbations\",\"url\":\"https://www.semanticscholar.org/paper/21f360cce06ffdb3e7a8a56f7499cc79ff86405a\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1712.04006\",\"authors\":[{\"authorId\":\"35311412\",\"name\":\"Alexander Bagnall\"},{\"authorId\":\"3139133\",\"name\":\"Razvan C. Bunescu\"},{\"authorId\":\"145658680\",\"name\":\"G. Stewart\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ac9d889ec6a58e0fa2bc703b004d110bb36c2d6\",\"title\":\"Training Ensembles to Detect Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/1ac9d889ec6a58e0fa2bc703b004d110bb36c2d6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.00404\",\"authors\":[{\"authorId\":\"3451543\",\"name\":\"Z. Yan\"},{\"authorId\":\"2527106\",\"name\":\"Yiwen Guo\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee95231783167baa4785a642e8ef563a572c5d63\",\"title\":\"Deep Defense: Training DNNs with Improved Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/ee95231783167baa4785a642e8ef563a572c5d63\",\"venue\":\"NeurIPS\",\"year\":2018}],\"title\":\"Exploiting Joint Robustness to Adversarial Perturbations\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/e673cb0efb480ac6ef573c751e46f0a299a4145e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"