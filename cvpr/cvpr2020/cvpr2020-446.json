"{\"abstract\":\"What jumps out in a single glance of an image is different than what you might notice after closer inspection. Yet conventional models of visual saliency produce predictions at an arbitrary, fixed viewing duration, offering a limited view of the rich interactions between image content and gaze location. In this paper we propose to capture gaze as a series of snapshots, by generating population-level saliency heatmaps for multiple viewing durations. We collect the CodeCharts1K dataset, which contains multiple distinct heatmaps per image corresponding to 0.5, 3, and 5 seconds of free-viewing. We develop an LSTM-based model of saliency that simultaneously trains on data from multiple viewing durations. Our Multi-Duration Saliency Excited Model (MD-SEM) achieves competitive performance on the LSUN 2017 Challenge with 57% fewer parameters than comparable architectures. It is the first model that produces heatmaps at multiple viewing durations, enabling applications where multi-duration saliency can be used to prioritize visual content to keep, transmit, and render.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\",\"url\":\"https://www.semanticscholar.org/author/1482544048\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\",\"url\":\"https://www.semanticscholar.org/author/117232498\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\",\"url\":\"https://www.semanticscholar.org/author/1482544051\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\",\"url\":\"https://www.semanticscholar.org/author/2204049\"},{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\",\"url\":\"https://www.semanticscholar.org/author/51150125\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\",\"url\":\"https://www.semanticscholar.org/author/143868587\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\",\"url\":\"https://www.semanticscholar.org/author/3326347\"},{\"authorId\":\"1618896088\",\"name\":\"Hong Kong\",\"url\":\"https://www.semanticscholar.org/author/1618896088\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2008.02912\",\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"24026083\",\"name\":\"Vincent Casser\"},{\"authorId\":\"1682200\",\"name\":\"Amish Kumar Bedi\"},{\"authorId\":\"1411051422\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1145/3379337.3415825\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7693331d4536bec5f38b2338936439cd821b5b0\",\"title\":\"Predicting Visual Importance Across Graphic Design Types\",\"url\":\"https://www.semanticscholar.org/paper/e7693331d4536bec5f38b2338936439cd821b5b0\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":\"2008.05413\",\"authors\":[{\"authorId\":\"51013428\",\"name\":\"Youssef A. Mejjati\"},{\"authorId\":\"1872039960\",\"name\":\"Celso F. Gomez\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-3-030-58592-1_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e03ef52b0f9a0a0742c692e0ecdf04ea609314b3\",\"title\":\"Look here! A parametric learning based approach to redirect visual attention\",\"url\":\"https://www.semanticscholar.org/paper/e03ef52b0f9a0a0742c692e0ecdf04ea609314b3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.09688\",\"authors\":[{\"authorId\":\"31742607\",\"name\":\"X. Wang\"},{\"authorId\":\"1666579341\",\"name\":\"Zoya Bylinskii\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"35072071\",\"name\":\"R. Pepperell\"}],\"doi\":\"10.1145/3418054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8098ca73fac60a07776a8daa74af9b88c1fd5139\",\"title\":\"Toward Quantifying Ambiguities in Artistic Images\",\"url\":\"https://www.semanticscholar.org/paper/8098ca73fac60a07776a8daa74af9b88c1fd5139\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219962823,\"doi\":\"10.1109/cvpr42600.2020.00453\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"cffc481c86d46ca812eff85030f812588bb20b80\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1167/11.4.14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66bb08b37ac9d4398b59e89570c0602d69ab3cc3\",\"title\":\"Fixations on low-resolution images.\",\"url\":\"https://www.semanticscholar.org/paper/66bb08b37ac9d4398b59e89570c0602d69ab3cc3\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"},{\"authorId\":\"145344139\",\"name\":\"Enhua Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2913372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df67d46e78aae0d2fccfb6212d101a342259c01b\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/df67d46e78aae0d2fccfb6212d101a342259c01b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1606.00915\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/TPAMI.2017.2699184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cab372bc3824780cce20d9dd1c22d4df39ed081a\",\"title\":\"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\",\"url\":\"https://www.semanticscholar.org/paper/cab372bc3824780cce20d9dd1c22d4df39ed081a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69436797\",\"name\":\"G. Buswell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15109e586d9724dff1e016e2228d1ffb23b243c2\",\"title\":\"How People Look At Pictures: A Study Of The Psychology Of Perception In Art\",\"url\":\"https://www.semanticscholar.org/paper/15109e586d9724dff1e016e2228d1ffb23b243c2\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.03716\",\"authors\":[{\"authorId\":\"3078154\",\"name\":\"H. Caesar\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/CVPR.2018.00132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0095b9f73c000f2609fc81ffb7769df7cd77bda1\",\"title\":\"COCO-Stuff: Thing and Stuff Classes in Context\",\"url\":\"https://www.semanticscholar.org/paper/0095b9f73c000f2609fc81ffb7769df7cd77bda1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1702.05150\",\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/3131275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc2e0b445dc1825c634768517de557ba4bf22e81\",\"title\":\"BubbleView\",\"url\":\"https://www.semanticscholar.org/paper/fc2e0b445dc1825c634768517de557ba4bf22e81\",\"venue\":\"ACM Trans. Comput. Hum. Interact.\",\"year\":2017},{\"arxivId\":\"1802.02611\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":\"10.1007/978-3-030-01234-2_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"title\":\"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1204.3367\",\"authors\":[{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c07b342e05ebb39c43fed7c5f23da62652d8060b\",\"title\":\"Crowdsourcing Gaze Data Collection\",\"url\":\"https://www.semanticscholar.org/paper/c07b342e05ebb39c43fed7c5f23da62652d8060b\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2262729\",\"name\":\"M. Posner\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"9aeb84ab5af22a63e1881aed2ff21e745100349c\",\"title\":\"Components of visual orienting\",\"url\":\"https://www.semanticscholar.org/paper/9aeb84ab5af22a63e1881aed2ff21e745100349c\",\"venue\":\"\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807962\",\"name\":\"F. Tsalakanidou\"},{\"authorId\":\"1744180\",\"name\":\"S. Malassiotis\"},{\"authorId\":\"145677195\",\"name\":\"M. Strintzis\"}],\"doi\":\"10.1007/978-0-387-78414-4_319\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1da588866260caa9255ac0d02ace18696b6b8b3f\",\"title\":\"Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1da588866260caa9255ac0d02ace18696b6b8b3f\",\"venue\":\"Encyclopedia of Multimedia\",\"year\":2008},{\"arxivId\":\"1701.01480\",\"authors\":[{\"authorId\":\"2855457\",\"name\":\"Y. Chen\"},{\"authorId\":\"1956472\",\"name\":\"Tzu-Wei Huang\"},{\"authorId\":\"50734056\",\"name\":\"Kai-Han Chang\"},{\"authorId\":\"46269379\",\"name\":\"Yu-Chen Tsai\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1733344\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2017.32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a841c23e6964882ca4a9d8362a95a5ae5c4de70\",\"title\":\"Quantitative Analysis of Automatic Image Cropping Algorithms: A Dataset and Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/9a841c23e6964882ca4a9d8362a95a5ae5c4de70\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034445\",\"name\":\"Alexandra Papoutsaki\"},{\"authorId\":\"3430745\",\"name\":\"Patsorn Sangkloy\"},{\"authorId\":\"38560689\",\"name\":\"James Laskey\"},{\"authorId\":\"2277777\",\"name\":\"N. Daskalova\"},{\"authorId\":\"145522949\",\"name\":\"Jeff Huang\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"73fc8e9b1faf45855cceee197f094ca3c05afe1c\",\"title\":\"WebGazer: Scalable Webcam Eye Tracking Using User Interactions\",\"url\":\"https://www.semanticscholar.org/paper/73fc8e9b1faf45855cceee197f094ca3c05afe1c\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1708.02660\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"1411051436\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"145899760\",\"name\":\"Sami Alsheikh\"},{\"authorId\":\"7232330\",\"name\":\"Spandan Madan\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"}],\"doi\":\"10.1145/3126594.3126653\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"title\":\"Learning Visual Importance for Graphic Designs and Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"venue\":\"UIST\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-319-10584-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"title\":\"Saliency in Crowd\",\"url\":\"https://www.semanticscholar.org/paper/2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143959228\",\"name\":\"H. Bouma\"},{\"authorId\":\"69558831\",\"name\":\"D. G. Bouwhuis\"}],\"doi\":\"10.2307/414713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"867990fbddada1fadd0bc1d51a710209c7dd3746\",\"title\":\"Attention and performance X : control of language processes\",\"url\":\"https://www.semanticscholar.org/paper/867990fbddada1fadd0bc1d51a710209c7dd3746\",\"venue\":\"\",\"year\":1984},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2001.04461\",\"authors\":[{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"144508258\",\"name\":\"B. McNamara\"},{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"7638730\",\"name\":\"Matthew Tancik\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1145/3313831.3376799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf10a7687378ce02dfdef60202bf86f6b4b88c46\",\"title\":\"TurkEyes: A Web-Based Toolbox for Crowdsourcing Attention Data\",\"url\":\"https://www.semanticscholar.org/paper/bf10a7687378ce02dfdef60202bf86f6b4b88c46\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":\"1612.04811\",\"authors\":[{\"authorId\":\"145139739\",\"name\":\"S. H. Esmaeili\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2017.445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"191731310cb1dea523c2bbfc30e2edadfe5f0fed\",\"title\":\"Fast-At: Fast Automatic Thumbnail Generation Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191731310cb1dea523c2bbfc30e2edadfe5f0fed\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"50562082\",\"name\":\"J. Zhang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"}],\"doi\":\"10.1109/CVPR.2018.00570\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b20dc4906fc021aaf8353df98f8828d99f951c3c\",\"title\":\"Good View Hunting: Learning Photo Composition from Dense View Pairs\",\"url\":\"https://www.semanticscholar.org/paper/b20dc4906fc021aaf8353df98f8828d99f951c3c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2273409\",\"name\":\"S. Park\"},{\"authorId\":\"4072388\",\"name\":\"Wonsik Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1007/978-3-642-33712-3_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d6e3b42ca9f8b67fd5661c1bb48be353f167268\",\"title\":\"Abnormal Object Detection by Canonical Scene-Based Contextual Model\",\"url\":\"https://www.semanticscholar.org/paper/8d6e3b42ca9f8b67fd5661c1bb48be353f167268\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"2195129\",\"name\":\"X. Jiang\"},{\"authorId\":\"120643531\",\"name\":\"A. Khosla\"},{\"authorId\":\"32157394\",\"name\":\"A. L. Lin\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2011.6126386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e15dc51de6da2bc5cabbb733cf2adf5a2c1f72c\",\"title\":\"Human action recognition by learning bases of action attributes and parts\",\"url\":\"https://www.semanticscholar.org/paper/8e15dc51de6da2bc5cabbb733cf2adf5a2c1f72c\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3017358\",\"name\":\"Y. Wang\"},{\"authorId\":\"30820560\",\"name\":\"B. Wang\"},{\"authorId\":\"4417713\",\"name\":\"Xiaofeng Wu\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s10339-016-0781-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b52c789adfad9123dbcf571053a1d71c3beb5d\",\"title\":\"Scanpath estimation based on foveated image saliency\",\"url\":\"https://www.semanticscholar.org/paper/30b52c789adfad9123dbcf571053a1d71c3beb5d\",\"venue\":\"Cognitive Processing\",\"year\":2016},{\"arxivId\":\"1511.00561\",\"authors\":[{\"authorId\":\"2442177\",\"name\":\"Vijay Badrinarayanan\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":\"10.1109/TPAMI.2016.2644615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0c065cd43aa7280e766b5dcbcc7e26abce59330\",\"title\":\"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b0c065cd43aa7280e766b5dcbcc7e26abce59330\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38497468\",\"name\":\"M. Cerf\"},{\"authorId\":\"2356306\",\"name\":\"E. P. Frady\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/9.12.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14d146b099b12af9b6d7c13342d9ca9db9984275\",\"title\":\"Faces and text attract gaze independent of the task: Experimental data and computer model.\",\"url\":\"https://www.semanticscholar.org/paper/14d146b099b12af9b6d7c13342d9ca9db9984275\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2553201\",\"name\":\"Wilma A. Bainbridge\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1037/a0033872\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b2dd5c61b23ead5ae5508bb8ce808b5ea266730\",\"title\":\"The intrinsic memorability of face photographs.\",\"url\":\"https://www.semanticscholar.org/paper/8b2dd5c61b23ead5ae5508bb8ce808b5ea266730\",\"venue\":\"Journal of experimental psychology. General\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1038/35058500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"320b36777d57e772d88d278ceeccd1f5e746304c\",\"title\":\"Computational modelling of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/320b36777d57e772d88d278ceeccd1f5e746304c\",\"venue\":\"Nature Reviews Neuroscience\",\"year\":2001},{\"arxivId\":\"1505.03581\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"519feb1f3c23baea6960dfa204521f96a74b82bb\",\"title\":\"CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research\",\"url\":\"https://www.semanticscholar.org/paper/519feb1f3c23baea6960dfa204521f96a74b82bb\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"40466012\",\"name\":\"M. Land\"},{\"authorId\":\"153332539\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1167/11.5.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ad8fb4a8af5e4a22b6bd40df055f8a3e0ec69dd\",\"title\":\"Eye guidance in natural vision: reinterpreting salience.\",\"url\":\"https://www.semanticscholar.org/paper/7ad8fb4a8af5e4a22b6bd40df055f8a3e0ec69dd\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"41211511\",\"name\":\"A. Raju\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/ICCV.2015.275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e89a45cb30f3e488fa14f74cc8ee7a209199638\",\"title\":\"Understanding and Predicting Image Memorability at a Large Scale\",\"url\":\"https://www.semanticscholar.org/paper/0e89a45cb30f3e488fa14f74cc8ee7a209199638\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"2767471\",\"name\":\"Gaocheng Bai\"},{\"authorId\":\"7795111\",\"name\":\"Shaoheng Liang\"},{\"authorId\":\"2043328\",\"name\":\"Zhengqin Li\"}],\"doi\":\"10.1109/CVPR.2016.61\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ca06a9c5e80bc0d4011f0d6f6ccc1a5ee746844\",\"title\":\"Automatic Image Cropping: A Computational Complexity Study\",\"url\":\"https://www.semanticscholar.org/paper/1ca06a9c5e80bc0d4011f0d6f6ccc1a5ee746844\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1794917\",\"name\":\"M. J. Choi\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1701607\",\"name\":\"A. Willsky\"}],\"doi\":\"10.1016/j.patrec.2011.12.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28aa465c3af7e5ccf1b10ae9cf76e83aab3ee34f\",\"title\":\"Context models and out-of-context objects\",\"url\":\"https://www.semanticscholar.org/paper/28aa465c3af7e5ccf1b10ae9cf76e83aab3ee34f\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1731790\",\"name\":\"T. Baccino\"}],\"doi\":\"10.3758/s13428-012-0226-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"title\":\"Methods for comparing scanpaths and saliency maps: strengths and weaknesses\",\"url\":\"https://www.semanticscholar.org/paper/a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"venue\":\"Behavior research methods\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Holger Caesar\"},{\"authorId\":null,\"name\":\"Jasper Uijlings\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Cocostuff: Thing and stuff classes in context. In Computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"IEEE conference on\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rachel England\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Twitter uses smart cropping to make image previews more interesting\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rachel England\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Twitter uses smart cropping to make image previews more interesting. https//engadget.com/2018/01/25/ twitter-uses-smart-cropping-to-make-image-previews-more\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2018.00785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"title\":\"Emotional Attention: A Study of Image Sentiment and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4314925\",\"name\":\"A. Samuel\"},{\"authorId\":\"50144662\",\"name\":\"D. Kat\"}],\"doi\":\"10.3758/BF03196550\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7626ab85168f3c82a453981b23c0832116f4bb00\",\"title\":\"Inhibition of return: A graphical meta-analysis of its time course and an empirical test of its temporal and spatial properties\",\"url\":\"https://www.semanticscholar.org/paper/7626ab85168f3c82a453981b23c0832116f4bb00\",\"venue\":\"Psychonomic bulletin & review\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144253743\",\"name\":\"Rui Han\"},{\"authorId\":\"2190637\",\"name\":\"Shuangjiu Xiao\"}],\"doi\":\"10.1145/3191442.3191463\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9632b544615197e083d6936cec3187564c7cc730\",\"title\":\"Human Visual Scanpath Prediction Based on RGB-D Saliency\",\"url\":\"https://www.semanticscholar.org/paper/9632b544615197e083d6936cec3187564c7cc730\",\"venue\":\"ICIGP 2018\",\"year\":2018},{\"arxivId\":\"1805.01047\",\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":\"10.1016/j.imavis.2020.103887\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"title\":\"EML-NET: An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"1809.00567\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1007/978-3-030-11021-5_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"title\":\"PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1610.02357\",\"authors\":[{\"authorId\":\"47924294\",\"name\":\"F. Chollet\"}],\"doi\":\"10.1109/CVPR.2017.195\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b6ec746d309b165f9f9def873a2375b6fb40f3d\",\"title\":\"Xception: Deep Learning with Depthwise Separable Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/5b6ec746d309b165f9f9def873a2375b6fb40f3d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.05814\",\"authors\":[{\"authorId\":\"34987921\",\"name\":\"Kyle Krafka\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"1712418\",\"name\":\"Petr Kellnhofer\"},{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"3422895\",\"name\":\"S. Bhandarkar\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.239\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0695751eb18cd138d7d9441378739882a8afc919\",\"title\":\"Eye Tracking for Everyone\",\"url\":\"https://www.semanticscholar.org/paper/0695751eb18cd138d7d9441378739882a8afc919\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40092548\",\"name\":\"Thuyen Ngo\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/ICIP.2017.8296920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67dd2d536023814f4b29023436a0f34b6ce1850d\",\"title\":\"Saccade gaze prediction using a recurrent neural network\",\"url\":\"https://www.semanticscholar.org/paper/67dd2d536023814f4b29023436a0f34b6ce1850d\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Piotr Doll\\u00e1r, and Ross Girshick. Mask r-cnn\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE international conference on computer vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurent Itti\"},{\"authorId\":null,\"name\":\"Christof Koch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Computational modeling of visual attention\",\"url\":\"\",\"venue\":\"Nature reviews. Neuroscience\",\"year\":null}],\"title\":\"How Much Time Do You Have? Modeling Multi-Duration Saliency\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/cffc481c86d46ca812eff85030f812588bb20b80\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"