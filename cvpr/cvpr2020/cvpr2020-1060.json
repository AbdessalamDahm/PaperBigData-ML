"{\"abstract\":\"In this paper, we consider a novel task, Spatio-Temporal Video Grounding for Multi-Form Sentences (STVG). Given an untrimmed video and a declarative/interrogative sentence depicting an object, STVG aims to localize the spatio-temporal tube of the queried object. STVG has two challenging settings: (1) We need to localize spatio-temporal object tubes from untrimmed videos, where the object may only exist in a very small segment of the video; (2) We deal with multi-form sentences, including the declarative sentences with explicit objects and interrogative sentences with unknown objects. Existing methods cannot tackle the STVG task due to the ineffective tube pre-generation and the lack of object relationship modeling. Thus, we then propose a novel Spatio-Temporal Graph Reasoning Network (STGRN) for this task. First, we build a spatio-temporal region graph to capture the region relationships with temporal object dynamics, which involves the implicit and explicit spatial subgraphs in each frame and the temporal dynamic subgraph across frames. We then incorporate textual clues into the graph and develop the multi-step cross-modal graph reasoning. Next, we introduce a spatio-temporal localizer with a dynamic selection method to directly retrieve the spatio-temporal tubes without tube pre-generation. Moreover, we contribute a large-scale video grounding dataset VidSTG based on video relation dataset VidOR. The extensive experiments demonstrate the effectiveness of our method.\",\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\",\"url\":\"https://www.semanticscholar.org/author/1742291\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\",\"url\":\"https://www.semanticscholar.org/author/47122664\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\",\"url\":\"https://www.semanticscholar.org/author/90148415\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\",\"url\":\"https://www.semanticscholar.org/author/50621207\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\",\"url\":\"https://www.semanticscholar.org/author/46936306\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\",\"url\":\"https://www.semanticscholar.org/author/2671321\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1912.06316\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"37557835\",\"name\":\"T. Kumar\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2020.3038720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e88bca2232e2c1d9ce7258aaed84bc89a799ee\",\"title\":\"Grounding-Tracking-Integration\",\"url\":\"https://www.semanticscholar.org/paper/c3e88bca2232e2c1d9ce7258aaed84bc89a799ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.08257\",\"authors\":[{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":\"10.1145/3394171.3413967\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02e5188e19523140b82d05f00bee10933ccc3b50\",\"title\":\"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/02e5188e19523140b82d05f00bee10933ccc3b50\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.06260\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"title\":\"DORi: Discovering Object Relationship for Moment Localization of a Natural-Language Query in Video\",\"url\":\"https://www.semanticscholar.org/paper/a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.06941\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"145078771\",\"name\":\"J. Yuan\"}],\"doi\":\"10.24963/ijcai.2020/149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"title\":\"Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2007.08814\",\"authors\":[{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"72347323\",\"name\":\"X. Yang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-030-58539-6_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13ee363f71e07112210ac2ff27d46625f6f8edab\",\"title\":\"Visual Relation Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/13ee363f71e07112210ac2ff27d46625f6f8edab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.05049\",\"authors\":[{\"authorId\":\"2008154246\",\"name\":\"Zongheng Tang\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2103483\",\"name\":\"X. Jin\"},{\"authorId\":\"2292508\",\"name\":\"Hongxu Jiang\"},{\"authorId\":\"1410184682\",\"name\":\"Qian Yu\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74c30c601d5de21af098389abf7be0f8261e6c13\",\"title\":\"Human-centric Spatio-Temporal Video Grounding With Visual Transformers\",\"url\":\"https://www.semanticscholar.org/paper/74c30c601d5de21af098389abf7be0f8261e6c13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993577888\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"47294827\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"1390958297\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1145/3394171.3413939\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bb76ef403f4c2592792b0f557f02a473cbef7f9\",\"title\":\"Text-Guided Image Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7bb76ef403f4c2592792b0f557f02a473cbef7f9\",\"venue\":\"ACM Multimedia\",\"year\":2020}],\"corpusId\":210839435,\"doi\":\"10.1109/cvpr42600.2020.01068\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"references\":[{\"arxivId\":\"1711.06640\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"38094552\",\"name\":\"Sam Thomson\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2018.00611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"title\":\"Neural Motifs: Scene Graph Parsing with Global Context\",\"url\":\"https://www.semanticscholar.org/paper/0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.08164\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/ICCV.2019.00474\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c8b8a2d61cdd9592faebb6aca262ec3a64e6d43\",\"title\":\"Dynamic Graph Attention for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/6c8b8a2d61cdd9592faebb6aca262ec3a64e6d43\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1801.01582\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00434\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"title\":\"Object Referring in Videos with Language and Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"413c1142de9d91804d6d11c67ff3fed59c9fc279\",\"title\":\"Adaptive Subgradient Methods for Online Learning and Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/413c1142de9d91804d6d11c67ff3fed59c9fc279\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00623\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeac614f10cb2a5dc000fdee30d857bbe5456ce5\",\"title\":\"Finding \\\"It\\\": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/aeac614f10cb2a5dc000fdee30d857bbe5456ce5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.09542\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2017.375\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a5b64709c677c131ec8b7846d3493df53987fa6f\",\"title\":\"A Joint Speaker-Listener-Reinforcer Model for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a5b64709c677c131ec8b7846d3493df53987fa6f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49887532\",\"name\":\"J. Shi\"},{\"authorId\":\"153173166\",\"name\":\"J. Xu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2019.01069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8842a793e10d35f917345f7290fc671edd8cc7bf\",\"title\":\"Not All Frames Are Equal: Weakly-Supervised Video Grounding With Contextual Similarity and Visual Clustering Losses\",\"url\":\"https://www.semanticscholar.org/paper/8842a793e10d35f917345f7290fc671edd8cc7bf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.08199\",\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9388ec8a0de86969afce29947b8b80b5698e4a21\",\"title\":\"Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\",\"url\":\"https://www.semanticscholar.org/paper/9388ec8a0de86969afce29947b8b80b5698e4a21\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/CVPR.2018.00808\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"title\":\"Visual Grounding via Accumulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.05113\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1609/AAAI.V33I01.33019062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"title\":\"Multilevel Language and Vision Integration for Text-to-Clip Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V33I01.33018175\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d85117bc69847b64f90424f4858ffc55c4fa3963\",\"title\":\"Localizing Natural Language in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d85117bc69847b64f90424f4858ffc55c4fa3963\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"144368926\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fa68cde4db12779adacb70a24961cf09b1adf73\",\"title\":\"Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/0fa68cde4db12779adacb70a24961cf09b1adf73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.07945\",\"authors\":[{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2017.162\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"06184106c9a5dc602cac98f162b991707aaa4a80\",\"title\":\"Spatio-Temporal Person Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/06184106c9a5dc602cac98f162b991707aaa4a80\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1712.01892\",\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2018.00437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d576ffe624f11fe4e84a03d4063856a5af838f\",\"title\":\"Grounding Referring Expressions in Images by Variational Context\",\"url\":\"https://www.semanticscholar.org/paper/69d576ffe624f11fe4e84a03d4063856a5af838f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.02549\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/P19-1183\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"title\":\"Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3209978.3210003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"519da94369c1d87e09c592f239b55cc9486b5b7c\",\"title\":\"Attentive Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/519da94369c1d87e09c592f239b55cc9486b5b7c\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1809.01337\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.18653/v1/D18-1168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b1ff82db09672656157874718860bee942483cf\",\"title\":\"Localizing Moments in Video with Temporal Language\",\"url\":\"https://www.semanticscholar.org/paper/0b1ff82db09672656157874718860bee942483cf\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ranjay Krishna\"},{\"authorId\":null,\"name\":\"Kenji Hata\"},{\"authorId\":null,\"name\":\"Frederic Ren\"},{\"authorId\":null,\"name\":\"Li Fei-Fei\"},{\"authorId\":null,\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Natural language object retrieval Finding \\u201d it \\u201d : Weakly - supervised reference - aware visual grounding in instructional videos Semi - supervised classification with graph convolutional networks\",\"url\":\"\",\"venue\":\"In ICLR\",\"year\":2016},{\"arxivId\":\"1906.02497\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"}],\"doi\":\"10.1145/3331184.3331235\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fb53803897d3df3e1f43a43a753ee88a64517c47\",\"title\":\"Cross-Modal Interaction Networks for Query-Based Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb53803897d3df3e1f43a43a753ee88a64517c47\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1608.00272\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"3451188\",\"name\":\"Patrick Poirson\"},{\"authorId\":\"144947353\",\"name\":\"S. Yang\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46475-6_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"title\":\"Modeling Context in Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1710.10903\",\"authors\":[{\"authorId\":\"3444569\",\"name\":\"Petar Velickovic\"},{\"authorId\":\"7153363\",\"name\":\"Guillem Cucurull\"},{\"authorId\":\"8742492\",\"name\":\"A. Casanova\"},{\"authorId\":\"144290131\",\"name\":\"A. Romero\"},{\"authorId\":\"144269589\",\"name\":\"P. Li\\u00f2\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.17863/CAM.48429\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33998aff64ce51df8dee45989cdca4b6b1329ec4\",\"title\":\"Graph Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/33998aff64ce51df8dee45989cdca4b6b1329ec4\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.01371\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/CVPR.2017.558\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9405a9180139f23f4dd9d90aa4e86944b35b8c88\",\"title\":\"Weakly-Supervised Visual Grounding of Phrases with Linguistic Structures\",\"url\":\"https://www.semanticscholar.org/paper/9405a9180139f23f4dd9d90aa4e86944b35b8c88\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1609.02907\",\"authors\":[{\"authorId\":\"41016725\",\"name\":\"Thomas Kipf\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36eff562f65125511b5dfab68ce7f7a943c27478\",\"title\":\"Semi-Supervised Classification with Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/36eff562f65125511b5dfab68ce7f7a943c27478\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2965987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"title\":\"Moment Retrieval via Cross-Modal Interaction Networks With Query Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"79723716\",\"name\":\"D. Di\"},{\"authorId\":\"66358686\",\"name\":\"J. Xiao\"},{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3323873.3325056\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fa0388f5373a2f17a3c456346a52427c887667ea\",\"title\":\"Annotating Objects and Relations in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/fa0388f5373a2f17a3c456346a52427c887667ea\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1906.12165\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.24963/ijcai.2019/610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d145292fd11ca274693ec9ea6941a9147ae5868\",\"title\":\"Localizing Unseen Activities in Video via Image Query\",\"url\":\"https://www.semanticscholar.org/paper/5d145292fd11ca274693ec9ea6941a9147ae5868\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1608.00525\",\"authors\":[{\"authorId\":\"3081378\",\"name\":\"Varun K. Nagaraja\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46493-0_48\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"title\":\"Modeling Context Between Objects for Referring Expression Understanding\",\"url\":\"https://www.semanticscholar.org/paper/86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1805.02834\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"46184233\",\"name\":\"Nathan Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1288aaf45ff85916ccef13668ceba421273a3c36\",\"title\":\"Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/1288aaf45ff85916ccef13668ceba421273a3c36\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175864710def9b3e8b42e4613856d0b840c37615\",\"title\":\"Cross-modal Moment Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/175864710def9b3e8b42e4613856d0b840c37615\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1801.08186\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"title\":\"MAttNet: Modular Attention Network for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1412.3555\",\"authors\":[{\"authorId\":\"8270717\",\"name\":\"J. Chung\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"title\":\"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1904.03282\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2019.01186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"title\":\"Weakly Supervised Video Moment Retrieval From Text Queries\",\"url\":\"https://www.semanticscholar.org/paper/ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014}],\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"topics\":[{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Photomultiplier\",\"topicId\":\"103044\",\"url\":\"https://www.semanticscholar.org/topic/103044\"}],\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"