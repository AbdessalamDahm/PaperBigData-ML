"{\"abstract\":\"Human face reenactment aims at transferring motion patterns from one face (from a source-domain video) to an-other (in the target domain with the identity of interest).While recent works report impressive results, they are notable to handle multiple identities in a unified model. In this paper, we propose a unique network of CrossID-GAN to perform multi-ID face reenactment. Given a source-domain video with extracted facial landmarks and a target-domain image, our CrossID-GAN learns the identity-invariant motion patterns via the extracted landmarks and such information to produce the videos whose ID matches that of the target domain. Both supervised and unsupervised settings are proposed to train and guide our model during training.Our qualitative/quantitative results confirm the robustness and effectiveness of our model, with ablation studies confirming our network design.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2660868\",\"name\":\"Po-Hsiang Huang\",\"url\":\"https://www.semanticscholar.org/author/2660868\"},{\"authorId\":\"41015732\",\"name\":\"Fu-En Yang\",\"url\":\"https://www.semanticscholar.org/author/41015732\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\",\"url\":null}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":219628333,\"doi\":\"10.1109/cvpr42600.2020.00711\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"5e393f107578d250bec23c2c5d076b692001f128\",\"references\":[{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1808.05174\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1007/978-3-030-01228-1_8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8ad3c383a79e85159098112127300dfd08c21319\",\"title\":\"Recycle-GAN: Unsupervised Video Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/8ad3c383a79e85159098112127300dfd08c21319\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.10550\",\"authors\":[{\"authorId\":\"8792285\",\"name\":\"Olivia Wiles\"},{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ea992f009492888c482d5f4006281eaa8b758e7\",\"title\":\"X2Face: A network for controlling face generation by using images, audio, and pose codes\",\"url\":\"https://www.semanticscholar.org/paper/9ea992f009492888c482d5f4006281eaa8b758e7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2816795.2818056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"890f137efc064f82450c776e6a4141eb9f08fabc\",\"title\":\"Real-time expression transfer for facial reenactment\",\"url\":\"https://www.semanticscholar.org/paper/890f137efc064f82450c776e6a4141eb9f08fabc\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":\"1802.01822\",\"authors\":[{\"authorId\":\"35790820\",\"name\":\"F. Qiao\"},{\"authorId\":\"49288884\",\"name\":\"N. Yao\"},{\"authorId\":\"35996065\",\"name\":\"Zirui Jiao\"},{\"authorId\":\"143846985\",\"name\":\"Z. Li\"},{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"7643981\",\"name\":\"H. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf933913d7380b5cb32266d68e75c095ce99eeae\",\"title\":\"Geometry-Contrastive GAN for Facial Expression Transfer.\",\"url\":\"https://www.semanticscholar.org/paper/bf933913d7380b5cb32266d68e75c095ce99eeae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143776763\",\"name\":\"L. Tran\"},{\"authorId\":\"2399004\",\"name\":\"Xi Yin\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/CVPR.2017.141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5ca8d4f259f35c1f3edfd9f108ce29881e478b0\",\"title\":\"Disentangled Representation Learning GAN for Pose-Invariant Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5ca8d4f259f35c1f3edfd9f108ce29881e478b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00165\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.02683\",\"authors\":[{\"authorId\":\"144589611\",\"name\":\"Xiang Wu\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/TIFS.2018.2833032\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7a7f27516a219122000b9b915289b7127dca2f2\",\"title\":\"A Light CNN for Deep Face Representation With Noisy Labels\",\"url\":\"https://www.semanticscholar.org/paper/f7a7f27516a219122000b9b915289b7127dca2f2\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2018},{\"arxivId\":\"1706.08500\",\"authors\":[{\"authorId\":\"2445103\",\"name\":\"Martin Heusel\"},{\"authorId\":\"19219270\",\"name\":\"Hubert Ramsauer\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"37082831\",\"name\":\"Bernhard Nessler\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"231af7dc01a166cac3b5b01ca05778238f796e41\",\"title\":\"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\",\"url\":\"https://www.semanticscholar.org/paper/231af7dc01a166cac3b5b01ca05778238f796e41\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46904799\",\"name\":\"Jie Shen\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICCVW.2015.132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07d95be4922670ef2f8b11997e0c00eb643f3fca\",\"title\":\"The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results\",\"url\":\"https://www.semanticscholar.org/paper/07d95be4922670ef2f8b11997e0c00eb643f3fca\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":\"1806.11191\",\"authors\":[{\"authorId\":\"6812347\",\"name\":\"Yu Tian\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"1753384\",\"name\":\"S. Zhang\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.24963/ijcai.2018/131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f89d6ef6c9e3ee4883595f94b38ab01d05d7b21\",\"title\":\"CR-GAN: Learning Complete Representations for Multi-view Generation\",\"url\":\"https://www.semanticscholar.org/paper/8f89d6ef6c9e3ee4883595f94b38ab01d05d7b21\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1801.07698\",\"authors\":[{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"3007274\",\"name\":\"J. Guo\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/CVPR.2019.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4f100ca5edfe53b562f1d170b2c48939bab0e27\",\"title\":\"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4f100ca5edfe53b562f1d170b2c48939bab0e27\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.08233\",\"authors\":[{\"authorId\":\"144395395\",\"name\":\"E. Zakharov\"},{\"authorId\":\"123830349\",\"name\":\"Aliaksandra Shysheya\"},{\"authorId\":\"52225338\",\"name\":\"Egor Burkov\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":\"10.1109/ICCV.2019.00955\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1cc8e9675dc9c39fc34def087699c3359eff495c\",\"title\":\"Few-Shot Adversarial Learning of Realistic Neural Talking Head Models\",\"url\":\"https://www.semanticscholar.org/paper/1cc8e9675dc9c39fc34def087699c3359eff495c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1811.03492\",\"authors\":[{\"authorId\":\"32363763\",\"name\":\"E. Sanchez\"},{\"authorId\":\"1795528\",\"name\":\"M. Valstar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"671bfefb22d2044ab3e4402703bb88a10a7da78a\",\"title\":\"Triple consistency loss for pairing distributions in GAN-based face synthesis\",\"url\":\"https://www.semanticscholar.org/paper/671bfefb22d2044ab3e4402703bb88a10a7da78a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3188342\",\"name\":\"Omkar M. Parkhi\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.29.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"162ea969d1929ed180cc6de9f0bf116993ff6e06\",\"title\":\"Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/162ea969d1929ed180cc6de9f0bf116993ff6e06\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2007.14808\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3292039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"title\":\"Face2Face: real-time face capture and reenactment of RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"venue\":\"Commun. ACM\",\"year\":2019},{\"arxivId\":\"1807.11079\",\"authors\":[{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"6693591\",\"name\":\"Yunxuan Zhang\"},{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":null,\"name\":\"Chen Qian\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/978-3-030-01246-5_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bfccbf6f4e88a92a7b1f2b5c588b68c5fa45a92\",\"title\":\"ReenactGAN: Learning to Reenact Faces via Boundary Transfer\",\"url\":\"https://www.semanticscholar.org/paper/2bfccbf6f4e88a92a7b1f2b5c588b68c5fa45a92\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuiwang Ji\"},{\"authorId\":null,\"name\":\"Wei Xu\"},{\"authorId\":null,\"name\":\"Ming Yang\"},{\"authorId\":null,\"name\":\"Kai Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tional neural networks for human action recognition\",\"url\":\"\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2012}],\"title\":\"Learning Identity-Invariant Motion Representations for Cross-ID Face Reenactment\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/5e393f107578d250bec23c2c5d076b692001f128\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"