"{\"abstract\":\"Joint understanding of vision and natural language is a challenging problem with a wide range of applications in artificial intelligence. In this work, we focus on integration of video and text for the task of actor and action video segmentation from a sentence. We propose a capsule-based approach which performs pixel-level localization based on a natural language query describing the actor of interest. We encode both the video and textual input in the form of capsules, which provide a more effective representation in comparison with standard convolution based features. Our novel visual-textual routing mechanism allows for the fusion of video and text capsules to successfully localize the actor and action. The existing works on actor-action localization are mainly focused on localization in a single frame instead of the full video. Different from existing works, we propose to perform the localization on all frames of the video. To validate the potential of the proposed network for actor and action video localization, we extend an existing actor-action dataset (A2D) with annotations for all the frames. The experimental evaluation demonstrates the effectiveness of our capsule network for text selective actor and action localization in videos. The proposed method also improves upon the performance of the existing state-of-the art works on single frame-based localization.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"153344447\",\"name\":\"Bruce McIntosh\",\"url\":\"https://www.semanticscholar.org/author/153344447\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\",\"url\":\"https://www.semanticscholar.org/author/7839191\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\",\"url\":\"https://www.semanticscholar.org/author/2116440\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\",\"url\":\"https://www.semanticscholar.org/author/145103010\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2011.10927\",\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"title\":\"We don't Need Thousand Proposals$\\\\colon$ Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6dd3595637c470f7f008b80a4db131da929e35e\",\"title\":\"We don't Need Thousand Proposals: Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f6dd3595637c470f7f008b80a4db131da929e35e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.02920\",\"authors\":[{\"authorId\":\"145435260\",\"name\":\"Tao Sun\"},{\"authorId\":\"2984891\",\"name\":\"Zhe-Wei Wang\"},{\"authorId\":\"153550995\",\"name\":\"C. D. Smith\"},{\"authorId\":\"34693490\",\"name\":\"Jundong Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c840176a099c759a7919c1052b4c6446690c62\",\"title\":\"TraceCaps: A Capsule-based Neural Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/09c840176a099c759a7919c1052b4c6446690c62\",\"venue\":\"\",\"year\":2019}],\"corpusId\":215752379,\"doi\":\"10.1109/cvpr42600.2020.00996\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"b990461318a506822182a689b0e13d5e9465f0dc\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"49185042\",\"name\":\"S. Wang\"}],\"doi\":\"10.1007/978-3-642-21735-7_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20f0357688876fa4662f806f985779dce6e24f3c\",\"title\":\"Transforming Auto-Encoders\",\"url\":\"https://www.semanticscholar.org/paper/20f0357688876fa4662f806f985779dce6e24f3c\",\"venue\":\"ICANN\",\"year\":2011},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"51188245\",\"name\":\"K. Fan\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"120281229\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1609/aaai.v33i01.33018320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49c0796d3cbc811c6e27470afdf191ba382cfae5\",\"title\":\"Deliberate Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49c0796d3cbc811c6e27470afdf191ba382cfae5\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1603.06180\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46448-0_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b133e361e2f8af22b823d25060b2e7c47f690985\",\"title\":\"Segmentation from Natural Language Expressions\",\"url\":\"https://www.semanticscholar.org/paper/b133e361e2f8af22b823d25060b2e7c47f690985\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"},{\"authorId\":\"1741866\",\"name\":\"H. Li\"},{\"authorId\":\"1706784\",\"name\":\"Fanman Meng\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-01231-1_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"title\":\"Key-Word-Aware Network for Referring Expression Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1710.00421\",\"authors\":[{\"authorId\":\"2664705\",\"name\":\"Y. Li\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144752689\",\"name\":\"David Edwin Carlson\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"title\":\"Video Generation From Text\",\"url\":\"https://www.semanticscholar.org/paper/3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1804.00538\",\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"},{\"authorId\":\"40846265\",\"name\":\"Zeyang Lei\"},{\"authorId\":\"2819904\",\"name\":\"Suofei Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"}],\"doi\":\"10.18653/v1/D18-1350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a377115d0026bca3f67ed34ea03543880f6a2e3\",\"title\":\"Investigating Capsule Networks with Dynamic Routing for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/6a377115d0026bca3f67ed34ea03543880f6a2e3\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V33I01.33018175\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d85117bc69847b64f90424f4858ffc55c4fa3963\",\"title\":\"Localizing Natural Language in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d85117bc69847b64f90424f4858ffc55c4fa3963\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"143752292\",\"name\":\"Sara Sabour\"},{\"authorId\":\"27737461\",\"name\":\"Nicholas Frosst\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"603caed9430283db6c7f43169555c8d18e97a281\",\"title\":\"Matrix capsules with EM routing\",\"url\":\"https://www.semanticscholar.org/paper/603caed9430283db6c7f43169555c8d18e97a281\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"1930068\",\"name\":\"Shao-Hang Hsieh\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2015.7298839\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b1616a59df96d9e2fa2dd3b2e1fd7bed7719913\",\"title\":\"Can humans fly? Action understanding with multiple classes of actors\",\"url\":\"https://www.semanticscholar.org/paper/0b1616a59df96d9e2fa2dd3b2e1fd7bed7719913\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1805.08162\",\"authors\":[{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9a576f03fc5f6cabbd6291fb65db0ee0a607103\",\"title\":\"VideoCapsuleNet: A Simplified Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/d9a576f03fc5f6cabbd6291fb65db0ee0a607103\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"143677598\",\"name\":\"R. Tao\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2017.777\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"736657bd62e6e8a1e29fd2bdb49910ee6da9b8c7\",\"title\":\"Tracking by Natural Language Specification\",\"url\":\"https://www.semanticscholar.org/paper/736657bd62e6e8a1e29fd2bdb49910ee6da9b8c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669461\",\"name\":\"Kuncheng Fang\"},{\"authorId\":\"144913277\",\"name\":\"Lian Zhou\"},{\"authorId\":\"145020731\",\"name\":\"Cheng Jin\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"35632219\",\"name\":\"Kangnian Weng\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"title\":\"Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention\",\"url\":\"https://www.semanticscholar.org/paper/506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1804.04241\",\"authors\":[{\"authorId\":\"37299201\",\"name\":\"Rodney LaLonde\"},{\"authorId\":\"1717161\",\"name\":\"U. Bagci\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df724040bf460858b3e325fab0a4dd3374a647a7\",\"title\":\"Capsules for Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/df724040bf460858b3e325fab0a4dd3374a647a7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1710.09829\",\"authors\":[{\"authorId\":\"143752292\",\"name\":\"Sara Sabour\"},{\"authorId\":\"27737461\",\"name\":\"Nicholas Frosst\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c4c06578f4870e4b126e6837907929f3c900b99f\",\"title\":\"Dynamic Routing Between Capsules\",\"url\":\"https://www.semanticscholar.org/paper/c4c06578f4870e4b126e6837907929f3c900b99f\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.01967\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-01261-8_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"title\":\"Visual Text Correction\",\"url\":\"https://www.semanticscholar.org/paper/ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1901.06829\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"1749527\",\"name\":\"Xiang Zhao\"},{\"authorId\":\"2864855\",\"name\":\"Jizhou Huang\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"title\":\"Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80389343\",\"name\":\"Zhihui Li\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"48691107\",\"name\":\"X. Zhang\"},{\"authorId\":\"2877263\",\"name\":\"Xianzhi Wang\"},{\"authorId\":\"1733096\",\"name\":\"Salil S. Kanhere\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018690\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6486cc2397d503a1135e1a69cbd554fc66b0ff55\",\"title\":\"Zero-Shot Object Detection with Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6486cc2397d503a1135e1a69cbd554fc66b0ff55\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"144252775\",\"name\":\"W. Chen\"}],\"doi\":\"10.1609/AAAI.V33I01.33019324\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63d730376789d0430bc4795b724cc0245ef32608\",\"title\":\"Dynamic Capsule Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/63d730376789d0430bc4795b724cc0245ef32608\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"2035475\",\"name\":\"Z. Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018957\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b312f921c937cf9b11cc3b7005613576f5607fcf\",\"title\":\"Hierarchical Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b312f921c937cf9b11cc3b7005613576f5607fcf\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017}],\"title\":\"Visual-Textual Capsule Routing for Text-Based Video Segmentation\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/b990461318a506822182a689b0e13d5e9465f0dc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"