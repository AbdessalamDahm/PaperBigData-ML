"{\"abstract\":\"The rapid increase in the amount of published visual data and the limited time of users bring the demand for processing untrimmed videos to produce shorter versions that convey the same information. Despite the remarkable progress that has been made by summarization methods, most of them can only select a few frames or skims, which creates visual gaps and breaks the video context. In this paper, we present a novel methodology based on a reinforcement learning formulation to accelerate instructional videos. Our approach can adaptively select frames that are not relevant to convey the information without creating gaps in the final video. Our agent is textually and visually oriented to select which frames to remove to shrink the input video. Additionally, we propose a novel network, called Visually-guided Document Attention Network (VDAN), able to generate a highly discriminative embedding space to represent both textual and visual data. Our experiments show that our method achieves the best performance in terms of F1 Score and coverage at the video segment level.\",\"arxivId\":\"2003.14229\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\",\"url\":\"https://www.semanticscholar.org/author/3459502\"},{\"authorId\":\"46464798\",\"name\":\"M. Silva\",\"url\":\"https://www.semanticscholar.org/author/46464798\"},{\"authorId\":\"152396628\",\"name\":\"E. Ara\\u00fajo\",\"url\":\"https://www.semanticscholar.org/author/152396628\"},{\"authorId\":\"2211313\",\"name\":\"Leandro Soriano Marcolino\",\"url\":\"https://www.semanticscholar.org/author/2211313\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\",\"url\":\"https://www.semanticscholar.org/author/2310152\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":214728198,\"doi\":\"10.1109/CVPR42600.2020.01094\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"references\":[{\"arxivId\":\"1802.08722\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR.2018.00253\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"title\":\"A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1412.3596\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2015.7299109\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6ce71f5bd42cf343a0f33deb2174b165d3463e89\",\"title\":\"EgoSampling: Fast-forward and stereo for egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6ce71f5bd42cf343a0f33deb2174b165d3463e89\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1904.12251\",\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1145/3123266.3123328\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"454e65c2a9b019a00790a1d6029dc5539edad35d\",\"title\":\"Hierarchical Recurrent Neural Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/454e65c2a9b019a00790a1d6029dc5539edad35d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2015.7298928\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"title\":\"Video summarization by learning submodular mixtures of objectives\",\"url\":\"https://www.semanticscholar.org/paper/cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1703.09788\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e10a5e0baf2aa87d804795af071808a9377cc80a\",\"title\":\"Towards Automatic Learning of Procedures From Web Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/e10a5e0baf2aa87d804795af071808a9377cc80a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"47772841\",\"name\":\"Michael Lam\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2017.318\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"620fe6c786d15efca7f553ad70f295e2b693b391\",\"title\":\"Unsupervised Video Summarization with Adversarial LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/620fe6c786d15efca7f553ad70f295e2b693b391\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30760312\",\"name\":\"Masaya Okamoto\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1007/978-3-642-53842-1_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4bf1a21bf9b1c79afaeadb071a3de47484b40bd\",\"title\":\"Summarization of Egocentric Moving Videos for Generating Walking Route Guidance\",\"url\":\"https://www.semanticscholar.org/paper/e4bf1a21bf9b1c79afaeadb071a3de47484b40bd\",\"venue\":\"PSIVT\",\"year\":2013},{\"arxivId\":\"1801.00054\",\"authors\":[{\"authorId\":\"9368124\",\"name\":\"K. Zhou\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e9e5f0c36548cfe2855aae46b519b146aa8c9ae\",\"title\":\"Deep Reinforcement Learning for Unsupervised Video Summarization with Diversity-Representativeness Reward\",\"url\":\"https://www.semanticscholar.org/paper/9e9e5f0c36548cfe2855aae46b519b146aa8c9ae\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1509.06461\",\"authors\":[{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b9732bb07dc99bde5e1f9f75251c6ea5039373e\",\"title\":\"Deep Reinforcement Learning with Double Q-Learning\",\"url\":\"https://www.semanticscholar.org/paper/3b9732bb07dc99bde5e1f9f75251c6ea5039373e\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.112\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97398356607115f78d677663a682363eec3302d7\",\"title\":\"Highlight Detection with Pairwise Deep Ranking for First-Person Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/97398356607115f78d677663a682363eec3302d7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1605.08110\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_47\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"title\":\"Video Summarization with Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1810.06553\",\"authors\":[{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"32856859\",\"name\":\"Nicholas Hynes\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"145686708\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"1684687\",\"name\":\"Ingmar Weber\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.327\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7170e3641ba7452987bfd299ef4c6e20dd8105c\",\"title\":\"Learning Cross-Modal Embeddings for Cooking Recipes and Food Images\",\"url\":\"https://www.semanticscholar.org/paper/d7170e3641ba7452987bfd299ef4c6e20dd8105c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.02792\",\"authors\":[{\"authorId\":\"46218538\",\"name\":\"Shuyue Lan\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"144400477\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2018.00708\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"82662d6680ae0444f5d76e637c414721cc6f0583\",\"title\":\"FFNet: Video Fast-Forwarding via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/82662d6680ae0444f5d76e637c414721cc6f0583\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.01362\",\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/TMM.2018.2832602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"031af500679ae544d0fc614f938de45a07c87c82\",\"title\":\"Predicting Visual Features From Text for Image and Video Caption Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/031af500679ae544d0fc614f938de45a07c87c82\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"144362750\",\"name\":\"A. Tan\"}],\"doi\":\"10.1109/THMS.2016.2623480\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"title\":\"Summarization of Egocentric Videos: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2449382\",\"name\":\"T. Hubert\"},{\"authorId\":\"144522726\",\"name\":\"L. Baker\"},{\"authorId\":\"40227832\",\"name\":\"Matthew Lai\"},{\"authorId\":\"34848283\",\"name\":\"A. Bolton\"},{\"authorId\":\"1519062204\",\"name\":\"Yutian Chen\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"88791868\",\"name\":\"F. Hui\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature24270\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c27db32efa8137cbf654902f8f728f338e55cd1c\",\"title\":\"Mastering the game of Go without human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c27db32efa8137cbf654902f8f728f338e55cd1c\",\"venue\":\"Nature\",\"year\":2017},{\"arxivId\":\"1804.11146\",\"authors\":[{\"authorId\":\"40361051\",\"name\":\"M. Carvalho\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"},{\"authorId\":\"145159652\",\"name\":\"L. Soulier\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1145/3209978.3210036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9b291a22aa3e53bc610d99429fc52ba2311e110\",\"title\":\"Cross-Modal Retrieval in the Cooking Context: Learning Semantic Text-Image Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a9b291a22aa3e53bc610d99429fc52ba2311e110\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"47819455\",\"name\":\"J. Choi\"},{\"authorId\":\"2347316\",\"name\":\"Young Joon Yoo\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"46174575\",\"name\":\"J. Choi\"}],\"doi\":\"10.1109/CVPR.2017.148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96dc41d3b004fd4c7f96b71b4e174beb3088b2bb\",\"title\":\"Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/96dc41d3b004fd4c7f96b71b4e174beb3088b2bb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"144007359\",\"name\":\"W. Kienzle\"},{\"authorId\":\"2441615\",\"name\":\"Mike Toelle\"},{\"authorId\":\"143711233\",\"name\":\"Matthew Uyttendaele\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1145/2766954\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"19b70d6c2fba3539d45fa0f2e15ec5a0ba3ba248\",\"title\":\"Real-time hyperlapse creation via optimal frame selection\",\"url\":\"https://www.semanticscholar.org/paper/19b70d6c2fba3539d45fa0f2e15ec5a0ba3ba248\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1145/2601097.2601195\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c445a9ca786225d08b68cda9662dec50046ed559\",\"title\":\"First-person hyper-lapse videos\",\"url\":\"https://www.semanticscholar.org/paper/c445a9ca786225d08b68cda9662dec50046ed559\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":\"1905.01273\",\"authors\":[{\"authorId\":\"39483391\",\"name\":\"H. Wang\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2039481\",\"name\":\"Chenghao Liu\"},{\"authorId\":\"1709901\",\"name\":\"E. Lim\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.1109/CVPR.2019.01184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4bc9475c4bc4950cd02d8e9bb8c31fd4ffa75d8\",\"title\":\"Learning Cross-Modal Embeddings With Adversarial Networks for Cooking Recipes and Food Images\",\"url\":\"https://www.semanticscholar.org/paper/f4bc9475c4bc4950cd02d8e9bb8c31fd4ffa75d8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.04160\",\"authors\":[{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/ICIP.2016.7532977\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a1d9effff545d429bd41e0d65cd5f39aa177860e\",\"title\":\"Fast-forward video based on semantic extraction\",\"url\":\"https://www.semanticscholar.org/paper/a1d9effff545d429bd41e0d65cd5f39aa177860e\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2017.118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06dc33896f94554d67514c8a5e34cad5ff9749bc\",\"title\":\"Enhancing Video Summarization via Vision-Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/06dc33896f94554d67514c8a5e34cad5ff9749bc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14998948\",\"name\":\"D. Li\"},{\"authorId\":\"9947552\",\"name\":\"Huikai Wu\"},{\"authorId\":\"2086001\",\"name\":\"Junge Zhang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00855\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5ac3c258bcadc0766e29638aa95e14058f6adf0\",\"title\":\"A2-RL: Aesthetics Aware Reinforcement Learning for Image Cropping\",\"url\":\"https://www.semanticscholar.org/paper/b5ac3c258bcadc0766e29638aa95e14058f6adf0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2097156\",\"name\":\"M. Fei\"},{\"authorId\":\"144893136\",\"name\":\"W. Jiang\"},{\"authorId\":\"38961654\",\"name\":\"Weijie Mao\"}],\"doi\":\"10.1016/j.jvcir.2016.12.001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"134cd4479b2470da8a2de331cdaa1bbf42ab0d89\",\"title\":\"Memorable and rich video summarization\",\"url\":\"https://www.semanticscholar.org/paper/134cd4479b2470da8a2de331cdaa1bbf42ab0d89\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2449382\",\"name\":\"T. Hubert\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"40227832\",\"name\":\"Matthew Lai\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1126/science.aar6404\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9717d29840f4d8f1cc19d1b1e80c5d12ec40608\",\"title\":\"A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play\",\"url\":\"https://www.semanticscholar.org/paper/f9717d29840f4d8f1cc19d1b1e80c5d12ec40608\",\"venue\":\"Science\",\"year\":2018},{\"arxivId\":\"1708.04146\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"40834129\",\"name\":\"Jo\\u00e3o Pedro Klock Ferreira\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1007/978-3-319-46604-0_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79ca84296f1869b1b4e986edb31de69ec113fb28\",\"title\":\"Towards Semantic Fast-Forward and Stabilized Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/79ca84296f1869b1b4e986edb31de69ec113fb28\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"2022168\",\"name\":\"Diyi Yang\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.18653/v1/N16-1174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"455afd748e8834ef521e4b67c7c056d3c33429e2\",\"title\":\"Hierarchical Attention Networks for Document Classification\",\"url\":\"https://www.semanticscholar.org/paper/455afd748e8834ef521e4b67c7c056d3c33429e2\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1016/j.jvcir.2018.02.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4398b6dc8c524ba69cf44ba7e5a22bad703d9a5d\",\"title\":\"Making a long story short: A multi-importance fast-forwarding egocentric videos with the emphasis on relevant objects\",\"url\":\"https://www.semanticscholar.org/paper/4398b6dc8c524ba69cf44ba7e5a22bad703d9a5d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/s13735-018-00166-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6305115f393d96df92f9044b8951969e28aa7114\",\"title\":\"Joint embeddings with multimodal cues for video-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6305115f393d96df92f9044b8951969e28aa7114\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065653\",\"name\":\"L. Paletta\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"}],\"doi\":\"10.1016/S0921-8890(99)00079-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adddd055a5983993e6b83d6e6b8e01ecf09584c5\",\"title\":\"Active object recognition by view integration and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/adddd055a5983993e6b83d6e6b8e01ecf09584c5\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145454815\",\"name\":\"Yue Zhao\"},{\"authorId\":\"1730129\",\"name\":\"X. Jin\"},{\"authorId\":\"2219600\",\"name\":\"Yuanzhuo Wang\"},{\"authorId\":\"1717004\",\"name\":\"X. Cheng\"}],\"doi\":\"10.18653/v1/P18-2066\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1e3c9c06f58e13019606349b9c2a0713d8295ad\",\"title\":\"Document Embedding Enhanced Event Detection with Hierarchical and Supervised Attention\",\"url\":\"https://www.semanticscholar.org/paper/a1e3c9c06f58e13019606349b9c2a0713d8295ad\",\"venue\":\"ACL\",\"year\":2018}],\"title\":\"Straight to the Point: Fast-Forwarding Videos via Reinforcement Learning Using Textual Data\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"F1 score\",\"topicId\":\"719\",\"url\":\"https://www.semanticscholar.org/topic/719\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"