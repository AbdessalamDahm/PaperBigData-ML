"{\"abstract\":\"Popularized as `bottom-up' attention, bounding box (or region) based visual features have recently surpassed vanilla grid-based convolutional features as the de facto standard for vision and language tasks like visual question answering (VQA). However, it is not clear whether the advantages of regions (e.g. better localization) are the key reasons for the success of bottom-up attention. In this paper, we revisit grid features for VQA, and find they can work surprisingly well -- running more than an order of magnitude faster with the same accuracy (e.g. if pre-trained in a similar fashion). Through extensive experiments, we verify that this observation holds true across different VQA models (reporting a state-of-the-art accuracy on VQA 2.0 test-std, 72.71), datasets, and generalizes well to other tasks like image captioning. As grid features make the model design and training process much simpler, this enables us to train them end-to-end and also use a more flexible network design. We learn VQA models end-to-end, from pixels directly to answers, and show that strong performance is achievable without using any region annotations in pre-training. We hope our findings help further improve the scientific understanding and the practical application of VQA. Code and features will be made available.\",\"arxivId\":\"2001.03615\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\",\"url\":\"https://www.semanticscholar.org/author/40175280\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\",\"url\":\"https://www.semanticscholar.org/author/1806773\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\",\"url\":\"https://www.semanticscholar.org/author/1389846455\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\",\"url\":\"https://www.semanticscholar.org/author/39717886\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2010.06087\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"32587693\",\"name\":\"A. Moudgil\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ead5088bc1922526be9a503dd42b15d467b962\",\"title\":\"Contrast and Classify: Alternate Training for Robust VQA\",\"url\":\"https://www.semanticscholar.org/paper/35ead5088bc1922526be9a503dd42b15d467b962\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04305\",\"authors\":[{\"authorId\":\"1918424\",\"name\":\"Jiacheng Chen\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"1906061249\",\"name\":\"Changhu Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"title\":\"Learning the Best Pooling Strategy for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06946\",\"authors\":[{\"authorId\":\"46583603\",\"name\":\"J. Wang\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"41171e9024d0082c2a57f4887bac93131669b881\",\"title\":\"MiniVLM: A Smaller and Faster Vision-Language Model\",\"url\":\"https://www.semanticscholar.org/paper/41171e9024d0082c2a57f4887bac93131669b881\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.11278\",\"authors\":[{\"authorId\":\"2706729\",\"name\":\"Jaemin Cho\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.707\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"title\":\"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2009.05684\",\"authors\":[{\"authorId\":\"46662193\",\"name\":\"V. Mittal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd6df4febb7135007077f835f9c44d12514aa522\",\"title\":\"AttnGrounder: Talking to Cars with Attention\",\"url\":\"https://www.semanticscholar.org/paper/dd6df4febb7135007077f835f9c44d12514aa522\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.11883\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c7faa44bde54f017e164ad8e687bd1963005988\",\"title\":\"Revisiting Modulated Convolutions for Visual Counting and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/6c7faa44bde54f017e164ad8e687bd1963005988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10966\",\"authors\":[{\"authorId\":\"1389550960\",\"name\":\"Tasmia Tasrin\"},{\"authorId\":\"1381931976\",\"name\":\"Md Sultan Al Nahian\"},{\"authorId\":\"34442699\",\"name\":\"B. Harrison\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"title\":\"Visual Question Answering Using Semantic Information from Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2011.11721\",\"authors\":[{\"authorId\":\"150209809\",\"name\":\"Maximilian Filtenborg\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1685090538\",\"name\":\"D. Gupta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b31eb6018275fa078080e08a1db1b0be5fcb4412\",\"title\":\"Siamese Tracking with Lingual Object Constraints\",\"url\":\"https://www.semanticscholar.org/paper/b31eb6018275fa078080e08a1db1b0be5fcb4412\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12902\",\"authors\":[{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"1410913697\",\"name\":\"Russ Howes\"},{\"authorId\":\"8277405\",\"name\":\"Brian Dolhansky\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdfcb7a9de6a0cb37bf2110bef619555a96258bc\",\"title\":\"Adversarial Evaluation of Multimodal Models under Realistic Gray Box Assumption\",\"url\":\"https://www.semanticscholar.org/paper/cdfcb7a9de6a0cb37bf2110bef619555a96258bc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.13681\",\"authors\":[{\"authorId\":\"20657367\",\"name\":\"A. Mani\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"},{\"authorId\":\"2029244392\",\"name\":\"Nobline Yoo\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"title\":\"Point and Ask: Incorporating Pointing into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020}],\"corpusId\":210156985,\"doi\":\"10.1109/cvpr42600.2020.01028\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1503.01817\",\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"118220290\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/2812802\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"title\":\"YFCC100M: the new data in multimedia research\",\"url\":\"https://www.semanticscholar.org/paper/354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":\"1807.09956\",\"authors\":[{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"36c3972569a6949ecca90bfa6f8e99883e092845\",\"title\":\"Pythia v0.1: the Winning Entry to the VQA Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/36c3972569a6949ecca90bfa6f8e99883e092845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":null,\"name\":\"Jianping Fan\"},{\"authorId\":null,\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal factorized bilinear pooling with co-attention learning for visual question answering\",\"url\":\"\",\"venue\":\"In ICCV,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1612.03144\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1790580\",\"name\":\"Bharath Hariharan\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2017.106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9b4e05faa194e5022edd9eb9dd07e3d675c2b36\",\"title\":\"Feature Pyramid Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b9b4e05faa194e5022edd9eb9dd07e3d675c2b36\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"},{\"authorId\":\"3766304\",\"name\":\"Abhaya Agarwal\"}],\"doi\":\"10.3115/1626355.1626389\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34d7a07c493ca6336c92156806a2947e115caadc\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/34d7a07c493ca6336c92156806a2947e115caadc\",\"venue\":\"WMT@ACL\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"\\u0141ukasz Kaiser\"},{\"authorId\":null,\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"terpretable counting for visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Saining Xie\"},{\"authorId\":null,\"name\":\"B Ross\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Girshick , Piotr Doll\\u00e1r , Zhuowen Tu , and Kaiming He . Aggregated residual transformations for deep neural networks\",\"url\":\"\",\"venue\":\"In CVPR\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"136309159\",\"name\":\"\\u77e5\\u79c0 \\u67f4\\u7530\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43f2ad297941db230c089ba353efc3f281ab678c\",\"title\":\"5\\u5206\\u3067\\u5206\\u304b\\u308b!? \\u6709\\u540d\\u8ad6\\u6587\\u30ca\\u30ca\\u30e1\\u8aad\\u307f\\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/43f2ad297941db230c089ba353efc3f281ab678c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"cs/9906002\",\"authors\":[{\"authorId\":\"2293327\",\"name\":\"S. Harnad\"}],\"doi\":\"10.4249/scholarpedia.2373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"026ff33083c647bd3a3734d41904d880a6525d13\",\"title\":\"Symbol grounding problem\",\"url\":\"https://www.semanticscholar.org/paper/026ff33083c647bd3a3734d41904d880a6525d13\",\"venue\":\"Scholarpedia\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1708.02002\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/ICCV.2017.324\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79cfb51a51fc093f66aac8e858afe2e14d4a1f20\",\"title\":\"Focal Loss for Dense Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/79cfb51a51fc093f66aac8e858afe2e14d4a1f20\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"96558862\",\"name\":\"Priyal Goyal\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/TPAMI.2018.2858826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72564a69bf339ff1d16a639c86a764db2321caab\",\"title\":\"Focal Loss for Dense Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/72564a69bf339ff1d16a639c86a764db2321caab\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Licheng Yu\"},{\"authorId\":null,\"name\":\"Faisal Ahmed\"},{\"authorId\":null,\"name\":\"Jia Deng\"},{\"authorId\":null,\"name\":\"Wei Dong\"},{\"authorId\":null,\"name\":\"Richard Socher\"},{\"authorId\":null,\"name\":\"Li-Jia Li\"},{\"authorId\":null,\"name\":\"Kai Li\"},{\"authorId\":null,\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bottom - up and top - down attention for image captioning and visual question answering Vqa : Visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1706.01427\",\"authors\":[{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"143724694\",\"name\":\"D. Raposo\"},{\"authorId\":\"50181861\",\"name\":\"David G. T. Barrett\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"007112213ece771be72cbecfd59f048209facabd\",\"title\":\"A simple neural network module for relational reasoning\",\"url\":\"https://www.semanticscholar.org/paper/007112213ece771be72cbecfd59f048209facabd\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1802.05766\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30a3eee5e9302108416f6234d739373dde68d373\",\"title\":\"Learning to Count Objects in Natural Images for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/30a3eee5e9302108416f6234d739373dde68d373\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1807.10221\",\"authors\":[{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"51149370\",\"name\":\"Yingcheng Liu\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-030-01228-1_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1\",\"title\":\"Unified Perceptual Parsing for Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644696911\",\"name\":\"DonahueJeff\"},{\"authorId\":\"1644694750\",\"name\":\"HendricksLisa Anne\"},{\"authorId\":\"1643893071\",\"name\":\"RohrbachMarcus\"},{\"authorId\":\"1644695575\",\"name\":\"VenugopalanSubhashini\"},{\"authorId\":\"1644695790\",\"name\":\"GuadarramaSergio\"},{\"authorId\":\"1644694743\",\"name\":\"SaenkoKate\"},{\"authorId\":\"1644040226\",\"name\":\"DarrellTrevor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bb892e8dd4fe4ff6a92470cd991c31c1aebaa99\",\"title\":\"Long-Term Recurrent Convolutional Networks for Visual Recognition and Description\",\"url\":\"https://www.semanticscholar.org/paper/6bb892e8dd4fe4ff6a92470cd991c31c1aebaa99\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.08920\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00851\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af1f7739283bdbd2b7a94903041f6d6afd991907\",\"title\":\"Towards VQA Models That Can Read\",\"url\":\"https://www.semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1811.11168\",\"authors\":[{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":\"10.1109/CVPR.2019.00953\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"987b2db58fbe0bda771f11a046cd23de1ce92b39\",\"title\":\"Deformable ConvNets V2: More Deformable, Better Results\",\"url\":\"https://www.semanticscholar.org/paper/987b2db58fbe0bda771f11a046cd23de1ce92b39\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1709.07871\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cfa5c97164129ce3630511f639040d28db1d4b7\",\"title\":\"FiLM: Visual Reasoning with a General Conditioning Layer\",\"url\":\"https://www.semanticscholar.org/paper/7cfa5c97164129ce3630511f639040d28db1d4b7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Piotr Doll\\u00e1r, and Ross Girshick. Mask r-cnn\",\"url\":\"\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jianping Shi\"},{\"authorId\":null,\"name\":\"Xiaojuan Qi\"},{\"authorId\":null,\"name\":\"Jiaya Jia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hare , and Adam Pr\\u00fcgel - Bennett . Learning to count objects in natural images for visual question answering\",\"url\":\"\",\"venue\":\"In ICLR\",\"year\":null},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.02325\",\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1007/978-3-319-46448-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"title\":\"SSD: Single Shot MultiBox Detector\",\"url\":\"https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1612.01105\",\"authors\":[{\"authorId\":\"3459894\",\"name\":\"Hengshuang Zhao\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":\"10.1109/CVPR.2017.660\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1031a69923b80ad01cf3fbb703d10757a80e699b\",\"title\":\"Pyramid Scene Parsing Network\",\"url\":\"https://www.semanticscholar.org/paper/1031a69923b80ad01cf3fbb703d10757a80e699b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1712.08697\",\"authors\":[{\"authorId\":\"3545259\",\"name\":\"A. Trott\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"title\":\"Interpretable Counting for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1810.02338\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d15ebe3f5aaf32a9f835f88703241461324c35b\",\"title\":\"Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/9d15ebe3f5aaf32a9f835f88703241461324c35b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/TPAMI.2018.2844175\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1a0912bb76777469295bb2c059faee907e7f3258\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/1a0912bb76777469295bb2c059faee907e7f3258\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020}],\"title\":\"In Defense of Grid Features for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Minimum bounding box\",\"topicId\":\"195508\",\"url\":\"https://www.semanticscholar.org/topic/195508\"},{\"topic\":\"Network planning and design\",\"topicId\":\"26472\",\"url\":\"https://www.semanticscholar.org/topic/26472\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Bottom-up parsing\",\"topicId\":\"682974\",\"url\":\"https://www.semanticscholar.org/topic/682974\"}],\"url\":\"https://www.semanticscholar.org/paper/8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"