"{\"abstract\":\"Effective defense of deep neural networks against adversarial attacks remains a challenging problem, especially under powerful white-box attacks. In this paper, we develop a new method called ensemble generative cleaning with feedback loops (EGC-FL) for effective defense of deep neural networks. The proposed EGC-FL method is based on two central ideas. First, we introduce a transformed deadzone layer into the defense network, which consists of an orthonormal transform and a deadzone-based activation function, to destroy the sophisticated noise pattern of adversarial attacks. Second, by constructing a generative cleaning network with a feedback loop, we are able to generate an ensemble of diverse estimations of the original clean image. We then learn a network to fuse this set of diverse estimations together to restore the original image. Our extensive experimental results demonstrate that our approach improves the state-of-art by large margins in both white-box and black-box attacks. It significantly improves the classification accuracy for white-box PGD attacks upon the second best method by more than 29% on the SVHN dataset and more than 39% on the challenging CIFAR-10 dataset.\",\"arxivId\":\"2004.11273\",\"authors\":[{\"authorId\":\"26603522\",\"name\":\"Jianhe Yuan\",\"url\":\"https://www.semanticscholar.org/author/26603522\"},{\"authorId\":\"1700714\",\"name\":\"Z. He\",\"url\":\"https://www.semanticscholar.org/author/1700714\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":216080713,\"doi\":\"10.1109/cvpr42600.2020.00066\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"57fc9eda62ce168bd69cd76e308f8e137dc56077\",\"references\":[{\"arxivId\":\"1902.07623\",\"authors\":[{\"authorId\":\"27623787\",\"name\":\"G. W. Ding\"},{\"authorId\":\"48169460\",\"name\":\"Luyu Wang\"},{\"authorId\":\"50562486\",\"name\":\"Xiaomeng Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f53bb893ca92f0a1b9b3d1bd2ee5de3cdb7c0da\",\"title\":\"advertorch v0.1: An Adversarial Robustness Toolbox based on PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/4f53bb893ca92f0a1b9b3d1bd2ee5de3cdb7c0da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.00117\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"2139712\",\"name\":\"Mayank Rana\"},{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"title\":\"Countering Adversarial Images using Input Transformations\",\"url\":\"https://www.semanticscholar.org/paper/e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Harini Kannan\"},{\"authorId\":null,\"name\":\"Alexey Kurakin\"},{\"authorId\":null,\"name\":\"Ian Goodfellow\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Adversarial logit pairing, 2018\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1607.05113\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfd6dc6cf0b4c42d26e6b07b74bb544ae5effa0f\",\"title\":\"On the Effectiveness of Defensive Distillation\",\"url\":\"https://www.semanticscholar.org/paper/cfd6dc6cf0b4c42d26e6b07b74bb544ae5effa0f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1801.02613\",\"authors\":[{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":null,\"name\":\"Yisen Wang\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"2825361\",\"name\":\"S. Wijewickrema\"},{\"authorId\":\"4480560\",\"name\":\"M. E. Houle\"},{\"authorId\":\"1710013\",\"name\":\"Grant Schoenebeck\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a18ada04d93981178234d9c8907fb99ea92fddcb\",\"title\":\"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\",\"url\":\"https://www.semanticscholar.org/paper/a18ada04d93981178234d9c8907fb99ea92fddcb\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47619311\",\"name\":\"J. Buckman\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"title\":\"Thermometer Encoding: One Hot Way To Resist Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1706.04701\",\"authors\":[{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"145604979\",\"name\":\"J. Wei\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"title\":\"Adversarial Example Defense: Ensembles of Weak Defenses are not Strong\",\"url\":\"https://www.semanticscholar.org/paper/6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"venue\":\"WOOT\",\"year\":2017},{\"arxivId\":\"1708.02582\",\"authors\":[{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"2813905\",\"name\":\"J. H. Ko\"},{\"authorId\":\"144192725\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a710be199c8eb43f465c88fc4b343267c35d38\",\"title\":\"Cascade Adversarial Machine Learning Regularized with a Unified Embedding\",\"url\":\"https://www.semanticscholar.org/paper/45a710be199c8eb43f465c88fc4b343267c35d38\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1607.04311\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"975b6ec05f04662a967af8c7504b7f552a0ee0bd\",\"title\":\"Defensive Distillation is Not Robust to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/975b6ec05f04662a967af8c7504b7f552a0ee0bd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":\"1511.04508\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"37785191\",\"name\":\"Xi Wu\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/SP.2016.41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"title\":\"Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"venue\":\"2016 IEEE Symposium on Security and Privacy (SP)\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1705.09064\",\"authors\":[{\"authorId\":\"24553949\",\"name\":\"Dongyu Meng\"},{\"authorId\":null,\"name\":\"Hao Chen\"}],\"doi\":\"10.1145/3133956.3134057\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63a010c69f00e65c946a68b546bbd42cbed03564\",\"title\":\"MagNet: A Two-Pronged Defense against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/63a010c69f00e65c946a68b546bbd42cbed03564\",\"venue\":\"CCS\",\"year\":2017},{\"arxivId\":\"1801.02610\",\"authors\":[{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"39037167\",\"name\":\"M. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.24963/ijcai.2018/543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5577abcc1fbf57d66017e3b5b2211a82022842c\",\"title\":\"Generating Adversarial Examples with Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d5577abcc1fbf57d66017e3b5b2211a82022842c\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":\"1704.01155\",\"authors\":[{\"authorId\":\"50231973\",\"name\":\"Weilin Xu\"},{\"authorId\":\"145685504\",\"name\":\"David Evans\"},{\"authorId\":\"1791105\",\"name\":\"Y. Qi\"}],\"doi\":\"10.14722/ndss.2018.23198\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"title\":\"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1811.09310\",\"authors\":[{\"authorId\":\"26995571\",\"name\":\"Adnan Siraj Rakin\"},{\"authorId\":\"3441899\",\"name\":\"Zhezhi He\"},{\"authorId\":\"37587676\",\"name\":\"Deliang Fan\"}],\"doi\":\"10.1109/CVPR.2019.00068\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3636d3f0562f3ab5f5df68c1c9a23530c0fbce64\",\"title\":\"Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness Against Adversarial Attack\",\"url\":\"https://www.semanticscholar.org/paper/3636d3f0562f3ab5f5df68c1c9a23530c0fbce64\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50121148\",\"name\":\"G. K. Wallace\"}],\"doi\":\"10.1145/103085.103089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e190281cc49c07bce64d037fb24705bb9296b9b\",\"title\":\"The JPEG still picture compression standard\",\"url\":\"https://www.semanticscholar.org/paper/9e190281cc49c07bce64d037fb24705bb9296b9b\",\"venue\":\"CACM\",\"year\":1991},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1803.06978\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"title\":\"Improving Transferability of Adversarial Examples With Input Diversity\",\"url\":\"https://www.semanticscholar.org/paper/f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.09591\",\"authors\":[{\"authorId\":\"1825155\",\"name\":\"Huaxia Wang\"},{\"authorId\":\"40040135\",\"name\":\"C. Yu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"04ee17ea05341aadc8643a21d21746cb67993a9d\",\"title\":\"A Direct Approach to Robust Deep Learning Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/04ee17ea05341aadc8643a21d21746cb67993a9d\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34180232\",\"name\":\"Yuval Netzer\"},{\"authorId\":\"17929104\",\"name\":\"T. Wang\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"1726358\",\"name\":\"A. Bissacco\"},{\"authorId\":\"144397975\",\"name\":\"B. Wu\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02227c94dd41fe0b439e050d377b0beb5d427cda\",\"title\":\"Reading Digits in Natural Images with Unsupervised Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/02227c94dd41fe0b439e050d377b0beb5d427cda\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1812.00037\",\"authors\":[{\"authorId\":\"47935294\",\"name\":\"Bo Sun\"},{\"authorId\":\"38614369\",\"name\":\"Nian-hsuan Tsai\"},{\"authorId\":\"32324034\",\"name\":\"Fangchen Liu\"},{\"authorId\":\"9965153\",\"name\":\"Ronald Yu\"},{\"authorId\":\"144914140\",\"name\":\"H. Su\"}],\"doi\":\"10.1109/CVPR.2019.01171\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c245dbb07a85fb0be8cc9aecb98a223dc48bce63\",\"title\":\"Adversarial Defense by Stratified Convolutional Sparse Coding\",\"url\":\"https://www.semanticscholar.org/paper/c245dbb07a85fb0be8cc9aecb98a223dc48bce63\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Warde-Farley\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"11 adversarial perturbations of deep neural networks. Perturbations\",\"url\":\"\",\"venue\":\"Optimization, and Statistics,\",\"year\":2016},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1811.12673\",\"authors\":[{\"authorId\":\"144890263\",\"name\":\"Xiaojun Jia\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/CVPR.2019.00624\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33e3ea69244ac597d61b9e31098b02fbfccd086d\",\"title\":\"ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/33e3ea69244ac597d61b9e31098b02fbfccd086d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.01442\",\"authors\":[{\"authorId\":\"16404879\",\"name\":\"Guneet S. Dhillon\"},{\"authorId\":\"3371922\",\"name\":\"Kamyar Azizzadenesheli\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"38267634\",\"name\":\"J. Bernstein\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"19268451\",\"name\":\"A. Khanna\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"title\":\"Stochastic Activation Pruning for Robust Adversarial Defense\",\"url\":\"https://www.semanticscholar.org/paper/2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1710.10766\",\"authors\":[{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"1684887\",\"name\":\"Nate Kushman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"title\":\"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"venue\":\"ICLR\",\"year\":2018}],\"title\":\"Ensemble Generative Cleaning With Feedback Loops for Defending Adversarial Attacks\",\"topics\":[{\"topic\":\"Feedback\",\"topicId\":\"242\",\"url\":\"https://www.semanticscholar.org/topic/242\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Plasma cleaning\",\"topicId\":\"904834\",\"url\":\"https://www.semanticscholar.org/topic/904834\"},{\"topic\":\"Activation function\",\"topicId\":\"84273\",\"url\":\"https://www.semanticscholar.org/topic/84273\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"}],\"url\":\"https://www.semanticscholar.org/paper/57fc9eda62ce168bd69cd76e308f8e137dc56077\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"