"{\"abstract\":\"Adversarial examples cause neural networks to produce incorrect outputs with high confidence. Although adversarial training is one of the most effective forms of defense against adversarial examples, unfortunately, a large gap exists between test accuracy and training accuracy in adversarial training. In this paper, we identify Adversarial Feature Overfitting (AFO), which may cause poor adversarially robust generalization, and we show that adversarial training can overshoot the optimal point in terms of robust generalization, leading to AFO in our simple Gaussian model. Considering these theoretical results, we present soft labeling as a solution to the AFO problem. Furthermore, we propose Adversarial Vertex mixup (AVmixup), a soft-labeled data augmentation approach for improving adversarially robust generalization. We complement our theoretical analysis with experiments on CIFAR10, CIFAR100, SVHN, and Tiny ImageNet, and show that AVmixup significantly improves the robust generalization performance and that it reduces the trade-off between standard accuracy and adversarial robustness.\",\"arxivId\":\"2003.02484\",\"authors\":[{\"authorId\":\"6732273\",\"name\":\"Saehyung Lee\",\"url\":\"https://www.semanticscholar.org/author/6732273\"},{\"authorId\":\"3135462\",\"name\":\"H. Lee\",\"url\":\"https://www.semanticscholar.org/author/3135462\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\",\"url\":\"https://www.semanticscholar.org/author/2999019\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2011.00593\",\"authors\":[{\"authorId\":\"144130492\",\"name\":\"Kevin J Liang\"},{\"authorId\":\"3314779\",\"name\":\"Weituo Hao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1652060942\",\"name\":\"Yufan Zhou\"},{\"authorId\":\"47482448\",\"name\":\"W. Chen\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8f6eb89897c5880a99748f23c3d3763346eea45\",\"title\":\"MixKD: Towards Efficient Distillation of Large-scale Language Models\",\"url\":\"https://www.semanticscholar.org/paper/e8f6eb89897c5880a99748f23c3d3763346eea45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05086\",\"authors\":[{\"authorId\":\"49576470\",\"name\":\"Yaoqing Yang\"},{\"authorId\":\"48351890\",\"name\":\"Rekha Khanna\"},{\"authorId\":\"29001000\",\"name\":\"Yaodong Yu\"},{\"authorId\":\"10419477\",\"name\":\"A. Gholami\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"},{\"authorId\":\"144307989\",\"name\":\"J. Gonzalez\"},{\"authorId\":\"144161012\",\"name\":\"K. Ramchandran\"},{\"authorId\":\"1717098\",\"name\":\"M. W. Mahoney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ee49e33b7e7b7a3a8c3af354cfb735ab08af31d\",\"title\":\"Boundary thickness and robustness in learning models\",\"url\":\"https://www.semanticscholar.org/paper/3ee49e33b7e7b7a3a8c3af354cfb735ab08af31d\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.00467\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"98182791\",\"name\":\"Xian Yang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"1739163379\",\"name\":\"Jun Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"title\":\"Bag of Tricks for Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12050\",\"authors\":[{\"authorId\":\"51162868\",\"name\":\"Chih-Hui Ho\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f3301984e50aebe52768cd1235c6a92028c8b19\",\"title\":\"Contrastive Learning with Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/2f3301984e50aebe52768cd1235c6a92028c8b19\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.04419\",\"authors\":[{\"authorId\":\"50346446\",\"name\":\"Vikas Verma\"},{\"authorId\":\"1707242\",\"name\":\"Minh-Thang Luong\"},{\"authorId\":\"1392876047\",\"name\":\"Kenji Kawaguchi\"},{\"authorId\":\"143950636\",\"name\":\"Hieu Pham\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df61b8703b81d0d44b90a16fa7e58e3f434cc228\",\"title\":\"Towards Domain-Agnostic Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/df61b8703b81d0d44b90a16fa7e58e3f434cc228\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":212414667,\"doi\":\"10.1109/cvpr42600.2020.00035\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"365fb36b15f13c0c69596a9fc98ddcaed3fe739c\",\"references\":[{\"arxivId\":\"1710.09412\",\"authors\":[{\"authorId\":\"48212395\",\"name\":\"Hongyi Zhang\"},{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"1401804750\",\"name\":\"David Lopez-Paz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4feef0fd284feb1233399b400eb897f59ec92755\",\"title\":\"mixup: Beyond Empirical Risk Minimization\",\"url\":\"https://www.semanticscholar.org/paper/4feef0fd284feb1233399b400eb897f59ec92755\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730609\",\"name\":\"O. Chapelle\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"50560492\",\"name\":\"V. Vapnik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39664b871e5b90aa0f82d89469a230d9ecd02498\",\"title\":\"Vicinal Risk Minimization\",\"url\":\"https://www.semanticscholar.org/paper/39664b871e5b90aa0f82d89469a230d9ecd02498\",\"venue\":\"NIPS\",\"year\":2000},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1704.01155\",\"authors\":[{\"authorId\":\"50231973\",\"name\":\"Weilin Xu\"},{\"authorId\":\"145685504\",\"name\":\"David Evans\"},{\"authorId\":\"1791105\",\"name\":\"Y. Qi\"}],\"doi\":\"10.14722/ndss.2018.23198\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"title\":\"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1702.04267\",\"authors\":[{\"authorId\":\"2708564\",\"name\":\"J. H. Metzen\"},{\"authorId\":\"3081854\",\"name\":\"Tim Genewein\"},{\"authorId\":\"47092548\",\"name\":\"Volker Fischer\"},{\"authorId\":\"3452473\",\"name\":\"B. Bischoff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"531e3a7b7768f199fdd401b266504db245ca039a\",\"title\":\"On Detecting Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/531e3a7b7768f199fdd401b266504db245ca039a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"47324530\",\"name\":\"V. Verma\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1145/3338501.3357369\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d15683422ffa9c044c2a90f45ea0ff845de83d9\",\"title\":\"Interpolated Adversarial Training: Achieving Robust Neural Networks Without Sacrificing Too Much Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/6d15683422ffa9c044c2a90f45ea0ff845de83d9\",\"venue\":\"AISec@CCS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"35188630\",\"name\":\"G. Dahl\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"14902530\",\"name\":\"P. Nguyen\"},{\"authorId\":\"98801017\",\"name\":\"Tara Sainath\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e33cbb25a8c7390aec6a398e36381f4f7770c283\",\"title\":\"Deep Neural Networks for Acoustic Modeling in Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e33cbb25a8c7390aec6a398e36381f4f7770c283\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1906.06784\",\"authors\":[{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"47324418\",\"name\":\"V. Verma\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1baf7448852b85baa93fd8d27a5f6f9afef37e32\",\"title\":\"Interpolated Adversarial Training: Achieving Robust Neural Networks without Sacrificing Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1baf7448852b85baa93fd8d27a5f6f9afef37e32\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.08598\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"32815692\",\"name\":\"Jessy Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"title\":\"Black-box Adversarial Attacks with Limited Queries and Information\",\"url\":\"https://www.semanticscholar.org/paper/b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1905.02175\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"78730080\",\"name\":\"B. Tran\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":\"10.23915/DISTILL.00019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd\",\"title\":\"Adversarial Examples Are Not Bugs, They Are Features\",\"url\":\"https://www.semanticscholar.org/paper/1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34180232\",\"name\":\"Yuval Netzer\"},{\"authorId\":\"17929104\",\"name\":\"T. Wang\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"1726358\",\"name\":\"A. Bissacco\"},{\"authorId\":\"144397975\",\"name\":\"B. Wu\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02227c94dd41fe0b439e050d377b0beb5d427cda\",\"title\":\"Reading Digits in Natural Images with Unsupervised Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/02227c94dd41fe0b439e050d377b0beb5d427cda\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1710.08864\",\"authors\":[{\"authorId\":\"1730754\",\"name\":\"Jiawei Su\"},{\"authorId\":\"145197293\",\"name\":\"Danilo Vasconcellos Vargas\"},{\"authorId\":\"145106127\",\"name\":\"K. Sakurai\"}],\"doi\":\"10.1109/TEVC.2019.2890858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"title\":\"One Pixel Attack for Fooling Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1712.04248\",\"authors\":[{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"title\":\"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1705.09064\",\"authors\":[{\"authorId\":\"24553949\",\"name\":\"Dongyu Meng\"},{\"authorId\":null,\"name\":\"Hao Chen\"}],\"doi\":\"10.1145/3133956.3134057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63a010c69f00e65c946a68b546bbd42cbed03564\",\"title\":\"MagNet: A Two-Pronged Defense against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/63a010c69f00e65c946a68b546bbd42cbed03564\",\"venue\":\"CCS\",\"year\":2017},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1610.08401\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"145602557\",\"name\":\"Omar Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2017.17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16aa01ca0834a924c25faad5d8bfef3fd1acfcfe\",\"title\":\"Universal Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/16aa01ca0834a924c25faad5d8bfef3fd1acfcfe\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1701.06548\",\"authors\":[{\"authorId\":\"2627937\",\"name\":\"G. Pereyra\"},{\"authorId\":\"145499435\",\"name\":\"G. Tucker\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ce1922802169f757bbafc6e087cc274a867c763\",\"title\":\"Regularizing Neural Networks by Penalizing Confident Output Distributions\",\"url\":\"https://www.semanticscholar.org/paper/6ce1922802169f757bbafc6e087cc274a867c763\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1804.11285\",\"authors\":[{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"35210462\",\"name\":\"Kunal Talwar\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"804fb9542f4f56e264dd2df57c255a9a2011c00f\",\"title\":\"Adversarially Robust Generalization Requires More Data\",\"url\":\"https://www.semanticscholar.org/paper/804fb9542f4f56e264dd2df57c255a9a2011c00f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1605.07146\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.87\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c4e9156ca07705531e45960b7a919dc473abb51\",\"title\":\"Wide Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c4e9156ca07705531e45960b7a919dc473abb51\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1905.07121\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"31693738\",\"name\":\"Jacob R. Gardner\"},{\"authorId\":\"10670082\",\"name\":\"Yurong You\"},{\"authorId\":\"145771261\",\"name\":\"A. Wilson\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65fd9ded2c411d90bcf6d38132463797754d2d21\",\"title\":\"Simple Black-box Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/65fd9ded2c411d90bcf6d38132463797754d2d21\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1704.03976\",\"authors\":[{\"authorId\":\"3213400\",\"name\":\"Takeru Miyato\"},{\"authorId\":\"35647224\",\"name\":\"S. Maeda\"},{\"authorId\":\"2877296\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"145516720\",\"name\":\"S. Ishii\"}],\"doi\":\"10.1109/TPAMI.2018.2858821\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b1c6f6521da545892f3f5dc39461584d4a27ec0\",\"title\":\"Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/4b1c6f6521da545892f3f5dc39461584d4a27ec0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1909.11515\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":null,\"name\":\"Kun Xu\"},{\"authorId\":\"47055094\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1b9d5d4cf17f5ceaf2d6798ffd594fd1d017eaa\",\"title\":\"Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/e1b9d5d4cf17f5ceaf2d6798ffd594fd1d017eaa\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.04508\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"37785191\",\"name\":\"Xi Wu\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/SP.2016.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"title\":\"Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"venue\":\"2016 IEEE Symposium on Security and Privacy (SP)\",\"year\":2016},{\"arxivId\":\"1901.08573\",\"authors\":[{\"authorId\":\"40975176\",\"name\":\"Hongyang Zhang\"},{\"authorId\":\"29001000\",\"name\":\"Yaodong Yu\"},{\"authorId\":\"2784735\",\"name\":\"J. Jiao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"1701847\",\"name\":\"L. Ghaoui\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"title\":\"Theoretically Principled Trade-off between Robustness and Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1711.09404\",\"authors\":[{\"authorId\":\"50683297\",\"name\":\"A. Ross\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"title\":\"Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients\",\"url\":\"https://www.semanticscholar.org/paper/ac8e45a0451ac578f17f631fc2663ee4b98b83a9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.10764\",\"authors\":[{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":\"1519286259\",\"name\":\"JianYu Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c1006c856fefdbd6cd710e840e57153f2d6cd04\",\"title\":\"Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/2c1006c856fefdbd6cd710e840e57153f2d6cd04\",\"venue\":\"NeurIPS\",\"year\":2019}],\"title\":\"Adversarial Vertex Mixup: Toward Better Adversarially Robust Generalization\",\"topics\":[{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Linear interpolation\",\"topicId\":\"185565\",\"url\":\"https://www.semanticscholar.org/topic/185565\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Line search\",\"topicId\":\"151054\",\"url\":\"https://www.semanticscholar.org/topic/151054\"},{\"topic\":\"Consortium\",\"topicId\":\"91939\",\"url\":\"https://www.semanticscholar.org/topic/91939\"},{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Brute-force search\",\"topicId\":\"40634\",\"url\":\"https://www.semanticscholar.org/topic/40634\"},{\"topic\":\"Tiny BASIC\",\"topicId\":\"3347884\",\"url\":\"https://www.semanticscholar.org/topic/3347884\"},{\"topic\":\"Overshoot (signal)\",\"topicId\":\"42764\",\"url\":\"https://www.semanticscholar.org/topic/42764\"},{\"topic\":\"Hybrid Memory Cube\",\"topicId\":\"730470\",\"url\":\"https://www.semanticscholar.org/topic/730470\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"}],\"url\":\"https://www.semanticscholar.org/paper/365fb36b15f13c0c69596a9fc98ddcaed3fe739c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"