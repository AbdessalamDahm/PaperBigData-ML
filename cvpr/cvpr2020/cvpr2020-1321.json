"{\"abstract\":\"Taking full advantage of the information from both vision and language is critical for the video captioning task. Existing models lack adequate visual representation due to the neglect of interaction between object, and sufficient training for content-related words due to long-tailed problems. In this paper, we propose a complete video captioning system including both a novel model and an effective training strategy. Specifically, we propose an object relational graph (ORG) based encoder, which captures more detailed interaction features to enrich visual representation. Meanwhile, we design a teacher-recommended learning (TRL) method to make full use of the successful external language model (ELM) to integrate the abundant linguistic knowledge into the caption model. The ELM generates more semantically similar word proposals which extend the groundtruth words used for training to deal with the long-tailed problem. Experimental evaluations on three benchmarks: MSVD, MSR-VTT and VATEX show the proposed ORG-TRL system achieves state-of-the-art performance. Extensive ablation studies and visualizations illustrate the effectiveness of our system.\",\"arxivId\":\"2002.11566\",\"authors\":[{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\",\"url\":\"https://www.semanticscholar.org/author/36811682\"},{\"authorId\":\"37198550\",\"name\":\"Yaya Shi\",\"url\":\"https://www.semanticscholar.org/author/37198550\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\",\"url\":null},{\"authorId\":null,\"name\":\"Bing Li\",\"url\":null},{\"authorId\":\"39397292\",\"name\":\"Peijin Wang\",\"url\":\"https://www.semanticscholar.org/author/39397292\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\",\"url\":\"https://www.semanticscholar.org/author/48594951\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\",\"url\":\"https://www.semanticscholar.org/author/143962510\"}],\"citationVelocity\":7,\"citations\":[{\"arxivId\":\"2007.01951\",\"authors\":[{\"authorId\":\"46659782\",\"name\":\"L. Wang\"},{\"authorId\":\"2574085\",\"name\":\"Jui-Ting Huang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"151485141\",\"name\":\"Kun Xu\"},{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":null,\"name\":\"Dong Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81a1ad1a0093b19f52242219a4ebd4b4164a037b\",\"title\":\"Improving Weakly Supervised Visual Grounding by Contrastive Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/81a1ad1a0093b19f52242219a4ebd4b4164a037b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07203\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"40052301\",\"name\":\"F. Petroni\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"title\":\"Video Understanding as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05937\",\"authors\":[{\"authorId\":null,\"name\":\"Lin Wang\"},{\"authorId\":\"51182421\",\"name\":\"Kuk-Jin Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2528a82dd2266600d4ee2b54165556a984de94d4\",\"title\":\"Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks\",\"url\":\"https://www.semanticscholar.org/paper/2528a82dd2266600d4ee2b54165556a984de94d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11760\",\"authors\":[{\"authorId\":\"24040986\",\"name\":\"Gabriel Huang\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"2062703\",\"name\":\"Z. Zhu\"},{\"authorId\":\"66193113\",\"name\":\"C. Rivera\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bacd2f2a70d756f108ad889b6bcddc79cc1ce51\",\"title\":\"Multimodal Pretraining for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2bacd2f2a70d756f108ad889b6bcddc79cc1ce51\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"1909.00121\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"145468578\",\"name\":\"Ke Lin\"},{\"authorId\":\"1772128\",\"name\":\"A. Maye\"},{\"authorId\":\"47786863\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3389/frobt.2020.475767\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"304f94dbe2ed228309e86298766ad24d9b6c6747\",\"title\":\"A Semantics-Assisted Video Captioning Model Trained With Scheduled Sampling\",\"url\":\"https://www.semanticscholar.org/paper/304f94dbe2ed228309e86298766ad24d9b6c6747\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"2009.01067\",\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"title\":\"Video Captioning Using Weak Annotation\",\"url\":\"https://www.semanticscholar.org/paper/aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.07335\",\"authors\":[{\"authorId\":\"16286752\",\"name\":\"Md. Mushfiqur Rahman\"},{\"authorId\":\"1945520590\",\"name\":\"Thasin Abedin\"},{\"authorId\":\"1945917684\",\"name\":\"Khondokar S. S. Prottoy\"},{\"authorId\":\"1945917586\",\"name\":\"Ayana Moshruba\"},{\"authorId\":\"32826273\",\"name\":\"F. H. Siddiqui\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2a0c5a1d5ae87ae734da2ef9c5eac6b2146536b\",\"title\":\"Semantically Sensible Video Captioning (SSVC)\",\"url\":\"https://www.semanticscholar.org/paper/e2a0c5a1d5ae87ae734da2ef9c5eac6b2146536b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993672539\",\"name\":\"Soumil Kanwal\"},{\"authorId\":\"1993398975\",\"name\":\"Vineet Mehta\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"}],\"doi\":\"10.1145/3394171.3416302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d51986070dbf6b76db4e553faf7dc301655e3ce4\",\"title\":\"Large Scale Hierarchical Anomaly Detection and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/d51986070dbf6b76db4e553faf7dc301655e3ce4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.02824\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144721617\",\"name\":\"Y. Asano\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"145414740\",\"name\":\"J. Henriques\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"title\":\"Support-set bottlenecks for video-text representation learning\",\"url\":\"https://www.semanticscholar.org/paper/78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.14752\",\"authors\":[{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"title\":\"A Comprehensive Review on Recent Methods and Challenges of Video Description\",\"url\":\"https://www.semanticscholar.org/paper/baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"1790251284\",\"name\":\"Lin Li\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"9594118\",\"name\":\"C. Gu\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/s11063-020-10352-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"title\":\"Adaptively Converting Auxiliary Attributes and Textual Embedding for Video Captioning Based on BiLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"venue\":\"Neural Process. Lett.\",\"year\":2020}],\"corpusId\":211506001,\"doi\":\"10.1109/cvpr42600.2020.01329\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f1dd557a8839733a5ee06d19989a265e61f603c1\",\"references\":[{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1803.11438\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"37378985\",\"name\":\"Wei Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00795\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba7405516e1408f0ee6e0d0a8c6d511ce33c0551\",\"title\":\"Reconstruction Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ba7405516e1408f0ee6e0d0a8c6d511ce33c0551\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Linjie Li\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yu Cheng\"},{\"authorId\":null,\"name\":\"Jingjing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Kipf and Max Welling . Semi - supervised classification with graph convolutional networks\",\"url\":\"\",\"venue\":\"3 rd International Conference on Learning Representations , ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1813915\",\"name\":\"S. Liu\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1145/3240508.3240667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"849642b4701ac11c035326069f707f23a51a6f1a\",\"title\":\"SibNet: Sibling Convolutional Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/849642b4701ac11c035326069f707f23a51a6f1a\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1708.06426\",\"authors\":[{\"authorId\":\"8401284\",\"name\":\"Anuroop Sriram\"},{\"authorId\":\"35450887\",\"name\":\"Heewoo Jun\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"}],\"doi\":\"10.21437/Interspeech.2018-1392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33125ec92a0b4b1687ccd153762d6275668e3d09\",\"title\":\"Cold Fusion: Training Seq2Seq Models Together with Language Models\",\"url\":\"https://www.semanticscholar.org/paper/33125ec92a0b4b1687ccd153762d6275668e3d09\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387016\",\"name\":\"Ziwei Yang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"50219447\",\"name\":\"Zheng Wang\"}],\"doi\":\"10.1145/3123266.3123327\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc2e6431a7092fb11418b79ca1c41a76b811ea0\",\"title\":\"Catching the Temporal Regions-of-Interest for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/abc2e6431a7092fb11418b79ca1c41a76b811ea0\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pietro Li\\u00f2\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Alemi . Inception - v 4 , inception - resnet and the impact of residual connections on learning\",\"url\":\"\",\"venue\":\"Proceed - ings of the Thirty - First AAAI Conference on Artificial Intelligence IEEE Conference on Computer Vision and Pattern Recognition , CVPR\",\"year\":2015},{\"arxivId\":\"1905.03966\",\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"49050519\",\"name\":\"Jiyuan Zhang\"},{\"authorId\":\"47119038\",\"name\":\"X. Wang\"},{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/CVPR.2019.00854\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"title\":\"Memory-Attended Recurrent Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.07243\",\"authors\":[{\"authorId\":\"1410126033\",\"name\":\"Will Norcliffe-Brown\"},{\"authorId\":\"2019087\",\"name\":\"Efstathios Vafeias\"},{\"authorId\":\"1398036715\",\"name\":\"Sarah Parisot\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ac33d3dcecbed17580509a34bccdff2425f7ed8\",\"title\":\"Learning Conditioned Graph Structures for Interpretable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ac33d3dcecbed17580509a34bccdff2425f7ed8\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1803.01457\",\"authors\":[{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"47527850\",\"name\":\"W. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1007/978-3-030-01261-8_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"title\":\"Less Is More: Picking Informative Frames for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1906.07155\",\"authors\":[{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"3058654\",\"name\":\"J. Wang\"},{\"authorId\":\"49968574\",\"name\":\"Jiangmiao Pang\"},{\"authorId\":\"50206929\",\"name\":\"Y. Cao\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"48569853\",\"name\":\"X. Li\"},{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"66165285\",\"name\":\"Wansen Feng\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"7169566\",\"name\":\"J. Xu\"},{\"authorId\":\"143644345\",\"name\":\"Zheng Zhang\"},{\"authorId\":\"48573140\",\"name\":\"Dazhi Cheng\"},{\"authorId\":\"47894545\",\"name\":\"Chenchen Zhu\"},{\"authorId\":\"46806979\",\"name\":\"Tianheng Cheng\"},{\"authorId\":\"2273005\",\"name\":\"Qijie Zhao\"},{\"authorId\":\"40940627\",\"name\":\"Buyu Li\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"144649568\",\"name\":\"Rui Zhu\"},{\"authorId\":\"144319631\",\"name\":\"Y. Wu\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2c083df88e88223e1a411e61040b94c233b1b63\",\"title\":\"MMDetection: Open MMLab Detection Toolbox and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c2c083df88e88223e1a411e61040b94c233b1b63\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Linjie Li\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yu Cheng\"},{\"authorId\":null,\"name\":\"Jingjing Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Relationaware graph attention network for visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":1903},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/ICCV.2019.00901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"title\":\"Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1712.01996\",\"authors\":[{\"authorId\":\"31801501\",\"name\":\"A. Kannan\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"14902530\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"51296765\",\"name\":\"Zhijeng Chen\"},{\"authorId\":\"2557391\",\"name\":\"Rohit Prabhavalkar\"}],\"doi\":\"10.1109/ICASSP.2018.8462682\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"478d6102a2df86b0f4e69e398f96619312ecdc8c\",\"title\":\"An Analysis of Incorporating an External Language Model into a Sequence-to-Sequence Model\",\"url\":\"https://www.semanticscholar.org/paper/478d6102a2df86b0f4e69e398f96619312ecdc8c\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1511.03476\",\"authors\":[{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2016.117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9a66904559011d48245bba01e55f72246927e77\",\"title\":\"Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e9a66904559011d48245bba01e55f72246927e77\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Linjie Li\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yu Cheng\"},{\"authorId\":null,\"name\":\"Jingjing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Relationaware graph attention network for visual question answering. CoRR, abs\",\"url\":\"\",\"venue\":\"\",\"year\":1903},{\"arxivId\":\"1906.02365\",\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144864336\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2909864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"title\":\"Context-Aware Visual Policy Network for Fine-Grained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035\",\"title\":\"Improving Language Understanding by Generative Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1907.06017\",\"authors\":[{\"authorId\":\"48442772\",\"name\":\"Ye Bai\"},{\"authorId\":\"3491973\",\"name\":\"Jiangyan Yi\"},{\"authorId\":\"47060742\",\"name\":\"J. Tao\"},{\"authorId\":\"150358126\",\"name\":\"Z. Tian\"},{\"authorId\":\"1718662\",\"name\":\"Zhengqi Wen\"}],\"doi\":\"10.21437/interspeech.2019-1554\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeec7b8ae2b63d0b8ffcce74a81677d48ad2c691\",\"title\":\"Learn Spelling from Teachers: Transferring Knowledge from Language Models to Sequence-to-Sequence Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aeec7b8ae2b63d0b8ffcce74a81677d48ad2c691\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018191\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"title\":\"Motion Guided Spatial Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1503.03535\",\"authors\":[{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"49955352\",\"name\":\"Huei-Chi Lin\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fcd41ca42659ff792fc8ee7d535156e8e69f987\",\"title\":\"On Using Monolingual Corpora in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/5fcd41ca42659ff792fc8ee7d535156e8e69f987\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Petar Velickovic\"},{\"authorId\":null,\"name\":\"Guillem Cucurull\"},{\"authorId\":null,\"name\":\"Arantxa Casanova\"},{\"authorId\":null,\"name\":\"Adriana Romero\"},{\"authorId\":null,\"name\":\"Pietro Li\\u00f2\"},{\"authorId\":null,\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph attention networks. CoRR\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7741774\",\"name\":\"Y. Hu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1145/3343031.3351072\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"db6035229a71a6c93d4f15c4a4280eb644228da4\",\"title\":\"Hierarchical Global-Local Temporal Modeling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/db6035229a71a6c93d4f15c4a4280eb644228da4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1711.06640\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"38094552\",\"name\":\"Sam Thomson\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2018.00611\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"title\":\"Neural Motifs: Scene Graph Parsing with Global Context\",\"url\":\"https://www.semanticscholar.org/paper/0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.04375\",\"authors\":[{\"authorId\":\"153389599\",\"name\":\"Junchao Zhang\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1109/CVPR.2019.00852\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6c9bd4d49d7bd70e1610c0f28fbd78ff97d0d0b5\",\"title\":\"Object-Aware Aggregation With Bidirectional Temporal Graph for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c9bd4d49d7bd70e1610c0f28fbd78ff97d0d0b5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1602.07261\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"122113652\",\"name\":\"Alexander Amir Alemi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"title\":\"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1701.06548\",\"authors\":[{\"authorId\":\"2627937\",\"name\":\"G. Pereyra\"},{\"authorId\":\"145499435\",\"name\":\"G. Tucker\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ce1922802169f757bbafc6e087cc274a867c763\",\"title\":\"Regularizing Neural Networks by Penalizing Confident Output Distributions\",\"url\":\"https://www.semanticscholar.org/paper/6ce1922802169f757bbafc6e087cc274a867c763\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1902.10322\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2019.01277\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20888a7aebaf77a306c0886f165bd0d468db806d\",\"title\":\"Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/20888a7aebaf77a306c0886f165bd0d468db806d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/CVPR.2018.00784\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b910a6f687a4e56062dc326786cee297bd60e8c1\",\"title\":\"M3: Multimodal Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b910a6f687a4e56062dc326786cee297bd60e8c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1901.00097\",\"authors\":[{\"authorId\":\"51288954\",\"name\":\"Jiarong Dong\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":\"144089410\",\"name\":\"J. Cao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fc5d77e3238a3a9d17698b35fb425cc227263be\",\"title\":\"Not All Words Are Equal: Video-specific Information Loss for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3fc5d77e3238a3a9d17698b35fb425cc227263be\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1609.02907\",\"authors\":[{\"authorId\":\"41016725\",\"name\":\"Thomas Kipf\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36eff562f65125511b5dfab68ce7f7a943c27478\",\"title\":\"Semi-Supervised Classification with Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/36eff562f65125511b5dfab68ce7f7a943c27478\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Will Kay\"},{\"authorId\":null,\"name\":\"Jo\\u00e3o Carreira\"},{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":null,\"name\":\"Brian Zhang\"},{\"authorId\":null,\"name\":\"Chloe Hillier\"},{\"authorId\":null,\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"Fabio Viola\"},{\"authorId\":null,\"name\":\"Tim Green\"},{\"authorId\":null,\"name\":\"Trevor Back\"},{\"authorId\":null,\"name\":\"Paul Natsev\"},{\"authorId\":null,\"name\":\"Mustafa Suleyman\"},{\"authorId\":null,\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The kinetics human action video\",\"url\":\"\",\"venue\":\"dataset. CoRR,\",\"year\":2017}],\"title\":\"Object Relational Graph With Teacher-Recommended Learning for Video Captioning\",\"topics\":[{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"}],\"url\":\"https://www.semanticscholar.org/paper/f1dd557a8839733a5ee06d19989a265e61f603c1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"