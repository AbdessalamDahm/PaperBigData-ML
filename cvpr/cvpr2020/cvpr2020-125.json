"{\"abstract\":\"While deep neural networks have been achieving state-of-the-art performance across a wide variety of applications, their vulnerability to adversarial attacks limits their widespread deployment for safety-critical applications. Alongside other adversarial defense approaches being investigated, there has been a very recent interest in improving adversarial robustness in deep neural networks through the introduction of perturbations during the training process. However, such methods leverage fixed, pre-defined perturbations and require significant hyper-parameter tuning that makes them very difficult to leverage in a general fashion. In this study, we introduce Learn2Perturb, an end-to-end feature perturbation learning approach for improving the adversarial robustness of deep neural networks. More specifically, we introduce novel perturbation-injection modules that are incorporated at each layer to perturb the feature space and increase uncertainty in the network. This feature perturbation is performed at both the training and the inference stages. Furthermore, inspired by the Expectation-Maximization, an alternating back-propagation training algorithm is introduced to train the network and noise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100 datasets show that the proposed Learn2Perturb method can result in deep neural networks which are 4-7% more robust on l_inf FGSM and PDG adversarial attacks and significantly outperforms the state-of-the-art against l_2 C\\\\&W attack and a wide range of well-known black-box attacks.\",\"arxivId\":\"2003.01090\",\"authors\":[{\"authorId\":\"1515531906\",\"name\":\"Ahmadreza Jeddi\",\"url\":\"https://www.semanticscholar.org/author/1515531906\"},{\"authorId\":\"35371895\",\"name\":\"M. Shafiee\",\"url\":\"https://www.semanticscholar.org/author/35371895\"},{\"authorId\":\"2326840\",\"name\":\"M. Karg\",\"url\":\"https://www.semanticscholar.org/author/2326840\"},{\"authorId\":\"1910464\",\"name\":\"C. Scharfenberger\",\"url\":\"https://www.semanticscholar.org/author/1910464\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\",\"url\":\"https://www.semanticscholar.org/author/50381441\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.06330\",\"authors\":[{\"authorId\":\"35472650\",\"name\":\"Yi Xiang Marcus Tan\"},{\"authorId\":\"31030883\",\"name\":\"Penny Chong\"},{\"authorId\":\"49991294\",\"name\":\"Jiamei Sun\"},{\"authorId\":\"1397239841\",\"name\":\"Yuval Elovici\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a6c3cce11f0c890e28db53f86e6f9c0da14a348\",\"title\":\"Detection of Adversarial Supports in Few-shot Classifiers Using Feature Preserving Autoencoders and Self-Similarity\",\"url\":\"https://www.semanticscholar.org/paper/7a6c3cce11f0c890e28db53f86e6f9c0da14a348\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.12721\",\"authors\":[{\"authorId\":\"1975413\",\"name\":\"Alireza Mehrtash\"},{\"authorId\":\"2427371\",\"name\":\"P. Abolmaesumi\"},{\"authorId\":\"1729630\",\"name\":\"P. Golland\"},{\"authorId\":\"2676616\",\"name\":\"T. Kapur\"},{\"authorId\":\"35466637\",\"name\":\"D. Wassermann\"},{\"authorId\":\"153671051\",\"name\":\"W. M. Wells\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c83a3448491e14e4f22ef895700ec34331437e2c\",\"title\":\"PEP: Parameter Ensembling by Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/c83a3448491e14e4f22ef895700ec34331437e2c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.13628\",\"authors\":[{\"authorId\":\"1515531906\",\"name\":\"Ahmadreza Jeddi\"},{\"authorId\":\"35371895\",\"name\":\"M. Shafiee\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3fccfd63590564038a4f7235b7ce5c4eddb9b33c\",\"title\":\"A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via Adversarial Fine-tuning\",\"url\":\"https://www.semanticscholar.org/paper/3fccfd63590564038a4f7235b7ce5c4eddb9b33c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.08756\",\"authors\":[{\"authorId\":\"35371895\",\"name\":\"M. Shafiee\"},{\"authorId\":\"1515531906\",\"name\":\"Ahmadreza Jeddi\"},{\"authorId\":\"38021890\",\"name\":\"A. Nazemi\"},{\"authorId\":\"93660405\",\"name\":\"P. Fieguth\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0100335c5f7dad3ddddde2458b002030ff0dc4\",\"title\":\"Deep Neural Network Perception Models and Robust Autonomous Driving Systems\",\"url\":\"https://www.semanticscholar.org/paper/7d0100335c5f7dad3ddddde2458b002030ff0dc4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35371895\",\"name\":\"M. Shafiee\"},{\"authorId\":\"1515531906\",\"name\":\"Ahmadreza Jeddi\"},{\"authorId\":\"50438354\",\"name\":\"A. Nazemi\"},{\"authorId\":\"93660405\",\"name\":\"P. Fieguth\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\"}],\"doi\":\"10.1109/MSP.2020.2982820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01ff39823ba33831e019c048537ee4be250a3fc7\",\"title\":\"Deep Neural Network Perception Models and Robust Autonomous Driving Systems: Practical Solutions for Mitigation and Improvement\",\"url\":\"https://www.semanticscholar.org/paper/01ff39823ba33831e019c048537ee4be250a3fc7\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2021},{\"arxivId\":\"2010.08852\",\"authors\":[{\"authorId\":\"25920858\",\"name\":\"Panagiotis Eustratiadis\"},{\"authorId\":\"2319565\",\"name\":\"Henry Gouk\"},{\"authorId\":\"1868538\",\"name\":\"D. Li\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"31618c4eaa98376c9ab3bec09970a11c3ea00d45\",\"title\":\"A Stochastic Neural Network for Attack-Agnostic Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/31618c4eaa98376c9ab3bec09970a11c3ea00d45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12190\",\"authors\":[{\"authorId\":\"48272627\",\"name\":\"K. Fang\"},{\"authorId\":\"50118050\",\"name\":\"Yingwen Wu\"},{\"authorId\":\"153051030\",\"name\":\"T. Li\"},{\"authorId\":\"47932717\",\"name\":\"Xiaolin Huang\"},{\"authorId\":\"145651836\",\"name\":\"Jie Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0ac8b754b6621c54bc1a77e04b0fa6d0ab5f9a94\",\"title\":\"Learn Robust Features via Orthogonal Multi-Path\",\"url\":\"https://www.semanticscholar.org/paper/0ac8b754b6621c54bc1a77e04b0fa6d0ab5f9a94\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":211677299,\"doi\":\"10.1109/cvpr42600.2020.00132\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"863b272a73ca06c819c5f9d93bdee35e4cfb7dc8\",\"references\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"This figure \\\"PGD.png\\\" is available in \\\"png\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1511.04508\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"37785191\",\"name\":\"Xi Wu\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/SP.2016.41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"title\":\"Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6adf016e7531c91100d3cf4a74f5d4c87b26b528\",\"venue\":\"2016 IEEE Symposium on Security and Privacy (SP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1903.10219\",\"authors\":[{\"authorId\":\"145533439\",\"name\":\"Alexandre Araujo\"},{\"authorId\":\"35449300\",\"name\":\"Rafael Pinot\"},{\"authorId\":\"2511985\",\"name\":\"Benjamin N\\u00e9grevergne\"},{\"authorId\":\"47516106\",\"name\":\"Laurent Meunier\"},{\"authorId\":\"1705871\",\"name\":\"Y. Chevaleyre\"},{\"authorId\":\"1783082\",\"name\":\"F. Yger\"},{\"authorId\":\"1773774\",\"name\":\"J. Atif\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d886858d9d4a4d47c8bed4d445bd658b83198ec\",\"title\":\"Robust Neural Networks using Randomized Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/6d886858d9d4a4d47c8bed4d445bd658b83198ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35449300\",\"name\":\"Rafael Pinot\"},{\"authorId\":\"47516106\",\"name\":\"Laurent Meunier\"},{\"authorId\":\"145141186\",\"name\":\"A. Ara\\u00fajo\"},{\"authorId\":\"2785830\",\"name\":\"H. Kashima\"},{\"authorId\":\"1783082\",\"name\":\"F. Yger\"},{\"authorId\":\"1398898321\",\"name\":\"C. Gouy-Pailler\"},{\"authorId\":\"1773774\",\"name\":\"J. Atif\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a416cb1cac9fb4fecad49af1ff07e2523c99cfe\",\"title\":\"Theoretical evidence for adversarial robustness through randomization\",\"url\":\"https://www.semanticscholar.org/paper/4a416cb1cac9fb4fecad49af1ff07e2523c99cfe\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1712.00673\",\"authors\":[{\"authorId\":\"23979212\",\"name\":\"Xuanqing Liu\"},{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1007/978-3-030-01234-2_23\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1cf361d02f5ad84567e48754f1a8f895653bc701\",\"title\":\"Towards Robust Neural Networks via Random Self-ensemble\",\"url\":\"https://www.semanticscholar.org/paper/1cf361d02f5ad84567e48754f1a8f895653bc701\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1803.05598\",\"authors\":[{\"authorId\":\"7843061\",\"name\":\"Gamaleldin F. Elsayed\"},{\"authorId\":\"1707347\",\"name\":\"Dilip Krishnan\"},{\"authorId\":\"3232655\",\"name\":\"H. Mobahi\"},{\"authorId\":\"144389412\",\"name\":\"Kevin Regan\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06f35a25c12d33a93578711eccf7cceab4e66d54\",\"title\":\"Large Margin Deep Networks for Classification\",\"url\":\"https://www.semanticscholar.org/paper/06f35a25c12d33a93578711eccf7cceab4e66d54\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50495880\",\"name\":\"Tian Han\"},{\"authorId\":\"47006165\",\"name\":\"Y. Lu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d07cf9bf54add8651f5cc8493cca50ef030ff9ba\",\"title\":\"Alternating Back-Propagation for Generator Network\",\"url\":\"https://www.semanticscholar.org/paper/d07cf9bf54add8651f5cc8493cca50ef030ff9ba\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1605.07277\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"78aa018ee7d52360e15d103390ea1cdb3a0beb41\",\"title\":\"Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/78aa018ee7d52360e15d103390ea1cdb3a0beb41\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1810.01279\",\"authors\":[{\"authorId\":\"23979212\",\"name\":\"Xuanqing Liu\"},{\"authorId\":\"48514899\",\"name\":\"Y. Li\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c1f76891bdfa07d9a61ad11a15de13b139b20d2a\",\"title\":\"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c1f76891bdfa07d9a61ad11a15de13b139b20d2a\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1707.07397\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"143883029\",\"name\":\"Kevin Kwok\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"title\":\"Synthesizing Robust Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1811.09310\",\"authors\":[{\"authorId\":\"26995571\",\"name\":\"Adnan Siraj Rakin\"},{\"authorId\":\"3441899\",\"name\":\"Zhezhi He\"},{\"authorId\":\"37587676\",\"name\":\"Deliang Fan\"}],\"doi\":\"10.1109/CVPR.2019.00068\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3636d3f0562f3ab5f5df68c1c9a23530c0fbce64\",\"title\":\"Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness Against Adversarial Attack\",\"url\":\"https://www.semanticscholar.org/paper/3636d3f0562f3ab5f5df68c1c9a23530c0fbce64\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.01128\",\"authors\":[{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1609/AAAI.V34I04.5767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdfbabfd7b3712a4c2cb864ca0ca5c201dfee5a1\",\"title\":\"Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/fdfbabfd7b3712a4c2cb864ca0ca5c201dfee5a1\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1801.00553\",\"authors\":[{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/ACCESS.2018.2807385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b514949ad8344071c0f342f182390d2d88bcc26d\",\"title\":\"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b514949ad8344071c0f342f182390d2d88bcc26d\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2980660\",\"name\":\"Shizhao Sun\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"1700438\",\"name\":\"X. Liu\"},{\"authorId\":\"152998017\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb8043fc95475ae862c13fba290d5b737b36bd3b\",\"title\":\"On the Depth of Deep Neural Networks: A Theoretical View\",\"url\":\"https://www.semanticscholar.org/paper/bb8043fc95475ae862c13fba290d5b737b36bd3b\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1802.03471\",\"authors\":[{\"authorId\":\"2574478\",\"name\":\"Mathias L\\u00e9cuyer\"},{\"authorId\":\"2501382\",\"name\":\"Vaggelis Atlidakis\"},{\"authorId\":\"1972091\",\"name\":\"Roxana Geambasu\"},{\"authorId\":\"46533534\",\"name\":\"D. Hsu\"},{\"authorId\":\"39400201\",\"name\":\"Suman Jana\"}],\"doi\":\"10.1109/SP.2019.00044\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e86a51d1f2051ab8f448b66c6dcc17924d17cfa\",\"title\":\"Certified Robustness to Adversarial Examples with Differential Privacy\",\"url\":\"https://www.semanticscholar.org/paper/3e86a51d1f2051ab8f448b66c6dcc17924d17cfa\",\"venue\":\"2019 IEEE Symposium on Security and Privacy (SP)\",\"year\":2019},{\"arxivId\":\"1801.01944\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SPW.2018.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a5704ac5fdacb7121a0c02a9be4de2bdc5a40fc\",\"title\":\"Audio Adversarial Examples: Targeted Attacks on Speech-to-Text\",\"url\":\"https://www.semanticscholar.org/paper/6a5704ac5fdacb7121a0c02a9be4de2bdc5a40fc\",\"venue\":\"2018 IEEE Security and Privacy Workshops (SPW)\",\"year\":2018},{\"arxivId\":\"1607.05113\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfd6dc6cf0b4c42d26e6b07b74bb544ae5effa0f\",\"title\":\"On the Effectiveness of Defensive Distillation\",\"url\":\"https://www.semanticscholar.org/paper/cfd6dc6cf0b4c42d26e6b07b74bb544ae5effa0f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rafael Pinot\"},{\"authorId\":null,\"name\":\"Laurent Meunier\"},{\"authorId\":null,\"name\":\"Alexandre Araujo\"},{\"authorId\":null,\"name\":\"Hisashi Kashima\"},{\"authorId\":null,\"name\":\"Florian Yger\"},{\"authorId\":null,\"name\":\"C\\u00e9dric Gouy-Pailler\"},{\"authorId\":null,\"name\":\"Jamal Atif\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Theoretical evidence for adversarial robustness\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1902.01148,\",\"year\":2019},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1901.08573\",\"authors\":[{\"authorId\":\"40975176\",\"name\":\"Hongyang Zhang\"},{\"authorId\":\"29001000\",\"name\":\"Yaodong Yu\"},{\"authorId\":\"2784735\",\"name\":\"J. Jiao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"1701847\",\"name\":\"L. Ghaoui\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"title\":\"Theoretically Principled Trade-off between Robustness and Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2269602\",\"name\":\"A. Bietti\"},{\"authorId\":\"51888120\",\"name\":\"Gr\\u00e9goire Mialon\"},{\"authorId\":\"81299639\",\"name\":\"Dexiong Chen\"},{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd93512eabdae6409f9935ee6e1fa99c3652e3ef\",\"title\":\"A Kernel Perspective for Regularizing Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/bd93512eabdae6409f9935ee6e1fa99c3652e3ef\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1902.01148\",\"authors\":[{\"authorId\":\"35449300\",\"name\":\"Rafael Pinot\"},{\"authorId\":\"47516106\",\"name\":\"Laurent Meunier\"},{\"authorId\":\"145533439\",\"name\":\"Alexandre Araujo\"},{\"authorId\":\"2785830\",\"name\":\"H. Kashima\"},{\"authorId\":\"1783082\",\"name\":\"F. Yger\"},{\"authorId\":\"1807092\",\"name\":\"C\\u00e9dric Gouy-Pailler\"},{\"authorId\":\"1773774\",\"name\":\"J. Atif\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0657e22aaeef4ae50c519d6bd1dc3d43c216d102\",\"title\":\"Theoretical evidence for adversarial robustness through randomization: the case of the Exponential family\",\"url\":\"https://www.semanticscholar.org/paper/0657e22aaeef4ae50c519d6bd1dc3d43c216d102\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36301492\",\"name\":\"Mahmood Sharif\"},{\"authorId\":\"38181360\",\"name\":\"Sruti Bhagavatula\"},{\"authorId\":\"41224057\",\"name\":\"L. Bauer\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"}],\"doi\":\"10.1145/2976749.2978392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f57e9939560562727344c1c987416285ef76cda\",\"title\":\"Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f57e9939560562727344c1c987416285ef76cda\",\"venue\":\"CCS\",\"year\":2016},{\"arxivId\":\"1605.07146\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.87\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c4e9156ca07705531e45960b7a919dc473abb51\",\"title\":\"Wide Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c4e9156ca07705531e45960b7a919dc473abb51\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1705.08475\",\"authors\":[{\"authorId\":\"143610806\",\"name\":\"M. Hein\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"title\":\"Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1611.02770\",\"authors\":[{\"authorId\":\"1887192\",\"name\":\"Y. Liu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"title\":\"Delving into Transferable Adversarial Examples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":\"1804.08598\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"32815692\",\"name\":\"Jessy Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"title\":\"Black-box Adversarial Attacks with Limited Queries and Information\",\"url\":\"https://www.semanticscholar.org/paper/b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1710.08864\",\"authors\":[{\"authorId\":\"1730754\",\"name\":\"Jiawei Su\"},{\"authorId\":\"145197293\",\"name\":\"Danilo Vasconcellos Vargas\"},{\"authorId\":\"145106127\",\"name\":\"K. Sakurai\"}],\"doi\":\"10.1109/TEVC.2019.2890858\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"title\":\"One Pixel Attack for Fooling Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019}],\"title\":\"Learn2Perturb: An End-to-End Feature Perturbation Learning to Improve Adversarial Robustness\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Perturbation theory\",\"topicId\":\"5972\",\"url\":\"https://www.semanticscholar.org/topic/5972\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Expectation\\u2013maximization algorithm\",\"topicId\":\"52938\",\"url\":\"https://www.semanticscholar.org/topic/52938\"},{\"topic\":\"Backpropagation\",\"topicId\":\"11998\",\"url\":\"https://www.semanticscholar.org/topic/11998\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Performance tuning\",\"topicId\":\"234192\",\"url\":\"https://www.semanticscholar.org/topic/234192\"},{\"topic\":\"Program Dependence Graph\",\"topicId\":\"329509\",\"url\":\"https://www.semanticscholar.org/topic/329509\"},{\"topic\":\"Software deployment\",\"topicId\":\"328066\",\"url\":\"https://www.semanticscholar.org/topic/328066\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"},{\"topic\":\"Black-box testing\",\"topicId\":\"335574\",\"url\":\"https://www.semanticscholar.org/topic/335574\"},{\"topic\":\"Quantum decoherence\",\"topicId\":\"76769\",\"url\":\"https://www.semanticscholar.org/topic/76769\"}],\"url\":\"https://www.semanticscholar.org/paper/863b272a73ca06c819c5f9d93bdee35e4cfb7dc8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"