"{\"abstract\":\"Machine learning models are vulnerable to adversarial examples. For the black-box setting, current substitute attacks need pre-trained models to generate adversarial examples. However, pre-trained models are hard to obtain in real-world tasks. In this paper, we propose a data-free substitute training method (DaST) to obtain substitute models for adversarial black-box attacks without the requirement of any real data. To achieve this, DaST utilizes specially designed generative adversarial networks (GANs) to train the substitute models. In particular, we design a multi-branch architecture and label-control loss for the generative model to deal with the uneven distribution of synthetic samples. The substitute model is then trained by the synthetic samples generated by the generative model, which are labeled by the attacked model subsequently. The experiments demonstrate the substitute models produced by DaST can achieve competitive performance compared with the baseline models which are trained by the same train set with attacked models. Additionally, to evaluate the practicability of the proposed method on the real-world task, we attack an online machine learning model on the Microsoft Azure platform. The remote model misclassifies 98.35% of the adversarial examples crafted by our method. To the best of our knowledge, we are the first to train a substitute model for adversarial attacks without any real data.\",\"arxivId\":\"2003.12703\",\"authors\":[{\"authorId\":\"4731229\",\"name\":\"Mingyi Zhou\",\"url\":\"https://www.semanticscholar.org/author/4731229\"},{\"authorId\":\"49387836\",\"name\":\"J. Wu\",\"url\":\"https://www.semanticscholar.org/author/49387836\"},{\"authorId\":\"2412396\",\"name\":\"Y. Liu\",\"url\":\"https://www.semanticscholar.org/author/2412396\"},{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\",\"url\":\"https://www.semanticscholar.org/author/2202149\"},{\"authorId\":\"143754859\",\"name\":\"C. Zhu\",\"url\":\"https://www.semanticscholar.org/author/143754859\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.02525\",\"authors\":[{\"authorId\":\"3494825\",\"name\":\"Qizhang Li\"},{\"authorId\":\"2527106\",\"name\":\"Yiwen Guo\"},{\"authorId\":\"36620472\",\"name\":\"Hao Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f9eb88409bfc6e171792668fecc83d1d9e3c8cf\",\"title\":\"Practical No-box Adversarial Attacks against DNNs\",\"url\":\"https://www.semanticscholar.org/paper/5f9eb88409bfc6e171792668fecc83d1d9e3c8cf\",\"venue\":\"NeurIPS\",\"year\":2020}],\"corpusId\":214714048,\"doi\":\"10.1109/cvpr42600.2020.00031\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"530e299050651dbf827d56f83808de6c7c0b1a92\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1712.04248\",\"authors\":[{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"title\":\"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1803.04765\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b50026b7b1054ef8e3643fcd7ef89d7b278a068\",\"title\":\"Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2b50026b7b1054ef8e3643fcd7ef89d7b278a068\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1609.02943\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"47191084\",\"name\":\"F. Zhang\"},{\"authorId\":\"1687161\",\"name\":\"A. Juels\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"},{\"authorId\":\"1707461\",\"name\":\"T. Ristenpart\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d15b21bdd117877c2d0e865b17d6a336737aea99\",\"title\":\"Stealing Machine Learning Models via Prediction APIs\",\"url\":\"https://www.semanticscholar.org/paper/d15b21bdd117877c2d0e865b17d6a336737aea99\",\"venue\":\"USENIX Security Symposium\",\"year\":2016},{\"arxivId\":\"1706.04701\",\"authors\":[{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"145604979\",\"name\":\"J. Wei\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"title\":\"Adversarial Example Defense: Ensembles of Weak Defenses are not Strong\",\"url\":\"https://www.semanticscholar.org/paper/6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"venue\":\"WOOT\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1807.07978\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ab21b120e305b6d3cbf81c5a906d36521152f1\",\"title\":\"Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors\",\"url\":\"https://www.semanticscholar.org/paper/10ab21b120e305b6d3cbf81c5a906d36521152f1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1703.00410\",\"authors\":[{\"authorId\":\"40285565\",\"name\":\"Reuben Feinman\"},{\"authorId\":\"34658148\",\"name\":\"Ryan R. Curtin\"},{\"authorId\":\"9371478\",\"name\":\"S. Shintre\"},{\"authorId\":\"39283183\",\"name\":\"Andrew B. Gardner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"405b6ff2ea2ec9a7c7d6b18ac951dc778892ffcf\",\"title\":\"Detecting Adversarial Samples from Artifacts\",\"url\":\"https://www.semanticscholar.org/paper/405b6ff2ea2ec9a7c7d6b18ac951dc778892ffcf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1804.08598\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"32815692\",\"name\":\"Jessy Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"title\":\"Black-box Adversarial Attacks with Limited Queries and Information\",\"url\":\"https://www.semanticscholar.org/paper/b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1702.04267\",\"authors\":[{\"authorId\":\"2708564\",\"name\":\"J. H. Metzen\"},{\"authorId\":\"3081854\",\"name\":\"Tim Genewein\"},{\"authorId\":\"47092548\",\"name\":\"Volker Fischer\"},{\"authorId\":\"3452473\",\"name\":\"B. Bischoff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"531e3a7b7768f199fdd401b266504db245ca039a\",\"title\":\"On Detecting Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/531e3a7b7768f199fdd401b266504db245ca039a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10754103\",\"name\":\"A. Bhagoji\"},{\"authorId\":\"3007016\",\"name\":\"Daniel Cullina\"},{\"authorId\":\"143615345\",\"name\":\"P. Mittal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"10bd926253cbf5829ee92e927127641b69546e65\",\"title\":\"Dimensionality Reduction as a Defense against Evasion Attacks on Machine Learning Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/10bd926253cbf5829ee92e927127641b69546e65\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":\"1811.09600\",\"authors\":[{\"authorId\":\"52009092\",\"name\":\"J\\u00e9r\\u00f4me Rony\"},{\"authorId\":\"2429097\",\"name\":\"Luiz G. Hafemann\"},{\"authorId\":\"144925520\",\"name\":\"L. Oliveira\"},{\"authorId\":\"144019647\",\"name\":\"I. B. Ayed\"},{\"authorId\":\"1744351\",\"name\":\"R. Sabourin\"},{\"authorId\":\"145611842\",\"name\":\"Eric Granger\"}],\"doi\":\"10.1109/CVPR.2019.00445\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a129a7451f0e91c14caae8acfa2ad29d96fb53\",\"title\":\"Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/76a129a7451f0e91c14caae8acfa2ad29d96fb53\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1702.06280\",\"authors\":[{\"authorId\":\"39221858\",\"name\":\"Kathrin Grosse\"},{\"authorId\":\"144278515\",\"name\":\"P. Manoharan\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144588806\",\"name\":\"M. Backes\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a77313fa10a864e14f538c73d417d7b4d6f320e\",\"title\":\"On the (Statistical) Detection of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/0a77313fa10a864e14f538c73d417d7b4d6f320e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1904.02144\",\"authors\":[{\"authorId\":\"144626708\",\"name\":\"Jianbo Chen\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":\"10.1109/SP40000.2020.00045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"493d5f344eea1468260946b29a80dc81b2be409c\",\"title\":\"HopSkipJumpAttack: A Query-Efficient Decision-Based Attack\",\"url\":\"https://www.semanticscholar.org/paper/493d5f344eea1468260946b29a80dc81b2be409c\",\"venue\":\"2020 IEEE Symposium on Security and Privacy (SP)\",\"year\":2020},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1608.00530\",\"authors\":[{\"authorId\":\"3422872\",\"name\":\"Dan Hendrycks\"},{\"authorId\":\"1700980\",\"name\":\"Kevin Gimpel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96ac1d61ff5ed5d4fc828f62297e8e007d7b674e\",\"title\":\"Early Methods for Detecting Adversarial Images\",\"url\":\"https://www.semanticscholar.org/paper/96ac1d61ff5ed5d4fc828f62297e8e007d7b674e\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1803.01442\",\"authors\":[{\"authorId\":\"16404879\",\"name\":\"Guneet S. Dhillon\"},{\"authorId\":\"3371922\",\"name\":\"Kamyar Azizzadenesheli\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"38267634\",\"name\":\"J. Bernstein\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"19268451\",\"name\":\"A. Khanna\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"title\":\"Stochastic Activation Pruning for Robust Adversarial Defense\",\"url\":\"https://www.semanticscholar.org/paper/2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47619311\",\"name\":\"J. Buckman\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"title\":\"Thermometer Encoding: One Hot Way To Resist Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1902.07623\",\"authors\":[{\"authorId\":\"27623787\",\"name\":\"G. W. Ding\"},{\"authorId\":\"48169460\",\"name\":\"Luyu Wang\"},{\"authorId\":\"50562486\",\"name\":\"Xiaomeng Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f53bb893ca92f0a1b9b3d1bd2ee5de3cdb7c0da\",\"title\":\"advertorch v0.1: An Adversarial Robustness Toolbox based on PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/4f53bb893ca92f0a1b9b3d1bd2ee5de3cdb7c0da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.02654\",\"authors\":[{\"authorId\":\"10754103\",\"name\":\"A. Bhagoji\"},{\"authorId\":\"3007016\",\"name\":\"Daniel Cullina\"},{\"authorId\":\"30175233\",\"name\":\"Chawin Sitawarin\"},{\"authorId\":\"153351045\",\"name\":\"P. Mittal\"}],\"doi\":\"10.1109/CISS.2018.8362326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9070dd33f56c180cc7677cc16784bb2c6ba15294\",\"title\":\"Enhancing robustness of machine learning systems via data transformations\",\"url\":\"https://www.semanticscholar.org/paper/9070dd33f56c180cc7677cc16784bb2c6ba15294\",\"venue\":\"2018 52nd Annual Conference on Information Sciences and Systems (CISS)\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1705.09064\",\"authors\":[{\"authorId\":\"24553949\",\"name\":\"Dongyu Meng\"},{\"authorId\":null,\"name\":\"Hao Chen\"}],\"doi\":\"10.1145/3133956.3134057\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63a010c69f00e65c946a68b546bbd42cbed03564\",\"title\":\"MagNet: A Two-Pronged Defense against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/63a010c69f00e65c946a68b546bbd42cbed03564\",\"venue\":\"CCS\",\"year\":2017},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1812.02766\",\"authors\":[{\"authorId\":\"9517443\",\"name\":\"Tribhuvanesh Orekondy\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/CVPR.2019.00509\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"089c6224cfbcf5c18b63564eb65001c7c42a7acf\",\"title\":\"Knockoff Nets: Stealing Functionality of Black-Box Models\",\"url\":\"https://www.semanticscholar.org/paper/089c6224cfbcf5c18b63564eb65001c7c42a7acf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1611.02770\",\"authors\":[{\"authorId\":\"1887192\",\"name\":\"Y. Liu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"title\":\"Delving into Transferable Adversarial Examples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1612.06299\",\"authors\":[{\"authorId\":\"2701535\",\"name\":\"Nina Narodytska\"},{\"authorId\":\"7993151\",\"name\":\"S. Kasiviswanathan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a76bf5895759af6a561d81a0e2960cd00f1167e\",\"title\":\"Simple Black-Box Adversarial Perturbations for Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a76bf5895759af6a561d81a0e2960cd00f1167e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1905.07121\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"31693738\",\"name\":\"Jacob R. Gardner\"},{\"authorId\":\"10670082\",\"name\":\"Yurong You\"},{\"authorId\":\"145771261\",\"name\":\"A. Wilson\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65fd9ded2c411d90bcf6d38132463797754d2d21\",\"title\":\"Simple Black-box Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/65fd9ded2c411d90bcf6d38132463797754d2d21\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":\"1704.04960\",\"authors\":[{\"authorId\":\"48398849\",\"name\":\"Zhitao Gong\"},{\"authorId\":\"9590047\",\"name\":\"Wenlu Wang\"},{\"authorId\":\"1758909\",\"name\":\"W. Ku\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adb762a645b72fc4605e6fb512ef2684db37cc93\",\"title\":\"Adversarial and Clean Data Are Not Twins\",\"url\":\"https://www.semanticscholar.org/paper/adb762a645b72fc4605e6fb512ef2684db37cc93\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1801.02613\",\"authors\":[{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":null,\"name\":\"Yisen Wang\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"2825361\",\"name\":\"S. Wijewickrema\"},{\"authorId\":\"4480560\",\"name\":\"M. E. Houle\"},{\"authorId\":\"1710013\",\"name\":\"Grant Schoenebeck\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a18ada04d93981178234d9c8907fb99ea92fddcb\",\"title\":\"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\",\"url\":\"https://www.semanticscholar.org/paper/a18ada04d93981178234d9c8907fb99ea92fddcb\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1807.04457\",\"authors\":[{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"145512402\",\"name\":\"Th\\u00f4ng L\\u00ea\"},{\"authorId\":\"153191364\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b862efa06baea0b032214675eb3c3645d5d69d46\",\"title\":\"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach\",\"url\":\"https://www.semanticscholar.org/paper/b862efa06baea0b032214675eb3c3645d5d69d46\",\"venue\":\"ICLR\",\"year\":2019}],\"title\":\"DaST: Data-Free Substitute Training for Adversarial Attacks\",\"topics\":[{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Microsoft Azure\",\"topicId\":\"8566\",\"url\":\"https://www.semanticscholar.org/topic/8566\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Generative adversarial networks\",\"topicId\":\"258908\",\"url\":\"https://www.semanticscholar.org/topic/258908\"},{\"topic\":\"Teaching method\",\"topicId\":\"73414\",\"url\":\"https://www.semanticscholar.org/topic/73414\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Online machine learning\",\"topicId\":\"556432\",\"url\":\"https://www.semanticscholar.org/topic/556432\"},{\"topic\":\"Synthetic intelligence\",\"topicId\":\"1588157\",\"url\":\"https://www.semanticscholar.org/topic/1588157\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Code\",\"topicId\":\"595\",\"url\":\"https://www.semanticscholar.org/topic/595\"}],\"url\":\"https://www.semanticscholar.org/paper/530e299050651dbf827d56f83808de6c7c0b1a92\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"