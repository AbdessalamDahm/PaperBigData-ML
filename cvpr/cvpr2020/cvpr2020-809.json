"{\"abstract\":\"Moving object segmentation in videos (MOS) is a highly demanding task for security-based applications like automated outdoor video surveillance. Most of the existing techniques proposed for MOS are highly depend on fine-tuning a model on the first frame(s) of test sequence or complicated training procedure, which leads to limited practical serviceability of the algorithm. In this paper, the inherent correlation learning-based edge extraction mechanism (EEM) and dense residual block (DRB) are proposed for the discriminative foreground representation. The multi-scale EEM module provides the efficient foreground edge related information (with the help of encoder) to the decoder through skip connection at subsequent scale. Further, the response of the optical flow encoder stream and the last EEM module are embedded in the bridge network. The bridge network comprises of multi-scale residual blocks with dense connections to learn the effective and efficient foreground relevant features. Finally, to generate accurate and consistent foreground object maps, a decoder block is proposed with skip connections from respective multi-scale EEM module feature maps and the subsequent down-sampled response of previous frame output. Specifically, the proposed network does not require any pre-trained models or fine-tuning of the parameters with the initial frame(s) of the test video. The performance of the proposed network is evaluated with different configurations like disjoint, cross-data, and global training-testing techniques. The ablation study is conducted to analyse each model of the proposed network. To demonstrate the effectiveness of the proposed framework, a comprehensive analysis on four benchmark video datasets is conducted. Experimental results show that the proposed approach outperforms the state-of-the-art methods for MOS\",\"arxivId\":null,\"authors\":[{\"authorId\":\"48842405\",\"name\":\"Prashant W. Patil\",\"url\":\"https://www.semanticscholar.org/author/48842405\"},{\"authorId\":\"144268770\",\"name\":\"K. M. Biradar\",\"url\":\"https://www.semanticscholar.org/author/144268770\"},{\"authorId\":\"47634649\",\"name\":\"Akshay Dudhane\",\"url\":\"https://www.semanticscholar.org/author/47634649\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\",\"url\":\"https://www.semanticscholar.org/author/1827383\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220069739,\"doi\":\"10.1109/cvpr42600.2020.00817\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"44b86f0e7adc96ee384213528e2fe6ad5d327d85\",\"references\":[{\"arxivId\":\"1802.01218\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"2637241\",\"name\":\"Yanran Wang\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/CVPR.2018.00680\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a70c20ad66e5f3bb12fccd84c63ba619053c811\",\"title\":\"Efficient Video Object Segmentation via Network Modulation\",\"url\":\"https://www.semanticscholar.org/paper/4a70c20ad66e5f3bb12fccd84c63ba619053c811\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"9284635\",\"name\":\"Hongmei Song\"},{\"authorId\":\"152836879\",\"name\":\"Shuyang Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/CVPR.2019.00318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f53761ea6276df40089753a4e008d1283f28e768\",\"title\":\"Learning Unsupervised Video Object Segmentation Through Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f53761ea6276df40089753a4e008d1283f28e768\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.04842\",\"authors\":[{\"authorId\":\"82912728\",\"name\":\"L. Maczyta\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1109/ICIP.2019.8803542\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8625efee271ec079e95493f029f9bbc2d879eee\",\"title\":\"Unsupervised Motion Saliency Map Estimation Based On Optical Flow Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/e8625efee271ec079e95493f029f9bbc2d879eee\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47634649\",\"name\":\"Akshay Dudhane\"},{\"authorId\":\"46472003\",\"name\":\"H. S. Aulakh\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/CVPRW.2019.00253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd9644acc07aeb9ecf7f8189686374ecfddf3086\",\"title\":\"RI-GAN: An End-To-End Network for Single Image Haze Removal\",\"url\":\"https://www.semanticscholar.org/paper/cd9644acc07aeb9ecf7f8189686374ecfddf3086\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1811.07958\",\"authors\":[{\"authorId\":\"32197655\",\"name\":\"B. A. Griffin\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/WACV.2019.00188\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"826dea02919606c39af6ff49a1cd9ca11ae9b65a\",\"title\":\"Tukey-Inspired Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/826dea02919606c39af6ff49a1cd9ca11ae9b65a\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1906.04574\",\"authors\":[{\"authorId\":\"144268770\",\"name\":\"K. M. Biradar\"},{\"authorId\":\"51053167\",\"name\":\"Ayushi Gupta\"},{\"authorId\":\"1888144\",\"name\":\"Murari Mandal\"},{\"authorId\":\"145353981\",\"name\":\"S. K. Vipparthi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c25fe4436257d6dc95428c44ac2ad2cf3ef0bf0\",\"title\":\"Challenges in Time-Stamp Aware Anomaly Detection in Traffic Videos\",\"url\":\"https://www.semanticscholar.org/paper/7c25fe4436257d6dc95428c44ac2ad2cf3ef0bf0\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1603.01976\",\"authors\":[{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"}],\"doi\":\"10.1109/CVPR.2016.58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c41e9e105ad138a114078d1dca6fbe2dc3b599c\",\"title\":\"Deep Contrast Learning for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c41e9e105ad138a114078d1dca6fbe2dc3b599c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2001.06810\",\"authors\":[{\"authorId\":\"50085218\",\"name\":\"Xiankai Lu\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2019.00374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e54fe27ed18d513e3e9171661bd9b6e1c982b7d5\",\"title\":\"See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/e54fe27ed18d513e3e9171661bd9b6e1c982b7d5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48630579\",\"name\":\"X. Wang\"},{\"authorId\":\"50081468\",\"name\":\"L. Zhang\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"2477116\",\"name\":\"Hejun Wu\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/TCSVT.2016.2556586\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc5264fd4c5cc4a82fdbec98e4c3b4948996079b\",\"title\":\"Weighted Low-Rank Decomposition for Robust Grayscale-Thermal Foreground Detection\",\"url\":\"https://www.semanticscholar.org/paper/cc5264fd4c5cc4a82fdbec98e4c3b4948996079b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390504639\",\"name\":\"Huaijia Lin\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"2949183\",\"name\":\"Jiaya Jia\"}],\"doi\":\"10.1109/ICCV.2019.00405\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f9a016b7e6e30875b0a55f7e39a2f1d64487043\",\"title\":\"AGSS-VOS: Attention Guided Single-Shot Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/0f9a016b7e6e30875b0a55f7e39a2f1d64487043\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1810.03783\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"47243067\",\"name\":\"P. Zhang\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TIP.2019.2930152\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"697e419ea37dc151930b82584fd451530d62c025\",\"title\":\"Unsupervised Online Video Object Segmentation With Motion Property Understanding\",\"url\":\"https://www.semanticscholar.org/paper/697e419ea37dc151930b82584fd451530d62c025\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1806.02323\",\"authors\":[{\"authorId\":\"26329506\",\"name\":\"Jingchun Cheng\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"1761842\",\"name\":\"Wei-Chih Hung\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2018.00774\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"12fae9a2c1ed867997e1ca70eba271b3c741c42f\",\"title\":\"Fast and Accurate Online Video Object Segmentation via Tracking Parts\",\"url\":\"https://www.semanticscholar.org/paper/12fae9a2c1ed867997e1ca70eba271b3c741c42f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.07061\",\"authors\":[{\"authorId\":\"2149861\",\"name\":\"Hao-Feng Li\"},{\"authorId\":\"1390855802\",\"name\":\"Guanqi Chen\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/ICCV.2019.00737\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c983332dae15577079fadc6e737af50a8578a7b1\",\"title\":\"Motion Guided Attention for Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/c983332dae15577079fadc6e737af50a8578a7b1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1712.01127\",\"authors\":[{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1007/s11263-018-1122-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd484035307a97c673c2dce9a201eb93c2c21e7d\",\"title\":\"Learning to Segment Moving Objects\",\"url\":\"https://www.semanticscholar.org/paper/bd484035307a97c673c2dce9a201eb93c2c21e7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143683532\",\"name\":\"P. Patil\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/WACV.2019.00193\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"064709b719f527535746e776999c0448d8944013\",\"title\":\"FgGAN: A Cascaded Unpaired Learning for Background Estimation and Foreground Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/064709b719f527535746e776999c0448d8944013\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1904.02363\",\"authors\":[{\"authorId\":\"143885335\",\"name\":\"Kai Xu\"},{\"authorId\":\"39774417\",\"name\":\"Longyin Wen\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"144651486\",\"name\":\"L. Bo\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/CVPR.2019.00147\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6682305217104f647db57191765da6bef71c3f1f\",\"title\":\"Spatiotemporal CNN for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6682305217104f647db57191765da6bef71c3f1f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.02772\",\"authors\":[{\"authorId\":\"1709962\",\"name\":\"Christopher Xie\"},{\"authorId\":\"144863550\",\"name\":\"Y. Xiang\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"}],\"doi\":\"10.1109/CVPR.2019.01023\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0672635f300663b7bce1d59475cf607141335e50\",\"title\":\"Object Discovery in Videos as Foreground Motion Clustering\",\"url\":\"https://www.semanticscholar.org/paper/0672635f300663b7bce1d59475cf607141335e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2016.85\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05e9e85b5137016c93d042170e82f77bb551a108\",\"title\":\"A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/05e9e85b5137016c93d042170e82f77bb551a108\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36637385\",\"name\":\"Y. Wang\"},{\"authorId\":\"1687510\",\"name\":\"Pierre-Marc Jodoin\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"144055319\",\"name\":\"J. Konrad\"},{\"authorId\":\"2523684\",\"name\":\"Y. Benezeth\"},{\"authorId\":\"1756038\",\"name\":\"P. Ishwar\"}],\"doi\":\"10.1109/CVPRW.2014.126\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"80c3b84fddd0ddece79500af5e1afbd2b40e7ef8\",\"title\":\"CDnet 2014: An Expanded Change Detection Benchmark Dataset\",\"url\":\"https://www.semanticscholar.org/paper/80c3b84fddd0ddece79500af5e1afbd2b40e7ef8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":\"1709.06031\",\"authors\":[{\"authorId\":\"2027105\",\"name\":\"K. Maninis\"},{\"authorId\":\"1413064976\",\"name\":\"S. Caelles\"},{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"117044719\",\"name\":\"L. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2838670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2fcb9088e6dca3ea850de871c08b6fa084a190e\",\"title\":\"Video Object Segmentation without Temporal Information\",\"url\":\"https://www.semanticscholar.org/paper/a2fcb9088e6dca3ea850de871c08b6fa084a190e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693461\",\"name\":\"Ping Hu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1693647\",\"name\":\"Xiangfei Kong\"},{\"authorId\":\"1859486\",\"name\":\"Jason Kuen\"},{\"authorId\":\"1689805\",\"name\":\"Y. Tan\"}],\"doi\":\"10.1109/CVPR.2018.00152\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14d0a53ede10cb42cf3ef8429e24340ef18d0814\",\"title\":\"Motion-Guided Cascaded Refinement Network for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/14d0a53ede10cb42cf3ef8429e24340ef18d0814\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.11611\",\"authors\":[{\"authorId\":\"19173439\",\"name\":\"Joakim Johnander\"},{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"},{\"authorId\":\"52036918\",\"name\":\"Emil Brissman\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":\"10.1109/CVPR.2019.00916\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"48e52aef87084fa17e6ccb20ad9b3a8ec45934f0\",\"title\":\"A Generative Appearance Model for End-To-End Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/48e52aef87084fa17e6ccb20ad9b3a8ec45934f0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51285581\",\"name\":\"T. Akilan\"},{\"authorId\":\"9393966\",\"name\":\"Q.M.J. Wu\"},{\"authorId\":\"2300029\",\"name\":\"A. Safaei\"},{\"authorId\":\"3314196\",\"name\":\"Jie Huo\"},{\"authorId\":\"2864059\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TITS.2019.2900426\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"600447a22532d33b5b1602f7cae171853323dd71\",\"title\":\"A 3D CNN-LSTM-Based Image-to-Image Foreground Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/600447a22532d33b5b1602f7cae171853323dd71\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.00607\",\"authors\":[{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/ICCV.2019.00932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"842b24b04ef2b142d655c7b50cd6ab0835d89330\",\"title\":\"Video Object Segmentation Using Space-Time Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/842b24b04ef2b142d655c7b50cd6ab0835d89330\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877789\",\"name\":\"Akilan Thangarajah\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"2864059\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/j.ins.2017.11.062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d804d626f916eff1f6b21e59f0a83644f57f281\",\"title\":\"Fusion-based foreground enhancement for background subtraction using multivariate multi-model Gaussian distribution\",\"url\":\"https://www.semanticscholar.org/paper/0d804d626f916eff1f6b21e59f0a83644f57f281\",\"venue\":\"Inf. Sci.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2133342\",\"name\":\"M. Babaee\"},{\"authorId\":\"9562315\",\"name\":\"Duc Tung Dinh\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1016/j.patcog.2017.09.040\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5ca978d1e7004c830a60bce8a0c17e8d5dde99\",\"title\":\"A deep convolutional neural network for video sequence background subtraction\",\"url\":\"https://www.semanticscholar.org/paper/5f5ca978d1e7004c830a60bce8a0c17e8d5dde99\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51285581\",\"name\":\"T. Akilan\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1109/TITS.2019.2940547\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"11843f4c6f6f5a1dc49aac1ea63709260f9a3c45\",\"title\":\"sEnDec: An Improved Image to Image CNN for Foreground Localization\",\"url\":\"https://www.semanticscholar.org/paper/11843f4c6f6f5a1dc49aac1ea63709260f9a3c45\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":\"1803.09453\",\"authors\":[{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00626\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1f0899c6b70f29dc30a6c2b9e96646dd7b331db\",\"title\":\"CNN in MRF: Video Object Segmentation via Inference in a CNN-Based Higher-Order Spatio-Temporal MRF\",\"url\":\"https://www.semanticscholar.org/paper/b1f0899c6b70f29dc30a6c2b9e96646dd7b331db\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143683532\",\"name\":\"P. Patil\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/TITS.2018.2880096\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d768ec5bb9e0b95d9c7466791e6d16a48dba2302\",\"title\":\"MSFgNet: A Novel Compact End-to-End Deep Network for Moving Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d768ec5bb9e0b95d9c7466791e6d16a48dba2302\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2019},{\"arxivId\":\"1909.12471\",\"authors\":[{\"authorId\":\"1751476\",\"name\":\"Xiaohui Zeng\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"143628180\",\"name\":\"L. Gu\"},{\"authorId\":\"3372084\",\"name\":\"Y. Xiong\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/ICCV.2019.00403\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1a9437e677bd1058b98b08e54fe0ea8efa03083\",\"title\":\"DMM-Net: Differentiable Mask-Matching Network for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f1a9437e677bd1058b98b08e54fe0ea8efa03083\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1807.09190\",\"authors\":[{\"authorId\":\"31553652\",\"name\":\"Jonathon Luiten\"},{\"authorId\":\"2767859\",\"name\":\"P. Voigtlaender\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":\"10.1007/978-3-030-20870-7_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4f8db9a68bf81a78df915db3906b49a6e2534d6\",\"title\":\"PReMVOS: Proposal-generation, Refinement and Merging for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d4f8db9a68bf81a78df915db3906b49a6e2534d6\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29550075\",\"name\":\"S. Yang\"},{\"authorId\":\"144404225\",\"name\":\"B. Luo\"},{\"authorId\":\"2199572\",\"name\":\"Chenglong Li\"},{\"authorId\":\"8810611\",\"name\":\"G. Wang\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"}],\"doi\":\"10.1109/TCSVT.2017.2721460\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f707bfc523e7779f1f49e8c9aeae1876bc0ea13c\",\"title\":\"Fast Grayscale-Thermal Foreground Detection With Collaborative Low-Rank Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/f707bfc523e7779f1f49e8c9aeae1876bc0ea13c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1904.09117\",\"authors\":[{\"authorId\":\"50500282\",\"name\":\"P. Liu\"},{\"authorId\":\"1785083\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"145310663\",\"name\":\"Irwin King\"},{\"authorId\":\"119858851\",\"name\":\"J. Xu\"}],\"doi\":\"10.1109/CVPR.2019.00470\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0c3a0a2ee00d0e0ca9a65f7b663d22b0be38d98\",\"title\":\"SelFlow: Self-Supervised Learning of Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/a0c3a0a2ee00d0e0ca9a65f7b663d22b0be38d98\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/CVPR.2018.00770\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e8e7eb0ef502d5a456b2d573eb290791e7657b76\",\"title\":\"Fast Video Object Segmentation by Reference-Guided Mask Propagation\",\"url\":\"https://www.semanticscholar.org/paper/e8e7eb0ef502d5a456b2d573eb290791e7657b76\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48842405\",\"name\":\"Prashant W. Patil\"},{\"authorId\":\"1396268305\",\"name\":\"Omkar Thawakar\"},{\"authorId\":\"47634649\",\"name\":\"Akshay Dudhane\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/ICIP.2019.8803091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a3c94bd1266ca8e0acfd04bccc2e880a234011d\",\"title\":\"Motion Saliency Based Generative Adversarial Network for Underwater Moving Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8a3c94bd1266ca8e0acfd04bccc2e880a234011d\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141988\",\"name\":\"F. Li\"},{\"authorId\":\"4729037\",\"name\":\"Taeyoung Kim\"},{\"authorId\":\"3162535\",\"name\":\"Ahmad Humayun\"},{\"authorId\":\"144664176\",\"name\":\"David Tsai\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.273\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"203ea8ab1d9c48977be97e6caf3fdbcc84101354\",\"title\":\"Video Segmentation by Tracking Many Figure-Ground Segments\",\"url\":\"https://www.semanticscholar.org/paper/203ea8ab1d9c48977be97e6caf3fdbcc84101354\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-019-01164-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e74469140e774cbfbe6eedfdd35dd85ca7624a1c\",\"title\":\"Lucid Data Dreaming for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e74469140e774cbfbe6eedfdd35dd85ca7624a1c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1708.01447\",\"authors\":[{\"authorId\":\"3327355\",\"name\":\"Trung-Nghia Le\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/TIP.2018.2849860\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d59e2432047f10b427ebefe4caa17bf5480645\",\"title\":\"Video Salient Object Detection Using Spatiotemporal Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/d4d59e2432047f10b427ebefe4caa17bf5480645\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1902.09513\",\"authors\":[{\"authorId\":\"2767859\",\"name\":\"P. Voigtlaender\"},{\"authorId\":\"34858254\",\"name\":\"Yuning Chai\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"}],\"doi\":\"10.1109/CVPR.2019.00971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d1ceeea504d98e60b4bad340775e4492fcda40b\",\"title\":\"FEELVOS: Fast End-To-End Embedding Learning for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7d1ceeea504d98e60b4bad340775e4492fcda40b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1908.06647\",\"authors\":[{\"authorId\":\"50218598\",\"name\":\"Z. Wang\"},{\"authorId\":null,\"name\":\"Jun Xu\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1109/ICCV.2019.00408\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d19afefc1ef823fd6f64f28ee1d620bf925156d\",\"title\":\"RANet: Ranking Attention Network for Fast Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7d19afefc1ef823fd6f64f28ee1d620bf925156d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"},{\"authorId\":\"121605234\",\"name\":\"You He\"}],\"doi\":\"10.1109/ICCV.2019.00568\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"09a646ee609afb875a6c28f01f8bf305bfb45b97\",\"title\":\"Fast Video Object Segmentation via Dynamic Targeting Network\",\"url\":\"https://www.semanticscholar.org/paper/09a646ee609afb875a6c28f01f8bf305bfb45b97\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51285581\",\"name\":\"T. Akilan\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"49039208\",\"name\":\"Wandong Zhang\"}],\"doi\":\"10.1109/TVT.2019.2937076\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5a50a48d8cb0ab34f61f1dae771bee310c184ae\",\"title\":\"Video Foreground Extraction Using Multi-View Receptive Field and Encoder\\u2013Decoder DCNN for Traffic and Surveillance Applications\",\"url\":\"https://www.semanticscholar.org/paper/f5a50a48d8cb0ab34f61f1dae771bee310c184ae\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2019}],\"title\":\"An End-to-End Edge Aggregation Network for Moving Object Segmentation\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/44b86f0e7adc96ee384213528e2fe6ad5d327d85\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"