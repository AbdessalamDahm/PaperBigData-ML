"{\"abstract\":\"While most visual attention studies focus on bottom-up attention with restricted field-of-view, real-life situations are filled with embodied vision tasks. The role of attention is more significant in the latter due to the information overload, and attention to the most important regions is critical to the success of tasks. The effects of visual attention on task performance in this context have also been widely ignored. This research addresses a number of challenges to bridge this research gap, on both the data and model aspects. Specifically, we introduce the first dataset of top-down attention in immersive scenes. The Immersive Question-directed Visual Attention (IQVA) dataset features visual attention and corresponding task performance (i.e., answer correctness). It consists of 975 questions and answers collected from people viewing 360\\u00b0 videos in a head-mounted display. Analyses of the data demonstrate a significant correlation between people's task performance and their eye movements, suggesting the role of attention in task performance. With that, a neural network is developed to encode the differences of correct and incorrect attention and jointly predict the two. The proposed attention model for the first time takes into account answer correctness, whose outputs naturally distinguish important regions from distractions. This study with new data and features may enable new tasks that leverage attention and answer correctness, and inspire new research that reveals the process behind decision making in performing various tasks.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\",\"url\":\"https://www.semanticscholar.org/author/1405907659\"},{\"authorId\":\"94011352\",\"name\":\"S. Chen\",\"url\":\"https://www.semanticscholar.org/author/94011352\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\",\"url\":\"https://www.semanticscholar.org/author/7788087\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\",\"url\":\"https://www.semanticscholar.org/author/153386875\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":215541284,\"doi\":\"10.1109/cvpr42600.2020.00305\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1145/3025453.3025781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25936a0b60af41d0679afcfc0c23ffed91ab3243\",\"title\":\"CrowdVerge: Predicting If People Will Agree on the Answer to a Visual Question\",\"url\":\"https://www.semanticscholar.org/paper/25936a0b60af41d0679afcfc0c23ffed91ab3243\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":\"1410.8027\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"title\":\"Towards a Visual Turing Challenge\",\"url\":\"https://www.semanticscholar.org/paper/3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xun Huang\"},{\"authorId\":null,\"name\":\"Chengyao Shen\"},{\"authorId\":null,\"name\":\"Xavier Boix\"},{\"authorId\":null,\"name\":\"Qi Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SAL- ICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"\",\"venue\":\"In ICCV,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"46510545\",\"name\":\"Immo Schuetz\"}],\"doi\":\"10.3389/fnhum.2017.00491\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"title\":\"How Well Can Saliency Models Predict Fixation Selection in Scenes Beyond Central Bias? A New Approach to Model Evaluation Using Generalized Linear Mixed Models\",\"url\":\"https://www.semanticscholar.org/paper/e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"venue\":\"Front. Hum. Neurosci.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398172020\",\"name\":\"Jes\\u00fas Guti\\u00e9rrez-Cill\\u00e1n\"},{\"authorId\":\"145316303\",\"name\":\"E. J. David\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/QoMEX.2018.8463369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a63d4653ed0b453f61c91e4e3aab2c1fa77f12bc\",\"title\":\"Introducing UN Salient360! Benchmark: A platform for evaluating visual attention models for 360\\u00b0 contents\",\"url\":\"https://www.semanticscholar.org/paper/a63d4653ed0b453f61c91e4e3aab2c1fa77f12bc\",\"venue\":\"2018 Tenth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144812989\",\"name\":\"D. Barba\"}],\"doi\":\"10.1016/j.visres.2007.06.015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"122134f9242785383949caaaea4601861beebad8\",\"title\":\"Predicting visual fixations on video based on low-level visual features\",\"url\":\"https://www.semanticscholar.org/paper/122134f9242785383949caaaea4601861beebad8\",\"venue\":\"Vision Research\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"2656592\",\"name\":\"Zhisheng Yan\"}],\"doi\":\"10.1145/3304109.3325820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25488bb3a7d469d49822f8a27e779d7e963368a2\",\"title\":\"A saliency dataset for 360-degree videos\",\"url\":\"https://www.semanticscholar.org/paper/25488bb3a7d469d49822f8a27e779d7e963368a2\",\"venue\":\"MMSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403256\",\"name\":\"Xavier Corbillon\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"1835841\",\"name\":\"G. Simon\"}],\"doi\":\"10.1145/3083187.3083215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b64310dd13e71e6b192ca70c76a3ab65143614c\",\"title\":\"360-Degree Video Head Movement Dataset\",\"url\":\"https://www.semanticscholar.org/paper/3b64310dd13e71e6b192ca70c76a3ab65143614c\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145316303\",\"name\":\"E. J. David\"},{\"authorId\":\"1398172020\",\"name\":\"Jes\\u00fas Guti\\u00e9rrez-Cill\\u00e1n\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1145/3204949.3208139\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ac847ccb66557ef523d61f1371fafca526a5553\",\"title\":\"A dataset of head and eye movements for 360\\u00b0 videos\",\"url\":\"https://www.semanticscholar.org/paper/7ac847ccb66557ef523d61f1371fafca526a5553\",\"venue\":\"MMSys\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/ICCV.2013.118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"title\":\"Analysis of Scores, Datasets, and Models in Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1705.09425\",\"authors\":[{\"authorId\":\"145592705\",\"name\":\"Yao Qin\"},{\"authorId\":\"40117581\",\"name\":\"Mengyang Feng\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1007/s11263-017-1062-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b87eeb3b873d27c68a5a1cdfd9409c14db352d92\",\"title\":\"Hierarchical Cellular Automata for Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/b87eeb3b873d27c68a5a1cdfd9409c14db352d92\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49330176\",\"name\":\"Lei Chen\"},{\"authorId\":\"1705151\",\"name\":\"M. \\u00d6zsu\"},{\"authorId\":\"1693176\",\"name\":\"Vincent Oria\"}],\"doi\":\"10.1145/1066157.1066213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efac1cdecf594038530fd4eebcec54bcfff4a36a\",\"title\":\"Robust and fast similarity search for moving object trajectories\",\"url\":\"https://www.semanticscholar.org/paper/efac1cdecf594038530fd4eebcec54bcfff4a36a\",\"venue\":\"SIGMOD '05\",\"year\":2005},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"2512942\",\"name\":\"Qiuhai He\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1007/978-3-319-25903-1_55\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b222931c89aed5a4dce3719a439722a5516a4ff\",\"title\":\"A Task-Driven Eye Tracking Dataset for Visual Attention Analysis\",\"url\":\"https://www.semanticscholar.org/paper/6b222931c89aed5a4dce3719a439722a5516a4ff\",\"venue\":\"ACIVS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcella Cornia\"},{\"authorId\":null,\"name\":\"Lorenzo Baraldi\"},{\"authorId\":null,\"name\":\"Giuseppe Serra\"},{\"authorId\":null,\"name\":\"Rita Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Predicting Human Eye Fixations via an LSTMbased Saliency\",\"url\":\"\",\"venue\":\"Attentive Model. TIP,\",\"year\":2018},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"},{\"authorId\":\"24318004\",\"name\":\"Mathew H. Tong\"},{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1080/13506280902771138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74afe4b51e0db1683a7331471eac8e03342e96d\",\"title\":\"SUN: Top-down saliency using natural statistics\",\"url\":\"https://www.semanticscholar.org/paper/e74afe4b51e0db1683a7331471eac8e03342e96d\",\"venue\":\"Visual cognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"8132902\",\"name\":\"Zhihao Tan\"},{\"authorId\":\"34191590\",\"name\":\"Z. Wang\"},{\"authorId\":\"1689674\",\"name\":\"S. Yang\"}],\"doi\":\"10.1145/3083187.3083210\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"337f5ff3b7fbc9a9bea8468eb703e4d9941a1e3b\",\"title\":\"A Dataset for Exploring User Behaviors in VR Spherical Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/337f5ff3b7fbc9a9bea8468eb703e4d9941a1e3b\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294217\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"219bac0d46072291b129748809973618646935e6\",\"title\":\"Saliency Detection in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/219bac0d46072291b129748809973618646935e6\",\"venue\":\"ECCV 2018\",\"year\":2018},{\"arxivId\":\"1811.07789\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"title\":\"Explicit Bias Discovery in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1829696\",\"name\":\"Y. Rubner\"},{\"authorId\":\"145086151\",\"name\":\"Carlo Tomasi\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1023/A:1026543900054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d13a04844e4a781e5180987118f732d93aa9f398\",\"title\":\"The Earth Mover's Distance as a Metric for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d13a04844e4a781e5180987118f732d93aa9f398\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c772def2b56e873e27cc6eccbde8ee51aa3b6eb\",\"title\":\"SUNDAy: Saliency Using Natural Statistics for Dynamic Analysis of Scenes\",\"url\":\"https://www.semanticscholar.org/paper/4c772def2b56e873e27cc6eccbde8ee51aa3b6eb\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10423740\",\"name\":\"Evgeniy Upenik\"},{\"authorId\":\"1681498\",\"name\":\"T. Ebrahimi\"}],\"doi\":\"10.1109/ICMEW.2017.8026231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b543cab631ce4ae6694068dc397a6abc25236fd\",\"title\":\"A simple method to obtain visual attention data in head mounted virtual reality\",\"url\":\"https://www.semanticscholar.org/paper/6b543cab631ce4ae6694068dc397a6abc25236fd\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3274386\",\"name\":\"E. Haroutunian\"}],\"doi\":\"10.1007/978-3-642-04898-2_643\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f88d8e39dfed5db2bf129467aafd1473f0a424b8\",\"title\":\"Information Theory and Statistics\",\"url\":\"https://www.semanticscholar.org/paper/f88d8e39dfed5db2bf129467aafd1473f0a424b8\",\"venue\":\"International Encyclopedia of Statistical Science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H Donald\"},{\"authorId\":null,\"name\":\"Edwards\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"samuel lamantia, james o mcnamara , and s mark williams\",\"url\":\"\",\"venue\":\"The Quarterly Review of Biology\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40794676\",\"name\":\"Benjamin Coors\"},{\"authorId\":\"2063161\",\"name\":\"A. Condurache\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1007/978-3-030-01240-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a0cb93b7a4e0cfe6c8cb6e5cdd0bc199b515ebc\",\"title\":\"SphereNet: Learning Spherical Representations for Detection and Classification in Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/8a0cb93b7a4e0cfe6c8cb6e5cdd0bc199b515ebc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ryan Kiros\"},{\"authorId\":null,\"name\":\"Yukun Zhu\"},{\"authorId\":null,\"name\":\"Ruslan Salakhutdinov\"},{\"authorId\":null,\"name\":\"S. Richard\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zemel , Antonio Torralba , Raquel Urtasun , and Sanja Fidler . Skip - thought vectors\",\"url\":\"\",\"venue\":\"In NIPS\",\"year\":2015},{\"arxivId\":\"1807.10437\",\"authors\":[{\"authorId\":\"39832600\",\"name\":\"E. Chong\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"3521087\",\"name\":\"Y. Wang\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2244531\",\"name\":\"Agata Rozga\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"009678c2034cf4a9924a78d533d2ec81303a946e\",\"title\":\"Connecting Gaze, Scene, and Attention: Generalized Attention Estimation via Joint Modeling of Gaze and Scene Saliency\",\"url\":\"https://www.semanticscholar.org/paper/009678c2034cf4a9924a78d533d2ec81303a946e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145137054\",\"name\":\"B. Hu\"},{\"authorId\":\"1410565140\",\"name\":\"Ishmael Johnson-Bey\"},{\"authorId\":\"46320180\",\"name\":\"M. Sharma\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/CISS.2017.7926138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a62969f16887fe558b0492066c7c0ea83a87542c\",\"title\":\"Head movements during visual exploration of natural images in virtual reality\",\"url\":\"https://www.semanticscholar.org/paper/a62969f16887fe558b0492066c7c0ea83a87542c\",\"venue\":\"2017 51st Annual Conference on Information Sciences and Systems (CISS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcella Cornia\"},{\"authorId\":null,\"name\":\"Lorenzo Baraldi\"},{\"authorId\":null,\"name\":\"Giuseppe Serra\"},{\"authorId\":null,\"name\":\"Rita Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Predicting Human Eye Fixations via an LSTMbased\",\"url\":\"\",\"venue\":\"Saliency Attentive Model. TIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17822951\",\"name\":\"Wen-Chih Lo\"},{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"8152707\",\"name\":\"J. Lee\"},{\"authorId\":\"2194011\",\"name\":\"C. Huang\"},{\"authorId\":\"6270307\",\"name\":\"Kuan-Ta Chen\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":\"10.1145/3083187.3083219\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d576ebcb4a0fa54825f0ba05eaf18cd8f9bdda80\",\"title\":\"360\\u00b0 Video Viewing Dataset in Head-Mounted Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/d576ebcb4a0fa54825f0ba05eaf18cd8f9bdda80\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693190\",\"name\":\"G. Buscher\"},{\"authorId\":\"1722375\",\"name\":\"E. Cutrell\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.1145/1518701.1518705\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"9d2b67c492ba42521d12939b527c22d681298436\",\"title\":\"What do you see when you're surfing?: using eye tracking to predict salient regions of web pages\",\"url\":\"https://www.semanticscholar.org/paper/9d2b67c492ba42521d12939b527c22d681298436\",\"venue\":\"CHI\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5462319\",\"name\":\"Karla K. Evans\"},{\"authorId\":\"6122551\",\"name\":\"T. Horowitz\"},{\"authorId\":\"145486086\",\"name\":\"P. Howe\"},{\"authorId\":\"6584792\",\"name\":\"R. Pedersini\"},{\"authorId\":\"4785762\",\"name\":\"E. Reijnen\"},{\"authorId\":\"89378839\",\"name\":\"Yair Pinto\"},{\"authorId\":\"4084069\",\"name\":\"Yoana I Kuzmova\"},{\"authorId\":\"1717172\",\"name\":\"J. Wolfe\"}],\"doi\":\"10.1002/wcs.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"752be8a1e8eb656042c63968244974f5c86e24e3\",\"title\":\"Visual attention.\",\"url\":\"https://www.semanticscholar.org/paper/752be8a1e8eb656042c63968244974f5c86e24e3\",\"venue\":\"Wiley interdisciplinary reviews. Cognitive science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anh Nguyen\"},{\"authorId\":null,\"name\":\"Zhisheng Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A saliency dataset for 360degree videos\",\"url\":\"\",\"venue\":\"In MMsys,\",\"year\":2019},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Donald H Edwards\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neuroscience. third edition. edited by dale purves, george j augustine, david fitzpatrick, william c hall, anthony-samuel lamantia, james o mcnamara , and s mark williams\",\"url\":\"\",\"venue\":\"The Quarterly Review of Biology,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ryan Kiros\"},{\"authorId\":null,\"name\":\"Yukun Zhu\"},{\"authorId\":null,\"name\":\"Ruslan Salakhutdinov\"},{\"authorId\":null,\"name\":\"Richard S Zemel\"},{\"authorId\":null,\"name\":\"Antonio Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Raquel Urtasun, and Sanja Fidler. Skip-thought vectors\",\"url\":\"\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143968470\",\"name\":\"Vinod Menon\"},{\"authorId\":\"9763151\",\"name\":\"L. Uddin\"}],\"doi\":\"10.1007/s00429-010-0262-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fd8bee2d3a38b29ae2228466d3431a34c7ae240\",\"title\":\"Saliency, switching, attention and control: a network model of insula function\",\"url\":\"https://www.semanticscholar.org/paper/7fd8bee2d3a38b29ae2228466d3431a34c7ae240\",\"venue\":\"Brain Structure and Function\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-319-10584-0_3\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0ef53fe5a5cfeb4cde46efe31378b93ae0cba328\",\"title\":\"Webpage Saliency\",\"url\":\"https://www.semanticscholar.org/paper/0ef53fe5a5cfeb4cde46efe31378b93ae0cba328\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35113211\",\"name\":\"Yashas Rai\"},{\"authorId\":\"1398172020\",\"name\":\"Jes\\u00fas Guti\\u00e9rrez-Cill\\u00e1n\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1145/3083187.3083218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"080bdf42c6de4a89a268cf90f56f5c4ec68df419\",\"title\":\"A Dataset of Head and Eye Movements for 360 Degree Images\",\"url\":\"https://www.semanticscholar.org/paper/080bdf42c6de4a89a268cf90f56f5c4ec68df419\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294797\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1007/978-3-030-01234-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"title\":\"Saliency Detection in 360 ^\\\\circ \\u2218 Videos\",\"url\":\"https://www.semanticscholar.org/paper/6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"