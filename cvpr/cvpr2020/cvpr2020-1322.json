"{\"abstract\":\"In late fusion, each modality is processed in a separate unimodal Convolutional Neural Network (CNN) stream and the scores of each modality are fused at the end. Due to its simplicity, late fusion is still the predominant approach in many state-of-the-art multimodal applications. In this paper, we present a simple neural network module for leveraging the knowledge from multiple modalities in convolutional neural networks. The proposed unit, named Multimodal Transfer Module (MMTM), can be added at different levels of the feature hierarchy, enabling slow modality fusion. Using squeeze and excitation operations, MMTM utilizes the knowledge of multiple modalities to recalibrate the channel-wise features in each CNN stream. Unlike other intermediate fusion methods, the proposed module could be used for feature modality fusion in convolution layers with different spatial dimensions. Another advantage of the proposed method is that it could be added among unimodal branches with minimum changes in the their network architectures, allowing each branch to be initialized with existing pretrained weights. Experimental results show that our framework improves the recognition accuracy of well-known multimodal networks. We demonstrate state-of-the-art or competitive performance on four datasets that span the task domains of dynamic hand gesture recognition, speech enhancement, and action recognition with RGB and body joints.\",\"arxivId\":\"1911.08670\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\",\"url\":\"https://www.semanticscholar.org/author/3227254\"},{\"authorId\":\"2966051\",\"name\":\"Amirreza Shaban\",\"url\":\"https://www.semanticscholar.org/author/2966051\"},{\"authorId\":\"67294118\",\"name\":\"Michael L. Iuzzolino\",\"url\":\"https://www.semanticscholar.org/author/67294118\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\",\"url\":\"https://www.semanticscholar.org/author/145733034\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Natalia Gusarova\"},{\"authorId\":null,\"name\":\"Artem Lobantsev\"},{\"authorId\":null,\"name\":\"Aleksandra Vatian\"},{\"authorId\":null,\"name\":\"Andrey Kapitonov\"},{\"authorId\":null,\"name\":\"Anatoly Shalyto\"}],\"doi\":\"10.31799/1684-8853-2020-5-70-79\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c2245bd378f722e8e79a2a5b597c6e12eada3df\",\"title\":\"Comparative assessment of text-image fusion models for medical diagnostics\",\"url\":\"https://www.semanticscholar.org/paper/7c2245bd378f722e8e79a2a5b597c6e12eada3df\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.00210\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1c3bde4639433102c6873a083e8875e8a7f375c\",\"title\":\"Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c1c3bde4639433102c6873a083e8875e8a7f375c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04945\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3e1e0a01d98c96463d5358a91734adda9d502e1d\",\"title\":\"Multi-modal Fusion for Single-Stage Continuous Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e1e0a01d98c96463d5358a91734adda9d502e1d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01652\",\"authors\":[{\"authorId\":\"144449526\",\"name\":\"Yanhui Guo\"},{\"authorId\":\"51462355\",\"name\":\"Xiongfei Zhang\"},{\"authorId\":\"66653936\",\"name\":\"X. Wu\"}],\"doi\":\"10.1145/3394171.3413709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2afb81b32e73f67688577cadd2af2bd5179bf09\",\"title\":\"Deep Multi-modality Soft-decoding of Very Low Bit-rate Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/f2afb81b32e73f67688577cadd2af2bd5179bf09\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.01148\",\"authors\":[{\"authorId\":\"2804902\",\"name\":\"M. M. Islam\"},{\"authorId\":\"32229358\",\"name\":\"Tariq Iqbal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ab3f612125a13410373c33600abd3fccdf79ce31\",\"title\":\"HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/ab3f612125a13410373c33600abd3fccdf79ce31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.07175\",\"authors\":[{\"authorId\":\"3151024\",\"name\":\"Lang Su\"},{\"authorId\":\"2037365541\",\"name\":\"Chuqing Hu\"},{\"authorId\":\"46439101\",\"name\":\"G. Li\"},{\"authorId\":\"1491099112\",\"name\":\"Dongpu Cao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da72f519272681d685b5fb07e8d2e42b447e680b\",\"title\":\"MSAF: Multimodal Split Attention Fusion\",\"url\":\"https://www.semanticscholar.org/paper/da72f519272681d685b5fb07e8d2e42b447e680b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.15244\",\"authors\":[{\"authorId\":\"1841089935\",\"name\":\"Mahdi Davoodikakhki\"},{\"authorId\":\"153505292\",\"name\":\"KangKang Yin\"}],\"doi\":\"10.1007/978-3-030-64556-4_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0359520036f33beea638b979d515c170420ac37b\",\"title\":\"Hierarchical Action Classification with Network Pruning\",\"url\":\"https://www.semanticscholar.org/paper/0359520036f33beea638b979d515c170420ac37b\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3151995\",\"name\":\"Hemanth Venkateswara\"},{\"authorId\":\"70993850\",\"name\":\"S. Panchanathan\"}],\"doi\":\"10.1007/978-3-030-45529-3_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a53044f0144fa93bbb137be6f357d2531614f187\",\"title\":\"Introduction to Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/a53044f0144fa93bbb137be6f357d2531614f187\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":208176099,\"doi\":\"10.1109/cvpr42600.2020.01330\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"eb8304061be88b2452872e12a53b23bc9f6b4925\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":null,\"name\":\"Mohan Manubhai Trivedi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal deep learn\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Karol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mysore , and Paris Smaragdis . On - line plca for real - time semi - supervised source separation\",\"url\":\"\",\"venue\":\"International Conference on Latent Variable Analysis and Signal Separation\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2725541\",\"name\":\"Guoning Hu\"},{\"authorId\":\"1733567\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/TASL.2010.2041110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a44f8aff15eddea8804590771470cc2ac99f4469\",\"title\":\"A Tandem Algorithm for Pitch Estimation and Voiced Speech Segregation\",\"url\":\"https://www.semanticscholar.org/paper/a44f8aff15eddea8804590771470cc2ac99f4469\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2010},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yifan Zhang\"},{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TMM.2018.2808769\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b64b6e5bf236a18734455417861539fc76e845a\",\"title\":\"EgoGesture: A New Dataset and Benchmark for Egocentric Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b64b6e5bf236a18734455417861539fc76e845a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"49436963\",\"name\":\"Shalini Gupta\"},{\"authorId\":\"3736059\",\"name\":\"Kihwan Kim\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPRW.2015.7301342\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b26202f350c8d06eb3fcbf3226045b16c34eb5\",\"title\":\"Hand gesture recognition with 3D convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/99b26202f350c8d06eb3fcbf3226045b16c34eb5\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"039c9bf4777f900017dddc054ea9e376faf1ebf9\",\"title\":\"Methods for objective and subjective assessment of quality Perceptual evaluation of speech quality ( PESQ ) : An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs\",\"url\":\"https://www.semanticscholar.org/paper/039c9bf4777f900017dddc054ea9e376faf1ebf9\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.21437/Interspeech.2018-1955\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f997d69d78af086dec4462e4319c6d241f42c0c1\",\"title\":\"Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/f997d69d78af086dec4462e4319c6d241f42c0c1\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144215175\",\"name\":\"R. Jacobs\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"1802785\",\"name\":\"S. Nowlan\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1162/neco.1991.3.1.79\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c8d90974c3f3b40fa05e322df2905fc16204aa56\",\"title\":\"Adaptive Mixtures of Local Experts\",\"url\":\"https://www.semanticscholar.org/paper/c8d90974c3f3b40fa05e322df2905fc16204aa56\",\"venue\":\"Neural Computation\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"}],\"doi\":\"10.1109/TITS.2014.2337331\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8fdb23b1de6fcac695d9746d30e572556cf1e665\",\"title\":\"Hand Gesture Recognition in Real Time for Automotive Interfaces: A Multimodal Vision-Based Approach and Evaluations\",\"url\":\"https://www.semanticscholar.org/paper/8fdb23b1de6fcac695d9746d30e572556cf1e665\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31983588\",\"name\":\"C. Schroeder\"},{\"authorId\":\"3229047\",\"name\":\"J. Foxe\"}],\"doi\":\"10.1016/j.conb.2005.06.008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"587b09f6a398af8d42bbe63b75540ed0faada2fe\",\"title\":\"Multisensory contributions to low-level, \\u2018unisensory\\u2019 processing\",\"url\":\"https://www.semanticscholar.org/paper/587b09f6a398af8d42bbe63b75540ed0faada2fe\",\"venue\":\"Current Opinion in Neurobiology\",\"year\":2005},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50429401\",\"name\":\"Dhanesh Ramachandram\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/MSP.2017.2738401\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0197f278e2dedd67ec5067f47037b8cdd3ae8509\",\"title\":\"Deep Multimodal Learning: A Survey on Recent Advances and Trends\",\"url\":\"https://www.semanticscholar.org/paper/0197f278e2dedd67ec5067f47037b8cdd3ae8509\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2683590\",\"name\":\"C. Taal\"},{\"authorId\":\"1814710\",\"name\":\"R. Hendriks\"},{\"authorId\":\"3131859\",\"name\":\"R. Heusdens\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.1109/TASL.2011.2114881\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"445ee3f6a7bc18ad6f029df27b4ea99b9eb44112\",\"title\":\"An Algorithm for Intelligibility Prediction of Time\\u2013Frequency Weighted Noisy Speech\",\"url\":\"https://www.semanticscholar.org/paper/445ee3f6a7bc18ad6f029df27b4ea99b9eb44112\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2011},{\"arxivId\":\"1806.05622\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1929\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8875ae233bc074f5cd6c4ebba447b536a7e847a5\",\"title\":\"VoxCeleb2: Deep Speaker Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8875ae233bc074f5cd6c4ebba447b536a7e847a5\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1804.07453\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/TPAMI.2019.2896631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58027f532153b9f9c6ad884d85a175862fc16e6\",\"title\":\"View Adaptive Neural Networks for High Performance Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a58027f532153b9f9c6ad884d85a175862fc16e6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":\"1703.04105\",\"authors\":[{\"authorId\":\"1799540\",\"name\":\"Themos Stafylakis\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"}],\"doi\":\"10.21437/INTERSPEECH.2017-85\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4afdb836301c0233bb8cf0d8a33212ac0c113381\",\"title\":\"Combining Residual Networks with LSTMs for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/4afdb836301c0233bb8cf0d8a33212ac0c113381\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1504.05524\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-015-0846-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"title\":\"A Robust and Efficient Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"145095714\",\"name\":\"S. Gupta\"},{\"authorId\":\"3736059\",\"name\":\"Kihwan Kim\"},{\"authorId\":\"1704409\",\"name\":\"K. Pulli\"}],\"doi\":\"10.1109/FG.2015.7163132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6bb85e4ebbd533a94e9322cb6465f0f99fbeeb5\",\"title\":\"Multi-sensor system for driver's hand-gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6bb85e4ebbd533a94e9322cb6465f0f99fbeeb5\",\"venue\":\"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797570\",\"name\":\"A. A. Ghazanfar\"},{\"authorId\":\"144173887\",\"name\":\"N. Logothetis\"}],\"doi\":\"10.1038/423937a\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9e5b2ea3dd37e8a67081caf2798221cc276e1c8\",\"title\":\"Neuroperception: Facial expressions linked to monkey calls\",\"url\":\"https://www.semanticscholar.org/paper/d9e5b2ea3dd37e8a67081caf2798221cc276e1c8\",\"venue\":\"Nature\",\"year\":2003},{\"arxivId\":\"1803.11264\",\"authors\":[{\"authorId\":\"1916516\",\"name\":\"M. Khodabandeh\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"15623770\",\"name\":\"I. Zharkov\"},{\"authorId\":\"3811436\",\"name\":\"V. Pradeep\"}],\"doi\":\"10.1109/CVPRW.2018.00194\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"title\":\"DIY Human Action Dataset Generation\",\"url\":\"https://www.semanticscholar.org/paper/74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35984288\",\"name\":\"Guangnan Ye\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"1740784\",\"name\":\"I-Hong Jhuo\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2012.6248032\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e17578e742024202156f27231b5c8ebbf3abc5f\",\"title\":\"Robust late fusion with rank minimization\",\"url\":\"https://www.semanticscholar.org/paper/9e17578e742024202156f27231b5c8ebbf3abc5f\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"},{\"authorId\":\"3185424\",\"name\":\"S. Bahaadini\"},{\"authorId\":\"143719659\",\"name\":\"R. Molina\"}],\"doi\":\"10.1109/JPROC.2015.2459017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01fecf4553132a5252b6bf6d264f68568a8dbf6e\",\"title\":\"Audiovisual Fusion: Challenges and New Approaches\",\"url\":\"https://www.semanticscholar.org/paper/01fecf4553132a5252b6bf6d264f68568a8dbf6e\",\"venue\":\"Proceedings of the IEEE\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ariel Ephrat\"},{\"authorId\":null,\"name\":\"Inbar Mosseri\"},{\"authorId\":null,\"name\":\"Oran Lang\"},{\"authorId\":null,\"name\":\"Tali Dekel\"},{\"authorId\":null,\"name\":\"Kevin Wilson\"},{\"authorId\":null,\"name\":\"Avinatan Hassidim\"},{\"authorId\":null,\"name\":\"T William\"},{\"authorId\":null,\"name\":\"Michael Rubinstein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mysore , and Paris Smaragdis . On - line plca for real - time semi - supervised source separation\",\"url\":\"\",\"venue\":\"International Conference on Latent Variable Analysis and Signal Separation\",\"year\":2012},{\"arxivId\":\"1603.07120\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2691321\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"title\":\"Deep Multimodal Feature Analysis for Action Recognition in RGB+D Videos\",\"url\":\"https://www.semanticscholar.org/paper/a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8520539\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"7588999\",\"name\":\"J. Pan\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/978-3-030-01234-2_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec18f3d930af5e55f55cc94ff4049cb1774ebbcd\",\"title\":\"Deep Bilinear Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec18f3d930af5e55f55cc94ff4049cb1774ebbcd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8726117\",\"name\":\"Jen-Cheng Hou\"},{\"authorId\":\"2426246\",\"name\":\"S. Wang\"},{\"authorId\":\"145274549\",\"name\":\"Ying-Hui Lai\"},{\"authorId\":\"145403933\",\"name\":\"Y. Tsao\"},{\"authorId\":\"144600099\",\"name\":\"Hsiu-Wen Chang\"},{\"authorId\":\"1710199\",\"name\":\"H. Wang\"}],\"doi\":\"10.1109/TETCI.2017.2784878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddf1461979a5e39321b931cfe5b470999b5e4aab\",\"title\":\"Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ddf1461979a5e39321b931cfe5b470999b5e4aab\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"},{\"authorId\":\"143905691\",\"name\":\"J. Beveridge\"},{\"authorId\":\"1694404\",\"name\":\"B. Draper\"}],\"doi\":\"10.1109/CVPR.2018.00549\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eb3134ad1dd03db46111f27c10fcadf9e9a9b73\",\"title\":\"Gesture Recognition: Focus on the Hands\",\"url\":\"https://www.semanticscholar.org/paper/1eb3134ad1dd03db46111f27c10fcadf9e9a9b73\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34727115\",\"name\":\"C. Rowe\"}],\"doi\":\"10.1098/rspb.2002.2012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c23450d1cea0383424a60420d223011311f5fb3\",\"title\":\"Sound improves visual discrimination learning in avian predators\",\"url\":\"https://www.semanticscholar.org/paper/2c23450d1cea0383424a60420d223011311f5fb3\",\"venue\":\"Proceedings of the Royal Society of London. Series B: Biological Sciences\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1145/2964284.2964297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"title\":\"Multilayer and Multimodal Fusion of Deep Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"49436963\",\"name\":\"Shalini Gupta\"},{\"authorId\":\"3736059\",\"name\":\"Kihwan Kim\"},{\"authorId\":\"2342481\",\"name\":\"S. Tyree\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2016.456\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b2282ba8b50165f21d42473c22ef89b0224864a\",\"title\":\"Online Detection and Classification of Dynamic Hand Gestures with Recurrent 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0b2282ba8b50165f21d42473c22ef89b0224864a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":null,\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"MS-ASL: A largescale data set and benchmark for understanding american sign language. BMVC, 2019\",\"url\":\"\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cees H Taal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visual speech enhancement Perceptual evaluation of speech quality ( PESQ ) : An objective method for end - to - end speech quality assessment of narrow - band telephone networks and speech codecs\",\"url\":\"\",\"venue\":\"Rec . ITU - T P . 862\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48171519\",\"name\":\"S. Partan\"},{\"authorId\":\"5244235\",\"name\":\"P. Marler\"}],\"doi\":\"10.1126/SCIENCE.283.5406.1272\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7a02a1fc6fd0f7e692eff2de7fce9ecc407fc11\",\"title\":\"Communication Goes Multimodal\",\"url\":\"https://www.semanticscholar.org/paper/b7a02a1fc6fd0f7e692eff2de7fce9ecc407fc11\",\"venue\":\"Science\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Emiliano Macaluso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", and Hedi Tabia . 2 d / 3 d pose estimation and action recognition using multitask deep learn\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"2802885\",\"name\":\"R. Marxer\"},{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1016/j.csl.2016.10.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e2e764ac82f81a5bc645c818d0d5ad7806e806\",\"title\":\"The third 'CHiME' speech separation and recognition challenge: Analysis and outcomes\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e764ac82f81a5bc645c818d0d5ad7806e806\",\"venue\":\"Comput. Speech Lang.\",\"year\":2017},{\"arxivId\":\"1804.04121\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1400\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"title\":\"The Conversation: Deep Audio-Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"1781063\",\"name\":\"Gautham J. Mysore\"},{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"}],\"doi\":\"10.1007/978-3-642-28551-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1368c02d1de5453d3b215ac47bbabd69accf9b2\",\"title\":\"Online PLCA for Real-Time Semi-supervised Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/c1368c02d1de5453d3b215ac47bbabd69accf9b2\",\"venue\":\"LVA/ICA\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Juan-Manuel P\\u00e9rez-R\\u00faa\"},{\"authorId\":null,\"name\":\"Valentin Vielzeuf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"St\\u00e9phane Pateux, Moez Baccouche, and Fr\\u00e9d\\u00e9ric Jurie. MFAS: Multimodal fusion architecture search\",\"url\":\"\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.07275\",\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"2504258\",\"name\":\"Alexis Lechervy\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-11024-6_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"45a41d539fd2e6803c31cfa5d9ba3683d2935046\",\"title\":\"CentralNet: a Multilayer Approach for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/45a41d539fd2e6803c31cfa5d9ba3683d2935046\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059230\",\"name\":\"L. Zhang\"},{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"}],\"doi\":\"10.1109/ICCVW.2017.369\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"863ad2838b9b90d4461995f498a39bcd2fb87c73\",\"title\":\"Learning Spatiotemporal Features Using 3DCNN and Convolutional LSTM for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/863ad2838b9b90d4461995f498a39bcd2fb87c73\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"2417546\",\"name\":\"S. Hadfield\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/ICPR.2016.7899606\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b74252625c91375f55cbdd2e6415e752a281d10\",\"title\":\"Using Convolutional 3D Neural Networks for User-independent continuous gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b74252625c91375f55cbdd2e6415e752a281d10\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1708.05237\",\"authors\":[{\"authorId\":\"145599121\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"8362374\",\"name\":\"Xiangyu Zhu\"},{\"authorId\":\"145754448\",\"name\":\"Z. Lei\"},{\"authorId\":\"1704812\",\"name\":\"Hailin Shi\"},{\"authorId\":\"40509061\",\"name\":\"Xiaobo Wang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/ICCV.2017.30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcf71245addaf66a868221041aabe23c0a074312\",\"title\":\"S^3FD: Single Shot Scale-Invariant Face Detector\",\"url\":\"https://www.semanticscholar.org/paper/dcf71245addaf66a868221041aabe23c0a074312\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Emiliano Macaluso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multisensory processing in sensoryspecific cortical areas. The neuroscientist\",\"url\":\"\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"3108302\",\"name\":\"Wei-Long Zheng\"},{\"authorId\":\"1715839\",\"name\":\"B. Lu\"}],\"doi\":\"10.1007/978-3-319-46672-9_58\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d73138f8a42893009f4796140dbd91eea8f1a3fe\",\"title\":\"Emotion Recognition Using Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d73138f8a42893009f4796140dbd91eea8f1a3fe\",\"venue\":\"ICONIP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Emiliano Macaluso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", and Hedi Tabia . 2 d / 3 d pose estimation and action recognition using multitask deep learn\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Juan-Manuel P\\u00e9rez-R\\u00faa\"},{\"authorId\":null,\"name\":\"Valentin Vielzeuf\"},{\"authorId\":null,\"name\":\"St\\u00e9phane Pateux\"},{\"authorId\":null,\"name\":\"Moez Baccouche\"},{\"authorId\":null,\"name\":\"Fr\\u00e9d\\u00e9ric Jurie\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"MFAS: Multimodal fusion architecture\",\"url\":\"\",\"venue\":\"search. CVPR, 2019\",\"year\":2019},{\"arxivId\":\"1703.07332\",\"authors\":[{\"authorId\":\"145245424\",\"name\":\"Adrian Bulat\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"}],\"doi\":\"10.1109/ICCV.2017.116\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aadf777ef924ac93317550fbdfb9649a10d8aa82\",\"title\":\"How Far are We from Solving the 2D & 3D Face Alignment Problem? (and a Dataset of 230,000 3D Facial Landmarks)\",\"url\":\"https://www.semanticscholar.org/paper/aadf777ef924ac93317550fbdfb9649a10d8aa82\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"},{\"authorId\":\"144894710\",\"name\":\"N. Ma\"},{\"authorId\":\"145295676\",\"name\":\"Heidi Christensen\"},{\"authorId\":\"144220752\",\"name\":\"P. Green\"}],\"doi\":\"10.1016/j.csl.2012.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3b85a9644ed4a01ab1bf63f03bc27119e4c3cdf\",\"title\":\"The PASCAL CHiME speech separation and recognition challenge\",\"url\":\"https://www.semanticscholar.org/paper/a3b85a9644ed4a01ab1bf63f03bc27119e4c3cdf\",\"venue\":\"Comput. Speech Lang.\",\"year\":2013},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33785481\",\"name\":\"Yelin Kim\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"}],\"doi\":\"10.1109/ICASSP.2013.6638346\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3aec2122d5043d920f81b2c52efe735a05388bb\",\"title\":\"Deep learning for robust feature generation in audiovisual emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3aec2122d5043d920f81b2c52efe735a05388bb\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":\"1804.06055\",\"authors\":[{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/109\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"1b10e59adfa3f0f7748f48e2e64e54db2a5362d3\",\"title\":\"Co-occurrence Feature Learning from Skeleton Data for Action Recognition and Detection with Hierarchical Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/1b10e59adfa3f0f7748f48e2e64e54db2a5362d3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Eshed Ohn\"},{\"authorId\":null,\"name\":\"- Bar\"},{\"authorId\":null,\"name\":\"Mohan Manubhai Trivedi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hand gesture recognition in real time for automotive interfaces: A multimodal vision-based approach and evaluations. IEEE transactions on intelligent transportation systems\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"1840183\",\"name\":\"H. Liu\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/CVPR.2017.175\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3c850001340266d4b2e7479f78387b5fda0815c\",\"title\":\"Recurrent Convolutional Neural Networks for Continuous Sign Language Recognition by Staged Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a3c850001340266d4b2e7479f78387b5fda0815c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mahdi Abavisani\"},{\"authorId\":null,\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":null,\"name\":\"V M Patel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Improving the performance of unimodal dynamic handgesture recognition with multimodal training. Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":null,\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ms-asl: A largescale data set and benchmark for understanding american sign language\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1812.01053,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Dan Oneata\"},{\"authorId\":null,\"name\":\"Jakob Verbeek\"},{\"authorId\":null,\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A robust and efficient video representation for action recognition. IJCV\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1812.06145\",\"authors\":[{\"authorId\":\"3152993\",\"name\":\"Mahdi Abavisani\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/CVPR.2019.00126\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae\",\"title\":\"Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition With Multimodal Training\",\"url\":\"https://www.semanticscholar.org/paper/7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49824581\",\"name\":\"P. Natarajan\"},{\"authorId\":\"21243543\",\"name\":\"Shuang Wu\"},{\"authorId\":\"3306372\",\"name\":\"S. Vitaladevuni\"},{\"authorId\":\"2433508\",\"name\":\"Xiaodan Zhuang\"},{\"authorId\":\"1923728\",\"name\":\"S. Tsakalidis\"},{\"authorId\":\"143858687\",\"name\":\"U. Park\"},{\"authorId\":\"36073757\",\"name\":\"Rohit Prasad\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":\"10.1109/CVPR.2012.6247814\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a322bf3be4118a4d787bd4f9cb77df48e5b6ce3d\",\"title\":\"Multimodal feature fusion for robust event detection in web videos\",\"url\":\"https://www.semanticscholar.org/paper/a322bf3be4118a4d787bd4f9cb77df48e5b6ce3d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"},{\"authorId\":\"145344139\",\"name\":\"Enhua Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2913372\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df67d46e78aae0d2fccfb6212d101a342259c01b\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/df67d46e78aae0d2fccfb6212d101a342259c01b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1802.07898\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CVPR.2018.00056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab45ab887b7c1379bba4179579568296448d16d6\",\"title\":\"Glimpse Clouds: Human Activity Recognition from Unstructured Feature Points\",\"url\":\"https://www.semanticscholar.org/paper/ab45ab887b7c1379bba4179579568296448d16d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.01053\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"title\":\"MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guangnan Ye\"},{\"authorId\":null,\"name\":\"Dong Liu\"},{\"authorId\":null,\"name\":\"I-Hong Jhuo\"},{\"authorId\":null,\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tilayer and multimodal fusion of deep neural networks for video classification\",\"url\":\"\",\"venue\":\"Proceedings of the 24 th ACM international conference on multimedia\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144145103\",\"name\":\"Qiguang Miao\"},{\"authorId\":\"9677165\",\"name\":\"Y. Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"9249689\",\"name\":\"Zhenxin Ma\"},{\"authorId\":\"145880437\",\"name\":\"Xin Xu\"},{\"authorId\":\"15243971\",\"name\":\"Weikang Shi\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"}],\"doi\":\"10.1109/ICCVW.2017.360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ff3da21d3495c5fa55778e70db5fe0a2f67a423\",\"title\":\"Multimodal Gesture Recognition Based on the ResC3D Network\",\"url\":\"https://www.semanticscholar.org/paper/2ff3da21d3495c5fa55778e70db5fe0a2f67a423\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1604.02808\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.115\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"title\":\"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jon Barker\"},{\"authorId\":null,\"name\":\"Emmanuel Vincent\"},{\"authorId\":null,\"name\":\"Ning Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Heidi Christensen, and Phil Green. The PASCAL CHiME speech separation and recognition challenge. Computer Speech and Language\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1802.09232\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"}],\"doi\":\"10.1109/CVPR.2018.00539\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4f5c848b41160ac665d1991529a67a3208061e\",\"title\":\"2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3d4f5c848b41160ac665d1991529a67a3208061e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.06234\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"1709835\",\"name\":\"Z. Tan\"},{\"authorId\":\"144810685\",\"name\":\"Sigur\\u00f0ur Sigur\\u00f0sson\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.1109/ICASSP.2019.8682790\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ce4b9f3202703d2a6ef105539bfe66dff22fb72\",\"title\":\"On Training Targets and Objective Functions for Deep-learning-based Audio-visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/5ce4b9f3202703d2a6ef105539bfe66dff22fb72\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1903.06496\",\"authors\":[{\"authorId\":\"1414405933\",\"name\":\"Juan-Manuel P\\u00e9rez-R\\u00faa\"},{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1109/CVPR.2019.00713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5cd45ee1e91ba7a68d2a18d0735a75ed021766a\",\"title\":\"MFAS: Multimodal Fusion Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/e5cd45ee1e91ba7a68d2a18d0735a75ed021766a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48607291\",\"name\":\"Yi Wu\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/ICCV.2017.406\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"title\":\"Egocentric Gesture Recognition Using Recurrent 3D Convolutional Neural Networks with Spatiotemporal Transformer Modules\",\"url\":\"https://www.semanticscholar.org/paper/f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3264357\",\"name\":\"Karol J. Piczak\"}],\"doi\":\"10.1145/2733373.2806390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99e6f700d374e34c8376f1f43af994b278924f28\",\"title\":\"ESC: Dataset for Environmental Sound Classification\",\"url\":\"https://www.semanticscholar.org/paper/99e6f700d374e34c8376f1f43af994b278924f28\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779050\",\"name\":\"Gunnar Farneb\\u00e4ck\"}],\"doi\":\"10.1007/3-540-45103-X_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"534805683c27accb27d66d9425f759b798df380a\",\"title\":\"Two-Frame Motion Estimation Based on Polynomial Expansion\",\"url\":\"https://www.semanticscholar.org/paper/534805683c27accb27d66d9425f759b798df380a\",\"venue\":\"SCIA\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2562254\",\"name\":\"Lingni Ma\"},{\"authorId\":\"1847505\",\"name\":\"Csaba Domokos\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"}],\"doi\":\"10.1007/978-3-319-54181-5_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9360ce51ec055c05fd0384343792c58363383952\",\"title\":\"FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture\",\"url\":\"https://www.semanticscholar.org/paper/9360ce51ec055c05fd0384343792c58363383952\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1907.04975\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/interspeech.2019-3114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7473594725d668a4cb174a86dbcba7c2148a598e\",\"title\":\"My lips are concealed: Audio-visual speech enhancement through obstructions\",\"url\":\"https://www.semanticscholar.org/paper/7473594725d668a4cb174a86dbcba7c2148a598e\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Emiliano Macaluso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multisensory processing in sensoryspecific cortical areas\",\"url\":\"\",\"venue\":\"The neuroscientist,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Vaezi Hamid Reza\"},{\"authorId\":null,\"name\":\"Oscar Joze\"},{\"authorId\":null,\"name\":\"Koller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"MS-ASL: A largescale data set and benchmark for understanding american sign language\",\"url\":\"\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1810.03414\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1109/ICASSP.2019.8683898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97924ebc712b3739adfdadfd428247fce84af4b5\",\"title\":\"Dense Multimodal Fusion for Hierarchically Joint Representation\",\"url\":\"https://www.semanticscholar.org/paper/97924ebc712b3739adfdadfd428247fce84af4b5\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pavlo Molchanov\"},{\"authorId\":null,\"name\":\"Shalini Gupta\"},{\"authorId\":null,\"name\":\"Kihwan Kim\"},{\"authorId\":null,\"name\":\"Kari Pulli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multi-sensor system for driver\\u2019s hand-gesture recog- 13297 nition\",\"url\":\"\",\"venue\":\"In IEEE International Conference and Workshops on Automatic Face and Gesture Recognition,\",\"year\":2015},{\"arxivId\":\"1702.01992\",\"authors\":[{\"authorId\":\"3258998\",\"name\":\"John Arevalo\"},{\"authorId\":\"1794626\",\"name\":\"T. Solorio\"},{\"authorId\":\"1400883928\",\"name\":\"M. Montes-y-G\\u00f3mez\"},{\"authorId\":\"145580599\",\"name\":\"Fabio A. Gonz\\u00e1lez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"37e3721940352df07faebd87620732c05b458985\",\"title\":\"Gated Multimodal Units for Information Fusion\",\"url\":\"https://www.semanticscholar.org/paper/37e3721940352df07faebd87620732c05b458985\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"}],\"doi\":\"10.1109/ACCESS.2017.2684186\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84f7b7be76bc9f34e6ed9ee15defafaeb85ec419\",\"title\":\"Multimodal Gesture Recognition Using 3-D Convolution and Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/84f7b7be76bc9f34e6ed9ee15defafaeb85ec419\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144695386\",\"name\":\"F. Li\"},{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/FG.2017.59\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"2be6f208bb09443c38cdfd21bdffb2732790e07f\",\"title\":\"Modout: Learning Multi-Modal Architectures by Stochastic Regularization\",\"url\":\"https://www.semanticscholar.org/paper/2be6f208bb09443c38cdfd21bdffb2732790e07f\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.07187\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"41020760\",\"name\":\"Neslihan K\\u00f6se\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/CVPRW.2018.00284\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e8829b95fcb8492c6fbb4a727ac6543932e5cc86\",\"title\":\"Motion Fused Frames: Data Level Fusion Strategy for Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8829b95fcb8492c6fbb4a727ac6543932e5cc86\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018}],\"title\":\"MMTM: Multimodal Transfer Module for CNN Fusion\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Gesture recognition\",\"topicId\":\"18039\",\"url\":\"https://www.semanticscholar.org/topic/18039\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Speech enhancement\",\"topicId\":\"29775\",\"url\":\"https://www.semanticscholar.org/topic/29775\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/eb8304061be88b2452872e12a53b23bc9f6b4925\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"