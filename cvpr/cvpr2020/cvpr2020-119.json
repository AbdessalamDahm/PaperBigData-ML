"{\"abstract\":\"Adversarial training is an effective defense method to protect classification models against adversarial attacks. However, one limitation of this approach is that it can require orders of magnitude additional training time due to high cost of generating strong adversarial examples during training. In this paper, we first show that there is high transferability between models from neighboring epochs in the same training process, i.e., adversarial examples from one epoch continue to be adversarial in subsequent epochs. Leveraging this property, we propose a novel method, Adversarial Training with Transferable Adversarial Examples (ATTA), that can enhance the robustness of trained models and greatly improve the training efficiency by accumulating adversarial perturbations through epochs. Compared to state-of-the-art adversarial training methods, ATTA enhances adversarial accuracy by up to 7.2% on CIFAR10 and requires 12~14x less training time on MNIST and CIFAR10 datasets with comparable model robustness.\",\"arxivId\":\"1912.11969\",\"authors\":[{\"authorId\":\"3101374\",\"name\":\"Haizhong Zheng\",\"url\":\"https://www.semanticscholar.org/author/3101374\"},{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\",\"url\":\"https://www.semanticscholar.org/author/36811682\"},{\"authorId\":\"3034469\",\"name\":\"Juncheng Gu\",\"url\":\"https://www.semanticscholar.org/author/3034469\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\",\"url\":\"https://www.semanticscholar.org/author/1697141\"},{\"authorId\":\"152435970\",\"name\":\"A. Prakash\",\"url\":\"https://www.semanticscholar.org/author/152435970\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2007.08716\",\"authors\":[{\"authorId\":\"3101374\",\"name\":\"Haizhong Zheng\"},{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"152435970\",\"name\":\"A. Prakash\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"311d221422b6f176bf889c6df20c29e28eabd11d\",\"title\":\"Understanding and Diagnosing Vulnerability under Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/311d221422b6f176bf889c6df20c29e28eabd11d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08034\",\"authors\":[{\"authorId\":\"152985849\",\"name\":\"Zichao Li\"},{\"authorId\":\"46458310\",\"name\":\"Liyuan Liu\"},{\"authorId\":\"3203277\",\"name\":\"Chengyu Dong\"},{\"authorId\":\"2884976\",\"name\":\"Jingbo Shang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49457426533c4526a991bcd97d46fac75908d66a\",\"title\":\"Overfitting or Underfitting? Understand Robustness Drop in Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/49457426533c4526a991bcd97d46fac75908d66a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.13628\",\"authors\":[{\"authorId\":\"1515531906\",\"name\":\"Ahmadreza Jeddi\"},{\"authorId\":\"35371895\",\"name\":\"M. Shafiee\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fccfd63590564038a4f7235b7ce5c4eddb9b33c\",\"title\":\"A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via Adversarial Fine-tuning\",\"url\":\"https://www.semanticscholar.org/paper/3fccfd63590564038a4f7235b7ce5c4eddb9b33c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.02076\",\"authors\":[{\"authorId\":\"146494384\",\"name\":\"Dou Goodman\"},{\"authorId\":\"50017779\",\"name\":\"Xin Hao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69c30f50550fbfab90a9fbcf4ebc00d57e25a289\",\"title\":\"Attacking and Defending Machine Learning Applications of Public Cloud\",\"url\":\"https://www.semanticscholar.org/paper/69c30f50550fbfab90a9fbcf4ebc00d57e25a289\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.14031\",\"authors\":[{\"authorId\":\"1396692136\",\"name\":\"Devvrit\"},{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"3310983\",\"name\":\"C. Hsieh\"},{\"authorId\":\"1783667\",\"name\":\"I. Dhillon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2e83247a3a20d25f66262712673230f7cb68334\",\"title\":\"Voting based ensemble improves robustness of defensive models\",\"url\":\"https://www.semanticscholar.org/paper/c2e83247a3a20d25f66262712673230f7cb68334\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.11816\",\"authors\":[{\"authorId\":\"1995146\",\"name\":\"Zain Khan\"},{\"authorId\":\"20428904\",\"name\":\"Jirong Yi\"},{\"authorId\":\"2154100\",\"name\":\"R. Mudumbai\"},{\"authorId\":\"47150147\",\"name\":\"X. Wu\"},{\"authorId\":\"48721628\",\"name\":\"Weiyu Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2eafe09f7f1063a5bc37e7c768bd26a73b7493b4\",\"title\":\"Do Deep Minds Think Alike? Selective Adversarial Attacks for Fine-Grained Manipulation of Multiple Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2eafe09f7f1063a5bc37e7c768bd26a73b7493b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.01699\",\"authors\":[{\"authorId\":\"8785459\",\"name\":\"Ryan Feng\"},{\"authorId\":\"1737674\",\"name\":\"W. Feng\"},{\"authorId\":\"152435970\",\"name\":\"A. Prakash\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9d1b6f1c541042efba6fa4c47e681e4cc0c906\",\"title\":\"Essential Features: Reducing the Attack Surface of Adversarial Perturbations with Robust Content-Aware Image Preprocessing\",\"url\":\"https://www.semanticscholar.org/paper/8a9d1b6f1c541042efba6fa4c47e681e4cc0c906\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08112\",\"authors\":[{\"authorId\":\"145163914\",\"name\":\"Nanyang Ye\"},{\"authorId\":\"1861517\",\"name\":\"Qianxiao Li\"},{\"authorId\":\"47155436\",\"name\":\"Xiaoyun Zhou\"},{\"authorId\":\"1703952\",\"name\":\"Zhanxing Zhu\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"085f82a273239242fd511037daf0a84e7e52810b\",\"title\":\"Amata: An Annealing Mechanism for Adversarial Training Acceleration\",\"url\":\"https://www.semanticscholar.org/paper/085f82a273239242fd511037daf0a84e7e52810b\",\"venue\":\"\",\"year\":2019}],\"corpusId\":209501025,\"doi\":\"10.1109/cvpr42600.2020.00126\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b58738620cb4b4ab5c6e0a63839ef7d8ccabb46c\",\"references\":[{\"arxivId\":\"1901.09960\",\"authors\":[{\"authorId\":\"3422872\",\"name\":\"Dan Hendrycks\"},{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"16787428\",\"name\":\"Mantas Mazeika\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa5741c74b7fac10680c1cfbdd49d9ffb5751a68\",\"title\":\"Using Pre-Training Can Improve Model Robustness and Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/aa5741c74b7fac10680c1cfbdd49d9ffb5751a68\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1803.06978\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00284\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"title\":\"Improving Transferability of Adversarial Examples With Input Diversity\",\"url\":\"https://www.semanticscholar.org/paper/f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378427\",\"name\":\"Maria-Irina Nicolae\"},{\"authorId\":\"144418887\",\"name\":\"M. Sinn\"},{\"authorId\":\"1653295564\",\"name\":\"Minh-Ngoc Tran\"},{\"authorId\":\"1474544597\",\"name\":\"Beat Buesser\"},{\"authorId\":\"22261698\",\"name\":\"Ambrish Rawat\"},{\"authorId\":\"2794970\",\"name\":\"M. Wistuba\"},{\"authorId\":\"3393449\",\"name\":\"Valentina Zantedeschi\"},{\"authorId\":\"2478882\",\"name\":\"Nathalie Baracaldo\"},{\"authorId\":\"34252152\",\"name\":\"B. Chen\"},{\"authorId\":\"144854947\",\"name\":\"Heiko Ludwig\"},{\"authorId\":\"2816941\",\"name\":\"Ian Molloy\"},{\"authorId\":\"1700532317\",\"name\":\"Ben Edwards\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b199d42c5e711ddc2060d3038633c43f165d4f48\",\"title\":\"Adversarial Robustness Toolbox v1.0.0\",\"url\":\"https://www.semanticscholar.org/paper/b199d42c5e711ddc2060d3038633c43f165d4f48\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.00851\",\"authors\":[{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"51026953\",\"name\":\"E. Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b23012689e0f17912fb38d4984775e567cff8d6\",\"title\":\"Provable defenses against adversarial examples via the convex outer adversarial polytope\",\"url\":\"https://www.semanticscholar.org/paper/4b23012689e0f17912fb38d4984775e567cff8d6\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1605.07277\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78aa018ee7d52360e15d103390ea1cdb3a0beb41\",\"title\":\"Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/78aa018ee7d52360e15d103390ea1cdb3a0beb41\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1801.09344\",\"authors\":[{\"authorId\":\"2655157\",\"name\":\"Aditi Raghunathan\"},{\"authorId\":\"5164568\",\"name\":\"J. Steinhardt\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"title\":\"Certified Defenses against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1905.13736\",\"authors\":[{\"authorId\":\"2444742\",\"name\":\"Y. Carmon\"},{\"authorId\":\"2655157\",\"name\":\"Aditi Raghunathan\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f1aa12dde233aaf543bb9ccb27213c494e0fd5\",\"title\":\"Unlabeled Data Improves Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/b3f1aa12dde233aaf543bb9ccb27213c494e0fd5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1805.04807\",\"authors\":[{\"authorId\":\"46193391\",\"name\":\"Qi-Zhi Cai\"},{\"authorId\":\"1968460\",\"name\":\"M. Du\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.24963/ijcai.2018/520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2c08d63682b348a9848a77f9b97378a37a6b447\",\"title\":\"Curriculum Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/a2c08d63682b348a9848a77f9b97378a37a6b447\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1904.12843\",\"authors\":[{\"authorId\":\"3246287\",\"name\":\"A. Shafahi\"},{\"authorId\":\"40465379\",\"name\":\"Mahyar Najibi\"},{\"authorId\":\"115752784\",\"name\":\"Amin Ghiasi\"},{\"authorId\":\"144897102\",\"name\":\"Zheng Xu\"},{\"authorId\":\"1718974\",\"name\":\"John P. Dickerson\"},{\"authorId\":\"1746575\",\"name\":\"Christoph Studer\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2189083\",\"name\":\"G. Taylor\"},{\"authorId\":\"1962083\",\"name\":\"T. Goldstein\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c92be891c5f8f0f60b6de206364f9a744612d1e8\",\"title\":\"Adversarial Training for Free!\",\"url\":\"https://www.semanticscholar.org/paper/c92be891c5f8f0f60b6de206364f9a744612d1e8\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36301492\",\"name\":\"Mahmood Sharif\"},{\"authorId\":\"38181360\",\"name\":\"Sruti Bhagavatula\"},{\"authorId\":\"41224057\",\"name\":\"L. Bauer\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"}],\"doi\":\"10.1145/2976749.2978392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f57e9939560562727344c1c987416285ef76cda\",\"title\":\"Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f57e9939560562727344c1c987416285ef76cda\",\"venue\":\"CCS\",\"year\":2016},{\"arxivId\":\"1705.03387\",\"authors\":[{\"authorId\":\"13621686\",\"name\":\"Hyeungill Lee\"},{\"authorId\":\"14417003\",\"name\":\"Sungyeob Han\"},{\"authorId\":\"49684730\",\"name\":\"J. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"398713c17e55558deb03d638f82bfd8d00ec470f\",\"title\":\"Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN\",\"url\":\"https://www.semanticscholar.org/paper/398713c17e55558deb03d638f82bfd8d00ec470f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.03413\",\"authors\":[{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"47651566\",\"name\":\"S. Bai\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1609/AAAI.V34I07.6810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67e856f76905f2269089cede51c9a6a7c4fd2f8c\",\"title\":\"Learning Transferable Adversarial Examples via Ghost Networks\",\"url\":\"https://www.semanticscholar.org/paper/67e856f76905f2269089cede51c9a6a7c4fd2f8c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1902.02918\",\"authors\":[{\"authorId\":\"39951470\",\"name\":\"Jeremy M. Cohen\"},{\"authorId\":\"49686853\",\"name\":\"Elan Rosenfeld\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed\",\"title\":\"Certified Adversarial Robustness via Randomized Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1901.04684\",\"authors\":[{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"143825455\",\"name\":\"Z. Song\"},{\"authorId\":\"2766041\",\"name\":\"D. Boning\"},{\"authorId\":\"1783667\",\"name\":\"I. Dhillon\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7124df6df2eafa1527c76cd136ab35c176844d4\",\"title\":\"The Limitations of Adversarial Training and the Blind-Spot Attack\",\"url\":\"https://www.semanticscholar.org/paper/f7124df6df2eafa1527c76cd136ab35c176844d4\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1707.08945\",\"authors\":[{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"1825256\",\"name\":\"Kevin Eykholt\"},{\"authorId\":\"35064352\",\"name\":\"E. Fernandes\"},{\"authorId\":\"1769675\",\"name\":\"T. Kohno\"},{\"authorId\":\"38620893\",\"name\":\"B. Li\"},{\"authorId\":\"49428285\",\"name\":\"Atul Prakash\"},{\"authorId\":\"145416145\",\"name\":\"A. Rahmati\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d295a620fc10a7a656dc693e1b1bf668d1508a8e\",\"title\":\"Robust Physical-World Attacks on Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/d295a620fc10a7a656dc693e1b1bf668d1508a8e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"153276638\",\"name\":\"Tianchen Zhao\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/ICCV.2019.00283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7d849a1d6631d591e6f3427a204ee42233e1955\",\"title\":\"Adversarial Defense via Learning to Generate Diverse Attacks\",\"url\":\"https://www.semanticscholar.org/paper/b7d849a1d6631d591e6f3427a204ee42233e1955\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1811.11304\",\"authors\":[{\"authorId\":\"3246287\",\"name\":\"A. Shafahi\"},{\"authorId\":\"40465379\",\"name\":\"Mahyar Najibi\"},{\"authorId\":\"144897102\",\"name\":\"Zheng Xu\"},{\"authorId\":\"1718974\",\"name\":\"John P. Dickerson\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"1962083\",\"name\":\"T. Goldstein\"}],\"doi\":\"10.1609/AAAI.V34I04.6017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"263f845e25c1df3dffbadbee4f17a03fd0cea5dc\",\"title\":\"Universal Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/263f845e25c1df3dffbadbee4f17a03fd0cea5dc\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1905.00877\",\"authors\":[{\"authorId\":\"113087412\",\"name\":\"Dinghuai Zhang\"},{\"authorId\":\"47593236\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"48518029\",\"name\":\"Yiping Lu\"},{\"authorId\":\"1703952\",\"name\":\"Zhanxing Zhu\"},{\"authorId\":\"39131579\",\"name\":\"Bin Dong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d33deae7f654b07ac8a5c437a4fa018c29e6af17\",\"title\":\"You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle\",\"url\":\"https://www.semanticscholar.org/paper/d33deae7f654b07ac8a5c437a4fa018c29e6af17\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1605.07146\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.87\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c4e9156ca07705531e45960b7a919dc473abb51\",\"title\":\"Wide Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c4e9156ca07705531e45960b7a919dc473abb51\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767244\",\"name\":\"S. Baluja\"},{\"authorId\":\"33091759\",\"name\":\"Ian S. Fischer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8b2c73f7c19f4e6e3783a5c19304025d9b7025f\",\"title\":\"Learning to Attack: Adversarial Transformation Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b2c73f7c19f4e6e3783a5c19304025d9b7025f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1611.02770\",\"authors\":[{\"authorId\":\"1887192\",\"name\":\"Y. Liu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"title\":\"Delving into Transferable Adversarial Examples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1810.03035\",\"authors\":[{\"authorId\":\"37360922\",\"name\":\"S. W. D. Chien\"},{\"authorId\":\"2279799\",\"name\":\"S. Markidis\"},{\"authorId\":\"51429120\",\"name\":\"Chaitanya Prasad Sishtla\"},{\"authorId\":\"143868423\",\"name\":\"Lu\\u00eds Santos\"},{\"authorId\":\"37103065\",\"name\":\"P. Herman\"},{\"authorId\":\"34915818\",\"name\":\"S. Narasimhamurthy\"},{\"authorId\":\"1758463\",\"name\":\"E. Laure\"}],\"doi\":\"10.1109/PDSW-DISCS.2018.00011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032adc24a5603dfba41d9a2bdccf3810b6358e9e\",\"title\":\"Characterizing Deep-Learning I/O Workloads in TensorFlow\",\"url\":\"https://www.semanticscholar.org/paper/032adc24a5603dfba41d9a2bdccf3810b6358e9e\",\"venue\":\"2018 IEEE/ACM 3rd International Workshop on Parallel Data Storage & Data Intensive Scalable Computing Systems (PDSW-DISCS)\",\"year\":2018},{\"arxivId\":\"1901.08573\",\"authors\":[{\"authorId\":\"40975176\",\"name\":\"Hongyang Zhang\"},{\"authorId\":\"29001000\",\"name\":\"Yaodong Yu\"},{\"authorId\":\"2784735\",\"name\":\"J. Jiao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"1701847\",\"name\":\"L. Ghaoui\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"title\":\"Theoretically Principled Trade-off between Robustness and Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1807.07769\",\"authors\":[{\"authorId\":\"1825256\",\"name\":\"Kevin Eykholt\"},{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"35064352\",\"name\":\"E. Fernandes\"},{\"authorId\":\"38620893\",\"name\":\"B. Li\"},{\"authorId\":\"102541559\",\"name\":\"A. Rahmati\"},{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"49428285\",\"name\":\"Atul Prakash\"},{\"authorId\":\"1769675\",\"name\":\"T. Kohno\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c67855ff840c9f8d256486158c63a242d912e41e\",\"title\":\"Physical Adversarial Examples for Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/c67855ff840c9f8d256486158c63a242d912e41e\",\"venue\":\"WOOT @ USENIX Security Symposium\",\"year\":2018},{\"arxivId\":\"1705.08475\",\"authors\":[{\"authorId\":\"143610806\",\"name\":\"M. Hein\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"title\":\"Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/255d2c2af6d7abbbebfc03dab51cd8574ad3558e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1905.02175\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"78730080\",\"name\":\"B. Tran\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":\"10.23915/DISTILL.00019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd\",\"title\":\"Adversarial Examples Are Not Bugs, They Are Features\",\"url\":\"https://www.semanticscholar.org/paper/1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1811.10716\",\"authors\":[{\"authorId\":null,\"name\":\"Jianyu Wang\"}],\"doi\":\"10.1109/ICCV.2019.00673\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"52a4555f85b18243a95b426d48aeb69e5b332322\",\"title\":\"Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/52a4555f85b18243a95b426d48aeb69e5b332322\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1804.11285\",\"authors\":[{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"35210462\",\"name\":\"Kunal Talwar\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"804fb9542f4f56e264dd2df57c255a9a2011c00f\",\"title\":\"Adversarially Robust Generalization Requires More Data\",\"url\":\"https://www.semanticscholar.org/paper/804fb9542f4f56e264dd2df57c255a9a2011c00f\",\"venue\":\"NeurIPS\",\"year\":2018}],\"title\":\"Efficient Adversarial Training With Transferable Adversarial Examples\",\"topics\":[{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Epoch (reference date)\",\"topicId\":\"62502\",\"url\":\"https://www.semanticscholar.org/topic/62502\"},{\"topic\":\"MNIST database\",\"topicId\":\"211771\",\"url\":\"https://www.semanticscholar.org/topic/211771\"},{\"topic\":\"Iterative method\",\"topicId\":\"304\",\"url\":\"https://www.semanticscholar.org/topic/304\"},{\"topic\":\"Robustness (computer science)\",\"topicId\":\"879\",\"url\":\"https://www.semanticscholar.org/topic/879\"},{\"topic\":\"Iteration\",\"topicId\":\"11823\",\"url\":\"https://www.semanticscholar.org/topic/11823\"}],\"url\":\"https://www.semanticscholar.org/paper/b58738620cb4b4ab5c6e0a63839ef7d8ccabb46c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"