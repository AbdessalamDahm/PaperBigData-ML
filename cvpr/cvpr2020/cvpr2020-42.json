"{\"abstract\":\"Modern image classification systems are often built on deep neural networks, which suffer from adversarial examples--images with deliberately crafted, imperceptible noise to mislead the network's classification. To defend against adversarial examples, a plausible idea is to obfuscate the network's gradient with respect to the input image. This general idea has inspired a long line of defense methods. Yet, almost all of them have proven vulnerable. We revisit this seemingly flawed idea from a radically different perspective. We embrace the omnipresence of adversarial examples and the numerical procedure of crafting them, and turn this harmful attacking process into a useful defense mechanism. Our defense method is conceptually simple: before feeding an input image for classification, transform it by finding an adversarial example on a pre-trained external model. We evaluate our method against a wide range of possible attacks. On both CIFAR-10 and Tiny ImageNet datasets, our method is significantly more robust than state-of-the-art methods. Particularly, in comparison to adversarial training, our method offers lower training cost as well as stronger robustness.\",\"arxivId\":\"1911.11219\",\"authors\":[{\"authorId\":\"50365745\",\"name\":\"C. Xiao\",\"url\":\"https://www.semanticscholar.org/author/50365745\"},{\"authorId\":\"46882430\",\"name\":\"C. Zheng\",\"url\":\"https://www.semanticscholar.org/author/46882430\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":208291436,\"doi\":\"10.1109/cvpr42600.2020.00049\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"43a8b2fd651c3783723f4265d7641f9601a5a6f4\",\"references\":[{\"arxivId\":\"1905.10510\",\"authors\":[{\"authorId\":\"145616374\",\"name\":\"Chang Xiao\"},{\"authorId\":\"1980148\",\"name\":\"Peilin Zhong\"},{\"authorId\":\"46882430\",\"name\":\"C. Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"449b8ee671510b7ba749074e053815a3a655b0be\",\"title\":\"Resisting Adversarial Attacks by k-Winners-Take-All\",\"url\":\"https://www.semanticscholar.org/paper/449b8ee671510b7ba749074e053815a3a655b0be\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.05787\",\"authors\":[{\"authorId\":\"6701579\",\"name\":\"Z. Liu\"},{\"authorId\":\"50384171\",\"name\":\"Qi Liu\"},{\"authorId\":\"50022014\",\"name\":\"T. Liu\"},{\"authorId\":\"46395036\",\"name\":\"Yanzhi Wang\"},{\"authorId\":\"35420329\",\"name\":\"W. Wen\"}],\"doi\":\"10.1109/CVPR.2019.00095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af0807dca8a11fbaf966c0f8bf9b5e8b69b4d47c\",\"title\":\"Feature Distillation: DNN-Oriented JPEG Compression Against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/af0807dca8a11fbaf966c0f8bf9b5e8b69b4d47c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1707.04131\",\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"title\":\"Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1710.10766\",\"authors\":[{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"1684887\",\"name\":\"Nate Kushman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"title\":\"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1801.02610\",\"authors\":[{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"39037167\",\"name\":\"M. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.24963/ijcai.2018/543\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d5577abcc1fbf57d66017e3b5b2211a82022842c\",\"title\":\"Generating Adversarial Examples with Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d5577abcc1fbf57d66017e3b5b2211a82022842c\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1904.08653\",\"authors\":[{\"authorId\":\"107848529\",\"name\":\"Simen Thys\"},{\"authorId\":\"2665071\",\"name\":\"Wiebe Van Ranst\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1109/CVPRW.2019.00012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55c5e4753ac6bfa88d2f0e00c8e881c49b72d48e\",\"title\":\"Fooling Automated Surveillance Cameras: Adversarial Patches to Attack Person Detection\",\"url\":\"https://www.semanticscholar.org/paper/55c5e4753ac6bfa88d2f0e00c8e881c49b72d48e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1712.02976\",\"authors\":[{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"151483845\",\"name\":\"Ming Liang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"48566726\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/CVPR.2018.00191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"title\":\"Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\",\"url\":\"https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.10716\",\"authors\":[{\"authorId\":null,\"name\":\"Jianyu Wang\"}],\"doi\":\"10.1109/ICCV.2019.00673\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52a4555f85b18243a95b426d48aeb69e5b332322\",\"title\":\"Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/52a4555f85b18243a95b426d48aeb69e5b332322\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113087412\",\"name\":\"Dinghuai Zhang\"},{\"authorId\":\"123437116\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"48518029\",\"name\":\"Yiping Lu\"},{\"authorId\":\"1703952\",\"name\":\"Zhanxing Zhu\"},{\"authorId\":\"39131579\",\"name\":\"Bin Dong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8f82100ae73bcc0433bb724405993cd11da57fc\",\"title\":\"You Only Propagate Once: Painless Adversarial Training Using Maximal Principle\",\"url\":\"https://www.semanticscholar.org/paper/f8f82100ae73bcc0433bb724405993cd11da57fc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144626708\",\"name\":\"Jianbo Chen\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bd578b7df1a3f7ac008a0ebf25fcb5a035f14f0\",\"title\":\"Boundary Attack++: Query-Efficient Decision-Based Adversarial Attack\",\"url\":\"https://www.semanticscholar.org/paper/1bd578b7df1a3f7ac008a0ebf25fcb5a035f14f0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.02613\",\"authors\":[{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":null,\"name\":\"Yisen Wang\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"2825361\",\"name\":\"S. Wijewickrema\"},{\"authorId\":\"4480560\",\"name\":\"M. E. Houle\"},{\"authorId\":\"1710013\",\"name\":\"Grant Schoenebeck\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a18ada04d93981178234d9c8907fb99ea92fddcb\",\"title\":\"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\",\"url\":\"https://www.semanticscholar.org/paper/a18ada04d93981178234d9c8907fb99ea92fddcb\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34885007\",\"name\":\"Edward Raff\"},{\"authorId\":\"40214038\",\"name\":\"J. Sylvester\"},{\"authorId\":\"28948354\",\"name\":\"S. Forsyth\"},{\"authorId\":\"37260244\",\"name\":\"M. McLean\"}],\"doi\":\"10.1109/CVPR.2019.00669\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17f2f3f7e58b916175d495109bc74b2757ef952a\",\"title\":\"Barrage of Random Transforms for Adversarially Robust Defense\",\"url\":\"https://www.semanticscholar.org/paper/17f2f3f7e58b916175d495109bc74b2757ef952a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.01160\",\"authors\":[{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"49184102\",\"name\":\"Siyu Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/CVPR.2019.00668\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6a3aff5cb098a402f5384ed46b333dad672044a\",\"title\":\"Curls & Whey: Boosting Black-Box Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/c6a3aff5cb098a402f5384ed46b333dad672044a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36301492\",\"name\":\"Mahmood Sharif\"},{\"authorId\":\"38181360\",\"name\":\"Sruti Bhagavatula\"},{\"authorId\":\"41224057\",\"name\":\"L. Bauer\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"}],\"doi\":\"10.1145/2976749.2978392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f57e9939560562727344c1c987416285ef76cda\",\"title\":\"Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f57e9939560562727344c1c987416285ef76cda\",\"venue\":\"CCS\",\"year\":2016},{\"arxivId\":\"1708.06131\",\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"2338858\",\"name\":\"I. Corona\"},{\"authorId\":\"3248803\",\"name\":\"Davide Maiorca\"},{\"authorId\":\"39743720\",\"name\":\"B. Nelson\"},{\"authorId\":\"2118348\",\"name\":\"Nedim Srndic\"},{\"authorId\":\"1754215\",\"name\":\"P. Laskov\"},{\"authorId\":\"1779484\",\"name\":\"G. Giacinto\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1007/978-3-642-40994-3_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"title\":\"Evasion Attacks against Machine Learning at Test Time\",\"url\":\"https://www.semanticscholar.org/paper/033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"venue\":\"ECML/PKDD\",\"year\":2013},{\"arxivId\":\"1904.02144\",\"authors\":[{\"authorId\":\"144626708\",\"name\":\"Jianbo Chen\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":\"10.1109/SP40000.2020.00045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"493d5f344eea1468260946b29a80dc81b2be409c\",\"title\":\"HopSkipJumpAttack: A Query-Efficient Decision-Based Attack\",\"url\":\"https://www.semanticscholar.org/paper/493d5f344eea1468260946b29a80dc81b2be409c\",\"venue\":\"2020 IEEE Symposium on Security and Privacy (SP)\",\"year\":2020},{\"arxivId\":\"1707.07397\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"143883029\",\"name\":\"Kevin Kwok\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"title\":\"Synthesizing Robust Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1710.10571\",\"authors\":[{\"authorId\":\"2635549\",\"name\":\"A. Sinha\"},{\"authorId\":\"40281109\",\"name\":\"Hongseok Namkoong\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a295f76c2afb7f79a970ccf086f16168d976bb93\",\"title\":\"Certifiable Distributional Robustness with Principled Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/a295f76c2afb7f79a970ccf086f16168d976bb93\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.00117\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"2139712\",\"name\":\"Mayank Rana\"},{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"title\":\"Countering Adversarial Images using Input Transformations\",\"url\":\"https://www.semanticscholar.org/paper/e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1905.00441\",\"authors\":[{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"50703694\",\"name\":\"L. Li\"},{\"authorId\":\"49681590\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7557a6512295ab7cfe8332b1d53ae40e675c9750\",\"title\":\"NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7557a6512295ab7cfe8332b1d53ae40e675c9750\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1809.02104\",\"authors\":[{\"authorId\":\"3246287\",\"name\":\"A. Shafahi\"},{\"authorId\":\"145677189\",\"name\":\"W. Huang\"},{\"authorId\":\"1746575\",\"name\":\"Christoph Studer\"},{\"authorId\":\"144276286\",\"name\":\"S. Feizi\"},{\"authorId\":\"1962083\",\"name\":\"T. Goldstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd02c5b49bab02fb814c6999ebf161f3be377c75\",\"title\":\"Are adversarial examples inevitable?\",\"url\":\"https://www.semanticscholar.org/paper/fd02c5b49bab02fb814c6999ebf161f3be377c75\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2015.7298965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"title\":\"Fully convolutional networks for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47619311\",\"name\":\"J. Buckman\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"title\":\"Thermometer Encoding: One Hot Way To Resist Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767244\",\"name\":\"S. Baluja\"},{\"authorId\":\"33091759\",\"name\":\"Ian S. Fischer\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a8b2c73f7c19f4e6e3783a5c19304025d9b7025f\",\"title\":\"Learning to Attack: Adversarial Transformation Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b2c73f7c19f4e6e3783a5c19304025d9b7025f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1909.00900\",\"authors\":[{\"authorId\":\"7700460\",\"name\":\"Chengzhi Mao\"},{\"authorId\":\"30188141\",\"name\":\"Ziyuan Zhong\"},{\"authorId\":\"152211006\",\"name\":\"Junfeng Yang\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"31631000\",\"name\":\"Baishakhi Ray\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f4615ce7118151e243cad5544f0c75b01be171e\",\"title\":\"Metric Learning for Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/3f4615ce7118151e243cad5544f0c75b01be171e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50365745\",\"name\":\"C. Xiao\"},{\"authorId\":\"1980148\",\"name\":\"Peilin Zhong\"},{\"authorId\":\"46882430\",\"name\":\"C. Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59dfd75b28733e834cf2c825561eb5d3b0312a52\",\"title\":\"Enhancing Adversarial Defense by k-Winners-Take-All\",\"url\":\"https://www.semanticscholar.org/paper/59dfd75b28733e834cf2c825561eb5d3b0312a52\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d9318f07331ec15e54fe2a4218bc4a5c247a38\",\"title\":\"Foolbox: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/59d9318f07331ec15e54fe2a4218bc4a5c247a38\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1712.04248\",\"authors\":[{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"title\":\"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/1b225474e7a5794f98cdfbde8b12ccbc56799409\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1901.08573\",\"authors\":[{\"authorId\":\"40975176\",\"name\":\"Hongyang Zhang\"},{\"authorId\":\"29001000\",\"name\":\"Yaodong Yu\"},{\"authorId\":\"2784735\",\"name\":\"J. Jiao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"1701847\",\"name\":\"L. Ghaoui\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"title\":\"Theoretically Principled Trade-off between Robustness and Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/6c405d4b5dc41a86be05acd59c06ed19daf01d14\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1904.00689\",\"authors\":[{\"authorId\":\"144040982\",\"name\":\"O. Taran\"},{\"authorId\":\"3074253\",\"name\":\"Shideh Rezaeifar\"},{\"authorId\":\"2189106\",\"name\":\"T. Holotyak\"},{\"authorId\":\"9428112\",\"name\":\"S. Voloshynovskiy\"}],\"doi\":\"10.1109/CVPR.2019.01148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1a3dc492c88427a0b6fa253f09c2b19fc6f0d48\",\"title\":\"Defending Against Adversarial Attacks by Randomized Diversification\",\"url\":\"https://www.semanticscholar.org/paper/b1a3dc492c88427a0b6fa253f09c2b19fc6f0d48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.00887\",\"authors\":[{\"authorId\":\"49119557\",\"name\":\"Aamir Mustafa\"},{\"authorId\":\"48394782\",\"name\":\"Salman H. Khan\"},{\"authorId\":\"145684318\",\"name\":\"Munawar Hayat\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"144a8fb6e9d573f7ffb0768846f94d7859811d44\",\"title\":\"Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/144a8fb6e9d573f7ffb0768846f94d7859811d44\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1802.08686\",\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"1709490\",\"name\":\"Hamza Fawzi\"},{\"authorId\":\"145602557\",\"name\":\"Omar Fawzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7005fe514458b538b7516b41af5f5e1971154070\",\"title\":\"Adversarial vulnerability for any classifier\",\"url\":\"https://www.semanticscholar.org/paper/7005fe514458b538b7516b41af5f5e1971154070\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1811.12673\",\"authors\":[{\"authorId\":\"144890263\",\"name\":\"Xiaojun Jia\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/CVPR.2019.00624\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33e3ea69244ac597d61b9e31098b02fbfccd086d\",\"title\":\"ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/33e3ea69244ac597d61b9e31098b02fbfccd086d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.06978\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"title\":\"Improving Transferability of Adversarial Examples With Input Diversity\",\"url\":\"https://www.semanticscholar.org/paper/f78a911f516625d6b7b76a9a33c1eb14613341c4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2635549\",\"name\":\"A. Sinha\"},{\"authorId\":\"40281109\",\"name\":\"Hongseok Namkoong\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"818c52f4ba56cb8cf152ad614f2f4803057a5cfe\",\"title\":\"Certifying Some Distributional Robustness with Principled Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/818c52f4ba56cb8cf152ad614f2f4803057a5cfe\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.11090\",\"authors\":[{\"authorId\":\"3030212\",\"name\":\"Moustafa Alzantot\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"144387904\",\"name\":\"S. Chakraborty\"},{\"authorId\":\"1702254\",\"name\":\"M. Srivastava\"}],\"doi\":\"10.1145/3321707.3321749\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df849813aa240c6c56342a32fbf7e13e78c6c2f0\",\"title\":\"GenAttack: practical black-box attacks with gradient-free optimization\",\"url\":\"https://www.semanticscholar.org/paper/df849813aa240c6c56342a32fbf7e13e78c6c2f0\",\"venue\":\"GECCO\",\"year\":2019},{\"arxivId\":\"1808.01688\",\"authors\":[{\"authorId\":\"144473414\",\"name\":\"D. Su\"},{\"authorId\":\"1768312\",\"name\":\"Huan Zhang\"},{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"}],\"doi\":\"10.1007/978-3-030-01258-8_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"821fd5bed14d6d06c25fbf44123fd7be382f7b4e\",\"title\":\"Is Robustness the Cost of Accuracy? - A Comprehensive Study on the Robustness of 18 Deep Image Classification Models\",\"url\":\"https://www.semanticscholar.org/paper/821fd5bed14d6d06c25fbf44123fd7be382f7b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17016739\",\"name\":\"R. Wengert\"}],\"doi\":\"10.1145/355586.364791\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5472ce10f0ba7bb245cf6ac4cb193ff411038d93\",\"title\":\"A simple automatic derivative evaluation program\",\"url\":\"https://www.semanticscholar.org/paper/5472ce10f0ba7bb245cf6ac4cb193ff411038d93\",\"venue\":\"CACM\",\"year\":1964},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52121635\",\"name\":\"Nathan Inkawhich\"},{\"authorId\":\"144558631\",\"name\":\"W. Wen\"},{\"authorId\":\"40348219\",\"name\":\"Hai Li\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"}],\"doi\":\"10.1109/CVPR.2019.00723\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b09a6690634a41f503c91ca066e3d9ade69171db\",\"title\":\"Feature Space Perturbations Yield More Transferable Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/b09a6690634a41f503c91ca066e3d9ade69171db\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.01442\",\"authors\":[{\"authorId\":\"16404879\",\"name\":\"Guneet S. Dhillon\"},{\"authorId\":\"3371922\",\"name\":\"Kamyar Azizzadenesheli\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"38267634\",\"name\":\"J. Bernstein\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"19268451\",\"name\":\"A. Khanna\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"title\":\"Stochastic Activation Pruning for Robust Adversarial Defense\",\"url\":\"https://www.semanticscholar.org/paper/2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1712.00673\",\"authors\":[{\"authorId\":\"23979212\",\"name\":\"Xuanqing Liu\"},{\"authorId\":\"2424698\",\"name\":\"Minhao Cheng\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1007/978-3-030-01234-2_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf361d02f5ad84567e48754f1a8f895653bc701\",\"title\":\"Towards Robust Neural Networks via Random Self-ensemble\",\"url\":\"https://www.semanticscholar.org/paper/1cf361d02f5ad84567e48754f1a8f895653bc701\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.12843\",\"authors\":[{\"authorId\":\"3246287\",\"name\":\"A. Shafahi\"},{\"authorId\":\"40465379\",\"name\":\"Mahyar Najibi\"},{\"authorId\":\"115752784\",\"name\":\"Amin Ghiasi\"},{\"authorId\":\"144897102\",\"name\":\"Zheng Xu\"},{\"authorId\":\"1718974\",\"name\":\"John P. Dickerson\"},{\"authorId\":\"1746575\",\"name\":\"Christoph Studer\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2189083\",\"name\":\"G. Taylor\"},{\"authorId\":\"1962083\",\"name\":\"T. Goldstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c92be891c5f8f0f60b6de206364f9a744612d1e8\",\"title\":\"Adversarial Training for Free!\",\"url\":\"https://www.semanticscholar.org/paper/c92be891c5f8f0f60b6de206364f9a744612d1e8\",\"venue\":\"NeurIPS\",\"year\":2019}],\"title\":\"One Man\\u2019s Trash Is Another Man\\u2019s Treasure: Resisting Adversarial Examples by Adversarial Examples\",\"topics\":[{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Numerical analysis\",\"topicId\":\"5413\",\"url\":\"https://www.semanticscholar.org/topic/5413\"},{\"topic\":\"Long line (telecommunications)\",\"topicId\":\"2908712\",\"url\":\"https://www.semanticscholar.org/topic/2908712\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"}],\"url\":\"https://www.semanticscholar.org/paper/43a8b2fd651c3783723f4265d7641f9601a5a6f4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"