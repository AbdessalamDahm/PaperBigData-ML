"{\"abstract\":\"Video question answering (VideoQA) is challenging as it requires modeling capacity to distill dynamic visual artifacts and distant relations and to associate them with linguistic concepts. We introduce a general-purpose reusable neural unit called Conditional Relation Network (CRN) that serves as a building block to construct more sophisticated structures for representation and reasoning over video. CRN takes as input an array of tensorial objects and a conditioning feature, and computes an array of encoded output objects. Model building becomes a simple exercise of replication, rearrangement and stacking of these reusable units for diverse modalities and contextual information. This design thus supports high-order relational and multi-step reasoning. The resulting architecture for VideoQA is a CRN hierarchy whose branches represent sub-videos or clips, all sharing the same question as the contextual condition. Our evaluations on well-known datasets achieved new SoTA results, demonstrating the impact of building a general-purpose reasoning unit on complex domains such as VideoQA.\",\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\",\"url\":\"https://www.semanticscholar.org/author/47267313\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\",\"url\":\"https://www.semanticscholar.org/author/144672395\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\",\"url\":\"https://www.semanticscholar.org/author/144162181\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\",\"url\":\"https://www.semanticscholar.org/author/6254479\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2011.07735\",\"authors\":[{\"authorId\":\"40016108\",\"name\":\"Aman Chadha\"},{\"authorId\":\"2025073690\",\"name\":\"Gurneet Arora\"},{\"authorId\":\"2025065763\",\"name\":\"Navpreet Kaloty\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"title\":\"iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.05710\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"title\":\"Look Before you Speak: Visually Contextualized Utterances\",\"url\":\"https://www.semanticscholar.org/paper/b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":211296465,\"doi\":\"10.1109/cvpr42600.2020.00999\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"references\":[{\"arxivId\":\"1612.08083\",\"authors\":[{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"144270981\",\"name\":\"Angela Fan\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88caa4a0253a8b0076176745ebc072864eab66e1\",\"title\":\"Language Modeling with Gated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/88caa4a0253a8b0076176745ebc072864eab66e1\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11263-017-1033-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"828ac57f755db989e2886042a85278ae4823297c\",\"title\":\"Uncovering the Temporal Context for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/828ac57f755db989e2886042a85278ae4823297c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1904.04357\",\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"49469577\",\"name\":\"X. Zhang\"},{\"authorId\":\"50202300\",\"name\":\"Shu Zhang\"},{\"authorId\":\"46314996\",\"name\":\"Wensheng Wang\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"46675463\",\"name\":\"Heng Huang\"}],\"doi\":\"10.1109/CVPR.2019.00210\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c5d99eff1377e141be293336a14ffddb323c364\",\"title\":\"Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5c5d99eff1377e141be293336a14ffddb323c364\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1611.04021\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1da2431a799f68888b7e035fe49fe47a4735b71b\",\"title\":\"Leveraging Video Descriptions to Learn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1da2431a799f68888b7e035fe49fe47a4735b71b\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1906.00377\",\"authors\":[{\"authorId\":\"1725590\",\"name\":\"F. Mao\"},{\"authorId\":\"50172048\",\"name\":\"Xiang Wu\"},{\"authorId\":\"143962062\",\"name\":\"H. Xue\"},{\"authorId\":\"145814758\",\"name\":\"Rong Zhang\"}],\"doi\":\"10.1007/978-3-030-11018-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ecf5b0eb33996673d2397b18ae501109365a11d\",\"title\":\"Hierarchical Video Frame Sequence Representation with Deep Convolutional Graph Network\",\"url\":\"https://www.semanticscholar.org/paper/7ecf5b0eb33996673d2397b18ae501109365a11d\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.03476\",\"authors\":[{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2016.117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9a66904559011d48245bba01e55f72246927e77\",\"title\":\"Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e9a66904559011d48245bba01e55f72246927e77\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1809.07999\",\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1007/978-3-030-01267-0_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01ed5c62abdc37c7318c155e12e366238bdc2f5\",\"title\":\"Multimodal Dual Attention Memory for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b01ed5c62abdc37c7318c155e12e366238bdc2f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"title\":\"Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network\",\"url\":\"https://www.semanticscholar.org/paper/396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36072771\",\"name\":\"Kien Do\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"183a6ee918ae1bf2e5a30188b14e60d003b5e7f5\",\"title\":\"Learning Deep Matrix Representations\",\"url\":\"https://www.semanticscholar.org/paper/183a6ee918ae1bf2e5a30188b14e60d003b5e7f5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.09345\",\"authors\":[{\"authorId\":\"19255603\",\"name\":\"Seil Na\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"49476855\",\"name\":\"Jisung Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/ICCV.2017.80\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d66bf8b883b85e72b98b75a87773281d86fed25\",\"title\":\"A Read-Write Memory Network for Movie Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6d66bf8b883b85e72b98b75a87773281d86fed25\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3103159\",\"name\":\"M. I. H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICIP.2018.8451103\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62504a1faaff417b275c6c68835ed024136a9eef\",\"title\":\"Hierarchical Relational Attention for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62504a1faaff417b275c6c68835ed024136a9eef\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018658\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"565359aac8914505e6b02db05822ee63d3ffd03a\",\"title\":\"Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/565359aac8914505e6b02db05822ee63d3ffd03a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1511.07289\",\"authors\":[{\"authorId\":\"34917892\",\"name\":\"Djork-Arn\\u00e9 Clevert\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f63e917638553414526a0cc8550de4ad2d83fe7a\",\"title\":\"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\",\"url\":\"https://www.semanticscholar.org/paper/f63e917638553414526a0cc8550de4ad2d83fe7a\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1707.00836\",\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.24963/ijcai.2017/280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e6cc717311c9c3dcf7279bc44e0c25b29650c15\",\"title\":\"DeepStory: Video Story QA by Deep Embedded Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/7e6cc717311c9c3dcf7279bc44e0c25b29650c15\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1707.04555\",\"authors\":[{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"38812373\",\"name\":\"Yunlong Bian\"},{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"46948074\",\"name\":\"Zhichao Li\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90bec6f106f6d8d60cd939d594568bfc0f1393d9\",\"title\":\"Temporal Modeling Approaches for Large-scale Youtube-8M Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/90bec6f106f6d8d60cd939d594568bfc0f1393d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"143761093\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d89c0c6a1d5bc5cf06b0927976eaca350653301\",\"title\":\"Learning to Reason with Relational Video Representation for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5d89c0c6a1d5bc5cf06b0927976eaca350653301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhou Zhao\"},{\"authorId\":null,\"name\":\"Qifan Yang\"},{\"authorId\":null,\"name\":\"Deng Cai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Xiaofei He, and Yueting Zhuang. Video question answering via hierarchical spatiotemporal attention networks\",\"url\":\"\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2017/492\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"title\":\"Video Question Answering via Hierarchical Spatio-Temporal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1709.07871\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cfa5c97164129ce3630511f639040d28db1d4b7\",\"title\":\"FiLM: Visual Reasoning with a General Conditioning Layer\",\"url\":\"https://www.semanticscholar.org/paper/7cfa5c97164129ce3630511f639040d28db1d4b7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123427\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"057b80e235b10799d03876ad25465208a4c64caf\",\"title\":\"Video Question Answering via Gradually Refined Attention over Appearance and Motion\",\"url\":\"https://www.semanticscholar.org/paper/057b80e235b10799d03876ad25465208a4c64caf\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"title\":\"Learnable Aggregating Net with Diversity Learning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1707.06355\",\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3077136.3080655\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d726f87a275dc7ff4ba4946abc3f8041b3af8b3a\",\"title\":\"Video Question Answering via Attribute-Augmented Attention Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/d726f87a275dc7ff4ba4946abc3f8041b3af8b3a\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":null,\"name\":\"Jianping Fan\"},{\"authorId\":null,\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal factorized bilinear pooling with co-attention learning for visual question answering\",\"url\":\"\",\"venue\":\"In Proceedings of the IEEE international conference on computer vision,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144739319\",\"name\":\"R. Lienhart\"}],\"doi\":\"10.1145/319878.319888\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ab5a6dafaa5904dfab648aea94ac79baa2d4f90\",\"title\":\"Abstracting home video automatically\",\"url\":\"https://www.semanticscholar.org/paper/4ab5a6dafaa5904dfab648aea94ac79baa2d4f90\",\"venue\":\"MULTIMEDIA '99\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3265987.3265996\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f042d17dff3afb9455c7bd40b7673debbd6363\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b4f042d17dff3afb9455c7bd40b7673debbd6363\",\"venue\":\"CoVieW@MM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"title\":\"Spatio-temporal Relational Reasoning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1611.09312\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"153925540\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2017.339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"title\":\"Hierarchical Boundary-Aware Neural Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1810.00207\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"46447561\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-11018-5_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"title\":\"Non-local NetVLAD Encoding for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"venue\":\"ECCV Workshops\",\"year\":2018}],\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Stacking\",\"topicId\":\"100839\",\"url\":\"https://www.semanticscholar.org/topic/100839\"},{\"topic\":\"Visual artifact\",\"topicId\":\"86964\",\"url\":\"https://www.semanticscholar.org/topic/86964\"},{\"topic\":\"General-purpose markup language\",\"topicId\":\"2852980\",\"url\":\"https://www.semanticscholar.org/topic/2852980\"},{\"topic\":\"General-purpose modeling\",\"topicId\":\"1218769\",\"url\":\"https://www.semanticscholar.org/topic/1218769\"}],\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"