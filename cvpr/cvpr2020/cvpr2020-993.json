"{\"abstract\":\"Many visual scenes contain text that carries crucial information, and it is thus essential to understand text in images for downstream reasoning tasks. For example, a deep water label on a warning sign warns people about the danger in the scene. Recent work has explored the TextVQA task that requires reading and understanding text in images to answer a question. However, existing approaches for TextVQA are mostly based on custom pairwise fusion mechanisms between a pair of two modalities and are restricted to a single prediction step by casting TextVQA as a classification task. In this work, we propose a novel model for the TextVQA task based on a multimodal transformer architecture accompanied by a rich representation for text in images. Our model naturally fuses different modalities homogeneously by embedding them into a common semantic space where self-attention is applied to model inter- and intra- modality context. Furthermore, it enables iterative answer decoding with a dynamic pointer network, allowing the model to form an answer through multi-step prediction instead of one-step classification. Our model outperforms existing approaches on three benchmark datasets for the TextVQA task by a large margin.\",\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\",\"url\":\"https://www.semanticscholar.org/author/2874347\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\",\"url\":\"https://www.semanticscholar.org/author/50286460\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\",\"url\":\"https://www.semanticscholar.org/author/1753210\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.03662\",\"authors\":[{\"authorId\":\"50218156\",\"name\":\"Zhaokai Wang\"},{\"authorId\":\"7760591\",\"name\":\"Renda Bao\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1fe7a16266cf2316f436688e0df6c6350c885ef\",\"title\":\"Confidence-aware Non-repetitive Multimodal Transformers for TextCaps\",\"url\":\"https://www.semanticscholar.org/paper/b1fe7a16266cf2316f436688e0df6c6350c885ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8480832\",\"name\":\"W. Zhu\"},{\"authorId\":\"1491627482\",\"name\":\"Xiaping Xu\"},{\"authorId\":\"10070729\",\"name\":\"K. Yan\"},{\"authorId\":\"1491626709\",\"name\":\"Shuang Liu\"},{\"authorId\":\"1491629341\",\"name\":\"Xiaoya Yin\"}],\"doi\":\"10.1109/ACCESS.2020.2969983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d38a7c381a3d69b4d3d2a7714acc3ed31a88f6f8\",\"title\":\"A Synchronized Word Representation Method With Dual Perceptual Information\",\"url\":\"https://www.semanticscholar.org/paper/d38a7c381a3d69b4d3d2a7714acc3ed31a88f6f8\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2010.02582\",\"authors\":[{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a65b38abc44bd6acb06ebc87e7e4765609d88a3\",\"title\":\"Finding the Evidence: Localization-aware Answer Prediction for Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a65b38abc44bd6acb06ebc87e7e4765609d88a3\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2002.08911\",\"authors\":[{\"authorId\":\"51519704\",\"name\":\"Candace Ross\"},{\"authorId\":\"143912599\",\"name\":\"B. Katz\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59bb7f41e72bae283f8aa2222b346956ee197a7a\",\"title\":\"Measuring Social Biases in Grounded Vision and Language Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/59bb7f41e72bae283f8aa2222b346956ee197a7a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.04638\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"46583994\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1882479\",\"name\":\"D. Flor\\u00eancio\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"145637095\",\"name\":\"Lei Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"title\":\"TAP: Text-Aware Pre-training for Text-VQA and Text-Caption\",\"url\":\"https://www.semanticscholar.org/paper/8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.12462\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"}],\"doi\":\"10.1007/978-3-030-58536-5_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7442eaaf453e63195cdee037f8e23830b4004027\",\"title\":\"TextCaps: a Dataset for Image Captioning with Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7442eaaf453e63195cdee037f8e23830b4004027\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.00398\",\"authors\":[{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b40bfcf339de3f0dba08fabb2b58b9368ff4c51a\",\"title\":\"DocVQA: A Dataset for VQA on Document Images\",\"url\":\"https://www.semanticscholar.org/paper/b40bfcf339de3f0dba08fabb2b58b9368ff4c51a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.05153\",\"authors\":[{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"952edddbb3438072312756762be1bfde287e1497\",\"title\":\"Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps\",\"url\":\"https://www.semanticscholar.org/paper/952edddbb3438072312756762be1bfde287e1497\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143647292\",\"name\":\"F. Liu\"},{\"authorId\":\"49560222\",\"name\":\"Guanghui Xu\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"145229535\",\"name\":\"W. Jia\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1145/3394171.3413924\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"title\":\"Cascade Reasoning Network for Text-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924571\",\"name\":\"Jing Wang\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413753\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"021d50ba5ae1c66e9175428f546976798126dd9f\",\"title\":\"Multimodal Attention with Image Text Spatial Relationship for OCR-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/021d50ba5ae1c66e9175428f546976798126dd9f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.12146\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"},{\"authorId\":\"5153264\",\"name\":\"A. Schwing\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":\"10.1007/978-3-030-58545-7_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"title\":\"Spatially Aware Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.00753\",\"authors\":[{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"title\":\"Structured Multimodal Attentions for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":208006464,\"doi\":\"10.1109/cvpr42600.2020.01001\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"references\":[{\"arxivId\":\"1606.01933\",\"authors\":[{\"authorId\":\"144729897\",\"name\":\"Ankur P. Parikh\"},{\"authorId\":\"2556289\",\"name\":\"Oscar T\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"143790066\",\"name\":\"Dipanjan Das\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"}],\"doi\":\"10.18653/v1/D16-1244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cd8e8f510c89c7c18268e8ad51c061e459ad321\",\"title\":\"A Decomposable Attention Model for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/2cd8e8f510c89c7c18268e8ad51c061e459ad321\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1607.04606\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.1162/tacl_a_00051\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2dba792360873aef125572812f3673b1a85d850\",\"title\":\"Enriching Word Vectors with Subword Information\",\"url\":\"https://www.semanticscholar.org/paper/e2dba792360873aef125572812f3673b1a85d850\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.09044\",\"authors\":[{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1007/978-3-030-01264-9_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d1da046da3626c7b12fb9091ce7ddbc64389b57\",\"title\":\"Single Shot Scene Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8d1da046da3626c7b12fb9091ce7ddbc64389b57\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1601.07140\",\"authors\":[{\"authorId\":\"2799898\",\"name\":\"Andreas Veit\"},{\"authorId\":\"2152992\",\"name\":\"T. Matera\"},{\"authorId\":\"145532509\",\"name\":\"Lukas Neumann\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b7325b788320f96f7b152768226f16e390ab6475\",\"title\":\"COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/b7325b788320f96f7b152768226f16e390ab6475\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhengkai Jiang\"},{\"authorId\":null,\"name\":\"Haoxuan You\"},{\"authorId\":null,\"name\":\"Pan Lu\"},{\"authorId\":null,\"name\":\"Steven CH Hoi\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":null,\"name\":\"Hongsheng Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"namic fusion with intra - and inter - modality attention flow for visual question answering\",\"url\":\"\",\"venue\":\"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing\",\"year\":null},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1910.05085\",\"authors\":[{\"authorId\":\"2973998\",\"name\":\"Fedor Borisyuk\"},{\"authorId\":\"1821267\",\"name\":\"A. Gordo\"},{\"authorId\":\"145422368\",\"name\":\"V. Sivakumar\"}],\"doi\":\"10.1145/3219819.3219861\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fde3ee5f9f8e217a4d6716013315614811820f21\",\"title\":\"Rosetta: Large Scale System for Text Detection and Recognition in Images\",\"url\":\"https://www.semanticscholar.org/paper/fde3ee5f9f8e217a4d6716013315614811820f21\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"50262380\",\"name\":\"Yu Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6dedf6d25df2a5cd727a019b613953afc9a0300\",\"title\":\"Pythia-A platform for vision & language research\",\"url\":\"https://www.semanticscholar.org/paper/d6dedf6d25df2a5cd727a019b613953afc9a0300\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1704.04368\",\"authors\":[{\"authorId\":\"13070498\",\"name\":\"A. See\"},{\"authorId\":\"35025299\",\"name\":\"Peter J. Liu\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/P17-1099\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"668db48c6a79826456341680ee1175dfc4cced71\",\"title\":\"Get To The Point: Summarization with Pointer-Generator Networks\",\"url\":\"https://www.semanticscholar.org/paper/668db48c6a79826456341680ee1175dfc4cced71\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39719398\",\"name\":\"Anand Mishra\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/ICCV.2013.378\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68ff3f104c1d5b07fc9009ad21c86f75dac5e7e0\",\"title\":\"Image Retrieval Using Textual Cues\",\"url\":\"https://www.semanticscholar.org/paper/68ff3f104c1d5b07fc9009ad21c86f75dac5e7e0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1904.08920\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00851\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"af1f7739283bdbd2b7a94903041f6d6afd991907\",\"title\":\"Towards VQA Models That Can Read\",\"url\":\"https://www.semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ruben Ali Furkan Biten\"},{\"authorId\":null,\"name\":\"Andres Tito\"},{\"authorId\":null,\"name\":\"Lluis Mafla\"},{\"authorId\":null,\"name\":\"Mar\\u00e7al Gomez\"},{\"authorId\":null,\"name\":\"Minesh Rusi\\u00f1ol\"},{\"authorId\":null,\"name\":\"Mathew\"},{\"authorId\":null,\"name\":\"Jawahar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ernest Valveny, and Dimosthenis Karatzas\",\"url\":\"\",\"venue\":\"Icdar 2019 competition on scene text visual question answering\",\"year\":2007},{\"arxivId\":\"1908.06066\",\"authors\":[{\"authorId\":\"150112700\",\"name\":\"Gen Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"143795948\",\"name\":\"Yuejian Fang\"},{\"authorId\":\"71790825\",\"name\":\"Daxin Jiang\"},{\"authorId\":\"143849622\",\"name\":\"M. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I07.6795\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bc1c8bd00bbf7401afcb5460277840fd8bab029\",\"title\":\"Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/2bc1c8bd00bbf7401afcb5460277840fd8bab029\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yuetan Lin\"},{\"authorId\":null,\"name\":\"Hongrui Zhao\"},{\"authorId\":null,\"name\":\"Yanan Li\"},{\"authorId\":null,\"name\":\"Donghui Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"DCD ZJU, TextVQA Challenge 2019 winner. https:// visualqa.org/workshop.html\",\"url\":\"\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1506.03134\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"39067762\",\"name\":\"Meire Fortunato\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9653d5c2c7844347343d073bbedd96e05d52f69b\",\"title\":\"Pointer Networks\",\"url\":\"https://www.semanticscholar.org/paper/9653d5c2c7844347343d073bbedd96e05d52f69b\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.00490\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICDAR.2019.00251\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"title\":\"ICDAR 2019 Competition on Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"2730090\",\"name\":\"L. G. I. Bigorda\"},{\"authorId\":\"2098117\",\"name\":\"A. Nicolaou\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"},{\"authorId\":\"35613969\",\"name\":\"M. Iwamura\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"145532509\",\"name\":\"Lukas Neumann\"},{\"authorId\":\"2510839\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1809705\",\"name\":\"S. Uchida\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"}],\"doi\":\"10.1109/ICDAR.2015.7333942\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b02f729e6d442f6872078f599fc9da5c3605cee\",\"title\":\"ICDAR 2015 competition on Robust Reading\",\"url\":\"https://www.semanticscholar.org/paper/9b02f729e6d442f6872078f599fc9da5c3605cee\",\"venue\":\"2015 13th International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhengkai Jiang\"},{\"authorId\":null,\"name\":\"Haoxuan You\"},{\"authorId\":null,\"name\":\"Pan Lu\"},{\"authorId\":null,\"name\":\"Steven CH Hoi\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":null,\"name\":\"Hongsheng Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"namic fusion with intra - and inter - modality attention flow for visual question answering\",\"url\":\"\",\"venue\":\"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing\",\"year\":null},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1809705\",\"name\":\"S. Uchida\"},{\"authorId\":\"35613969\",\"name\":\"M. Iwamura\"},{\"authorId\":\"2730090\",\"name\":\"L. G. I. Bigorda\"},{\"authorId\":\"2729896\",\"name\":\"Sergi Robles Mestre\"},{\"authorId\":\"40016884\",\"name\":\"J. M. Romeu\"},{\"authorId\":\"50313341\",\"name\":\"D. F. Mota\"},{\"authorId\":\"145467588\",\"name\":\"J. Almaz\\u00e1n\"},{\"authorId\":\"70894898\",\"name\":\"L. D. L. Heras\"}],\"doi\":\"10.1109/ICDAR.2013.221\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcd7b547bf0a6646a282f521db880e74974aa838\",\"title\":\"ICDAR 2013 Robust Reading Competition\",\"url\":\"https://www.semanticscholar.org/paper/fcd7b547bf0a6646a282f521db880e74974aa838\",\"venue\":\"2013 12th International Conference on Document Analysis and Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Anonymous submission\",\"url\":\"\",\"venue\":\"MSFT VTI, TextVQA Challenge 2019 top entry\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1908.05054\",\"authors\":[{\"authorId\":\"114577307\",\"name\":\"C. Alberti\"},{\"authorId\":\"50602231\",\"name\":\"Jeffrey Ling\"},{\"authorId\":\"123052390\",\"name\":\"Michael Collins\"},{\"authorId\":\"1781409\",\"name\":\"D. Reitter\"}],\"doi\":\"10.18653/v1/D19-1219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"title\":\"Fusion of Detected Objects in Text for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b82153bf85d5d1edd3f170aace830e5328ca9ed0\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145467588\",\"name\":\"J. Almaz\\u00e1n\"},{\"authorId\":\"1821267\",\"name\":\"A. Gordo\"},{\"authorId\":\"1686569\",\"name\":\"A. Forn\\u00e9s\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"}],\"doi\":\"10.1109/TPAMI.2014.2339814\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e61061b2ddd5e789a071e0681f4eb405bf811339\",\"title\":\"Word Spotting and Recognition with Embedded Attributes\",\"url\":\"https://www.semanticscholar.org/paper/e61061b2ddd5e789a071e0681f4eb405bf811339\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"46264474\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICDAR.2019.00156\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1097cf8cf5961589ff693b069002e7181e24e631\",\"title\":\"OCR-VQA: Visual Question Answering by Reading Text in Images\",\"url\":\"https://www.semanticscholar.org/paper/1097cf8cf5961589ff693b069002e7181e24e631\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.10731\",\"authors\":[{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"}],\"doi\":\"10.18653/v1/W19-5917\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e62f783e1a3f8c56c9bb117b7b0e0cce5870551\",\"title\":\"DeepCopy: Grounded Response Generation with Hierarchical Pointer Networks\",\"url\":\"https://www.semanticscholar.org/paper/9e62f783e1a3f8c56c9bb117b7b0e0cce5870551\",\"venue\":\"SIGdial\",\"year\":2019},{\"arxivId\":\"1610.09038\",\"authors\":[{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"title\":\"Professor Forcing: A New Algorithm for Training Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1910.10683\",\"authors\":[{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"145625142\",\"name\":\"Adam Roberts\"},{\"authorId\":\"3844009\",\"name\":\"Katherine Lee\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"1380243217\",\"name\":\"M. Matena\"},{\"authorId\":\"2389316\",\"name\":\"Yanqi Zhou\"},{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"35025299\",\"name\":\"Peter J. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cfb319689f06bf04c2e28399361f414ca32c4b3\",\"title\":\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\",\"url\":\"https://www.semanticscholar.org/paper/3cfb319689f06bf04c2e28399361f414ca32c4b3\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2020},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Linjie Li\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yu Cheng\"},{\"authorId\":null,\"name\":\"Jingjing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Relationaware graph attention network for visual question answering\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1903.12314,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alina Kuznetsova\"},{\"authorId\":null,\"name\":\"Hassan Rom\"},{\"authorId\":null,\"name\":\"Neil Alldrin\"},{\"authorId\":null,\"name\":\"Jasper Uijlings\"},{\"authorId\":null,\"name\":\"Ivan Krasin\"},{\"authorId\":null,\"name\":\"Jordi Pont-Tuset\"},{\"authorId\":null,\"name\":\"Shahab Kamali\"},{\"authorId\":null,\"name\":\"Stefan Popov\"},{\"authorId\":null,\"name\":\"Matteo Malloci\"},{\"authorId\":null,\"name\":\"Tom Duerig\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1811.00982,\",\"year\":2018}],\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"topics\":[{\"topic\":\"Transformer\",\"topicId\":\"6977\",\"url\":\"https://www.semanticscholar.org/topic/6977\"},{\"topic\":\"Pointer (computer programming)\",\"topicId\":\"20732\",\"url\":\"https://www.semanticscholar.org/topic/20732\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Iterative method\",\"topicId\":\"304\",\"url\":\"https://www.semanticscholar.org/topic/304\"},{\"topic\":\"Transformers\",\"topicId\":\"927204\",\"url\":\"https://www.semanticscholar.org/topic/927204\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Downstream (software development)\",\"topicId\":\"10055\",\"url\":\"https://www.semanticscholar.org/topic/10055\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Domain-specific language\",\"topicId\":\"81892\",\"url\":\"https://www.semanticscholar.org/topic/81892\"}],\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"