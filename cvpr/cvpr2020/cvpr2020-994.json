"{\"abstract\":\"Existing VQA datasets contain questions with varying levels of complexity. While the majority of questions in these datasets require perception for recognizing existence, properties, and spatial relationships of entities, a significant portion of questions pose challenges that correspond to reasoning tasks \\u2013 tasks that can only be answered through a synthesis of perception and knowledge about the world, logic and / or reasoning. Analyzing performance across this distinction allows us to notice when existing VQA models have consistency issues \\u2013 they answer the reasoning questions correctly but fail on associated low-level perception questions. For example, in Figure 1, models answer the complex reasoning question \\u201cIs the banana ripe enough to eat?\\u201d correctly, but fail on the associated perception question \\u201cAre the bananas mostly green or yellow?\\u201d indicating that the model likely answered the reasoning question correctly but for the wrong reason. We quantify the extent to which this phenomenon occurs by creating a new Reasoning split of the VQA dataset and collecting VQAintrospect, a new dataset1 which currently consists of 200K new perception questions which serve as sub questions corresponding to the set of perceptual tasks needed to effectively answer the complex reasoning questions in the Reasoning split. Our evaluation shows that state-of-the-art VQA models have comparable performance in answering perception and reasoning questions, but suffer from consistency problems. To address this shortcoming, we propose an approach called Sub-Question Importance-aware Network Tuning (SQuINT), which encourages the model to attend to the same parts of the image when answering the reasoning question and the perception sub question. We show that SQuINT improves model consistency by \\u223c7%, also marginally improving performance on the Reasoning questions in VQA, while also displaying better attention maps.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\",\"url\":\"https://www.semanticscholar.org/author/35100058\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\",\"url\":\"https://www.semanticscholar.org/author/87994165\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\",\"url\":\"https://www.semanticscholar.org/author/145479841\"},{\"authorId\":\"3055431\",\"name\":\"Marco T\\u00falio Ribeiro\",\"url\":\"https://www.semanticscholar.org/author/3055431\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\",\"url\":\"https://www.semanticscholar.org/author/2571049\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\",\"url\":\"https://www.semanticscholar.org/author/1783184\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2006.11524\",\"authors\":[{\"authorId\":\"1961237\",\"name\":\"S. Amizadeh\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"2636739\",\"name\":\"Oleksandr Polozov\"},{\"authorId\":\"153268415\",\"name\":\"Y. Huang\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb62c82e469a265d986a164ba56d96d130937fd7\",\"title\":\"Neuro-Symbolic Visual Reasoning: Disentangling \\\"Visual\\\" from \\\"Reasoning\\\"\",\"url\":\"https://www.semanticscholar.org/paper/fb62c82e469a265d986a164ba56d96d130937fd7\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13354\",\"authors\":[{\"authorId\":\"119869488\",\"name\":\"Grusha Prasad\"},{\"authorId\":\"40383658\",\"name\":\"Yixin Nie\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"3422908\",\"name\":\"Robin Jia\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"81840293\",\"name\":\"Adina Williams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03e28116af64f89e9bcb38371ffa3b00b2725681\",\"title\":\"To what extent do human explanations of model behavior align with actual model behavior?\",\"url\":\"https://www.semanticscholar.org/paper/03e28116af64f89e9bcb38371ffa3b00b2725681\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.04422\",\"authors\":[{\"authorId\":\"1802508687\",\"name\":\"Vatsal Goel\"},{\"authorId\":\"1802505447\",\"name\":\"Mohit Chandak\"},{\"authorId\":\"47583481\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"title\":\"IQ-VQA: Intelligent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06087\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"32587693\",\"name\":\"A. Moudgil\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ead5088bc1922526be9a503dd42b15d467b962\",\"title\":\"Contrast and Classify: Alternate Training for Robust VQA\",\"url\":\"https://www.semanticscholar.org/paper/35ead5088bc1922526be9a503dd42b15d467b962\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10094\",\"authors\":[{\"authorId\":\"2027617785\",\"name\":\"Anh-Cat Le-Ngo\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"2867032\",\"name\":\"S. Rana\"},{\"authorId\":\"119971153\",\"name\":\"Sunil Gupta\"},{\"authorId\":\"49337894\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"684e40bc390a9478a325995ea360267d77e4ddaa\",\"title\":\"Logically Consistent Loss for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/684e40bc390a9478a325995ea360267d77e4ddaa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08566\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.63\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf4e64566252b3a342ba344e8a123c2b209766f2\",\"title\":\"MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf4e64566252b3a342ba344e8a123c2b209766f2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.10038\",\"authors\":[{\"authorId\":\"31340289\",\"name\":\"Sameer Dharur\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"title\":\"SOrT-ing VQA Models : Contrastive Gradient Learning for Improved Consistency\",\"url\":\"https://www.semanticscholar.org/paper/997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":214811850,\"doi\":\"10.1109/CVPR42600.2020.01002\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"27cea494961a45d6a0687c75248fd078999d9a43\",\"references\":[{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1807.00517\",\"authors\":[{\"authorId\":\"40895688\",\"name\":\"Kaylee Burns\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01219-9_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0c5dc3fa19a2bc97606ccb6f55226b913984395\",\"title\":\"Women also Snowboard: Overcoming Bias in Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b0c5dc3fa19a2bc97606ccb6f55226b913984395\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2001.06927\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"title\":\"SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145042015\",\"name\":\"M. McCloskey\"},{\"authorId\":\"48909510\",\"name\":\"N. J. Cohen\"}],\"doi\":\"10.1016/S0079-7421(08)60536-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c213af6582c0d518a6e8e14217611c733eeb1ef1\",\"title\":\"Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem\",\"url\":\"https://www.semanticscholar.org/paper/c213af6582c0d518a6e8e14217611c733eeb1ef1\",\"venue\":\"\",\"year\":1989},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1807.09956\",\"authors\":[{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"36c3972569a6949ecca90bfa6f8e99883e092845\",\"title\":\"Pythia v0.1: the Winning Entry to the VQA Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/36c3972569a6949ecca90bfa6f8e99883e092845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ramprasaath R. Selvaraju\"},{\"authorId\":null,\"name\":\"Purva Tendulkar\"},{\"authorId\":null,\"name\":\"Devi Parikh\"},{\"authorId\":null,\"name\":\"Eric Horvitz\"},{\"authorId\":null,\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":null,\"name\":\"Besmira Nushi\"},{\"authorId\":null,\"name\":\"Ece Kamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions\",\"url\":\"\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1709.06308\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fafe70edc7067015ca2d49aef2773c22a71647d\",\"title\":\"Exploring Human-like Attention Supervision in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3fafe70edc7067015ca2d49aef2773c22a71647d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259916\",\"name\":\"D. Hoffman\"},{\"authorId\":\"152805281\",\"name\":\"W. Richards\"}],\"doi\":\"10.1016/0010-0277(84)90022-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"150662e38fc67ca81ac93faf981cf2151fbf6a9a\",\"title\":\"Parts of recognition\",\"url\":\"https://www.semanticscholar.org/paper/150662e38fc67ca81ac93faf981cf2151fbf6a9a\",\"venue\":\"Cognition\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38663378\",\"name\":\"J. Fodor\"},{\"authorId\":\"3194015\",\"name\":\"Z. Pylyshyn\"}],\"doi\":\"10.1016/0010-0277(88)90031-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7\",\"title\":\"Connectionism and cognitive architecture: A critical analysis\",\"url\":\"https://www.semanticscholar.org/paper/56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7\",\"venue\":\"Cognition\",\"year\":1988},{\"arxivId\":\"1803.03067\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"289fb3709475f5c87df8d97f129af54029d27fee\",\"title\":\"Compositional Attention Networks for Machine Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/289fb3709475f5c87df8d97f129af54029d27fee\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1902.05660\",\"authors\":[{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2019.00681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"title\":\"Cycle-Consistency for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"}],\"doi\":\"10.18653/v1/P19-1621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2723f54b4f5ed2d3f3a47c1b6749bbf5d8c660fd\",\"title\":\"Are Red Roses Red? Evaluating Consistency of Question-Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/2723f54b4f5ed2d3f3a47c1b6749bbf5d8c660fd\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1802.08129\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2018.00915\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"title\":\"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.04696\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"}],\"doi\":\"10.18653/v1/D19-1596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"title\":\"Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/87d18100012d8e3bd85bfde93b34dadce4653fc6\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiasen Lu\"},{\"authorId\":null,\"name\":\"C Lawrence Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", and Devi Parikh . Vqa : Visual question answering\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE International Conference on Computer Vision\",\"year\":null}],\"title\":\"SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/27cea494961a45d6a0687c75248fd078999d9a43\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"