"{\"abstract\":\"Video interpolation aims to synthesize non-existent frames between two consecutive frames. Although existing optical flow based methods have achieved promising results, they still face great challenges in dealing with the interpolation of complicated dynamic scenes, which include occlusion, blur or abrupt brightness change. This is mainly because these cases may break the basic assumptions of the optical flow estimation (i.e. smoothness, consistency). In this work, we devised a novel structure-to-texture generation framework which splits the video interpolation task into two stages: structure-guided interpolation and texture refinement. In the first stage, deep structure-aware features are employed to predict feature flows from two consecutive frames to their intermediate result, and further generate the structure image of the intermediate frame. In the second stage, based on the generated coarse result, a Frame Texture Compensator is trained to fill in detailed textures. To the best of our knowledge, this is the first work that attempts to directly generate the intermediate frame through blending deep features. Experiments on both the benchmark datasets and challenging occlusion cases demonstrate the superiority of the proposed framework over the state-of-the-art methods. Codes are available on https://github.com/CM-BF/FeatureFlow.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\",\"url\":\"https://www.semanticscholar.org/author/1914700964\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\",\"url\":\"https://www.semanticscholar.org/author/1409848027\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\",\"url\":\"https://www.semanticscholar.org/author/47261253\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\",\"url\":\"https://www.semanticscholar.org/author/143719918\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.04642\",\"authors\":[{\"authorId\":\"49422053\",\"name\":\"Yihao Liu\"},{\"authorId\":\"1604613100\",\"name\":\"Liangbin Xie\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"title\":\"Enhanced Quadratic Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":219962863,\"doi\":\"10.1109/cvpr42600.2020.01402\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1904.02296\",\"authors\":[{\"authorId\":\"46772448\",\"name\":\"X. Chen\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2018.2869695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35dc2337a7f871c93b733432ae84635dffd366aa\",\"title\":\"Gated-GAN: Adversarial Gated Networks for Multi-Collection Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/35dc2337a7f871c93b733432ae84635dffd366aa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"1958191\",\"name\":\"X. Liu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2017.274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e378ce25579f3676ca50c8f6454e92a886b9e4d7\",\"title\":\"Robust Video Super-Resolution with Learned Temporal Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/e378ce25579f3676ca50c8f6454e92a886b9e4d7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3346215\",\"name\":\"R. Castagno\"},{\"authorId\":\"1684728\",\"name\":\"P. Haavisto\"},{\"authorId\":\"144763839\",\"name\":\"G. Ramponi\"}],\"doi\":\"10.1109/76.538926\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f16f2ce968d4caf85bf13eba8417bfb5e6edfa32\",\"title\":\"A method for motion adaptive frame rate up-conversion\",\"url\":\"https://www.semanticscholar.org/paper/f16f2ce968d4caf85bf13eba8417bfb5e6edfa32\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"50976427\",\"name\":\"L. Chen\"},{\"authorId\":\"7886022\",\"name\":\"Lianghui Ding\"},{\"authorId\":\"49538591\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/TIP.2018.2825100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9f8142cefbb99351853d930dcc3903c1e20e9d7\",\"title\":\"High-Order Model and Dynamic Filtering for Frame Rate Up-Conversion\",\"url\":\"https://www.semanticscholar.org/paper/c9f8142cefbb99351853d930dcc3903c1e20e9d7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1811.08815\",\"authors\":[{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/ICCV.2019.00638\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"title\":\"Learning Motion in Feature Space: Locally-Consistent Deformable Convolution Networks for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1007/978-3-030-01234-2_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"caec4597ebc0ceae0bd8706c23080d9c59b5404b\",\"title\":\"Deformable Pose Traversal Convolution for 3D Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/caec4597ebc0ceae0bd8706c23080d9c59b5404b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.06798\",\"authors\":[{\"authorId\":\"46772448\",\"name\":\"X. Chen\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1007/978-3-030-01216-8_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5470c1d487c5d86648aa4292e1cdbd852ce6947\",\"title\":\"Attention-GAN for Object Transfiguration in Wild Images\",\"url\":\"https://www.semanticscholar.org/paper/d5470c1d487c5d86648aa4292e1cdbd852ce6947\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1803.00657\",\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143901532\",\"name\":\"X. Yao\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TEVC.2019.2895748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbca46c24c800bee41b21ac0258651db54892e80\",\"title\":\"Evolutionary Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/cbca46c24c800bee41b21ac0258651db54892e80\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1902.10903\",\"authors\":[{\"authorId\":\"12874945\",\"name\":\"Jianzhong He\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"2894970\",\"name\":\"Yanhu Shan\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/CVPR.2019.00395\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9c7dec575f55c9b4d1b58358b0df734bbfdd88dd\",\"title\":\"Bi-Directional Cascade Network for Perceptual Edge Detection\",\"url\":\"https://www.semanticscholar.org/paper/9c7dec575f55c9b4d1b58358b0df734bbfdd88dd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2886023\",\"name\":\"Manuel Werlberger\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"2443335\",\"name\":\"M. Unger\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-642-23094-3_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"title\":\"Optical Flow Guided TV-L1 Video Interpolation and Restoration\",\"url\":\"https://www.semanticscholar.org/paper/fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"venue\":\"EMMCVPR\",\"year\":2011},{\"arxivId\":\"1810.08768\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/tpami.2019.2941941\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d833c48334e906537f21757b6f9fa44da66f6c76\",\"title\":\"MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d833c48334e906537f21757b6f9fa44da66f6c76\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1703.06211\",\"authors\":[{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"7217794\",\"name\":\"Haozhi Qi\"},{\"authorId\":\"3372084\",\"name\":\"Y. Xiong\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"46266081\",\"name\":\"Guodong Zhang\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/ICCV.2017.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a73a1840945e87583d89ca0216a2c449d50a4a3\",\"title\":\"Deformable Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/4a73a1840945e87583d89ca0216a2c449d50a4a3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1807.06521\",\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"6485607\",\"name\":\"Jongchan Park\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1007/978-3-030-01234-2_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de95601d9e3b20ec51aa33e1f27b1880d2c44ef2\",\"title\":\"CBAM: Convolutional Block Attention Module\",\"url\":\"https://www.semanticscholar.org/paper/de95601d9e3b20ec51aa33e1f27b1880d2c44ef2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1907.02544\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cde35c87aaabbc617d38f9cfaa2721a2e166d750\",\"title\":\"Large Scale Adversarial Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/cde35c87aaabbc617d38f9cfaa2721a2e166d750\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2951325\",\"name\":\"P. Charbonnier\"},{\"authorId\":\"1389816580\",\"name\":\"L. Blanc-F\\u00e9raud\"},{\"authorId\":\"31641158\",\"name\":\"G. Aubert\"},{\"authorId\":\"144459223\",\"name\":\"M. Barlaud\"}],\"doi\":\"10.1109/ICIP.1994.413553\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"870fdfe89c440f35ce83b915519001ea0da518ec\",\"title\":\"Two deterministic half-quadratic regularization algorithms for computed imaging\",\"url\":\"https://www.semanticscholar.org/paper/870fdfe89c440f35ce83b915519001ea0da518ec\",\"venue\":\"Proceedings of 1st International Conference on Image Processing\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1758739\",\"name\":\"Shuochen Su\"},{\"authorId\":\"2346590\",\"name\":\"M. Delbracio\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1752192\",\"name\":\"W. Heidrich\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":\"10.1109/CVPR.2017.33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f35dd6d024db12f6ae5d0854d8d6589af5d40c\",\"title\":\"Deep Video Deblurring for Hand-Held Cameras\",\"url\":\"https://www.semanticscholar.org/paper/f1f35dd6d024db12f6ae5d0854d8d6589af5d40c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.02898\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00342\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"02c6f4bb3adb4ce080575c122eb6430d2dc2a8ef\",\"title\":\"TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/02c6f4bb3adb4ce080575c122eb6430d2dc2a8ef\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.02716\",\"authors\":[{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"47841301\",\"name\":\"K. Yu\"},{\"authorId\":\"144964867\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPRW.2019.00247\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"28b3833743ab00904da1f4a30cd6c771cc164c0d\",\"title\":\"EDVR: Video Restoration With Enhanced Deformable Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/28b3833743ab00904da1f4a30cd6c771cc164c0d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1807.04979\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/978-3-030-01219-9_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58a91c57a3e799d25eceac7e95744e2692a13be3\",\"title\":\"Zoom-Net: Mining Deep Feature Interactions for Visual Relationship Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58a91c57a3e799d25eceac7e95744e2692a13be3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1803.05549\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1007/978-3-030-01258-8_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64c8a2a129ce8159f68dd25465c9d03ceaa56b14\",\"title\":\"Object Detection in Video with Spatiotemporal Sampling Networks\",\"url\":\"https://www.semanticscholar.org/paper/64c8a2a129ce8159f68dd25465c9d03ceaa56b14\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1706.09138\",\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"2482345\",\"name\":\"C. Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2018.2836316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"732fa3c6d17e6c8a857afd441ec2f43f028b07d0\",\"title\":\"Perceptual Adversarial Networks for Image-to-Image Transformation\",\"url\":\"https://www.semanticscholar.org/paper/732fa3c6d17e6c8a857afd441ec2f43f028b07d0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1803.10967\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"40405236\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2018.00183\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65fadccad0fc743876a259c2b779622636c2ffde\",\"title\":\"Context-Aware Synthesis for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/65fadccad0fc743876a259c2b779622636c2ffde\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.00708\",\"authors\":[{\"authorId\":\"8418299\",\"name\":\"Liuyuan Deng\"},{\"authorId\":null,\"name\":\"Ming Yang\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"47268256\",\"name\":\"T. Li\"},{\"authorId\":\"49699391\",\"name\":\"B. Hu\"},{\"authorId\":\"8205831\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/TITS.2019.2939832\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"833fbf0e4be3ba82e7a1efdbc16813ee849d9942\",\"title\":\"Restricted Deformable Convolution-Based Road Scene Semantic Segmentation Using Surround View Cameras\",\"url\":\"https://www.semanticscholar.org/paper/833fbf0e4be3ba82e7a1efdbc16813ee849d9942\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sanghyun Woo\"},{\"authorId\":null,\"name\":\"Jongchan Park\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module\",\"url\":\"\",\"venue\":\"The European Conference on Computer Vision (ECCV)\",\"year\":null},{\"arxivId\":\"1806.02919\",\"authors\":[{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"1766554\",\"name\":\"B. Wen\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbd65255f6266f798326acc8e0654e40ea0918cf\",\"title\":\"Non-Local Recurrent Network for Image Restoration\",\"url\":\"https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\"}],\"doi\":\"10.1109/CVPR.2019.00250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122539900\",\"name\":\"Shan You\"},{\"authorId\":\"144962257\",\"name\":\"C. Xu\"},{\"authorId\":\"48259108\",\"name\":\"C. Xu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1145/3097983.3098135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c4b6f59a4dd9b6fb589abb826d063f7872a5808\",\"title\":\"Learning from Multiple Teacher Networks\",\"url\":\"https://www.semanticscholar.org/paper/3c4b6f59a4dd9b6fb589abb826d063f7872a5808\",\"venue\":\"KDD\",\"year\":2017},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1807.02758\",\"authors\":[{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"50754085\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"49243317\",\"name\":\"K. Li\"},{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1007/978-3-030-01234-2_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9775f8964a2eea1c9e35a02b1b906487396ea1f5\",\"title\":\"Image Super-Resolution Using Very Deep Residual Channel Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/9775f8964a2eea1c9e35a02b1b906487396ea1f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shanshan Zhang\"},{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2018.00731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f97279a463a3bd18cc3c284d7a8ab28a5aaa1d\",\"title\":\"Occluded Pedestrian Detection Through Guided Attention in CNNs\",\"url\":\"https://www.semanticscholar.org/paper/63f97279a463a3bd18cc3c284d7a8ab28a5aaa1d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"2482345\",\"name\":\"C. Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.24963/ijcai.2017/404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"754c379ae4d66a47b2f6d41b4cd141ce186c0015\",\"title\":\"Tag Disentangled Generative Adversarial Network for Object Image Re-rendering\",\"url\":\"https://www.semanticscholar.org/paper/754c379ae4d66a47b2f6d41b4cd141ce186c0015\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007}],\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}\n"