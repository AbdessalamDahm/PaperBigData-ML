"{\"abstract\":\"During recent years remarkable progress has been made in visual saliency modeling. Our interest is in video saliency. Since videos are fundamentally different from still images, they are viewed differently by human observers. For example, the time each video frame is observed is a fraction of a second, while a still image can be viewed leisurely. Therefore, video saliency estimation methods should differ substantially from image saliency methods. In this paper we propose a novel method for video saliency estimation, which is inspired by the way people watch videos. We explicitly model the continuity of the video by predicting the saliency map of a given frame, conditioned on the map from the previous frame. Furthermore, accuracy and computation speed are improved by restricting the salient locations to a carefully selected candidate set. We validate our method using two gaze-tracked video datasets and show we outperform the state-of-the-art.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\",\"url\":\"https://www.semanticscholar.org/author/40635259\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\",\"url\":\"https://www.semanticscholar.org/author/1976171\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\",\"url\":\"https://www.semanticscholar.org/author/2177801\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\",\"url\":\"https://www.semanticscholar.org/author/1398327241\"}],\"citationVelocity\":17,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"2401277\",\"name\":\"Elizabeth Shtrom\"},{\"authorId\":\"3226509\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/CVPR.2012.6247703\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65dc75918d6476051604a96a138216ea04e2026d\",\"title\":\"Surface Regions of Interest for Viewpoint Selection\",\"url\":\"https://www.semanticscholar.org/paper/65dc75918d6476051604a96a138216ea04e2026d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82048748\",\"name\":\"Aytekin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5080655990fe0e0446bcb038b3e0adad0218bd29\",\"title\":\"Quantum Cuts A Quantum Mechanical Spectral Graph Partitioning Method for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/5080655990fe0e0446bcb038b3e0adad0218bd29\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2009.06924\",\"authors\":[{\"authorId\":\"71953006\",\"name\":\"A. Mishra\"},{\"authorId\":\"1798966\",\"name\":\"Hsuan-Tien Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fec5e2296390cd1d1615f44d98c1e75dd08ba5c4\",\"title\":\"360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales\",\"url\":\"https://www.semanticscholar.org/paper/fec5e2296390cd1d1615f44d98c1e75dd08ba5c4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2018.00783\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a2fae46c67189fb2aea33f12091772e635361f1\",\"title\":\"Going from Image to Video Saliency: Augmenting Image Salience with Dynamic Attentional Push\",\"url\":\"https://www.semanticscholar.org/paper/9a2fae46c67189fb2aea33f12091772e635361f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105152\",\"name\":\"\\u00c7aglar Aytekin\"},{\"authorId\":\"1795105\",\"name\":\"Ezgi C. Ozan\"},{\"authorId\":\"1741196\",\"name\":\"S. Kiranyaz\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1109/ICIP.2015.7351089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aed60d28183fbcc571c9fc2de3ec7cc7b06eee6\",\"title\":\"Visual saliency by extended quantum cuts\",\"url\":\"https://www.semanticscholar.org/paper/2aed60d28183fbcc571c9fc2de3ec7cc7b06eee6\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47835189\",\"name\":\"Qi Zhang\"},{\"authorId\":\"153239184\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1117/12.2503058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9c4688fb7a80f9f479203d7e3a0eccd2ff2ff0e\",\"title\":\"Dynamic saliency detection via CNN and spatial-temporal fusion\",\"url\":\"https://www.semanticscholar.org/paper/c9c4688fb7a80f9f479203d7e3a0eccd2ff2ff0e\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-319-10584-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8150f267cd2852f27639d4d85c3a311360346c88\",\"title\":\"Salient Montages from Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/8150f267cd2852f27639d4d85c3a311360346c88\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50543166\",\"name\":\"Anne-Flore Perrin\"},{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1007/978-3-030-29888-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"title\":\"How Well Current Saliency Prediction Models Perform on UAVs Videos?\",\"url\":\"https://www.semanticscholar.org/paper/3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"venue\":\"CAIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105152\",\"name\":\"\\u00c7aglar Aytekin\"},{\"authorId\":\"1795105\",\"name\":\"Ezgi C. Ozan\"},{\"authorId\":\"1741196\",\"name\":\"S. Kiranyaz\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1007/s11042-016-3431-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05e0dff6c848f1ecbfc91b0789005004c00f3228\",\"title\":\"Extended quantum cuts for unsupervised salient object extraction\",\"url\":\"https://www.semanticscholar.org/paper/05e0dff6c848f1ecbfc91b0789005004c00f3228\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":\"1702.00714\",\"authors\":[{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"3252109\",\"name\":\"N. Guyader\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7e7e251a4a69af23cf2de2eea49b4675ba49d2b\",\"title\":\"Learning a time-dependent master saliency map from eye-tracking data in videos\",\"url\":\"https://www.semanticscholar.org/paper/c7e7e251a4a69af23cf2de2eea49b4675ba49d2b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1109/TPAMI.2016.2623699\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9974b7d35d9425faf8d31ede581c605f4f0abc1\",\"title\":\"Summarizing Unconstrained Videos Using Salient Montages\",\"url\":\"https://www.semanticscholar.org/paper/c9974b7d35d9425faf8d31ede581c605f4f0abc1\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-54190-7_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9100bb05210dcb4539c1e5d92f4401d5a2ec9c10\",\"title\":\"Pano2Vid: Automatic Cinematography for Watching 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/9100bb05210dcb4539c1e5d92f4401d5a2ec9c10\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3000378\",\"name\":\"M. Desnoyer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3901e94de3c7646f31f2b60589fc39f694db4f99\",\"title\":\"Visual Utility : A Framework for Focusing Computer Vision Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/3901e94de3c7646f31f2b60589fc39f694db4f99\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1806.10359\",\"authors\":[{\"authorId\":\"9275594\",\"name\":\"Aymen Azaza\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1766272\",\"name\":\"A. Douik\"},{\"authorId\":\"37077230\",\"name\":\"Marc Masana\"}],\"doi\":\"10.1016/j.cviu.2018.06.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b43745fe3e9a999e13fb9ecab01d28f33ae4973\",\"title\":\"Context Proposals for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/8b43745fe3e9a999e13fb9ecab01d28f33ae4973\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"47842446\",\"name\":\"MingYu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360{\\\\deg} Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121544541\",\"name\":\"Zhiming Li\"}],\"doi\":\"10.1007/978-3-030-25128-4_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e598869e53844bb6911cfaab654a6052c4c6460\",\"title\":\"Fast Calculation Method of Video Saliency Based on Temporal and Spatial Edge-Preserving Filter\",\"url\":\"https://www.semanticscholar.org/paper/2e598869e53844bb6911cfaab654a6052c4c6460\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144183638\",\"name\":\"Xian Sun\"},{\"authorId\":\"2508428\",\"name\":\"Songhao Zhu\"},{\"authorId\":\"2751316\",\"name\":\"Yanyun Cheng\"}],\"doi\":\"10.1109/CCDC.2017.7978845\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"378d6155f9c7f81766cae7b8bee3eb707a640d7e\",\"title\":\"Object detection via optical information and background information\",\"url\":\"https://www.semanticscholar.org/paper/378d6155f9c7f81766cae7b8bee3eb707a640d7e\",\"venue\":\"2017 29th Chinese Control And Decision Conference (CCDC)\",\"year\":2017},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7667827\",\"name\":\"L. Duan\"},{\"authorId\":\"2026288\",\"name\":\"Tao Xi\"},{\"authorId\":\"48058046\",\"name\":\"S. Cui\"},{\"authorId\":\"144097734\",\"name\":\"H. Qi\"},{\"authorId\":\"1747569\",\"name\":\"A. Bovik\"}],\"doi\":\"10.1016/j.image.2015.08.005\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6018f3402ecc2aa657909a9eb4034b0fed328ff7\",\"title\":\"A spatiotemporal weighted dissimilarity-based method for video saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/6018f3402ecc2aa657909a9eb4034b0fed328ff7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":\"1611.08215\",\"authors\":[{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c92e701c908908bda407f12edf6984b283e8c258\",\"title\":\"Where Should You Attend While Driving?\",\"url\":\"https://www.semanticscholar.org/paper/c92e701c908908bda407f12edf6984b283e8c258\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"3252109\",\"name\":\"N. Guyader\"}],\"doi\":\"10.1167/14.8.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a9f2486ded05be499a7400ae548f0b90f2d8e34\",\"title\":\"How saliency, faces, and sound influence gaze in dynamic social scenes.\",\"url\":\"https://www.semanticscholar.org/paper/0a9f2486ded05be499a7400ae548f0b90f2d8e34\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"9741677\",\"name\":\"Senmao Ye\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"}],\"doi\":\"10.1109/TIP.2017.2658957\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75c5e7566ef28c5d51fe0825afe40d4bd3d90746\",\"title\":\"Revealing Event Saliency in Unconstrained Video Collection\",\"url\":\"https://www.semanticscholar.org/paper/75c5e7566ef28c5d51fe0825afe40d4bd3d90746\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2705863\",\"name\":\"C. Ozcinar\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/QoMEX.2018.8463418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0588eeafc09dd9893143327c79d2a077d03f387\",\"title\":\"Visual Attention in Omnidirectional Video for Virtual Reality Applications\",\"url\":\"https://www.semanticscholar.org/paper/f0588eeafc09dd9893143327c79d2a077d03f387\",\"venue\":\"2018 Tenth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"Mai Xu\"},{\"authorId\":\"39923487\",\"name\":\"Chen Li\"},{\"authorId\":\"1754571\",\"name\":\"Zulin Wang\"},{\"authorId\":\"1724811\",\"name\":\"Zhenzhong Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5814f82c6d65071e1b28875258a48ea3905206fa\",\"title\":\"Visual Quality Assessment of Panoramic Video\",\"url\":\"https://www.semanticscholar.org/paper/5814f82c6d65071e1b28875258a48ea3905206fa\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36014747\",\"name\":\"K. B. Rekha\"},{\"authorId\":\"152167930\",\"name\":\"A. R. Kumar\"}],\"doi\":\"10.21917/IJIVP.2017.0222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6b0fd487eb46d85c5ff89632b329d92880d80e6\",\"title\":\"EFFICIENT HIGH QUALITY VIDEO ASSESSMENT USING SALIENT FEATURES\",\"url\":\"https://www.semanticscholar.org/paper/c6b0fd487eb46d85c5ff89632b329d92880d80e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7818121\",\"name\":\"Jiaping Zhao\"},{\"authorId\":\"1973892\",\"name\":\"Christian Siagian\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2015.7298937\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c861a37b14d656053c52c5a1ebc1bee67c0bbedd\",\"title\":\"Fixation bank: Learning to reweight fixation candidates\",\"url\":\"https://www.semanticscholar.org/paper/c861a37b14d656053c52c5a1ebc1bee67c0bbedd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105152\",\"name\":\"\\u00c7aglar Aytekin\"},{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"1741196\",\"name\":\"S. Kiranyaz\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1109/ICPR.2016.7900221\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c1257ec024dfc2a3d73e6490f77ccf32cbff42d\",\"title\":\"Salient object segmentation based on linearly combined affinity graphs\",\"url\":\"https://www.semanticscholar.org/paper/6c1257ec024dfc2a3d73e6490f77ccf32cbff42d\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"2243473\",\"name\":\"Athanasios Katsamanis\"},{\"authorId\":\"46788705\",\"name\":\"A. Vatakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"title\":\"A behaviorally inspired fusion approach for computational audiovisual saliency modeling\",\"url\":\"https://www.semanticscholar.org/paper/5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1709.06342\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"46651223\",\"name\":\"C. Li\"},{\"authorId\":\"48354614\",\"name\":\"Zhenzhong Chen\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"2694633\",\"name\":\"Zhenyu Guan\"}],\"doi\":\"10.1109/TCSVT.2018.2886277\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a55f87fed6cf14896a7494e893180dc71a7d55c6\",\"title\":\"Assessing Visual Quality of Omnidirectional Videos\",\"url\":\"https://www.semanticscholar.org/paper/a55f87fed6cf14896a7494e893180dc71a7d55c6\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1603.08199\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"title\":\"Recurrent Mixture Density Network for Spatiotemporal Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"},{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"38501056\",\"name\":\"Feiniu Yuan\"}],\"doi\":\"10.1109/ICMEW.2014.6890709\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"48b738887df3c37f4962d80b1bd48937bc792b7d\",\"title\":\"Learning visual saliency for stereoscopic images\",\"url\":\"https://www.semanticscholar.org/paper/48b738887df3c37f4962d80b1bd48937bc792b7d\",\"venue\":\"2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2401277\",\"name\":\"Elizabeth Shtrom\"},{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"3226509\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/ICCV.2013.446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e99dfffde1fa61cf9806c439cddc3e18d0ee0b\",\"title\":\"Saliency Detection in Large Point Sets\",\"url\":\"https://www.semanticscholar.org/paper/66e99dfffde1fa61cf9806c439cddc3e18d0ee0b\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1806.01320\",\"authors\":[{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"50993085\",\"name\":\"Chun-Hung Chao\"},{\"authorId\":\"46181955\",\"name\":\"Jin-Dong Dong\"},{\"authorId\":\"2486384\",\"name\":\"Hao-Kai Wen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2018.00154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"title\":\"Cube Padding for Weakly-Supervised Saliency Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"37287044\",\"name\":\"A. Chakraborty\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICIP.2016.7532978\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f7367fb1dbd9fa62faa0c1ce3e6b8fd5abf9ed\",\"title\":\"A poisson process model for activity forecasting\",\"url\":\"https://www.semanticscholar.org/paper/63f7367fb1dbd9fa62faa0c1ce3e6b8fd5abf9ed\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144881168\",\"name\":\"Tobias Fischer\"},{\"authorId\":\"1999236\",\"name\":\"H. Chang\"},{\"authorId\":\"1699337\",\"name\":\"Y. Demiris\"}],\"doi\":\"10.1007/978-3-030-01249-6_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35ab5978376ea8113ff476076f18a677b4136d92\",\"title\":\"RT-GENE: Real-Time Eye Gaze Estimation in Natural Environments\",\"url\":\"https://www.semanticscholar.org/paper/35ab5978376ea8113ff476076f18a677b4136d92\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144224933\",\"name\":\"Y. Yao\"},{\"authorId\":\"9229269\",\"name\":\"Yingguang Hao\"},{\"authorId\":\"3285450\",\"name\":\"H. Wang\"}],\"doi\":\"10.1109/ICCT.2017.8359881\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48f228a70cbcdaedee3af9cbf32ae21053c47981\",\"title\":\"Small infrared target detection based on spatio-temporal fusion saliency\",\"url\":\"https://www.semanticscholar.org/paper/48f228a70cbcdaedee3af9cbf32ae21053c47981\",\"venue\":\"2017 IEEE 17th International Conference on Communication Technology (ICCT)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"1917151\",\"name\":\"Byung-Uck Kim\"},{\"authorId\":\"2310815\",\"name\":\"N. Lom\\u00e9nie\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1007/978-3-319-16628-5_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36999373fae12710ac0131ca401e256fb416e615\",\"title\":\"Search Guided Saliency\",\"url\":\"https://www.semanticscholar.org/paper/36999373fae12710ac0131ca401e256fb416e615\",\"venue\":\"ACCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50813206\",\"name\":\"F. Zhou\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1109/CVPR.2014.429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fe57bffe456e8a042c9c2292d9cd5ad24ab0e3a\",\"title\":\"Time-Mapping Using Space-Time Saliency\",\"url\":\"https://www.semanticscholar.org/paper/5fe57bffe456e8a042c9c2292d9cd5ad24ab0e3a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36014747\",\"name\":\"K. Bhanu Rekha\"},{\"authorId\":null,\"name\":\"AV Dr.RaviKumar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"733427eb9a798283e86dfeacc2f3bbed16513d24\",\"title\":\"An Algorithm and Architecture for HEVC Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/733427eb9a798283e86dfeacc2f3bbed16513d24\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"8189996\",\"name\":\"Jingxian Liu\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TMM.2017.2767784\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"title\":\"Saliency Detection in Face Videos: A Data-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"title\":\"Attentive Models in Vision 3 Input Image Human Fixation Map Loss Function Final Convolutional Layers Learned Prior Low , Medium and High Level Features Predicted Saliency Map Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143784265\",\"name\":\"D. Mahapatra\"},{\"authorId\":\"2455342\",\"name\":\"S. Gilani\"},{\"authorId\":\"1760714\",\"name\":\"M. Saini\"}],\"doi\":\"10.1109/JSTSP.2014.2315874\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb04e5f9e241f073faeffb39f5b93a48c77ca56e\",\"title\":\"Coherency Based Spatio-Temporal Saliency Detection for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/bb04e5f9e241f073faeffb39f5b93a48c77ca56e\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1847070\",\"name\":\"Keren Fu\"},{\"authorId\":\"144515956\",\"name\":\"I. Gu\"},{\"authorId\":\"33124583\",\"name\":\"Y. Yun\"},{\"authorId\":\"48281014\",\"name\":\"C. Gong\"},{\"authorId\":\"1688428\",\"name\":\"Jie Yang\"}],\"doi\":\"10.1109/ICPR.2014.411\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cff4372696b79d2fa235d7c442b61d8e420bfe0\",\"title\":\"Graph Construction for Salient Object Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0cff4372696b79d2fa235d7c442b61d8e420bfe0\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-020-01371-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"title\":\"DeepVS2.0: A Saliency-Structured Deep Learning Method for Predicting Dynamic Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.3233/IA-170033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"title\":\"Attentive models in vision: Computing saliency maps in the deep learning era\",\"url\":\"https://www.semanticscholar.org/paper/9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"venue\":\"Intelligenza Artificiale\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.2312/wiced.20171071\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985f76d3acec86219c6a9c11c145214972611e2c\",\"title\":\"Pano2Vid: Automatic Cinematography for Watching 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/985f76d3acec86219c6a9c11c145214972611e2c\",\"venue\":\"WICED@Eurographics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47474943\",\"name\":\"Shaotong Zhu\"},{\"authorId\":\"46868131\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47715899\",\"name\":\"T. Liang\"}],\"doi\":\"10.1109/ITNEC.2017.8284774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0451843feae306c5536f6987724388d05ebf57d\",\"title\":\"Video saliency detection using the propagation of image saliency between frames\",\"url\":\"https://www.semanticscholar.org/paper/f0451843feae306c5536f6987724388d05ebf57d\",\"venue\":\"2017 IEEE 2nd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"}],\"doi\":\"10.1007/s11042-015-2803-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bd8fd3f9ac207600460ab0c9fe7fa8a136f9618\",\"title\":\"Geometrical cues in visual saliency models for active object recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/2bd8fd3f9ac207600460ab0c9fe7fa8a136f9618\",\"venue\":\"PIVP '14\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"2401277\",\"name\":\"Elizabeth Shtrom\"},{\"authorId\":\"3226509\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2016.2522437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"130d686442c05baed24aa27e1455e345e40a1425\",\"title\":\"Surface regions of interest for viewpoint selection\",\"url\":\"https://www.semanticscholar.org/paper/130d686442c05baed24aa27e1455e345e40a1425\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/CVPR.2019.00415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"title\":\"Emotion-Aware Human Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46781563\",\"name\":\"R. Yang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/ICME.2016.7552864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1a94cd95e65bf045cef1075bfef302c81924aa0\",\"title\":\"Subjective-quality-optimized complexity control for HEVC decoding\",\"url\":\"https://www.semanticscholar.org/paper/a1a94cd95e65bf045cef1075bfef302c81924aa0\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":\"1811.07480\",\"authors\":[{\"authorId\":\"50251712\",\"name\":\"Ziqi Zhou\"},{\"authorId\":\"40514580\",\"name\":\"Z. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"47673404\",\"name\":\"S. Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1016/j.patcog.2020.107275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7de478275fdc5e154f6d904b910e8d291033edd\",\"title\":\"Global and Local Sensitivity Guided Key Salient Object Re-augmentation for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7de478275fdc5e154f6d904b910e8d291033edd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3362425\",\"name\":\"N. Souly\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s11263-015-0853-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5786bce12b6d9d4c9ba4cef422b3f6454f775f05\",\"title\":\"Visual Saliency Detection Using Group Lasso Regularization in Videos of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/5786bce12b6d9d4c9ba4cef422b3f6454f775f05\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"3411472\",\"name\":\"G. Panagiotaropoulou\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2018.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"113eda25ece35fd7ecb51cb104182a973ea2313e\",\"title\":\"Audio-Visual Temporal Saliency Modeling Validated by fMRI Data\",\"url\":\"https://www.semanticscholar.org/paper/113eda25ece35fd7ecb51cb104182a973ea2313e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"2009.06886\",\"authors\":[{\"authorId\":\"1492115154\",\"name\":\"Jinquan Li\"},{\"authorId\":\"1486405312\",\"name\":\"Ling Pei\"},{\"authorId\":\"71078457\",\"name\":\"Danping Zou\"},{\"authorId\":\"1944162339\",\"name\":\"Songpengcheng Xia\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"153051030\",\"name\":\"T. Li\"},{\"authorId\":\"145522783\",\"name\":\"Z. Sun\"},{\"authorId\":\"1969144\",\"name\":\"W. Yu\"}],\"doi\":\"10.1109/jsen.2020.3038432\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c902ed986820670e7a929ab5d20b732a8b4ef47\",\"title\":\"Attention-SLAM: A Visual Monocular SLAM Learning from Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/3c902ed986820670e7a929ab5d20b732a8b4ef47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8649661\",\"name\":\"Wenliang Qiu\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"51481294\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/TIP.2018.2843680\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6ad6937fa128b6a321461910967bbbd896b8a0f\",\"title\":\"Eye Fixation Assisted Video Saliency Detection via Total Variation-Based Pairwise Interaction\",\"url\":\"https://www.semanticscholar.org/paper/a6ad6937fa128b6a321461910967bbbd896b8a0f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48551624\",\"name\":\"Z. Wu\"},{\"authorId\":\"145235481\",\"name\":\"Li Su\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2018.2870954\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"title\":\"Learning Coupled Convolutional Networks Fusion for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144183598\",\"name\":\"T. Zhang\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"},{\"authorId\":\"1688428\",\"name\":\"Jie Yang\"},{\"authorId\":\"1740385\",\"name\":\"P. Shi\"},{\"authorId\":\"1714410\",\"name\":\"Wenjing Jia\"}],\"doi\":\"10.1109/ICIP.2015.7351160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046f08469fcfc837aa7660fa51c5fb456e3b23d8\",\"title\":\"Sparse coding-based spatiotemporal saliency for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/046f08469fcfc837aa7660fa51c5fb456e3b23d8\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/IVS.2017.7995833\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"983f02cbe705bb0d384c590241b6d07ffdd23277\",\"title\":\"Learning where to attend like a human driver\",\"url\":\"https://www.semanticscholar.org/paper/983f02cbe705bb0d384c590241b6d07ffdd23277\",\"venue\":\"2017 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2017},{\"arxivId\":\"1703.00495\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8230369f11b7c1dee7071806874dc0f66290c22\",\"title\":\"Making 360\\u00b0 Video Watchable in 2D: Learning Videography for Click Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/e8230369f11b7c1dee7071806874dc0f66290c22\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xinyi Wu\"},{\"authorId\":\"153006222\",\"name\":\"Zhenyao Wu\"},{\"authorId\":\"24392163\",\"name\":\"J. Zhang\"},{\"authorId\":\"47668707\",\"name\":\"Li-li Ju\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6927\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"title\":\"SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation-Based ConvLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1007/978-3-319-10578-9_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c7233825e45e9489f3fc6834c554521d230efcf\",\"title\":\"Comparing Salient Object Detection Results without Ground Truth\",\"url\":\"https://www.semanticscholar.org/paper/2c7233825e45e9489f3fc6834c554521d230efcf\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"3238659\",\"name\":\"Zhaoting Ye\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TIP.2016.2628583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3ed9103b9f9eee87ee0b1d3430b44c32bc140bc\",\"title\":\"Learning to Detect Video Saliency With HEVC Features\",\"url\":\"https://www.semanticscholar.org/paper/d3ed9103b9f9eee87ee0b1d3430b44c32bc140bc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2018958\",\"name\":\"Li-Hua Fu\"},{\"authorId\":\"47202964\",\"name\":\"W. Wu\"},{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1729664\",\"name\":\"R. Klette\"}],\"doi\":\"10.5391/IJFIS.2015.15.1.27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94854cd65969184c6056ab109114c7af1a11459e\",\"title\":\"Unusual Motion Detection for Vision-Based Driver Assistance\",\"url\":\"https://www.semanticscholar.org/paper/94854cd65969184c6056ab109114c7af1a11459e\",\"venue\":\"Int. J. Fuzzy Log. Intell. Syst.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12961054\",\"name\":\"Z. Lou\"},{\"authorId\":\"122381839\",\"name\":\"Link\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5d601a65a660a9db4199970bdb00ca28d14c512\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Structural image and video understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5d601a65a660a9db4199970bdb00ca28d14c512\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1016/j.image.2015.08.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"933fe12164f8e4c6c1075dc557b1b3fdcb4f5168\",\"title\":\"A perceptually based spatio-temporal computational framework for visual saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/933fe12164f8e4c6c1075dc557b1b3fdcb4f5168\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50034936\",\"name\":\"Xiaohui Fu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"145583736\",\"name\":\"Lei Qin\"}],\"doi\":\"10.1109/ChinaSIP.2015.7230461\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ad60366cccd3ce34eee83a23fd0047f76819f17\",\"title\":\"Video saliency prediction through machine learning with semantic information\",\"url\":\"https://www.semanticscholar.org/paper/1ad60366cccd3ce34eee83a23fd0047f76819f17\",\"venue\":\"2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29003312\",\"name\":\"\\u00c7a\\u011flar Aytekin\"},{\"authorId\":\"1720811\",\"name\":\"Horst Possegger\"},{\"authorId\":\"1679171\",\"name\":\"T. Mauthner\"},{\"authorId\":\"1741196\",\"name\":\"S. Kiranyaz\"},{\"authorId\":\"144746443\",\"name\":\"H. Bischof\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1109/TMM.2017.2713982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b93b07d795d68c04a37b15fcf66264535ff6b64a\",\"title\":\"Spatiotemporal Saliency Estimation by Spectral Foreground Detection\",\"url\":\"https://www.semanticscholar.org/paper/b93b07d795d68c04a37b15fcf66264535ff6b64a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1709.06316\",\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"title\":\"Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1604.00906\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46454-1_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a0957d2238a8dca24aa4a276c3370fad671c104\",\"title\":\"Detecting Engagement in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/2a0957d2238a8dca24aa4a276c3370fad671c104\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7726850\",\"name\":\"Yinghua Fu\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"38051237\",\"name\":\"W. Wang\"}],\"doi\":\"10.1007/s11042-016-3630-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e0496d49679f3c0eb8683886c6959788d01cb93\",\"title\":\"Sparse coding-based space-time video representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1e0496d49679f3c0eb8683886c6959788d01cb93\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":\"1705.03854\",\"authors\":[{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TPAMI.2018.2845370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"914e98db74f29fc608106ff438edde58965037c5\",\"title\":\"Predicting the Driver's Focus of Attention: The DR(eye)VE Project\",\"url\":\"https://www.semanticscholar.org/paper/914e98db74f29fc608106ff438edde58965037c5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1016/j.neucom.2017.05.050\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"453d9bd3564ef220e4f45944318ad1b626443875\",\"title\":\"Learning visual saliency from human fixations for stereoscopic images\",\"url\":\"https://www.semanticscholar.org/paper/453d9bd3564ef220e4f45944318ad1b626443875\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026288\",\"name\":\"Tao Xi\"},{\"authorId\":\"144876305\",\"name\":\"W. Zhao\"},{\"authorId\":null,\"name\":\"Han Wang\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TIP.2016.2631900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bed8005905852340fca01d9f06895f37a93ebaa2\",\"title\":\"Salient Object Detection With Spatiotemporal Background Priors for Video\",\"url\":\"https://www.semanticscholar.org/paper/bed8005905852340fca01d9f06895f37a93ebaa2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46989533\",\"name\":\"Lei Bao\"},{\"authorId\":\"1804316\",\"name\":\"X. Zhang\"},{\"authorId\":\"2755361\",\"name\":\"Yunfei Zheng\"},{\"authorId\":null,\"name\":\"Yang Li\"}],\"doi\":\"10.1007/s11042-015-2692-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef3508f2793a52bc31755f655203673401301bbf\",\"title\":\"Video saliency detection using 3D shearlet transform\",\"url\":\"https://www.semanticscholar.org/paper/ef3508f2793a52bc31755f655203673401301bbf\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50320765\",\"name\":\"B. Rekha\"},{\"authorId\":\"116702540\",\"name\":\"Ravi Kumar Av\"}],\"doi\":\"10.11591/ijeecs.v7.i3.pp708-717\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef446a5b2417a9b8ec1a18b299510afd7da6c72f\",\"title\":\"High Definition Video Compression Using Saliency Features\",\"url\":\"https://www.semanticscholar.org/paper/ef446a5b2417a9b8ec1a18b299510afd7da6c72f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1609.03868\",\"authors\":[{\"authorId\":\"2105152\",\"name\":\"\\u00c7aglar Aytekin\"},{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1016/j.patcog.2017.09.023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a86ecc99d77592df3147f6e1300cc8b8091d1aa4\",\"title\":\"Probabilistic saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/a86ecc99d77592df3147f6e1300cc8b8091d1aa4\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47786533\",\"name\":\"Junhao Li\"},{\"authorId\":\"152614069\",\"name\":\"Z. Liu\"},{\"authorId\":\"100620761\",\"name\":\"Xiang Zhang\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1683512\",\"name\":\"Liquan Shen\"}],\"doi\":\"10.1016/j.image.2015.04.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b80c895957a02b596791a360dee70ed11ccb13e\",\"title\":\"Spatiotemporal saliency detection based on superpixel-level trajectory\",\"url\":\"https://www.semanticscholar.org/paper/8b80c895957a02b596791a360dee70ed11ccb13e\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1612.02335\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e09735c76d125a3628e8c894bb1563b31309bfbc\",\"title\":\"Pano2Vid: Automatic Cinematography for Watching 360$^{\\\\circ}$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/e09735c76d125a3628e8c894bb1563b31309bfbc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-319-10584-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"title\":\"Saliency in Crowd\",\"url\":\"https://www.semanticscholar.org/paper/2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1805.00311\",\"authors\":[{\"authorId\":\"51280237\",\"name\":\"Yinheng Zhu\"},{\"authorId\":\"3075291\",\"name\":\"Wanli Chen\"},{\"authorId\":\"2264578\",\"name\":\"Xun Zhan\"},{\"authorId\":\"35877550\",\"name\":\"Zonglin Guo\"},{\"authorId\":\"2678219\",\"name\":\"Hongjian Shi\"},{\"authorId\":\"1781062\",\"name\":\"Ian G. Harris\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e0eb98d045565978f048d1eebc0f0f2fdf020b5\",\"title\":\"Head Mounted Pupil Tracking Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2e0eb98d045565978f048d1eebc0f0f2fdf020b5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941188\",\"name\":\"Jihoon Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce177693f8d4a3f761446d55828a9f348e1ddaa9\",\"title\":\"ON SELECTED PROBLEMS IN BACKSCATTER NETWORKS AND QUALITY OF EXPERIENCE IN NETWORKED APPLICATIONS\",\"url\":\"https://www.semanticscholar.org/paper/ce177693f8d4a3f761446d55828a9f348e1ddaa9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39793067\",\"name\":\"Zhongyu Lou\"},{\"authorId\":\"1695527\",\"name\":\"T. Gevers\"}],\"doi\":\"10.1109/TMM.2014.2363936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06ce8cdaa65d3bc3603184fb09a48a144cccd441\",\"title\":\"Extracting Primary Objects by Video Co-Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/06ce8cdaa65d3bc3603184fb09a48a144cccd441\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"},{\"authorId\":\"144620591\",\"name\":\"X. Wu\"},{\"authorId\":\"51104559\",\"name\":\"Ruilong Li\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"29962444\",\"name\":\"Zhao-Heng Zheng\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TMM.2018.2790163\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bdadc478d0290f8b275a4efedccf5395f70bb80\",\"title\":\"Detecting and Removing Visual Distractors for Video Aesthetic Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/1bdadc478d0290f8b275a4efedccf5395f70bb80\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"79439415\",\"name\":\"Haoyu Dong\"},{\"authorId\":\"2560900\",\"name\":\"Shengxi Li\"}],\"doi\":\"10.1109/CVPRW.2017.208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7d81091f909f718425eb428336ff72de5f3ad0e\",\"title\":\"Learning Dynamic GMM for Attention Distribution on Single-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/f7d81091f909f718425eb428336ff72de5f3ad0e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-70169-1_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"title\":\"Attentive Models in Vision: Computing Saliency Maps in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"venue\":\"AI*IA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50320765\",\"name\":\"B. Rekha\"},{\"authorId\":\"116702540\",\"name\":\"Ravi Kumar Av\"}],\"doi\":\"10.11591/IJEECS.V7.I3.PP761-772\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"17c5cf0eedf6f5e4ea7c8d89a5fbbbd7eb8a77da\",\"title\":\"High Quality Video Assessment Using Salient Features\",\"url\":\"https://www.semanticscholar.org/paper/17c5cf0eedf6f5e4ea7c8d89a5fbbbd7eb8a77da\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50219447\",\"name\":\"Zheng Wang\"},{\"authorId\":\"145811527\",\"name\":\"J. Ren\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.01.076\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a35ba189491bb8ae59df3c8b41a5f157e34231d2\",\"title\":\"A deep-learning based feature hybrid framework for spatiotemporal saliency detection inside videos\",\"url\":\"https://www.semanticscholar.org/paper/a35ba189491bb8ae59df3c8b41a5f157e34231d2\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105152\",\"name\":\"\\u00c7aglar Aytekin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a75b01f58924de70ad661285d45f4969b3e0262\",\"title\":\"A Quantum Mechanical Spectral Graph Partitioning Method for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1a75b01f58924de70ad661285d45f4969b3e0262\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8add9c8bad1f479f81f9cfaaf7b0e210fc3d929c\",\"title\":\"Perceptual object of interest recognition : application to the interpretation of instrumental activities of daily living for dementia studies. (Reconnaissance perceptuelle des objets d'Int\\u00e9r\\u00eat : application \\u00e0 l'interpre'tation des activite's instrumentales de la vie quotidienne pour les \\u00e9tudes de de\",\"url\":\"https://www.semanticscholar.org/paper/8add9c8bad1f479f81f9cfaaf7b0e210fc3d929c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"1902.10953\",\"authors\":[{\"authorId\":\"51441396\",\"name\":\"B. Mass\\u00e9\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"2793152\",\"name\":\"Pablo Mesejo\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1109/FG.2019.8756555\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c018c6d80b0dbcc8fcc64b8dcf2b46f785184da7\",\"title\":\"Extended Gaze Following: Detecting Objects in Videos Beyond the Camera Field of View\",\"url\":\"https://www.semanticscholar.org/paper/c018c6d80b0dbcc8fcc64b8dcf2b46f785184da7\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105152\",\"name\":\"\\u00c7aglar Aytekin\"},{\"authorId\":\"1741196\",\"name\":\"S. Kiranyaz\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1016/j.patrec.2015.12.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9abcfa69e4de33fc249db9a52ddc1bf26f98b7e\",\"title\":\"Learning to rank salient segments extracted by multispectral Quantum Cuts\",\"url\":\"https://www.semanticscholar.org/paper/e9abcfa69e4de33fc249db9a52ddc1bf26f98b7e\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7741488\",\"name\":\"Yinlin Hu\"},{\"authorId\":\"2721212\",\"name\":\"Yunsong Li\"},{\"authorId\":\"145072964\",\"name\":\"Rui Song\"}],\"doi\":\"10.1109/CVPR.2017.509\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ae77b4c567b996dabc8e9a757ed2edeb71f43c3\",\"title\":\"Robust Interpolation of Correspondences for Large Displacement Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/3ae77b4c567b996dabc8e9a757ed2edeb71f43c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"145143111\",\"name\":\"R. Hu\"},{\"authorId\":\"143684018\",\"name\":\"F. He\"}],\"doi\":\"10.1109/TIP.2018.2837106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1a854d574d0bd14786c41247db272be6062581\",\"title\":\"Find Who to Look at: Turning From Action to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/9f1a854d574d0bd14786c41247db272be6062581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1603.03669\",\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"2161276\",\"name\":\"Tristan Swedish\"},{\"authorId\":\"1398734187\",\"name\":\"E. Bayro-Corrochano\"},{\"authorId\":\"145711633\",\"name\":\"R. Raskar\"}],\"doi\":\"10.1109/ICCV.2017.188\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca1ff286ad8eba2aa6bc442f0f8321572fd0b090\",\"title\":\"Learning Gaze Transitions from Depth to Improve Video Saliency Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ca1ff286ad8eba2aa6bc442f0f8321572fd0b090\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbe038b455c20f02c86b26b2e08e7f907a1951e\",\"title\":\"Making 360$^{\\\\circ}$ Video Watchable in 2D: Learning Videography for Click Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/1bbe038b455c20f02c86b26b2e08e7f907a1951e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48692957\",\"name\":\"B. Jin\"},{\"authorId\":\"144022683\",\"name\":\"G. Yildirim\"},{\"authorId\":\"2850024\",\"name\":\"Cheryl Lau\"},{\"authorId\":\"2863792\",\"name\":\"A. Shaji\"},{\"authorId\":\"46871376\",\"name\":\"Maria V. Ortiz Segovia\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1117/12.2076936\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da30eb66c7ddc2537783ebf08b2bc7a4de9b5de3\",\"title\":\"Modeling the importance of faces in natural images\",\"url\":\"https://www.semanticscholar.org/paper/da30eb66c7ddc2537783ebf08b2bc7a4de9b5de3\",\"venue\":\"Electronic Imaging\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3089461\",\"name\":\"Grzegorz Kurzejamski\"},{\"authorId\":\"1786116\",\"name\":\"M. Iwanowski\"}],\"doi\":\"10.1007/978-3-319-59162-9_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b9336592778b8850437afa9bbac6c05da57ccd8\",\"title\":\"Saliency-Based Optimization for the Histogram of Oriented Gradients-Based Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/2b9336592778b8850437afa9bbac6c05da57ccd8\",\"venue\":\"CORES\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119924024\",\"name\":\"Yinan Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"}],\"doi\":\"10.1109/ACCESS.2017.2753830\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c90427085909029afd2af01d1967e80b78e01b88\",\"title\":\"Gaze-Assisted Multi-Stream Deep Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c90427085909029afd2af01d1967e80b78e01b88\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693461\",\"name\":\"Ping Hu\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"},{\"authorId\":\"144106250\",\"name\":\"K. Lu\"}],\"doi\":\"10.1109/TIP.2016.2594489\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09a4bcf284c3390ce5c7ab054326b0805dd6a0bd\",\"title\":\"Detecting Salient Objects via Color and Texture Compactness Hypotheses\",\"url\":\"https://www.semanticscholar.org/paper/09a4bcf284c3390ce5c7ab054326b0805dd6a0bd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2018.00785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"title\":\"Emotional Attention: A Study of Image Sentiment and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.06090\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14286fdc78b3039fc724274c18aa24caee8b59e\",\"title\":\"Digging Deeper Into Egocentric Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b14286fdc78b3039fc724274c18aa24caee8b59e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144877825\",\"name\":\"A. Singh\"},{\"authorId\":\"38200353\",\"name\":\"C. H. Chu\"},{\"authorId\":\"32563987\",\"name\":\"M. A. Pratt\"}],\"doi\":\"10.5220/0005206402010209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f40d63ac3290252c76c1c605d061713d99e7f8\",\"title\":\"Learning to Predict Video Saliency using Temporal Superpixels\",\"url\":\"https://www.semanticscholar.org/paper/02f40d63ac3290252c76c1c605d061713d99e7f8\",\"venue\":\"ICPRAM\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":null,\"name\":\"Songyang Zhang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2017.343\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"title\":\"Predicting Salient Face in Multiple-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1705.01759\",\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.153\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba227bb94ea9414bad8846673c904a10d813e443\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360\\u00b0 Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba227bb94ea9414bad8846673c904a10d813e443\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2016.11.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf54a133c89f730adc5ea12c3ac646971120781c\",\"title\":\"A comparative study for feature integration strategies in dynamic saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/cf54a133c89f730adc5ea12c3ac646971120781c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"}],\"doi\":\"10.1145/2662996.2663007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d33c73d344b33ca9ad72eaee26e59ae0a4cd2c9e\",\"title\":\"Geometrical Cues in Visual Saliency Models for Active Object Recognition in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d33c73d344b33ca9ad72eaee26e59ae0a4cd2c9e\",\"venue\":\"PIVP@MM\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2255689\",\"name\":\"F. Li\"}],\"doi\":\"10.1007/s00530-015-0490-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a449a96e7d259966616e78c62f1457ba5b16ffc9\",\"title\":\"A hierarchical visual saliency detection method by combining distinction and background probability maps\",\"url\":\"https://www.semanticscholar.org/paper/a449a96e7d259966616e78c62f1457ba5b16ffc9\",\"venue\":\"Multimedia Systems\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805004\",\"name\":\"T. Shanableh\"}],\"doi\":\"10.1007/s11760-015-0798-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6fff46c54f1be3de3a57da1b284e4a7c6593b4c\",\"title\":\"Saliency detection in MPEG and HEVC video using intra-frame and inter-frame distances\",\"url\":\"https://www.semanticscholar.org/paper/a6fff46c54f1be3de3a57da1b284e4a7c6593b4c\",\"venue\":\"Signal Image Video Process.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3362425\",\"name\":\"N. Souly\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1331cf3d34c1db0528bbd548e861f977aba54536\",\"title\":\"Visual Saliency Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1331cf3d34c1db0528bbd548e861f977aba54536\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941188\",\"name\":\"Jihoon Ryoo\"},{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1691843\",\"name\":\"Samir R Das\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.1145/2910017.2910592\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e359ea3ec9e22b7556d76bbf652c9e2daef1e4cd\",\"title\":\"Design and evaluation of a foveated video streaming service for commodity client devices\",\"url\":\"https://www.semanticscholar.org/paper/e359ea3ec9e22b7556d76bbf652c9e2daef1e4cd\",\"venue\":\"MMSys\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30447557\",\"name\":\"J. Zhao\"},{\"authorId\":\"46757505\",\"name\":\"X. Gao\"},{\"authorId\":\"145456329\",\"name\":\"G. Lin\"},{\"authorId\":\"150084176\",\"name\":\"D. Wang\"}],\"doi\":\"10.1016/J.IJLEO.2015.12.132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caf7dc11a0ae4787adea2f5fdb0c7eeb62b0f5f0\",\"title\":\"An optical information processing-based idea for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/caf7dc11a0ae4787adea2f5fdb0c7eeb62b0f5f0\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1610.02516\",\"authors\":[{\"authorId\":\"145653633\",\"name\":\"R. Yang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TBC.2018.2795459\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfbc779750453b6bc3ee0ddbeec4dcf3c556677b\",\"title\":\"Saliency-Guided Complexity Control for HEVC Decoding\",\"url\":\"https://www.semanticscholar.org/paper/cfbc779750453b6bc3ee0ddbeec4dcf3c556677b\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145607579\",\"name\":\"J. Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f782ad069edf3d3d0b619706dac38d40ed01c867\",\"title\":\"Shape representations using nested descriptors\",\"url\":\"https://www.semanticscholar.org/paper/f782ad069edf3d3d0b619706dac38d40ed01c867\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679171\",\"name\":\"T. Mauthner\"},{\"authorId\":\"1720811\",\"name\":\"Horst Possegger\"},{\"authorId\":\"1903921\",\"name\":\"Georg Waltner\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1109/CVPR.2015.7298864\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb1ea76ebb2653816fe2a48e4b224424b25fca20\",\"title\":\"Encoding based saliency detection for videos and images\",\"url\":\"https://www.semanticscholar.org/paper/cb1ea76ebb2653816fe2a48e4b224424b25fca20\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"corpusId\":168976,\"doi\":\"10.1109/CVPR.2013.152\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":10,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"3d7924e07914a147d7f6b868050d4edd093b952d\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145165599\",\"name\":\"T. Smith\"}],\"doi\":\"10.3167/PROJ.2012.060102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d0e67593c8866929ba88c7ec901931329a15ece\",\"title\":\"The attentional theory of cinematic continuity\",\"url\":\"https://www.semanticscholar.org/paper/7d0e67593c8866929ba88c7ec901931329a15ece\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B Block\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The visual story: seeing the structure of film, TV, and new media\",\"url\":\"\",\"venue\":\"The visual story: seeing the structure of film, TV, and new media\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46837630\",\"name\":\"Po-He Tseng\"},{\"authorId\":\"34414200\",\"name\":\"R. Carmi\"},{\"authorId\":\"145777626\",\"name\":\"I. G. Cameron\"},{\"authorId\":\"144440243\",\"name\":\"D. Munoz\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/9.7.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe311d83782515767e5584c4fa0239daee14075c\",\"title\":\"Quantifying center bias of observers in free viewing of dynamic natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/fe311d83782515767e5584c4fa0239daee14075c\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B. Block\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The visual story: seeing the structure of film\",\"url\":\"\",\"venue\":\"TV, and new media. Focal Press\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Zanetti\"},{\"authorId\":null,\"name\":\"L. Zelnik-Manor\"},{\"authorId\":null,\"name\":\"P. Perona\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A walk through the webs video clips\",\"url\":\"\",\"venue\":\"CVPRW, pages 1\\u20138. IEEE\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66313d48a6352e731e40450f80a66c64aabae817\",\"title\":\"Exploring new representations and applications for motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/66313d48a6352e731e40450f80a66c64aabae817\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12525266\",\"name\":\"Xinyi Cui\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1145/1631272.1631370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3257d74e4ad050a1a518a53b0d23751f771f483\",\"title\":\"Temporal spectral residual: fast motion saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/b3257d74e4ad050a1a518a53b0d23751f771f483\",\"venue\":\"MM '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2011.272\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"title\":\"Context-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tobii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Advertising research and eye tracking. http://www.tobii.com/ eye-tracking-research/global/ research/advertising-research\",\"url\":\"\",\"venue\":\"Advertising research and eye tracking. http://www.tobii.com/ eye-tracking-research/global/ research/advertising-research\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502152\",\"name\":\"A. Treisman\"},{\"authorId\":\"46475250\",\"name\":\"G. Gelade\"}],\"doi\":\"10.1016/0010-0285(80)90005-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76361a44e145732a39dbc68d9418871038c83be2\",\"title\":\"A feature-integration theory of attention\",\"url\":\"https://www.semanticscholar.org/paper/76361a44e145732a39dbc68d9418871038c83be2\",\"venue\":\"Cognitive Psychology\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12525266\",\"name\":\"Xinyi Cui\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"},{\"authorId\":\"1753384\",\"name\":\"S. Zhang\"},{\"authorId\":\"46319694\",\"name\":\"F. Yang\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1016/j.neucom.2011.12.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18e310aba29b710d712dbd223267b092e08f155d\",\"title\":\"Temporal Spectral Residual for fast salient motion detection\",\"url\":\"https://www.semanticscholar.org/paper/18e310aba29b710d712dbd223267b092e08f155d\",\"venue\":\"Neurocomputing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"}],\"doi\":\"10.1109/CVPR.2005.310\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a0024fbad7fcda8af1d241064f0948a8365b969\",\"title\":\"Robust object detection via soft cascade\",\"url\":\"https://www.semanticscholar.org/paper/9a0024fbad7fcda8af1d241064f0948a8365b969\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602925\",\"name\":\"Boris Schauerte\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/WACV.2012.6163035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92f0eaf5ceaaa940d3934d3a6f0cef76c54cf646\",\"title\":\"Predicting human gaze using quaternion DCT image signature saliency and face detection\",\"url\":\"https://www.semanticscholar.org/paper/92f0eaf5ceaaa940d3934d3a6f0cef76c54cf646\",\"venue\":\"2012 IEEE Workshop on the Applications of Computer Vision (WACV)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"}],\"doi\":\"10.1016/j.tics.2003.09.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fddfba9d2da26515f6510c579ad7e1d40ec0bc1\",\"title\":\"Human gaze control during real-world scene perception\",\"url\":\"https://www.semanticscholar.org/paper/0fddfba9d2da26515f6510c579ad7e1d40ec0bc1\",\"venue\":\"Trends in Cognitive Sciences\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Henderson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attentional theory of cinematic continu\",\"url\":\"\",\"venue\":\"Projections : The Journal for Movies and Mind\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/TPAMI.2009.112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62eb421cdac9de9255578f14fba55146d958be44\",\"title\":\"Spatiotemporal Saliency in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/62eb421cdac9de9255578f14fba55146d958be44\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2587444\",\"name\":\"A. Liaw\"},{\"authorId\":\"39707890\",\"name\":\"M. Wiener\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e633b41d93051375ef9135102d54fa097dc8cf8\",\"title\":\"Classification and Regression by randomForest\",\"url\":\"https://www.semanticscholar.org/paper/6e633b41d93051375ef9135102d54fa097dc8cf8\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88649317\",\"name\":\"G. Johansson\"}],\"doi\":\"10.3758/BF03212378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58ea2fa0580b2117618be6e1cc9658a5c9531dba\",\"title\":\"Visual perception of biological motion and a model for its analysis\",\"url\":\"https://www.semanticscholar.org/paper/58ea2fa0580b2117618be6e1cc9658a5c9531dba\",\"venue\":\"\",\"year\":1973},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T Smith\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attentional theory of cinematic continuity . Projections: The Journal for Movies and Mind\",\"url\":\"\",\"venue\":\"Attentional theory of cinematic continuity . Projections: The Journal for Movies and Mind\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34526725\",\"name\":\"Wonjun Kim\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2011.2125450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b96e94d318b583066df5fa946d5c2010d1704892\",\"title\":\"Spatiotemporal Saliency Detection and Its Applications in Static and Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b96e94d318b583066df5fa946d5c2010d1704892\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1007/s12559-010-9074-z\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"title\":\"Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion\",\"url\":\"https://www.semanticscholar.org/paper/27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"}],\"doi\":\"10.16910/JEMR.2.2.6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9695d4c31eb23c65870b022d413e70f0fd982eaa\",\"title\":\"Edit Blindness: The relationship between attention and global change blindness in dynamic scenes.\",\"url\":\"https://www.semanticscholar.org/paper/9695d4c31eb23c65870b022d413e70f0fd982eaa\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Goferman\"},{\"authorId\":null,\"name\":\"L. Zelnik-Manor\"},{\"authorId\":null,\"name\":\"A. Tal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Contextaware saliency detection\",\"url\":\"\",\"venue\":\"PAMI, 34(10):1915\\u20131926\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2004.834657\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"title\":\"Automatic foveation for video compression using a neurobiological model of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114264617\",\"name\":\"Roy C. Langford\"}],\"doi\":\"10.1037/H0050502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9c9e78a2b6a30acf4254416c3fd9a05660ac2ff\",\"title\":\"How People Look at Pictures, A Study of the Psychology of Perception in Art.\",\"url\":\"https://www.semanticscholar.org/paper/c9c9e78a2b6a30acf4254416c3fd9a05660ac2ff\",\"venue\":\"\",\"year\":1936},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2009.5459303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55b29a2505149d06d8c1d616cd30edca40cb029c\",\"title\":\"Poselets: Body part detectors trained using 3D human pose annotations\",\"url\":\"https://www.semanticscholar.org/paper/55b29a2505149d06d8c1d616cd30edca40cb029c\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49097100\",\"name\":\"Y. Cheng\"}],\"doi\":\"10.1109/34.400568\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c168275c59ba382588350ee1443537f59978183\",\"title\":\"Mean Shift, Mode Seeking, and Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1c168275c59ba382588350ee1443537f59978183\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48604993\",\"name\":\"R. Goldstein\"},{\"authorId\":\"2018241\",\"name\":\"R. Woods\"},{\"authorId\":\"1802088\",\"name\":\"E. Peli\"}],\"doi\":\"10.1016/J.COMPBIOMED.2006.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9968fde18e6e2f31bb1850ca0aeca1e3ef30104\",\"title\":\"Where people look when watching movies: Do all viewers look at the same place?\",\"url\":\"https://www.semanticscholar.org/paper/e9968fde18e6e2f31bb1850ca0aeca1e3ef30104\",\"venue\":\"Comput. Biol. Medicine\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Liaw\"},{\"authorId\":null,\"name\":\"M Wiener\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Classification and regression by randomforest. R news\",\"url\":\"\",\"venue\":\"Classification and regression by randomforest. R news\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"L.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention modeling\",\"url\":\"\",\"venue\":\"\",\"year\":2001}],\"title\":\"Learning Video Saliency from Human Gaze Using Candidate Selection\",\"topics\":[{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Decimation (signal processing)\",\"topicId\":\"8296\",\"url\":\"https://www.semanticscholar.org/topic/8296\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Difference of Gaussians\",\"topicId\":\"173199\",\"url\":\"https://www.semanticscholar.org/topic/173199\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Interpolation\",\"topicId\":\"1131\",\"url\":\"https://www.semanticscholar.org/topic/1131\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Scott continuity\",\"topicId\":\"79000\",\"url\":\"https://www.semanticscholar.org/topic/79000\"},{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Protein structure prediction\",\"topicId\":\"17949\",\"url\":\"https://www.semanticscholar.org/topic/17949\"},{\"topic\":\"Aggregate data\",\"topicId\":\"54317\",\"url\":\"https://www.semanticscholar.org/topic/54317\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"}],\"url\":\"https://www.semanticscholar.org/paper/3d7924e07914a147d7f6b868050d4edd093b952d\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013}\n"