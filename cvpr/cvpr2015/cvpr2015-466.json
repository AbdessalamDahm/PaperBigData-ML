"{\"abstract\":\"Visual features are of vital importance for human action understanding in videos. This paper presents a new video representation, called trajectory-pooled deep-convolutional descriptor (TDD), which shares the merits of both hand-crafted features [31] and deep-learned features [24]. Specifically, we utilize deep architectures to learn discriminative convolutional feature maps, and conduct trajectory-constrained pooling to aggregate these convolutional features into effective descriptors. To enhance the robustness of TDDs, we design two normalization methods to transform convolutional feature maps, namely spatiotemporal normalization and channel normalization. The advantages of our features come from (i) TDDs are automatically learned and contain high discriminative capacity compared with those hand-crafted features; (ii) TDDs take account of the intrinsic characteristics of temporal dimension and introduce the strategies of trajectory-constrained sampling and pooling for aggregating deep-learned features. We conduct experiments on two challenging datasets: HMD-B51 and UCF101. Experimental results show that TDDs outperform previous hand-crafted features [31] and deep-learned features [24]. Our method also achieves superior performance to the state of the art on these datasets.\",\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\",\"url\":\"https://www.semanticscholar.org/author/33345248\"},{\"authorId\":null,\"name\":\"Yu Qiao\",\"url\":null},{\"authorId\":\"50295995\",\"name\":\"X. Tang\",\"url\":\"https://www.semanticscholar.org/author/50295995\"}],\"citationVelocity\":178,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"title\":\"Enhancing human action recognition with region proposals\",\"url\":\"https://www.semanticscholar.org/paper/30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"venue\":\"ICRA 2015\",\"year\":2015},{\"arxivId\":\"2011.02451\",\"authors\":[{\"authorId\":\"10804714\",\"name\":\"Zheheng Jiang\"},{\"authorId\":\"65939441\",\"name\":\"Feixiang Zhou\"},{\"authorId\":\"2994481\",\"name\":\"Aite Zhao\"},{\"authorId\":\"51376876\",\"name\":\"X. Li\"},{\"authorId\":\"8998684\",\"name\":\"L. Li\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"67180560\",\"name\":\"Xuelong Li\"},{\"authorId\":\"13211796\",\"name\":\"H. Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b859a7939a81139b58780c0660eb038a3cc9c0d2\",\"title\":\"Muti-view Mouse Social Behaviour Recognition with Deep Graphical Model\",\"url\":\"https://www.semanticscholar.org/paper/b859a7939a81139b58780c0660eb038a3cc9c0d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d90bcce87174d2e85004036ae3e977c1ef222695\",\"title\":\"Scale-Adaptive Video Understanding.\",\"url\":\"https://www.semanticscholar.org/paper/d90bcce87174d2e85004036ae3e977c1ef222695\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2685285\",\"name\":\"P. Palasek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3507f5839b28cd385e477d7cadee3373c6bc3e67\",\"title\":\"Action recognition using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/3507f5839b28cd385e477d7cadee3373c6bc3e67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3265845.3265851\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"title\":\"Sports Video Captioning by Attentive Motion Representation based Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"venue\":\"MMSports@MM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47543815\",\"name\":\"Eunsoo Park\"},{\"authorId\":\"2932704\",\"name\":\"S. Kim\"},{\"authorId\":\"2267529\",\"name\":\"E. Ryu\"}],\"doi\":\"10.5909/JBE.2020.25.3.374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b238a27ab62caaaaf80dd685c0244a844978a49\",\"title\":\"Preprocessing Technique for Improving Action Recognition Performance in ERP Video with Multiple Objects\",\"url\":\"https://www.semanticscholar.org/paper/7b238a27ab62caaaaf80dd685c0244a844978a49\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"47775167\",\"name\":\"Teng Li\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/TNNLS.2017.2731775\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4d7b8eb0a8e6d2bb5b90b027c1bf32bad320ba5\",\"title\":\"Learning Semantic-Aligned Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/e4d7b8eb0a8e6d2bb5b90b027c1bf32bad320ba5\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72493600\",\"name\":\"Ala addin I. Sidig\"},{\"authorId\":\"35063144\",\"name\":\"Sabri A. Mahmoud\"}],\"doi\":\"10.14569/IJACSA.2018.090442\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"827797a1f7b6e29e5f2a6a846064245d56153aa3\",\"title\":\"Trajectory based Arabic Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/827797a1f7b6e29e5f2a6a846064245d56153aa3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33124583\",\"name\":\"Yixiao Yun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cc8f79365b9e6e0e12f83ee305fefc9b3089bbf\",\"title\":\"Riemannian Manifold-Based Modeling and Classification Methods for Video Activities with Applications to Assisted Living and Smart Home\",\"url\":\"https://www.semanticscholar.org/paper/7cc8f79365b9e6e0e12f83ee305fefc9b3089bbf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/TMM.2018.2887021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"title\":\"Unsupervised Universal Attribute Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/s13735-016-0117-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"title\":\"Learning hierarchical video representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48506667\",\"name\":\"Huan Yan\"},{\"authorId\":\"102684135\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yujie Wang\"},{\"authorId\":\"100511783\",\"name\":\"Kangle Xu\"}],\"doi\":\"10.1109/JSEN.2019.2938245\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd8358e4c90a511496cc7fbdd981f7ec28d7ca98\",\"title\":\"WiAct: A Passive WiFi-Based Human Activity Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/fd8358e4c90a511496cc7fbdd981f7ec28d7ca98\",\"venue\":\"IEEE Sensors Journal\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491438016\",\"name\":\"Yuanye Fang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-030-39431-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"title\":\"Action Recognition in Videos with Temporal Segments Fusions\",\"url\":\"https://www.semanticscholar.org/paper/d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"145070659\",\"name\":\"M. Sun\"},{\"authorId\":\"144437722\",\"name\":\"D. Yuan\"}],\"doi\":\"10.1109/IJCNN.2016.7727234\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c7136d250f731b0ca8c274a67a07830a69a08fd\",\"title\":\"Recurrent Temporal Sparse Autoencoder for attention-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c7136d250f731b0ca8c274a67a07830a69a08fd\",\"venue\":\"2016 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2016},{\"arxivId\":\"1805.06741\",\"authors\":[{\"authorId\":\"145505116\",\"name\":\"Xin Wei\"},{\"authorId\":\"49527646\",\"name\":\"Hui Wang\"},{\"authorId\":\"144493732\",\"name\":\"B. Scotney\"},{\"authorId\":\"144760098\",\"name\":\"H. Wan\"}],\"doi\":\"10.1016/j.patcog.2019.107012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddfde808af8dc8b737d115869d6cca780d050884\",\"title\":\"Minimum Margin Loss for Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ddfde808af8dc8b737d115869d6cca780d050884\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92959427\",\"name\":\"J. Wu\"},{\"authorId\":\"46274693\",\"name\":\"L. Yu\"},{\"authorId\":\"2173341\",\"name\":\"Liuqing Wang\"},{\"authorId\":\"104138391\",\"name\":\"K. Wang\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"2270833\",\"name\":\"T. Zhou\"}],\"doi\":\"10.1088/1742-6596/1237/2/022087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46d08e8368c9907a2dbc7971395366443ed7e2ee\",\"title\":\"Skeleton Based Temporal Action Detection with YOLO\",\"url\":\"https://www.semanticscholar.org/paper/46d08e8368c9907a2dbc7971395366443ed7e2ee\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1605.08140\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ee7990e2ae054aab5f1fc08670fe5eddb96fb19\",\"title\":\"Temporal attention filters for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0ee7990e2ae054aab5f1fc08670fe5eddb96fb19\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752811545\",\"name\":\"Guimei Qi\"},{\"authorId\":\"49134163\",\"name\":\"L. Du\"},{\"authorId\":\"48202088\",\"name\":\"Min Zhi\"},{\"authorId\":\"1752878249\",\"name\":\"Qing Yong\"}],\"doi\":\"10.1109/ICCCS49078.2020.9118580\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0d681e3b407721b7ff7bf754c5a90a081e6e75\",\"title\":\"Driving State Recognition for Ego-central Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/5a0d681e3b407721b7ff7bf754c5a90a081e6e75\",\"venue\":\"2020 5th International Conference on Computer and Communication Systems (ICCCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2581044\",\"name\":\"Cemil Zalluhoglu\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fb4c91cbb55ab8f6ceea76f1812506df58bf634\",\"title\":\"Region based multi-stream convolutional neural networks for collective activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fb4c91cbb55ab8f6ceea76f1812506df58bf634\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097122\",\"name\":\"Y. Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"9359893\",\"name\":\"Shengrong Gong\"}],\"doi\":\"10.1145/3378026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e075864cdf19117f6b5f78db877347e2bca4f\",\"title\":\"Spatio-temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/083e075864cdf19117f6b5f78db877347e2bca4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48114960\",\"name\":\"Ali Mohammad Nickfarjam\"},{\"authorId\":\"1402318194\",\"name\":\"H. Ebrahimpour-Komleh\"}],\"doi\":\"10.1007/s11042-018-7076-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"title\":\"Multi-input 1-dimensional deep belief network: action and activity recognition as case study\",\"url\":\"https://www.semanticscholar.org/paper/cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1612.00881\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1109/CVPR.2017.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f31de384bee955d8faffa1efe5f7b51cb299381\",\"title\":\"Procedural Generation of Videos to Train Deep Action Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f31de384bee955d8faffa1efe5f7b51cb299381\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"47748577\",\"name\":\"C. Ouyang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7671146\",\"name\":\"Shugang Zhang\"},{\"authorId\":\"145815630\",\"name\":\"Z. Wei\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"48545182\",\"name\":\"L. Huang\"},{\"authorId\":\"50695608\",\"name\":\"S. Wang\"},{\"authorId\":\"1700892\",\"name\":\"Z. Li\"}],\"doi\":\"10.1155/2017/3090343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bbbe65f6b4a01152b467a1376dfcf9203690013\",\"title\":\"A Review on Human Activity Recognition Using Vision-Based Method\",\"url\":\"https://www.semanticscholar.org/paper/8bbbe65f6b4a01152b467a1376dfcf9203690013\",\"venue\":\"Journal of healthcare engineering\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1607097044\",\"name\":\"Arif Ahmed Sekh\"},{\"authorId\":\"77242587\",\"name\":\"I. S. Opstad\"},{\"authorId\":\"46606875\",\"name\":\"\\u00c5sa Birna Birgisdottir\"},{\"authorId\":\"5322552\",\"name\":\"T. Myrmel\"},{\"authorId\":\"117242327\",\"name\":\"B. S. Ahluwalia\"},{\"authorId\":\"1492122663\",\"name\":\"Krishna Agarwal\"},{\"authorId\":\"145052847\",\"name\":\"D. K. Prasad\"}],\"doi\":\"10.1109/cvpr42600.2020.01403\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4775622074c8cc11185d4046497a675b9ac66e6f\",\"title\":\"Learning Nanoscale Motion Patterns of Vesicles in Living Cells\",\"url\":\"https://www.semanticscholar.org/paper/4775622074c8cc11185d4046497a675b9ac66e6f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1511.04067\",\"authors\":[{\"authorId\":\"39963722\",\"name\":\"Raviteja Vemulapalli\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"}],\"doi\":\"10.1109/CVPR.2016.519\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f71bb02fe5fb2719e588f7cb275e6effd1bf4858\",\"title\":\"Deep Gaussian Conditional Random Field Network: A Model-Based Deep Network for Discriminative Denoising\",\"url\":\"https://www.semanticscholar.org/paper/f71bb02fe5fb2719e588f7cb275e6effd1bf4858\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICASSP.2016.7471878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"586456925c74c51287476e4395b5c69a831442cc\",\"title\":\"Codebook enhancement of vlad representation for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/586456925c74c51287476e4395b5c69a831442cc\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1803.11333\",\"authors\":[{\"authorId\":\"148426228\",\"name\":\"Zhanxiang Feng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"46397019\",\"name\":\"X. Xie\"}],\"doi\":\"10.1109/TIP.2018.2818438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15b7247b23442d5eadb21ec86a6e371e39aac973\",\"title\":\"Learning View-Specific Deep Networks for Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/15b7247b23442d5eadb21ec86a6e371e39aac973\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1707.00823\",\"authors\":[{\"authorId\":\"79993273\",\"name\":\"Jian Liu\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/s11263-019-01192-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57ba391f7462d2f6b7957d30682670c7f833009d\",\"title\":\"Learning Human Pose Models from Synthesized Data for Robust RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57ba391f7462d2f6b7957d30682670c7f833009d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551536\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"title\":\"Enhanced Action Recognition With Visual Attribute-Augmented 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46396087\",\"name\":\"Y. Wang\"},{\"authorId\":\"5738033\",\"name\":\"R. Xiong\"},{\"authorId\":\"2964296\",\"name\":\"H. Yu\"},{\"authorId\":\"2610692\",\"name\":\"Jiafan Zhang\"},{\"authorId\":\"47910004\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/TMECH.2018.2799963\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c6362ccab206e6d15f6f51366272e2e887d66a1\",\"title\":\"Perception of Demonstration for Automatic Programing of Robotic Assembly: Framework, Algorithm, and Validation\",\"url\":\"https://www.semanticscholar.org/paper/1c6362ccab206e6d15f6f51366272e2e887d66a1\",\"venue\":\"IEEE/ASME Transactions on Mechatronics\",\"year\":2018},{\"arxivId\":\"1803.08834\",\"authors\":[{\"authorId\":\"3314448\",\"name\":\"Isma Hadji\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"title\":\"What Do We Understand About Convolutional Networks?\",\"url\":\"https://www.semanticscholar.org/paper/5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145632270\",\"name\":\"O. P. Mishra\"},{\"authorId\":\"145598806\",\"name\":\"Rajiv Kapoor\"}],\"doi\":\"10.5815/ijigsp.2019.09.04\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"074a131c50bbb7f9b612861d1e4cd7679fe83385\",\"title\":\"Human Action Recognition Using Modified Bag of Visual Word based on Spectral Perception\",\"url\":\"https://www.semanticscholar.org/paper/074a131c50bbb7f9b612861d1e4cd7679fe83385\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"title\":\"Action Recognition in Multi-view Videos\",\"url\":\"https://www.semanticscholar.org/paper/ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2006.07609\",\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1380212680\",\"name\":\"A. K. Qin\"},{\"authorId\":\"46276184\",\"name\":\"Jinyang Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddc5b5371bc1bc1ab283818034f3dcb3756cff69\",\"title\":\"DTG-Net: Differentiated Teachers Guided Self-Supervised Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ddc5b5371bc1bc1ab283818034f3dcb3756cff69\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1608.00797\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48596202\",\"name\":\"Hang Song\"},{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8d3b24cd4e6477e9dc7979580449db962d50e19\",\"title\":\"CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016\",\"url\":\"https://www.semanticscholar.org/paper/b8d3b24cd4e6477e9dc7979580449db962d50e19\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94173091\",\"name\":\"Y. Wan\"},{\"authorId\":\"7822579\",\"name\":\"Zujun Yu\"},{\"authorId\":null,\"name\":\"Yao Wang\"},{\"authorId\":\"50079335\",\"name\":\"Xingxin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2993227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"title\":\"Action Recognition Based on Two-Stream Convolutional Networks With Long-Short-Term Spatiotemporal Features\",\"url\":\"https://www.semanticscholar.org/paper/ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50502362\",\"name\":\"Z. Qin\"},{\"authorId\":\"3564227\",\"name\":\"C. Shelton\"}],\"doi\":\"10.1109/TIP.2017.2745209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"251e20403c015a3b7d799f7acf16444b1ec8ca60\",\"title\":\"Event Detection in Continuous Video: An Inference in Point Process Approach\",\"url\":\"https://www.semanticscholar.org/paper/251e20403c015a3b7d799f7acf16444b1ec8ca60\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbec00c4f238ae139cf9f53bd251581e90bfe96b\",\"title\":\"Mairal Large-Scale Machine Learning and Applications Soutenue le 4 octobre 2017\",\"url\":\"https://www.semanticscholar.org/paper/fbec00c4f238ae139cf9f53bd251581e90bfe96b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145742542\",\"name\":\"W. Li\"},{\"authorId\":\"144536247\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2018.2863943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd22e6532211f679ba6057d15a801ba448b9915c\",\"title\":\"Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/cd22e6532211f679ba6057d15a801ba448b9915c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1016/j.jvcir.2017.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"title\":\"A novel recurrent hybrid network for feature fusion in action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30177384\",\"name\":\"Md Azher Uddin\"},{\"authorId\":\"1750915\",\"name\":\"Y. Lee\"}],\"doi\":\"10.3390/s19071599\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"02830b56dde8695982251369b0c8a9f096b86e5b\",\"title\":\"Feature Fusion of Deep Spatial Features and Handcrafted Spatiotemporal Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/02830b56dde8695982251369b0c8a9f096b86e5b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144452609\",\"name\":\"Jonathan Boyle\"},{\"authorId\":\"145814824\",\"name\":\"Tahir Nawaz\"},{\"authorId\":\"1760885\",\"name\":\"J. Ferryman\"}],\"doi\":\"10.1109/AVSS.2017.8078509\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90c4c8bafe50500312350e73d93eda6e63196832\",\"title\":\"Deep trajectory representation-based clustering for motion pattern extraction in videos\",\"url\":\"https://www.semanticscholar.org/paper/90c4c8bafe50500312350e73d93eda6e63196832\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2581371\",\"name\":\"B. Seddik\"},{\"authorId\":\"3342453\",\"name\":\"S. Gazzah\"},{\"authorId\":\"2536574\",\"name\":\"N. B. Amara\"}],\"doi\":\"10.1049/iet-cvi.2016.0326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8e5d5be587c5db8164ad5cbcc70e03c63250a16\",\"title\":\"Human-action recognition using a multi-layered fusion scheme of Kinect modalities\",\"url\":\"https://www.semanticscholar.org/paper/c8e5d5be587c5db8164ad5cbcc70e03c63250a16\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138115\",\"name\":\"F. Negin\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.3390/s19194237\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"title\":\"An Unsupervised Framework for Online Spatiotemporal Detection of Activities of Daily Living by Hierarchical Activity Models\",\"url\":\"https://www.semanticscholar.org/paper/4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1711.05523\",\"authors\":[{\"authorId\":\"30161970\",\"name\":\"Reza Kahani\"},{\"authorId\":\"97703279\",\"name\":\"A. Talebpour\"},{\"authorId\":\"1405144816\",\"name\":\"Ahmad Mahmoudi-Aznaveh\"}],\"doi\":\"10.1007/s11042-019-7429-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1158affc69155d8de216d131a80a233be2a7ff9c\",\"title\":\"A correlation based feature representation for first-person activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1158affc69155d8de216d131a80a233be2a7ff9c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2004.08821\",\"authors\":[{\"authorId\":\"9698970\",\"name\":\"Florenc Demrozi\"},{\"authorId\":\"48950431\",\"name\":\"G. Pravadelli\"},{\"authorId\":\"46293053\",\"name\":\"A. Bihorac\"},{\"authorId\":\"1715006\",\"name\":\"Parisa Rashidi\"}],\"doi\":\"10.1109/ACCESS.2020.3037715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"837bf7383fce317dda02abf575f94b94bb0ef280\",\"title\":\"Human Activity Recognition Using Inertial, Physiological and Environmental Sensors: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/837bf7383fce317dda02abf575f94b94bb0ef280\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235260\",\"name\":\"Q. Chen\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/LSP.2017.2689921\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e5b160892b70a1e846aa9dcdf132b8011937ec6\",\"title\":\"Sequential Segment Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e5b160892b70a1e846aa9dcdf132b8011937ec6\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557606546\",\"name\":\"Jose M. Rodriguez-Borbon\"},{\"authorId\":\"72445820\",\"name\":\"X. Ma\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1778860\",\"name\":\"W. Najjar\"}],\"doi\":\"10.1109/TCSVT.2019.2895304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"title\":\"Heterogeneous Acceleration of HAR Applications\",\"url\":\"https://www.semanticscholar.org/paper/62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46895558\",\"name\":\"W. Song\"},{\"authorId\":\"38763335\",\"name\":\"Xinguo Yu\"}],\"doi\":\"10.1007/978-3-030-34879-3_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dd4965e33dbb9acbe22dd77bb9a7200b7b30134\",\"title\":\"Double Channel 3D Convolutional Neural Network for Exam Scene Classification of Invigilation Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dd4965e33dbb9acbe22dd77bb9a7200b7b30134\",\"venue\":\"PSIVT\",\"year\":2019},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.07160\",\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":null,\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TCYB.2017.2756840\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cec1d16a4d848fad0e92081294a1fde94a4d9f88\",\"title\":\"Body Joint Guided 3-D Deep Convolutional Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cec1d16a4d848fad0e92081294a1fde94a4d9f88\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"49112947\",\"name\":\"Shichao Zhao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1109/ICME.2017.8019360\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba30cc9d8bac724dafc0aea247159cc7e7105784\",\"title\":\"Top attention in line with time: A light-weight strategy\",\"url\":\"https://www.semanticscholar.org/paper/ba30cc9d8bac724dafc0aea247159cc7e7105784\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"- ING\"},{\"authorId\":\"69354043\",\"name\":\"Ang\"},{\"authorId\":null,\"name\":\"- IDA\"},{\"authorId\":\"102770090\",\"name\":\"Ussain\"},{\"authorId\":null,\"name\":\"- ESONG\"},{\"authorId\":\"115925168\",\"name\":\"Ei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"title\":\"Trajectory-based 3D Convolutional Descriptors for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303630\",\"name\":\"Zhaoyang Guo\"},{\"authorId\":\"2293643\",\"name\":\"Xin'an Wang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"144851083\",\"name\":\"Zheng Xie\"}],\"doi\":\"10.1587/TRANSINF.2017EDL8006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4e1fc36197583d165c887b6d82bc0e61ee0c64d\",\"title\":\"A Novel 3D Gradient LBP Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4e1fc36197583d165c887b6d82bc0e61ee0c64d\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"title\":\"Inertial-Vision: Cross-Domain Knowledge Transfer for Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"439668462b3630ba6c43aec8a24a53ea8a316491\",\"title\":\"Domain learning joint with semantic adaptation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/439668462b3630ba6c43aec8a24a53ea8a316491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1810.11348\",\"authors\":[{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"145294062\",\"name\":\"C. Yang\"},{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"}],\"doi\":\"10.5194/ISPRS-ANNALS-IV-1-W1-19-2017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b78d785ebcb57027db4abb5d64a31efad34d57\",\"title\":\"Security Event Recognition for Visual Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/38b78d785ebcb57027db4abb5d64a31efad34d57\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":\"2937291\",\"name\":\"Zhikang Fu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"title\":\"Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map Based Feature Extraction for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"145468103\",\"name\":\"S. Gao\"},{\"authorId\":\"38836749\",\"name\":\"Wenran Liu\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/MMSP.2018.8547088\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c4761b47c3f259559740c90bd42ed8442249499d\",\"title\":\"3-Stream Convolutional Networks for Video Action Recognition with Hybrid Motion Field\",\"url\":\"https://www.semanticscholar.org/paper/c4761b47c3f259559740c90bd42ed8442249499d\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1007/978-3-319-58771-4_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a244a8188f586a9fd8aedb728fe4f0e3c2ad05da\",\"title\":\"Spatio-Temporal Scale Selection in Video Data\",\"url\":\"https://www.semanticscholar.org/paper/a244a8188f586a9fd8aedb728fe4f0e3c2ad05da\",\"venue\":\"SSVM\",\"year\":2017},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1602.00224\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2019.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"title\":\"Order-aware Convolutional Pooling for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1701.05088\",\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1007/s10851-016-0691-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26a5154a0f7bf380c3d5044e344f280d7d7b85a6\",\"title\":\"Temporal Scale Selection in Time-Causal Scale Space\",\"url\":\"https://www.semanticscholar.org/paper/26a5154a0f7bf380c3d5044e344f280d7d7b85a6\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2016},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"37811966\",\"name\":\"Junior Fabian\"},{\"authorId\":\"145963874\",\"name\":\"P. Pardo\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"1763726\",\"name\":\"J. Gonz\\u00e1lez\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1707548\",\"name\":\"D. Misevic\"},{\"authorId\":\"145199579\",\"name\":\"U. Steiner\"},{\"authorId\":\"1743797\",\"name\":\"I. Guyon\"}],\"doi\":\"10.1109/ICCVW.2015.40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ad51a3cef14ce467297ff329c9f052beaa1675b\",\"title\":\"ChaLearn Looking at People 2015: Apparent Age and Cultural Event Recognition Datasets and Results\",\"url\":\"https://www.semanticscholar.org/paper/8ad51a3cef14ce467297ff329c9f052beaa1675b\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35678872\",\"name\":\"Hongxin Zhi\"},{\"authorId\":\"1792198\",\"name\":\"H. Yu\"},{\"authorId\":\"8086859\",\"name\":\"Shaomei Li\"},{\"authorId\":\"144036350\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/SSCI.2017.8285296\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"279459cbbc5c6db4802e9c737cc72a612d76f7fc\",\"title\":\"DMMLN: A deep multi-task and metric learning based network for video classification\",\"url\":\"https://www.semanticscholar.org/paper/279459cbbc5c6db4802e9c737cc72a612d76f7fc\",\"venue\":\"2017 IEEE Symposium Series on Computational Intelligence (SSCI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39812549\",\"name\":\"R. A. Sharma\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"},{\"authorId\":\"13614028\",\"name\":\"V. Chari\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1007/s11760-016-0916-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3bd338affdfccb752d0e98872e8b5ad8395cc3dc\",\"title\":\"Automatic analysis of broadcast football videos using contextual priors\",\"url\":\"https://www.semanticscholar.org/paper/3bd338affdfccb752d0e98872e8b5ad8395cc3dc\",\"venue\":\"Signal Image Video Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ICASSP.2018.8461988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"title\":\"A 203 FPS VLSI Architecture of Improved Dense Trajectories for Real-Time Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1708.09825\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCVW.2017.307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56426f6b86276b577f3d49c97189f609490022a0\",\"title\":\"Inferring Human Activities Using Robust Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/56426f6b86276b577f3d49c97189f609490022a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"2795697\",\"name\":\"Jingfan Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3123266.3123380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd9d64d8020585f464ad7c7bf3ad2b929992bac2\",\"title\":\"Video Visual Relation Detection\",\"url\":\"https://www.semanticscholar.org/paper/fd9d64d8020585f464ad7c7bf3ad2b929992bac2\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47039680\",\"name\":\"X. Zhao\"},{\"authorId\":\"145359183\",\"name\":\"Y. Yi\"},{\"authorId\":\"144186239\",\"name\":\"Zemin Qiu\"},{\"authorId\":\"9235546\",\"name\":\"Qingqing Zeng\"}],\"doi\":\"10.1109/ICCCS49078.2020.9118516\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"title\":\"Feature Retrieving for Human Action Recognition by Mixed Scale Deep Feature Combined with Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"venue\":\"2020 5th International Conference on Computer and Communication Systems (ICCCS)\",\"year\":2020},{\"arxivId\":\"1701.05432\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/WACV.2017.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ccf2c5212d793fc44d11f31bbdab7a26ef48f1c\",\"title\":\"Higher-Order Pooling of CNN Features via Kernel Linearization for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ccf2c5212d793fc44d11f31bbdab7a26ef48f1c\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754924\",\"name\":\"Zhihui Lin\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":\"10.1007/978-3-319-27674-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"429b4f5b078a3074426b9813216e3dd003b81aa2\",\"title\":\"A Very Deep Sequences Learning Approach for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/429b4f5b078a3074426b9813216e3dd003b81aa2\",\"venue\":\"MMM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682418\",\"name\":\"C. Aggarwal\"}],\"doi\":\"10.1007/978-3-319-94463-0_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb56d59750118f7662bdb0df65a9e6192c297547\",\"title\":\"Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/eb56d59750118f7662bdb0df65a9e6192c297547\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"}],\"doi\":\"10.1016/j.neucom.2018.02.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"title\":\"Action recognition with motion map 3D network\",\"url\":\"https://www.semanticscholar.org/paper/c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2238575\",\"name\":\"Daesik Kim\"},{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1109/IJCNN.2017.7965886\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4d1ecf5c5473c050e11f6876ce148de1c8920a\",\"title\":\"Matching video net: Memory-based embedding for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad4d1ecf5c5473c050e11f6876ce148de1c8920a\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145880435\",\"name\":\"X. Xu\"},{\"authorId\":\"120095506\",\"name\":\"LiQiming Liu\"},{\"authorId\":\"47059208\",\"name\":\"L. Zhang\"},{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1786301\",\"name\":\"J. Chen\"}],\"doi\":\"10.1002/spe.2701\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca7b86fc587625955adb35b768cb3b0037da7985\",\"title\":\"Abnormal visual event detection based on multi\\u2010instance learning and autoregressive integrated moving average model in edge\\u2010based Smart City surveillance\",\"url\":\"https://www.semanticscholar.org/paper/ca7b86fc587625955adb35b768cb3b0037da7985\",\"venue\":\"Softw. Pract. Exp.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48456191\",\"name\":\"Hirokatsu Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICRA.2019.8793709\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9ee0ef81eb1f5fa3c9dfebdec16933618d1f80e\",\"title\":\"Unsupervised Out-of-context Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9ee0ef81eb1f5fa3c9dfebdec16933618d1f80e\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2656603\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/DICTA.2017.8227505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"title\":\"Viewpoint Invariant RGB-D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"1802.06724\",\"authors\":[{\"authorId\":\"32082024\",\"name\":\"Ali Javidani\"},{\"authorId\":\"2757076\",\"name\":\"Ahmad Mahmoudi Aznaveh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"075ec6ce86828da112558e4c73e7135e0a7a269f\",\"title\":\"Learning Representative Temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/075ec6ce86828da112558e4c73e7135e0a7a269f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51268431\",\"name\":\"Xinshu Qiao\"},{\"authorId\":\"9764225\",\"name\":\"Chuanwei Zhou\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":null,\"name\":\"Jian Yang\"}],\"doi\":\"10.1109/ICIP.2018.8451548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53da7e4e193b334ce3891a55c61593a9fe479e19\",\"title\":\"Action Recognition with Spatial-Temporal Representation Analysis Across Grassmannian Manifold and Euclidean Space\",\"url\":\"https://www.semanticscholar.org/paper/53da7e4e193b334ce3891a55c61593a9fe479e19\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50726620\",\"name\":\"Konstantinos Raptis\"}],\"doi\":\"10.7912/C2CW7G\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"218eff05ba07f488e2c11c2f6f3a73dbf4b8dab9\",\"title\":\"The clash between two worlds in human action recognition: Supervised feature training vs recurrent ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/218eff05ba07f488e2c11c2f6f3a73dbf4b8dab9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66260185\",\"name\":\"Zhongliang Nie\"},{\"authorId\":\"67028934\",\"name\":\"A. Mattey\"},{\"authorId\":\"145147506\",\"name\":\"Zhe Huang\"},{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"}],\"doi\":\"10.1109/SMC.2018.00403\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c07a5c90e892a9ec5b2cdb8132eee43fc7f5c10\",\"title\":\"Revisit of Region-Feature Combinations in Facial Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0c07a5c90e892a9ec5b2cdb8132eee43fc7f5c10\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145929374\",\"name\":\"Xue Bai\"},{\"authorId\":\"3150525\",\"name\":\"Enqing Chen\"},{\"authorId\":\"74806144\",\"name\":\"Haron Chweya Tinega\"}],\"doi\":\"10.1117/12.2540268\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"title\":\"Real-time action recognition based on enhanced motion vector temporal segment network\",\"url\":\"https://www.semanticscholar.org/paper/678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"},{\"authorId\":\"20624177\",\"name\":\"F. Ziaeetabar\"},{\"authorId\":\"153091386\",\"name\":\"S. Pfeiffer\"},{\"authorId\":\"144108901\",\"name\":\"O. Kaya\"},{\"authorId\":\"1518685532\",\"name\":\"T. Kulvicius\"},{\"authorId\":\"152716499\",\"name\":\"M. Tamosiunaite\"}],\"doi\":\"10.1038/s41598-020-60923-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ca4989ac8316cfe0e243c7cd54f8a517f58aea0\",\"title\":\"Humans Predict Action using Grammar-like Structures\",\"url\":\"https://www.semanticscholar.org/paper/8ca4989ac8316cfe0e243c7cd54f8a517f58aea0\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145598806\",\"name\":\"Rajiv Kapoor\"},{\"authorId\":\"103825173\",\"name\":\"O. Mishra\"},{\"authorId\":\"50466173\",\"name\":\"Madan Mohan Tripathi\"}],\"doi\":\"10.2478/jee-2019-0077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36e4fab99667b646297b3d29f405a30e383a7728\",\"title\":\"Human action recognition using descriptor based on selective finite element analysis\",\"url\":\"https://www.semanticscholar.org/paper/36e4fab99667b646297b3d29f405a30e383a7728\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"},{\"authorId\":\"2452789\",\"name\":\"L. Wang\"},{\"authorId\":\"2095855\",\"name\":\"B. Ma\"},{\"authorId\":\"1859062\",\"name\":\"Xingjian Gu\"}],\"doi\":\"10.1016/j.jvcir.2018.08.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bb7e36612564868a7c880f8bd968250a1f3b40e\",\"title\":\"Evolution modeling with multi-scale smoothing for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6bb7e36612564868a7c880f8bd968250a1f3b40e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631862\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/s11042-019-7700-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad6493b57050955d9686b3c1fc84a19195852f8c\",\"title\":\"Computer vision based working environment monitoring to analyze Generalized Anxiety Disorder (GAD)\",\"url\":\"https://www.semanticscholar.org/paper/ad6493b57050955d9686b3c1fc84a19195852f8c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1707.09074\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2017.562\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e65e93566b909c04d2d74bc1ade1592e476adf\",\"title\":\"Learning from Video and Text via Large-Scale Discriminative Clustering\",\"url\":\"https://www.semanticscholar.org/paper/f6e65e93566b909c04d2d74bc1ade1592e476adf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152227626\",\"name\":\"X. Gao\"},{\"authorId\":\"89953833\",\"name\":\"W. Hu\"},{\"authorId\":\"1397711601\",\"name\":\"Jiaxiang Tang\"},{\"authorId\":\"48211108\",\"name\":\"J. Liu\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3343031.3351170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e41d005b41d94cce048afa31fb9f3c22ff76edbe\",\"title\":\"Optimized Skeleton-based Action Recognition via Sparsified Graph Regression\",\"url\":\"https://www.semanticscholar.org/paper/e41d005b41d94cce048afa31fb9f3c22ff76edbe\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1016/J.INFRARED.2019.103014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"title\":\"Deep residual infrared action recognition by integrating local and global spatio-temporal cues\",\"url\":\"https://www.semanticscholar.org/paper/45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/ICME.2016.7552981\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"65bd46ef168002fe53c5577a595e52bdd06ac5ff\",\"title\":\"Multimedia event detection via deep spatial-temporal neural networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd46ef168002fe53c5577a595e52bdd06ac5ff\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32062468\",\"name\":\"H. Ou\"},{\"authorId\":\"2994709\",\"name\":\"J. Sun\"}],\"doi\":\"10.1117/1.JEI.28.2.023009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"title\":\"Spatiotemporal information deep fusion network with frame attention mechanism for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"1409918228\",\"name\":\"Xin Ma\"},{\"authorId\":\"9348561\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/TMM.2019.2953814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9433095a4a5339815bc0fc000971797e99babdda\",\"title\":\"Convolutional Networks With Channel and STIPs Attention Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9433095a4a5339815bc0fc000971797e99babdda\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9521309\",\"name\":\"Reem Alfaifi\"},{\"authorId\":\"46845102\",\"name\":\"A M Artoli\"}],\"doi\":\"10.1007/s42979-020-00293-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"title\":\"Human Action Prediction with 3D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1706.07397\",\"authors\":[{\"authorId\":\"144891954\",\"name\":\"T. Sun\"},{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"}],\"doi\":\"10.1016/j.imavis.2017.06.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84e9de36dd7915f9334db5cc1fe567e17d717495\",\"title\":\"Fine-grained categorization via CNN-based automatic extraction and integration of object-level and part-level features\",\"url\":\"https://www.semanticscholar.org/paper/84e9de36dd7915f9334db5cc1fe567e17d717495\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"9355577\",\"name\":\"Shangqian Gao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"}],\"doi\":\"10.1109/TMM.2016.2626959\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"202f562509cfa2cd54296662a2bba7be43f0e500\",\"title\":\"Discriminative Multi-instance Multitask Learning for 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/202f562509cfa2cd54296662a2bba7be43f0e500\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1705.10420\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-017-1030-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5615d6045301ecbc5be35e46cab711f676aadf3a\",\"title\":\"Discriminatively Learned Hierarchical Rank Pooling Networks\",\"url\":\"https://www.semanticscholar.org/paper/5615d6045301ecbc5be35e46cab711f676aadf3a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1608.08128\",\"authors\":[{\"authorId\":\"145346209\",\"name\":\"A. Montes\"},{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1927afcfc5aa0d830cd867065ccb07f890b6d261\",\"title\":\"Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1927afcfc5aa0d830cd867065ccb07f890b6d261\",\"venue\":\"NIPS 2016\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-319-97909-0_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5549576809e8f9c3871c31285601f71d2d82ce5d\",\"title\":\"Residual Gating Fusion Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5549576809e8f9c3871c31285601f71d2d82ce5d\",\"venue\":\"CCBR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"title\":\"T-C3D: Temporal Convolutional 3D Network for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"39271955\",\"name\":\"Zhiwen Fang\"}],\"doi\":\"10.1117/12.2285518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"title\":\"Action recognition in depth video from RGB perspective: A knowledge transfer manner\",\"url\":\"https://www.semanticscholar.org/paper/e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97232650\",\"name\":\"W. Dai\"},{\"authorId\":\"50579817\",\"name\":\"Yi-min Chen\"},{\"authorId\":\"73067906\",\"name\":\"C. Huang\"},{\"authorId\":\"71543140\",\"name\":\"Mingke Gao\"},{\"authorId\":\"50812964\",\"name\":\"Xinyu Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851702\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"414e4a17e5b661c36e20937223bbe312ed227efc\",\"title\":\"Two-Stream Convolution Neural Network with Video-stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/414e4a17e5b661c36e20937223bbe312ed227efc\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1512.03980\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d748ab44c4ce2679027aebd5456d7e94a3924edc\",\"title\":\"Action Recognition with Image Based CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/d748ab44c4ce2679027aebd5456d7e94a3924edc\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1505.00296\",\"authors\":[{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPRW.2015.7301333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab369ba59724dd11f476b3019801512411bb49aa\",\"title\":\"Object-Scene Convolutional Neural Networks for event recognition in images\",\"url\":\"https://www.semanticscholar.org/paper/ab369ba59724dd11f476b3019801512411bb49aa\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47787302\",\"name\":\"J. Li\"},{\"authorId\":\"80541342\",\"name\":\"Zhenxin Xu\"},{\"authorId\":\"2284510\",\"name\":\"J. Li\"},{\"authorId\":\"48094476\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-030-19086-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6bb583d05366d5b3690ed79abdc47b853587333\",\"title\":\"An Improved Human Action Recognition Method Based on 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b6bb583d05366d5b3690ed79abdc47b853587333\",\"venue\":\"ADHIP\",\"year\":2018},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10804714\",\"name\":\"Zheheng Jiang\"},{\"authorId\":\"143964618\",\"name\":\"D. Crookes\"},{\"authorId\":\"6739239\",\"name\":\"B. Green\"},{\"authorId\":\"46317278\",\"name\":\"Yunfeng Zhao\"},{\"authorId\":\"40456891\",\"name\":\"Haiping Ma\"},{\"authorId\":\"50703754\",\"name\":\"Ling Li\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144951749\",\"name\":\"H. Zhou\"}],\"doi\":\"10.1109/TIP.2018.2875335\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4354153b6d7d80084376740288d9408f8ff9092e\",\"title\":\"Context-Aware Mouse Behavior Recognition Using Hidden Markov Models\",\"url\":\"https://www.semanticscholar.org/paper/4354153b6d7d80084376740288d9408f8ff9092e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145483621\",\"name\":\"R. Li\"},{\"authorId\":\"144977049\",\"name\":\"Hong Fu\"},{\"authorId\":\"2330090\",\"name\":\"W. Lo\"},{\"authorId\":\"8590720\",\"name\":\"Z. Chi\"},{\"authorId\":\"73741985\",\"name\":\"Zongxi Song\"},{\"authorId\":\"47027262\",\"name\":\"Desheng Wen\"}],\"doi\":\"10.1109/ACCESS.2019.2954744\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81b746600233bd63e0b09da17317f2fbde8ef440\",\"title\":\"Skeleton-Based Action Recognition With Key-Segment Descriptor and Temporal Step Matrix Model\",\"url\":\"https://www.semanticscholar.org/paper/81b746600233bd63e0b09da17317f2fbde8ef440\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83167758\",\"name\":\"Jie Zheng\"},{\"authorId\":\"11733729\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/CISP-BMEI48845.2019.8965930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b0f6b8c475d1765629ec7d03ae479c6036ee90a\",\"title\":\"Non-Local Spatiaotemporal Two-Stream Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b0f6b8c475d1765629ec7d03ae479c6036ee90a\",\"venue\":\"2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825539\",\"name\":\"Wei Wang\"},{\"authorId\":\"152299675\",\"name\":\"Siyuan Hao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"3124720\",\"name\":\"Shengtao Xiao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ACCESS.2019.2936604\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"74195742093c489401ef8dc3d7f8639fd12c20e8\",\"title\":\"Temporal Spiking Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74195742093c489401ef8dc3d7f8639fd12c20e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48186839\",\"name\":\"Yan Sun\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1727698\",\"name\":\"M. Nixon\"}],\"doi\":\"10.1016/j.patcog.2020.107710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eacf6707668d588696ba8b260170db6e2f1ae31\",\"title\":\"On parameterizing higher-order motion for behaviour recognition\",\"url\":\"https://www.semanticscholar.org/paper/1eacf6707668d588696ba8b260170db6e2f1ae31\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2581044\",\"name\":\"Cemil Zalluhoglu\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1016/j.imavis.2020.103870\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cd8441db0c344897d728c013dd600baf918113a\",\"title\":\"Collective Sports: A multi-task dataset for collective activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cd8441db0c344897d728c013dd600baf918113a\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":null,\"name\":\"Gedas Bertasius\"},{\"authorId\":null,\"name\":\"Tae-Hyun Oh\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/TIP.2019.2922826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"title\":\"Compact and Low-Complexity Binary Feature Descriptor and Fisher Vectors for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"47002225\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1177/1729881418825093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"title\":\"Hierarchical dynamic depth projected difference images\\u2013based action recognition in videos with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/ICCVW.2017.375\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f0a0c9552ff698f613439a4c095e24431c3ce2b\",\"title\":\"Darwintrees for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f0a0c9552ff698f613439a4c095e24431c3ce2b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"1492113737\",\"name\":\"Jiani Li\"},{\"authorId\":\"50248679\",\"name\":\"Guanshuo Wang\"},{\"authorId\":\"46499930\",\"name\":\"Y. Yuan\"},{\"authorId\":\"116176284\",\"name\":\"X. Zhou\"}],\"doi\":\"10.1007/978-3-030-29894-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8619695b651c52f8a847392588cc8911bb567bb\",\"title\":\"General Interaction-Aware Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d8619695b651c52f8a847392588cc8911bb567bb\",\"venue\":\"PRICAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"47430935\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1007/s11042-019-7675-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b04b5503532a69428841548e32c1847f4cd24021\",\"title\":\"Action prediction via deep residual feature learning and weighted loss\",\"url\":\"https://www.semanticscholar.org/paper/b04b5503532a69428841548e32c1847f4cd24021\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682418\",\"name\":\"C. Aggarwal\"}],\"doi\":\"10.1007/978-3-319-94463-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a53f2344de0620ed26861a350c1d109fcbc53de\",\"title\":\"Neural Networks and Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8a53f2344de0620ed26861a350c1d109fcbc53de\",\"venue\":\"Springer International Publishing\",\"year\":2018},{\"arxivId\":\"1706.08807\",\"authors\":[{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1007/978-3-319-66709-6_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd7504be47ebc28b0d608502ca78c0aea6a65a2\",\"title\":\"Recurrent Residual Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/edd7504be47ebc28b0d608502ca78c0aea6a65a2\",\"venue\":\"GCPR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"30118739\",\"name\":\"X. Zhang\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1109/ICASSP.2017.7952428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb5adf82ee210782d0afd66de6a5e257b1b9578\",\"title\":\"Learning a hierarchical spatio-temporal model for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbb5adf82ee210782d0afd66de6a5e257b1b9578\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"34094551\",\"name\":\"G. S. Babu\"},{\"authorId\":\"2307813\",\"name\":\"P. P. San\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"}],\"doi\":\"10.1109/CVPRW.2016.54\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a9168bd32550e06f2cd23105f82f6735fb2edf4\",\"title\":\"Multimodal Multi-Stream Deep Learning for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6a9168bd32550e06f2cd23105f82f6735fb2edf4\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"3307728\",\"name\":\"T. Sun\"},{\"authorId\":\"1888867\",\"name\":\"X. Jiang\"},{\"authorId\":\"2999987\",\"name\":\"Shilin Wang\"}],\"doi\":\"10.1109/CISP-BMEI.2016.7852685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"102f22cfa8e463a645f3b072cebed86777327278\",\"title\":\"Long-term Residual Recurrent Network for human interaction recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/102f22cfa8e463a645f3b072cebed86777327278\",\"venue\":\"2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2016},{\"arxivId\":\"1705.09894\",\"authors\":[{\"authorId\":\"38689120\",\"name\":\"Brandon Victor\"},{\"authorId\":\"1787185\",\"name\":\"Z. He\"},{\"authorId\":\"31548192\",\"name\":\"S. Morgan\"},{\"authorId\":\"2874225\",\"name\":\"D. Miniutti\"}],\"doi\":\"10.1109/CVPRW.2017.21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8820d1d3fa73cde623662d92ecf2e3faf1e3f328\",\"title\":\"Continuous Video to Simple Signals for Swimming Stroke Detection with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8820d1d3fa73cde623662d92ecf2e3faf1e3f328\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"Bharat Singh\"}],\"doi\":\"10.13016/M2FX7423N\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4391b692d6b7a242f719e4d219b4b7db155bccea\",\"title\":\"Detecting Objects and Actions with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4391b692d6b7a242f719e4d219b4b7db155bccea\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490672305\",\"name\":\"M. Suresha\"},{\"authorId\":\"98570196\",\"name\":\"S. Kuppa\"},{\"authorId\":\"1490675042\",\"name\":\"D. S. Raghukumar\"}],\"doi\":\"10.1007/s13735-019-00190-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac8f926b205bba37df42bab279c397a5eca07445\",\"title\":\"A study on deep learning spatiotemporal models and feature extraction techniques for video understanding\",\"url\":\"https://www.semanticscholar.org/paper/ac8f926b205bba37df42bab279c397a5eca07445\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7560130\",\"name\":\"L. Zhang\"},{\"authorId\":\"2238957\",\"name\":\"Xuezhi Xiang\"}],\"doi\":\"10.1007/s11042-019-08457-5\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"title\":\"Video event classification based on two-stage neural network\",\"url\":\"https://www.semanticscholar.org/paper/c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1701.07368\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/CVPRW.2017.161\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"title\":\"Deep Local Video Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51262793\",\"name\":\"Shichen Zeng\"},{\"authorId\":\"2024038\",\"name\":\"G. Lu\"},{\"authorId\":\"144281505\",\"name\":\"Peng Yan\"}],\"doi\":\"10.1007/s11760-018-1311-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6933ad150db24f9a1f24c1964defe9cbde86a0af\",\"title\":\"Enhancing human action recognition via structural average curves analysis\",\"url\":\"https://www.semanticscholar.org/paper/6933ad150db24f9a1f24c1964defe9cbde86a0af\",\"venue\":\"Signal Image Video Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46203415\",\"name\":\"N. Rahmad\"},{\"authorId\":\"1409463470\",\"name\":\"M. As'ari\"},{\"authorId\":\"52070258\",\"name\":\"N. F. Ghazali\"},{\"authorId\":\"52077963\",\"name\":\"N. Shahar\"},{\"authorId\":\"46172815\",\"name\":\"N. A. J. Sufri\"}],\"doi\":\"10.11591/IJEECS.V11.I3.PP987-993\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"52aa1267ef61ad3be83c3eb9d2d5459fb356323c\",\"title\":\"A Survey of Video Based Action Recognition in Sports\",\"url\":\"https://www.semanticscholar.org/paper/52aa1267ef61ad3be83c3eb9d2d5459fb356323c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"2765994\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"246c1e49f956063e28ba7941b6cc6242d753d303\",\"title\":\"CNN Activity : Tumbling Complete Tumbling ? Yes\",\"url\":\"https://www.semanticscholar.org/paper/246c1e49f956063e28ba7941b6cc6242d753d303\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7769579\",\"name\":\"Zhikang Liu\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"}],\"doi\":\"10.1109/ICIP.2017.8296405\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81d232e1f432db7de67baf4f30f240c62d1a9055\",\"title\":\"Improving human action recognitionby temporal attention\",\"url\":\"https://www.semanticscholar.org/paper/81d232e1f432db7de67baf4f30f240c62d1a9055\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1611.04357\",\"authors\":[{\"authorId\":\"7245071\",\"name\":\"Yashas Annadani\"},{\"authorId\":\"8341532\",\"name\":\"Vijayakrishna Naganoor\"},{\"authorId\":\"8341302\",\"name\":\"A. K. Jagadish\"},{\"authorId\":\"2139966\",\"name\":\"K. Chemmangat\"}],\"doi\":\"10.1109/SITIS.2016.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8f3f6d8f188f65ca8ea2725b248397c7d1e662d\",\"title\":\"Selfie Detection by Synergy-Constraint Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b8f3f6d8f188f65ca8ea2725b248397c7d1e662d\",\"venue\":\"2016 12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1049/iet-cvi.2017.0005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"title\":\"Fully convolutional networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"title\":\"Diversity encouraging ensemble of convolutional networks for high performance action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1016/j.patcog.2018.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c6f39799392aaacf2fb342518d420e30e24785\",\"title\":\"Learning principal orientations and residual descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2c6f39799392aaacf2fb342518d420e30e24785\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2911996.2912001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"title\":\"Action Recognition by Learning Deep Multi-Granular Spatio-Temporal Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"49543595\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/SmartWorld.2018.00123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"303b832123a0d219e91a3e0bed337d74f68b3fcc\",\"title\":\"Constructing Hierarchical Spatiotemporal Information for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303b832123a0d219e91a3e0bed337d74f68b3fcc\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2019216\",\"name\":\"J. Hong\"},{\"authorId\":\"1998950624\",\"name\":\"Zhangzhi Feng\"},{\"authorId\":\"50695489\",\"name\":\"S. Wang\"},{\"authorId\":\"2939584\",\"name\":\"A. Peet\"},{\"authorId\":\"46867408\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143971676\",\"name\":\"Y. Sun\"},{\"authorId\":\"103050765\",\"name\":\"M. Yang\"}],\"doi\":\"10.3389/fneur.2020.584682\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ce364347a0405400efda48476c1fec502e1ad5a\",\"title\":\"Brain Age Prediction of Children Using Routine Brain MR Images via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/7ce364347a0405400efda48476c1fec502e1ad5a\",\"venue\":\"Frontiers in Neurology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385152\",\"name\":\"Marko Jocic\"},{\"authorId\":null,\"name\":\"\\u0110or\\u0111e Obradovi\\u0107\"},{\"authorId\":\"2279271\",\"name\":\"V. Malbasa\"},{\"authorId\":\"3167093\",\"name\":\"Z. Konjovic\"},{\"authorId\":\"3167093\",\"name\":\"Z. Konjovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7cfe069ea662bedce7f5110fb8ae64e17d1db75\",\"title\":\"Image tagging with an ensemble of deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e7cfe069ea662bedce7f5110fb8ae64e17d1db75\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.05941\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b11d14c5812e5f41348beebceaca84b46cc55346\",\"title\":\"Skepxels: Spatio-temporal Image Representation of Human Skeleton Joints for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b11d14c5812e5f41348beebceaca84b46cc55346\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1702.08652\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"35061362\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/CVPR.2017.52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"title\":\"Scene Flow to Action Map: A New Representation for RGB-D Based Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"},{\"authorId\":\"144620591\",\"name\":\"X. Wu\"},{\"authorId\":\"51104559\",\"name\":\"Ruilong Li\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"29962444\",\"name\":\"Zhao-Heng Zheng\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TMM.2018.2790163\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bdadc478d0290f8b275a4efedccf5395f70bb80\",\"title\":\"Detecting and Removing Visual Distractors for Video Aesthetic Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/1bdadc478d0290f8b275a4efedccf5395f70bb80\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1894487\",\"name\":\"Noorkholis Luthfil Hakim\"},{\"authorId\":\"2215094\",\"name\":\"T. Shih\"},{\"authorId\":\"1485520099\",\"name\":\"S. P. K. Arachchi\"},{\"authorId\":\"144188350\",\"name\":\"W. Aditya\"},{\"authorId\":\"50580465\",\"name\":\"Yi-cheng Chen\"},{\"authorId\":\"2601342\",\"name\":\"Chih-Yang Lin\"}],\"doi\":\"10.3390/s19245429\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b488f46df7f7d853911c12824095ebec9f2250f\",\"title\":\"Dynamic Hand Gesture Recognition Using 3DCNN and LSTM with FSM Context-Aware Model\",\"url\":\"https://www.semanticscholar.org/paper/7b488f46df7f7d853911c12824095ebec9f2250f\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2017.341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"title\":\"Spatio-Temporal Vector of Locally Max Pooled Features for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1807.11122\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"51150048\",\"name\":\"Kyle Buettner\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"title\":\"Story Understanding in Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38764391\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"50561740\",\"name\":\"J. Zhang\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2017.2758524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"title\":\"Discriminative Part Selection for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35e808424317cf03b51516df7d083f45791311ae\",\"title\":\"A Survey for Action Recognition Research\",\"url\":\"https://www.semanticscholar.org/paper/35e808424317cf03b51516df7d083f45791311ae\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708998\",\"name\":\"Nguyen Anh Tu\"},{\"authorId\":\"1402997421\",\"name\":\"Thien Huynh-The\"},{\"authorId\":\"46581230\",\"name\":\"K. Khan\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/TCSVT.2018.2816960\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c0d23485c0ece214000ff8c0dcb3042bc114048\",\"title\":\"ML-HDP: A Hierarchical Bayesian Nonparametric Model for Recognizing Human Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/5c0d23485c0ece214000ff8c0dcb3042bc114048\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144985898\",\"name\":\"B. Su\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"145507765\",\"name\":\"X. Ding\"},{\"authorId\":\"47095827\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TIP.2017.2745212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab0981d1da654f37620ca39c6b42de21d7eb58eb\",\"title\":\"Unsupervised Hierarchical Dynamic Parsing and Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab0981d1da654f37620ca39c6b42de21d7eb58eb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"144813540\",\"name\":\"K. Kang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.606\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cbc729fdf29f78c42c5a04c331d753ee915f102\",\"title\":\"Slicing Convolutional Neural Network for Crowd Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5cbc729fdf29f78c42c5a04c331d753ee915f102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1007/978-981-15-1816-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c426717bed63d0afdfb16dd98c8cba915f52853\",\"title\":\"Action Recognition in Videos Using Multi-stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c426717bed63d0afdfb16dd98c8cba915f52853\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1016/J.NEUCOM.2018.10.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9589c0a89cc807ab6269fff8258278af2b0902ba\",\"title\":\"Correlational Convolutional LSTM for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9589c0a89cc807ab6269fff8258278af2b0902ba\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3439788\",\"name\":\"Ashwan Abdulmunem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f96f1afd07706941e96126d25577d9e1bf1fd1bb\",\"title\":\"Human action recognition using saliency-based global and local features\",\"url\":\"https://www.semanticscholar.org/paper/f96f1afd07706941e96126d25577d9e1bf1fd1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657684879\",\"name\":\"Tuan Hung Vu\"},{\"authorId\":\"1839657\",\"name\":\"J. Boonaert\"},{\"authorId\":\"50606173\",\"name\":\"S. Ambellouis\"},{\"authorId\":\"1398602709\",\"name\":\"A. Taleb-Ahmed\"}],\"doi\":\"10.1007/978-3-030-40605-9_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abf448ff5ea8ac4961b6688b74c148e92ad958aa\",\"title\":\"Vehicles Tracking by Combining Convolutional Neural Network Based Segmentation and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/abf448ff5ea8ac4961b6688b74c148e92ad958aa\",\"venue\":\"ACIVS\",\"year\":2020},{\"arxivId\":\"1803.11064\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/CVPR.2018.00234\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13d93feb5431eda200ac482b5230f51667c0146a\",\"title\":\"Non-linear Temporal Subspace Representations for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13d93feb5431eda200ac482b5230f51667c0146a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116261591\",\"name\":\"Ali Beikmohammadi\"},{\"authorId\":\"1692435\",\"name\":\"K. Faez\"},{\"authorId\":\"1642261834\",\"name\":\"Mohammad Hosein Mahmoodian\"},{\"authorId\":\"1642298581\",\"name\":\"Mohammad Hosein Hamian\"}],\"doi\":\"10.1109/ICSPIS48872.2019.9066014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b0b9a2a28e655b56822b3d06092b0cda6971e7b\",\"title\":\"Mixture of Deep-Based Representation and Shallow Classifiers to Recognize Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/8b0b9a2a28e655b56822b3d06092b0cda6971e7b\",\"venue\":\"2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8744711\",\"name\":\"K. Yamada\"},{\"authorId\":\"65954842\",\"name\":\"Seiya Ito\"},{\"authorId\":\"6965816\",\"name\":\"N. Kaneko\"},{\"authorId\":\"145441213\",\"name\":\"K. Sumi\"}],\"doi\":\"10.1007/978-3-030-21074-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f35f1424c9409f94868bd5a05a9cf291183b20\",\"title\":\"Human Action Recognition via Body Part Region Segmented Dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/88f35f1424c9409f94868bd5a05a9cf291183b20\",\"venue\":\"ACCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687893\",\"name\":\"Y. Li\"},{\"authorId\":\"2036880\",\"name\":\"Q. Zhai\"},{\"authorId\":\"3293151\",\"name\":\"Sihao Ding\"},{\"authorId\":null,\"name\":\"Fan Yang\"},{\"authorId\":\"143736626\",\"name\":\"Gang Li\"},{\"authorId\":\"145473088\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1007/s10044-017-0660-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a2f3b6d3423a36eaf164797122af67b1a547c73\",\"title\":\"Efficient health-related abnormal behavior detection with visual and inertial sensor integration\",\"url\":\"https://www.semanticscholar.org/paper/6a2f3b6d3423a36eaf164797122af67b1a547c73\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599734\",\"name\":\"I. Lee\"},{\"authorId\":\"8307027\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"72490873\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/TMM.2020.2978637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df84818634b8d82a10faf6a35f2775be002f1a6f\",\"title\":\"3-D Human Behavior Understanding Using Generalized TS-LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/df84818634b8d82a10faf6a35f2775be002f1a6f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70441825\",\"name\":\"Preksha Pareek\"},{\"authorId\":\"2136673\",\"name\":\"A. Thakkar\"}],\"doi\":\"10.1007/S10462-020-09904-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d11a704eeae83031e6141f87412cfe9b5b1585e2\",\"title\":\"A survey on video-based Human Action Recognition: recent updates, datasets, challenges, and applications\",\"url\":\"https://www.semanticscholar.org/paper/d11a704eeae83031e6141f87412cfe9b5b1585e2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.08511\",\"authors\":[{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"title\":\"Action Recognition Using Volumetric Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.05465\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f257300b2b4141aab73f93c146bf94846aef5fa1\",\"title\":\"Eigen Evolution Pooling for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f257300b2b4141aab73f93c146bf94846aef5fa1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1806.05341\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b23f52bde0bfa9ec093a360962df07f188dc1962\",\"title\":\"From Trailers to Storylines: An Efficient Way to Learn from Movies\",\"url\":\"https://www.semanticscholar.org/paper/b23f52bde0bfa9ec093a360962df07f188dc1962\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/ICME.2017.8019520\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"00083b3b6c356aca3eccfa26988ce52a6682bd6b\",\"title\":\"Temporal aggregation for first-person action recognition using Hilbert-Huang transform\",\"url\":\"https://www.semanticscholar.org/paper/00083b3b6c356aca3eccfa26988ce52a6682bd6b\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"Srijan Das\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"Fran\\u00e7ois Br\\u00e9mond\"}],\"doi\":\"10.1145/3293353.3293376\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"631a704edb53b0a4b852421891172ff785879727\",\"title\":\"Spatio-Temporal Grids for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/631a704edb53b0a4b852421891172ff785879727\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1608.04339\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-319-46604-0_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9abd35b37a49ee1295e8197aac59bde802a934f3\",\"title\":\"Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9abd35b37a49ee1295e8197aac59bde802a934f3\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1810.12522\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-030-20893-6_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"283181a2173b485726664edc6fe73f0465387629\",\"title\":\"Random Temporal Skipping for Multirate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/283181a2173b485726664edc6fe73f0465387629\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1739993\",\"name\":\"X. Wang\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.1109/IJCNN.2017.7965890\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f0d9ea525b545bd474ed5db59b33a56bfff39c9\",\"title\":\"Human action recognition using transfer learning with deep representations\",\"url\":\"https://www.semanticscholar.org/paper/6f0d9ea525b545bd474ed5db59b33a56bfff39c9\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677670\",\"name\":\"H. Kim\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"14090815\",\"name\":\"Seunghyeon Ko\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1117/1.OE.55.5.053108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9642adb0999d035d7589012d6ec05d618a223d33\",\"title\":\"Weighing classes and streams: toward better methods for two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/9642adb0999d035d7589012d6ec05d618a223d33\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46810646\",\"name\":\"Wenjing Shi\"},{\"authorId\":\"47293698\",\"name\":\"M. Pattichis\"},{\"authorId\":\"1403924583\",\"name\":\"Sylvia Celedon-Pattichis\"},{\"authorId\":\"9623767\",\"name\":\"Carlos LopezLeiva\"}],\"doi\":\"10.1109/ACSSC.2018.8645132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50ead642b71f97e58e4397ddda93414d2329a34f\",\"title\":\"Dynamic Group Interactions in Collaborative Learning Videos\",\"url\":\"https://www.semanticscholar.org/paper/50ead642b71f97e58e4397ddda93414d2329a34f\",\"venue\":\"2018 52nd Asilomar Conference on Signals, Systems, and Computers\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50762746\",\"name\":\"Jun Chen\"},{\"authorId\":\"13849852\",\"name\":\"Yuan-ping Xu\"},{\"authorId\":\"9372837\",\"name\":\"Chao-long Zhang\"},{\"authorId\":\"50070258\",\"name\":\"Zhijie Xu\"},{\"authorId\":\"89978385\",\"name\":\"Xiangxiang Meng\"},{\"authorId\":\"97773646\",\"name\":\"J. Wang\"}],\"doi\":\"10.23919/IConAC.2019.8894962\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841ae506fbd745273cd3498c923088a5736f42d1\",\"title\":\"An Improved Two-stream 3D Convolutional Neural Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/841ae506fbd745273cd3498c923088a5736f42d1\",\"venue\":\"2019 25th International Conference on Automation and Computing (ICAC)\",\"year\":2019},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720195\",\"name\":\"Y. Li\"},{\"authorId\":\"104269236\",\"name\":\"Q. Li\"},{\"authorId\":\"145298361\",\"name\":\"Q. Huang\"},{\"authorId\":\"31280147\",\"name\":\"Rongjie Xia\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1117/1.JEI.28.3.033002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cd2f99475097dfc1e4c37e67c1771a9df72b47f\",\"title\":\"Spatiotemporal interest point detector exploiting appearance and motion-variation information\",\"url\":\"https://www.semanticscholar.org/paper/1cd2f99475097dfc1e4c37e67c1771a9df72b47f\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651877\",\"name\":\"Changlin Li\"},{\"authorId\":\"49969948\",\"name\":\"Zhihui Li\"},{\"authorId\":\"1808390\",\"name\":\"ZongYuan Ge\"},{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"}],\"doi\":\"10.1016/j.jvcir.2019.102628\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2afb75192852c9bc56727070fbd3f0c502bebdf6\",\"title\":\"Knowledge driven temporal activity localization\",\"url\":\"https://www.semanticscholar.org/paper/2afb75192852c9bc56727070fbd3f0c502bebdf6\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1904.05244\",\"authors\":[{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"2878772\",\"name\":\"Girum G. Demisse\"},{\"authorId\":\"1814260\",\"name\":\"Enjie Ghorbel\"},{\"authorId\":\"144910981\",\"name\":\"Michel Antunes\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.3390/s19163503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99a978419ec4226f84ff34b43a866b8e711b6eee\",\"title\":\"Localized Trajectories for 2D and 3D Action Recognition \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/99a978419ec4226f84ff34b43a866b8e711b6eee\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3130030\",\"name\":\"M. Farrajota\"},{\"authorId\":\"143955056\",\"name\":\"J. Rodrigues\"},{\"authorId\":\"1394604631\",\"name\":\"J. M. H. du Buf\"}],\"doi\":\"10.1007/s10044-018-0727-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b999364980e4c21d9c22cc5a9f14501432999ca4\",\"title\":\"Human action recognition in videos with articulated pose information by deep networks\",\"url\":\"https://www.semanticscholar.org/paper/b999364980e4c21d9c22cc5a9f14501432999ca4\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1909.08287\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"1950475\",\"name\":\"Z. Lu\"},{\"authorId\":\"40448837\",\"name\":\"Jing Li\"},{\"authorId\":\"49876187\",\"name\":\"T. Yang\"},{\"authorId\":\"145670268\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/LSP.2018.2823910\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"98e098ba9ff98fc58f22fed6d3d8540116284b91\",\"title\":\"Global Temporal Representation Based CNNs for Infrared Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/98e098ba9ff98fc58f22fed6d3d8540116284b91\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-017-1043-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"60efdb2e204b2be6701a8e168983fa666feac1be\",\"title\":\"Transferring Deep Object and Scene Representations for Event Recognition in Still Images\",\"url\":\"https://www.semanticscholar.org/paper/60efdb2e204b2be6701a8e168983fa666feac1be\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31776258\",\"name\":\"Chin-Po Chen\"},{\"authorId\":\"3144712\",\"name\":\"S. S. Gau\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"}],\"doi\":\"10.1016/J.CSL.2018.12.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a7d7c885dc25d72cfa6dcd510b13511d43f5299\",\"title\":\"Toward differential diagnosis of autism spectrum disorder using multimodal behavior descriptors and executive functions\",\"url\":\"https://www.semanticscholar.org/paper/9a7d7c885dc25d72cfa6dcd510b13511d43f5299\",\"venue\":\"Comput. Speech Lang.\",\"year\":2019},{\"arxivId\":\"1609.00153\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2666739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c45ce0e5b795765d14b801b6b8ece2ee9bb641fb\",\"title\":\"Weakly Supervised PatchNets: Describing and Aggregating Local Patches for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c45ce0e5b795765d14b801b6b8ece2ee9bb641fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1702.08634\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/ICCV.2017.185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f36ea3d671cf458e8084db00c191b8784fb6f8c\",\"title\":\"Super-Trajectory for Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5f36ea3d671cf458e8084db00c191b8784fb6f8c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1703.01170\",\"authors\":[{\"authorId\":\"1804838\",\"name\":\"H. Shih\"}],\"doi\":\"10.1109/TCSVT.2017.2655624\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c4ce36063dd3496a5926afd301e562899ff53ea\",\"title\":\"A Survey of Content-Aware Video Analysis for Sports\",\"url\":\"https://www.semanticscholar.org/paper/5c4ce36063dd3496a5926afd301e562899ff53ea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"48981507\",\"name\":\"J. Cao\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ICPR.2016.7900180\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d2f054bc1f66cc9443956d5ac7501aee54e4e33\",\"title\":\"MSR-CNN: Applying motion salient region based descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d2f054bc1f66cc9443956d5ac7501aee54e4e33\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1808.00286\",\"authors\":[{\"authorId\":\"144655318\",\"name\":\"F. M. Castro\"},{\"authorId\":\"1712683\",\"name\":\"Nicol\\u00e1s Guil Mata\"},{\"authorId\":\"1398347979\",\"name\":\"M. Mar\\u00edn-Jim\\u00e9nez\"},{\"authorId\":\"34627686\",\"name\":\"Jes\\u00fas P\\u00e9rez Serrano\"},{\"authorId\":\"82008152\",\"name\":\"M. Ujald\\u00f3n\"}],\"doi\":\"10.1002/cpe.4786\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c94212ed65f04511173dd7d611ceb193e428fea\",\"title\":\"Energy\\u2010based tuning of convolutional neural networks on multi\\u2010GPUs\",\"url\":\"https://www.semanticscholar.org/paper/8c94212ed65f04511173dd7d611ceb193e428fea\",\"venue\":\"Concurr. Comput. Pract. Exp.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"48513221\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/ACCESS.2018.2887144\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb42378c1fee81bc25caeb159a98bfca3e8a2e69\",\"title\":\"Fall Detection in Videos With Trajectory-Weighted Deep-Convolutional Rank-Pooling Descriptor\",\"url\":\"https://www.semanticscholar.org/paper/cb42378c1fee81bc25caeb159a98bfca3e8a2e69\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1711.01201\",\"authors\":[{\"authorId\":\"35000381\",\"name\":\"Dillon Graham\"},{\"authorId\":\"3231447\",\"name\":\"Seyed Hamed Fatemi Langroudi\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"},{\"authorId\":\"3327477\",\"name\":\"D. Kudithipudi\"}],\"doi\":\"10.1109/ICRC.2017.8123647\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b70990fd8a2b4936394f41527f29f0095d92675\",\"title\":\"Convolutional Drift Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1b70990fd8a2b4936394f41527f29f0095d92675\",\"venue\":\"2017 IEEE International Conference on Rebooting Computing (ICRC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49763212\",\"name\":\"J. Tang\"},{\"authorId\":\"8769664\",\"name\":\"Haiqun Jin\"},{\"authorId\":\"1907978\",\"name\":\"Shoubiao Tan\"},{\"authorId\":\"145768551\",\"name\":\"D. Liang\"}],\"doi\":\"10.1016/j.imavis.2016.02.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac1a321c7c1b699244c7d8c09fdb68fcee1a9ed3\",\"title\":\"Cross-domain action recognition via collective matrix factorization with graph Laplacian regularization\",\"url\":\"https://www.semanticscholar.org/paper/ac1a321c7c1b699244c7d8c09fdb68fcee1a9ed3\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2018.2870945\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ddf75a72c5a95895dcfcd541cbd88311590375d\",\"title\":\"Low-Rank Transfer Human Motion Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9ddf75a72c5a95895dcfcd541cbd88311590375d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2018.2877936\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"title\":\"Toward Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1812.02817\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"2252963\",\"name\":\"Xinyu Li\"},{\"authorId\":\"3302978\",\"name\":\"Kaixiang Huang\"},{\"authorId\":\"7707929\",\"name\":\"Yehan Wang\"},{\"authorId\":\"51231992\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"144555425\",\"name\":\"Ivan Marsic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"556ca2389246b0a848b578dc824b930e1337a4bc\",\"title\":\"Tri-axial Self-Attention for Concurrent Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/556ca2389246b0a848b578dc824b930e1337a4bc\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"b2e5df82c55295912194ec73f0dca346f7c113f6\",\"title\":\"CUHK & SIAT Submission for THUMOS 15 Action Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b2e5df82c55295912194ec73f0dca346f7c113f6\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICPR.2018.8546325\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d45f7abeca184533ee0f0670c4946bcd34edda81\",\"title\":\"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/d45f7abeca184533ee0f0670c4946bcd34edda81\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"1739110630\",\"name\":\"Yuanrun Fang\"},{\"authorId\":\"10225694\",\"name\":\"F. Xiao\"},{\"authorId\":\"7970846\",\"name\":\"Li-juan Sun\"}],\"doi\":\"10.1109/TVT.2020.2993901\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65927d7236eeac2ddb099d4122b1a37b7f3cee9e\",\"title\":\"An Accurate Device-Free Action Recognition System Using Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/65927d7236eeac2ddb099d4122b1a37b7f3cee9e\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"}],\"doi\":\"10.1007/978-3-030-56150-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"title\":\"Action Recognition Using Co-trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/s10489-018-1395-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"title\":\"A motion-aware ConvLSTM network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":\"1906.04928\",\"authors\":[{\"authorId\":\"3210262\",\"name\":\"Senzhang Wang\"},{\"authorId\":\"144115026\",\"name\":\"J. Cao\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/tkde.2020.3025580\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a54c647f6db73621ec496ea86355726161c0898d\",\"title\":\"Deep Learning for Spatio-Temporal Data Mining: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/a54c647f6db73621ec496ea86355726161c0898d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1811.07503\",\"authors\":[{\"authorId\":\"143749869\",\"name\":\"Y. Pan\"},{\"authorId\":\"1703302\",\"name\":\"J. Xu\"},{\"authorId\":\"50468674\",\"name\":\"M. Wang\"},{\"authorId\":\"7173620\",\"name\":\"Jinmian Ye\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":\"10.1609/aaai.v33i01.33014683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"title\":\"Compressing Recurrent Neural Networks with Tensor Ring for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"144981720\",\"name\":\"Xue Bai\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"74806144\",\"name\":\"H. Tinega\"},{\"authorId\":\"1761058\",\"name\":\"Y. Ding\"}],\"doi\":\"10.1109/ACCESS.2019.2910604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"title\":\"A Spatiotemporal Heterogeneous Two-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49520427\",\"name\":\"X. Fang\"},{\"authorId\":\"12464207\",\"name\":\"Han Fang\"},{\"authorId\":\"145892592\",\"name\":\"Zhan Feng\"},{\"authorId\":\"144213485\",\"name\":\"Jie Wang\"},{\"authorId\":\"48207185\",\"name\":\"Libin Zhou\"}],\"doi\":\"10.3390/app10010139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8bc673379d76bdc211e45d45c5996a5fa35e336\",\"title\":\"Artificial Auditory Perception Pattern Recognition System Based on Spatiotemporal Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/e8bc673379d76bdc211e45d45c5996a5fa35e336\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"},{\"authorId\":\"152684187\",\"name\":\"Wei-Yun Yau\"},{\"authorId\":\"1714572\",\"name\":\"E. Teoh\"},{\"authorId\":\"1387241200\",\"name\":\"N. Magnenat-Thalmann\"}],\"doi\":\"10.1109/APSIPA.2017.8282038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13876f084198f182f4d031c4927585a3623a181f\",\"title\":\"Pose-invariant kinematic features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/13876f084198f182f4d031c4927585a3623a181f\",\"venue\":\"2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773194\",\"name\":\"Fei Pan\"},{\"authorId\":\"1720424\",\"name\":\"Y. Guo\"},{\"authorId\":\"151485208\",\"name\":\"Z. Yan\"},{\"authorId\":\"50115448\",\"name\":\"Jie Guo\"}],\"doi\":\"10.1109/ICME.2019.00283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"title\":\"Temporal Segment Convolutional Kernel Networks for Sequence Modeling of Videos\",\"url\":\"https://www.semanticscholar.org/paper/85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145024325\",\"name\":\"Y. Zeng\"},{\"authorId\":\"1704688\",\"name\":\"A. Vilanova\"},{\"authorId\":\"2713976\",\"name\":\"N. Sepasian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"792f115212b5dd92e2956e81292a214a40e81cea\",\"title\":\"Spatio-Temporal Data Mining, Visual Analytics for Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/792f115212b5dd92e2956e81292a214a40e81cea\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2366262\",\"name\":\"Junkai Chen\"},{\"authorId\":\"8590720\",\"name\":\"Z. Chi\"},{\"authorId\":\"144977049\",\"name\":\"Hong Fu\"}],\"doi\":\"10.1016/j.cviu.2016.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddef793a07612d6e9efdc5fa72720a48ec5017a6\",\"title\":\"A new framework with multiple tasks for detecting and locating pain events in video\",\"url\":\"https://www.semanticscholar.org/paper/ddef793a07612d6e9efdc5fa72720a48ec5017a6\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TSMC.2016.2625840\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"title\":\"Group Sparse-Based Mid-Level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48842639\",\"name\":\"Dotan Kaufman\"},{\"authorId\":\"36813724\",\"name\":\"Gil Levi\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"48519520\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1109/ICCV.2017.20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62e6b749ed5825739aa906021c5e613803d5cbe2\",\"title\":\"Temporal Tessellation: A Unified Approach for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/62e6b749ed5825739aa906021c5e613803d5cbe2\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"46947100\",\"name\":\"Zhibin Li\"}],\"doi\":\"10.1016/j.image.2020.115809\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"835963d0f0157841597d6c0d923df6491fa1244e\",\"title\":\"Deeply fusing multi-model quality-aware features for sophisticated human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/835963d0f0157841597d6c0d923df6491fa1244e\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18947121\",\"name\":\"Muhammad Attique Khan\"},{\"authorId\":\"7550152\",\"name\":\"Yudong Zhang\"},{\"authorId\":\"46883468\",\"name\":\"S. Khan\"},{\"authorId\":\"1845891052\",\"name\":\"Muhammad Attique\"},{\"authorId\":\"46855540\",\"name\":\"A. Rehman\"},{\"authorId\":\"5686109\",\"name\":\"Sanghyun Seo\"}],\"doi\":\"10.1007/s11042-020-09408-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a42ddba691a30ffd1b2ce059eace768e0a1965a6\",\"title\":\"A resource conscious human action recognition framework using 26-layered deep convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/a42ddba691a30ffd1b2ce059eace768e0a1965a6\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7224408\",\"name\":\"Himangi Saraogi\"},{\"authorId\":\"39812549\",\"name\":\"R. A. Sharma\"},{\"authorId\":\"37956314\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1145/3009977.3010074\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"add6d96fc018986f51a1aac47eae9ee3fc62fb66\",\"title\":\"Event recognition in broadcast soccer videos\",\"url\":\"https://www.semanticscholar.org/paper/add6d96fc018986f51a1aac47eae9ee3fc62fb66\",\"venue\":\"ICVGIP '16\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39812549\",\"name\":\"R. A. Sharma\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"13614028\",\"name\":\"V. Chari\"},{\"authorId\":\"1790095\",\"name\":\"J. Sivaswamy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4638ee9dda100be48da979403bf4f54c11ef5b7e\",\"title\":\"Automatic Analysis of Cricket And Soccer Broadcast Videos\",\"url\":\"https://www.semanticscholar.org/paper/4638ee9dda100be48da979403bf4f54c11ef5b7e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1802.00977\",\"authors\":[{\"authorId\":\"35964034\",\"name\":\"Yuliang Xiu\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"34269118\",\"name\":\"H. Wang\"},{\"authorId\":\"35807809\",\"name\":\"Y. Fang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6759fd391e3f8a1aea7673d617d3e1b04d069804\",\"title\":\"Pose Flow: Efficient Online Pose Tracking\",\"url\":\"https://www.semanticscholar.org/paper/6759fd391e3f8a1aea7673d617d3e1b04d069804\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40989062\",\"name\":\"Nweke Henry Friday\"},{\"authorId\":\"1403206186\",\"name\":\"M. A. Al-garadi\"},{\"authorId\":\"2280741\",\"name\":\"G. Mujtaba\"},{\"authorId\":\"40994774\",\"name\":\"U. R. Alo\"},{\"authorId\":\"1814285\",\"name\":\"A. Waqas\"}],\"doi\":\"10.1109/ICOMET.2018.8346364\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d472d018965ef68d1b2895804e322e17a8af2ecb\",\"title\":\"Deep learning fusion conceptual frameworks for complex human activity recognition using mobile and wearable sensors\",\"url\":\"https://www.semanticscholar.org/paper/d472d018965ef68d1b2895804e322e17a8af2ecb\",\"venue\":\"2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119958\",\"name\":\"B. Fu\"},{\"authorId\":\"2265721\",\"name\":\"Naser Damer\"},{\"authorId\":\"2178720\",\"name\":\"Florian Kirchbuchner\"},{\"authorId\":\"145307900\",\"name\":\"Arjan Kuijper\"}],\"doi\":\"10.1109/ACCESS.2020.2991891\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1a11339fd37ed9dc409fdf160436c3ffafe06a6\",\"title\":\"Sensing Technology for Human Activity Recognition: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/e1a11339fd37ed9dc409fdf160436c3ffafe06a6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1709.06447\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"939232314d39b26c89cd190c005b2ca71f14220a\",\"title\":\"Human Activity Recognition Using Robust Adaptive Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/939232314d39b26c89cd190c005b2ca71f14220a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571637\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/TIP.2018.2866688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"title\":\"Learning Match Kernels on Grassmann Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8492319\",\"name\":\"Z. Wang\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"145951569\",\"name\":\"Wu Luo\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICIP.2018.8451483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dce5aa041b08862f24f4e11301e9466a204d24f4\",\"title\":\"Key Joints Selection and Spatiotemporal Mining for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce5aa041b08862f24f4e11301e9466a204d24f4\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/DICTA.2017.8227428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b8b33481e92189044fd595ed9d177812017e0f3\",\"title\":\"Evaluation of Triple-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b8b33481e92189044fd595ed9d177812017e0f3\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3439788\",\"name\":\"Ashwan Abdulmunem\"},{\"authorId\":\"7827503\",\"name\":\"Y. Lai\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"}],\"doi\":\"10.1109/ICPR.2016.7899734\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e22022de2db3432b3d77a49180b58d29058750d2\",\"title\":\"3D GLOH features for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e22022de2db3432b3d77a49180b58d29058750d2\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004671930\",\"name\":\"Zhenzhi Wang\"},{\"authorId\":\"152536294\",\"name\":\"Ziteng Gao\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff80201906d5534dc186e0821ada754dd9ab34e2\",\"title\":\"Boundary-Aware Cascade Networks for Temporal Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ff80201906d5534dc186e0821ada754dd9ab34e2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1419463073\",\"name\":\"Huaizhong Zhang\"},{\"authorId\":\"37603348\",\"name\":\"C. Luo\"},{\"authorId\":\"47599111\",\"name\":\"Q. Wang\"},{\"authorId\":\"145228198\",\"name\":\"M. Kitchin\"},{\"authorId\":\"3052243\",\"name\":\"Andrew Parmley\"},{\"authorId\":\"1404852743\",\"name\":\"Jes\\u00fas Monge-\\u00c1lvarez\"},{\"authorId\":\"1397280789\",\"name\":\"P. Casaseca-de-la-Higuera\"}],\"doi\":\"10.1007/s11042-018-5883-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6452d294af27b1f9408c9522bfb98bf00e1e4732\",\"title\":\"A novel infrared video surveillance system using deep learning based techniques\",\"url\":\"https://www.semanticscholar.org/paper/6452d294af27b1f9408c9522bfb98bf00e1e4732\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1604.08826\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2859204\",\"name\":\"Masatoshi Hidaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967222\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"title\":\"Improved Dense Trajectory with Cross Streams\",\"url\":\"https://www.semanticscholar.org/paper/da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1604.04574\",\"authors\":[{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"144660063\",\"name\":\"J. Neumann\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2016.86\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97e7c94a78ae17cfb90848c1cfca8c431082a7b2\",\"title\":\"Learning Temporal Regularity in Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/97e7c94a78ae17cfb90848c1cfca8c431082a7b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"title\":\"Mining Spatial and Spatio-Temporal ROIs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1607.06416\",\"authors\":[{\"authorId\":null,\"name\":\"Yilin Wang\"},{\"authorId\":\"2893721\",\"name\":\"Suhang Wang\"},{\"authorId\":\"1736632\",\"name\":\"Jiliang Tang\"},{\"authorId\":\"1401255262\",\"name\":\"N. O'Hare\"},{\"authorId\":\"120586587\",\"name\":\"Y. Chang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f499948121abb47b31ca904030243e924585d5f\",\"title\":\"Hierarchical Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9f499948121abb47b31ca904030243e924585d5f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67081320\",\"name\":\"Chen Liu\"},{\"authorId\":\"2169704\",\"name\":\"Weiyan Hou\"},{\"authorId\":\"3338217\",\"name\":\"D. Liu\"}],\"doi\":\"10.1007/s11063-017-9629-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"728c1ecb8d22f2a67015685514c9d732cf793aa2\",\"title\":\"Foreign Exchange Rates Forecasting with Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/728c1ecb8d22f2a67015685514c9d732cf793aa2\",\"venue\":\"Neural Processing Letters\",\"year\":2017},{\"arxivId\":\"1805.02860\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f414a4f51748d548c2e72971f1e428ebb34754bd\",\"title\":\"Visual Attribute-augmented Three-dimensional Convolutional Neural Network for Enhanced Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f414a4f51748d548c2e72971f1e428ebb34754bd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145188795\",\"name\":\"Eman M. Nejad\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b54f5d3cb2ff5102e2bd9a6ab01d4ef858c1aa2\",\"title\":\"Simple and Complex Human Action Recognition in Constrained and Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/7b54f5d3cb2ff5102e2bd9a6ab01d4ef858c1aa2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"145721183\",\"name\":\"R. Xiang\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"}],\"doi\":\"10.1007/s11042-017-5058-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d056a1c52ac21566b621a627ce06a8dff9deab45\",\"title\":\"Complex event detection via attention-based video representation and classification\",\"url\":\"https://www.semanticscholar.org/paper/d056a1c52ac21566b621a627ce06a8dff9deab45\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40457242\",\"name\":\"Yu Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.5220/0007257803110318\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1a55c7452bd65a989d22a766a26bac7b7fb7cc9\",\"title\":\"Supervised Spatial Transformer Networks for Attention Learning in Fine-grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1a55c7452bd65a989d22a766a26bac7b7fb7cc9\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1807.08291\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"50433510\",\"name\":\"Takio Kurita\"}],\"doi\":\"10.1016/j.image.2019.115731\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"title\":\"Correlation Net: Spatiotemporal multimodal deep learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"1607.02556\",\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"29644358\",\"name\":\"Gu Wang\"},{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2288696b6558b7397bdebe3aed77bedec7b9c0a9\",\"title\":\"Action Recognition with Joint Attention on Multi-Level Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/2288696b6558b7397bdebe3aed77bedec7b9c0a9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2374364\",\"name\":\"Yusuke Mukuta\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCVW.2017.127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d31e9a28e85c63f1744f01a2d88364551e0a988\",\"title\":\"Spatial-Temporal Weighted Pyramid Using Spatial Orthogonal Pooling\",\"url\":\"https://www.semanticscholar.org/paper/6d31e9a28e85c63f1744f01a2d88364551e0a988\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47916686\",\"name\":\"K. Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"}],\"doi\":\"10.1587/TRANSINF.2017EDL8049\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"title\":\"Trajectory-Set Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdde8d08733b4d9840089f8af07f042749675f\",\"title\":\"Deep network for human action recognition using Weber motion\",\"url\":\"https://www.semanticscholar.org/paper/66cdde8d08733b4d9840089f8af07f042749675f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151443666\",\"name\":\"Shaharyar Alam Ansari\"},{\"authorId\":\"11287311\",\"name\":\"A. Zafar\"}],\"doi\":\"10.1007/978-981-15-0339-9_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59f6cd5794825780dda7b608a92d5506503270a7\",\"title\":\"A Review on Video Analytics Its Challenges and Applications\",\"url\":\"https://www.semanticscholar.org/paper/59f6cd5794825780dda7b608a92d5506503270a7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1437971672\",\"name\":\"Chao Jing\"},{\"authorId\":\"1437972053\",\"name\":\"Ping Wei\"},{\"authorId\":\"152767762\",\"name\":\"H. Sun\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/s00521-019-04615-w\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dd038623aaad3da02e567b9907218f85987cd4b\",\"title\":\"Spatiotemporal neural networks for action recognition based on joint loss\",\"url\":\"https://www.semanticscholar.org/paper/8dd038623aaad3da02e567b9907218f85987cd4b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000272213\",\"name\":\"Mainak Chakraborty\"},{\"authorId\":\"2000636940\",\"name\":\"Alik Pramanick\"},{\"authorId\":\"9266339\",\"name\":\"S. Dhavale\"}],\"doi\":\"10.1007/978-981-15-5148-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d2b3f186c7310060163d3716ec9c46599306c8f\",\"title\":\"Two-Stream Mid-Level Fusion Network for Human Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/2d2b3f186c7310060163d3716ec9c46599306c8f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18186434\",\"name\":\"Nudrat Nida\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1155/2019/2474865\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d0b838b40a3fffdc4e796e16a69f2e8b3ed210b\",\"title\":\"Instructor Activity Recognition through Deep Spatiotemporal Features and Feedforward Extreme Learning Machines\",\"url\":\"https://www.semanticscholar.org/paper/6d0b838b40a3fffdc4e796e16a69f2e8b3ed210b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.05215\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3b532e8ea6304446b1623e83b0b9a96968f926c\",\"title\":\"Joint Network based Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3b532e8ea6304446b1623e83b0b9a96968f926c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"49835905\",\"name\":\"Xuesong Jiang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1007/s11042-017-5038-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf784156547c3be146706e2763c1a52d939d1722\",\"title\":\"Breaking video into pieces for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf784156547c3be146706e2763c1a52d939d1722\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"32161932\",\"name\":\"Yuwei Wu\"}],\"doi\":\"10.1109/LSP.2016.2598878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de048065ea2c5b3e306e2c963533df055e7dfcaa\",\"title\":\"Discriminative Action States Discovery for Online Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de048065ea2c5b3e306e2c963533df055e7dfcaa\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1803.07179\",\"authors\":[{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd613000f7b2b6161548b1c1044ab46c7327a901\",\"title\":\"Attention-based Temporal Weighted Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd613000f7b2b6161548b1c1044ab46c7327a901\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"title\":\"First Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144997028\",\"name\":\"L. Li\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"title\":\"Deep Temporal Feature Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129493\",\"name\":\"Timur M. Bagautdinov\"}],\"doi\":\"10.5075/epfl-thesis-8680\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e586547a63400881c7a95d6ad6d5fa31ac237ca9\",\"title\":\"Variational Methods for Human Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e586547a63400881c7a95d6ad6d5fa31ac237ca9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145867466\",\"name\":\"Taisong Jin\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"}],\"doi\":\"10.24963/ijcai.2019/371\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e82159ea90d2d61a6b76d85e9dfad4ae7c3f0f6\",\"title\":\"Hypergraph Induced Convolutional Manifold Networks\",\"url\":\"https://www.semanticscholar.org/paper/9e82159ea90d2d61a6b76d85e9dfad4ae7c3f0f6\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11485621\",\"name\":\"Cyrille Beaudry\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"3027952\",\"name\":\"L. Mascarilla\"}],\"doi\":\"10.1007/s00138-016-0760-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9652f154f4ae7807bdaff32d3222cc0c485a6762\",\"title\":\"An efficient and sparse approach for large scale human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/9652f154f4ae7807bdaff32d3222cc0c485a6762\",\"venue\":\"Machine Vision and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"title\":\"LSTM with Hand-crafted View-Invariant and Differential Cues (HVDC) for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.02447\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"7718545\",\"name\":\"Z. Li\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1145/2964284.2967191\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce601575f213073c2e11c53eba169a695eaa4cad\",\"title\":\"Action Recognition Based on Joint Trajectory Maps Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce601575f213073c2e11c53eba169a695eaa4cad\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1602.06149\",\"authors\":[{\"authorId\":\"2217051\",\"name\":\"S. Bianco\"}],\"doi\":\"10.1016/j.patrec.2017.03.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4481fdc488ed952b1296eb7779cc3f679e2305\",\"title\":\"Large Age-Gap face verification by feature injection in deep networks\",\"url\":\"https://www.semanticscholar.org/paper/fd4481fdc488ed952b1296eb7779cc3f679e2305\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1812.01922\",\"authors\":[{\"authorId\":\"48379459\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"7595315\",\"name\":\"Christian Jarvers\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1109/CVPR.2019.01228\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"428934f26e240aadeec86b40b23182455fb25c1a\",\"title\":\"Local Temporal Bilinear Pooling for Fine-Grained Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/428934f26e240aadeec86b40b23182455fb25c1a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48624774\",\"name\":\"Xiao-li Hou\"},{\"authorId\":\"1462995819\",\"name\":\"andXurong Chen\"},{\"authorId\":\"1463031544\",\"name\":\"andJan Gaura\"},{\"authorId\":\"144561849\",\"name\":\"K. Nishida\"},{\"authorId\":\"2234588\",\"name\":\"Vedrana Krivokuca\"},{\"authorId\":\"1463000710\",\"name\":\"WaleedAbdulla andAkshya\"},{\"authorId\":\"50762725\",\"name\":\"J. Chen\"},{\"authorId\":\"2237357\",\"name\":\"P. Matsakis\"},{\"authorId\":\"1733851\",\"name\":\"S. Mahmoodi\"},{\"authorId\":\"152315424\",\"name\":\"M. Bennett\"},{\"authorId\":\"1755210\",\"name\":\"H. Xiao\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"2919612\",\"name\":\"Shuren Tan\"},{\"authorId\":\"49435089\",\"name\":\"S. Ricciardi\"},{\"authorId\":\"1453073794\",\"name\":\"K. Liu\"},{\"authorId\":\"35493784\",\"name\":\"Yu-Lin He\"},{\"authorId\":\"7741858\",\"name\":\"Yan-Xing Hu\"},{\"authorId\":\"1462948109\",\"name\":\"Heydar Maboudi\"}],\"doi\":\"10.1007/978-3-030-05499-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60ab728bc47edd74435a2fc1353cc0ee91e5636f\",\"title\":\"Pattern Recognition Applications and Methods\",\"url\":\"https://www.semanticscholar.org/paper/60ab728bc47edd74435a2fc1353cc0ee91e5636f\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"145791406\",\"name\":\"Han Zou\"},{\"authorId\":\"47067803\",\"name\":\"Hao Jiang\"},{\"authorId\":\"145050702\",\"name\":\"L. Xie\"}],\"doi\":\"10.1109/JIOT.2018.2849655\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1b412a537705698518e5eed9c2480f2d7ed150b\",\"title\":\"Device-Free Occupant Activity Sensing Using WiFi-Enabled IoT Devices for Smart Homes\",\"url\":\"https://www.semanticscholar.org/paper/a1b412a537705698518e5eed9c2480f2d7ed150b\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"49308434\",\"name\":\"Y. Yang\"},{\"authorId\":\"2092709\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.3390/jimaging5100082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"title\":\"Deep Learning of Fuzzy Weighted Multi-Resolution Depth Motion Maps with Spatial Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"venue\":\"J. Imaging\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2005.04366\",\"authors\":[{\"authorId\":\"1471722186\",\"name\":\"Miao Yin\"},{\"authorId\":\"145657535\",\"name\":\"Siyu Liao\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"48632004\",\"name\":\"X. Wang\"},{\"authorId\":\"1471729588\",\"name\":\"Bo Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"title\":\"Compressing Recurrent Neural Networks Using Hierarchical Tucker Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/AVSS.2016.7738023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efc5cf6e30ba5a175cff919be2c1642abf408565\",\"title\":\"Modeling spatial layout of features for real world scenario RGB-D action recognition\",\"url\":\"https://www.semanticscholar.org/paper/efc5cf6e30ba5a175cff919be2c1642abf408565\",\"venue\":\"2016 13th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29516300\",\"name\":\"V. O. Silva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5b9269c7499be1bf6d50678c2b06db648dbd283\",\"title\":\"Human action recognition in image sequences based on a two-stream convolutional neural network classifier\",\"url\":\"https://www.semanticscholar.org/paper/e5b9269c7499be1bf6d50678c2b06db648dbd283\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96469945\",\"name\":\"W. Hua\"},{\"authorId\":\"94225959\",\"name\":\"W. Zhang\"},{\"authorId\":\"153154611\",\"name\":\"J. Li\"},{\"authorId\":\"153872592\",\"name\":\"Kaijun Cai\"},{\"authorId\":\"1708290698\",\"name\":\"Yuquan Jiang\"}],\"doi\":\"10.1080/10584587.2020.1728660\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d56c2b542e7f9cda5a78728044512904c537d55e\",\"title\":\"Feasibility of Abandoned Ammunition Materials Cold Cutting Experimental Study and Numerical Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d56c2b542e7f9cda5a78728044512904c537d55e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2227667\",\"name\":\"Naifan Zhuang\"},{\"authorId\":\"49502400\",\"name\":\"G. Qi\"},{\"authorId\":\"29765068\",\"name\":\"T. Kieu\"},{\"authorId\":\"1730455\",\"name\":\"K. Hua\"}],\"doi\":\"10.1145/3337928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e5251d30ae8090511d26df83be26ba90d03092\",\"title\":\"Rethinking the Combined and Individual Orders of Derivative of States for Differential Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43e5251d30ae8090511d26df83be26ba90d03092\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"87046280\",\"name\":\"H. Yang\"},{\"authorId\":\"1560347965\",\"name\":\"Jun Sun\"}],\"doi\":\"10.1109/ICIP40778.2020.9191071\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"title\":\"Multilevel Interaction Reasoning For Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2023447\",\"name\":\"S. Hemminki\"},{\"authorId\":\"2475493\",\"name\":\"Keisuke Kuribayashi\"},{\"authorId\":\"1741223\",\"name\":\"Shin'ichi Konomi\"},{\"authorId\":\"2583077\",\"name\":\"P. Nurmi\"},{\"authorId\":\"1759241\",\"name\":\"Sasu Tarkoma\"}],\"doi\":\"10.1145/3317666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86e23cb514391932b247af4ac938ca48f746a321\",\"title\":\"Crowd Replication\",\"url\":\"https://www.semanticscholar.org/paper/86e23cb514391932b247af4ac938ca48f746a321\",\"venue\":\"ACM Trans. Spatial Algorithms Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144543350\",\"name\":\"P. Dong\"},{\"authorId\":\"38158055\",\"name\":\"J. Li\"},{\"authorId\":\"1964397\",\"name\":\"J. Dong\"},{\"authorId\":\"145953636\",\"name\":\"L. Qi\"}],\"doi\":\"10.1117/12.2302485\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d852602cd18cf3859f92cf2178346e8c9860f7f1\",\"title\":\"Multi-dimension feature fusion for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d852602cd18cf3859f92cf2178346e8c9860f7f1\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18071979\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2588acc7a730d864f84d4e1a050070ff873b03d5\",\"title\":\"Action Recognition by an Attention-Aware Temporal Weighted Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2588acc7a730d864f84d4e1a050070ff873b03d5\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"791ab87f53b521400464a412fe1a4019496aeaab\",\"title\":\"Encoding Feature Maps of CNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/791ab87f53b521400464a412fe1a4019496aeaab\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/CVPRW.2016.142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f351e99da70625f2011b0dccd131a5e50aa8644\",\"title\":\"Embedding Sequential Information into Spatiotemporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f351e99da70625f2011b0dccd131a5e50aa8644\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1701.03246\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2017.26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"title\":\"Ordered Pooling of Optical Flow Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1711.08238\",\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"225fb9181545f8750061c7693661b62d715dc542\",\"title\":\"Multi-Level Recurrent Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/225fb9181545f8750061c7693661b62d715dc542\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19301412\",\"name\":\"Weimian Li\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICME.2017.8019335\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b2366f2a3c0845de03b37b4866c1da2df0592ae\",\"title\":\"A joint model for action localization and classification in untrimmed video with visual attention\",\"url\":\"https://www.semanticscholar.org/paper/9b2366f2a3c0845de03b37b4866c1da2df0592ae\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN.2017.7966210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"title\":\"Recent advances in video-based human action recognition using deep learning: A review\",\"url\":\"https://www.semanticscholar.org/paper/c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":\"1805.00258\",\"authors\":[{\"authorId\":\"143729925\",\"name\":\"H. Feng\"},{\"authorId\":\"50695067\",\"name\":\"S. Wang\"},{\"authorId\":\"5136757\",\"name\":\"S. Ge\"}],\"doi\":\"10.1109/TCYB.2019.2904901\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d4c1910ad3ba1afdeeabc70d3fbfa06ad438277\",\"title\":\"Object Activity Scene Description, Construction and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d4c1910ad3ba1afdeeabc70d3fbfa06ad438277\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3439788\",\"name\":\"Ashwan Abdulmunem\"},{\"authorId\":\"7827503\",\"name\":\"Y. Lai\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f22b157fb9f9963b21a82860cb47585556bd79d5\",\"title\":\"3 D GLOH Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22b157fb9f9963b21a82860cb47585556bd79d5\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642847\",\"name\":\"Yongbin Gao\"},{\"authorId\":\"79890978\",\"name\":\"Xuehao Xiang\"},{\"authorId\":\"145826495\",\"name\":\"N. Xiong\"},{\"authorId\":\"144230953\",\"name\":\"Bo Huang\"},{\"authorId\":\"4292934\",\"name\":\"H. J. Lee\"},{\"authorId\":\"52240872\",\"name\":\"Rad Alrifai\"},{\"authorId\":\"48324819\",\"name\":\"Xiaoyan Jiang\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"}],\"doi\":\"10.1109/ACCESS.2018.2869790\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"11c67d6fedc3dd95b752ade4e46ee143ac494259\",\"title\":\"Human Action Monitoring for Healthcare Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/11c67d6fedc3dd95b752ade4e46ee143ac494259\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11485621\",\"name\":\"Cyrille Beaudry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d52edd32144eb9a14b635a5f612cc063d9129a20\",\"title\":\"Analyse et reconnaissance de s\\u00e9quences vid\\u00e9os d'activit\\u00e9s humaines dans l'espace s\\u00e9mantique. (Analysis and recognition of human activities in video sequences in the semantic space)\",\"url\":\"https://www.semanticscholar.org/paper/d52edd32144eb9a14b635a5f612cc063d9129a20\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994847\",\"name\":\"Tiezheng Ge\"},{\"authorId\":\"49608472\",\"name\":\"Liqin Zhao\"},{\"authorId\":\"35066946\",\"name\":\"Guorui Zhou\"},{\"authorId\":\"40897674\",\"name\":\"Keyu Chen\"},{\"authorId\":\"50152570\",\"name\":\"Shuying Liu\"},{\"authorId\":\"36534721\",\"name\":\"H. Yi\"},{\"authorId\":\"13643730\",\"name\":\"Zelin Hu\"},{\"authorId\":\"2231067\",\"name\":\"Bochao Liu\"},{\"authorId\":\"145551072\",\"name\":\"Peng Sun\"},{\"authorId\":\"46936332\",\"name\":\"H. Liu\"},{\"authorId\":\"32507655\",\"name\":\"Pengtao Yi\"},{\"authorId\":\"50179239\",\"name\":\"Sui Huang\"},{\"authorId\":\"40630836\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2388034\",\"name\":\"Xiaoqiang Zhu\"},{\"authorId\":\"46867976\",\"name\":\"Y. Zhang\"},{\"authorId\":\"20029557\",\"name\":\"K. Gai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6896ec1939f002a0ddbdf1b62c97dd8291c776c1\",\"title\":\"Image Matters: Jointly Train Advertising CTR Model with Image Representation of Ad and User Behavior\",\"url\":\"https://www.semanticscholar.org/paper/6896ec1939f002a0ddbdf1b62c97dd8291c776c1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.00604\",\"authors\":[{\"authorId\":\"51056422\",\"name\":\"Xuelun Shen\"},{\"authorId\":\"26994316\",\"name\":\"Cheng Wang\"},{\"authorId\":\"48568672\",\"name\":\"Xin Li\"},{\"authorId\":\"150358799\",\"name\":\"Zenglei Yu\"},{\"authorId\":\"46275530\",\"name\":\"J. Li\"},{\"authorId\":\"2869063\",\"name\":\"Chenglu Wen\"},{\"authorId\":\"143657776\",\"name\":\"M. Cheng\"},{\"authorId\":\"2558787\",\"name\":\"Zijian He\"}],\"doi\":\"10.1109/CVPR.2019.00832\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc77291c3620abed2a247db09ca392772e1508ae\",\"title\":\"RF-Net: An End-To-End Image Matching Network Based on Receptive Field\",\"url\":\"https://www.semanticscholar.org/paper/bc77291c3620abed2a247db09ca392772e1508ae\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938121\",\"name\":\"Pejman Habashi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c05a10cafbeeffc0c1923fe28f619b2db3c7b101\",\"title\":\"Trajectory-based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c05a10cafbeeffc0c1923fe28f619b2db3c7b101\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.08074\",\"authors\":[{\"authorId\":\"1641594002\",\"name\":\"Motoshi Abe\"},{\"authorId\":\"2698604\",\"name\":\"J. Miyao\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb717a5aadcb2f73cb3294689daf5df75e2752fe\",\"title\":\"Adaptive Neuron-wise Discriminant Criterion and Adaptive Center Loss at Hidden Layer for Deep Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/eb717a5aadcb2f73cb3294689daf5df75e2752fe\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1611.09502\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.435\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"title\":\"Deep Quantization: Encoding Convolutional Activations with Deep Generative Model\",\"url\":\"https://www.semanticscholar.org/paper/ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145783730\",\"name\":\"X. Xiao\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"145524181\",\"name\":\"W. Wan\"}],\"doi\":\"10.1109/ICALIP.2016.7846652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"861a51e66553979535df2b41971150453ab26372\",\"title\":\"Overview: Video recognition from handcrafted method to deep learning method\",\"url\":\"https://www.semanticscholar.org/paper/861a51e66553979535df2b41971150453ab26372\",\"venue\":\"2016 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3379311\",\"name\":\"Slawomir Wojciechowski\"},{\"authorId\":\"3043492\",\"name\":\"M. Kulbacki\"},{\"authorId\":\"2554241\",\"name\":\"J. Segen\"},{\"authorId\":\"3366961\",\"name\":\"Rafal Wycislok\"},{\"authorId\":\"49829226\",\"name\":\"Artur Bak\"},{\"authorId\":\"2722816\",\"name\":\"Kamil Wereszczynski\"},{\"authorId\":\"1758579\",\"name\":\"K. Wojciechowski\"}],\"doi\":\"10.1007/978-3-662-49390-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6226918e098fb9570519656ebab83a6d76bda674\",\"title\":\"Selected Space-Time Based Methods for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6226918e098fb9570519656ebab83a6d76bda674\",\"venue\":\"ACIIDS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1227d95fd4e11aa8b251456f1b6bc568f83543f0\",\"title\":\"SPATIAL-TEMPORAL NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/1227d95fd4e11aa8b251456f1b6bc568f83543f0\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"title\":\"RECOGNITIONWITH GRADIENT BOUNDARY CONVOLUTIONAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500430677\",\"name\":\"Shengbo Wang\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49679333\",\"name\":\"C. Ma\"},{\"authorId\":\"49141021\",\"name\":\"M. Li\"}],\"doi\":\"10.1109/CAC48633.2019.8996591\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8167063e02c8c46b6f1b93ac8dea0a70dd10a09b\",\"title\":\"Boundary Sensitive and Category Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/8167063e02c8c46b6f1b93ac8dea0a70dd10a09b\",\"venue\":\"2019 Chinese Automation Congress (CAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145779142\",\"name\":\"Peng Liu\"},{\"authorId\":\"143736991\",\"name\":\"L. Yin\"}],\"doi\":\"10.1109/ICME.2017.8019315\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90f6f13e402454a964f6c5707b91dd2e13f3a9c9\",\"title\":\"Spontaneous thermal facial expression analysis based on trajectory-pooled fisher vector descriptor\",\"url\":\"https://www.semanticscholar.org/paper/90f6f13e402454a964f6c5707b91dd2e13f3a9c9\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1808.09892\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1007/978-3-030-03840-3_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"title\":\"Top-down Attention Recurrent VLAD Encoding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"venue\":\"AI*IA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145594181\",\"name\":\"B. Zhu\"}],\"doi\":\"10.1007/978-3-030-03338-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"title\":\"Feature Aggregation Tree: Capture Temporal Motion Information for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46395977\",\"name\":\"Yaohui Wang\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"},{\"authorId\":\"12565299\",\"name\":\"Jean-Claude Broutart\"},{\"authorId\":\"144805077\",\"name\":\"P. Robert\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"31474374\",\"name\":\"P. Bilinski\"}],\"doi\":\"10.1007/978-3-030-11024-6_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6164a339b387b1964e62a490456c4e4b15696361\",\"title\":\"Comparing Methods for Assessment of Facial Dynamics in Patients with Major Neurocognitive Disorders\",\"url\":\"https://www.semanticscholar.org/paper/6164a339b387b1964e62a490456c4e4b15696361\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12277476\",\"name\":\"Lifei Song\"},{\"authorId\":\"1779987\",\"name\":\"Liguo Weng\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"47715056\",\"name\":\"Min Xia\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2018.8451662\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"title\":\"Two-Stream Designed 2D/3D Residual Networks with Lstms for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1912.11691\",\"authors\":[{\"authorId\":\"3180077\",\"name\":\"F. Fooladgar\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6879e23d91d8278a476a82d5fcdbef60e889111\",\"title\":\"Multi-Modal Attention-based Fusion Model for Semantic Segmentation of RGB-Depth Images\",\"url\":\"https://www.semanticscholar.org/paper/e6879e23d91d8278a476a82d5fcdbef60e889111\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"3464776\",\"name\":\"Jiayi Fan\"}],\"doi\":\"10.1016/j.sigpro.2017.08.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"760d3c57504ae1fdb719237503233850097bde8e\",\"title\":\"Joints kinetic and relational features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/760d3c57504ae1fdb719237503233850097bde8e\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"},{\"authorId\":\"50059546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1109/LSP.2018.2888758\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afa59eb5fedbcabc895ca7b43d6669ad9bbeda87\",\"title\":\"End-to-End Temporal Action Detection Using Bag of Discriminant Snippets\",\"url\":\"https://www.semanticscholar.org/paper/afa59eb5fedbcabc895ca7b43d6669ad9bbeda87\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":\"1612.00558\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW.2017.205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57c59011614c43f51a509e10717e47505c776389\",\"title\":\"Unsupervised Human Action Detection by Action Matching\",\"url\":\"https://www.semanticscholar.org/paper/57c59011614c43f51a509e10717e47505c776389\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98294026\",\"name\":\"S. Liu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"32083314\",\"name\":\"Yi-bin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2979549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"title\":\"An End to End Framework With Adaptive Spatio-Temporal Attention Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1793532\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TMM.2016.2631881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9182cd457884a91c461f2b7b7677fe92e06d165c\",\"title\":\"Dancelets Mining for Video Recommendation Based on Dance Styles\",\"url\":\"https://www.semanticscholar.org/paper/9182cd457884a91c461f2b7b7677fe92e06d165c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"145917158\",\"name\":\"H. J. Chang\"},{\"authorId\":\"144540522\",\"name\":\"I. Serrano\"},{\"authorId\":\"1397942042\",\"name\":\"O. D\\u00e9niz-Su\\u00e1rez\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/WACV.2016.7477709\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f613aa581546ffb37561fe87dffd484d6daecbf0\",\"title\":\"Transition Hough forest for trajectory-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f613aa581546ffb37561fe87dffd484d6daecbf0\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145271111\",\"name\":\"N. Henderson\"},{\"authorId\":\"3867127\",\"name\":\"R. Aygun\"}],\"doi\":\"10.1109/ISM.2017.22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cba090a5bfae7dd8a60a973259f0870ed68c4dd3\",\"title\":\"Human Action Classification Using Temporal Slicing for Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cba090a5bfae7dd8a60a973259f0870ed68c4dd3\",\"venue\":\"2017 IEEE International Symposium on Multimedia (ISM)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474374\",\"name\":\"P. Bilinski\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/AVSS.2016.7738019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"940ab36a8b2cdf6cb6a08093bd382ad375717942\",\"title\":\"Human violence recognition and detection in surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/940ab36a8b2cdf6cb6a08093bd382ad375717942\",\"venue\":\"2016 13th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2016},{\"arxivId\":\"1706.04508\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TMM.2018.2823900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"title\":\"Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49325258\",\"name\":\"Mingzhi Pang\"},{\"authorId\":\"8314653\",\"name\":\"X. Yang\"},{\"authorId\":\"49722131\",\"name\":\"J. Liu\"},{\"authorId\":\"10367284\",\"name\":\"Peihao Li\"},{\"authorId\":\"2028614762\",\"name\":\"Faren Yan\"},{\"authorId\":\"70173441\",\"name\":\"P. Chen\"}],\"doi\":\"10.1007/978-981-33-4214-9_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b150cc58f6972fc8f2497d6b6589ea70f00aba51\",\"title\":\"Device-Free Activity Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b150cc58f6972fc8f2497d6b6589ea70f00aba51\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12372393\",\"name\":\"Kunwar Yashraj Singh\"},{\"authorId\":\"49926372\",\"name\":\"N. Davis\"},{\"authorId\":\"38812851\",\"name\":\"Chih-Pin Hsiao\"},{\"authorId\":\"3108794\",\"name\":\"Mikhail Jacob\"},{\"authorId\":\"144000742\",\"name\":\"Krunal Patel\"},{\"authorId\":\"1691882\",\"name\":\"Brian Magerko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bdfc646b472cf93f1c2ef10602cc937f935d3c1\",\"title\":\"Recognizing Actions in Motion Trajectories Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8bdfc646b472cf93f1c2ef10602cc937f935d3c1\",\"venue\":\"AIIDE\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423471283\",\"name\":\"Lijun Xu\"},{\"authorId\":\"1423717505\",\"name\":\"Shengzan Yan\"},{\"authorId\":\"92203493\",\"name\":\"X. Chen\"},{\"authorId\":\"94691539\",\"name\":\"P. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2952432\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"5015e5095ce610a3d5c11590ddcbfab1066261fc\",\"title\":\"Motion Recognition Algorithm Based on Deep Edge-Aware Pyramid Pooling Network in Human\\u2013Computer Interaction\",\"url\":\"https://www.semanticscholar.org/paper/5015e5095ce610a3d5c11590ddcbfab1066261fc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119868440\",\"name\":\"Mengdan Lou\"},{\"authorId\":\"46276431\",\"name\":\"Jieyu Li\"},{\"authorId\":\"2477114\",\"name\":\"G. Wang\"},{\"authorId\":\"46408707\",\"name\":\"G. He\"}],\"doi\":\"10.1109/ISCAS.2019.8702353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1606965af1202ad3cab983cde3746db9f227e9e5\",\"title\":\"AR-C3D: Action Recognition Accelerator for Human-Computer Interaction on FPGA\",\"url\":\"https://www.semanticscholar.org/paper/1606965af1202ad3cab983cde3746db9f227e9e5\",\"venue\":\"2019 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2019},{\"arxivId\":\"1604.06397\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2016.295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae7122103f0868995ea2b53695479af553ab1361\",\"title\":\"Improving Human Action Recognition by Non-action Classification\",\"url\":\"https://www.semanticscholar.org/paper/ae7122103f0868995ea2b53695479af553ab1361\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964097\",\"name\":\"A. Ghosh\"},{\"authorId\":null,\"name\":\"Kartheek Alahari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e62b5f5e17c1093ea090c3512358210570f1086\",\"title\":\"Analyzing Racket Sports From Broadcast Videos\",\"url\":\"https://www.semanticscholar.org/paper/1e62b5f5e17c1093ea090c3512358210570f1086\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143709116\",\"name\":\"Zhen Gao\"},{\"authorId\":\"2024038\",\"name\":\"G. Lu\"},{\"authorId\":\"144281505\",\"name\":\"Peng Yan\"}],\"doi\":\"10.1109/CISP-BMEI.2016.7852687\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"994b2f6ca1ad1795f7921b606e694640e2675494\",\"title\":\"Averaging video sequences to improve action recognition\",\"url\":\"https://www.semanticscholar.org/paper/994b2f6ca1ad1795f7921b606e694640e2675494\",\"venue\":\"2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"title\":\"Multi-Level ResNets with Stacked SRUs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2018.2844101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ef6b55a23aab0ec6b02fdb01d5e30181ef42e04\",\"title\":\"Hierarchical Concept Score Postprocessing and Concept-Wise Normalization in CNN-Based Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ef6b55a23aab0ec6b02fdb01d5e30181ef42e04\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/CVPR.2017.390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa3e3f4f1159e3af45a32eb0b3e206204d201721\",\"title\":\"Deep Sequential Context Networks for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa3e3f4f1159e3af45a32eb0b3e206204d201721\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1109/CVPR.2016.216\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"title\":\"A Multi-stream Bi-directional Recurrent Neural Network for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.08395\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1007/978-3-319-49409-8_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"31625522950e82ad4dffef7ed0df00fdd2401436\",\"title\":\"Motion Representation with Acceleration Images\",\"url\":\"https://www.semanticscholar.org/paper/31625522950e82ad4dffef7ed0df00fdd2401436\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.371\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a2801b968c889a8625d4ab62e03323bd14d6eda\",\"title\":\"Large-Scale Multimodal Gesture Segmentation and Recognition Based on Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9a2801b968c889a8625d4ab62e03323bd14d6eda\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2023447\",\"name\":\"S. Hemminki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f902c412d4a486b79857b15c9d6cfd6b0a6cff8f\",\"title\":\"Advances in Motion Sensing on Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/f902c412d4a486b79857b15c9d6cfd6b0a6cff8f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8474034\",\"name\":\"Osama Mazhar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2aafdef2416dd8dfc4fac345b86ca20720fe6f4\",\"title\":\"Vision-based Human Gestures Recognition for Human-Robot Interaction. (Reconnaissance des gestes humains bas\\u00e9e sur la vision pour l'interaction homme-robot)\",\"url\":\"https://www.semanticscholar.org/paper/c2aafdef2416dd8dfc4fac345b86ca20720fe6f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49210768\",\"name\":\"Ling Guan\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"1403961741\",\"name\":\"Nour El-Din El-Madany\"},{\"authorId\":\"3337292\",\"name\":\"Chengwu Liang\"}],\"doi\":\"10.1109/MIPR.2018.00059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60462b981fda63c5f9d780528a37c46884fe0b54\",\"title\":\"Statistical Machine Learning vs Deep Learning in Information Fusion: Competition or Collaboration?\",\"url\":\"https://www.semanticscholar.org/paper/60462b981fda63c5f9d780528a37c46884fe0b54\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"414c85e333a24456a3bb5b194d97e95e69175dea\",\"title\":\"Jointly Recognizing Object Fluents and Tasks in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/414c85e333a24456a3bb5b194d97e95e69175dea\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708998\",\"name\":\"Nguyen Anh Tu\"},{\"authorId\":\"1402997421\",\"name\":\"Thien Huynh-The\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/DICTA47822.2019.8945874\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97b8042136aafdc37c2ef95dcf6e5d11ccb1e0b3\",\"title\":\"Scalable Video Classification using Bag of Visual Words on Spark\",\"url\":\"https://www.semanticscholar.org/paper/97b8042136aafdc37c2ef95dcf6e5d11ccb1e0b3\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1607.02003\",\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-017-1023-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9dd21511fc70f9b7ed1d095a51f09c60f9f1efe1\",\"title\":\"Tubelets: Unsupervised Action Proposals from Spatiotemporal Super-Voxels\",\"url\":\"https://www.semanticscholar.org/paper/9dd21511fc70f9b7ed1d095a51f09c60f9f1efe1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1905.05344\",\"authors\":[{\"authorId\":\"1938121\",\"name\":\"Pejman Habashi\"},{\"authorId\":\"48344469\",\"name\":\"B. Boufama\"},{\"authorId\":\"145687244\",\"name\":\"Imran Ahmad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd96ec0c36de8282de926d3abf8f74d1324ec6ab\",\"title\":\"Disparity-Augmented Trajectories for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd96ec0c36de8282de926d3abf8f74d1324ec6ab\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1905.00745\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"79795951498660c539ff440d2ddcb32f3132b97e\",\"title\":\"Human Action Recognition with Deep Temporal Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/79795951498660c539ff440d2ddcb32f3132b97e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2003.04852\",\"authors\":[{\"authorId\":\"3286107\",\"name\":\"X. Wang\"},{\"authorId\":\"1884134\",\"name\":\"Xiya Zhang\"},{\"authorId\":\"51280237\",\"name\":\"Yinheng Zhu\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"2536159\",\"name\":\"Xiaoyun Yuan\"},{\"authorId\":\"83620577\",\"name\":\"Liuyu Xiang\"},{\"authorId\":\"96309455\",\"name\":\"Z. Wang\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1741299\",\"name\":\"D. Brady\"},{\"authorId\":\"48382219\",\"name\":\"Qiong-hai Dai\"},{\"authorId\":\"47547866\",\"name\":\"Lu Fang\"}],\"doi\":\"10.1109/cvpr42600.2020.00333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf9a30ee3ef6320780c6980f21f3c3ea43fc2c62\",\"title\":\"PANDA: A Gigapixel-Level Human-Centric Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bf9a30ee3ef6320780c6980f21f3c3ea43fc2c62\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"102599406\",\"name\":\"Y. Tan\"},{\"authorId\":\"46276803\",\"name\":\"J. Li\"},{\"authorId\":\"46513749\",\"name\":\"Bin Tan\"}],\"doi\":\"10.1016/j.jvcir.2020.102875\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32c722384bdf8ac2ade6d6e4ce3225077b124555\",\"title\":\"Translating video into language by enhancing visual and language representations\",\"url\":\"https://www.semanticscholar.org/paper/32c722384bdf8ac2ade6d6e4ce3225077b124555\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9115391\",\"name\":\"G. Li\"},{\"authorId\":\"143895325\",\"name\":\"L. Deng\"},{\"authorId\":\"3401913\",\"name\":\"Yansong Chua\"},{\"authorId\":null,\"name\":\"Peng Li\"},{\"authorId\":\"1404242270\",\"name\":\"Emre O. Neftci\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.3389/fnins.2020.00276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb6862574ecdecd482779a43d0d643560cebe947\",\"title\":\"Editorial: Spiking Neural Network Learning, Benchmarking, Programming and Executing\",\"url\":\"https://www.semanticscholar.org/paper/cb6862574ecdecd482779a43d0d643560cebe947\",\"venue\":\"Frontiers in Neuroscience\",\"year\":2020},{\"arxivId\":\"1708.00973\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3123266.3123432\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f510bc627be67fc1dea8b2465f1697bc0cdb3041\",\"title\":\"Attention Transfer from Web Images for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f510bc627be67fc1dea8b2465f1697bc0cdb3041\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"146761298\",\"name\":\"Fu Xiaoc\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TCSVT.2019.2918591\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"title\":\"Discriminative Multi-View Subspace Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1016/j.patcog.2018.07.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"756532d707209f13c44b96e6306ac0c96e6733a5\",\"title\":\"Asymmetric 3D Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/756532d707209f13c44b96e6306ac0c96e6733a5\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121030\",\"name\":\"Rajiv Singh\"},{\"authorId\":\"39727023\",\"name\":\"Swati Nigam\"}],\"doi\":\"10.1007/978-3-030-15887-3_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"title\":\"Deep Neural Networks for Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"venue\":\"Handbook of Multimedia Information Security\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":\"1503.01224\",\"authors\":[{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"2572430\",\"name\":\"Yuanzhouhan Cao\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TCSVT.2016.2576761\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2a7ad6bb5fee853218b474460eebcef9cad3259\",\"title\":\"Temporal Pyramid Pooling-Based Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2a7ad6bb5fee853218b474460eebcef9cad3259\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1512.07155\",\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1016/j.patcog.2017.01.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"title\":\"Do less and achieve more: Training CNNs for action recognition utilizing action images from the Web\",\"url\":\"https://www.semanticscholar.org/paper/ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126047\",\"name\":\"Xiu-Shen Wei\"},{\"authorId\":\"2226422\",\"name\":\"Bin-Bin Gao\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"}],\"doi\":\"10.1109/ICCVW.2015.45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dbe09fc20bb315d85a306bca47766bea1d6151d\",\"title\":\"Deep Spatial Pyramid Ensemble for Cultural Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5dbe09fc20bb315d85a306bca47766bea1d6151d\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123933870\",\"name\":\"D. Prasanna\"},{\"authorId\":\"49980374\",\"name\":\"M. Prabhakar\"}],\"doi\":\"10.1007/s10586-018-1747-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6821d3010a7297401ee226e0c6ad38f11c79db8c\",\"title\":\"An effiecient human tracking system using Haar-like and hog feature extraction\",\"url\":\"https://www.semanticscholar.org/paper/6821d3010a7297401ee226e0c6ad38f11c79db8c\",\"venue\":\"Cluster Computing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"}],\"doi\":\"10.1109/ICIP.2018.8451226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c6655ab00cf3fbcb412949e85204b608937c881\",\"title\":\"Action Recognition Based on Discriminative Embedding of Actions Using Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6655ab00cf3fbcb412949e85204b608937c881\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"},{\"authorId\":\"50656755\",\"name\":\"Qing Yuan Zhou\"},{\"authorId\":\"50424096\",\"name\":\"Nicolas Christou\"},{\"authorId\":\"145081360\",\"name\":\"Alan Loddon Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"title\":\"Electronic Theses and Dissertations Title Mining Spatial and Spatio-Temporal ROIs for Action Recognition Permalink\",\"url\":\"https://www.semanticscholar.org/paper/4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150965117\",\"name\":\"Daniel Alejandro Castro Chin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"title\":\"Understanding The Motion of A Human State In Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3091544\",\"name\":\"Enjie Ding\"},{\"authorId\":\"2643775\",\"name\":\"Zhongyu Liu\"},{\"authorId\":\"46398350\",\"name\":\"Y. Liu\"},{\"authorId\":\"46697303\",\"name\":\"Dawei Xu\"},{\"authorId\":\"2481620\",\"name\":\"Shimin Feng\"},{\"authorId\":\"3222657\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/GCWkshps45667.2019.9024615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b6ca6991dd154362791fa068cb8405b7eba09d\",\"title\":\"Unsafe Action Recognition of Miners Based on Video Description\",\"url\":\"https://www.semanticscholar.org/paper/d4b6ca6991dd154362791fa068cb8405b7eba09d\",\"venue\":\"2019 IEEE Globecom Workshops (GC Wkshps)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2566189\",\"name\":\"Suguo Zhu\"},{\"authorId\":\"51188296\",\"name\":\"Zhenying Fang\"},{\"authorId\":\"40013369\",\"name\":\"Y. Wang\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"}],\"doi\":\"10.1016/J.JVCIR.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"title\":\"Multimodal activity recognition with local block CNN and attention-based spatial weighted CNN\",\"url\":\"https://www.semanticscholar.org/paper/74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1609.01693\",\"authors\":[{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-319-49409-8_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20f5be36bf8347276130eb5764fd3c0e7b99240d\",\"title\":\"Making a Case for Learning Motion Representations with Phase\",\"url\":\"https://www.semanticscholar.org/paper/20f5be36bf8347276130eb5764fd3c0e7b99240d\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-319-46487-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5498b3cc5ac12ac5209ec3c8c751e87b59e9c31\",\"title\":\"Webly-Supervised Video Recognition by Mutually Voting for Relevant Web Images and Web Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/c5498b3cc5ac12ac5209ec3c8c751e87b59e9c31\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35035828\",\"name\":\"A. Ulhaq\"}],\"doi\":\"10.1109/IPAS.2018.8708853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff4ff29985a61bb9cfb29e4bd4e2cc28985601b8\",\"title\":\"Deep Cross-view Convolutional Features for View-invariant Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ff4ff29985a61bb9cfb29e4bd4e2cc28985601b8\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46245804\",\"name\":\"Akihiro Matsufuji\"},{\"authorId\":\"3400938\",\"name\":\"Wei-Fen Hsieh\"},{\"authorId\":\"1924843\",\"name\":\"Hao-Ming Hung\"},{\"authorId\":\"30967601\",\"name\":\"Eri Shimokawara\"},{\"authorId\":\"145576856\",\"name\":\"T. Yamaguchi\"},{\"authorId\":\"38378710\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/TAAI.2018.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de082cb25953d4082c844b1907803306de1e9ce8\",\"title\":\"A Method of Action Recognition in Ego-Centric Videos by Using Object-Hand Relations\",\"url\":\"https://www.semanticscholar.org/paper/de082cb25953d4082c844b1907803306de1e9ce8\",\"venue\":\"2018 Conference on Technologies and Applications of Artificial Intelligence (TAAI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66072241\",\"name\":\"P. Singh\"},{\"authorId\":\"2654478\",\"name\":\"V. Pankajakshan\"}],\"doi\":\"10.1109/NCC.2018.8599969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7268a1948372b5dea1bfd13761373cfe8c46247\",\"title\":\"A Deep Learning Based Technique for Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/f7268a1948372b5dea1bfd13761373cfe8c46247\",\"venue\":\"2018 Twenty Fourth National Conference on Communications (NCC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152502426\",\"name\":\"Shaoqing Tan\"},{\"authorId\":\"8092869\",\"name\":\"R. Yang\"}],\"doi\":\"10.1109/IJCNN.2019.8851694\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1964f5e913bc386707e98e872861dbdf00ed13e\",\"title\":\"Learning Similarity: Feature-Aligning Network for Few-shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1964f5e913bc386707e98e872861dbdf00ed13e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ACPR.2017.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08acfa0920abbac5c5046edcff01e41b12c98be7\",\"title\":\"Learning Principal Orientations Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08acfa0920abbac5c5046edcff01e41b12c98be7\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123482139\",\"name\":\"R. Singh\"},{\"authorId\":\"38825416\",\"name\":\"Jagwinder Kaur Dhillon\"},{\"authorId\":\"3016430\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s11042-018-6425-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fec13c887410dc27a2a16b058a0ea4d114f2d68\",\"title\":\"Depth based enlarged temporal dimension of 3D deep convolutional network for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/8fec13c887410dc27a2a16b058a0ea4d114f2d68\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"49605422\",\"name\":\"Jing Wang\"},{\"authorId\":\"4869835\",\"name\":\"T. Hassan\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.3390/fi11020042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"title\":\"3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"},{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"5810483\",\"name\":\"R. Bom\"}],\"doi\":\"10.1007/978-3-030-25590-9_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"title\":\"Human Activity Identification in Smart Daily Environments\",\"url\":\"https://www.semanticscholar.org/paper/0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3318552\",\"name\":\"Francesco Turchini\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1016/j.cviu.2016.11.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2851efe83633a1c80272ba2c9302a1333dd32523\",\"title\":\"Understanding and localizing activities from correspondences of clustered trajectories\",\"url\":\"https://www.semanticscholar.org/paper/2851efe83633a1c80272ba2c9302a1333dd32523\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1016/j.neucom.2016.08.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b04aa6b89670dc078915adf16c524a1187353453\",\"title\":\"A novel mid-level distinctive feature learning for action recognition via diffusion map\",\"url\":\"https://www.semanticscholar.org/paper/b04aa6b89670dc078915adf16c524a1187353453\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2007.09943\",\"authors\":[{\"authorId\":\"1823941979\",\"name\":\"Sucheng Ren\"},{\"authorId\":\"1641959671\",\"name\":\"Chu Han\"},{\"authorId\":\"6131290\",\"name\":\"X. Yang\"},{\"authorId\":\"2823769\",\"name\":\"G. Han\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1007/978-3-030-58558-7_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1caaf771cf0b8bd0105b01bf7f2b73a58904b5b0\",\"title\":\"TENet: Triple Excitation Network for Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1caaf771cf0b8bd0105b01bf7f2b73a58904b5b0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10790697\",\"name\":\"Dario Dotti\"},{\"authorId\":\"143728689\",\"name\":\"M. Popa\"},{\"authorId\":\"1753719\",\"name\":\"S. Asteriadis\"}],\"doi\":\"10.1016/J.PATREC.2019.06.030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d47056ccb00e3ccbfd650ba2926f1f93972af156\",\"title\":\"A hierarchical autoencoder learning model for path prediction and abnormality detection\",\"url\":\"https://www.semanticscholar.org/paper/d47056ccb00e3ccbfd650ba2926f1f93972af156\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"1511.02126\",\"authors\":[{\"authorId\":\"49112947\",\"name\":\"Shichao Zhao\"},{\"authorId\":\"1732242\",\"name\":\"Y. Liu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"153076339\",\"name\":\"Qinghua Hu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TCSVT.2017.2682196\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"695426275dee2ec56bc0c0afe1c5b4227a350840\",\"title\":\"Pooling the Convolutional Layers in Deep ConvNets for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/695426275dee2ec56bc0c0afe1c5b4227a350840\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ikechukwu Ofodile\"},{\"authorId\":null,\"name\":\"Kaustubh Kulkarni\"},{\"authorId\":\"22211769\",\"name\":\"Ikechukwu Ofodile\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"1783043\",\"name\":\"S. Hyniewska\"},{\"authorId\":\"26987012\",\"name\":\"Juri Allik\"},{\"authorId\":\"3087532\",\"name\":\"G. Anbarjafari\"}],\"doi\":\"10.1109/TAFFC.2018.2874996\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7e6939742251a5a2988c117cb8e54f96583cd61\",\"title\":\"Automatic Recognition of Facial Displays of Unfelt Emotions\",\"url\":\"https://www.semanticscholar.org/paper/a7e6939742251a5a2988c117cb8e54f96583cd61\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2011.07807\",\"authors\":[{\"authorId\":\"1782000465\",\"name\":\"Aftab Alam\"},{\"authorId\":\"51453868\",\"name\":\"Irfan Ullah\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/ACCESS.2020.3017135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"title\":\"Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues\",\"url\":\"https://www.semanticscholar.org/paper/9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38796462\",\"name\":\"Imen Jegham\"},{\"authorId\":\"31259963\",\"name\":\"Anouar Ben Khalifa\"},{\"authorId\":\"2880991\",\"name\":\"Ihsen Alouani\"},{\"authorId\":\"1707715\",\"name\":\"M. Mahjoub\"}],\"doi\":\"10.1016/j.fsidi.2019.200901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b3316944b07e1fb77c9edfa0b716a0ea9e2052\",\"title\":\"Vision-based human action recognition: An overview and real world challenges\",\"url\":\"https://www.semanticscholar.org/paper/46b3316944b07e1fb77c9edfa0b716a0ea9e2052\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d281b07ee152f6c1312297b71791d358f4dc88cb\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360$^{\\\\circ}$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/d281b07ee152f6c1312297b71791d358f4dc88cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.5244/c.31.125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55934f5326f7c86f4a00bc2070723d49e250b307\",\"title\":\"Feature Sequence Representation Via Slow Feature Analysis For Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/55934f5326f7c86f4a00bc2070723d49e250b307\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47930257\",\"name\":\"R. S. C. Oliveira\"}],\"doi\":\"10.25911/5dfc956bbd86c\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"title\":\"Visual Recognition From Structured Supervision\",\"url\":\"https://www.semanticscholar.org/paper/388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.01716\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"29905643\",\"name\":\"Fatih Murat Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"title\":\"Action Representation Using Classifier Decision Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050512\",\"name\":\"Eman Mohammadi\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"2864059\",\"name\":\"Y. Yang\"},{\"authorId\":\"145278886\",\"name\":\"M. Saif\"}],\"doi\":\"10.1109/ICIP.2017.8296589\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f24e2afe83cb21201a2bd4c061b4a9d7d0692fc\",\"title\":\"Effect of wavelet and hybrid classification on action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f24e2afe83cb21201a2bd4c061b4a9d7d0692fc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49112947\",\"name\":\"Shichao Zhao\"},{\"authorId\":\"40566345\",\"name\":\"Yanbin Liu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"515f45e2716626cfd1546a4026f5da1988bbe884\",\"title\":\"Pooling the Convolutional Layers in Deep ConvNets for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/515f45e2716626cfd1546a4026f5da1988bbe884\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1603.01006\",\"authors\":[{\"authorId\":\"144655318\",\"name\":\"F. M. Castro\"},{\"authorId\":\"1398347979\",\"name\":\"M. Mar\\u00edn-Jim\\u00e9nez\"},{\"authorId\":\"1712683\",\"name\":\"Nicol\\u00e1s Guil Mata\"},{\"authorId\":\"6703190\",\"name\":\"N. P. D. L. Blanca\"}],\"doi\":\"10.1007/978-3-319-59147-6_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4263f35acf270651cd4be079db72b0d62ac14fb9\",\"title\":\"Automatic Learning of Gait Signatures for People Identification\",\"url\":\"https://www.semanticscholar.org/paper/4263f35acf270651cd4be079db72b0d62ac14fb9\",\"venue\":\"IWANN\",\"year\":2017},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9012538\",\"name\":\"Salah Alghyaline\"},{\"authorId\":\"144717607\",\"name\":\"Jun-Wei Hsieh\"},{\"authorId\":\"33689898\",\"name\":\"Chi-Hung Chuang\"}],\"doi\":\"10.1109/SMC.2017.8122640\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"title\":\"Video action classification using symmelets and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2894025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"title\":\"Spatiotemporal Relation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51498323\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"3016430\",\"name\":\"Alok Kumar Singh Kushwaha\"}],\"doi\":\"10.1109/ICSCCC.2018.8703295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8354ae30ddbf9f4e7f6a92673ca5d1ee2a17d3b5\",\"title\":\"Deep Learning Approaches for Human Activity Recognition in Video Surveillance - A Survey\",\"url\":\"https://www.semanticscholar.org/paper/8354ae30ddbf9f4e7f6a92673ca5d1ee2a17d3b5\",\"venue\":\"2018 First International Conference on Secure Cyber Computing and Communication (ICSCCC)\",\"year\":2018},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"47558808\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TMM.2019.2919434\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"b0c6a1c99280b862ad42712682d15317e717f789\",\"title\":\"First-Person Action Recognition With Temporal Pooling and Hilbert\\u2013Huang Transform\",\"url\":\"https://www.semanticscholar.org/paper/b0c6a1c99280b862ad42712682d15317e717f789\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/TIP.2018.2791180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"title\":\"Real-Time Action Recognition With Deeply Transferred Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47704922\",\"name\":\"Caijuan Shi\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"9212616\",\"name\":\"Ruizhen Zhao\"},{\"authorId\":\"134614599\",\"name\":\"Qiuiqi Ruan\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TCSVT.2016.2576919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f73bb21cecb668cd6e2d6f02a7c77d0e339f3a2\",\"title\":\"Multiview Hessian Semisupervised Sparse Feature Selection for Multimedia Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9f73bb21cecb668cd6e2d6f02a7c77d0e339f3a2\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":\"2001.08111\",\"authors\":[{\"authorId\":\"49101030\",\"name\":\"C. Tong\"},{\"authorId\":\"51229053\",\"name\":\"Shyam Tailor\"},{\"authorId\":\"144948031\",\"name\":\"N. Lane\"}],\"doi\":\"10.1145/3376897.3377867\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"941f8bd3c080d2c2c2c2b2bcf0270d5b34b320fe\",\"title\":\"Are Accelerometers for Activity Recognition a Dead-end?\",\"url\":\"https://www.semanticscholar.org/paper/941f8bd3c080d2c2c2c2b2bcf0270d5b34b320fe\",\"venue\":\"HotMobile\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1016/j.sigpro.2017.12.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"title\":\"Recurrent attention network using spatial-temporal relations for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":\"1801.07455\",\"authors\":[{\"authorId\":\"1979911\",\"name\":\"S. Yan\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"title\":\"Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1811.09974\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"50023941\",\"name\":\"Y. Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1609/aaai.v33i01.33018674\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ae72dc774f62b190036fb094be4558d827e53d2\",\"title\":\"Temporal Bilinear Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ae72dc774f62b190036fb094be4558d827e53d2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70147929\",\"name\":\"H. Yang\"},{\"authorId\":\"18997752\",\"name\":\"Jun Zhang\"},{\"authorId\":\"2721485\",\"name\":\"Shuohao Li\"},{\"authorId\":\"3249639\",\"name\":\"Tingjin Luo\"}],\"doi\":\"10.3233/JIFS-18209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"title\":\"Bi-direction hierarchical LSTM with spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27687205\",\"name\":\"N. Efthymiou\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"30192180\",\"name\":\"P. P. Filntisis\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2018.8451146\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b56a568799a0dee06587d8ab54032f7bf7712008\",\"title\":\"Multi- View Fusion for Action Recognition in Child-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/b56a568799a0dee06587d8ab54032f7bf7712008\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708998\",\"name\":\"Nguyen Anh Tu\"},{\"authorId\":\"1402997421\",\"name\":\"Thien Huynh-The\"},{\"authorId\":\"2802256\",\"name\":\"Kok-Seng Wong\"},{\"authorId\":\"1490776524\",\"name\":\"Dinh-Mao Bui\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/IMCOM48794.2020.9001680\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e605423620919228036177698d8824ad708bafd\",\"title\":\"Distributed Feature Extraction on Apache Spark for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e605423620919228036177698d8824ad708bafd\",\"venue\":\"2020 14th International Conference on Ubiquitous Information Management and Communication (IMCOM)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122651175\",\"name\":\"Hanqing Guo\"},{\"authorId\":\"65857992\",\"name\":\"Nan Zhang\"},{\"authorId\":\"1680557630\",\"name\":\"Shao-En Wu\"},{\"authorId\":\"50513922\",\"name\":\"Q. Yang\"}],\"doi\":\"10.1109/ICC40277.2020.9148758\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"941ed952a435007da693e0ab1aec86b7acc1f04f\",\"title\":\"Deep Learning Driven Wireless Real-time Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/941ed952a435007da693e0ab1aec86b7acc1f04f\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2396114\",\"name\":\"T. Moreira\"},{\"authorId\":\"8343623\",\"name\":\"D. Menotti\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1109/ICASSP.2017.7952632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c29f21f0b098123e523df17b23fdc4a82940cabe\",\"title\":\"First-person action recognition through Visual Rhythm texture description\",\"url\":\"https://www.semanticscholar.org/paper/c29f21f0b098123e523df17b23fdc4a82940cabe\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1608.08242\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1007/978-3-319-49409-8_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6903ea1adc08200dfe2df5a54896c4c76a0088d1\",\"title\":\"Temporal Convolutional Networks: A Unified Approach to Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6903ea1adc08200dfe2df5a54896c4c76a0088d1\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38100171\",\"name\":\"Yoshiki Kohari\"},{\"authorId\":\"1691940\",\"name\":\"Jun Miura\"},{\"authorId\":\"35620770\",\"name\":\"S. Oishi\"}],\"doi\":\"10.1109/IROS.2018.8594427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74091a749da5c38196bc47cbff33cf9e6ebfb19a\",\"title\":\"Generating Adaptive Attending Behaviors using User State Classification and Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74091a749da5c38196bc47cbff33cf9e6ebfb19a\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1807.08259\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/978-3-030-01225-0_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fef65bd7287b57f0c3b36bf8e6bc987fd161b7d\",\"title\":\"Deep Discriminative Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/6fef65bd7287b57f0c3b36bf8e6bc987fd161b7d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151471179\",\"name\":\"Nasim Khani\"},{\"authorId\":\"1917506\",\"name\":\"M. Rezaeian\"}],\"doi\":\"10.1109/PRIA.2019.8785989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"615f2ff53e297c753b323df4a1550a68953c0260\",\"title\":\"Three-stream Very Deep Neural Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/615f2ff53e297c753b323df4a1550a68953c0260\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47003295\",\"name\":\"Yonggang Li\"},{\"authorId\":\"48843874\",\"name\":\"Rui Ge\"},{\"authorId\":\"36352159\",\"name\":\"Y. Ji\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1109/TCSVT.2017.2759299\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e18c35667c46829a6c7374de11c937359c2b837\",\"title\":\"Trajectory-Pooled Spatial-Temporal Architecture of Deep Convolutional Neural Networks for Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/5e18c35667c46829a6c7374de11c937359c2b837\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9271111\",\"name\":\"Nasrin Sadeghzadehyazdi\"},{\"authorId\":\"2870447\",\"name\":\"T. Batabyal\"},{\"authorId\":\"1771388\",\"name\":\"L. Barnes\"},{\"authorId\":\"1737005\",\"name\":\"S. Acton\"}],\"doi\":\"10.1109/ACSSC.2016.7869577\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9cf8d3b1609f8df248f4ba51bbf6800e6613bc6f\",\"title\":\"Graph-based classification of healthcare provider activity\",\"url\":\"https://www.semanticscholar.org/paper/9cf8d3b1609f8df248f4ba51bbf6800e6613bc6f\",\"venue\":\"2016 50th Asilomar Conference on Signals, Systems and Computers\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014138\",\"name\":\"L. Qi\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"}],\"doi\":\"10.1145/3271553.3271563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08410196627dfd16371d781a64e98573c54d07a4\",\"title\":\"Action Recognition by Jointly Using Video Proposal and Trajectory\",\"url\":\"https://www.semanticscholar.org/paper/08410196627dfd16371d781a64e98573c54d07a4\",\"venue\":\"ICVISP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/ICASSP.2017.7952427\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cdc9bb623bf7e587c8ffb9561aaab9a7e1f0a95\",\"title\":\"Action-vectors: Unsupervised movement modeling for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc9bb623bf7e587c8ffb9561aaab9a7e1f0a95\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491820\",\"name\":\"Nicholas Soures\"},{\"authorId\":\"3327477\",\"name\":\"D. Kudithipudi\"}],\"doi\":\"10.3389/fnins.2019.00686\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47077e47f18f4f63cb30ec90058eb0d59c69c8b5\",\"title\":\"Deep Liquid State Machines With Neural Plasticity for Video Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47077e47f18f4f63cb30ec90058eb0d59c69c8b5\",\"venue\":\"Front. Neurosci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.06321\",\"authors\":[{\"authorId\":\"8474034\",\"name\":\"Osama Mazhar\"},{\"authorId\":\"2521896\",\"name\":\"S. Ramdani\"},{\"authorId\":\"48747847\",\"name\":\"A. Cherubini\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"278347be77a9784763fd9c12750e600dc54169cb\",\"title\":\"A Deep Learning Framework for Recognizing both Static and Dynamic Gestures\",\"url\":\"https://www.semanticscholar.org/paper/278347be77a9784763fd9c12750e600dc54169cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"93233966\",\"name\":\"Chunping Hou\"},{\"authorId\":\"145874777\",\"name\":\"Y. Lang\"},{\"authorId\":\"144902595\",\"name\":\"T. Sakamoto\"},{\"authorId\":\"143605211\",\"name\":\"Yuan He\"},{\"authorId\":\"144455669\",\"name\":\"Wei Xiang\"}],\"doi\":\"10.1109/TGRS.2019.2958178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3b126f91b1a3f1f0c4664e2850f37419bb1121d\",\"title\":\"Omnidirectional Motion Classification With Monostatic Radar System Using Micro-Doppler Signatures\",\"url\":\"https://www.semanticscholar.org/paper/f3b126f91b1a3f1f0c4664e2850f37419bb1121d\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"40495154\",\"name\":\"M. Hayashi\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.5244/C.30.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b063f4a71a7561ea401ea52d49c8fb8348021355\",\"title\":\"Recognition of Transitional Action for Short-Term Action Prediction using Discriminative Temporal CNN Feature\",\"url\":\"https://www.semanticscholar.org/paper/b063f4a71a7561ea401ea52d49c8fb8348021355\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2017.8078548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b9df1094d7db7e17702e785931a927bf568ae7\",\"title\":\"Action recognition based on a mixture of RGB and depth based skeleton\",\"url\":\"https://www.semanticscholar.org/paper/71b9df1094d7db7e17702e785931a927bf568ae7\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144620591\",\"name\":\"X. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"2523380\",\"name\":\"Qingge Ji\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00714\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f66a2c5225551837b8894f94ae9feca0e406c9c1\",\"title\":\"Interpretable Video Captioning via Trajectory Structured Localization\",\"url\":\"https://www.semanticscholar.org/paper/f66a2c5225551837b8894f94ae9feca0e406c9c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/CVPR.2016.287\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1705.07818\",\"authors\":[{\"authorId\":\"144529493\",\"name\":\"Li Ding\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1219c1334c292fb4e5fd0c434dacd0e1e4d5e28\",\"title\":\"TricorNet: A Hybrid Temporal Convolutional and Recurrent Network for Video Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c1219c1334c292fb4e5fd0c434dacd0e1e4d5e28\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2683300\",\"name\":\"Dongcheng Huang\"},{\"authorId\":null,\"name\":\"Xiang Li\"},{\"authorId\":\"3018623\",\"name\":\"H. Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1007/978-3-319-25417-3_72\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bac5a8c2ec366beeb186b5d4cbcf4c00420e6513\",\"title\":\"Learning 3D Compact Binary Descriptor for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/bac5a8c2ec366beeb186b5d4cbcf4c00420e6513\",\"venue\":\"CCBR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121586646\",\"name\":\"A. Sokolova\"},{\"authorId\":\"144608239\",\"name\":\"Anton Konushin\"}],\"doi\":\"10.5194/ISPRS-ARCHIVES-XLII-2-W4-207-2017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11346dfbb4b251e96fb40ca4666c863a2503b1f8\",\"title\":\"GAIT RECOGNITION BASED ON CONVOLUTIONAL NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/11346dfbb4b251e96fb40ca4666c863a2503b1f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91999133\",\"name\":\"Ji-Hwan Kim\"},{\"authorId\":\"3247148\",\"name\":\"Jae-Pil Heo\"}],\"doi\":\"10.1109/ACCESS.2019.2946898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1db07ce91065594751cd51d31f086bc02d42968\",\"title\":\"Learning Coarse and Fine Features for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f1db07ce91065594751cd51d31f086bc02d42968\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2853939\",\"name\":\"Nam-Gyu Cho\"},{\"authorId\":\"39487908\",\"name\":\"S. Park\"},{\"authorId\":\"2479176\",\"name\":\"Jeong-Seon Park\"},{\"authorId\":\"143858687\",\"name\":\"U. Park\"},{\"authorId\":\"1703007\",\"name\":\"S. Lee\"}],\"doi\":\"10.1016/j.neucom.2017.06.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a9457941e57d4b6d59dc979f60c73842ee42fe9\",\"title\":\"Compositional interaction descriptor for human interaction recognition\",\"url\":\"https://www.semanticscholar.org/paper/4a9457941e57d4b6d59dc979f60c73842ee42fe9\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.03148\",\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b191aa2c5b8ece06c221c3a4a0914e8157a16129\",\"title\":\"Deep Spatio-temporal Manifold Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b191aa2c5b8ece06c221c3a4a0914e8157a16129\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"1414105614\",\"name\":\"Tehseen Ul-Hassan\"},{\"authorId\":\"14858604\",\"name\":\"F. Hussain\"},{\"authorId\":\"152924726\",\"name\":\"Jing Wang\"},{\"authorId\":\"144506603\",\"name\":\"Zesong Fei\"}],\"doi\":\"10.1080/1206212X.2018.1486001\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"title\":\"Video representation by dense trajectories motion map applied to human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18947121\",\"name\":\"Muhammad Attique Khan\"},{\"authorId\":\"6482830\",\"name\":\"T. Akram\"},{\"authorId\":\"49311443\",\"name\":\"M. Sharif\"},{\"authorId\":\"145887706\",\"name\":\"Tanzila Saba\"}],\"doi\":\"10.1007/s11042-020-09244-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ff92117ceb91e0c431461de323db337e581fabb\",\"title\":\"Fruits diseases classification: exploiting a hierarchical framework for deep features fusion and selection\",\"url\":\"https://www.semanticscholar.org/paper/4ff92117ceb91e0c431461de323db337e581fabb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"1604959773\",\"name\":\"Yichu Liu\"}],\"doi\":\"10.1007/s11063-019-10091-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"title\":\"Action Recognition with Multiple Relative Descriptors of Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669190956\",\"name\":\"Quanling Meng\"},{\"authorId\":\"9517714\",\"name\":\"Heyan Zhu\"},{\"authorId\":\"8660383\",\"name\":\"W. Zhang\"},{\"authorId\":\"37507545\",\"name\":\"Xuefeng Piao\"},{\"authorId\":\"1669161026\",\"name\":\"A. Zhang\"}],\"doi\":\"10.1145/3350840\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a27008678d149d4d286654217a29559c2a55b96\",\"title\":\"Action Recognition Using Form and Motion Modalities\",\"url\":\"https://www.semanticscholar.org/paper/8a27008678d149d4d286654217a29559c2a55b96\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.05231\",\"authors\":[{\"authorId\":\"5911068\",\"name\":\"V. Kaushik\"},{\"authorId\":\"2550012\",\"name\":\"Prerana Mukherjee\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"}],\"doi\":\"10.1145/3293353.3293419\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d99fd437137b8562ed4f4ece533d4d363ebcf0b2\",\"title\":\"Nrityantar: Pose oblivious Indian classical dance sequence classification system\",\"url\":\"https://www.semanticscholar.org/paper/d99fd437137b8562ed4f4ece533d4d363ebcf0b2\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":null,\"name\":\"Yu WANG\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1587/transinf.2019edp7045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e1d13a84e105f9ce6e176d2ebf22e10c473bae5\",\"title\":\"Attention-Guided Spatial Transformer Networks for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e1d13a84e105f9ce6e176d2ebf22e10c473bae5\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":\"1706.06905\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"title\":\"Learnable pooling with Context Gating for video classification\",\"url\":\"https://www.semanticscholar.org/paper/1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9742265\",\"name\":\"O. C. Kwon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/ICIP.2018.8451493\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"title\":\"Action Recognition: First-and Second-Order 3D Feature in Bi-Directional Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1728931\",\"name\":\"K. Kiguchi\"},{\"authorId\":\"66904386\",\"name\":\"Manosha Chathuramali\"}],\"doi\":\"10.1109/SMC.2018.00160\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d948111319095c8f2b5d805764efbbb8a40bacf3\",\"title\":\"A Study on Real-Time Detection of Interacting Motion Intention for Perception-Assist with an Upper-Limb Wearable Power-Assist Robot\",\"url\":\"https://www.semanticscholar.org/paper/d948111319095c8f2b5d805764efbbb8a40bacf3\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068393\",\"name\":\"Xiusheng Lu\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"},{\"authorId\":\"1793532\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1007/978-3-319-77380-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"994b9df5038a6457185e8408075b81e97f1ccafe\",\"title\":\"Trajectory-Pooled 3D Convolutional Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/994b9df5038a6457185e8408075b81e97f1ccafe\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":\"1701.01821\",\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"3378457\",\"name\":\"Boya Peng\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"title\":\"Unsupervised Learning of Long-Term Motion Dynamics for Videos\",\"url\":\"https://www.semanticscholar.org/paper/cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"1740321\",\"name\":\"Jian Yu\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1016/j.neucom.2019.01.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f38d00417e5e6655caf8eeea224aaceffbe20606\",\"title\":\"Action recognition and localization with spatial and temporal contexts\",\"url\":\"https://www.semanticscholar.org/paper/f38d00417e5e6655caf8eeea224aaceffbe20606\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1804.06248\",\"authors\":[{\"authorId\":\"48169955\",\"name\":\"L. Wang\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"2858139\",\"name\":\"L. Yang\"},{\"authorId\":\"47827548\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"}],\"doi\":\"10.1007/978-3-030-01231-1_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f1afe81db19cc4a60d597f5480c9d8e9346f21e\",\"title\":\"PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities\",\"url\":\"https://www.semanticscholar.org/paper/8f1afe81db19cc4a60d597f5480c9d8e9346f21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"39952920\",\"name\":\"Q. Qin\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.patcog.2018.01.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa733992a236258adf36a41413b96707c8e9f4c\",\"title\":\"Multi-stream CNN: Learning representations based on human-related regions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/baa733992a236258adf36a41413b96707c8e9f4c\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1806.00631\",\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"145957093\",\"name\":\"Wen Zhou\"},{\"authorId\":\"47095962\",\"name\":\"Yuxuan Wu\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"46398737\",\"name\":\"Yongwen Liu\"}],\"doi\":\"10.1109/ICSP.2018.8652287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da092dad9a978f420bff4fb7731d5453ebed1d5e\",\"title\":\"Squeeze-and-Excitation on Spatial and Temporal Deep Feature Space for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/da092dad9a978f420bff4fb7731d5453ebed1d5e\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1902.08990\",\"authors\":[{\"authorId\":\"1455928386\",\"name\":\"Chongyang Wang\"},{\"authorId\":\"38792093\",\"name\":\"Temitayo A. Olugbade\"},{\"authorId\":\"152859908\",\"name\":\"Akhil Mathur\"},{\"authorId\":\"144450667\",\"name\":\"A. Williams\"},{\"authorId\":\"144948031\",\"name\":\"N. Lane\"},{\"authorId\":\"1398541310\",\"name\":\"N. Bianchi-Berthouze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51268f83d57650802521573f5bfe4de2760e073b\",\"title\":\"Chronic-Pain Protective Behavior Detection with Deep Learning.\",\"url\":\"https://www.semanticscholar.org/paper/51268f83d57650802521573f5bfe4de2760e073b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"1764521\",\"name\":\"A. A. Salah\"}],\"doi\":\"10.1016/j.eswa.2015.06.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb657cd8729773cd9a52ed31c68f550be1f86323\",\"title\":\"Efficient large-scale action recognition in videos using extreme learning machines\",\"url\":\"https://www.semanticscholar.org/paper/eb657cd8729773cd9a52ed31c68f550be1f86323\",\"venue\":\"Expert Syst. Appl.\",\"year\":2015},{\"arxivId\":\"2002.03266\",\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":\"10.1109/WACV45572.2020.9093283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144397879\",\"name\":\"S. N. Gowda\"}],\"doi\":\"10.1109/CVPRW.2017.203\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9df46ca568e4feda02cbe7fe87f7184d3daa773\",\"title\":\"Human Activity Recognition Using Combinatorial Deep Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/c9df46ca568e4feda02cbe7fe87f7184d3daa773\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1906.11465\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1761350\",\"name\":\"M. Mansour\"}],\"doi\":\"10.1109/ICIP.2019.8803051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e017494522a1609516f755f3023e7a48b18a95e\",\"title\":\"Loss Switching Fusion with Similarity Search for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/3e017494522a1609516f755f3023e7a48b18a95e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3206025.3206028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"title\":\"Dense Dilated Network for Few Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145184141\",\"name\":\"Yifan Wang\"},{\"authorId\":\"40403685\",\"name\":\"J. Song\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"2531379\",\"name\":\"Otmar Hilliges\"}],\"doi\":\"10.5244/C.30.108\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b09b693708f412823053508578df289b8403100a\",\"title\":\"Two-Stream SR-CNNs for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b09b693708f412823053508578df289b8403100a\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3191503\",\"name\":\"H. Abrishami Moghaddam\"},{\"authorId\":\"145937063\",\"name\":\"A. Zare\"}],\"doi\":\"10.1007/s13735-018-00167-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeb6a52303212d5507d8747c8ef20e5ba01c7676\",\"title\":\"Spatiotemporal wavelet correlogram for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/aeb6a52303212d5507d8747c8ef20e5ba01c7676\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2086802\",\"name\":\"J. Cai\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"},{\"authorId\":\"2504555\",\"name\":\"F. Imai\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/ICIP.2016.7533142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95f1790da3d0a4a5310a050512ce355b3c5aac86\",\"title\":\"Towards temporal adaptive representation for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/95f1790da3d0a4a5310a050512ce355b3c5aac86\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"152245395\",\"name\":\"Zexin Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2933303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"title\":\"Refined Spatial Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50084326\",\"name\":\"Guirong Liu\"},{\"authorId\":\"48615424\",\"name\":\"Yi Xu\"},{\"authorId\":\"26972197\",\"name\":\"Jinpeng Lan\"}],\"doi\":\"10.1117/12.2239019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5dc51ad768d26fcf6f91aa1b43e096b154a8667\",\"title\":\"No-reference face image assessment based on deep features\",\"url\":\"https://www.semanticscholar.org/paper/e5dc51ad768d26fcf6f91aa1b43e096b154a8667\",\"venue\":\"Optical Engineering + Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32154590\",\"name\":\"Krit Karan Singh\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1007/978-981-13-0020-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d428f98e0bad7c34e3acd6064f7967ba8d5cd59\",\"title\":\"Recognizing Human Activities in Videos Using Improved Dense Trajectories over LSTM\",\"url\":\"https://www.semanticscholar.org/paper/4d428f98e0bad7c34e3acd6064f7967ba8d5cd59\",\"venue\":\"NCVPRIPG\",\"year\":2017},{\"arxivId\":\"1510.03979\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143921504\",\"name\":\"S. Guo\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCVW.2015.46\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e93d38ef345ae17d18789c47c41ca10f6b588eda\",\"title\":\"Better Exploiting OS-CNNs for Better Event Recognition in Images\",\"url\":\"https://www.semanticscholar.org/paper/e93d38ef345ae17d18789c47c41ca10f6b588eda\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Li\"},{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2016.215\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ca818c89b1589549ad91ff67223053ec75fa9ac5\",\"title\":\"VLAD3: Encoding Dynamics of Deep Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca818c89b1589549ad91ff67223053ec75fa9ac5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71767110\",\"name\":\"Vicent Roig Ripoll\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3dc67bb4cd3601ae9bdb7df4ed5036f525ff21d\",\"title\":\"Multimodal 2DCNN action recognition from RGB-D data with video summarization\",\"url\":\"https://www.semanticscholar.org/paper/f3dc67bb4cd3601ae9bdb7df4ed5036f525ff21d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068393\",\"name\":\"Xiusheng Lu\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1007/s11042-017-5251-3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"40d62396bb195d510bef5c0fd2bfa2bae6777754\",\"title\":\"Action recognition with multi-scale trajectory-pooled 3D convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/40d62396bb195d510bef5c0fd2bfa2bae6777754\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2018.2819173\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"766ae45375cd023464b730ace01fdd7d312f963b\",\"title\":\"Semi-Supervised Video Object Segmentation with Super-Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/766ae45375cd023464b730ace01fdd7d312f963b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84259605\",\"name\":\"Filip Granqvist\"},{\"authorId\":\"83191308\",\"name\":\"Oskar Holmberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16e445d470129a4fdb3c484216a368dc4a611bd2\",\"title\":\"A deep learning based tracking framework for passenger monitoring\",\"url\":\"https://www.semanticscholar.org/paper/16e445d470129a4fdb3c484216a368dc4a611bd2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00052\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"title\":\"Improving a 3-D Convolutional Neural Network Model Reinvented from VGG16 with Batch Normalization\",\"url\":\"https://www.semanticscholar.org/paper/50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"title\":\"Two-Stage Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"1410115257\",\"name\":\"Ge Li\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"}],\"doi\":\"10.1007/978-3-319-64698-5_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20828d021b5987bebc3ce495e44eb9e48eb9be3e\",\"title\":\"A Violence Detection Approach Based on Spatio-temporal Hypergraph Transition\",\"url\":\"https://www.semanticscholar.org/paper/20828d021b5987bebc3ce495e44eb9e48eb9be3e\",\"venue\":\"CAIP\",\"year\":2017},{\"arxivId\":\"1707.04061\",\"authors\":[{\"authorId\":\"22211769\",\"name\":\"Ikechukwu Ofodile\"},{\"authorId\":\"145930781\",\"name\":\"Kaustubh Kulkarni\"},{\"authorId\":\"22197083\",\"name\":\"C. Corneanu\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"1783043\",\"name\":\"S. Hyniewska\"},{\"authorId\":\"26987012\",\"name\":\"Juri Allik\"},{\"authorId\":\"3087532\",\"name\":\"G. Anbarjafari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47d4838087a7ac2b995f3c5eba02ecdd2c28ba14\",\"title\":\"Automatic Recognition of Deceptive Facial Expressions of Emotion\",\"url\":\"https://www.semanticscholar.org/paper/47d4838087a7ac2b995f3c5eba02ecdd2c28ba14\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"9637828\",\"name\":\"Junho Jin\"},{\"authorId\":\"144396280\",\"name\":\"Yongjin Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"144341935\",\"name\":\"K. Park\"}],\"doi\":\"10.4218/ETRIJ.17.0116.0054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58c692a2ac35d4beab97836c4c95881d52beb61\",\"title\":\"Extensible Hierarchical Method of Detecting Interactive Actions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e58c692a2ac35d4beab97836c4c95881d52beb61\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390076423\",\"name\":\"Guang Ting Foo\"},{\"authorId\":\"46917486\",\"name\":\"Kam Meng Goh\"}],\"doi\":\"10.3233/IDT-190360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"914f36710026d0796f133469c0839915af711490\",\"title\":\"Violence action recognition using region proposal in region convolution neural network\",\"url\":\"https://www.semanticscholar.org/paper/914f36710026d0796f133469c0839915af711490\",\"venue\":\"Intell. Decis. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2461523\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"},{\"authorId\":\"145684034\",\"name\":\"F. Lin\"}],\"doi\":\"10.1016/j.image.2017.05.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83a6d5cbc148d10e6dadcf2066df08f0c58f0161\",\"title\":\"Combined trajectories for action recognition based on saliency detection and motion boundary\",\"url\":\"https://www.semanticscholar.org/paper/83a6d5cbc148d10e6dadcf2066df08f0c58f0161\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":\"1601.07576\",\"authors\":[{\"authorId\":\"143921503\",\"name\":\"S. Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2016.2629443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0dd1d6984eff4e3af358eaf7117c2912e9f536f5\",\"title\":\"Locally Supervised Deep Hybrid Model for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0dd1d6984eff4e3af358eaf7117c2912e9f536f5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3436875\",\"name\":\"Omar ElHarrouss\"},{\"authorId\":\"2380070\",\"name\":\"Noor Almaadeed\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-Maadeed\"}],\"doi\":\"10.1007/978-981-15-0637-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"title\":\"MHAD: Multi-Human Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"venue\":\"ICICT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/s11263-015-0859-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16eaa26a84468b27e559215db01c53286808ec2a\",\"title\":\"MoFAP: A Multi-level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16eaa26a84468b27e559215db01c53286808ec2a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1145/2964284.2964297\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"title\":\"Multilayer and Multimodal Fusion of Deep Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49741227\",\"name\":\"Haifeng Sang\"},{\"authorId\":\"152254334\",\"name\":\"Z. Zhao\"},{\"authorId\":\"3030181\",\"name\":\"Dakuo He\"}],\"doi\":\"10.1109/ACCESS.2019.2936628\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"title\":\"Two-Level Attention Model Based Video Action Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"2767515\",\"name\":\"Izaro Goienetxea\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"}],\"doi\":\"10.3390/s20082436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"708ef686a14105ba5f1d75d1c5f4db9f96e46c93\",\"title\":\"Shedding Light on People Action Recognition in Social Robotics by Means of Common Spatial Patterns\",\"url\":\"https://www.semanticscholar.org/paper/708ef686a14105ba5f1d75d1c5f4db9f96e46c93\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1709.05087\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"3003408\",\"name\":\"Mian M. Ajmal\"}],\"doi\":\"10.1109/ACCESS.2018.2880231\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"title\":\"Viewpoint Invariant Action Recognition Using RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1701.00599\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TMM.2017.2751969\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1da240dd35a4923b623b7bae66b1b7f074890852\",\"title\":\"AENet: Learning Deep Audio Features for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1da240dd35a4923b623b7bae66b1b7f074890852\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3241032\",\"name\":\"M. Z. Uddin\"},{\"authorId\":\"1757843\",\"name\":\"W. Khaksar\"},{\"authorId\":\"9395911\",\"name\":\"J. T\\u00f8rresen\"}],\"doi\":\"10.3390/s18072027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16810e9d90de52aa1e310e0b8b2e594cc4e0d86d\",\"title\":\"Ambient Sensors for Elderly Care and Independent Living: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/16810e9d90de52aa1e310e0b8b2e594cc4e0d86d\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193978\",\"name\":\"Y. C. Song\"},{\"authorId\":\"2296971\",\"name\":\"Iftekhar Naim\"},{\"authorId\":\"50059663\",\"name\":\"A. Mamun\"},{\"authorId\":\"145930781\",\"name\":\"Kaustubh Kulkarni\"},{\"authorId\":\"35108153\",\"name\":\"Parag Singla\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1793218\",\"name\":\"Daniel Gildea\"},{\"authorId\":\"1690271\",\"name\":\"Henry A. Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a639e9bc9c630d917b02b29b37b03e4efd2f63fc\",\"title\":\"Unsupervised Alignment of Actions in Video with Text Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a639e9bc9c630d917b02b29b37b03e4efd2f63fc\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"2139431\",\"name\":\"Lianyang Ma\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"},{\"authorId\":\"144419119\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TPAMI.2018.2863279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9b958c2494b7ba08b5b460f19a06814dba8aee0\",\"title\":\"Early Action Prediction by Soft Regression\",\"url\":\"https://www.semanticscholar.org/paper/c9b958c2494b7ba08b5b460f19a06814dba8aee0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"40236409\",\"name\":\"Heng Li\"},{\"authorId\":\"30963734\",\"name\":\"Xincong Yang\"},{\"authorId\":\"2740879\",\"name\":\"Y. Yu\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"}],\"doi\":\"10.1111/mice.12419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"311c2e2b55e72c43d3e70eb6c10335b4d23d4fe0\",\"title\":\"Capturing and Understanding Workers' Activities in Far-Field Surveillance Videos with Deep Action Recognition and Bayesian Nonparametric Learning\",\"url\":\"https://www.semanticscholar.org/paper/311c2e2b55e72c43d3e70eb6c10335b4d23d4fe0\",\"venue\":\"Comput. Aided Civ. Infrastructure Eng.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144091320\",\"name\":\"Guyue Zhang\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"10727378\",\"name\":\"Y. Chen\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/LSP.2017.2731952\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a3523db70e5a0a24b1a38ea8bd55a25c63972d8\",\"title\":\"Joint Human Detection and Head Pose Estimation via Multistream Networks for RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/5a3523db70e5a0a24b1a38ea8bd55a25c63972d8\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2016.288\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"16461bc1f06c781b5357cb1157248d28dc3672a0\",\"title\":\"Recognizing Micro-Actions and Reactions from Paired Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/16461bc1f06c781b5357cb1157248d28dc3672a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":\"47681623\",\"name\":\"Lin Li\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICARM.2016.7606913\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b68f55bab12ca50b033d8b5c773ce5fe88c5923d\",\"title\":\"Human action recognition with DeepAction Kernel Gaussian Process\",\"url\":\"https://www.semanticscholar.org/paper/b68f55bab12ca50b033d8b5c773ce5fe88c5923d\",\"venue\":\"2016 International Conference on Advanced Robotics and Mechatronics (ICARM)\",\"year\":2016},{\"arxivId\":\"1609.05281\",\"authors\":[{\"authorId\":\"144883800\",\"name\":\"A. Gandhi\"},{\"authorId\":\"34751361\",\"name\":\"Arjun Sharma\"},{\"authorId\":\"47606073\",\"name\":\"A. Biswas\"},{\"authorId\":\"2116262\",\"name\":\"O. Deshmukh\"}],\"doi\":\"10.1007/978-3-319-48881-3_58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"551fa37e8d6d03b89d195a5c00c74cc52ff1c67a\",\"title\":\"GeThR-Net: A Generalized Temporally Hybrid Recurrent Neural Network for Multimodal Information Fusion\",\"url\":\"https://www.semanticscholar.org/paper/551fa37e8d6d03b89d195a5c00c74cc52ff1c67a\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"Vittorio Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"Martial Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"144538257\",\"name\":\"Yair Weiss\"}],\"doi\":\"10.1007/978-3-030-01231-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"326fdd827e8026ea313c769452912eebf56eff5d\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/326fdd827e8026ea313c769452912eebf56eff5d\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2749314\",\"name\":\"Suolan Liu\"},{\"authorId\":\"108384329\",\"name\":\"Rol. M. Lagonegro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bb1b5e4a541527ca14c9e54e68672228367f857\",\"title\":\"Action Recognition Scheme Based on RGB-D Mixture Model\",\"url\":\"https://www.semanticscholar.org/paper/7bb1b5e4a541527ca14c9e54e68672228367f857\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"144653471\",\"name\":\"X. Xiao\"}],\"doi\":\"10.1007/s11063-018-9932-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e64440c4088ae1b871fb3f6af8dd5c4e7dbe00a\",\"title\":\"Action Recognition Using Multiple Pooling Strategies of CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/5e64440c4088ae1b871fb3f6af8dd5c4e7dbe00a\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPRW.2015.7301330\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dc7693733fc72b20955d0154c0223955056fd2c\",\"title\":\"Exploring Fisher vector and deep networks for action spotting\",\"url\":\"https://www.semanticscholar.org/paper/5dc7693733fc72b20955d0154c0223955056fd2c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.212\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"641421832f237b280644261a77eca3974ac9c0c1\",\"title\":\"Discriminative Hierarchical Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/641421832f237b280644261a77eca3974ac9c0c1\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144391007\",\"name\":\"Tiago Lima\"},{\"authorId\":\"30884385\",\"name\":\"B. Fernandes\"},{\"authorId\":\"144039832\",\"name\":\"P. Barros\"}],\"doi\":\"10.1109/LA-CCI.2017.8285700\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86bd586aa5f4b1bb3e6cd58ee417ac0ad0ee6596\",\"title\":\"Human action recognition with 3D convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/86bd586aa5f4b1bb3e6cd58ee417ac0ad0ee6596\",\"venue\":\"2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI)\",\"year\":2017},{\"arxivId\":\"1505.04427\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"1711953\",\"name\":\"Dezhong Yao\"},{\"authorId\":\"144247537\",\"name\":\"Ming Lin\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPRW.2016.152\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e42377ef3aad1b22172079ed70a69a4848c76367\",\"title\":\"The Best of BothWorlds: Combining Data-Independent and Data-Driven Approaches for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e42377ef3aad1b22172079ed70a69a4848c76367\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ISCAS.2018.8350912\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"title\":\"A 65 fps Full-HD Hardware Implementation of HOG, HOF, MBHx, and MBHy for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1801.07388\",\"authors\":[{\"authorId\":\"118242229\",\"name\":\"D. Castro\"},{\"authorId\":\"2935619\",\"name\":\"Steven Hickson\"},{\"authorId\":\"3430745\",\"name\":\"Patsorn Sangkloy\"},{\"authorId\":\"145389008\",\"name\":\"Bhavishya Mittal\"},{\"authorId\":\"35459529\",\"name\":\"Sean Dai\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e25cab2251a8ded43c44b28a87f4c62e3a548a\",\"title\":\"Let's Dance: Learning From Online Dance Videos\",\"url\":\"https://www.semanticscholar.org/paper/a6e25cab2251a8ded43c44b28a87f4c62e3a548a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"1880569\",\"name\":\"Jingzhuo Wang\"},{\"authorId\":\"3424070\",\"name\":\"Y. Bu\"}],\"doi\":\"10.1109/ISCAS.2017.8050638\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1241b2f9f5bccd3daeee3302747a9a1583a2b225\",\"title\":\"Better deep visual attention with reinforcement learning in action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1241b2f9f5bccd3daeee3302747a9a1583a2b225\",\"venue\":\"2017 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429500\",\"name\":\"Eva Coupet\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"526ce79587f9098ee6c153424ead74e7fbf02a80\",\"title\":\"Reconnaissance de gestes et actions pour la collaboration homme-robot sur cha\\u00eene de montage. (Recognition of gestures and actions for man and robot collaboration on assembly line)\",\"url\":\"https://www.semanticscholar.org/paper/526ce79587f9098ee6c153424ead74e7fbf02a80\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"}],\"doi\":\"10.22028/D291-27156\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"title\":\"From perception over anticipation to manipulation\",\"url\":\"https://www.semanticscholar.org/paper/993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1508.06073\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73ed64803d6f2c49f01cffef8e6be8fc9b5273b8\",\"title\":\"Cooking in the kitchen: Recognizing and Segmenting Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/73ed64803d6f2c49f01cffef8e6be8fc9b5273b8\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2016.333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"title\":\"Regularizing Long Short Term Memory with 3D Human-Skeleton Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2093239\",\"name\":\"Dazi Li\"},{\"authorId\":\"145929479\",\"name\":\"Mingjie Yan\"},{\"authorId\":\"2008152248\",\"name\":\"Zhiwen Miao\"},{\"authorId\":\"1693024178\",\"name\":\"Yue Fang\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/ICNSC48988.2020.9238085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e7f9bab8c09ee416990f30c4f64869eb405a8f0\",\"title\":\"LSTM Neural Network based Tensile Stress Prediction of Rubber Streching\",\"url\":\"https://www.semanticscholar.org/paper/4e7f9bab8c09ee416990f30c4f64869eb405a8f0\",\"venue\":\"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)\",\"year\":2020},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"896b764cff4d71f917c485593ef78d2f1ed7124d\",\"title\":\"Online, Supervised and Unsupervised Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/896b764cff4d71f917c485593ef78d2f1ed7124d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153838578\",\"name\":\"C. Payan\"},{\"authorId\":\"46806492\",\"name\":\"F. Manuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"28278216a83ea3b80d8d167601daa3554a3d5a02\",\"title\":\"Gait recognition from multiple view-points\",\"url\":\"https://www.semanticscholar.org/paper/28278216a83ea3b80d8d167601daa3554a3d5a02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"}],\"doi\":\"10.32657/10356/70099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"title\":\"Pose-invariant action recognition for automated behaviour analysis\",\"url\":\"https://www.semanticscholar.org/paper/fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2751145\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4289f9f727af39414537a97e5eef90b06115a5db\",\"title\":\"Global-Local Temporal Saliency Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4289f9f727af39414537a97e5eef90b06115a5db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24702080\",\"name\":\"S. Tong\"},{\"authorId\":\"7727059\",\"name\":\"Yuzhuo Fu\"},{\"authorId\":\"9543601\",\"name\":\"Xinwei Yue\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"}],\"doi\":\"10.1109/ACCESS.2018.2874073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3fbeda9cbce94bbc0d85494935ed27c49e8a0a6\",\"title\":\"Multi-View Gait Recognition Based on a Spatial-Temporal Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c3fbeda9cbce94bbc0d85494935ed27c49e8a0a6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037859\",\"name\":\"Saddam Bekhet\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"274be0f6a343c0c75e792f4fa9f598bf7d1924c8\",\"title\":\"Signature-based videos' visual similarity detection and measurement\",\"url\":\"https://www.semanticscholar.org/paper/274be0f6a343c0c75e792f4fa9f598bf7d1924c8\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35000381\",\"name\":\"Dillon Graham\"},{\"authorId\":\"3231447\",\"name\":\"Seyed Hamed Fatemi Langroudi\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"},{\"authorId\":\"3327477\",\"name\":\"D. Kudithipudi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9172f8c1eb64b82dbfe0cf512adf393cfc03f6ca\",\"title\":\"C V ] 3 N ov 2 01 7 Convolutional Drift Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/9172f8c1eb64b82dbfe0cf512adf393cfc03f6ca\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144985898\",\"name\":\"B. Su\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"145507765\",\"name\":\"X. Ding\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1007/978-3-319-46493-0_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d59e73984f3538dfd1e793d0c4be6a788a4872f\",\"title\":\"Hierarchical Dynamic Parsing and Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d59e73984f3538dfd1e793d0c4be6a788a4872f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001082\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"1755153\",\"name\":\"N. M. Charkari\"}],\"doi\":\"10.1049/iet-cvi.2016.0355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"title\":\"Survey on deep learning methods in human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":\"10.1109/ROMAN.2017.8172462\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d86e4dd39731778ac85ec7ff56cbc9fdf4ef739b\",\"title\":\"Basic study on appearance-based proficiency evaluation of the football inside kick\",\"url\":\"https://www.semanticscholar.org/paper/d86e4dd39731778ac85ec7ff56cbc9fdf4ef739b\",\"venue\":\"2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21243543\",\"name\":\"Shuang Wu\"},{\"authorId\":\"47912692\",\"name\":\"Hua Yang\"},{\"authorId\":\"2071921\",\"name\":\"S. Zheng\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"2576377\",\"name\":\"Yawen Fan\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/s11263-017-1005-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22d4e52ece7f5b7ec499246550b69885f0341fed\",\"title\":\"Crowd Behavior Analysis via Curl and Divergence of Motion Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/22d4e52ece7f5b7ec499246550b69885f0341fed\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1605.04988\",\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.imavis.2017.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"title\":\"Going deeper into action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1007/978-3-319-57687-9_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"961c880bb487dd77eafc066da6c014ab8eab543c\",\"title\":\"Saliency Prediction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/961c880bb487dd77eafc066da6c014ab8eab543c\",\"venue\":\"Visual Content Indexing and Retrieval with Psycho-Visual Models\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798691\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144323097\",\"name\":\"W. Yu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9695232daa85651937569d1b7b2541faf2633dc\",\"title\":\"Actionness-pooled Deep-convolutional Descriptor for fine-grained action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9695232daa85651937569d1b7b2541faf2633dc\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1904.13085\",\"authors\":[{\"authorId\":\"144766725\",\"name\":\"D. Wang\"},{\"authorId\":\"49521346\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2904857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"title\":\"Early Action Prediction With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"143792007\",\"name\":\"Peng Duan\"},{\"authorId\":\"2095855\",\"name\":\"B. Ma\"},{\"authorId\":\"144044737\",\"name\":\"P. Wu\"},{\"authorId\":\"2882531\",\"name\":\"Weizhi Lu\"}],\"doi\":\"10.1016/J.JVCIR.2019.04.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"735ddb487ed4efdbffd83239019662ba6c584c63\",\"title\":\"Action recognition using dynamic hierarchical trees\",\"url\":\"https://www.semanticscholar.org/paper/735ddb487ed4efdbffd83239019662ba6c584c63\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1703.02716\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"title\":\"A Pursuit of Temporal Accuracy in General Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f865770fa62204783c475186fdb92d496362c2b9\",\"title\":\"Large-Scale Multimodal Gesture Recognition Using Heterogeneous Networks\",\"url\":\"https://www.semanticscholar.org/paper/f865770fa62204783c475186fdb92d496362c2b9\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"102868457\",\"name\":\"W. Li\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144410724\",\"name\":\"K. Jin\"}],\"doi\":\"10.1145/3234804.3234821\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"title\":\"Local Feature Analysis for real-time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"venue\":\"ICDLT '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"1702330\",\"name\":\"R. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"title\":\"Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1603.08561\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e03e86ac61cfac9148b371d75ce81a55e8b332ca\",\"title\":\"Unsupervised Learning using Sequential Verification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e03e86ac61cfac9148b371d75ce81a55e8b332ca\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108523210\",\"name\":\"Cunhuang Xie\"},{\"authorId\":\"143857124\",\"name\":\"L. Yu\"},{\"authorId\":\"67235507\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/VCIP.2018.8698688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acf509cf987abb997947de86a30700401d703b9f\",\"title\":\"Deep Feature Extraction and Multi-feature Fusion for Similar Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/acf509cf987abb997947de86a30700401d703b9f\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1702.04037\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa29975169ba3bbb954e518bc9814a5819876f6\",\"title\":\"Evolution-Preserving Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/faa29975169ba3bbb954e518bc9814a5819876f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"143657565\",\"name\":\"P. Jiang\"}],\"doi\":\"10.1007/s10489-018-1347-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"57bb032953f09168953f1cc03102b9269eeee7f5\",\"title\":\"Learning multi-temporal-scale deep information for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/57bb032953f09168953f1cc03102b9269eeee7f5\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6544209\",\"name\":\"N. Kumaran\"},{\"authorId\":\"3846423\",\"name\":\"U. S. Reddy\"}],\"doi\":\"10.1109/ICICI.2017.8365242\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ec431e36919e29524eceb1431d3e1202637cf19\",\"title\":\"Object detection and tracking in crowd environment \\u2014 A review\",\"url\":\"https://www.semanticscholar.org/paper/7ec431e36919e29524eceb1431d3e1202637cf19\",\"venue\":\"2017 International Conference on Inventive Computing and Informatics (ICICI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202319\",\"name\":\"K. Xia\"},{\"authorId\":\"1826167\",\"name\":\"Hongsheng Yin\"}],\"doi\":\"10.1109/ACCESS.2019.2953517\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8517fd045beee87757b521b29f2f527bb7c61a6f\",\"title\":\"Liver Detection Algorithm Based on an Improved Deep Network Combined With Edge Perception\",\"url\":\"https://www.semanticscholar.org/paper/8517fd045beee87757b521b29f2f527bb7c61a6f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1016/B978-0-12-810408-8.00003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783cd91797aad234b1558099689e794b48694092\",\"title\":\"An Introduction to Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/783cd91797aad234b1558099689e794b48694092\",\"venue\":\"Deep Learning for Medical Image Analysis\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004905657\",\"name\":\"Rihem Mahmoud\"},{\"authorId\":\"1757886\",\"name\":\"S. Belgacem\"},{\"authorId\":\"3169159\",\"name\":\"M. Omri\"}],\"doi\":\"10.1016/j.jksuci.2020.08.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"title\":\"Deep Signature-based Isolated and Large Scale Continuous Gesture Recognition Approach\",\"url\":\"https://www.semanticscholar.org/paper/52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"3393556\",\"name\":\"Kaipeng Zhang\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1007/978-3-319-46478-7_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cfd770ccecae1c0b4248bc800d7fd35c817bbbd\",\"title\":\"A Discriminative Feature Learning Approach for Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cfd770ccecae1c0b4248bc800d7fd35c817bbbd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2964284.2964328\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"899be93e14d991017b1f8a4afdf907cbc03cf300\",\"title\":\"Multi-Stream Multi-Class Fusion of Deep Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/899be93e14d991017b1f8a4afdf907cbc03cf300\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1911.06080\",\"authors\":[{\"authorId\":\"1409975963\",\"name\":\"Yushuai Hu\"},{\"authorId\":\"143618654\",\"name\":\"Y. Jin\"},{\"authorId\":\"48881611\",\"name\":\"R. Li\"},{\"authorId\":\"47958382\",\"name\":\"XiangXiang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20541068388f9555b0cbb9b5004b4afe56d8ec66\",\"title\":\"CMSN: Continuous Multi-stage Network and Variable Margin Cosine Loss for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/20541068388f9555b0cbb9b5004b4afe56d8ec66\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"47740566\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"title\":\"Action recognition with gradient boundary convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84243115\",\"name\":\"R. Singh\"},{\"authorId\":\"39727023\",\"name\":\"Swati Nigam\"},{\"authorId\":\"48775558\",\"name\":\"A. Singh\"},{\"authorId\":\"49282672\",\"name\":\"M. Elhoseny\"}],\"doi\":\"10.1007/978-3-030-31873-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62a2179c7776610fa1bb54759feb2a077db6dce8\",\"title\":\"Wavelets for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/62a2179c7776610fa1bb54759feb2a077db6dce8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49836180\",\"name\":\"Zhimin Bai\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e3baf29a555ca959f51b848fb21ee224835db9b\",\"title\":\"High-Order Graph Convolutional Network for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e3baf29a555ca959f51b848fb21ee224835db9b\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15287636\",\"name\":\"K. Sun\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"12791664\",\"name\":\"Lianqiang Li\"},{\"authorId\":\"51511262\",\"name\":\"Ningyu He\"},{\"authorId\":\"50820964\",\"name\":\"Jie Zhu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df8b5676d62e0114ae2a804894c33b8e3d8ab3bf\",\"title\":\"Spatial Attentional Bilinear 3D Convolutional Network for Video-Based Autism Spectrum Disorder Detection\",\"url\":\"https://www.semanticscholar.org/paper/df8b5676d62e0114ae2a804894c33b8e3d8ab3bf\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890560\",\"name\":\"Ryota Yoshihashi\"},{\"authorId\":\"38621343\",\"name\":\"T. Trinh\"},{\"authorId\":\"48727803\",\"name\":\"Rei Kawakami\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"144801845\",\"name\":\"M. Iida\"},{\"authorId\":\"143851958\",\"name\":\"T. Naemura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fd6863a59e88b45f62e82bb72dff3fb52c49be1\",\"title\":\"Differentiating Objects by Motion: Joint Detection and Tracking of Small Flying Objects\",\"url\":\"https://www.semanticscholar.org/paper/5fd6863a59e88b45f62e82bb72dff3fb52c49be1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145326532\",\"name\":\"Camille Dupont\"},{\"authorId\":\"10421064\",\"name\":\"Luis Tobias\"},{\"authorId\":\"3174694\",\"name\":\"Bertrand Luvison\"}],\"doi\":\"10.1109/CVPRW.2017.271\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bd3b15944ac28aa7021db126e4344a478bdabf4\",\"title\":\"Crowd-11: A Dataset for Fine Grained Crowd Behaviour Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9bd3b15944ac28aa7021db126e4344a478bdabf4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1609.00162\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7a3da2a011bea3ba33e9344644482f425445708\",\"title\":\"Transferring Object-Scene Convolutional Neural Networks for Event Recognition in Still Images\",\"url\":\"https://www.semanticscholar.org/paper/e7a3da2a011bea3ba33e9344644482f425445708\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"}],\"doi\":\"10.1109/ICME.2018.8486452\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"title\":\"Temporal Attentive Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"},{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"81752605\",\"name\":\"Jiao-fen Li\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"}],\"doi\":\"10.1109/TNNLS.2018.2886008\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4d4b6c67c05de1d31990076a5142719cd1ff3f6\",\"title\":\"Semisupervised Discriminant Multimanifold Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d4b6c67c05de1d31990076a5142719cd1ff3f6\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1710.05112\",\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2017.2786999\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"title\":\"Video Classification With CNNs: Using the Codec as a Spatio-Temporal Activity Sensor\",\"url\":\"https://www.semanticscholar.org/paper/ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007998\",\"name\":\"Lars Andersson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865403\",\"name\":\"Zhiyu Chen\"},{\"authorId\":\"1668787617\",\"name\":\"Yangwei Gu\"},{\"authorId\":\"50542782\",\"name\":\"Chunhua Deng\"},{\"authorId\":\"34611435\",\"name\":\"Ziqi Zhu\"}],\"doi\":\"10.1109/SPAC49953.2019.237869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"747cd60482560cc92a254eccc516cf8f230845d8\",\"title\":\"Adaptive Temporal Segmentation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/747cd60482560cc92a254eccc516cf8f230845d8\",\"venue\":\"2019 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39893135\",\"name\":\"M. Yu\"},{\"authorId\":\"1712773\",\"name\":\"Weizhe Zhang\"},{\"authorId\":\"48411615\",\"name\":\"Qingxiang Zeng\"},{\"authorId\":\"47074418\",\"name\":\"C. Wang\"},{\"authorId\":\"38158055\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/ICAIIC.2019.8669069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"title\":\"Human-Object Contour for Action Recognition with Attentional Multi-modal Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"venue\":\"2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"title\":\"SCNN: Sequential convolutional neural network for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930831020\",\"name\":\"Lorxayxang Kai\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"},{\"authorId\":\"3017565\",\"name\":\"Xiaodong Dai\"},{\"authorId\":\"81498564\",\"name\":\"M. Ma\"}],\"doi\":\"10.1007/978-3-030-57884-8_71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"title\":\"Fast Video Classification with CNNs in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":\"1906.06813\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/WACV.2018.00045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"title\":\"A Temporal Sequence Learning for Action Recognition and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145530174\",\"name\":\"Li Du\"},{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"},{\"authorId\":\"3268756\",\"name\":\"B. Zhuang\"},{\"authorId\":\"47195274\",\"name\":\"N. Boulgouris\"}],\"doi\":\"10.1109/TVT.2019.2905598\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c06c698de5ad3beadcc326adcdcf477253c0a44a\",\"title\":\"Adaptive Visual Interaction Based Multi-Target Future State Prediction For Autonomous Driving Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/c06c698de5ad3beadcc326adcdcf477253c0a44a\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"3393556\",\"name\":\"Kaipeng Zhang\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1007/s11263-018-01142-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ad8178e285901c886e3e2e66f2340115347b23f\",\"title\":\"A Comprehensive Study on Center Loss for Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ad8178e285901c886e3e2e66f2340115347b23f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3411298\",\"name\":\"Ammar Ladjailia\"},{\"authorId\":\"2674025\",\"name\":\"Imed Bouchrika\"},{\"authorId\":\"2548327\",\"name\":\"H. Merouani\"},{\"authorId\":\"3410927\",\"name\":\"Nouzha Harrati\"},{\"authorId\":\"9323182\",\"name\":\"Zohra Mahfouf\"}],\"doi\":\"10.1007/s00521-018-3951-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ced2c36d700e2f4ed5b7844789cd4977b8a3ab30\",\"title\":\"Human activity recognition via optical flow: decomposing activities into basic actions\",\"url\":\"https://www.semanticscholar.org/paper/ced2c36d700e2f4ed5b7844789cd4977b8a3ab30\",\"venue\":\"Neural Computing and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2461523\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"}],\"doi\":\"10.1016/j.jvcir.2016.10.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e094697064cf77bafd7ed318b774115b7d364e70\",\"title\":\"Saliency-based dense trajectories for action recognition using low-rank matrix decomposition\",\"url\":\"https://www.semanticscholar.org/paper/e094697064cf77bafd7ed318b774115b7d364e70\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP6100309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5aa998cf8cb7b60627a6bfe29a569c7cca0f3644\",\"title\":\"Human Action Recognition from Multiple Views Based on View-Invariant Feature Descriptor Using Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/5aa998cf8cb7b60627a6bfe29a569c7cca0f3644\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1830456822\",\"name\":\"R. Lang\"},{\"authorId\":\"89662118\",\"name\":\"Xiaosu Zhu\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3397271.3401122\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7066512f40da8bdf61a8165dd08177932b9605be\",\"title\":\"3D Self-Attention for Unsupervised Video Quantization\",\"url\":\"https://www.semanticscholar.org/paper/7066512f40da8bdf61a8165dd08177932b9605be\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5975764\",\"name\":\"R. Singh\"},{\"authorId\":\"39727023\",\"name\":\"Swati Nigam\"},{\"authorId\":\"48775558\",\"name\":\"A. Singh\"},{\"authorId\":\"49282672\",\"name\":\"M. Elhoseny\"}],\"doi\":\"10.1007/978-3-030-31873-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90d70a02855a36956790680c008fb9beb305b8cd\",\"title\":\"Intelligent Wavelet Based Techniques for Advanced Multimedia Applications\",\"url\":\"https://www.semanticscholar.org/paper/90d70a02855a36956790680c008fb9beb305b8cd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578886\",\"name\":\"Mohamed R. Ibrahim\"},{\"authorId\":\"38973565\",\"name\":\"J. Haworth\"},{\"authorId\":\"145561918\",\"name\":\"N. Christie\"},{\"authorId\":\"49829302\",\"name\":\"T. Cheng\"},{\"authorId\":\"1718391\",\"name\":\"S. Hailes\"}],\"doi\":\"10.1080/01441647.2020.1840456\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b89e059bbec06777dbba1d26464700c423b1fa\",\"title\":\"Cycling near misses: a review of the current methods, challenges and the potential of an AI-embedded system\",\"url\":\"https://www.semanticscholar.org/paper/46b89e059bbec06777dbba1d26464700c423b1fa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.08714\",\"authors\":[{\"authorId\":\"2964097\",\"name\":\"A. Ghosh\"},{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/WACV.2018.00039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2359c0f81a7eb032cff1fe45e3b80007facaa2a\",\"title\":\"Towards Structured Analysis of Broadcast Badminton Videos\",\"url\":\"https://www.semanticscholar.org/paper/a2359c0f81a7eb032cff1fe45e3b80007facaa2a\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"144061516\",\"name\":\"L. Tao\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1109/WACV.2017.20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b3aaa685bcfe24081f33005b3be051f079a5411\",\"title\":\"Deep Moving Poselets for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3aaa685bcfe24081f33005b3be051f079a5411\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17872440\",\"name\":\"Muhammad Aminur Rahaman\"},{\"authorId\":\"145493029\",\"name\":\"M. Jasim\"},{\"authorId\":\"35179514\",\"name\":\"M. H. Ali\"},{\"authorId\":\"47105247\",\"name\":\"M. Hasanuzzaman\"}],\"doi\":\"10.1007/s11704-018-7253-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6faa98ae6e01dd165eaa56bfa0efc107a82836c\",\"title\":\"Bangla language modeling algorithm for automatic recognition of hand-sign-spelled Bangla sign language\",\"url\":\"https://www.semanticscholar.org/paper/f6faa98ae6e01dd165eaa56bfa0efc107a82836c\",\"venue\":\"Frontiers of Computer Science\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23677993\",\"name\":\"Wenkai Dong\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":null,\"name\":\"Shu Zhang\"}],\"doi\":\"10.1109/ICDSP.2016.7868603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0ba06ca457672c5de0c254c52b853d304412967\",\"title\":\"Digital recognition from lip texture analysis\",\"url\":\"https://www.semanticscholar.org/paper/e0ba06ca457672c5de0c254c52b853d304412967\",\"venue\":\"2016 IEEE International Conference on Digital Signal Processing (DSP)\",\"year\":2016},{\"arxivId\":\"2003.05614\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"594163df647890f47e6ab0b0b426363f7175c9a0\",\"title\":\"Beyond the Camera: Neural Networks in World Coordinates\",\"url\":\"https://www.semanticscholar.org/paper/594163df647890f47e6ab0b0b426363f7175c9a0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s11704-016-6066-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b9aa210e42ea808cc454be162fd1da0f6f3ea5\",\"title\":\"Attribute-based supervised deep learning model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/06b9aa210e42ea808cc454be162fd1da0f6f3ea5\",\"venue\":\"Frontiers of Computer Science\",\"year\":2016},{\"arxivId\":\"1611.09078\",\"authors\":[{\"authorId\":\"2129493\",\"name\":\"Timur M. Bagautdinov\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"2721983\",\"name\":\"F. Fleuret\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/CVPR.2017.365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81ba5202424906f64b77f68afca063658139fbb2\",\"title\":\"Social Scene Understanding: End-to-End Multi-person Action Localization and Collective Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/81ba5202424906f64b77f68afca063658139fbb2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"},{\"authorId\":\"6881850\",\"name\":\"S. Oikawa\"},{\"authorId\":\"1720770\",\"name\":\"Y. Matsui\"}],\"doi\":\"10.3390/s18020627\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"e0d878cc095eaae220ad1f681b33d7d61eb5e425\",\"title\":\"Temporal and Fine-Grained Pedestrian Action Recognition on Driving Recorder Database\",\"url\":\"https://www.semanticscholar.org/paper/e0d878cc095eaae220ad1f681b33d7d61eb5e425\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dba69f6d1e5b0ab75a5b317debec898a406a92bb\",\"title\":\"REAL-TIME HUMAN ACTIVITY RECOGNITION BASED ON RADAR A THESIS SUBMITTED TO THE GRADUATE SCHOOL IN PARTIAL FULFILLMENT OF THE REQUIREMENT FOR THE DEGREE MASTER OF SCIENCE BY HANQING GUO\",\"url\":\"https://www.semanticscholar.org/paper/dba69f6d1e5b0ab75a5b317debec898a406a92bb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493606\",\"name\":\"M. Bruni\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/2964284.2967301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e5eedbdf779277b96caf4309aa631ac3e38ae6d\",\"title\":\"Do Textual Descriptions Help Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/5e5eedbdf779277b96caf4309aa631ac3e38ae6d\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27074902\",\"name\":\"Zihan Meng\"},{\"authorId\":\"46685438\",\"name\":\"J. Yuan\"},{\"authorId\":\"1700892\",\"name\":\"Z. Li\"}],\"doi\":\"10.1007/978-3-319-68345-4_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12741fcbae717bfe6a22db11c0195b8714ecacbe\",\"title\":\"Trajectory-Pooled Deep Convolutional Networks for Violence Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/12741fcbae717bfe6a22db11c0195b8714ecacbe\",\"venue\":\"ICVS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1007/s11042-016-3768-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5d5cc27ca519d1300e77e3c1a535a089f52f646\",\"title\":\"Stratified pooling based deep convolutional neural networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d5d5cc27ca519d1300e77e3c1a535a089f52f646\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2001.01083\",\"authors\":[{\"authorId\":\"51991145\",\"name\":\"Naina Dhingra\"},{\"authorId\":\"143717147\",\"name\":\"A. Kunz\"}],\"doi\":\"10.1109/3DV.2019.00061\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"title\":\"Res3ATN - Deep 3D Residual Attention Network for Hand Gesture Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578886\",\"name\":\"Mohamed R. Ibrahim\"},{\"authorId\":\"38973565\",\"name\":\"J. Haworth\"},{\"authorId\":\"144944046\",\"name\":\"T. Cheng\"}],\"doi\":\"10.1016/j.cities.2019.102481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2213e058a897cb790070b53e53c765f09b6c44d8\",\"title\":\"Understanding cities with machine eyes: A review of deep computer vision in urban analytics\",\"url\":\"https://www.semanticscholar.org/paper/2213e058a897cb790070b53e53c765f09b6c44d8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.02929\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"title\":\"Step-by-step Erasion, One-by-one Collection: A Weakly Supervised Temporal Action Detector\",\"url\":\"https://www.semanticscholar.org/paper/d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46234730\",\"name\":\"P. Khaire\"},{\"authorId\":\"39168002\",\"name\":\"P. Kumar\"},{\"authorId\":\"40413834\",\"name\":\"J. Imran\"}],\"doi\":\"10.1016/j.patrec.2018.04.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73a8b1fff98d8c76d638a1d237bbd00b75a7de1c\",\"title\":\"Combining CNN streams of RGB-D and skeletal data for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/73a8b1fff98d8c76d638a1d237bbd00b75a7de1c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1609.03056\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TMM.2017.2666540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"776ce1429272028e9c566369cf647177d3522e26\",\"title\":\"Sequential Deep Trajectory Descriptor for Action Recognition With Three-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/776ce1429272028e9c566369cf647177d3522e26\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2685285\",\"name\":\"P. Palasek\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":\"10.1145/2927006.2927012\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3150e329e01be31ba08b6d76fc46b0da88a5ddeb\",\"title\":\"Action Recognition Using Convolutional Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/3150e329e01be31ba08b6d76fc46b0da88a5ddeb\",\"venue\":\"MARMI@ICMR\",\"year\":2016},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35035828\",\"name\":\"A. Ulhaq\"},{\"authorId\":\"49665006\",\"name\":\"Xiaoxia Yin\"},{\"authorId\":\"49122246\",\"name\":\"Jing He\"},{\"authorId\":\"34853026\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2765821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2d890c3b1055c363fc6fa98ae20b1fdb1e5c80e\",\"title\":\"On Space-Time Filtering Framework for Matching Human Actions Across Different Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/a2d890c3b1055c363fc6fa98ae20b1fdb1e5c80e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"}],\"doi\":\"10.1007/s11042-017-4416-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0831794eddcbac1f601dcb9be9d45531a56dbf7e\",\"title\":\"Learning correlations for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0831794eddcbac1f601dcb9be9d45531a56dbf7e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1109/WACV.2016.7477589\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"title\":\"Combining multiple sources of knowledge in deep CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1603.06182\",\"authors\":[{\"authorId\":\"46701988\",\"name\":\"Haimin Zhang\"},{\"authorId\":\"145093159\",\"name\":\"Min Xu\"},{\"authorId\":\"145194969\",\"name\":\"Changsheng Xu\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"164b34268c42a1de531d8afb8568889a4b112898\",\"title\":\"Modelling Temporal Information Using Discrete Fourier Transform for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/164b34268c42a1de531d8afb8568889a4b112898\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49794918\",\"name\":\"Xin Chen\"},{\"authorId\":\"145369053\",\"name\":\"J. Weng\"},{\"authorId\":null,\"name\":\"Wei Lu\"},{\"authorId\":null,\"name\":\"Jiaming Xu\"},{\"authorId\":\"81346503\",\"name\":\"Jiasi Weng\"}],\"doi\":\"10.1109/TNNLS.2017.2740318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"782a05fbe30269ff8ab427109f5c4d0a577e5284\",\"title\":\"Deep Manifold Learning Combined With Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/782a05fbe30269ff8ab427109f5c4d0a577e5284\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744109\",\"name\":\"C. Jia\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"},{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2017.2781299\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a032bf569a1ff7a87aa1b642bf8009238025dcdd\",\"title\":\"Stacked Denoising Tensor Auto-Encoder for Action Recognition With Spatiotemporal Corruptions\",\"url\":\"https://www.semanticscholar.org/paper/a032bf569a1ff7a87aa1b642bf8009238025dcdd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24944572\",\"name\":\"Shahela Saif\"},{\"authorId\":\"51935429\",\"name\":\"Samabia Tehseen\"},{\"authorId\":\"1880755\",\"name\":\"Sumaira Kausar\"}],\"doi\":\"10.3390/s18113979\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe4aa088362d371daf15ccf9290291c8867e4f23\",\"title\":\"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/fe4aa088362d371daf15ccf9290291c8867e4f23\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9086667\",\"name\":\"Ghazal Shamsipour\"},{\"authorId\":\"144683683\",\"name\":\"S. Pirasteh\"}],\"doi\":\"10.20944/preprints201908.0289.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ead995758e4298b791c25a565c51aee957c2f89\",\"title\":\"Artificial Intelligence and Convolutional Neural Network for Recognition of Human Interaction by Video from Drone\",\"url\":\"https://www.semanticscholar.org/paper/0ead995758e4298b791c25a565c51aee957c2f89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380363846\",\"name\":\"Masato Ishii\"},{\"authorId\":\"145444976\",\"name\":\"Atsushi Sato\"}],\"doi\":\"10.1109/IJCNN.2019.8852250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b4ee63ff45abe8c5b29976c68d9dbe5c710e54c\",\"title\":\"Training Deep Neural Networks with Adversarially Augmented Features for Small-scale Training Datasets\",\"url\":\"https://www.semanticscholar.org/paper/0b4ee63ff45abe8c5b29976c68d9dbe5c710e54c\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"Mahmoud Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Yanyan Yang\"},{\"authorId\":\"105033173\",\"name\":\"David Ndzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"title\":\"UWS Academic Portal Deep learning of fuzzy weighted multi-resolution depth motion maps with spatial feature fusion for action recognition Al-Faris,\",\"url\":\"https://www.semanticscholar.org/paper/728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152390773\",\"name\":\"B. Jiang\"},{\"authorId\":\"46696524\",\"name\":\"Lei Zhou\"},{\"authorId\":\"152644243\",\"name\":\"L. Lin\"},{\"authorId\":\"36557488\",\"name\":\"B. Xu\"},{\"authorId\":\"4074288\",\"name\":\"Jiahong Yu\"},{\"authorId\":\"70538826\",\"name\":\"Xu-ping Zheng\"},{\"authorId\":\"119685358\",\"name\":\"K. Wu\"}],\"doi\":\"10.1109/ICIP.2019.8803838\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2283ea00819c199394589af4710e47b36789c297\",\"title\":\"A Real-Time Multi-Label Classification System for Short Videos\",\"url\":\"https://www.semanticscholar.org/paper/2283ea00819c199394589af4710e47b36789c297\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48607291\",\"name\":\"Yi Wu\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/ICCV.2017.406\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"title\":\"Egocentric Gesture Recognition Using Recurrent 3D Convolutional Neural Networks with Spatiotemporal Transformer Modules\",\"url\":\"https://www.semanticscholar.org/paper/f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"49185004\",\"name\":\"Shuhang Wang\"},{\"authorId\":\"46285365\",\"name\":\"Yifan Yang\"},{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"}],\"doi\":\"10.1007/s00138-018-0956-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"title\":\"End-to-end temporal attention extraction and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48466004\",\"name\":\"Isaac Sanou\"},{\"authorId\":\"144353664\",\"name\":\"D. Conte\"},{\"authorId\":\"2436386\",\"name\":\"H. Cardot\"}],\"doi\":\"10.5220/0007253301910199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68a87599c33c597f1792709c4f0cfd673b5e1b61\",\"title\":\"An Extensible Deep Architecture for Action Recognition Problem\",\"url\":\"https://www.semanticscholar.org/paper/68a87599c33c597f1792709c4f0cfd673b5e1b61\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1512.06498\",\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69fb98e11df56b5d7ec7d45442af274889e4be52\",\"title\":\"Harnessing the Deep Net Object Models for Enhancing Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69fb98e11df56b5d7ec7d45442af274889e4be52\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98807254\",\"name\":\"F. Han\"},{\"authorId\":\"13800522\",\"name\":\"L. Zhang\"},{\"authorId\":\"20491027\",\"name\":\"Xuanke You\"},{\"authorId\":\"3474846\",\"name\":\"G. Wang\"},{\"authorId\":\"87784995\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/MASS.2019.00022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7e1975cb77721c752b7a4be25c1a21c7e7fd3e4\",\"title\":\"SHAD: Privacy-Friendly Shared Activity Detection and Data Sharing\",\"url\":\"https://www.semanticscholar.org/paper/b7e1975cb77721c752b7a4be25c1a21c7e7fd3e4\",\"venue\":\"2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144230956\",\"name\":\"Bo Huang\"},{\"authorId\":\"28899830\",\"name\":\"Hualong Huang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-319-70090-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89b279005e08a4936365eadbaea3bba1477188fb\",\"title\":\"Convolutional Gated Recurrent Units Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89b279005e08a4936365eadbaea3bba1477188fb\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41189343\",\"name\":\"A. E. Seghrouchni\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-56150-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"title\":\"Artificial Intelligence. IJCAI 2019 International Workshops: Macao, China, August 10\\u201312, 2019, Revised Selected Best Papers\",\"url\":\"https://www.semanticscholar.org/paper/ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3180077\",\"name\":\"F. Fooladgar\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"}],\"doi\":\"10.1007/978-3-030-17798-0_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ec44c89b2f45946c103f3695a299cde0d451c63\",\"title\":\"3M2RNet: Multi-Modal Multi-Resolution Refinement Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/0ec44c89b2f45946c103f3695a299cde0d451c63\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.03466\",\"authors\":[{\"authorId\":\"14370059\",\"name\":\"M. U. Khalid\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/ICPR.2018.8546131\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"59478365451b82f5227bc4b694a2ff319025cc33\",\"title\":\"Multi-Modal Three-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/59478365451b82f5227bc4b694a2ff319025cc33\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8962288\",\"name\":\"Zichen zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"title\":\"Attention Before and After Feature Extraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.04685\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054200\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"title\":\"Learning Spatio-Temporal Representations With Temporal Squeeze Pooling\",\"url\":\"https://www.semanticscholar.org/paper/ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3492176\",\"name\":\"Z. Dong\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-981-10-3002-4_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8695862769ae88ad9e1f60fd964735fbbc259bb\",\"title\":\"Multi-stream Deep Networks for Person to Person Violence Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d8695862769ae88ad9e1f60fd964735fbbc259bb\",\"venue\":\"CCPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"35517688\",\"name\":\"Hugo Bertiche\"},{\"authorId\":\"145653560\",\"name\":\"Vicent Roig\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/ICCVW.2017.376\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"title\":\"Action Recognition from RGB-D Data: Comparison and Fusion of Spatio-Temporal Handcrafted Features and Deep Strategies\",\"url\":\"https://www.semanticscholar.org/paper/8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6323911\",\"name\":\"Jacob Westerberg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9626bcb3fc7c7df2c5a423ae8d0a046b2f69180c\",\"title\":\"A deep learning approach for action classification in American football video sequences\",\"url\":\"https://www.semanticscholar.org/paper/9626bcb3fc7c7df2c5a423ae8d0a046b2f69180c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.159\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a671cb0d366ab895249349ca457673150ecc8ee2\",\"title\":\"A Long Short-Term Memory Convolutional Neural Network for First-Person Vision Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a671cb0d366ab895249349ca457673150ecc8ee2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67331131\",\"name\":\"Jian-fang Hu\"},{\"authorId\":\"3333315\",\"name\":\"Wei-Shi Zheng\"},{\"authorId\":\"2139431\",\"name\":\"Lianyang Ma\"},{\"authorId\":\"1910988\",\"name\":\"Gang Wang\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8c655d64ffd7959106b7ea27be0f9b4e6514a15\",\"title\":\"University of Dundee Early Action Prediction by Soft Regression\",\"url\":\"https://www.semanticscholar.org/paper/d8c655d64ffd7959106b7ea27be0f9b4e6514a15\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICASSP.2016.7472030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"537abce20479d86db095efb521bcc9a052f8935a\",\"title\":\"Multiple instance discriminative dictionary learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/537abce20479d86db095efb521bcc9a052f8935a\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145142026\",\"name\":\"Q. Fu\"},{\"authorId\":\"3198145\",\"name\":\"S. Ma\"},{\"authorId\":\"47968200\",\"name\":\"Lina Liu\"},{\"authorId\":\"49722519\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/FSKD.2018.8686921\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"386e5c18efbfd9a56c5c7687f4a2b995cdaae067\",\"title\":\"Human Action Recognition Based on Sparse LSTM Auto-encoder and Improved 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/386e5c18efbfd9a56c5c7687f4a2b995cdaae067\",\"venue\":\"2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1857401\",\"name\":\"Lihong Ma\"},{\"authorId\":\"1684616\",\"name\":\"Jing Tian\"}],\"doi\":\"10.1109/SMC.2018.00431\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a0f2737e2a351eec2505ba466e717b4a96bb628\",\"title\":\"TDP: Temporal Dynamic Pooling \\u2014 A New Method for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/0a0f2737e2a351eec2505ba466e717b4a96bb628\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"145473096\",\"name\":\"Yu Zheng\"},{\"authorId\":\"145758664\",\"name\":\"J. Fan\"}],\"doi\":\"10.1109/TMM.2019.2907453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56da037ea82b991caf206c07318f793dd0513c4a\",\"title\":\"Exploiting Mid-Level Semantics for Large-Scale Complex Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/56da037ea82b991caf206c07318f793dd0513c4a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144540522\",\"name\":\"I. Serrano\"},{\"authorId\":\"1397942042\",\"name\":\"O. D\\u00e9niz-Su\\u00e1rez\"},{\"authorId\":\"24255563\",\"name\":\"G. Garc\\u00eda\"},{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1007/s00138-017-0894-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"593dc59fc8b89d5040be7fa5239755ab47b0e01d\",\"title\":\"Spatio-temporal elastic cuboid trajectories for efficient fight recognition using Hough forests\",\"url\":\"https://www.semanticscholar.org/paper/593dc59fc8b89d5040be7fa5239755ab47b0e01d\",\"venue\":\"Machine Vision and Applications\",\"year\":2017},{\"arxivId\":\"1704.02112\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.172\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faae39b8708de562a78b2b4294694a935442844a\",\"title\":\"Generalized Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/faae39b8708de562a78b2b4294694a935442844a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235260\",\"name\":\"Q. Chen\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":null,\"name\":\"Xue Li\"},{\"authorId\":\"1678435\",\"name\":\"B. Liu\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICIP.2016.7532925\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b211f8221162ce7ef212956b637b50e30ad48f4\",\"title\":\"Saliency-context two-stream convnets for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b211f8221162ce7ef212956b637b50e30ad48f4\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"title\":\"Recognition Prediction ? ? ? ? ? ? ? ? Gap fi lling\",\"url\":\"https://www.semanticscholar.org/paper/5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145674667\",\"name\":\"J. Miao\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"2704537\",\"name\":\"Shuoyang Qiu\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2015.2490551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e1e195f294c463f4832c4686775bf386b3de39\",\"title\":\"Temporal Variance Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93e1e195f294c463f4832c4686775bf386b3de39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66471378\",\"name\":\"Allah Bux\"}],\"doi\":\"10.17635/LANCASTER/THESIS/186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"title\":\"Vision-based human action recognition using machine learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"145684947\",\"name\":\"M. Yu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"}],\"doi\":\"10.1007/978-3-030-05716-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"title\":\"Action Recognition Using Visual Attention with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.06.071\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"title\":\"Action recognition using spatial-optical data organization and sequential learning framework\",\"url\":\"https://www.semanticscholar.org/paper/f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1706.08218\",\"authors\":[{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"39514690\",\"name\":\"Xi Peng\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"}],\"doi\":\"10.1109/TIP.2018.2806279\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baac20337b7fcdb54547abf2984be8ee753f4c3b\",\"title\":\"YoTube: Searching Action Proposal Via Recurrent and Static Regression Networks\",\"url\":\"https://www.semanticscholar.org/paper/baac20337b7fcdb54547abf2984be8ee753f4c3b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1810.07926\",\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"34762956\",\"name\":\"Abhinav Agarwalla\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":\"10.1145/3293353.3293423\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"821ba3eba1e36a29cc482f5378f4a0d0f6893159\",\"title\":\"Unsupervised Domain Adaptation for Learning Eye Gaze from a Million Synthetic Images: An Adversarial Approach\",\"url\":\"https://www.semanticscholar.org/paper/821ba3eba1e36a29cc482f5378f4a0d0f6893159\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1905.09282\",\"authors\":[{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"46199775\",\"name\":\"Torben Priegnitz\"},{\"authorId\":\"3452947\",\"name\":\"T. Saathoff\"},{\"authorId\":\"1994997\",\"name\":\"S. Antoni\"},{\"authorId\":\"143956932\",\"name\":\"D. Meyer\"},{\"authorId\":\"10193733\",\"name\":\"M. Hamann\"},{\"authorId\":\"144690829\",\"name\":\"K. J\\u00fcnemann\"},{\"authorId\":\"34365914\",\"name\":\"C. Otte\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1007/s11548-019-02006-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c21a2d5854b79985965f7ce4f47a7f10740f39f1\",\"title\":\"Spatio-temporal deep learning models for tip force estimation during needle insertion\",\"url\":\"https://www.semanticscholar.org/paper/c21a2d5854b79985965f7ce4f47a7f10740f39f1\",\"venue\":\"International Journal of Computer Assisted Radiology and Surgery\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145309464\",\"name\":\"Min Jiang\"},{\"authorId\":\"51010977\",\"name\":\"N. Pan\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"}],\"doi\":\"10.1016/j.jvcir.2020.102846\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"title\":\"Spatial-temporal saliency action mask attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1608.08851\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"title\":\"Efficient Two-Stream Motion and Appearance 3D CNNs for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1602.01168\",\"authors\":[{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"1691470\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"144941335\",\"name\":\"Walter Andrews\"},{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"}],\"doi\":\"10.1109/WACV.2017.30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"90b1e6081425e5ccd1d647a7a8bf59dbe45c7c1f\",\"title\":\"Learning Discriminative Features via Label Consistent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/90b1e6081425e5ccd1d647a7a8bf59dbe45c7c1f\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681148\",\"name\":\"L. Wang\"},{\"authorId\":\"3034546\",\"name\":\"Lianzheng Ge\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e378d5258615b542484fb519f2ca28b0ab1f1394\",\"title\":\"Three-stream CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e378d5258615b542484fb519f2ca28b0ab1f1394\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":\"1703.00492\",\"authors\":[{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"47006269\",\"name\":\"Y. Lu\"},{\"authorId\":\"1714082\",\"name\":\"M. Dong\"},{\"authorId\":\"35661244\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"},{\"authorId\":\"143887379\",\"name\":\"W. Zhuang\"}],\"doi\":\"10.1109/THMS.2017.2693242\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"65aba73d653369b387b7ed14f5821c6b61ef5e9f\",\"title\":\"Qualitative Action Recognition by Wireless Radio Signals in Human\\u2013Machine Systems\",\"url\":\"https://www.semanticscholar.org/paper/65aba73d653369b387b7ed14f5821c6b61ef5e9f\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":\"2011.10250\",\"authors\":[{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"31170827\",\"name\":\"J. Meng\"},{\"authorId\":\"2019493593\",\"name\":\"Jin Zhou\"},{\"authorId\":\"2004175\",\"name\":\"Dongyan Guo\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"1739956171\",\"name\":\"Jianhua Zhang\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"1739189491\",\"name\":\"Shengyong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"title\":\"LAGNet: Logic-Aware Graph Network for Human Interaction Understanding\",\"url\":\"https://www.semanticscholar.org/paper/2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.13072\",\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP.2018.8461792\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"title\":\"Cross-Modal Message Passing for Two-Stream Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.12013\",\"authors\":[{\"authorId\":\"143856160\",\"name\":\"Xiang Gao\"},{\"authorId\":\"145066190\",\"name\":\"Wei Hu\"},{\"authorId\":\"32656382\",\"name\":\"Jiaxiang Tang\"},{\"authorId\":\"1798482\",\"name\":\"P. Pan\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f8b45eca925e69d67df909f111626b54d98eed4\",\"title\":\"Generalized Graph Convolutional Networks for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f8b45eca925e69d67df909f111626b54d98eed4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1706.04122\",\"authors\":[{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76798bddd0f12ae03de26b7c7743c008d505215\",\"title\":\"Joint Max Margin and Semantic Features for Continuous Event Detection in Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/e76798bddd0f12ae03de26b7c7743c008d505215\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47599321\",\"name\":\"Qian Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"title\":\"Zero-shot visual recognition via latent embedding learning\",\"url\":\"https://www.semanticscholar.org/paper/6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1810.06827\",\"authors\":[{\"authorId\":\"3415077\",\"name\":\"Sameera Ramasinghe\"},{\"authorId\":\"32548363\",\"name\":\"Jathushan Rajasegaran\"},{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"48430646\",\"name\":\"Kanchana Ranasinghe\"},{\"authorId\":\"144952844\",\"name\":\"R. Rodrigo\"},{\"authorId\":\"144224514\",\"name\":\"A. Pasqual\"}],\"doi\":\"10.1109/TCSVT.2017.2760858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"title\":\"Combined Static and Motion Features for Deep-Networks-Based Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"32281398\",\"name\":\"V. Q. Tran\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"}],\"doi\":\"10.1109/FG.2018.00076\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2bb36c875754a2a8919f2f9b00a336c00006e453\",\"title\":\"Eigen-Evolution Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2bb36c875754a2a8919f2f9b00a336c00006e453\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"}],\"doi\":\"10.1109/ICMLA.2018.00077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a294e26e92187a447a74bafc2d6123847c4acd7b\",\"title\":\"Multi-stream Convolutional Neural Networks for Action Recognition in Video Sequences Based on Adaptive Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a294e26e92187a447a74bafc2d6123847c4acd7b\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/3078971.3078988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"title\":\"Simple, Efficient and Effective Encodings of Local Deep Features for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1612.01194\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2018.2797266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"title\":\"Online Localization and Prediction of Actions and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145078773\",\"name\":\"J. Yuan\"},{\"authorId\":\"48169695\",\"name\":\"Lidong Wang\"},{\"authorId\":\"143856986\",\"name\":\"P. Wu\"},{\"authorId\":\"145047257\",\"name\":\"C. Gao\"},{\"authorId\":\"9925597\",\"name\":\"Lingqing Sun\"}],\"doi\":\"10.1134/S1054661818040168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1766c91394fbf8b6323b6e8611c9a2baf894ee7b\",\"title\":\"Detection of Wildfires along Transmission Lines Using Deep Time and Space Features\",\"url\":\"https://www.semanticscholar.org/paper/1766c91394fbf8b6323b6e8611c9a2baf894ee7b\",\"venue\":\"Pattern Recognition and Image Analysis\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450479\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1738364\",\"name\":\"Bing Deng\"},{\"authorId\":\"144600664\",\"name\":\"Chen Shen\"},{\"authorId\":\"2354748\",\"name\":\"Yau-Wen Liu\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":\"10.1145/3123266.3123451\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fef6f1e04fa64f2f26ac9f01cd143dd19e549790\",\"title\":\"Spatio-Temporal AutoEncoder for Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/fef6f1e04fa64f2f26ac9f01cd143dd19e549790\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.1109/ICCV.2017.600\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"703c9c8f20860a1b1be63e6df1622b2021b003ca\",\"title\":\"Flip-Invariant Motion Representation\",\"url\":\"https://www.semanticscholar.org/paper/703c9c8f20860a1b1be63e6df1622b2021b003ca\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1607.04867\",\"authors\":[{\"authorId\":\"39095434\",\"name\":\"Aarti Sathyanarayana\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"81780580\",\"name\":\"L. Fern\\u00e1ndez-Luque\"},{\"authorId\":\"144235071\",\"name\":\"J. Srivastava\"},{\"authorId\":\"145188857\",\"name\":\"A. Elmagarmid\"},{\"authorId\":\"3076771\",\"name\":\"T. Arora\"},{\"authorId\":\"38199958\",\"name\":\"S. Taheri\"}],\"doi\":\"10.1109/ICDMW.2016.0077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d964aa6f07800ff64fb7d0f6dd99ef2b335dfc69\",\"title\":\"Robust Automated Human Activity Recognition and Its Application to Sleep Research\",\"url\":\"https://www.semanticscholar.org/paper/d964aa6f07800ff64fb7d0f6dd99ef2b335dfc69\",\"venue\":\"2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2396114\",\"name\":\"T. Moreira\"},{\"authorId\":\"50534501\",\"name\":\"D. Menotti\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1016/j.jvcir.2020.102771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49278c84a9c0204319a62073d1d42556dee3ff4e\",\"title\":\"Video action recognition based on visual rhythm representation\",\"url\":\"https://www.semanticscholar.org/paper/49278c84a9c0204319a62073d1d42556dee3ff4e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145141847\",\"name\":\"M. Fan\"},{\"authorId\":\"145264515\",\"name\":\"Qi Han\"},{\"authorId\":\"47956995\",\"name\":\"X. Zhang\"},{\"authorId\":\"47910149\",\"name\":\"Yaling Liu\"},{\"authorId\":\"10993830\",\"name\":\"Huan Chen\"},{\"authorId\":\"48484029\",\"name\":\"Y. Hu\"}],\"doi\":\"10.1109/DDCLS.2018.8515970\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f3b0452e11e44c9adb16e228defc3966e04334e\",\"title\":\"Human Action Recognition Based on Dense Sampling of Motion Boundary and Histogram of Motion Gradient\",\"url\":\"https://www.semanticscholar.org/paper/7f3b0452e11e44c9adb16e228defc3966e04334e\",\"venue\":\"2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40415139\",\"name\":\"Neelay Pandit\"},{\"authorId\":\"40005980\",\"name\":\"S. Abdelhak\"}],\"doi\":\"10.1145/3126686.3126775\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c648da4d3b0fb7f175111ddad58ba912b37d9c6\",\"title\":\"Evolution of Trajectories: A Novel Representation for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c648da4d3b0fb7f175111ddad58ba912b37d9c6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1605.05054\",\"authors\":[{\"authorId\":\"3254747\",\"name\":\"Minseok Park\"},{\"authorId\":\"3407591\",\"name\":\"H. Li\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"500993a8852f766d4bac7b5039b9072b587e4d09\",\"title\":\"HARRISON: A Benchmark on HAshtag Recommendation for Real-world Images in Social Networks\",\"url\":\"https://www.semanticscholar.org/paper/500993a8852f766d4bac7b5039b9072b587e4d09\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1007/s10851-017-0766-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c61eaf172820fcafaabf39005bd4536f0c45f995\",\"title\":\"Spatio-Temporal Scale Selection in Video Data\",\"url\":\"https://www.semanticscholar.org/paper/c61eaf172820fcafaabf39005bd4536f0c45f995\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23124669\",\"name\":\"Jiewan Zheng\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"7883602\",\"name\":\"Xiangbo Su\"}],\"doi\":\"10.1109/TNNLS.2018.2844464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc95fb644c12ee9caa989390af29c969b4c1d646\",\"title\":\"Deep Ensemble Machine for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc95fb644c12ee9caa989390af29c969b4c1d646\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404403\",\"name\":\"Longteng Kong\"},{\"authorId\":\"145022824\",\"name\":\"D. Huang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2893318\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef022983983d8b948ab27a686da4e76cf92d18b1\",\"title\":\"A Joint Framework for Athlete Tracking and Action Recognition in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ef022983983d8b948ab27a686da4e76cf92d18b1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1611.06624\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":\"10.1109/ICCV.2017.308\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"title\":\"Temporal Generative Adversarial Nets with Singular Value Clipping\",\"url\":\"https://www.semanticscholar.org/paper/062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"152539938\",\"name\":\"J. Xie\"},{\"authorId\":\"144145644\",\"name\":\"Yi Fang\"}],\"doi\":\"10.1016/j.imavis.2016.06.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"465bd4e269b455d2607b8bf08538cf098688d82d\",\"title\":\"From handcrafted to learned representations for human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/465bd4e269b455d2607b8bf08538cf098688d82d\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1007/s11263-016-0918-1\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"6c9e1a9c1136a557a2f4a36eba43442c0a731010\",\"title\":\"Complex\\u00a0Activity\\u00a0Recognition Via Attribute\\u00a0Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/6c9e1a9c1136a557a2f4a36eba43442c0a731010\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1601.06615\",\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.3389/frobt.2015.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"412b3ef02c85087e5f1721176114672c722b17a4\",\"title\":\"A Taxonomy of Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/412b3ef02c85087e5f1721176114672c722b17a4\",\"venue\":\"Front. Robot. AI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3206025.3206041\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"title\":\"Recognizing Actions in Wearable-Camera Videos by Training Classifiers on Fixed-Camera Videos\",\"url\":\"https://www.semanticscholar.org/paper/b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"1763134\",\"name\":\"Yeonho Kim\"},{\"authorId\":\"144499950\",\"name\":\"J. S. Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1016/j.patrec.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c81c88f74d466a65520ea9751970ff781352ec0a\",\"title\":\"First Person Action Recognition via Two-stream ConvNet with Long-term Fusion Pooling\",\"url\":\"https://www.semanticscholar.org/paper/c81c88f74d466a65520ea9751970ff781352ec0a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31689549\",\"name\":\"H. F. Nweke\"},{\"authorId\":\"1717493\",\"name\":\"Teh Ying Wah\"},{\"authorId\":\"1403206186\",\"name\":\"M. A. Al-garadi\"},{\"authorId\":\"40994774\",\"name\":\"U. R. Alo\"}],\"doi\":\"10.1016/j.eswa.2018.03.056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0cf8271b76661b58936f443bfe7387d18ddf9a5\",\"title\":\"Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges\",\"url\":\"https://www.semanticscholar.org/paper/d0cf8271b76661b58936f443bfe7387d18ddf9a5\",\"venue\":\"Expert Syst. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shivam Gadhadara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e0f1477dc9d2ba75583a9fd7e8bc26c31d6de74\",\"title\":\"ANALYSIS AND RECOGNITION OF HUMAN BY CONCEPTUAL FEATURES\",\"url\":\"https://www.semanticscholar.org/paper/5e0f1477dc9d2ba75583a9fd7e8bc26c31d6de74\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8060096\",\"name\":\"Sheng-hung Hu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ICPR.2016.7899735\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f6ab4543cc38f23d0339e3037a952df7bcf696b\",\"title\":\"Video2vec: Learning semantic spatio-temporal embeddings for video representation\",\"url\":\"https://www.semanticscholar.org/paper/5f6ab4543cc38f23d0339e3037a952df7bcf696b\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713611\",\"name\":\"J. Filipe\"},{\"authorId\":\"17324395\",\"name\":\"A. Ghosh\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"71888255\",\"name\":\"Zhanjun Hao\"},{\"authorId\":\"70226424\",\"name\":\"X. Dang\"},{\"authorId\":\"49178133\",\"name\":\"Honghong Chen\"},{\"authorId\":\"24521940\",\"name\":\"Fenfang Li\"}],\"doi\":\"10.1007/978-981-33-4214-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c326ae12396c2a5c4efc123db4d8ddc1e375c32b\",\"title\":\"Wireless Sensor Networks: 14th China Conference, CWSN 2020, Dunhuang, China, September 18\\u201321, 2020, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/c326ae12396c2a5c4efc123db4d8ddc1e375c32b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035597\",\"name\":\"Novanto Yudistira\"},{\"authorId\":\"145375983\",\"name\":\"Takio Kurita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e297f10a02580dfc74595ff8d7db34020002ec4\",\"title\":\"Correlation Net : spatio temporal multimodal deep learning\",\"url\":\"https://www.semanticscholar.org/paper/6e297f10a02580dfc74595ff8d7db34020002ec4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.05045\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"839a2155995acc0a053a326e283be12068b35cb8\",\"title\":\"Handcrafted Local Features are Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/839a2155995acc0a053a326e283be12068b35cb8\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51295994\",\"name\":\"Ee Heng Chen\"},{\"authorId\":\"1791260\",\"name\":\"Darius Burschka\"}],\"doi\":\"10.1109/ICRA.2018.8462973\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"33cd5da38a699142c1868f6e6e4080818897ff8b\",\"title\":\"Object-Centric Approach to Prediction and Labeling of Manipulation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/33cd5da38a699142c1868f6e6e4080818897ff8b\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00b8cf945c995ea9ba6307f5dca308d22f4deab7\",\"title\":\"Jurassic World Hotel Rwanda One Day Toy Story Action Sci-Fi Adventure monster suspense escape murder violence death Drama History War Drama Romance love Animation Comedy Fantasy escape\",\"url\":\"https://www.semanticscholar.org/paper/00b8cf945c995ea9ba6307f5dca308d22f4deab7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-3-030-01240-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2003d6e1de789b7fe60819257d8dfd54d267517\",\"title\":\"Dividing and Aggregating Network for Multi-view Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2003d6e1de789b7fe60819257d8dfd54d267517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1872087\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"2930187\",\"name\":\"Xiangyin Zhang\"},{\"authorId\":\"7824818\",\"name\":\"X. Li\"}],\"doi\":\"10.1117/1.JEI.27.5.053049\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c19ba3d8d9eb5e4c2304df5cb365d171fdb95dc6\",\"title\":\"Saliency-based foreground trajectory extraction using multiscale hybrid masks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c19ba3d8d9eb5e4c2304df5cb365d171fdb95dc6\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39566337\",\"name\":\"D. Hossain\"},{\"authorId\":\"1718054\",\"name\":\"G. Capi\"}],\"doi\":\"10.1080/01691864.2018.1529620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c59e01192d43b50bdaf7aeeb6e9456c6baee0d2\",\"title\":\"Multiobjective evolution of deep learning parameters for robot manipulator object recognition and grasping\",\"url\":\"https://www.semanticscholar.org/paper/8c59e01192d43b50bdaf7aeeb6e9456c6baee0d2\",\"venue\":\"Adv. Robotics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30957938\",\"name\":\"Martin Torstensson\"},{\"authorId\":null,\"name\":\"Thanh Hai Bui\"},{\"authorId\":\"11177520\",\"name\":\"D. Lindstr\\u00f6m\"},{\"authorId\":\"1720470\",\"name\":\"Cristofer Englund\"},{\"authorId\":\"21630800\",\"name\":\"B. Dur\\u00e1n\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e60abac6874a83b405df66c6eb2406b8a454104\",\"title\":\"In-vehicle Driver and Passenger Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e60abac6874a83b405df66c6eb2406b8a454104\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398782128\",\"name\":\"C. Anjali\"},{\"authorId\":\"51370460\",\"name\":\"M. V. Beena\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"18ef8569421af09345ccfc34eefc8a7a3dd7cd9b\",\"title\":\"Human Activity Recognition using Convolutional 3 D Network\",\"url\":\"https://www.semanticscholar.org/paper/18ef8569421af09345ccfc34eefc8a7a3dd7cd9b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.01888\",\"authors\":[{\"authorId\":\"1966561\",\"name\":\"S. Ghorbani\"},{\"authorId\":\"1519541371\",\"name\":\"Kimia Mahdaviani\"},{\"authorId\":\"40481439\",\"name\":\"A. Thaler\"},{\"authorId\":\"36121677\",\"name\":\"Konrad P. K\\u00f6rding\"},{\"authorId\":\"32104861\",\"name\":\"D. J. Cook\"},{\"authorId\":\"2015591\",\"name\":\"G. Blohm\"},{\"authorId\":\"2932365\",\"name\":\"N. Troje\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"title\":\"MoVi: A Large Multipurpose Motion and Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/CVPR.2017.604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890560\",\"name\":\"Ryota Yoshihashi\"},{\"authorId\":\"38621343\",\"name\":\"T. Trinh\"},{\"authorId\":\"48727803\",\"name\":\"Rei Kawakami\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"144801845\",\"name\":\"M. Iida\"},{\"authorId\":\"143851958\",\"name\":\"T. Naemura\"}],\"doi\":\"10.1186/s41074-018-0048-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"087a6baef9d81178f2f8f001aa9be4c0d4ed7733\",\"title\":\"Pedestrian detection with motion features via two-stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/087a6baef9d81178f2f8f001aa9be4c0d4ed7733\",\"venue\":\"IPSJ Transactions on Computer Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1402256256\",\"name\":\"A. Abdel-Hakim\"},{\"authorId\":\"1401805077\",\"name\":\"Moumen T. El-Melegy\"},{\"authorId\":\"3391325\",\"name\":\"Shreen K. Refaay\"}],\"doi\":\"10.1145/3341016.3341029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e5f70113f4a2975560ecaa247fd0b1be8329530\",\"title\":\"Recognizing Faces in Shades of Gray\",\"url\":\"https://www.semanticscholar.org/paper/0e5f70113f4a2975560ecaa247fd0b1be8329530\",\"venue\":\"ICCCV 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"145082678\",\"name\":\"G. Chen\"}],\"doi\":\"10.1007/978-3-030-05710-7_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"title\":\"Hierarchical Temporal Pooling for Efficient Online Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"144910981\",\"name\":\"Michel Antunes\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.1109/ICASSP.2018.8462633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82c7254230433cfabfba382af520db38201531ce\",\"title\":\"A Revisit of Action Detection Using Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/82c7254230433cfabfba382af520db38201531ce\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2018.2837386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7deb1abdfdbb9fee0912b409bdb32335948b56f\",\"title\":\"Beyond Joints: Learning Representations From Primitive Geometries for Skeleton-Based Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/c7deb1abdfdbb9fee0912b409bdb32335948b56f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66589187\",\"name\":\"Hanjian Song\"},{\"authorId\":\"50167971\",\"name\":\"L. Tian\"},{\"authorId\":\"49673312\",\"name\":\"Chen Li\"}],\"doi\":\"10.1109/ISM.2018.00036\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a69959449e8ba64b6f75b6a794075018ad01f57\",\"title\":\"3D Convolutional Network Based Foreground Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/2a69959449e8ba64b6f75b6a794075018ad01f57\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40901768\",\"name\":\"Sony Allappa\"},{\"authorId\":\"3055959\",\"name\":\"Veena Thenkanidiyoor\"},{\"authorId\":\"35362808\",\"name\":\"Dileep Aroor Dinesh\"}],\"doi\":\"10.1007/978-3-030-05499-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83e6489baba70cd5eaa88500158d392d6e67936e\",\"title\":\"Video Activity Recognition Using Sequence Kernel Based Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/83e6489baba70cd5eaa88500158d392d6e67936e\",\"venue\":\"ICPRAM\",\"year\":2018},{\"arxivId\":\"1708.07632\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICCVW.2017.373\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"title\":\"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP7010110\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a87e37d43d4c47bef8992ace408de0f872739efc\",\"title\":\"A Comprehensive Review on Handcrafted and Learning-Based Action Representation Approaches for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a87e37d43d4c47bef8992ace408de0f872739efc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1874862797\",\"name\":\"Boge Wen\"},{\"authorId\":\"122665402\",\"name\":\"Siyuan Chen\"},{\"authorId\":\"3090858\",\"name\":\"Chenhui Shao\"}],\"doi\":\"10.1016/j.compind.2020.103255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"title\":\"Temporal action proposal for online driver action monitoring using Dilated Convolutional Temporal Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"venue\":\"Comput. Ind.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46381810\",\"name\":\"H. Li\"},{\"authorId\":\"102461379\",\"name\":\"J. Wang\"},{\"authorId\":\"3033573\",\"name\":\"Jian-Jun Han\"},{\"authorId\":\"49049946\",\"name\":\"Jinmin Zhang\"},{\"authorId\":\"2808646\",\"name\":\"Yushan Yang\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"}],\"doi\":\"10.1177/0020294020902788\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85810af8b757717d81ab63772d2958445e0818f8\",\"title\":\"A novel multi-stream method for violent interaction detection using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/85810af8b757717d81ab63772d2958445e0818f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145937063\",\"name\":\"A. Zare\"},{\"authorId\":\"2060085\",\"name\":\"H. Moghaddam\"},{\"authorId\":\"144499901\",\"name\":\"A. Sharifi\"}],\"doi\":\"10.1007/s10044-019-00788-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8147e421fee31608fdaf9e189d5ac2ec1bf78e16\",\"title\":\"Video spatiotemporal mapping for human action recognition by convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/8147e421fee31608fdaf9e189d5ac2ec1bf78e16\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152441499\",\"name\":\"Jiang Bian\"},{\"authorId\":\"40380492\",\"name\":\"Dayong Tian\"},{\"authorId\":\"2289713\",\"name\":\"Yuanyan Tang\"},{\"authorId\":\"143719919\",\"name\":\"D. Tao\"}],\"doi\":\"10.1145/3330138\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bd6470e300018390cb7ba21c826760aa994bfd3\",\"title\":\"Trajectory Data Classification\",\"url\":\"https://www.semanticscholar.org/paper/2bd6470e300018390cb7ba21c826760aa994bfd3\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72462569\",\"name\":\"C. Wang\"},{\"authorId\":\"38792093\",\"name\":\"Temitayo A. Olugbade\"},{\"authorId\":\"152859908\",\"name\":\"Akhil Mathur\"},{\"authorId\":\"144450667\",\"name\":\"A. Williams\"},{\"authorId\":\"144948031\",\"name\":\"N. Lane\"},{\"authorId\":\"1398541310\",\"name\":\"N. Bianchi-Berthouze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"502c55c271310ac53ef8f54e7844ee269be3b2c2\",\"title\":\"Automatic Detection of Protective Behavior in Chronic Pain Physical Rehabilitation: A Recurrent Neural Network Approach\",\"url\":\"https://www.semanticscholar.org/paper/502c55c271310ac53ef8f54e7844ee269be3b2c2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.3233/IA-190021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"title\":\"Top-down attention recurrent VLAD encoding for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"venue\":\"Intelligenza Artificiale\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":\"10.1007/s11859-017-1219-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c4ab901ea11654d09648d79fb2b1d34a529cf8\",\"title\":\"Multiple feature fusion in convolutional neural networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/84c4ab901ea11654d09648d79fb2b1d34a529cf8\",\"venue\":\"Wuhan University Journal of Natural Sciences\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39095434\",\"name\":\"Aarti Sathyanarayana\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1400859800\",\"name\":\"L. Fern\\u00e1ndez-Luque\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"144235071\",\"name\":\"J. Srivastava\"},{\"authorId\":\"40394220\",\"name\":\"A. Elmagarmid\"},{\"authorId\":\"3076771\",\"name\":\"T. Arora\"},{\"authorId\":\"38199958\",\"name\":\"S. Taheri\"}],\"doi\":\"10.2196/MHEALTH.6562\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c82884f9d6d39c8a89ac46b8f688669fb2931144\",\"title\":\"Sleep Quality Prediction From Wearable Data Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/c82884f9d6d39c8a89ac46b8f688669fb2931144\",\"venue\":\"JMIR mHealth and uHealth\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f66086e4cbb22c5736c836614830489f9594b91\",\"title\":\"Action Recognition with Joints-Pooled 3D Deep Convolutional Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2f66086e4cbb22c5736c836614830489f9594b91\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1703.08089\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1016/j.cviu.2016.10.014\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"title\":\"A bag-of-words equivalent recurrent neural network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.10370\",\"authors\":[{\"authorId\":\"2581371\",\"name\":\"B. Seddik\"},{\"authorId\":\"2536574\",\"name\":\"N. B. Amara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"248d264cc75fc589a2c3dc0f1a5153a57a0b4fe1\",\"title\":\"Visual Methods for Sign Language Recognition: A Modality-Based Review\",\"url\":\"https://www.semanticscholar.org/paper/248d264cc75fc589a2c3dc0f1a5153a57a0b4fe1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1117/12.2229531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55cd7f8b46eab20bd7e8f905e3c83397b11e6759\",\"title\":\"Video-based convolutional neural networks for activity recognition from robot-centric videos\",\"url\":\"https://www.semanticscholar.org/paper/55cd7f8b46eab20bd7e8f905e3c83397b11e6759\",\"venue\":\"SPIE Defense + Security\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51441246\",\"name\":\"G. Morales\"},{\"authorId\":\"1417319752\",\"name\":\"Itamar Salazar-Reque\"},{\"authorId\":\"46289213\",\"name\":\"J. Telles\"},{\"authorId\":\"144833189\",\"name\":\"D. D\\u00edaz\"}],\"doi\":\"10.1007/978-3-030-19823-7_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74892e3cacf82e7c94b1f4561303018fa8ecb4c8\",\"title\":\"Detecting Violent Robberies in CCTV Videos Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/74892e3cacf82e7c94b1f4561303018fa8ecb4c8\",\"venue\":\"AIAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24735756\",\"name\":\"Zhengkui Weng\"},{\"authorId\":\"40641593\",\"name\":\"Y. Guan\"}],\"doi\":\"10.1117/1.JEI.28.2.021004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"title\":\"Trajectory-aware three-stream CNN for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1812.06203\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2019.00022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"title\":\"TAN: Temporal Aggregation Network for Dense Multi-Label Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.04666\",\"authors\":[{\"authorId\":\"1890560\",\"name\":\"Ryota Yoshihashi\"},{\"authorId\":\"38621343\",\"name\":\"T. Trinh\"},{\"authorId\":\"48727803\",\"name\":\"Rei Kawakami\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"144801845\",\"name\":\"M. Iida\"},{\"authorId\":\"143851958\",\"name\":\"T. Naemura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28a16718b633dbc7f612de637fdb0d49c0e09219\",\"title\":\"Learning Multi-frame Visual Representation for Joint Detection and Tracking of Small Objects\",\"url\":\"https://www.semanticscholar.org/paper/28a16718b633dbc7f612de637fdb0d49c0e09219\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2016.290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68bd9fa880a368b82782f617deefbde9552cac28\",\"title\":\"Predicting the Where and What of Actors and Actions through Online Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/68bd9fa880a368b82782f617deefbde9552cac28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"title\":\"Going Deeper into First-Person Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.09053\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/CVPR.2017.147\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"533d14e539ae5cdca0ece392487a2b19106d468a\",\"title\":\"Bidirectional Multirate Reconstruction for Temporal Modeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/533d14e539ae5cdca0ece392487a2b19106d468a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144444772\",\"name\":\"S. J. Berlin\"},{\"authorId\":\"34799829\",\"name\":\"M. John\"}],\"doi\":\"10.1007/s11042-020-08704-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a093bb0526c3e21469be8be537bbbf01198d0616\",\"title\":\"Particle swarm optimization with deep learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a093bb0526c3e21469be8be537bbbf01198d0616\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1605.05440\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICIP.2016.7532983\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41aa209e9d294d370357434f310d49b2b0baebeb\",\"title\":\"Beyond caption to narrative: Video captioning with multiple sentences\",\"url\":\"https://www.semanticscholar.org/paper/41aa209e9d294d370357434f310d49b2b0baebeb\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"title\":\"Efficient and Effective Solutions for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"title\":\"Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters\",\"url\":\"https://www.semanticscholar.org/paper/aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"venue\":\"AAAI 2017\",\"year\":2016},{\"arxivId\":\"1705.08583\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49733ccd65c087f3f0cf3d2235bed1b76f66e693\",\"title\":\"Sequence Summarization Using Order-constrained Kernelized Feature Subspaces\",\"url\":\"https://www.semanticscholar.org/paper/49733ccd65c087f3f0cf3d2235bed1b76f66e693\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"49682370\",\"name\":\"Alexander Keidel\"},{\"authorId\":\"73650373\",\"name\":\"Bappaditya Debnath\"}],\"doi\":\"10.1007/978-3-030-12939-2_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64abe70f02579fafc8b23b99700d625f1ca440a4\",\"title\":\"Context-driven Multi-stream LSTM (M-LSTM) for Recognizing Fine-Grained Activity of Drivers\",\"url\":\"https://www.semanticscholar.org/paper/64abe70f02579fafc8b23b99700d625f1ca440a4\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35990033\",\"name\":\"Fabio Luiz Marinho De Oliveira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"85211be21a397f7b44454725deb26fa04e916737\",\"title\":\"Motion Description Based on Histograms of Sparse Trajectories Juiz de Fora 2016\",\"url\":\"https://www.semanticscholar.org/paper/85211be21a397f7b44454725deb26fa04e916737\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2018.2882805\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"02c293bc06c580305c8b62a8ed90f37a75608493\",\"title\":\"Adversarial Action Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/02c293bc06c580305c8b62a8ed90f37a75608493\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150356708\",\"name\":\"Zhongyin Huang\"},{\"authorId\":\"73227160\",\"name\":\"Wei Chen\"}],\"doi\":\"10.2991/icaita-18.2018.3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1321f366a1c58124039664a9a40c8d188b78d80a\",\"title\":\"Research of Action Recognition Methods Based on RGB+D Videos\",\"url\":\"https://www.semanticscholar.org/paper/1321f366a1c58124039664a9a40c8d188b78d80a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.05060\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f24594e87dd1b2139197c3b22e88518a6b05892c\",\"title\":\"Recognizing Video Events with Varying Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/f24594e87dd1b2139197c3b22e88518a6b05892c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67135648\",\"name\":\"Meixia Fu\"},{\"authorId\":\"145732482\",\"name\":\"N. Chen\"},{\"authorId\":\"14042415\",\"name\":\"Zhongjie Huang\"},{\"authorId\":\"51940516\",\"name\":\"Kaili Ni\"},{\"authorId\":\"47908920\",\"name\":\"Yuhao Liu\"},{\"authorId\":\"1770819\",\"name\":\"Songlin Sun\"},{\"authorId\":\"35181056\",\"name\":\"X. Ma\"}],\"doi\":\"10.1007/978-981-13-7123-3_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"608efb376175bb8b1c26076fe2fe3fbf7d750720\",\"title\":\"Human Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/608efb376175bb8b1c26076fe2fe3fbf7d750720\",\"venue\":\"ICSINC 2018 Fall\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9086667\",\"name\":\"G. Shamsipour\"},{\"authorId\":\"1771914\",\"name\":\"J. Shanbehzadeh\"},{\"authorId\":\"3267221\",\"name\":\"H. Sarrafzadeh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b94944b27a6e29a7f9dd7296069a9c56f19ac751\",\"title\":\"Human action recognition by conceptual features\",\"url\":\"https://www.semanticscholar.org/paper/b94944b27a6e29a7f9dd7296069a9c56f19ac751\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8548039\",\"name\":\"L. Yu\"},{\"authorId\":\"144245857\",\"name\":\"W. Chan\"},{\"authorId\":\"46317377\",\"name\":\"Y. Zhao\"},{\"authorId\":\"145690550\",\"name\":\"Kwok-Leung Tsui\"}],\"doi\":\"10.1109/ACCESS.2018.2848936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d16bc4777b373a2e1d14537da14c1847e41ea4e9\",\"title\":\"Personalized Health Monitoring System of Elderly Wellness at the Community Level in Hong Kong\",\"url\":\"https://www.semanticscholar.org/paper/d16bc4777b373a2e1d14537da14c1847e41ea4e9\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92679c8cff92442f39de3405c21c8028162fe56a\",\"title\":\"Temporal 3D ConvNets Using Temporal Transition Layer\",\"url\":\"https://www.semanticscholar.org/paper/92679c8cff92442f39de3405c21c8028162fe56a\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144925873\",\"name\":\"N. Kumaran\"},{\"authorId\":\"3846423\",\"name\":\"U. S. Reddy\"},{\"authorId\":\"46574794\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"title\":\"Multiple Action Recognition for Human Object with Motion Video Sequence using the Properties of HSV Color Space Applying with Region of Interest\",\"url\":\"https://www.semanticscholar.org/paper/80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323047\",\"name\":\"Fengqian Pang\"},{\"authorId\":\"49404404\",\"name\":\"Heng Li\"},{\"authorId\":\"1855894\",\"name\":\"Yonggang Shi\"},{\"authorId\":\"7768957\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1089/cmb.2018.0023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da522ad0a79b71f548a789e124f45d09b843dbfd\",\"title\":\"Computational Analysis of Cell Dynamics in Videos with Hierarchical-Pooled Deep-Convolutional Features\",\"url\":\"https://www.semanticscholar.org/paper/da522ad0a79b71f548a789e124f45d09b843dbfd\",\"venue\":\"J. Comput. Biol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46203415\",\"name\":\"N. Rahmad\"},{\"authorId\":\"46172815\",\"name\":\"N. A. J. Sufri\"},{\"authorId\":\"1409463470\",\"name\":\"M. As'ari\"},{\"authorId\":\"1411842815\",\"name\":\"Aizreena Azaman\"}],\"doi\":\"10.11591/IJEEI.V7I4.968\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fab4f2e98a08f588f931a4e5c93885ba612c305d\",\"title\":\"Recognition of Badminton Action Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/fab4f2e98a08f588f931a4e5c93885ba612c305d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.05267\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"49447925\",\"name\":\"M. Flynn\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1109/CVPR.2017.113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"title\":\"Temporal Convolutional Networks for Action Segmentation and Detection\",\"url\":\"https://www.semanticscholar.org/paper/210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheyuan Liu\"},{\"authorId\":\"9642011\",\"name\":\"Xiaoteng Zhang\"},{\"authorId\":\"33055674\",\"name\":\"L. Song\"},{\"authorId\":\"2261516\",\"name\":\"Zhengyan Ding\"},{\"authorId\":\"1730199\",\"name\":\"Huixian Duan\"}],\"doi\":\"10.1007/s10586-017-1309-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"title\":\"More efficient and effective tricks for deep action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904697\",\"name\":\"Zhenbing Liu\"},{\"authorId\":\"1796258521\",\"name\":\"Zeya Li\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"51251812\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"}],\"doi\":\"10.1007/s00521-020-05144-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"575448ab04aef0856a73d8eba3a75a5321e0506d\",\"title\":\"Spatiotemporal saliency-based multi-stream networks with attention-aware LSTM for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/575448ab04aef0856a73d8eba3a75a5321e0506d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49402429\",\"name\":\"J. Yu\"},{\"authorId\":\"46533851\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"40322073\",\"name\":\"L. Wan\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TCSVT.2019.2919064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10129da014606c70b6fab077319491c772b01c04\",\"title\":\"Spatio-Temporal Deep Q-Networks for Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/10129da014606c70b6fab077319491c772b01c04\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"8025372\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/DICTA.2016.7797041\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"91f1c7c6f272a1d194ac6e845e348b90b965680d\",\"title\":\"Fast Binary-Based Video Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/91f1c7c6f272a1d194ac6e845e348b90b965680d\",\"venue\":\"2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72547325\",\"name\":\"Bassel S. Chawky\"},{\"authorId\":\"2805974\",\"name\":\"A. S. Elons\"},{\"authorId\":\"114287783\",\"name\":\"A. Ali\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1007/978-3-319-63754-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88d70d8cf4557e032bc359d2c2a15b06686612ea\",\"title\":\"A Study of Action Recognition Problems: Dataset and Architectures Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/88d70d8cf4557e032bc359d2c2a15b06686612ea\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0008958003510358\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"e9213f65145533551043f36b542ee549b08089d3\",\"title\":\"Multi-stream Architecture with Symmetric Extended Visual Rhythms for Deep Learning Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e9213f65145533551043f36b542ee549b08089d3\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10442800\",\"name\":\"Chenhao Lin\"},{\"authorId\":\"144633965\",\"name\":\"A. Kumar\"}],\"doi\":\"10.1109/TIFS.2018.2854765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"234082729adfd043712dab007a05f01a170187d2\",\"title\":\"A CNN-Based Framework for Comparison of Contactless to Contact-Based Fingerprints\",\"url\":\"https://www.semanticscholar.org/paper/234082729adfd043712dab007a05f01a170187d2\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2019},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144195544\",\"name\":\"S. Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.1016/J.COMCOM.2019.07.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d10ce66a13a6e2d270329f47aae1761cf4389\",\"title\":\"Crowd Video Event Classification using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/476d10ce66a13a6e2d270329f47aae1761cf4389\",\"venue\":\"Comput. Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29326440\",\"name\":\"A. Roy\"}],\"doi\":\"10.15167/ROY-ABHINABA_PHD2019-02-21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0c43e113d7ae99e763ea09dac97ba115d9e54bb\",\"title\":\"Data Driven Approaches for Image & Video Understanding: from Traditional to Zero-shot Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/c0c43e113d7ae99e763ea09dac97ba115d9e54bb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9229148\",\"name\":\"Y. Han\"},{\"authorId\":\"48754075\",\"name\":\"P. Zhang\"},{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"1730584\",\"name\":\"W. Huang\"},{\"authorId\":\"1801395\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.patrec.2017.08.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"180f0de5d46522cccd34aae83716999c4a69f193\",\"title\":\"Going deeper with two-stream ConvNets for action recognition in video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/180f0de5d46522cccd34aae83716999c4a69f193\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"40546560\",\"name\":\"Qingquan Sun\"}],\"doi\":\"10.1016/j.neucom.2016.09.106\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"title\":\"Action recognition by saliency-based dense sampling\",\"url\":\"https://www.semanticscholar.org/paper/6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.sigpro.2017.10.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778e6aee04548ec06a52fd3f6aff32074132abdd\",\"title\":\"Distinctive action sketch for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/778e6aee04548ec06a52fd3f6aff32074132abdd\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":\"1804.02555\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"6881850\",\"name\":\"S. Oikawa\"},{\"authorId\":\"1720770\",\"name\":\"Y. Matsui\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICRA.2018.8460812\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b13f8c8733503ddfee6a140e62b7e280d70f48d\",\"title\":\"Drive Video Analysis for the Detection of Traffic Near-Miss Incidents\",\"url\":\"https://www.semanticscholar.org/paper/8b13f8c8733503ddfee6a140e62b7e280d70f48d\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":\"1806.07753\",\"authors\":[{\"authorId\":\"51027897\",\"name\":\"F. M. Castro\"},{\"authorId\":\"1398347979\",\"name\":\"M. Mar\\u00edn-Jim\\u00e9nez\"},{\"authorId\":\"1712683\",\"name\":\"Nicol\\u00e1s Guil Mata\"},{\"authorId\":\"6703190\",\"name\":\"N. P. D. L. Blanca\"}],\"doi\":\"10.1007/s00521-020-04811-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a77e9f0bd205a7733431a6d1028f09f57f9f73b0\",\"title\":\"Multimodal feature fusion for CNN-based gait recognition: an empirical comparison\",\"url\":\"https://www.semanticscholar.org/paper/a77e9f0bd205a7733431a6d1028f09f57f9f73b0\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"1603.07120\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2691321\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"title\":\"Deep Multimodal Feature Analysis for Action Recognition in RGB+D Videos\",\"url\":\"https://www.semanticscholar.org/paper/a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018}],\"corpusId\":4284367,\"doi\":\"10.1109/CVPR.2015.7299059\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":90,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630277553\",\"name\":\"M. Sankar\"}],\"doi\":\"10.1515/9783111548050-024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"title\":\"M\",\"url\":\"https://www.semanticscholar.org/paper/517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1007/978-3-642-37431-9_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"536bd55a69a5f536fc4450ac4f482d47333b0270\",\"title\":\"A Comparative Study of Encoding, Pooling and Normalization Methods for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/536bd55a69a5f536fc4450ac4f482d47333b0270\",\"venue\":\"ACCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2985266\",\"name\":\"Zhuowei Cai\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2014.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"title\":\"Multi-view Super Vector for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C Szegedy\"},{\"authorId\":null,\"name\":\"W Liu\"},{\"authorId\":null,\"name\":\"Y Jia\"},{\"authorId\":null,\"name\":\"P Sermanet\"},{\"authorId\":null,\"name\":\"S Reed\"},{\"authorId\":null,\"name\":\"D Anguelov\"},{\"authorId\":null,\"name\":\"D Erhan\"},{\"authorId\":null,\"name\":\"V Vanhoucke\"},{\"authorId\":null,\"name\":\"A Rabinovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Going deeper with convolutions. CoRR, abs/1409\",\"url\":\"\",\"venue\":\"Going deeper with convolutions. CoRR, abs/1409\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. G. Lowe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Distinctive image features from scale-inva  riant keypoints.IJCV\",\"url\":\"\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00003-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06d5b55bec96f2157276b631e2f21d52a33ea246\",\"title\":\"C\",\"url\":\"https://www.semanticscholar.org/paper/06d5b55bec96f2157276b631e2f21d52a33ea246\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The TDD code and learned two-stream ConvNet models are available at https\",\"url\":\"\",\"venue\":\"The TDD code and learned two-stream ConvNet models are available at https\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TIP.2013.2295753\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca137df68953b803d2a8e224ed22be3cbcccf819\",\"title\":\"Latent Hierarchical Model of Temporal Structure for Complex Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/ca137df68953b803d2a8e224ed22be3cbcccf819\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403818358\",\"name\":\"Alonso Patron-Perez\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/TPAMI.2012.24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adaf72ae34d6165df4e2b6d3e03e3c6a0d33fd9f\",\"title\":\"Structured Learning of Human Interactions in TV Shows\",\"url\":\"https://www.semanticscholar.org/paper/adaf72ae34d6165df4e2b6d3e03e3c6a0d33fd9f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/B978-0-12-384931-1.00018-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3b8146c7950597628689d14551e74d46cc3543d\",\"title\":\"R\",\"url\":\"https://www.semanticscholar.org/paper/a3b8146c7950597628689d14551e74d46cc3543d\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A comparative study of encoding\",\"url\":\"\",\"venue\":\"pooling and normalization methods for action recognition. InACCV\",\"year\":2012},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2013.6474994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6ad6f3d311b6fc2fe7c4f85077b24d59c208452\",\"title\":\"Large-scale web video event classification by use of Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/f6ad6f3d311b6fc2fe7c4f85077b24d59c208452\",\"venue\":\"2013 IEEE Workshop on Applications of Computer Vision (WACV)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2465976\",\"name\":\"M. Fischler\"},{\"authorId\":\"1764443\",\"name\":\"R. Bolles\"}],\"doi\":\"10.1145/358669.358692\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"278c9a78d4505cfaf6b709df364dbd1206a017c1\",\"title\":\"Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography\",\"url\":\"https://www.semanticscholar.org/paper/278c9a78d4505cfaf6b709df364dbd1206a017c1\",\"venue\":\"CACM\",\"year\":1981},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10602-1_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"title\":\"Video Action Detection with Relational Dynamic-Poselets\",\"url\":\"https://www.semanticscholar.org/paper/d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Toderici A. Karpathy\"},{\"authorId\":null,\"name\":\"S. Shetty\"},{\"authorId\":null,\"name\":\"T. Leung\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge : Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Wang\"},{\"authorId\":null,\"name\":\"M. M. Ullah\"},{\"authorId\":null,\"name\":\"A. Kl\\u00e4ser\"},{\"authorId\":null,\"name\":\"I. Laptev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and C\",\"url\":\"\",\"venue\":\"Schmid . Evaluation of local spatio-temporal features for action re  cognition. In BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Patron-Perez\"},{\"authorId\":null,\"name\":\"M. Marszalek\"},{\"authorId\":null,\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"Zisserma n. Structured learning of human interactions in TV shows. TPAMI, 34(12)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrej Karpathy\"},{\"authorId\":null,\"name\":\"George Toderici\"},{\"authorId\":null,\"name\":\"Sanketh Shetty\"},{\"authorId\":null,\"name\":\"Thomas Leung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rahul Sukthankar, and Li Fei-Fei. Large-scale video classification with convolutional neural networks\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Piccardi\"},{\"authorId\":null,\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and R\",\"url\":\"\",\"venue\":\"Sukthankar. THUMOS challenge: Action recognition with a large number of classes\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mid - level 3 D parts for human motion recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144075041\",\"name\":\"C. Evans\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7cf406a47048730c1a08d46cb0166b16566524\",\"title\":\"SURF : Speeded Up Robust Features\",\"url\":\"https://www.semanticscholar.org/paper/6c7cf406a47048730c1a08d46cb0166b16566524\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84362927\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"123108776\",\"name\":\"M.S. Ryoo\"}],\"doi\":\"10.1145/1922649.1922653\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"title\":\"Human activity analysis: A review\",\"url\":\"https://www.semanticscholar.org/paper/56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"venue\":\"CSUR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37335907\",\"name\":\"G. Willems\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-540-88688-4_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"title\":\"An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector\",\"url\":\"https://www.semanticscholar.org/paper/117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Kuehne\"},{\"authorId\":null,\"name\":\"H. Jhuang\"},{\"authorId\":null,\"name\":\"E. Garrote\"},{\"authorId\":null,\"name\":\"T. Poggio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and T\",\"url\":\"\",\"venue\":\"Serre  . HMDB: A large video database for human motion recognition. In ICCV\",\"year\":2011},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Szegedy\"},{\"authorId\":null,\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"P. Sermanet\"},{\"authorId\":null,\"name\":\"S. Reed\"},{\"authorId\":null,\"name\":\"D. Anguelov\"},{\"authorId\":null,\"name\":\"D. Erhan\"},{\"authorId\":null,\"name\":\"V. Vanhoucke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"Rabinovich. Going deeper with convolutions.CoRR, abs/1409.4842\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390562671\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"}],\"doi\":\"10.1007/s11263-013-0636-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4cede3acfd94fccc927519e04384a8debfec705\",\"title\":\"Image Classification with the Fisher Vector: Theory and Practice\",\"url\":\"https://www.semanticscholar.org/paper/d4cede3acfd94fccc927519e04384a8debfec705\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644050191\",\"name\":\"G. LoweDavid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121996\",\"name\":\"William M. Marsden\"}],\"doi\":\"10.1017/CBO9781139207249.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d2218b17e7898a222e5fc2079a3f1531990708f\",\"title\":\"I and J\",\"url\":\"https://www.semanticscholar.org/paper/3d2218b17e7898a222e5fc2079a3f1531990708f\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948848\",\"name\":\"S. Sadanand\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247806\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"title\":\"Action bank: A high-level representation of activity in video\",\"url\":\"https://www.semanticscholar.org/paper/d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"31064779\",\"name\":\"W. Zhang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/ICCV.2013.442\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21e8f3344170a8f133b69308c178518df8a27274\",\"title\":\"Action Recognition with Actons\",\"url\":\"https://www.semanticscholar.org/paper/21e8f3344170a8f133b69308c178518df8a27274\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2013.333\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b11228f6ce7d681a2a065b4ba191a51456671d29\",\"title\":\"Mining Motion Atoms and Phrases for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b11228f6ce7d681a2a065b4ba191a51456671d29\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. D. Zeiler\"},{\"authorId\":null,\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing and understandi ng convolutional networks\",\"url\":\"\",\"venue\":\"InECCV\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"E. Shelhamer\"},{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"S. Karayev\"},{\"authorId\":null,\"name\":\"J. Long\"},{\"authorId\":null,\"name\":\"R. B. Girshick\"},{\"authorId\":null,\"name\":\"S. Guadarrama\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Piccardi\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"D convolutional neural networks for human action recognition\",\"url\":\"\",\"venue\":\"THUMOS challenge : Action recognition with a large number of classes\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dffe7498c67e9451db2d04bb8408f376ae86992\",\"title\":\"LEAR-INRIA submission for the THUMOS workshop\",\"url\":\"https://www.semanticscholar.org/paper/7dffe7498c67e9451db2d04bb8408f376ae86992\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2013.345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2633f6a4bb683aafecd86e9484258c0767196422\",\"title\":\"Motionlets: Mid-level 3D Parts for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2633f6a4bb683aafecd86e9484258c0767196422\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G Jiang\"},{\"authorId\":null,\"name\":\"J Liu\"},{\"authorId\":null,\"name\":\"A Roshan\"},{\"authorId\":null,\"name\":\"I Zamir\"},{\"authorId\":null,\"name\":\"M Laptev\"},{\"authorId\":null,\"name\":\"M Piccardi\"},{\"authorId\":null,\"name\":\"R Shah\"},{\"authorId\":null,\"name\":\"Sukthankar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"THUMOS challenge: Action recognition with a large number of classes\",\"year\":2013}],\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"topics\":[{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Database normalization\",\"topicId\":\"16746\",\"url\":\"https://www.semanticscholar.org/topic/16746\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Aggregate data\",\"topicId\":\"54317\",\"url\":\"https://www.semanticscholar.org/topic/54317\"},{\"topic\":\"Test-driven development\",\"topicId\":\"99317\",\"url\":\"https://www.semanticscholar.org/topic/99317\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Head-mounted display\",\"topicId\":\"207277\",\"url\":\"https://www.semanticscholar.org/topic/207277\"}],\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"