"{\"abstract\":\"In spite of many dataset efforts for human action recognition, current computer vision algorithms are still severely limited in terms of the variability and complexity of the actions that they can recognize. This is in part due to the simplicity of current benchmarks, which mostly focus on simple actions and movements occurring on manually trimmed videos. In this paper we introduce ActivityNet, a new large-scale video benchmark for human activity understanding. Our benchmark aims at covering a wide range of complex human activities that are of interest to people in their daily living. In its current version, ActivityNet provides samples from 203 activity classes with an average of 137 untrimmed videos per class and 1.41 activity instances per video, for a total of 849 video hours. We illustrate three scenarios in which ActivityNet can be used to compare algorithms for human activity understanding: untrimmed video classification, trimmed activity classification and activity detection.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\",\"url\":\"https://www.semanticscholar.org/author/3175258\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\",\"url\":\"https://www.semanticscholar.org/author/144201025\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\",\"url\":\"https://www.semanticscholar.org/author/2931652\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\",\"url\":\"https://www.semanticscholar.org/author/9200530\"}],\"citationVelocity\":223,\"citations\":[{\"arxivId\":\"1810.12522\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-030-20893-6_34\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"283181a2173b485726664edc6fe73f0465387629\",\"title\":\"Random Temporal Skipping for Multirate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/283181a2173b485726664edc6fe73f0465387629\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1802.02668\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"50588067\",\"name\":\"Xueqing Deng\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/TMM.2019.2891999\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1791a75776a3fed65ab8a110faa461f39d090d7c\",\"title\":\"Fine-Grained Land Use Classification at the City Scale Using Ground-Level Images\",\"url\":\"https://www.semanticscholar.org/paper/1791a75776a3fed65ab8a110faa461f39d090d7c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1808.02559\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"153188107\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-01234-2_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8befcd91c24038e5c26df0238d26e2311b21719a\",\"title\":\"A Joint Sequence Fusion Model for Video Question Answering and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8befcd91c24038e5c26df0238d26e2311b21719a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":null,\"name\":\"Lei Zhu\"}],\"doi\":\"10.1109/ICCV.2017.394\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6ae53b5837f6e6ca975dcb7af53ef51ac820e3a7\",\"title\":\"Leveraging Weak Semantic Relevance for Complex Video Event Classification\",\"url\":\"https://www.semanticscholar.org/paper/6ae53b5837f6e6ca975dcb7af53ef51ac820e3a7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4fa0b4e518de397fafa3fe8c9d925bcd4a3438e\",\"title\":\"Online action detection\",\"url\":\"https://www.semanticscholar.org/paper/f4fa0b4e518de397fafa3fe8c9d925bcd4a3438e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1611.09053\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/CVPR.2017.147\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"533d14e539ae5cdca0ece392487a2b19106d468a\",\"title\":\"Bidirectional Multirate Reconstruction for Temporal Modeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/533d14e539ae5cdca0ece392487a2b19106d468a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"153439664\",\"name\":\"Y. Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"}],\"doi\":\"10.1109/SIP.2015.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64c4019f1ea9b54b1848418ac53c4e2584dc62d4\",\"title\":\"ActionNet-VE Dataset: A Dataset for Describing Visual Events by Extending VIRAT Ground 2.0\",\"url\":\"https://www.semanticscholar.org/paper/64c4019f1ea9b54b1848418ac53c4e2584dc62d4\",\"venue\":\"2015 8th International Conference on Signal Processing, Image Processing and Pattern Recognition (SIP)\",\"year\":2015},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/WACV.2016.7477586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65355cbb581a219bd7461d48b3afd115263ea760\",\"title\":\"Recognition of ongoing complex activities by sequence prediction over a hierarchical label space\",\"url\":\"https://www.semanticscholar.org/paper/65355cbb581a219bd7461d48b3afd115263ea760\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2186316\",\"name\":\"H. Chen\"},{\"authorId\":\"3102340\",\"name\":\"Mingcong Song\"},{\"authorId\":\"9693830\",\"name\":\"J. Zhao\"},{\"authorId\":\"145279386\",\"name\":\"Yuting Dai\"},{\"authorId\":null,\"name\":\"Tao Li\"}],\"doi\":\"10.1145/3307650.3322260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ad728e01d83ff880bd63735a0fc2156e908fd53\",\"title\":\"3D-based Video Recognition Acceleration by Leveraging Temporal Locality\",\"url\":\"https://www.semanticscholar.org/paper/0ad728e01d83ff880bd63735a0fc2156e908fd53\",\"venue\":\"2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)\",\"year\":2019},{\"arxivId\":\"1812.06587\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00674\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"171a027fc6c7f4194569170accc48187c8bb5aaa\",\"title\":\"Grounded Video Description\",\"url\":\"https://www.semanticscholar.org/paper/171a027fc6c7f4194569170accc48187c8bb5aaa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.01575\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01264-9_4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"title\":\"Video Re-localization\",\"url\":\"https://www.semanticscholar.org/paper/8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.01938\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2018.00556\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"title\":\"Learning Latent Super-Events to Detect Multiple Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"3112203\",\"name\":\"Yongqiang Huang\"},{\"authorId\":\"1388011059\",\"name\":\"J. Meloncon\"},{\"authorId\":\"49696823\",\"name\":\"Y. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d53eace5ff054e8f135e39662e93ba7a0c39ba58\",\"title\":\"Motion Taxonomy and Coding for Robots\",\"url\":\"https://www.semanticscholar.org/paper/d53eace5ff054e8f135e39662e93ba7a0c39ba58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.04326\",\"authors\":[{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"2996464\",\"name\":\"Jiaqing Lin\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"title\":\"STAIR Actions: A Video Dataset of Everyday Home Actions\",\"url\":\"https://www.semanticscholar.org/paper/d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134659275\",\"name\":\"Ryo Miyoshi\"},{\"authorId\":\"40168195\",\"name\":\"N. Nagata\"},{\"authorId\":\"48338800\",\"name\":\"M. Hashimoto\"}],\"doi\":\"10.1109/DICTA47822.2019.8946025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50ee97a344f08aa4241434940d676cc18d55ff91\",\"title\":\"Facial-Expression Recognition from Video using Enhanced Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/50ee97a344f08aa4241434940d676cc18d55ff91\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"2004.02678\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"145984816\",\"name\":\"Y. Xiong\"},{\"authorId\":\"48048546\",\"name\":\"Guo-dong Xu\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.01016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3214f9ed95d89c04ebc16c3a142c2ece98d66e75\",\"title\":\"A Local-to-Global Approach to Multi-Modal Movie Scene Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3214f9ed95d89c04ebc16c3a142c2ece98d66e75\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.00195\",\"authors\":[{\"authorId\":\"49461641\",\"name\":\"G. Li\"},{\"authorId\":\"113143344\",\"name\":\"Guocheng Qian\"},{\"authorId\":\"1379921764\",\"name\":\"Itzel C. Delgadillo\"},{\"authorId\":\"1391027880\",\"name\":\"Matthias M\\u00fcller\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.00169\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab40ffbe08230084a6345630ffb3a9b9a2c3bb67\",\"title\":\"SGAS: Sequential Greedy Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/ab40ffbe08230084a6345630ffb3a9b9a2c3bb67\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151473343\",\"name\":\"Amirhosein Zanganeh\"},{\"authorId\":\"1896730\",\"name\":\"Mahdi Jampour\"}],\"doi\":\"10.1109/PRIA.2019.8785966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"627ba85b977ba79fec73e727853da3f6e7334a5f\",\"title\":\"Automatic Weak Learners Selection for Pattern Recognition and its application in Soccer Goal Recognition\",\"url\":\"https://www.semanticscholar.org/paper/627ba85b977ba79fec73e727853da3f6e7334a5f\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115621884\",\"name\":\"Y. Li\"},{\"authorId\":\"48335554\",\"name\":\"Bao-peng Zhang\"},{\"authorId\":\"104824906\",\"name\":\"Jiajie Tian\"},{\"authorId\":\"73014418\",\"name\":\"R. Li\"},{\"authorId\":\"73580479\",\"name\":\"S. Wang\"},{\"authorId\":\"48203684\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/BESC48373.2019.8963477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73b17b7cf8289333556dffda28618b00f3063ae4\",\"title\":\"Object-based Image Discrimination Relationship Recognition\",\"url\":\"https://www.semanticscholar.org/paper/73b17b7cf8289333556dffda28618b00f3063ae4\",\"venue\":\"2019 6th International Conference on Behavioral, Economic and Socio-Cultural Computing (BESC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TMM.2019.2943204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"881103d13eda11f231f88205b7ed2c6f6c8eea1b\",\"title\":\"Coarse-to-Fine Localization of Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/881103d13eda11f231f88205b7ed2c6f6c8eea1b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2799968\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"title\":\"Multi-Modality Multi-Task Recurrent Neural Network for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2007.03777\",\"authors\":[{\"authorId\":\"1500388631\",\"name\":\"Huai-Yi Huang\"},{\"authorId\":\"1591146277\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"92138570\",\"name\":\"Z. Guo\"},{\"authorId\":\"3173957\",\"name\":\"Z. Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58589-1_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8a8dcb20f7836da0578fb4f14e15cb569956502\",\"title\":\"Placepedia: Comprehensive Place Understanding with Multi-Faceted Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d8a8dcb20f7836da0578fb4f14e15cb569956502\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7967365\",\"name\":\"Sijia Tian\"}],\"doi\":\"10.14288/1.0375801\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74e620b52f0bb8d9d39871cbb05cc065c58184f4\",\"title\":\"Group event recognition in ice hockey\",\"url\":\"https://www.semanticscholar.org/paper/74e620b52f0bb8d9d39871cbb05cc065c58184f4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"title\":\"Video Action Classification Using PredNet\",\"url\":\"https://www.semanticscholar.org/paper/bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2376695\",\"name\":\"Annapurna P. Patil\"},{\"authorId\":\"1390000527\",\"name\":\"A. Srinath\"},{\"authorId\":\"1389892592\",\"name\":\"Atif Adib\"},{\"authorId\":\"40928888\",\"name\":\"Dimple Doshi\"},{\"authorId\":\"40928160\",\"name\":\"Darshan Dalsaniya\"}],\"doi\":\"10.1109/ICACCP.2019.8882987\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da93b22cfcb35d242351670ca3f68974db83769d\",\"title\":\"Scalable Activity Recognition Framework using Ensemble Models\",\"url\":\"https://www.semanticscholar.org/paper/da93b22cfcb35d242351670ca3f68974db83769d\",\"venue\":\"2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP)\",\"year\":2019},{\"arxivId\":\"1909.03252\",\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"145913039\",\"name\":\"Y. Rong\"},{\"authorId\":\"144259957\",\"name\":\"P. Zhao\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/ICCV.2019.00719\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd8e725159159ca2169d302f6cb510e3b1cc1a4b\",\"title\":\"Graph Convolutional Networks for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/fd8e725159159ca2169d302f6cb510e3b1cc1a4b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144843868\",\"name\":\"Brandon Haynes\"},{\"authorId\":\"19170117\",\"name\":\"Amrita Mazumdar\"},{\"authorId\":\"1718134\",\"name\":\"M. Balazinska\"},{\"authorId\":\"1717411\",\"name\":\"L. Ceze\"},{\"authorId\":\"144385783\",\"name\":\"A. Cheung\"}],\"doi\":\"10.1145/3299869.3324955\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e318bd214b623655c9a67f8888e5d5131335e6\",\"title\":\"Visual Road: A Video Data Management Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/43e318bd214b623655c9a67f8888e5d5131335e6\",\"venue\":\"SIGMOD Conference\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143635958\",\"name\":\"D. Fernandez\"},{\"authorId\":\"2023762\",\"name\":\"D. Varas\"},{\"authorId\":\"39925976\",\"name\":\"Joan Espadaler\"},{\"authorId\":\"8136555\",\"name\":\"Issey Masuda\"},{\"authorId\":\"35303838\",\"name\":\"Jordi Ferreira\"},{\"authorId\":\"38874877\",\"name\":\"A. Woodward\"},{\"authorId\":\"120974377\",\"name\":\"D. Rodriguez\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"35528008\",\"name\":\"Juan Carlos Riveiro\"},{\"authorId\":\"2429242\",\"name\":\"Elisenda Bou\"}],\"doi\":\"10.1109/ICCVW.2017.48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d0eb497812a12cda0c6c0e90959f9115de4908f\",\"title\":\"ViTS: Video Tagging System from Massive Web Multimedia Collections\",\"url\":\"https://www.semanticscholar.org/paper/5d0eb497812a12cda0c6c0e90959f9115de4908f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"145529194\",\"name\":\"M. Martinez\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-030-11018-5_8\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c127e27ec746afbeede792f63316663fb96bf95\",\"title\":\"Towards a Fair Evaluation of Zero-Shot Action Recognition Using External Data\",\"url\":\"https://www.semanticscholar.org/paper/1c127e27ec746afbeede792f63316663fb96bf95\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1502.07209\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"49606697\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TPAMI.2017.2670560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"title\":\"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1808.02536\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-20870-7_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"929c8a73fceb88148847c6abca98a4d413d15415\",\"title\":\"Dynamic Temporal Pyramid Network: A Closer Look at Multi-Scale Modeling for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/929c8a73fceb88148847c6abca98a4d413d15415\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2008.03270\",\"authors\":[{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1007/978-3-030-60639-8_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"title\":\"Multi-level Temporal Pyramid Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"49835905\",\"name\":\"Xuesong Jiang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1007/s11042-017-5038-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf784156547c3be146706e2763c1a52d939d1722\",\"title\":\"Breaking video into pieces for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf784156547c3be146706e2763c1a52d939d1722\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1808.05326\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/D18-1009\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"af5c4b80fbf847f69a202ba5a780a3dd18c1a027\",\"title\":\"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\",\"url\":\"https://www.semanticscholar.org/paper/af5c4b80fbf847f69a202ba5a780a3dd18c1a027\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"}],\"doi\":\"10.15781/T2QR4P68H\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"title\":\"Natural Language Video Description using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40909443\",\"name\":\"Y. Hu\"},{\"authorId\":\"50655168\",\"name\":\"MingQi Lu\"},{\"authorId\":\"47415615\",\"name\":\"Chao Xie\"},{\"authorId\":\"153010660\",\"name\":\"Xiao-Bo Lu\"}],\"doi\":\"10.1109/TCSVT.2019.2958188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fed50b6e4411a15bdec1dc85680fc0ddb60e107b\",\"title\":\"Driver Drowsiness Recognition via 3D Conditional GAN and Two-Level Attention Bi-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fed50b6e4411a15bdec1dc85680fc0ddb60e107b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1908.02422\",\"authors\":[{\"authorId\":\"1737602\",\"name\":\"C. Zhang\"},{\"authorId\":\"47103450\",\"name\":\"Yunlu Xu\"},{\"authorId\":\"2398015\",\"name\":\"Zhanzhan Cheng\"},{\"authorId\":\"2760746\",\"name\":\"Yi Niu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"47586475\",\"name\":\"Futai Zou\"}],\"doi\":\"10.1145/3343031.3351044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc4ce2dff0b386dbe28a67db78314c00926c79a8\",\"title\":\"Adversarial Seeded Sequence Growing for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/cc4ce2dff0b386dbe28a67db78314c00926c79a8\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2057472\",\"name\":\"Nebojsa Jojic\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/TPAMI.2018.2866114\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3aec6702fdb8fb93753dbde79a2eb7482fb22444\",\"title\":\"Video Imprint\",\"url\":\"https://www.semanticscholar.org/paper/3aec6702fdb8fb93753dbde79a2eb7482fb22444\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102786474\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"48622607\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a7173d31b1cb91ae9f2d8bed4e5dd92c0b65f21\",\"title\":\"How to build HAKE Part States Definition : WordNet Expert Annotation Initial Annotations Part States Refinement : Annotators Repetitive Labelling Automatic Check Expert Check Existing Activity Datasets with Instance-level Annotations Automatic Generation\",\"url\":\"https://www.semanticscholar.org/paper/3a7173d31b1cb91ae9f2d8bed4e5dd92c0b65f21\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"79723716\",\"name\":\"D. Di\"},{\"authorId\":\"66358686\",\"name\":\"J. Xiao\"},{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3323873.3325056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa0388f5373a2f17a3c456346a52427c887667ea\",\"title\":\"Annotating Objects and Relations in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/fa0388f5373a2f17a3c456346a52427c887667ea\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"1908.04519\",\"authors\":[{\"authorId\":\"97765655\",\"name\":\"J. Xia\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82614927db94b233415975ab98f92e9468e6492\",\"title\":\"Three Branches: Detecting Actions With Richer Features\",\"url\":\"https://www.semanticscholar.org/paper/a82614927db94b233415975ab98f92e9468e6492\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159364\",\"name\":\"Karthik D Patel\"},{\"authorId\":\"1753738548\",\"name\":\"Siddesh M G\"},{\"authorId\":\"151387459\",\"name\":\"A. Agarwal\"},{\"authorId\":\"1753739506\",\"name\":\"Akshay Nihalani\"},{\"authorId\":\"2805176\",\"name\":\"M. B. Nirmala\"},{\"authorId\":\"1753629584\",\"name\":\"Kavitha H\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120926\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fddc9e74e6ea1f0cd5bc640114308e85ae102a17\",\"title\":\"Autonomous Malicious Video Content Categorization Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fddc9e74e6ea1f0cd5bc640114308e85ae102a17\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":\"2007.06643\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-58568-6_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"title\":\"Adversarial Background-Aware Loss for Weakly-supervised Temporal Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1808.00297\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-20876-9_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"563fcc87934a4e6c8843c81b58273cb366918bfb\",\"title\":\"TraMNet - Transition Matrix Network for Efficient Action Tube Proposals\",\"url\":\"https://www.semanticscholar.org/paper/563fcc87934a4e6c8843c81b58273cb366918bfb\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01240-3_16\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78c4086c392d03e206d2a25be55768cd58ce3462\",\"title\":\"Action Search: Spotting Actions in Videos and Its Application to Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/78c4086c392d03e206d2a25be55768cd58ce3462\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2016.211\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bac994dda1385cd709e08e24170c711d8c573676\",\"title\":\"Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bac994dda1385cd709e08e24170c711d8c573676\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2018.2844101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ef6b55a23aab0ec6b02fdb01d5e30181ef42e04\",\"title\":\"Hierarchical Concept Score Postprocessing and Concept-Wise Normalization in CNN-Based Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ef6b55a23aab0ec6b02fdb01d5e30181ef42e04\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1708.02862\",\"authors\":[{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"2794259\",\"name\":\"Eirikur Agustsson\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5de5848dc3fc35e40420ffec70a407e4770e3a8d\",\"title\":\"WebVision Database: Visual Learning and Understanding from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/5de5848dc3fc35e40420ffec70a407e4770e3a8d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52580548\",\"name\":\"M. Young\"},{\"authorId\":\"153761408\",\"name\":\"Hyung-il Kim\"},{\"authorId\":\"83168173\",\"name\":\"Park Jongyoul\"}],\"doi\":\"10.22648/ETRI.2020.J.350303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c47ff65e56035aa523f48ece1b462df1ed0c7f\",\"title\":\"Trends in Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/31c47ff65e56035aa523f48ece1b462df1ed0c7f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1910.11792\",\"authors\":[{\"authorId\":\"1382655067\",\"name\":\"Roberto Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"},{\"authorId\":\"51257737\",\"name\":\"Abhijeet Shenoi\"},{\"authorId\":\"50556043\",\"name\":\"Mihir Patel\"},{\"authorId\":\"39813007\",\"name\":\"JunYoung Gwak\"},{\"authorId\":\"40556444\",\"name\":\"Nathan Dass\"},{\"authorId\":\"49693671\",\"name\":\"Alan N. Federman\"},{\"authorId\":\"144368914\",\"name\":\"P. Goebel\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1d1acf42e539746769ef4736bdb3ab39b388b71\",\"title\":\"JRDB: A Dataset and Benchmark for Visual Perception for Navigation in Human Environments\",\"url\":\"https://www.semanticscholar.org/paper/f1d1acf42e539746769ef4736bdb3ab39b388b71\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447537\",\"name\":\"Haijun Liu\"},{\"authorId\":\"2019481\",\"name\":\"S. Wang\"},{\"authorId\":\"97520398\",\"name\":\"Wen Wang\"},{\"authorId\":\"144569543\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/TMM.2019.2929923\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"title\":\"Multi-Scale Based Context-Aware Net for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/s00371-019-01725-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"812cfc1f88008476dc2ae90d0117065a4001a81b\",\"title\":\"Deep motion templates and extreme learning machine for sign language recognition\",\"url\":\"https://www.semanticscholar.org/paper/812cfc1f88008476dc2ae90d0117065a4001a81b\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1807.10418\",\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/978-3-030-01225-0_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"title\":\"W-TALC: Weakly-supervised Temporal Activity Localization and Classification\",\"url\":\"https://www.semanticscholar.org/paper/b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"title\":\"Weakly Supervised EM Process For Temporal Localization Within Video\",\"url\":\"https://www.semanticscholar.org/paper/aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.00973\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3123266.3123432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f510bc627be67fc1dea8b2465f1697bc0cdb3041\",\"title\":\"Attention Transfer from Web Images for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f510bc627be67fc1dea8b2465f1697bc0cdb3041\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3215608\",\"name\":\"J. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/S11063-020-10349-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eac014f40c5601fdf1eab65b117250f6888e8799\",\"title\":\"Complementary Boundary Estimation Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/eac014f40c5601fdf1eab65b117250f6888e8799\",\"venue\":\"Neural Process. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"},{\"authorId\":\"47037488\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1016/j.compeleceng.2020.106654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20a84646f5f38ae7f7148b81f0924640807e2b19\",\"title\":\"Vectors of temporally correlated snippets for temporal action detection\",\"url\":\"https://www.semanticscholar.org/paper/20a84646f5f38ae7f7148b81f0924640807e2b19\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":\"2010.06260\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"title\":\"DORi: Discovering Object Relationship for Moment Localization of a Natural-Language Query in Video\",\"url\":\"https://www.semanticscholar.org/paper/a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.04301\",\"authors\":[{\"authorId\":\"144909180\",\"name\":\"H. Hosseini\"},{\"authorId\":\"2797515\",\"name\":\"Baicen Xiao\"},{\"authorId\":\"145280190\",\"name\":\"A. Clark\"},{\"authorId\":\"144786412\",\"name\":\"R. Poovendran\"}],\"doi\":\"10.1145/3137616.3137618\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1832c646a98e4794e8408cb23593e8e049d9351\",\"title\":\"Attacking Automatic Video Analysis Algorithms: A Case Study of Google Cloud Video Intelligence API\",\"url\":\"https://www.semanticscholar.org/paper/a1832c646a98e4794e8408cb23593e8e049d9351\",\"venue\":\"MPS@CCS\",\"year\":2017},{\"arxivId\":\"2010.11594\",\"authors\":[{\"authorId\":\"3191371\",\"name\":\"Yuanhao Zhai\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2914452\",\"name\":\"W. Tang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-58539-6_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"title\":\"Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.11893\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"2000157278\",\"name\":\"Qi Dai\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80126506f744e1efd827e69951bdb6e558eb77a7\",\"title\":\"Temporal Action Detection with Multi-level Supervision\",\"url\":\"https://www.semanticscholar.org/paper/80126506f744e1efd827e69951bdb6e558eb77a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08977\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"title\":\"Generating Adjacency Matrix for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.07339\",\"authors\":[{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"47057695\",\"name\":\"Xinbo Li\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"}],\"doi\":\"10.14358/PERS.85.4.297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cb3e0c4ad37dd7e0abd2eedd704d4d27edb0a17\",\"title\":\"Vehicle Detection in Aerial Images\",\"url\":\"https://www.semanticscholar.org/paper/8cb3e0c4ad37dd7e0abd2eedd704d4d27edb0a17\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1109/TIP.2019.2942814\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"title\":\"Deep Reinforcement Learning for Weak Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/CVPR.2017.604\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33685943\",\"name\":\"Mayoore S. Jaiswal\"},{\"authorId\":\"144222336\",\"name\":\"H. P. Hofstee\"},{\"authorId\":\"15110752\",\"name\":\"V. Chen\"},{\"authorId\":\"21080039\",\"name\":\"Suvadip Paul\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"153035546\",\"name\":\"F. Liu\"},{\"authorId\":\"2055404\",\"name\":\"A. Jagannathan\"},{\"authorId\":\"32272278\",\"name\":\"A. Gattiker\"},{\"authorId\":\"152565412\",\"name\":\"Inseok Hwang\"},{\"authorId\":\"48052648\",\"name\":\"J. Lee\"},{\"authorId\":\"11398739\",\"name\":\"M. Tong\"},{\"authorId\":\"1382198044\",\"name\":\"Sahil Dureja\"},{\"authorId\":\"4353428\",\"name\":\"Soham Shah\"}],\"doi\":\"10.1109/ICCVW.2019.00188\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8873d1369590249113e1f0491ce49d1502395b9c\",\"title\":\"Video-Text Compliance: Activity Verification Based on Natural Language Instructions\",\"url\":\"https://www.semanticscholar.org/paper/8873d1369590249113e1f0491ce49d1502395b9c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1706.05150\",\"authors\":[{\"authorId\":\"3405101\",\"name\":\"He-Da Wang\"},{\"authorId\":null,\"name\":\"Teng Zhang\"},{\"authorId\":\"144527769\",\"name\":\"Ji Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bda6b3a88c6b19048ad6fd62196d1650cc468f9\",\"title\":\"The Monkeytyping Solution to the YouTube-8M Video Understanding Challenge\",\"url\":\"https://www.semanticscholar.org/paper/0bda6b3a88c6b19048ad6fd62196d1650cc468f9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"1390826784\",\"name\":\"Rui-Qi Wang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/TIP.2020.2987425\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"174168393288dbb61a6ec4c674a0298e489b9e4d\",\"title\":\"Confidence-Guided Self Refinement for Action Prediction in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/174168393288dbb61a6ec4c674a0298e489b9e4d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1712.09374\",\"authors\":[{\"authorId\":\"49453213\",\"name\":\"Hang Zhao\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bd9157331104a0708aa4f8ae79b7651a5be797c6\",\"title\":\"SLAC: A Sparsely Labeled Dataset for Action Classification and Localization\",\"url\":\"https://www.semanticscholar.org/paper/bd9157331104a0708aa4f8ae79b7651a5be797c6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"48874063\",\"name\":\"Q. Liu\"},{\"authorId\":\"144635784\",\"name\":\"X. Hu\"}],\"doi\":\"10.1145/3394171.3413595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"title\":\"Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"568cff415e7e1bebd4769c4a628b90db293c1717\",\"title\":\"Concepts Not Alone: Exploring Pairwise Relationships for Zero-Shot Video Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/568cff415e7e1bebd4769c4a628b90db293c1717\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1608.08128\",\"authors\":[{\"authorId\":\"145346209\",\"name\":\"A. Montes\"},{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1927afcfc5aa0d830cd867065ccb07f890b6d261\",\"title\":\"Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1927afcfc5aa0d830cd867065ccb07f890b6d261\",\"venue\":\"NIPS 2016\",\"year\":2016},{\"arxivId\":\"2002.02921\",\"authors\":[{\"authorId\":\"50625399\",\"name\":\"Yidan Qin\"},{\"authorId\":\"2538502\",\"name\":\"Sahba Aghajani Pedram\"},{\"authorId\":\"3267953\",\"name\":\"S. Feyzabadi\"},{\"authorId\":\"48313894\",\"name\":\"M. Allan\"},{\"authorId\":\"145068636\",\"name\":\"A. J. McLeod\"},{\"authorId\":\"144751617\",\"name\":\"J. Burdick\"},{\"authorId\":\"1715489\",\"name\":\"M. Azizian\"}],\"doi\":\"10.1109/ICRA40945.2020.9196560\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c706e2b90ddb38138385a32ff758c854a34bb60c\",\"title\":\"Temporal Segmentation of Surgical Sub-tasks through Deep Learning with Multiple Data Sources\",\"url\":\"https://www.semanticscholar.org/paper/c706e2b90ddb38138385a32ff758c854a34bb60c\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1902.07370\",\"authors\":[{\"authorId\":\"49470254\",\"name\":\"X. Zhang\"},{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"49673319\",\"name\":\"Changsheng Li\"},{\"authorId\":\"145487535\",\"name\":\"Kai Zheng\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"}],\"doi\":\"10.1609/aaai.v33i01.33019227\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e273f4763004d9e224e1e91c6f87e63d6d49daf\",\"title\":\"Learning Transferable Self-attentive Representations for Action Recognition in Untrimmed Videos with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7e273f4763004d9e224e1e91c6f87e63d6d49daf\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19188327\",\"name\":\"Nghia Pham Trong\"},{\"authorId\":\"144715435\",\"name\":\"H. Nguyen\"},{\"authorId\":\"1791753\",\"name\":\"K. Kotani\"},{\"authorId\":\"145344657\",\"name\":\"H. Le\"}],\"doi\":\"10.1007/978-3-319-62392-4_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50a31ac7866c2cba2b5f580973bfbbbd92569142\",\"title\":\"A Comprehensive Survey on Human Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/50a31ac7866c2cba2b5f580973bfbbbd92569142\",\"venue\":\"ICCSA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"62f1b47d94350ac17ec16e8569dcf6d9cf1ffcda\",\"title\":\"Activity Detection with Latent Sub-event Hierarchy Learning\",\"url\":\"https://www.semanticscholar.org/paper/62f1b47d94350ac17ec16e8569dcf6d9cf1ffcda\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46528640\",\"name\":\"H. T. Binh\"},{\"authorId\":\"9283769\",\"name\":\"Ma Thi Chau\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"9349062\",\"name\":\"B. Duy\"}],\"doi\":\"10.1109/ICCCE.2018.8539313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3901f177642912be3fd132807a1e7d16796d1011\",\"title\":\"Selecting active frames for action recognition with vote fusion method\",\"url\":\"https://www.semanticscholar.org/paper/3901f177642912be3fd132807a1e7d16796d1011\",\"venue\":\"2018 7th International Conference on Computer and Communication Engineering (ICCCE)\",\"year\":2018},{\"arxivId\":\"2007.09877\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"title\":\"Graph Neural Network for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"37384277\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.32470/CCN.2018.1137-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37850689bcf5ae10caec20ba6657778998220d92\",\"title\":\"A Large Scale Multi-Label Action Dataset for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/37850689bcf5ae10caec20ba6657778998220d92\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.00053\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2017.361\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"title\":\"The Pose Knows: Video Forecasting by Generating Pose Futures\",\"url\":\"https://www.semanticscholar.org/paper/3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":null,\"name\":\"Zhicheng Yan\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00876\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"title\":\"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691251\",\"name\":\"J. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.jvcir.2018.03.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3780f56d2563dcdea4a3ce178acd265456f05dd\",\"title\":\"Temporally enhanced image object proposals for online video object and action detections\",\"url\":\"https://www.semanticscholar.org/paper/e3780f56d2563dcdea4a3ce178acd265456f05dd\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1145/3078971.3079002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34912edb1cf0576ff36ca9c4f651237f9115deed\",\"title\":\"Musical Instrument Recognition in User-generated Videos using a Multimodal Convolutional Neural Network Architecture\",\"url\":\"https://www.semanticscholar.org/paper/34912edb1cf0576ff36ca9c4f651237f9115deed\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2489020\",\"name\":\"Brian Geuther\"},{\"authorId\":\"1995462965\",\"name\":\"Asaf Pe'er\"},{\"authorId\":\"145818206\",\"name\":\"Hao He\"},{\"authorId\":\"71586239\",\"name\":\"G. Sabnis\"},{\"authorId\":\"2264830\",\"name\":\"V. Philip\"},{\"authorId\":\"49533156\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1101/2020.10.08.331017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b63e43d368935fb8657fa0bd800d03b1229485eb\",\"title\":\"Action detection using a neural network elucidates the genetics of mouse grooming behavior\",\"url\":\"https://www.semanticscholar.org/paper/b63e43d368935fb8657fa0bd800d03b1229485eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1709.01077\",\"authors\":[{\"authorId\":\"2116952\",\"name\":\"Guy Rosman\"},{\"authorId\":\"31496901\",\"name\":\"John W. Fisher\"},{\"authorId\":\"145944286\",\"name\":\"Daniela Rus\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d18d63edf9c0b2a8f8f72f41d26557d763eadf3\",\"title\":\"A Nonparametric Model for Multimodal Collaborative Activities Summarization\",\"url\":\"https://www.semanticscholar.org/paper/8d18d63edf9c0b2a8f8f72f41d26557d763eadf3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"153439664\",\"name\":\"Yongjin Kwon\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"}],\"doi\":\"10.1109/SIP.2015.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8943474b9e7f0cc65266c93246b66de458d3918e\",\"title\":\"Investigation and Review of Embedded Events in Public Video Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8943474b9e7f0cc65266c93246b66de458d3918e\",\"venue\":\"2015 8th International Conference on Signal Processing, Image Processing and Pattern Recognition (SIP)\",\"year\":2015},{\"arxivId\":\"1706.07911\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"50152762\",\"name\":\"Sen Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"title\":\"Large-Scale Human Activity Mapping using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2008.07819\",\"authors\":[{\"authorId\":\"72831997\",\"name\":\"T. Ma\"},{\"authorId\":\"101160956\",\"name\":\"L. Zhang\"},{\"authorId\":\"87641774\",\"name\":\"X. Diao\"},{\"authorId\":\"1411075691\",\"name\":\"O. Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"title\":\"ConvGRU in Fine-grained Pitching Action Recognition for Action Outcome Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591117210\",\"name\":\"Yanxia Zhang\"},{\"authorId\":\"2195286\",\"name\":\"Andreas Girgensohn\"},{\"authorId\":\"1404320306\",\"name\":\"Yulius Tjahjadi\"}],\"doi\":\"10.1109/CSE/EUC.2019.00089\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25528bc0b3554c5b5d89637f60ce5cb274b913d2\",\"title\":\"Activity Forecasting in Routine Tasks by Combining Local Motion Trajectories and High-Level Temporal Models\",\"url\":\"https://www.semanticscholar.org/paper/25528bc0b3554c5b5d89637f60ce5cb274b913d2\",\"venue\":\"2019 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)\",\"year\":2019},{\"arxivId\":\"1806.03863\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"},{\"authorId\":\"1807336\",\"name\":\"L. Mazar\\u00e9\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":\"10.1007/978-3-030-01225-0_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3254692e2794ef8c8f96374aadb27c3f3926492e\",\"title\":\"Massively Parallel Video Networks\",\"url\":\"https://www.semanticscholar.org/paper/3254692e2794ef8c8f96374aadb27c3f3926492e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.05402\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70557ea6b65846fc30729ceed224acd4ac64ca5d\",\"title\":\"MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/70557ea6b65846fc30729ceed224acd4ac64ca5d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1905.03922\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19659297ac67a29d7524fba60062558f2235f8a\",\"title\":\"Spatio-Temporal Video Re-Localization by Warp LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878475584\",\"name\":\"Xin Gao\"},{\"authorId\":\"1878338267\",\"name\":\"Xusheng Liu\"},{\"authorId\":\"1879512992\",\"name\":\"Taotao Yang\"},{\"authorId\":\"34604525\",\"name\":\"G. Deng\"},{\"authorId\":\"1878360893\",\"name\":\"Hao Peng\"},{\"authorId\":\"1877628045\",\"name\":\"Qiaosong Zhang\"},{\"authorId\":\"97584815\",\"name\":\"H. Li\"},{\"authorId\":\"1879297772\",\"name\":\"Junhui Liu\"}],\"doi\":\"10.1109/ICMEW46912.2020.9106051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"title\":\"Automatic Key Moment Extraction and Highlights Generation Based on Comprehensive Soccer Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"1911.11306\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"50112704\",\"name\":\"Sumin Lee\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2019.2953187\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13aa627f35de78af64d1861fceb97c834a769b05\",\"title\":\"SRG: Snippet Relatedness-Based Temporal Action Proposal Generator\",\"url\":\"https://www.semanticscholar.org/paper/13aa627f35de78af64d1861fceb97c834a769b05\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1804.03247\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2018.00226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7404a8d77ba515633b61c68164210d3422d0aaf0\",\"title\":\"Fine-Grained Activity Recognition in Baseball Videos\",\"url\":\"https://www.semanticscholar.org/paper/7404a8d77ba515633b61c68164210d3422d0aaf0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1703.02437\",\"authors\":[{\"authorId\":\"2414059\",\"name\":\"S. Manen\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICCV.2017.40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ae84b0adc5054db47814a5c475f732e6c1c9098\",\"title\":\"PathTrack: Fast Trajectory Annotation with Path Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6ae84b0adc5054db47814a5c475f732e6c1c9098\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001407\",\"name\":\"S. Cappallo\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1145/3123266.3123437\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"06b94b47b70c9bfcddbe277a61a9a802acd20096\",\"title\":\"Future-Supervised Retrieval of Unseen Queries for Live Video\",\"url\":\"https://www.semanticscholar.org/paper/06b94b47b70c9bfcddbe277a61a9a802acd20096\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1607.07429\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0d5aa7f797113c825053f4c4fd3772dc3601139\",\"title\":\"Much Ado About Time: Exhaustive Annotation of Temporal Data\",\"url\":\"https://www.semanticscholar.org/paper/d0d5aa7f797113c825053f4c4fd3772dc3601139\",\"venue\":\"HCOMP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13723092\",\"name\":\"J. Chauhan\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/CRV.2018.00039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2945e982dd21d4efc3103a6c8aae7b7bd367414\",\"title\":\"Context-Aware Action Detection in Untrimmed Videos Using Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/b2945e982dd21d4efc3103a6c8aae7b7bd367414\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96668091\",\"name\":\"Tan Yu\"},{\"authorId\":\"49201849\",\"name\":\"Z. Ren\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"104219153\",\"name\":\"Enxu Yan\"},{\"authorId\":\"145857596\",\"name\":\"N. Xu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/ICCV.2019.00562\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c\",\"title\":\"Temporal Structure Mining for Weakly Supervised Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49415643\",\"name\":\"Y. Wang\"},{\"authorId\":\"46696648\",\"name\":\"L. Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2018.00557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"title\":\"Temporal Hallucinating for Action Recognition with Few Still Images\",\"url\":\"https://www.semanticscholar.org/paper/1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.08586\",\"authors\":[{\"authorId\":\"34567611\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"8020375\",\"name\":\"Yueming Lyu\"},{\"authorId\":\"145821440\",\"name\":\"X. Shen\"},{\"authorId\":\"1807998\",\"name\":\"I. Tsang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c97556edbc192896cc55395f8f21fe0ff148580\",\"title\":\"Marginalized Average Attentional Network for Weakly-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/6c97556edbc192896cc55395f8f21fe0ff148580\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"48093650\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"}],\"doi\":\"10.1145/3365212\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76f6ca119c719cd9f9362a160fb15af2b895095f\",\"title\":\"A Benchmark Dataset and Comparison Study for Multi-modal Human Action Analytics\",\"url\":\"https://www.semanticscholar.org/paper/76f6ca119c719cd9f9362a160fb15af2b895095f\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":\"1811.06052\",\"authors\":[{\"authorId\":\"145746855\",\"name\":\"G. Mastorakis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6967deb139ba3dddefbdeb5aea58ca9867173db2\",\"title\":\"Human-like machine learning: limitations and suggestions\",\"url\":\"https://www.semanticscholar.org/paper/6967deb139ba3dddefbdeb5aea58ca9867173db2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"145473096\",\"name\":\"Yu Zheng\"},{\"authorId\":\"145758664\",\"name\":\"J. Fan\"}],\"doi\":\"10.1109/TMM.2019.2907453\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"56da037ea82b991caf206c07318f793dd0513c4a\",\"title\":\"Exploiting Mid-Level Semantics for Large-Scale Complex Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/56da037ea82b991caf206c07318f793dd0513c4a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036839966\",\"name\":\"Bh. SravyaPranati\"},{\"authorId\":\"1573504331\",\"name\":\"D. Suma\"},{\"authorId\":\"2008765960\",\"name\":\"C. ManjuLatha\"},{\"authorId\":\"2620777\",\"name\":\"Sudhakar Putheti\"}],\"doi\":\"10.1007/978-981-15-7062-9_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac67c3a534591a606d342a96519fccf671cdca7\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ac67c3a534591a606d342a96519fccf671cdca7\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2019.2921655\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"title\":\"Sports Video Captioning via Attentive Motion Representation and Group Relationship Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2011.07807\",\"authors\":[{\"authorId\":\"1782000465\",\"name\":\"Aftab Alam\"},{\"authorId\":\"51453868\",\"name\":\"Irfan Ullah\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/ACCESS.2020.3017135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"title\":\"Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues\",\"url\":\"https://www.semanticscholar.org/paper/9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1808.08803\",\"authors\":[{\"authorId\":\"1819984\",\"name\":\"K. Ning\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"47118295\",\"name\":\"Ming Cai\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20da5315cfe5eab69d99bbda270e73ab488a49ba\",\"title\":\"Attentive Sequence to Sequence Translation for Localizing Clips of Interest by Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/20da5315cfe5eab69d99bbda270e73ab488a49ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423738380\",\"name\":\"Zakia Yahya\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"}],\"doi\":\"10.1109/HONET.2019.8908040\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"title\":\"Classification and Temporal Localization of Robbery Events in CCTV Videos through Multi-Stream Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"venue\":\"2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT and AI (HONET-ICT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72557716\",\"name\":\"Song Liu\"},{\"authorId\":\"1709381241\",\"name\":\"Qiaolin He\"},{\"authorId\":\"48708884\",\"name\":\"Z. Wang\"},{\"authorId\":\"153005923\",\"name\":\"Y. Pu\"},{\"authorId\":\"4763857\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICCCBDA49378.2020.9095594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"title\":\"Irregular Action Recognition in Court with 3D Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"venue\":\"2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)\",\"year\":2020},{\"arxivId\":\"2003.03530\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"150352016\",\"name\":\"Yanzhou Su\"},{\"authorId\":\"144941515\",\"name\":\"Y. Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2de59074948bca0c0a4919bba03229477f65e821\",\"title\":\"TTPP: Temporal Transformer with Progressive Prediction for Efficient Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2de59074948bca0c0a4919bba03229477f65e821\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.13931\",\"authors\":[{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"},{\"authorId\":\"1735962\",\"name\":\"Aixin Sun\"},{\"authorId\":\"1492128584\",\"name\":\"Wei Jing\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"}],\"doi\":\"10.18653/v1/2020.acl-main.585\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"title\":\"Span-based Localizing Network for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669712931\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":\"10.1016/j.imavis.2020.103944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22f92789daadfb944e33f7f76ca13553765eabb3\",\"title\":\"Viewpoint constrained and unconstrained Cricket stroke localization from untrimmed videos\",\"url\":\"https://www.semanticscholar.org/paper/22f92789daadfb944e33f7f76ca13553765eabb3\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"2003.12424\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"152464732\",\"name\":\"Qi Dai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"title\":\"Weakly-Supervised Action Localization by Generative Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"506ea19145838a035e7dba535519fb40a3a0018c\",\"title\":\"Learning Shared Multimodal Embeddings with Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/506ea19145838a035e7dba535519fb40a3a0018c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2017.161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"title\":\"Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks\",\"url\":\"https://www.semanticscholar.org/paper/28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1609.08675\",\"authors\":[{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"144317839\",\"name\":\"Nisarg Kothari\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"title\":\"YouTube-8M: A Large-Scale Video Classification Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1706.04261\",\"authors\":[{\"authorId\":\"38962424\",\"name\":\"Raghav Goyal\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"12929417\",\"name\":\"S. Westphal\"},{\"authorId\":\"2233986\",\"name\":\"Heuna Kim\"},{\"authorId\":\"7241984\",\"name\":\"V. Haenel\"},{\"authorId\":\"47544625\",\"name\":\"Ingo Fr\\u00fcnd\"},{\"authorId\":\"19265538\",\"name\":\"Peter Yianilos\"},{\"authorId\":\"1414405239\",\"name\":\"Moritz Mueller-Freitag\"},{\"authorId\":\"143931146\",\"name\":\"F. Hoppe\"},{\"authorId\":\"2020614\",\"name\":\"Christian Thurau\"},{\"authorId\":\"2443288\",\"name\":\"I. Bax\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":\"10.1109/ICCV.2017.622\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68811a9b5cafe4795a11c1048541750068b7ad0\",\"title\":\"The \\u201cSomething Something\\u201d Video Database for Learning and Evaluating Visual Common Sense\",\"url\":\"https://www.semanticscholar.org/paper/b68811a9b5cafe4795a11c1048541750068b7ad0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":\"1910.11009\",\"authors\":[{\"authorId\":\"47424372\",\"name\":\"Yu Xiong\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"10357054\",\"name\":\"L. Guo\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87699cff38982712ddb0b2349313077779a5d0ff\",\"title\":\"A Graph-Based Framework to Bridge Movies and Synopses\",\"url\":\"https://www.semanticscholar.org/paper/87699cff38982712ddb0b2349313077779a5d0ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27687205\",\"name\":\"N. Efthymiou\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"30192180\",\"name\":\"P. P. Filntisis\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2018.8451146\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b56a568799a0dee06587d8ab54032f7bf7712008\",\"title\":\"Multi- View Fusion for Action Recognition in Child-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/b56a568799a0dee06587d8ab54032f7bf7712008\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1908.07410\",\"authors\":[{\"authorId\":\"1403953272\",\"name\":\"Giorgos Kordopatis-Zilos\"},{\"authorId\":\"48594399\",\"name\":\"S. Papadopoulos\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1109/ICCV.2019.00645\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1167b93dbe428b5a59452af658f652f16653034b\",\"title\":\"ViSiL: Fine-Grained Spatio-Temporal Video Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/1167b93dbe428b5a59452af658f652f16653034b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40939344\",\"name\":\"A. Goel\"},{\"authorId\":\"31056622\",\"name\":\"Abdelrahman G. Abubakr\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/IPAS.2018.8708880\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4846df8b97148e9226c92da612b4352dbda704ce\",\"title\":\"Online temporal detection of daily-living human activities in long untrimmed video streams\",\"url\":\"https://www.semanticscholar.org/paper/4846df8b97148e9226c92da612b4352dbda704ce\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138115\",\"name\":\"F. Negin\"},{\"authorId\":\"40939344\",\"name\":\"A. Goel\"},{\"authorId\":\"31056622\",\"name\":\"Abdelrahman G. Abubakr\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2018.8639471\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"240cead6dabc50986a25b18dca414b538b937a51\",\"title\":\"Online Detection of Long-Term Daily Living Activities by Weakly Supervised Recognition of Sub-Activities\",\"url\":\"https://www.semanticscholar.org/paper/240cead6dabc50986a25b18dca414b538b937a51\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jun Yang\"},{\"authorId\":\"7947723\",\"name\":\"Zhongke Shi\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"}],\"doi\":\"10.1016/j.aei.2016.04.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57d60c00baa0152a5f7edb88e3b2220038bf5222\",\"title\":\"Vision-based action recognition of construction workers using dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/57d60c00baa0152a5f7edb88e3b2220038bf5222\",\"venue\":\"Adv. Eng. Informatics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50290191\",\"name\":\"Tianyu Li\"},{\"authorId\":\"2004641888\",\"name\":\"Bing Bing\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/s11042-020-09703-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a14f6a0222385bf0173c0737b47a0cce0c9b036\",\"title\":\"Boundary discrimination and proposal evaluation for temporal action proposal generation\",\"url\":\"https://www.semanticscholar.org/paper/7a14f6a0222385bf0173c0737b47a0cce0c9b036\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1109/CVPR.2018.00772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3586c182a3450f6eea4d64d69217383bae77e6c1\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/3586c182a3450f6eea4d64d69217383bae77e6c1\",\"venue\":\"CVPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145476300\",\"name\":\"P. Zhdanov\"},{\"authorId\":\"143636123\",\"name\":\"A. Khan\"},{\"authorId\":\"2525887\",\"name\":\"A. R. Rivera\"},{\"authorId\":\"1803086\",\"name\":\"A. Khattak\"}],\"doi\":\"10.1109/IJCNN.2018.8489663\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c54fe61181045865d6834e2fe4376aeea1f9884\",\"title\":\"Improving Human Action Recognition through Hierarchical Neural Network Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/4c54fe61181045865d6834e2fe4376aeea1f9884\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48021090\",\"name\":\"B. Zhu\"},{\"authorId\":\"50290087\",\"name\":\"T. Li\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-030-31726-3_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46c899e661ed9c0bef182b8019035bf5a68cd61d\",\"title\":\"Exploiting Human Pose for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/46c899e661ed9c0bef182b8019035bf5a68cd61d\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1808.05085\",\"authors\":[{\"authorId\":\"40192003\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1145/3240508.3240534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"title\":\"Temporal Sequence Distillation: Towards Few-Frame Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"2007.02632\",\"authors\":[{\"authorId\":\"52025559\",\"name\":\"Mahsa Ehsanpour\"},{\"authorId\":\"3447236\",\"name\":\"A. Abedin\"},{\"authorId\":\"19170799\",\"name\":\"F. Saleh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1007/978-3-030-58545-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81287e31f3e659aaedb5dce0646ba2b86377b282\",\"title\":\"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/81287e31f3e659aaedb5dce0646ba2b86377b282\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1810.12126\",\"authors\":[{\"authorId\":\"8556451\",\"name\":\"F. Angelini\"},{\"authorId\":\"9573943\",\"name\":\"Zeyu Fu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144403678\",\"name\":\"S. Naqvi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"66837b29270f3e03df64941a081d70c687c7955c\",\"title\":\"ActionXPose: A Novel 2D Multi-view Pose-based Algorithm for Real-time Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/66837b29270f3e03df64941a081d70c687c7955c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.00137\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb23ed33c6b2a2234d19a5899f7628ff2a15b858\",\"title\":\"Revisiting Few-shot Activity Detection with Class Similarity Control\",\"url\":\"https://www.semanticscholar.org/paper/bb23ed33c6b2a2234d19a5899f7628ff2a15b858\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1911.08199\",\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6820\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9388ec8a0de86969afce29947b8b80b5698e4a21\",\"title\":\"Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\",\"url\":\"https://www.semanticscholar.org/paper/9388ec8a0de86969afce29947b8b80b5698e4a21\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096937\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b39d9873e95553406923f0bbd492ba70f6db7d83\",\"title\":\"Real-time Detection of Activities in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/b39d9873e95553406923f0bbd492ba70f6db7d83\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"1801.09184\",\"authors\":[{\"authorId\":\"2860057\",\"name\":\"Yancheng Bai\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"601d81b164afceecf6f155d60bfb400510a5be4e\",\"title\":\"Contextual Multi-Scale Region Convolutional 3D Network for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/601d81b164afceecf6f155d60bfb400510a5be4e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e78232f23508b879c6c5ae372030487ed071ca1f\",\"title\":\"Video Action Classification Using Deep Predictive Coding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e78232f23508b879c6c5ae372030487ed071ca1f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.11794\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"}],\"doi\":\"10.1007/978-3-030-20890-5_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59795eab858174e34ce31e302f831d1a2243ddb1\",\"title\":\"Cascaded Pyramid Mining Network for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/59795eab858174e34ce31e302f831d1a2243ddb1\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2009.14265\",\"authors\":[{\"authorId\":\"1845917958\",\"name\":\"Samreen Anjum\"},{\"authorId\":\"50554791\",\"name\":\"Chi Lin\"},{\"authorId\":\"1420431848\",\"name\":\"Danna Gurari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c87206ce4bcdcb53d1283cd92d3f384051e4c781\",\"title\":\"CrowdMOT: Crowdsourcing Strategies for Tracking Multiple Objects in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c87206ce4bcdcb53d1283cd92d3f384051e4c781\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.03877\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.00043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"title\":\"Gaussian Temporal Awareness Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1612.06753\",\"authors\":[{\"authorId\":\"2001407\",\"name\":\"S. Cappallo\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.5244/C.30.143\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"243ee4a76ad685b12383cbcec06677996ce7c0b1\",\"title\":\"Video Stream Retrieval of Unseen Queries using Semantic Memory\",\"url\":\"https://www.semanticscholar.org/paper/243ee4a76ad685b12383cbcec06677996ce7c0b1\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1908.07236\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":\"10.1109/WACV45572.2020.9093328\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"title\":\"Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention\",\"url\":\"https://www.semanticscholar.org/paper/03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145322964\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1609/AAAI.V33I01.33018328\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d0fd644b14871bfdf3d4a25e8613b30328eb335\",\"title\":\"Video Imprint Segmentation for Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d0fd644b14871bfdf3d4a25e8613b30328eb335\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490966079\",\"name\":\"A. Calabrese\"},{\"authorId\":\"143802044\",\"name\":\"Michele Bevilacqua\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.18653/v1/2020.acl-main.425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36d7e8c618bbc5e59ba3d13d7cce7e94d829eea5\",\"title\":\"Fatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts\",\"url\":\"https://www.semanticscholar.org/paper/36d7e8c618bbc5e59ba3d13d7cce7e94d829eea5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"46461307\",\"name\":\"S. Z. Gilani\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"},{\"authorId\":\"9493788\",\"name\":\"Han-lin Qin\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.3390/s20236941\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"title\":\"Self-Supervised Learning to Detect Key Frames in Videos\",\"url\":\"https://www.semanticscholar.org/paper/61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404783588\",\"name\":\"Merve Ar\\u0131t\\u00fcrk\"},{\"authorId\":\"1404783588\",\"name\":\"Merve Ar\\u0131t\\u00fcrk\"},{\"authorId\":\"2684904\",\"name\":\"S. Yavuz\"},{\"authorId\":\"1697598\",\"name\":\"T. Allahviranloo\"}],\"doi\":\"10.1002/9781119585640.ch17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74f9a6d1f024da1ce8dfdb88aec5b09dda657d69\",\"title\":\"Artificial Intelligence and Autonomous Car\",\"url\":\"https://www.semanticscholar.org/paper/74f9a6d1f024da1ce8dfdb88aec5b09dda657d69\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"1807515831\",\"name\":\"Lei Yang\"},{\"authorId\":\"2837671\",\"name\":\"Huaiyi Huang\"},{\"authorId\":\"150325884\",\"name\":\"T. Wu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58520-4_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2dd5b397c86da5bc916b1a0c5b96d9a87ab8e52d\",\"title\":\"Caption-Supervised Face Recognition: Training a State-of-the-Art Face Model Without Manual Annotation\",\"url\":\"https://www.semanticscholar.org/paper/2dd5b397c86da5bc916b1a0c5b96d9a87ab8e52d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122336282\",\"name\":\"M. Sanabria\"},{\"authorId\":\"52066907\",\"name\":\"Sherly\"},{\"authorId\":\"150103589\",\"name\":\"F. Precioso\"},{\"authorId\":\"36180475\",\"name\":\"Thomas Menguy\"}],\"doi\":\"10.1145/3347318.3355524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a15e0179f4c0d3cd93dce45c5d867cfe217954a\",\"title\":\"A Deep Architecture for Multimodal Summarization of Soccer Games\",\"url\":\"https://www.semanticscholar.org/paper/1a15e0179f4c0d3cd93dce45c5d867cfe217954a\",\"venue\":\"MMSports '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3130030\",\"name\":\"M. Farrajota\"},{\"authorId\":\"143955056\",\"name\":\"J. Rodrigues\"},{\"authorId\":\"1394604631\",\"name\":\"J. M. H. du Buf\"}],\"doi\":\"10.1007/s10044-018-0727-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b999364980e4c21d9c22cc5a9f14501432999ca4\",\"title\":\"Human action recognition in videos with articulated pose information by deep networks\",\"url\":\"https://www.semanticscholar.org/paper/b999364980e4c21d9c22cc5a9f14501432999ca4\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"1810.06807\",\"authors\":[{\"authorId\":\"145490315\",\"name\":\"Kartik Hegde\"},{\"authorId\":\"50843533\",\"name\":\"R. Agrawal\"},{\"authorId\":\"51463024\",\"name\":\"Yulun Yao\"},{\"authorId\":\"2012099\",\"name\":\"Christopher W. Fletcher\"}],\"doi\":\"10.1109/MICRO.2018.00080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"title\":\"Morph: Flexible Acceleration for 3D CNN-Based Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"venue\":\"2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7531875\",\"name\":\"Cuiwei Liu\"},{\"authorId\":\"1862641\",\"name\":\"Zhaokui Li\"},{\"authorId\":\"3085797\",\"name\":\"Xiangbin Shi\"},{\"authorId\":\"144571454\",\"name\":\"Chong Du\"}],\"doi\":\"10.1155/2018/3508350\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a9fd281281f046c2e4d548104a7d1f79d133b24\",\"title\":\"Learning a Mid-Level Representation for Multiview Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a9fd281281f046c2e4d548104a7d1f79d133b24\",\"venue\":\"Adv. Multim.\",\"year\":2018},{\"arxivId\":\"1807.02929\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"title\":\"Step-by-step Erasion, One-by-one Collection: A Weakly Supervised Temporal Action Detector\",\"url\":\"https://www.semanticscholar.org/paper/d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1901.02598\",\"authors\":[{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3285568\",\"name\":\"Yanan Sui\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2019.00366\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00ccecc56ed83945fafb8e2dc48ffc1609618040\",\"title\":\"D3TW: Discriminative Differentiable Dynamic Time Warping for Weakly Supervised Action Alignment and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00ccecc56ed83945fafb8e2dc48ffc1609618040\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2012.02109\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72b19a0125ddda2752cfcf8c5758a13c52275665\",\"title\":\"SAFCAR: Structured Attention Fusion for Compositional Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b19a0125ddda2752cfcf8c5758a13c52275665\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15168\",\"authors\":[{\"authorId\":\"20574924\",\"name\":\"M. F. Chen\"},{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"14123214\",\"name\":\"F. Sala\"},{\"authorId\":\"50425695\",\"name\":\"Sen Wu\"},{\"authorId\":\"47368718\",\"name\":\"R. T. Mullapudi\"},{\"authorId\":\"1779956265\",\"name\":\"Fait Poms\"},{\"authorId\":\"1399047905\",\"name\":\"Kayvon Fatahalian\"},{\"authorId\":\"144988097\",\"name\":\"C. R\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77dcb003fe36cbfc4847ef86f685f425c4c1dbfd\",\"title\":\"Train and You'll Miss It: Interactive Model Iteration with Weak Supervision and Pre-Trained Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/77dcb003fe36cbfc4847ef86f685f425c4c1dbfd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67267687\",\"name\":\"K. Degiorgio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb4fc543bb24f5793aa797fd36907dcfebd4cfe6\",\"title\":\"Automatic Localization and Annotation of Spatio-Temporal Actions in Weakly Labelled Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb4fc543bb24f5793aa797fd36907dcfebd4cfe6\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"title\":\"POLITECNICO DI TORINO Master of Science in Mathematical Engineering Deep Learning Algorithms for Video Classification: Application on Real-Time Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.01725\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-030-01252-6_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"title\":\"Liquid Pouring Monitoring via Rich Sensory Inputs\",\"url\":\"https://www.semanticscholar.org/paper/e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"1391188897\",\"name\":\"Bernard\"},{\"authorId\":\"66827766\",\"name\":\"Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"562f8111f7214d9f19eb37224243802c572b273f\",\"title\":\"Diagnosing Error in Temporal Action Detectors ( Supplementary Material )\",\"url\":\"https://www.semanticscholar.org/paper/562f8111f7214d9f19eb37224243802c572b273f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122822134\",\"name\":\"Gregory Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"145901595\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2b840276017c04e090058e281431379d35de88b\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Security Video\",\"url\":\"https://www.semanticscholar.org/paper/a2b840276017c04e090058e281431379d35de88b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1801.04134\",\"authors\":[{\"authorId\":\"35309584\",\"name\":\"Jonas Rothfuss\"},{\"authorId\":\"145839029\",\"name\":\"F. Ferreira\"},{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"46432716\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/LRA.2018.2860057\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"970a8f1655ab329cba5fe26edf543e62fe354376\",\"title\":\"Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution\",\"url\":\"https://www.semanticscholar.org/paper/970a8f1655ab329cba5fe26edf543e62fe354376\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77393486\",\"name\":\"Neha Belapurkar\"},{\"authorId\":\"80496214\",\"name\":\"Sagar Shelke\"},{\"authorId\":\"1783275\",\"name\":\"Baris Aksanli\"}],\"doi\":\"10.1145/3277593.3277628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a77d8da534ec49bde27caef43c0095f07ad823d\",\"title\":\"The case for ambient sensing for human activity detection\",\"url\":\"https://www.semanticscholar.org/paper/7a77d8da534ec49bde27caef43c0095f07ad823d\",\"venue\":\"IOT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704860\",\"name\":\"J. Choi\"},{\"authorId\":\"2378263\",\"name\":\"Kyungrae Kim\"},{\"authorId\":\"48872879\",\"name\":\"T. Park\"},{\"authorId\":\"52413783\",\"name\":\"Junho Yun\"},{\"authorId\":\"82536563\",\"name\":\"Jonghwan Lee\"},{\"authorId\":\"2917665\",\"name\":\"Songkuk Kim\"},{\"authorId\":\"2081318\",\"name\":\"Hyunjung Shim\"},{\"authorId\":\"29495301\",\"name\":\"J. Lee\"}],\"doi\":\"10.1145/3379336.3381482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38807681bf53121cd4731c529b3d99e948b26f54\",\"title\":\"Real-time Integrated Human Activity Recognition System based on Multimodal User Understanding\",\"url\":\"https://www.semanticscholar.org/paper/38807681bf53121cd4731c529b3d99e948b26f54\",\"venue\":\"IUI Companion\",\"year\":2020},{\"arxivId\":\"1602.02995\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"0258749b418db624de697ea934b4f1425c961066\",\"title\":\"Segmental Spatio-Temporal CNNs for Fine-grained Action Segmentation and Classification\",\"url\":\"https://www.semanticscholar.org/paper/0258749b418db624de697ea934b4f1425c961066\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2010.09890\",\"authors\":[{\"authorId\":\"143872936\",\"name\":\"Xavier Puig\"},{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\"},{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":\"50219251\",\"name\":\"Zilin Wang\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd24143d9f9d6244bf4c7a6a1cd30ab9ae059096\",\"title\":\"Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration\",\"url\":\"https://www.semanticscholar.org/paper/dd24143d9f9d6244bf4c7a6a1cd30ab9ae059096\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.14266\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/cvpr42600.2020.00058\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"title\":\"SCT: Set Constrained Temporal Transformer for Set Supervised Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/978-981-13-2553-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbc7c5f41123e0b6603697232866ac5ec81cd8dd\",\"title\":\"Human Activity Recognition in Video Benchmarks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/dbc7c5f41123e0b6603697232866ac5ec81cd8dd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097295\",\"name\":\"Yue Li\"},{\"authorId\":\"31399226\",\"name\":\"Wenrui Ding\"},{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"46843692\",\"name\":\"Yuanjun Huang\"},{\"authorId\":\"9325297\",\"name\":\"Yalong Jiang\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9191306\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"title\":\"Cam-Net: Compressed Attentive Multi-Granularity Network For Dynamic Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2481662\",\"name\":\"Y. Zhou\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00775\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"title\":\"Now You Shake Me: Towards Automatic 4D Cinema\",\"url\":\"https://www.semanticscholar.org/paper/ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"},{\"authorId\":\"2817677\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"152299623\",\"name\":\"C. Yan\"},{\"authorId\":\"46518251\",\"name\":\"L. Yao\"}],\"doi\":\"10.1016/j.knosys.2020.106432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6072b5407daf1db4871fa27bdac7f63407019091\",\"title\":\"Memory transformation networks for weakly supervised visual classification\",\"url\":\"https://www.semanticscholar.org/paper/6072b5407daf1db4871fa27bdac7f63407019091\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2005.08465\",\"authors\":[{\"authorId\":\"71777904\",\"name\":\"H. Zhang\"},{\"authorId\":\"2884662\",\"name\":\"Xuemiao Xu\"},{\"authorId\":\"2823769\",\"name\":\"G. Han\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1109/cvpr42600.2020.00075\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d29fc735af090ac33d986d129daf022268839096\",\"title\":\"Context-Aware and Scale-Insensitive Temporal Repetition Counting\",\"url\":\"https://www.semanticscholar.org/paper/d29fc735af090ac33d986d129daf022268839096\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860787381\",\"name\":\"Madhumita Mallick\"},{\"authorId\":\"4213990\",\"name\":\"Niloy Ganguly\"},{\"authorId\":\"48018833\",\"name\":\"Suparna Bhattacharya\"}],\"doi\":\"10.1109/MDM48529.2020.00033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"525e1181f8ea5d3a49e28a7a9c2dd3a3a269ac7d\",\"title\":\"GradeSense: Gradation Aware Storage for Robust Activity Recognition in a Multimodal Smarthome\",\"url\":\"https://www.semanticscholar.org/paper/525e1181f8ea5d3a49e28a7a9c2dd3a3a269ac7d\",\"venue\":\"2020 21st IEEE International Conference on Mobile Data Management (MDM)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.5220/0008345900110013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68e12c2f62a1d7a177172148711e0f83ae48d918\",\"title\":\"A Fine-grained Perspective onto Object Interactions from First-person Views\",\"url\":\"https://www.semanticscholar.org/paper/68e12c2f62a1d7a177172148711e0f83ae48d918\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1811.07460\",\"authors\":[{\"authorId\":\"47103450\",\"name\":\"Yunlu Xu\"},{\"authorId\":\"1737602\",\"name\":\"C. Zhang\"},{\"authorId\":\"2398015\",\"name\":\"Zhanzhan Cheng\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"143767386\",\"name\":\"Yi Niu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1609/aaai.v33i01.33019070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3934262388cddf2fa6a8af32fbca7e8533ef62df\",\"title\":\"Segregated Temporal Assembly Recurrent Networks for Weakly Supervised Multiple Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/3934262388cddf2fa6a8af32fbca7e8533ef62df\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1707.00251\",\"authors\":[{\"authorId\":\"1949021\",\"name\":\"Sangkuk Lee\"},{\"authorId\":\"2238575\",\"name\":\"Daesik Kim\"},{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"33039133\",\"name\":\"Jihye Hwang\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"fd7e065947973a967a2ff4287463ead402a8845d\",\"title\":\"Where to Play: Retrieval of Video Segments using Natural-Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/fd7e065947973a967a2ff4287463ead402a8845d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518145\",\"name\":\"Yantao Lu\"},{\"authorId\":\"48513191\",\"name\":\"Yilan Li\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/ICIP.2019.8803823\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab0e96b66e8cef1bc33f8afa255cb391c96e70fa\",\"title\":\"Efficient Human Activity Classification from Egocentric Videos Incorporating Actor-Critic Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ab0e96b66e8cef1bc33f8afa255cb391c96e70fa\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2011.14478\",\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"2437353\",\"name\":\"Shanghang Zhang\"},{\"authorId\":\"2004342113\",\"name\":\"Guangyao Chen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"efa758ff318dec043c1e331962c068ba4eb54722\",\"title\":\"Annotation-Efficient Untrimmed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efa758ff318dec043c1e331962c068ba4eb54722\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.04965\",\"authors\":[{\"authorId\":\"47092548\",\"name\":\"Volker Fischer\"},{\"authorId\":\"49759539\",\"name\":\"J. K\\u00f6hler\"},{\"authorId\":\"46818707\",\"name\":\"T. Pfeil\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99967d34b2fc185090ab05494bf1b2a9b2609f8d\",\"title\":\"The streaming rollout of deep networks - towards fully model-parallel execution\",\"url\":\"https://www.semanticscholar.org/paper/99967d34b2fc185090ab05494bf1b2a9b2609f8d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2008.03548\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"80180784\",\"name\":\"Xuekun Jiang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58621-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"title\":\"A Unified Framework for Shot Type Classification Based on Subject Centric Lens\",\"url\":\"https://www.semanticscholar.org/paper/49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10703\",\"authors\":[{\"authorId\":\"31638576\",\"name\":\"A. Arnab\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-58607-2_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d9660f127a880ec9757aedc90509524d744c15a\",\"title\":\"Uncertainty-Aware Weakly Supervised Action Detection from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/7d9660f127a880ec9757aedc90509524d744c15a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.09037\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"2331418\",\"name\":\"S. Samsi\"},{\"authorId\":\"3302251\",\"name\":\"W. Arcand\"},{\"authorId\":\"2159806\",\"name\":\"David Bestor\"},{\"authorId\":\"34001612\",\"name\":\"Bill Bergeron\"},{\"authorId\":\"2098646\",\"name\":\"C. Byun\"},{\"authorId\":\"1850501832\",\"name\":\"Micheal Houle\"},{\"authorId\":\"145238688\",\"name\":\"M. Hubbell\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"3257323\",\"name\":\"J. Kepner\"},{\"authorId\":\"1983355\",\"name\":\"A. Kirby\"},{\"authorId\":\"1684116\",\"name\":\"P. Michaleas\"},{\"authorId\":\"3385550\",\"name\":\"Lauren Milechin\"},{\"authorId\":\"143913450\",\"name\":\"J. Mullen\"},{\"authorId\":\"2417672\",\"name\":\"A. Prout\"},{\"authorId\":\"144557576\",\"name\":\"A. Rosa\"},{\"authorId\":\"2097629\",\"name\":\"Albert Reuther\"},{\"authorId\":\"145378881\",\"name\":\"C. Yee\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":\"10.1109/HPEC43674.2020.9286249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"title\":\"Accuracy and Performance Comparison of Video Action Recognition Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"venue\":\"2020 IEEE High Performance Extreme Computing Conference (HPEC)\",\"year\":2020},{\"arxivId\":\"1904.01172\",\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1832b749528755dfcbe462717f4f5afc07243b8\",\"title\":\"Commonsense Reasoning for Natural Language Understanding: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b1832b749528755dfcbe462717f4f5afc07243b8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.01716\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"29905643\",\"name\":\"Fatih Murat Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"title\":\"Action Representation Using Classifier Decision Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2871170\",\"name\":\"Huifen Xia\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/ACCESS.2020.2986861\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"title\":\"A Survey on Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152341152\",\"name\":\"Saipriyati Singh\"},{\"authorId\":\"121493358\",\"name\":\"Baris Aksanli\"}],\"doi\":\"10.1109/SENSORS43011.2019.8956594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e57643c66bce01350b411bd17f53cd612cf0735\",\"title\":\"Detecting Multiple People with Low-Resolution Thermal Sensors in Smart Spaces\",\"url\":\"https://www.semanticscholar.org/paper/2e57643c66bce01350b411bd17f53cd612cf0735\",\"venue\":\"2019 IEEE SENSORS\",\"year\":2019},{\"arxivId\":\"1910.01286\",\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2019.00717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39623465df05ddf240bf900fed81fdf9fdad191d\",\"title\":\"Learning Temporal Action Proposals With Fewer Labels\",\"url\":\"https://www.semanticscholar.org/paper/39623465df05ddf240bf900fed81fdf9fdad191d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410106115\",\"name\":\"Tieu Binh Hoang\"},{\"authorId\":\"29543391\",\"name\":\"T. C. Ma\"},{\"authorId\":\"71752568\",\"name\":\"Sugimoto Akihiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"title\":\"Selecting active frames for action recognition with 3D convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"144350546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1007/978-3-030-00776-8_57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"title\":\"DT-3DResNet-LSTM: An Architecture for Temporal Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52132362\",\"name\":\"Saluky\"},{\"authorId\":\"2774694\",\"name\":\"S. Supangkat\"},{\"authorId\":\"9231742\",\"name\":\"Fetty Fitriyanti Lubis\"}],\"doi\":\"10.1109/ICTSS.2018.8550012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f495ba8926f65d578bdc0d3a636033c16e5eeb80\",\"title\":\"Moving Image Interpretation Models to Support City Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f495ba8926f65d578bdc0d3a636033c16e5eeb80\",\"venue\":\"2018 International Conference on ICT for Smart Society (ICISS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"47818608\",\"name\":\"Leilei Chen\"},{\"authorId\":\"152745066\",\"name\":\"Can-jin Wang\"},{\"authorId\":null,\"name\":\"Chen Wang\"},{\"authorId\":\"1732904\",\"name\":\"Haijing Liu\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d9448f6fa289b86b1c448882907332a0ce49376\",\"title\":\"Comprehensive Soccer Video Understanding: Towards Human-comparable Video Understanding System in Constrained Environment\",\"url\":\"https://www.semanticscholar.org/paper/0d9448f6fa289b86b1c448882907332a0ce49376\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49264448\",\"name\":\"Jiang He\"},{\"authorId\":\"48481808\",\"name\":\"Y. Song\"},{\"authorId\":\"28911396\",\"name\":\"H. Jiang\"}],\"doi\":\"10.1007/978-3-030-41404-7_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2c88ee0091e12d2f2a068de19a0a86c83702be0\",\"title\":\"Bi-direction Feature Pyramid Temporal Action Detection Network\",\"url\":\"https://www.semanticscholar.org/paper/c2c88ee0091e12d2f2a068de19a0a86c83702be0\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113727681\",\"name\":\"Haotao Wang\"},{\"authorId\":\"145287209\",\"name\":\"Z. Wu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad1480c694a57466a25d9d54671a67207fbd140b\",\"title\":\"Privacy-Preserving Deep Visual Recognition: An Adversarial Learning Framework and A New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/ad1480c694a57466a25d9d54671a67207fbd140b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"19301412\",\"name\":\"Weimian Li\"},{\"authorId\":\"3258842\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-319-64698-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"897da34bf6b69018fa725cad1e1b065370db2d21\",\"title\":\"Attention-Based Two-Phase Model for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/897da34bf6b69018fa725cad1e1b065370db2d21\",\"venue\":\"CAIP\",\"year\":2017},{\"arxivId\":\"1811.02765\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33018965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"title\":\"Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2318546\",\"name\":\"Shiping Wen\"},{\"authorId\":\"9252399\",\"name\":\"Guanghua Ren\"},{\"authorId\":\"48696229\",\"name\":\"Y. Cao\"},{\"authorId\":\"2619052\",\"name\":\"Zhenyuan Guo\"},{\"authorId\":\"145692431\",\"name\":\"Qiang Xiao\"},{\"authorId\":\"145043786\",\"name\":\"Z. Zeng\"},{\"authorId\":\"50592545\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/978-3-319-92537-0_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c1b14ebb101c349e23b4be1021d1b251b7deffd\",\"title\":\"WeiboCluster: An Event-Oriented Sina Weibo Dataset with Estimating Credit\",\"url\":\"https://www.semanticscholar.org/paper/1c1b14ebb101c349e23b4be1021d1b251b7deffd\",\"venue\":\"ISNN\",\"year\":2018},{\"arxivId\":\"1512.07155\",\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1016/j.patcog.2017.01.027\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"title\":\"Do less and achieve more: Training CNNs for action recognition utilizing action images from the Web\",\"url\":\"https://www.semanticscholar.org/paper/ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3452354\",\"name\":\"Caihong Yuan\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"8269333\",\"name\":\"Tianjiang Wang\"},{\"authorId\":\"145922230\",\"name\":\"Fang Liu\"},{\"authorId\":\"2037865\",\"name\":\"Zhiqiang Zhao\"},{\"authorId\":\"144734887\",\"name\":\"P. Feng\"},{\"authorId\":\"2217316\",\"name\":\"Jingjuan Guo\"}],\"doi\":\"10.1007/s11042-017-4896-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6448acca3bf4d14ad44756974a6486a317095a54\",\"title\":\"Deep multi-instance learning for end-to-end person re-identification\",\"url\":\"https://www.semanticscholar.org/paper/6448acca3bf4d14ad44756974a6486a317095a54\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1604.00427\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8926471921ff608f70c6c81777782974a91086ae\",\"title\":\"Leaving Some Stones Unturned: Dynamic Feature Prioritization for Activity Detection in Streaming Video\",\"url\":\"https://www.semanticscholar.org/paper/8926471921ff608f70c6c81777782974a91086ae\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.01326\",\"authors\":[{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"},{\"authorId\":\"9870507\",\"name\":\"R. Gade\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/CVPR42600.2020.01314\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"title\":\"A Context-Aware Loss Function for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.10141\",\"authors\":[{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"1645272447\",\"name\":\"Mor Shpigel\"},{\"authorId\":\"1408268488\",\"name\":\"Ophir Azulai\"},{\"authorId\":\"46189009\",\"name\":\"U. Barzelay\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8b7637b757133c1aa88403754bdc42e25ad3ab31\",\"title\":\"TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b7637b757133c1aa88403754bdc42e25ad3ab31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10531\",\"authors\":[{\"authorId\":\"2775025\",\"name\":\"Ruicong Xu\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"49051251\",\"name\":\"Jianfu Zhang\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6941\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b92762e958f1ddc712f1e1608a3cb3188720f977\",\"title\":\"A Proposal-based Approach for Activity Image-to-Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b92762e958f1ddc712f1e1608a3cb3188720f977\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1563634707\",\"name\":\"Noorhan Khaled\"},{\"authorId\":\"37370786\",\"name\":\"Mohammed Marey\"},{\"authorId\":\"9160196\",\"name\":\"M. Aref\"}],\"doi\":\"10.1109/ICICIS46948.2019.9014707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d502ee62d6a46520880ca360a374fdd393f3259b\",\"title\":\"Temporal Action Detection with Fused Two-Stream 3D Residual Neural Networks and Bi-Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/d502ee62d6a46520880ca360a374fdd393f3259b\",\"venue\":\"2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96066534\",\"name\":\"P. Joshi\"},{\"authorId\":\"51497543\",\"name\":\"Chitwan Saharia\"},{\"authorId\":\"1557378944\",\"name\":\"V. Singh\"},{\"authorId\":\"51267359\",\"name\":\"Digvijaysingh Gautam\"},{\"authorId\":\"145799547\",\"name\":\"Ganesh Ramakrishnan\"},{\"authorId\":\"1557645545\",\"name\":\"P. Jyothi\"}],\"doi\":\"10.1109/ICCVW.2019.00459\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"523e8f226cc75a8fa5597aeb410e9236efc02f5d\",\"title\":\"A Tale of Two Modalities for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/523e8f226cc75a8fa5597aeb410e9236efc02f5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50363618\",\"name\":\"Y. Long\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79554caf84ce3b7fb5434737505ba6a7549189b2\",\"title\":\"Zero-shot image classification\",\"url\":\"https://www.semanticscholar.org/paper/79554caf84ce3b7fb5434737505ba6a7549189b2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1612.01175\",\"authors\":[{\"authorId\":\"8140754\",\"name\":\"Benjamin Eysenbach\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fac17d4bb7268bbf33290de2915c33e6e57647da\",\"title\":\"Who is Mistaken?\",\"url\":\"https://www.semanticscholar.org/paper/fac17d4bb7268bbf33290de2915c33e6e57647da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1802.06822\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01219-9_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"title\":\"Online Detection of Action Start in Untrimmed, Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"145779317\",\"name\":\"R. Gasser\"},{\"authorId\":\"1693655\",\"name\":\"Jakub Loko\\u010d\"},{\"authorId\":\"35537256\",\"name\":\"W. Bailer\"},{\"authorId\":\"1937120\",\"name\":\"K. Sch\\u00f6ffmann\"},{\"authorId\":\"2251616\",\"name\":\"Bernd M\\u00fcnzer\"},{\"authorId\":\"40037607\",\"name\":\"T. Soucek\"},{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1982596\",\"name\":\"Paolo Bolettieri\"},{\"authorId\":\"3403185\",\"name\":\"A. Leibetseder\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"}],\"doi\":\"10.1109/TMM.2020.2980944\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67ea56e031a77eed8214bede62c52004e201cb9f\",\"title\":\"Interactive Video Retrieval in the Age of Deep Learning \\u2013 Detailed Evaluation of VBS 2019\",\"url\":\"https://www.semanticscholar.org/paper/67ea56e031a77eed8214bede62c52004e201cb9f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44e8ddac792f35105dd4db176345515f531a0b71\",\"title\":\"Bottom-Up Temporal Action Localization with Mutual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/44e8ddac792f35105dd4db176345515f531a0b71\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410849045\",\"name\":\"\\u00d6zge Yal\\u00e7\\u0131nkaya\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75a5d5b5b47aec2a7423632fa8a6efffdf320f46\",\"title\":\"Prototypes : exemplar based video representation\",\"url\":\"https://www.semanticscholar.org/paper/75a5d5b5b47aec2a7423632fa8a6efffdf320f46\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"152187759\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"title\":\"Dataset Paper Videos Hours Classes Description Charades Hollywood in Homes : Crowdsourcing Data Collection for Activity Understanding 9848\",\"url\":\"https://www.semanticscholar.org/paper/aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1706.00699\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"Alexander Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7577a1ddf9195513a5c976887ad806d1386bb1e9\",\"title\":\"Temporal Action Labeling using Action Sets\",\"url\":\"https://www.semanticscholar.org/paper/7577a1ddf9195513a5c976887ad806d1386bb1e9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255213\",\"name\":\"Z. Zhang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"47337540\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"2597292\",\"name\":\"Chuanqi Tan\"}],\"doi\":\"10.1109/TCSVT.2019.2936526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"title\":\"Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3436875\",\"name\":\"Omar ElHarrouss\"},{\"authorId\":\"2380070\",\"name\":\"Noor Almaadeed\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-Maadeed\"}],\"doi\":\"10.1007/978-981-15-0637-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"title\":\"MHAD: Multi-Human Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"venue\":\"ICICT\",\"year\":2019},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152808637\",\"name\":\"M. Wang\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":\"66947096\",\"name\":\"Hu Shi-min\"},{\"authorId\":\"151225728\",\"name\":\"Shing-Tung Yau\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84d6edefee7d491b890f5df133e5ec7006d7481f\",\"title\":\"Write-A-Video: Computational Video Montage from Themed Text\",\"url\":\"https://www.semanticscholar.org/paper/84d6edefee7d491b890f5df133e5ec7006d7481f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.06845\",\"authors\":[{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"38896301\",\"name\":\"G. Kundu\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1007/978-3-030-58548-8_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"84d710727a9a5775ab4691a969f52bc3062325e2\",\"title\":\"SF-Net: Single-Frame Supervision for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/84d710727a9a5775ab4691a969f52bc3062325e2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"41076692\",\"name\":\"King Abdullah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a1eaf6c39b147b0c25af180c75de60728bd5b05\",\"title\":\"Surfing Start : Unknown End : Unknown ! Input : Temporal Action Localization with Weak Supervision ! Background ! Pseudo Ground Truth ! !\",\"url\":\"https://www.semanticscholar.org/paper/0a1eaf6c39b147b0c25af180c75de60728bd5b05\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.02696\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.235\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45f858f9e8d7713f60f52618e54089ba68dfcd6d\",\"title\":\"What Actions are Needed for Understanding Human Actions in Videos?\",\"url\":\"https://www.semanticscholar.org/paper/45f858f9e8d7713f60f52618e54089ba68dfcd6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51023221\",\"name\":\"Daochang Liu\"},{\"authorId\":\"145427096\",\"name\":\"T. Jiang\"},{\"authorId\":\"26960212\",\"name\":\"Yizhou Wang\"}],\"doi\":\"10.1109/CVPR.2019.00139\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1976a516fda5e0e164c5ae7d7ad89dd09387116\",\"title\":\"Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e1976a516fda5e0e164c5ae7d7ad89dd09387116\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500430677\",\"name\":\"Shengbo Wang\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49679333\",\"name\":\"C. Ma\"},{\"authorId\":\"49141021\",\"name\":\"M. Li\"}],\"doi\":\"10.1109/CAC48633.2019.8996591\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8167063e02c8c46b6f1b93ac8dea0a70dd10a09b\",\"title\":\"Boundary Sensitive and Category Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/8167063e02c8c46b6f1b93ac8dea0a70dd10a09b\",\"venue\":\"2019 Chinese Automation Congress (CAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.02755\",\"authors\":[{\"authorId\":\"3288111\",\"name\":\"S. Ghosh\"},{\"authorId\":\"50714560\",\"name\":\"A. Agarwal\"},{\"authorId\":\"27456119\",\"name\":\"Zarana Parekh\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/N19-1198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"title\":\"ExCL: Extractive Clip Localization Using Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145987553\",\"name\":\"F. Li\"},{\"authorId\":\"3223020\",\"name\":\"Xin Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0b58740e78ca06cc8c2963720e1657d012d9922\",\"title\":\"Multi-modal fusion network based on relation-aware pyramid network for temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/b0b58740e78ca06cc8c2963720e1657d012d9922\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.08333\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01270-0_10\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca\",\"title\":\"AutoLoc: Weakly-Supervised Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.08723\",\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb08f679f2cb29c7aa972d66fe9e9996c8dfae00\",\"title\":\"Action Understanding with Multiple Classes of Actors\",\"url\":\"https://www.semanticscholar.org/paper/cb08f679f2cb29c7aa972d66fe9e9996c8dfae00\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"1719062\",\"name\":\"J. R. Kender\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"823e726283792ddb457c82c84c236be59f06aab4\",\"title\":\"Visual Feature Extractor ( Inception-ResNet ) Text Feature Extractor ( fastText ) p : I , Tc c c Image-Text Sequence of culture c Speech Recognition Frame Decomposition fcv fcl\",\"url\":\"https://www.semanticscholar.org/paper/823e726283792ddb457c82c84c236be59f06aab4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398197\",\"name\":\"Yuxiang Liu\"},{\"authorId\":\"2284679\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"46641989\",\"name\":\"W. Liu\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ef6dd6ead099d35ba0af21cf1056e2d04f771ed\",\"title\":\"Multi-granularity Generator for Temporal Action Proposal \\u2013 Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/3ef6dd6ead099d35ba0af21cf1056e2d04f771ed\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.05014\",\"authors\":[{\"authorId\":\"47244850\",\"name\":\"Rongcheng Lin\"},{\"authorId\":\"144033366\",\"name\":\"J. Xiao\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1007/978-3-030-11018-5_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"919548553251d5cf92a2cb50e87d29b862613bb5\",\"title\":\"NeXtVLAD: An Efficient Neural Network to Aggregate Frame-level Features for Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/919548553251d5cf92a2cb50e87d29b862613bb5\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3132847.3133030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77e545ee564b0d68dbaa50160996adf63aaf6d99\",\"title\":\"Jointly Modeling Static Visual Appearance and Temporal Pattern for Unsupervised Video Hashing\",\"url\":\"https://www.semanticscholar.org/paper/77e545ee564b0d68dbaa50160996adf63aaf6d99\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"46970799\",\"name\":\"Y. Song\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"}],\"doi\":\"10.1007/978-3-030-00764-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2036b394a5dff537df48d6db62a0d61491c92046\",\"title\":\"iMakeup: Makeup Instructional Video Dataset for Fine-Grained Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2036b394a5dff537df48d6db62a0d61491c92046\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1910.09505\",\"authors\":[{\"authorId\":\"82449565\",\"name\":\"F. Sala\"},{\"authorId\":\"1782486\",\"name\":\"P. Varma\"},{\"authorId\":\"144428045\",\"name\":\"Jason A. Fries\"},{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"2389237\",\"name\":\"Shiori Sagawa\"},{\"authorId\":\"122333481\",\"name\":\"Saelig Khattar\"},{\"authorId\":\"98536774\",\"name\":\"Ashwini Ramamoorthy\"},{\"authorId\":\"144293517\",\"name\":\"Ke Xiao\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"},{\"authorId\":\"153670513\",\"name\":\"J. Priest\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2effb581419f8eb6701e88c8cd8bad15f57b9fa\",\"title\":\"Multi-Resolution Weak Supervision for Sequential Data\",\"url\":\"https://www.semanticscholar.org/paper/f2effb581419f8eb6701e88c8cd8bad15f57b9fa\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152808637\",\"name\":\"M. Wang\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":\"153056077\",\"name\":\"S. Hu\"},{\"authorId\":\"151225728\",\"name\":\"Shing-Tung Yau\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"}],\"doi\":\"10.1145/3355089.3356520\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0370796679da520b2491dae7cf288c3c2fbd54e5\",\"title\":\"Write-a-video\",\"url\":\"https://www.semanticscholar.org/paper/0370796679da520b2491dae7cf288c3c2fbd54e5\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145795309\",\"name\":\"K. Shi\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICME.2018.8486530\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"182b627d73de02764498c500aa7fb56cbeb1a424\",\"title\":\"Entity Competition Network for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/182b627d73de02764498c500aa7fb56cbeb1a424\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"2012.06440\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2951229\",\"name\":\"Hisham Cholakkal\"},{\"authorId\":\"145684318\",\"name\":\"Munawar Hayat\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43166698fd0fc13c1fe70a1f6249413559a9dcf3\",\"title\":\"D2-Net: Weakly-Supervised Action Localization via Discriminative Embeddings and Denoised Activations\",\"url\":\"https://www.semanticscholar.org/paper/43166698fd0fc13c1fe70a1f6249413559a9dcf3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.11206\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1109/cvpr42600.2020.00100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"title\":\"Oops! Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"49418159\",\"name\":\"Y. Wang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/TCSVT.2019.2894161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c75881e226b5d57e1c5570bf8e51a93bdada9e8\",\"title\":\"stagNet: An Attentive Semantic RNN for Group Activity and Individual Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c75881e226b5d57e1c5570bf8e51a93bdada9e8\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1806.02964\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"3004751\",\"name\":\"Chongjing Wang\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-030-01225-0_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49e2b4db35a408e91353578764be9085ac1210da\",\"title\":\"BSN: Boundary Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/49e2b4db35a408e91353578764be9085ac1210da\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1662772707\",\"name\":\"Xue Lin\"},{\"authorId\":\"1380876608\",\"name\":\"Qi Zou\"},{\"authorId\":\"50180715\",\"name\":\"Xixia Xu\"}],\"doi\":\"10.24963/ijcai.2020/154\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3b24b7fac0a768aefb9a6ace96257b82e969ee9\",\"title\":\"Action-Guided Attention Mining and Relation Reasoning Network for Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/b3b24b7fac0a768aefb9a6ace96257b82e969ee9\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2003.10606\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR42600.2020.01043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"title\":\"Video Object Grounding Using Semantic Roles in Language Description\",\"url\":\"https://www.semanticscholar.org/paper/70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.05623\",\"authors\":[{\"authorId\":\"50677284\",\"name\":\"C. Roig\"},{\"authorId\":\"2023762\",\"name\":\"D. Varas\"},{\"authorId\":\"8136555\",\"name\":\"Issey Masuda\"},{\"authorId\":\"35528008\",\"name\":\"Juan Carlos Riveiro\"},{\"authorId\":\"2429242\",\"name\":\"Elisenda Bou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba13e430fd90d2f4160a88ab8b8b8f1d62c1df38\",\"title\":\"Unsupervised Multi-label Dataset Generation from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/ba13e430fd90d2f4160a88ab8b8b8f1d62c1df38\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39691613\",\"name\":\"H. Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2018.00175\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"title\":\"Instance-Aware Detailed Action Labeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2006.03732\",\"authors\":[{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"1396536560\",\"name\":\"Ran Xu\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ae911d5c92fdaece8171f5db8b08e083b7b8f29\",\"title\":\"WOAD: Weakly Supervised Online Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/5ae911d5c92fdaece8171f5db8b08e083b7b8f29\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.11189\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"145681036\",\"name\":\"Xiao Tan\"},{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"39826117\",\"name\":\"Kaiyu Yue\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1007/978-3-030-01228-1_9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1102250a0fae62263979b32ad3c25749be9bca6b\",\"title\":\"Fine-Grained Video Categorization with Redundancy Reduction Attention\",\"url\":\"https://www.semanticscholar.org/paper/1102250a0fae62263979b32ad3c25749be9bca6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22604360\",\"name\":\"Gengshen Wu\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"144073923\",\"name\":\"Li Liu\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"143710669\",\"name\":\"Qiang Ni\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2882155\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2110dd412aa5a0ace530cd9aef1464e8682a71c1\",\"title\":\"Unsupervised Deep Video Hashing via Balanced Code for Large-Scale Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2110dd412aa5a0ace530cd9aef1464e8682a71c1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2003.00832\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"50031872\",\"name\":\"Yunsheng Ma\"},{\"authorId\":\"37989322\",\"name\":\"Y. Gu\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"151185822\",\"name\":\"Runbo Hu\"},{\"authorId\":\"144626314\",\"name\":\"Hua Chai\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1609/AAAI.V34I01.5364\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"title\":\"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.07375\",\"authors\":[{\"authorId\":\"145551068\",\"name\":\"Peng Sun\"},{\"authorId\":\"2008295118\",\"name\":\"G. Draughon\"},{\"authorId\":\"153789973\",\"name\":\"J. Lynch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fef348de8b19c2be0e2d34e544e8b94805892be\",\"title\":\"An Autonomous Approach to Measure Social Distances and Hygienic Practices during COVID-19 Pandemic in Public Open Spaces\",\"url\":\"https://www.semanticscholar.org/paper/0fef348de8b19c2be0e2d34e544e8b94805892be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.01461\",\"authors\":[{\"authorId\":\"101786574\",\"name\":\"Peitin Sun\"},{\"authorId\":\"151185786\",\"name\":\"R. Hou\"},{\"authorId\":\"153789973\",\"name\":\"J. Lynch\"}],\"doi\":\"10.1109/WACV45572.2020.9093336\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60d1308eeee57529931319fb3cfc90f5c477d607\",\"title\":\"Measuring the Utilization of Public Open Spaces by Deep Learning: a Benchmark Study at the Detroit Riverfront\",\"url\":\"https://www.semanticscholar.org/paper/60d1308eeee57529931319fb3cfc90f5c477d607\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.00163\",\"authors\":[{\"authorId\":\"1603002784\",\"name\":\"Zhekun Luo\"},{\"authorId\":\"3493957\",\"name\":\"Devin Guillory\"},{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"4505317\",\"name\":\"W. Ke\"},{\"authorId\":\"1510781142\",\"name\":\"Fang Wan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"}],\"doi\":\"10.1007/978-3-030-58526-6_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a84514fc6b08b93e51432d0539cae4ab7692cc56\",\"title\":\"Weakly-Supervised Action Localization with Expectation-Maximization Multi-Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/a84514fc6b08b93e51432d0539cae4ab7692cc56\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04950\",\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"35462690\",\"name\":\"Jungwon Lee\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d52448d649ce5d35189abdeecdc62db647b4246\",\"title\":\"HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0d52448d649ce5d35189abdeecdc62db647b4246\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.11524\",\"authors\":[{\"authorId\":\"46398922\",\"name\":\"Y. Liu\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.00372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"title\":\"Multi-Granularity Generator for Temporal Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143792021\",\"name\":\"Terrence Adams\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1c119361952120507d010b96d53ee8bee13c4b7\",\"title\":\"Description of a Tracking Metric Inspired by KL-divergence\",\"url\":\"https://www.semanticscholar.org/paper/c1c119361952120507d010b96d53ee8bee13c4b7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.11147\",\"authors\":[{\"authorId\":\"40897654\",\"name\":\"Abhishek Venkataraman\"},{\"authorId\":\"145141012\",\"name\":\"Brent Griffin\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce3edf04c9f0c9da462832cbf8c5a1982e3e6bf8\",\"title\":\"Learning Kinematic Descriptions using SPARE: Simulated and Physical ARticulated Extendable dataset\",\"url\":\"https://www.semanticscholar.org/paper/ce3edf04c9f0c9da462832cbf8c5a1982e3e6bf8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.10000\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1995717\",\"name\":\"Bingyi Kang\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"12479dcd4808b96d6a149919183ef15afcf6a89e\",\"title\":\"Similarity R-C3D for Few-shot Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/12479dcd4808b96d6a149919183ef15afcf6a89e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"Shiwen Zhang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a19185b1cbb6588682318bb9ce649a611e889162\",\"title\":\"VIDEO-LEVEL REPRESENTATION LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/a19185b1cbb6588682318bb9ce649a611e889162\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.04837\",\"authors\":[{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cc4a4bc7f9a989130d5ac129d24426a444fe161\",\"title\":\"Recent Advances in Zero-shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cc4a4bc7f9a989130d5ac129d24426a444fe161\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"145429878\",\"name\":\"Hui Yu\"},{\"authorId\":\"47591280\",\"name\":\"Feiyu Chen\"},{\"authorId\":\"144485153\",\"name\":\"D. Yang\"}],\"doi\":\"10.1109/LSP.2020.3018914\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc27658c8db517561c77de3a8cd2cdee08a547bf\",\"title\":\"Spatial Enhancement and Temporal Constraint for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/dc27658c8db517561c77de3a8cd2cdee08a547bf\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"1611.09502\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.435\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"title\":\"Deep Quantization: Encoding Convolutional Activations with Deep Generative Model\",\"url\":\"https://www.semanticscholar.org/paper/ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.00803\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef70b917ef25646d7eb919752448cfbc028d861a\",\"title\":\"Aggregating Frame-level Features for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ef70b917ef25646d7eb919752448cfbc028d861a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/2964284.2967196\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"357a65432aecd0565df9dc9b8e013dd46d8d184b\",\"title\":\"Emotion in Context: Deep Semantic Feature Fusion for Video Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/357a65432aecd0565df9dc9b8e013dd46d8d184b\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1912.01127\",\"authors\":[{\"authorId\":\"48511110\",\"name\":\"Tianqi Liu\"},{\"authorId\":\"1441128337\",\"name\":\"Qizhan Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7706ed62e51487ee1fab56f932f5274bdeaea171\",\"title\":\"BERT for Large-scale Video Segment Classification with Test-time Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/7706ed62e51487ee1fab56f932f5274bdeaea171\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.09041\",\"authors\":[{\"authorId\":\"153198570\",\"name\":\"Guoyun Tu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"11004839\",\"name\":\"Jiarui Gao\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TMM.2019.2922129\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41b76703b03ecb40dbcc00e9fbf6a73b0b808778\",\"title\":\"A Multi-Task Neural Approach for Emotion Attribution, Classification, and Summarization\",\"url\":\"https://www.semanticscholar.org/paper/41b76703b03ecb40dbcc00e9fbf6a73b0b808778\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443785630\",\"name\":\"Chayanin Tongphasook\"},{\"authorId\":\"2871912\",\"name\":\"C. Chantrapornchai\"}],\"doi\":\"10.1109/INCIT.2019.8912096\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80f3fb895f4410ec5cd1f432edbc2504ccf0b961\",\"title\":\"Two Recognition Models for Thai Dancing Data Set\",\"url\":\"https://www.semanticscholar.org/paper/80f3fb895f4410ec5cd1f432edbc2504ccf0b961\",\"venue\":\"2019 4th International Conference on Information Technology (InCIT)\",\"year\":2019},{\"arxivId\":\"1710.08011\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"35163655\",\"name\":\"K. Hata\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba11083602568bbc2514c0905e0d831a65c2af6e\",\"title\":\"ActivityNet Challenge 2017 Summary\",\"url\":\"https://www.semanticscholar.org/paper/ba11083602568bbc2514c0905e0d831a65c2af6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1607.08584\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-319-46493-0_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18994755100686833b92c34af8ec1b35934e23d6\",\"title\":\"Connectionist Temporal Modeling for Weakly Supervised Action Labeling\",\"url\":\"https://www.semanticscholar.org/paper/18994755100686833b92c34af8ec1b35934e23d6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153146302\",\"name\":\"P. Sun\"},{\"authorId\":\"151185786\",\"name\":\"R. Hou\"},{\"authorId\":\"2780364\",\"name\":\"J. Lynch\"}],\"doi\":\"10.1145/3360773.3360880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19766f24e69cf51e17e242b8ce283cd2f07bb2c1\",\"title\":\"A Computer Vision Framework for Human User Sensing in Public Open Spaces\",\"url\":\"https://www.semanticscholar.org/paper/19766f24e69cf51e17e242b8ce283cd2f07bb2c1\",\"venue\":\"DFHS@BuildSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2019.00400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"title\":\"Weakly Supervised Temporal Action Localization Through Contrast Based Evaluation Networks\",\"url\":\"https://www.semanticscholar.org/paper/87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1908.00707\",\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"9693996\",\"name\":\"Liangfeng Zheng\"},{\"authorId\":\"144654776\",\"name\":\"Kun Bai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/icme46284.2020.9102850\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"title\":\"Scale Matters: Temporal Scale Aggregation Network For Precise Action Localization In Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41172535\",\"name\":\"Che Sun\"},{\"authorId\":\"40506635\",\"name\":\"Hao Song\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"40dd38de26834c7d6da8607c6d55a52d0db9e2ba\",\"title\":\"Exploiting Informative Video Segments for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/40dd38de26834c7d6da8607c6d55a52d0db9e2ba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.11792\",\"authors\":[{\"authorId\":\"1382655067\",\"name\":\"Roberto Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"1752792912\",\"name\":\"Mihir Patel\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"},{\"authorId\":\"51257737\",\"name\":\"Abhijeet Shenoi\"},{\"authorId\":\"39813007\",\"name\":\"JunYoung Gwak\"},{\"authorId\":\"13941540\",\"name\":\"Eric H. Frankel\"},{\"authorId\":\"145759966\",\"name\":\"Amir Sadeghian\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11f3b408612992ff1c769710f558e809d2758e2c\",\"title\":\"JRDB: A Dataset and Benchmark of Egocentric Visual Perception for Navigation in Human Environments.\",\"url\":\"https://www.semanticscholar.org/paper/11f3b408612992ff1c769710f558e809d2758e2c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2016.339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9671ec394ec374021702642713aa634b8556312\",\"title\":\"Harnessing Object and Scene Semantics for Large-Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9671ec394ec374021702642713aa634b8556312\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73354715\",\"name\":\"Francesc Sastre Cabot\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"827699fc9b989d340784f23e49c598da42439f87\",\"title\":\"Scalability Study of Deep Learning Algorithms in High Performance Computer Infrastructures\",\"url\":\"https://www.semanticscholar.org/paper/827699fc9b989d340784f23e49c598da42439f87\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13460802\",\"name\":\"Yaning Tan\"},{\"authorId\":\"2169519\",\"name\":\"Xinyan Yang\"},{\"authorId\":\"50336438\",\"name\":\"Tianyi Feng\"},{\"authorId\":\"49659000\",\"name\":\"Xin Xiang\"},{\"authorId\":\"46583513\",\"name\":\"Jianbiao Wang\"},{\"authorId\":\"46269770\",\"name\":\"Long Ye\"}],\"doi\":\"10.1109/icis46139.2019.8940339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49671a30b401d47e4949df17630bf6eb5e191068\",\"title\":\"M2-VISD:A Visual Intelligence Evaluation Dataset Based on Virtual Scene*\",\"url\":\"https://www.semanticscholar.org/paper/49671a30b401d47e4949df17630bf6eb5e191068\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":\"2008.06285\",\"authors\":[{\"authorId\":\"80741463\",\"name\":\"Shenyu Zhang\"},{\"authorId\":\"35460116\",\"name\":\"Zichen Zhu\"},{\"authorId\":\"119896097\",\"name\":\"Qingquan Bao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10f380b227bb838d986e1955a6fa1053e6cc275e\",\"title\":\"Rb-PaStaNet: A Few-Shot Human-Object Interaction Detection Based on Rules and Part States\",\"url\":\"https://www.semanticscholar.org/paper/10f380b227bb838d986e1955a6fa1053e6cc275e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.03107\",\"authors\":[{\"authorId\":\"7821695\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf1a4818504c6d62ac7c030003946dcfa6cd6d33\",\"title\":\"Cricket stroke extraction: Towards creation of a large-scale cricket actions dataset\",\"url\":\"https://www.semanticscholar.org/paper/cf1a4818504c6d62ac7c030003946dcfa6cd6d33\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143718461\",\"name\":\"M. E. Hajji\"},{\"authorId\":\"3403642\",\"name\":\"Morgane Daniel\"},{\"authorId\":\"1392826929\",\"name\":\"Lucile Gelin\"}],\"doi\":\"10.21437/slate.2019-21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26cf2987258bb096f4854d1e379219e8ebf400a2\",\"title\":\"Transfer Learning based Audio Classification for a noisy and speechless recordings detection task, in a classroom context\",\"url\":\"https://www.semanticscholar.org/paper/26cf2987258bb096f4854d1e379219e8ebf400a2\",\"venue\":\"SLaTE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50760128\",\"name\":\"Sandy Ardianto\"},{\"authorId\":\"144922393\",\"name\":\"H. Hang\"}],\"doi\":\"10.23919/APSIPA.2018.8659539\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"19ee845f49ed8ddbcf08bf7b53c2ac05a3649500\",\"title\":\"Multi-View and Multi-Modal Action Recognition with Learned Fusion\",\"url\":\"https://www.semanticscholar.org/paper/19ee845f49ed8ddbcf08bf7b53c2ac05a3649500\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"},{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"81752605\",\"name\":\"Jiao-fen Li\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"}],\"doi\":\"10.1109/TNNLS.2018.2886008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4d4b6c67c05de1d31990076a5142719cd1ff3f6\",\"title\":\"Semisupervised Discriminant Multimanifold Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d4b6c67c05de1d31990076a5142719cd1ff3f6\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350413\",\"name\":\"Zijian Kang\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-19823-7_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"title\":\"Extracting Action Sensitive Features to Facilitate Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"venue\":\"AIAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216212\",\"name\":\"Vladyslav Sydorov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32045707a041e18f7afd2b4e7024f9b0dad75890\",\"title\":\"Focused Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32045707a041e18f7afd2b4e7024f9b0dad75890\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1704.04671\",\"authors\":[{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/CVPR.2017.342\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"60ca4a90d751e315a2b143289a5c54488e324949\",\"title\":\"Temporal Action Localization by Structured Maximal Sums\",\"url\":\"https://www.semanticscholar.org/paper/60ca4a90d751e315a2b143289a5c54488e324949\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50754085\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":\"10.1109/cvpr42600.2020.01254\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1a780c6219996c8481c117056efcf071cbfbd15\",\"title\":\"Screencast Tutorial Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b1a780c6219996c8481c117056efcf071cbfbd15\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.01598\",\"authors\":[{\"authorId\":\"151504088\",\"name\":\"X. Ding\"},{\"authorId\":\"151488319\",\"name\":\"N. Wang\"},{\"authorId\":\"49779747\",\"name\":\"Xinbo Gao\"},{\"authorId\":\"1492114961\",\"name\":\"Jie Li\"},{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"121698214\",\"name\":\"Tongliang Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"title\":\"Weakly Supervised Temporal Action Localization with Segment-Level Labels\",\"url\":\"https://www.semanticscholar.org/paper/5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"title\":\"Unseen Action Recognition with Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.04231\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"title\":\"Relational Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"49404404\",\"name\":\"Heng Li\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"},{\"authorId\":\"2740879\",\"name\":\"Y. Yu\"},{\"authorId\":\"30963734\",\"name\":\"Xincong Yang\"},{\"authorId\":\"51029695\",\"name\":\"Ting Huang\"}],\"doi\":\"10.1016/J.AUTCON.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9384eb2b25b939d83b81a618abfc9de686fe5ec5\",\"title\":\"Towards efficient and objective work sampling: Recognizing workers' activities in site surveillance videos with two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/9384eb2b25b939d83b81a618abfc9de686fe5ec5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.04430\",\"authors\":[{\"authorId\":\"119352476\",\"name\":\"M. M. K. Moghaddam\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"title\":\"Follow the Attention: Combining Partial Pose and Object Motion for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.09392\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TPAMI.2020.2980824\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"title\":\"Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2007.09883\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1768672172\",\"name\":\"Zhenyu Jiang\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"title\":\"Complementary Boundary Generator with Scale-Invariant Relation Modeling for Temporal Action Localization: Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.00097\",\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"title\":\"Budget-Aware Activity Detection with A Recurrent Policy Network\",\"url\":\"https://www.semanticscholar.org/paper/11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3394380\",\"name\":\"F. Scheidegger\"},{\"authorId\":\"1701257\",\"name\":\"L. Cavigelli\"},{\"authorId\":\"144370502\",\"name\":\"M. Schaffner\"},{\"authorId\":\"2535792\",\"name\":\"A. C. I. Malossi\"},{\"authorId\":\"48268669\",\"name\":\"C. Bekas\"},{\"authorId\":\"1710649\",\"name\":\"L. Benini\"}],\"doi\":\"10.3929/ETHZ-B-000201545\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dded0f6aa38419c177a57194961469cfdee57ba\",\"title\":\"Impact of temporal subsampling on accuracy and performance in practical video classification\",\"url\":\"https://www.semanticscholar.org/paper/1dded0f6aa38419c177a57194961469cfdee57ba\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1507.05738\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"47243342\",\"name\":\"N. Jin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-017-1013-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"title\":\"Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1830456822\",\"name\":\"R. Lang\"},{\"authorId\":\"89662118\",\"name\":\"Xiaosu Zhu\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3397271.3401122\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7066512f40da8bdf61a8165dd08177932b9605be\",\"title\":\"3D Self-Attention for Unsupervised Video Quantization\",\"url\":\"https://www.semanticscholar.org/paper/7066512f40da8bdf61a8165dd08177932b9605be\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"1912.00215\",\"authors\":[{\"authorId\":\"47267576\",\"name\":\"Cinjon Resnick\"},{\"authorId\":\"51126679\",\"name\":\"Zeping Zhan\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"29b2518305a4a1726fb60f2e9448fe15f4808800\",\"title\":\"Probing the State of the Art: A Critical Look at Visual Representation Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/29b2518305a4a1726fb60f2e9448fe15f4808800\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91999133\",\"name\":\"Ji-Hwan Kim\"},{\"authorId\":\"3247148\",\"name\":\"Jae-Pil Heo\"}],\"doi\":\"10.1109/ACCESS.2019.2946898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1db07ce91065594751cd51d31f086bc02d42968\",\"title\":\"Learning Coarse and Fine Features for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f1db07ce91065594751cd51d31f086bc02d42968\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"1478185914\",\"name\":\"Zehan Song\"},{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/TIP.2020.2963950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"title\":\"Open-Ended Video Question Answering via Multi-Modal Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tian Wang\"},{\"authorId\":null,\"name\":\"Shiye Lei\"},{\"authorId\":\"116503541\",\"name\":\"Youyou Jiang\"},{\"authorId\":\"97207595\",\"name\":\"Zihang Deng\"},{\"authorId\":null,\"name\":\"Xin Su\"},{\"authorId\":\"102633245\",\"name\":\"Chang Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cc3947038142ccb82ff7c2e546d61c927371036\",\"title\":\"A high performance computing method for accelerating temporal action proposal generation\",\"url\":\"https://www.semanticscholar.org/paper/0cc3947038142ccb82ff7c2e546d61c927371036\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TIP.2019.2922108\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ff4f13d4973cfe74f8ac7ef8384548c22284011e\",\"title\":\"Breaking Winner-Takes-All: Iterative-Winners-Out Networks for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/ff4f13d4973cfe74f8ac7ef8384548c22284011e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1704.03503\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"48559935\",\"name\":\"Zaikun Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86d0ab0e55a3e598637b56acd59369ec74cd852b\",\"title\":\"UC Merced Submission to the ActivityNet Challenge 2016\",\"url\":\"https://www.semanticscholar.org/paper/86d0ab0e55a3e598637b56acd59369ec74cd852b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09530\",\"authors\":[{\"authorId\":\"153769937\",\"name\":\"H. Akbari\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"120157163\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"37409035\",\"name\":\"R. Fernandez\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"title\":\"Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.07793\",\"authors\":[{\"authorId\":\"145724888\",\"name\":\"Ashraful Islam\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1109/WACV45572.2020.9093620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145c15e10967f9eb598b62ab547312571ec3ac3c\",\"title\":\"Weakly Supervised Temporal Action Localization Using Deep Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/145c15e10967f9eb598b62ab547312571ec3ac3c\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"2765994\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"246c1e49f956063e28ba7941b6cc6242d753d303\",\"title\":\"CNN Activity : Tumbling Complete Tumbling ? Yes\",\"url\":\"https://www.semanticscholar.org/paper/246c1e49f956063e28ba7941b6cc6242d753d303\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"3451334\",\"name\":\"Michelle Guo\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"24126456\",\"name\":\"Rishab Mehra\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3225040\",\"name\":\"N. L. Downing\"},{\"authorId\":\"13454501\",\"name\":\"Francesca Salipur\"},{\"authorId\":\"50165568\",\"name\":\"Jeffrey Jopling\"},{\"authorId\":\"35678076\",\"name\":\"Brian Campbell\"},{\"authorId\":\"6535683\",\"name\":\"K. Deru\"},{\"authorId\":\"2066361\",\"name\":\"W. Beninati\"},{\"authorId\":\"46802048\",\"name\":\"A. Milstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0ffc8feb93f0c3240bcdf155e665009276f75d6\",\"title\":\"D Point Cloud-Based Visual Prediction of ICU Mobility Care Activities 3 D Point Cloud-Based Visual Prediction of ICU Mobility Care Activities\",\"url\":\"https://www.semanticscholar.org/paper/a0ffc8feb93f0c3240bcdf155e665009276f75d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121533\",\"name\":\"Bokyung Lee\"},{\"authorId\":\"65756158\",\"name\":\"M. Lee\"},{\"authorId\":\"153596089\",\"name\":\"P. Zhang\"},{\"authorId\":\"49276610\",\"name\":\"A. Tessier\"},{\"authorId\":\"50724174\",\"name\":\"A. Khan\"}],\"doi\":\"10.1145/3341162.3343807\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"92158b4105cd74064cf4333b137f2e37be293249\",\"title\":\"Semantic human activity annotation tool using skeletonized surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/92158b4105cd74064cf4333b137f2e37be293249\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2019},{\"arxivId\":\"1807.04821\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-01216-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a52d7c53bb0745994e476079bbdea8b8577582a3\",\"title\":\"CTAP: Complementary Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/a52d7c53bb0745994e476079bbdea8b8577582a3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.04236\",\"authors\":[{\"authorId\":\"41079205\",\"name\":\"Oana Ignat\"},{\"authorId\":\"8003011\",\"name\":\"Laura Burdick\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.18653/v1/P19-1643\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fe96f493334987589f8ccd55f2d1209df258449\",\"title\":\"Identifying Visible Actions in Lifestyle Vlogs\",\"url\":\"https://www.semanticscholar.org/paper/0fe96f493334987589f8ccd55f2d1209df258449\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1904.00227\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34a07e2867c0be481a3fdd9ea43b608c3dc62a5b\",\"title\":\"RefineLoc: Iterative Refinement for Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/34a07e2867c0be481a3fdd9ea43b608c3dc62a5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"47469967\",\"name\":\"Jianwu Fang\"},{\"authorId\":\"48754122\",\"name\":\"P. Zhang\"}],\"doi\":\"10.1007/S11633-018-1126-Y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"171b81fda05c90384246a28bb0831c9e6b0ce10b\",\"title\":\"A Survey of Scene Understanding by Event Reasoning in Autonomous Driving\",\"url\":\"https://www.semanticscholar.org/paper/171b81fda05c90384246a28bb0831c9e6b0ce10b\",\"venue\":\"Int. J. Autom. Comput.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3452475\",\"name\":\"Jiawei Jiang\"},{\"authorId\":\"8230405\",\"name\":\"Y. Tong\"},{\"authorId\":\"144106863\",\"name\":\"Hua Lu\"},{\"authorId\":\"144585959\",\"name\":\"B. Cui\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2697681\",\"name\":\"Lele Yu\"}],\"doi\":\"10.1145/3041657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"476099af05456f9aba7f9ead8bed58980ad91a2c\",\"title\":\"GVoS: A General System for Near-Duplicate Video-Related Applications on Storm\",\"url\":\"https://www.semanticscholar.org/paper/476099af05456f9aba7f9ead8bed58980ad91a2c\",\"venue\":\"ACM Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":\"1908.10700\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"144585402\",\"name\":\"Peng Zhang\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3343031.3351040\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"title\":\"Explainable Video Action Reasoning via Prior Knowledge and State Transitions\",\"url\":\"https://www.semanticscholar.org/paper/7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"1679704\",\"name\":\"Y. Liu\"},{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"}],\"doi\":\"10.1109/TIE.2018.2884206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58ff25ce1332b5fdc9ac430222d03e550b4e29e9\",\"title\":\"Learning-Based Hand Motion Capture and Understanding in Assembly Process\",\"url\":\"https://www.semanticscholar.org/paper/58ff25ce1332b5fdc9ac430222d03e550b4e29e9\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2019},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1607.01979\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3f85e81f716fe7f8094d84bbe9a5d564b95398a8\",\"title\":\"Untrimmed Video Classification for Activity Detection: submission to ActivityNet Challenge\",\"url\":\"https://www.semanticscholar.org/paper/3f85e81f716fe7f8094d84bbe9a5d564b95398a8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1605.07289\",\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2012673\",\"name\":\"H. Liu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef89ef57db3039f07304e46c9a2bb7c5bfef119d\",\"title\":\"EventNet Version 1.1 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/ef89ef57db3039f07304e46c9a2bb7c5bfef119d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/ICCV.2017.312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730228\",\"name\":\"M. Liu\"},{\"authorId\":\"47781541\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1145/3347450.3357654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d062058cdef85163512c3984f0f1ba78f625582e\",\"title\":\"Deep Reinforcement Learning Visual-Text Attention for Multimodal Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d062058cdef85163512c3984f0f1ba78f625582e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1601.05511\",\"authors\":[{\"authorId\":\"47539715\",\"name\":\"Jing Zhang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"}],\"doi\":\"10.1016/j.patcog.2016.05.019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a52a2d27a0d6f7f5508941998344df692216f4d\",\"title\":\"RGB-D-based action recognition datasets: A survey\",\"url\":\"https://www.semanticscholar.org/paper/6a52a2d27a0d6f7f5508941998344df692216f4d\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145082678\",\"name\":\"G. Chen\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"}],\"doi\":\"10.1007/978-3-030-05710-7_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64a157d61e72b204013acb70bb5c16b55ce7ba09\",\"title\":\"STMP: Spatial Temporal Multi-level Proposal Network for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/64a157d61e72b204013acb70bb5c16b55ce7ba09\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"144064571\",\"name\":\"I. Pitas\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1016/j.image.2017.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"title\":\"Big Media Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":\"2005.04208\",\"authors\":[{\"authorId\":\"153000035\",\"name\":\"M. Bain\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"152853748\",\"name\":\"A. Brown\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"title\":\"Condensed Movies: Story Based Retrieval with Contextual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13886\",\"authors\":[{\"authorId\":\"51128743\",\"name\":\"Srikanth Malla\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"}],\"doi\":\"10.1109/cvpr42600.2020.01120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"title\":\"TITAN: Future Forecast Using Action Priors\",\"url\":\"https://www.semanticscholar.org/paper/55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.11961\",\"authors\":[{\"authorId\":\"1391221756\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"49673319\",\"name\":\"Changsheng Li\"},{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"145924255\",\"name\":\"Peng Li\"},{\"authorId\":\"143689318\",\"name\":\"Jing Dong\"}],\"doi\":\"10.1109/tnnls.2019.2962815\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77e48bc788edc9870dd7c1bdfe7283a909a25b2f\",\"title\":\"AdapNet: Adaptability Decomposing Encoder-Decoder Network for Weakly Supervised Action Recognition and Localization\",\"url\":\"https://www.semanticscholar.org/paper/77e48bc788edc9870dd7c1bdfe7283a909a25b2f\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41172535\",\"name\":\"Che Sun\"},{\"authorId\":\"40506635\",\"name\":\"Hao Song\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1007/978-3-030-31654-9_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46e9f9c38d93e7882ae82d81e007ae8eb9ab6462\",\"title\":\"Learning Weighted Video Segments for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/46e9f9c38d93e7882ae82d81e007ae8eb9ab6462\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1708.00666\",\"authors\":[{\"authorId\":\"34567611\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.200\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c44b730bef287581ad1d70bf9a883787d5998d8d\",\"title\":\"Temporal Dynamic Graph LSTM for Action-Driven Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/c44b730bef287581ad1d70bf9a883787d5998d8d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152341152\",\"name\":\"Saipriyati Singh\"},{\"authorId\":\"121493358\",\"name\":\"Baris Aksanli\"}],\"doi\":\"10.3390/JSAN8030040\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fef7e404129ec966f566baae50a3290f5345a768\",\"title\":\"Non-Intrusive Presence Detection and Position Tracking for Multiple People Using Low-Resolution Thermal Sensors\",\"url\":\"https://www.semanticscholar.org/paper/fef7e404129ec966f566baae50a3290f5345a768\",\"venue\":\"J. Sens. Actuator Networks\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405196499\",\"name\":\"Marcos Baptista-R\\u00edos\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"},{\"authorId\":\"1402975934\",\"name\":\"F. J. Acevedo-Rodr\\u00edguez\"},{\"authorId\":\"1412159037\",\"name\":\"Pilar Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"1398470117\",\"name\":\"S. Maldonado-Basc\\u00f3n\"}],\"doi\":\"10.3390/s20102953\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"250cff3f869805e76bf0cda34406f5def042148c\",\"title\":\"Unsupervised Action Proposals Using Support Vector Classifiers for Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/250cff3f869805e76bf0cda34406f5def042148c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3394380\",\"name\":\"F. Scheidegger\"},{\"authorId\":\"1701257\",\"name\":\"L. Cavigelli\"},{\"authorId\":\"144370502\",\"name\":\"M. Schaffner\"},{\"authorId\":\"2535792\",\"name\":\"A. C. I. Malossi\"},{\"authorId\":\"10107014\",\"name\":\"C. Bekas\"},{\"authorId\":\"1710649\",\"name\":\"L. Benini\"}],\"doi\":\"10.23919/EUSIPCO.2017.8081357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82007bd70d83869fdbe39c03bda0b4459991fda7\",\"title\":\"Impact of temporal subsampling on accuracy and performance in practical video classification\",\"url\":\"https://www.semanticscholar.org/paper/82007bd70d83869fdbe39c03bda0b4459991fda7\",\"venue\":\"2017 25th European Signal Processing Conference (EUSIPCO)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"448c3a671ff66fd9184f2a8482dfbe223913035c\",\"title\":\"Boundary Sensitive Network : Submission to ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/448c3a671ff66fd9184f2a8482dfbe223913035c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24126456\",\"name\":\"Rishab Mehra\"},{\"authorId\":\"49015503\",\"name\":\"G. Bianconi\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f94945951bddeffcf1bda37a1f66163b46d77f7\",\"title\":\"Depth-Based Activity Recognition in ICUs Using Convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f94945951bddeffcf1bda37a1f66163b46d77f7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.08634\",\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.00804\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1aea7d20edfd40b0907249270a80842382d93964\",\"title\":\"DDLSTM: Dual-Domain LSTM for Cross-Dataset Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1aea7d20edfd40b0907249270a80842382d93964\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"122651168\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ACCESS.2018.2872759\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6114916d2bd874ba15653168a207df6c55c11efd\",\"title\":\"Active Temporal Action Detection in Untrimmed Videos Via Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6114916d2bd874ba15653168a207df6c55c11efd\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1704.07863\",\"authors\":[{\"authorId\":\"145848547\",\"name\":\"A. Romero\"},{\"authorId\":\"49648929\",\"name\":\"J. Le\\u00f3n\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"}],\"doi\":\"10.1016/J.IMAVIS.2018.09.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f618cbf19917ce5b8703adbc14e15b0bf0d35cc\",\"title\":\"Multi-View Dynamic Facial Action Unit Detection\",\"url\":\"https://www.semanticscholar.org/paper/4f618cbf19917ce5b8703adbc14e15b0bf0d35cc\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/CVPR.2016.214\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"title\":\"Learning Activity Progression in LSTMs for Activity Detection and Early Detection\",\"url\":\"https://www.semanticscholar.org/paper/e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423699581\",\"name\":\"A. F. D. Marsiano\"},{\"authorId\":\"9149246\",\"name\":\"I. Soesanti\"},{\"authorId\":\"2969172\",\"name\":\"Igi Ardiyanto\"}],\"doi\":\"10.1109/ICAICTA.2019.8904395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"title\":\"Deep learning-based Anomaly Detection on Surveillance Videos: Recent Advances\",\"url\":\"https://www.semanticscholar.org/paper/8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"93768847\",\"name\":\"Xinghan Wang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00984\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"title\":\"Learning Temporal Co-Attention Models for Unsupervised Video Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102769741\",\"name\":\"Jung-In. Park\"},{\"authorId\":\"49685029\",\"name\":\"J. Lee\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICIP.2019.8803589\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6633bf2049917272ba7f60087d3b0a1e89e21e3\",\"title\":\"Graph Regularization Network with Semantic Affinity for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6633bf2049917272ba7f60087d3b0a1e89e21e3\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144235416\",\"name\":\"Peng Qiu\"},{\"authorId\":\"2456541\",\"name\":\"S. Kim\"},{\"authorId\":\"51039934\",\"name\":\"Jeong-Hyu Lee\"},{\"authorId\":\"49331354\",\"name\":\"J. Choi\"}],\"doi\":\"10.1007/978-981-10-7512-4_59\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfc3a3365a29e4b75e2a3a6bd6e6b8f3f6ddcb15\",\"title\":\"Anomaly Detection in a Crowd Using a Cascade of Deep Learning Networks\",\"url\":\"https://www.semanticscholar.org/paper/cfc3a3365a29e4b75e2a3a6bd6e6b8f3f6ddcb15\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27720832\",\"name\":\"T. Long\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00122\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"title\":\"Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1803.08460\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"144537809\",\"name\":\"Yu Guan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2018.00983\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"30ca009c3988d96c4ef7671692f709e8100967f5\",\"title\":\"Towards Universal Representation for Unseen Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/30ca009c3988d96c4ef7671692f709e8100967f5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.02308\",\"authors\":[{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1721328\",\"name\":\"S. Antani\"},{\"authorId\":\"145949571\",\"name\":\"D. Bulterman\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"},{\"authorId\":\"144049352\",\"name\":\"Julia Hirschberg\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"},{\"authorId\":\"1398227667\",\"name\":\"K. Mayer-Patel\"},{\"authorId\":\"2337428\",\"name\":\"R. Meth\"},{\"authorId\":\"144447740\",\"name\":\"R. Mooney\"},{\"authorId\":\"1688353\",\"name\":\"K. Nahrstedt\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"},{\"authorId\":\"2807460\",\"name\":\"S. Oviatt\"},{\"authorId\":\"70295214\",\"name\":\"B. Prabhakaran\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"},{\"authorId\":\"145372008\",\"name\":\"H. Sundaram\"},{\"authorId\":\"51064498\",\"name\":\"Zhengyou Zhang\"},{\"authorId\":\"1705742\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"539a7061d4289b1aa72f319c680ea87ff695289c\",\"title\":\"Report of 2017 NSF Workshop on Multimedia Challenges, Opportunities and Research Roadmaps\",\"url\":\"https://www.semanticscholar.org/paper/539a7061d4289b1aa72f319c680ea87ff695289c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.01060\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1410071510\",\"name\":\"Hongru Li\"},{\"authorId\":\"144410963\",\"name\":\"S. Kung\"}],\"doi\":\"10.1109/tmm.2020.3042077\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbcb5f600f0fde2cc94f90b96a830652a47e7af5\",\"title\":\"Temporal Action Localization using Long Short-Term Dependency\",\"url\":\"https://www.semanticscholar.org/paper/fbcb5f600f0fde2cc94f90b96a830652a47e7af5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1557269924\",\"name\":\"Tao Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2020.107477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"156fae773062f7ef0d4e9c4bb141cfae46e8ba85\",\"title\":\"Play and rewind: Context-aware video temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/156fae773062f7ef0d4e9c4bb141cfae46e8ba85\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2007.07355\",\"authors\":[{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"title\":\"TinyVIRAT: Low-resolution Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"title\":\"Representing Videos based on Scene Layouts for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2012.07138\",\"authors\":[{\"authorId\":\"48212577\",\"name\":\"Hongming Zhang\"},{\"authorId\":\"2036553451\",\"name\":\"Yintong Huo\"},{\"authorId\":\"1500662261\",\"name\":\"Xinran Zhao\"},{\"authorId\":\"95882703\",\"name\":\"Y. Song\"},{\"authorId\":\"152567881\",\"name\":\"Dan Roth\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2aa58cc59d3ce919ce1298ae9207f304587458f5\",\"title\":\"Learning Contextual Causality from Time-consecutive Images\",\"url\":\"https://www.semanticscholar.org/paper/2aa58cc59d3ce919ce1298ae9207f304587458f5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1109/MSP.2017.2763441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6a596c71828b7488d62627fefbe7fff123b62a3\",\"title\":\"Recent Advances in Zero-Shot Recognition: Toward Data-Efficient Understanding of Visual Content\",\"url\":\"https://www.semanticscholar.org/paper/d6a596c71828b7488d62627fefbe7fff123b62a3\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.3389/frobt.2015.00028\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"90a754f597958a2717862fbaa313f67b25083bf9\",\"title\":\"A Review of Human Activity Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/90a754f597958a2717862fbaa313f67b25083bf9\",\"venue\":\"Front. Robot. AI\",\"year\":2015},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1910.11006\",\"authors\":[{\"authorId\":\"2981509\",\"name\":\"Dongxu Li\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"144349266\",\"name\":\"X. Yu\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1109/WACV45572.2020.9093512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dda8d1d7400d49e5ad54bc9abfca96170245763\",\"title\":\"Word-level Deep Sign Language Recognition from Video: A New Large-scale Dataset and Methods Comparison\",\"url\":\"https://www.semanticscholar.org/paper/2dda8d1d7400d49e5ad54bc9abfca96170245763\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1907.11272\",\"authors\":[{\"authorId\":\"10385459\",\"name\":\"Noor Al-M\\u00e1adeed\"},{\"authorId\":\"1693388823\",\"name\":\"Omar Elharrouss\"},{\"authorId\":\"1406702495\",\"name\":\"S. Al-M\\u00e1adeed\"},{\"authorId\":\"71753708\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e86020284db7de53d85b11ba7818aea80f9247f0\",\"title\":\"A Novel Approach for Robust Multi Human Action Recognition and Summarization based on 3D Convolutional Neural Networks.\",\"url\":\"https://www.semanticscholar.org/paper/e86020284db7de53d85b11ba7818aea80f9247f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1901.09403\",\"authors\":[{\"authorId\":\"41049768\",\"name\":\"Amlaan Bhoi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"title\":\"Spatio-temporal Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19301412\",\"name\":\"Weimian Li\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICME.2017.8019335\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b2366f2a3c0845de03b37b4866c1da2df0592ae\",\"title\":\"A joint model for action localization and classification in untrimmed video with visual attention\",\"url\":\"https://www.semanticscholar.org/paper/9b2366f2a3c0845de03b37b4866c1da2df0592ae\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"46583885\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d708ce7103a992634b1b4e87612815f03ba3ab24\",\"title\":\"FCVID : Fudan-Columbia Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d708ce7103a992634b1b4e87612815f03ba3ab24\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143676076\",\"name\":\"Boyu Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1016/j.cviu.2018.10.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c6b64312fd6adc8b563852ad59483dc1aea3693\",\"title\":\"Back to the beginning: Starting point detection for early recognition of ongoing human actions\",\"url\":\"https://www.semanticscholar.org/paper/2c6b64312fd6adc8b563852ad59483dc1aea3693\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1807.00686\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"145950948\",\"name\":\"Xue Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3aea4d43c157d8e2fcf692b172e2c1c1e4bae6ec\",\"title\":\"YH Technologies at ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/3aea4d43c157d8e2fcf692b172e2c1c1e4bae6ec\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.03740\",\"authors\":[{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1749272\",\"name\":\"Ziyu Guan\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2985868\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"title\":\"Query-Biased Self-Attentive Network for Query-Focused Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1703.07475\",\"authors\":[{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b673ffe63c5d0723009042f0f922f19f093b7e34\",\"title\":\"PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b673ffe63c5d0723009042f0f922f19f093b7e34\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900432330\",\"name\":\"Ke Ning\"},{\"authorId\":\"1811534\",\"name\":\"M. Cai\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TMM.2019.2957854\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9f2837b150eab8a1aa2e74a1a528700e1e6d8b8\",\"title\":\"An Attentive Sequence to Sequence Translator for Localizing Video Clips by Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/f9f2837b150eab8a1aa2e74a1a528700e1e6d8b8\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1909.06423\",\"authors\":[{\"authorId\":\"153494805\",\"name\":\"Valter Lu\\u00eds Estevam Junior\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"50534501\",\"name\":\"D. Menotti\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e93e88c1b38e9d4733f3b5d692b354035fe57fdf\",\"title\":\"Zero-Shot Action Recognition in Videos: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/e93e88c1b38e9d4733f3b5d692b354035fe57fdf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1709.02123\",\"authors\":[{\"authorId\":\"2675450\",\"name\":\"Zhizhong Li\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.24963/ijcai.2017/312\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5fb6c32eb9d4788828694a5483a2ff5190e965e\",\"title\":\"Integrating Specialized Classifiers Based on Continuous Time Markov Chain\",\"url\":\"https://www.semanticscholar.org/paper/b5fb6c32eb9d4788828694a5483a2ff5190e965e\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50677284\",\"name\":\"C. Roig\"},{\"authorId\":\"2023762\",\"name\":\"D. Varas\"},{\"authorId\":\"134124221\",\"name\":\"Issey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7b41f1c3567b7cd45a12d727df93929ccb8aacb\",\"title\":\"Unsupervised Large-Scale World Locations Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e7b41f1c3567b7cd45a12d727df93929ccb8aacb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.02307\",\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"47559205\",\"name\":\"Y. Chen\"},{\"authorId\":\"32639375\",\"name\":\"Teruhisa Misu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2018.00803\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b5bd8535e49747b752c5eb8c0d80cd45a30078b\",\"title\":\"Toward Driving Scene Understanding: A Dataset for Learning Driver Behavior and Causal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7b5bd8535e49747b752c5eb8c0d80cd45a30078b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.01.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"title\":\"Video you only look once: Overall temporal convolutions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1704.07129\",\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.18653/v1/P17-2011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"766330b56c01c946d257cb3bef5234ac29bc7f69\",\"title\":\"An Analysis of Action Recognition Datasets for Language and Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/766330b56c01c946d257cb3bef5234ac29bc7f69\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1803.06316\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"title\":\"Temporal Gaussian Mixture Layer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1604.06182\",\"authors\":[{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40633675\",\"name\":\"Alex Gorban\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2016.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c57a070724b48962935ff46ab1384d919e1d1089\",\"title\":\"The THUMOS challenge on action recognition for videos \\\"in the wild\\\"\",\"url\":\"https://www.semanticscholar.org/paper/c57a070724b48962935ff46ab1384d919e1d1089\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1604.06506\",\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-46454-1_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"574ab231627eadc1056162c38d0895f372121250\",\"title\":\"Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/574ab231627eadc1056162c38d0895f372121250\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1812.11631\",\"authors\":[{\"authorId\":\"32859304\",\"name\":\"Oytun Ulutan\"},{\"authorId\":\"34889835\",\"name\":\"S. Rallapalli\"},{\"authorId\":\"1718467\",\"name\":\"M. Srivatsa\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/WACV45572.2020.9093617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"title\":\"Actor Conditioned Attention Maps for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50010487\",\"name\":\"Lei Bai\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"51126631\",\"name\":\"Xianzhi Wang\"},{\"authorId\":\"1733096\",\"name\":\"Salil S. Kanhere\"},{\"authorId\":\"152122171\",\"name\":\"Bin Guo\"},{\"authorId\":\"144861834\",\"name\":\"Zhiwen Yu\"}],\"doi\":\"10.1145/3397323\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2c3c78ec8aa00a4350d97bdfdf49223f02eb682\",\"title\":\"Adversarial Multi-view Networks for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2c3c78ec8aa00a4350d97bdfdf49223f02eb682\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1708.09522\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c51069d03974bd28dd821142a852ec24ce7546a\",\"title\":\"Action Classification and Highlighting in Videos\",\"url\":\"https://www.semanticscholar.org/paper/2c51069d03974bd28dd821142a852ec24ce7546a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2004.13918\",\"authors\":[{\"authorId\":\"150140898\",\"name\":\"Junho Choi\"},{\"authorId\":\"1688671\",\"name\":\"J. Lee\"}],\"doi\":\"10.1145/3341162.3344871\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f9dc46c32f55ab0c0db5d9d3a29152d03bf58f7\",\"title\":\"EmbraceNet for activity: a deep multimodal fusion architecture for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f9dc46c32f55ab0c0db5d9d3a29152d03bf58f7\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51162043\",\"name\":\"V. Voronin\"},{\"authorId\":\"101975530\",\"name\":\"M. Pismenskova\"},{\"authorId\":\"51477368\",\"name\":\"A. Zelensky\"},{\"authorId\":\"2337096\",\"name\":\"Yigang Cen\"},{\"authorId\":\"152732735\",\"name\":\"A. Nadykto\"},{\"authorId\":\"1683084\",\"name\":\"K. Egiazarian\"}],\"doi\":\"10.1117/12.2326801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbceaba6999984120d86e76e36854cafa444e69e\",\"title\":\"Action recognition using the 3D dense microblock difference\",\"url\":\"https://www.semanticscholar.org/paper/cbceaba6999984120d86e76e36854cafa444e69e\",\"venue\":\"Security + Defence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1145/3264706.3264716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"title\":\"PhD thesis: objects for spatio-temporal activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"venue\":\"ACMMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2479610\",\"name\":\"O. Yalcinkaya\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"}],\"doi\":\"10.1109/SIU.2017.7960314\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce301fb8c8a98dca15daf334f2820276abf1331c\",\"title\":\"Action recognition with prototypes\",\"url\":\"https://www.semanticscholar.org/paper/ce301fb8c8a98dca15daf334f2820276abf1331c\",\"venue\":\"2017 25th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2017},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805489\",\"name\":\"Z. Zhang\"},{\"authorId\":\"50144812\",\"name\":\"Z. Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725989041b70ce21c5e20d90037691a59a483257\",\"title\":\"Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/725989041b70ce21c5e20d90037691a59a483257\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1911.11462\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.01017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"title\":\"G-TAD: Sub-Graph Localization for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.06958\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4545cdb909f2be23ce6542defef6091912729648\",\"title\":\"SALAD: Self-Assessment Learning for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/4545cdb909f2be23ce6542defef6091912729648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05675\",\"authors\":[{\"authorId\":\"2557642\",\"name\":\"HyeokHyen Kwon\"},{\"authorId\":\"49101030\",\"name\":\"C. Tong\"},{\"authorId\":\"1396120509\",\"name\":\"Harish Haresamudram\"},{\"authorId\":\"152673873\",\"name\":\"Yan Gao\"},{\"authorId\":\"9267108\",\"name\":\"Gregory D. Abowd\"},{\"authorId\":\"144948031\",\"name\":\"N. Lane\"},{\"authorId\":\"2191750\",\"name\":\"T. Pl\\u00f6tz\"}],\"doi\":\"10.1145/3411841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30847bf643b810a4bc536fe8ce3630704e10f971\",\"title\":\"IMUTube: Automatic extraction of virtual on-body accelerometry from video for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/30847bf643b810a4bc536fe8ce3630704e10f971\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47933011\",\"name\":\"Xiaoping Huang\"},{\"authorId\":\"1857401\",\"name\":\"Lihong Ma\"},{\"authorId\":\"2038350017\",\"name\":\"Jing Tian\"}],\"doi\":\"10.1109/TENCON50793.2020.9293843\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e69622e98a5d8d4c84ef1b756f8ac0f5cff6417c\",\"title\":\"A Novel Weakly-Supervised Proposal Method Based on Vector Perceptron and Unbalanced Action-Background Self-supervised Boundary Inferring\",\"url\":\"https://www.semanticscholar.org/paper/e69622e98a5d8d4c84ef1b756f8ac0f5cff6417c\",\"venue\":\"2020 IEEE REGION 10 CONFERENCE (TENCON)\",\"year\":2020},{\"arxivId\":\"1603.03369\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2016.120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3db6c8086082acd55f6c95070ad309ecb834517\",\"title\":\"Summary Transfer: Exemplar-Based Subset Selection for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/e3db6c8086082acd55f6c95070ad309ecb834517\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2002.01449\",\"authors\":[{\"authorId\":\"35157022\",\"name\":\"Maheen Rashid\"},{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/WACV45572.2020.9093404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"412efd7ffb214d66b2a4e26ff1bbc805e0196b52\",\"title\":\"Action Graphs: Weakly-supervised Action Localization with Graph Convolution Networks\",\"url\":\"https://www.semanticscholar.org/paper/412efd7ffb214d66b2a4e26ff1bbc805e0196b52\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1804.08274\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00782\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"title\":\"Jointly Localizing and Describing Events for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669712931\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":\"10.1145/3293353.3293415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8889beea3ae4e529f888525e33bd2160559f9153\",\"title\":\"Temporal Cricket Stroke Localization from Untrimmed Highlight Videos\",\"url\":\"https://www.semanticscholar.org/paper/8889beea3ae4e529f888525e33bd2160559f9153\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"title\":\"y 1 ? ? ? ? ? open jar scoop sugar ? ? ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1706.05461\",\"authors\":[{\"authorId\":null,\"name\":\"Zhe Wang\"},{\"authorId\":\"38513577\",\"name\":\"K. Kuan\"},{\"authorId\":\"14038850\",\"name\":\"Mathieu Ravaut\"},{\"authorId\":\"11730285\",\"name\":\"G. Manek\"},{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143844731\",\"name\":\"Yuan Fang\"},{\"authorId\":\"1412681930\",\"name\":\"Kim Seokhwan\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1405511901\",\"name\":\"Luis Fernando D'Haro\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"3111797\",\"name\":\"Z. Zeng\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1787822\",\"name\":\"G. Piliouras\"},{\"authorId\":\"66190968\",\"name\":\"Jie Lin\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f67c665208b8d67555130cd3555a4a15f3940cfe\",\"title\":\"Truly Multi-modal YouTube-8M Video Classification with Video, Audio, and Text\",\"url\":\"https://www.semanticscholar.org/paper/f67c665208b8d67555130cd3555a4a15f3940cfe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.06539\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"46265470\",\"name\":\"L. Xu\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"46953609\",\"name\":\"Ze Ma\"},{\"authorId\":\"48622851\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"39547281\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"18aa02401bfdd6cbde847c850fe994926ee99f24\",\"title\":\"HAKE: Human Activity Knowledge Engine\",\"url\":\"https://www.semanticscholar.org/paper/18aa02401bfdd6cbde847c850fe994926ee99f24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e753a55e8905cb0b72672e72e9b8fa8f34694dbc\",\"title\":\"LPAT: Learning to Predict Adaptive Threshold for Weakly-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e753a55e8905cb0b72672e72e9b8fa8f34694dbc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152987957\",\"name\":\"Tian Wang\"},{\"authorId\":\"152384041\",\"name\":\"Shiye Lei\"},{\"authorId\":\"116503541\",\"name\":\"Youyou Jiang\"},{\"authorId\":\"122209497\",\"name\":\"Choi Chang\"},{\"authorId\":\"2103629\",\"name\":\"Hichem Snoussi\"},{\"authorId\":\"49021634\",\"name\":\"Guangcun Shan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7af61853fd6e536f347b3b69c3e1288db6401e36\",\"title\":\"Accelerating temporal action proposal generation via high performance computing.\",\"url\":\"https://www.semanticscholar.org/paper/7af61853fd6e536f347b3b69c3e1288db6401e36\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.10774\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"1648707714\",\"name\":\"Qazi Ammar Arshad\"},{\"authorId\":\"144212662\",\"name\":\"Chen Chen\"}],\"doi\":\"10.1007/978-3-030-03243-2_846-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e3ff4cad99d691ecb613b384d311cd411569b9\",\"title\":\"Action recognition in real-world videos\",\"url\":\"https://www.semanticscholar.org/paper/54e3ff4cad99d691ecb613b384d311cd411569b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"48624462\",\"name\":\"W. Li\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"}],\"doi\":\"10.1109/TMM.2018.2839534\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"602412f61e8902052e6489e84a6f24ccc7407814\",\"title\":\"Fully Convolutional Network for Multiscale Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/602412f61e8902052e6489e84a6f24ccc7407814\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1802.09723\",\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"2126444\",\"name\":\"Xiaolin Fang\"},{\"authorId\":\"35933894\",\"name\":\"Chaoqin Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPR.2018.00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a640bc0faef2c0ee44074bfd17e813d9b538bd17\",\"title\":\"Recurrent Residual Module for Fast Inference in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a640bc0faef2c0ee44074bfd17e813d9b538bd17\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"7576095\",\"name\":\"Zikai Song\"},{\"authorId\":\"46958488\",\"name\":\"T. Wang\"},{\"authorId\":\"51048063\",\"name\":\"Hengyou Cai\"},{\"authorId\":\"144410809\",\"name\":\"N. Feng\"}],\"doi\":\"10.1109/MIPR.2018.00090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e3b981b9f3751fc5873f77ad2aa7789c3e1d1d2\",\"title\":\"Comprehensive Dataset of Broadcast Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/2e3b981b9f3751fc5873f77ad2aa7789c3e1d1d2\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":\"2009.07641\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"title\":\"BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1512.05227\",\"authors\":[{\"authorId\":\"50355189\",\"name\":\"Yin Cui\"},{\"authorId\":\"50813206\",\"name\":\"F. Zhou\"},{\"authorId\":\"1695082\",\"name\":\"Y. Lin\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2016.130\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d62494053ec3bdccdc953d6916d2fab49b92049b\",\"title\":\"Fine-Grained Categorization and Dataset Bootstrapping Using Deep Metric Learning with Humans in the Loop\",\"url\":\"https://www.semanticscholar.org/paper/d62494053ec3bdccdc953d6916d2fab49b92049b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"144934447\",\"name\":\"M. Dom\\u00ednguez\"},{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/CVPRW.2017.274\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"477d58ad32e0e54c40da135fb8db28b23ad0ffd0\",\"title\":\"Temporally Steered Gaussian Attention for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/477d58ad32e0e54c40da135fb8db28b23ad0ffd0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1911.00232\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"150937390\",\"name\":\"Barry A. McNamara\"},{\"authorId\":\"118728832\",\"name\":\"A. Lascelles\"},{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da0822f776025dd73698adf6ed29ac63302d1a32\",\"title\":\"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/da0822f776025dd73698adf6ed29ac63302d1a32\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.00207\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"46447561\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-11018-5_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"title\":\"Non-local NetVLAD Encoding for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1808.06739\",\"authors\":[{\"authorId\":\"50021905\",\"name\":\"T. Liu\"},{\"authorId\":\"47655718\",\"name\":\"Bo Liu\"}],\"doi\":\"10.1007/978-3-030-11018-5_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e89c8d2147475d1fca42fbb2a92bb602e275a86d\",\"title\":\"Constrained-size Tensorflow Models for YouTube-8M Video Understanding Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e89c8d2147475d1fca42fbb2a92bb602e275a86d\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121879338\",\"name\":\"Rashim Bhardwaj\"},{\"authorId\":\"143609348\",\"name\":\"P. Singh\"}],\"doi\":\"10.1109/CONFLUENCE.2016.7508177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b5474aedb0e9f7d4ab59edc7c48464adc8dbe68\",\"title\":\"Analytical review on human activity recognition in video\",\"url\":\"https://www.semanticscholar.org/paper/8b5474aedb0e9f7d4ab59edc7c48464adc8dbe68\",\"venue\":\"2016 6th International Conference - Cloud System and Big Data Engineering (Confluence)\",\"year\":2016},{\"arxivId\":\"2003.12058\",\"authors\":[{\"authorId\":\"4055152\",\"name\":\"Sarah Pratt\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"20745881\",\"name\":\"Luca Weihs\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1007/978-3-030-58548-8_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc261c0efb5f9ce82581932d1440630b861fb85f\",\"title\":\"Grounded Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc261c0efb5f9ce82581932d1440630b861fb85f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04461\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.00089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a57a186a0b71ed38afaa9d5594b28f942a7b6231\",\"title\":\"Learning to Discriminate Information for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/a57a186a0b71ed38afaa9d5594b28f942a7b6231\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.09215\",\"authors\":[{\"authorId\":\"50218817\",\"name\":\"Zhengwei Wang\"},{\"authorId\":\"1486411393\",\"name\":\"Qi She\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/CVPRW50498.2020.00123\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"title\":\"CatNet: Class Incremental 3D ConvNets for Lifelong Egocentric Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26940993\",\"name\":\"Djamila Romaissa Beddiar\"},{\"authorId\":\"2079007\",\"name\":\"B. Nini\"},{\"authorId\":\"1887141250\",\"name\":\"Mohammad Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/s11042-020-09004-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46995f6b266a40c10bc05b046654a4be8bf2220c\",\"title\":\"Vision-based human activity recognition: a survey\",\"url\":\"https://www.semanticscholar.org/paper/46995f6b266a40c10bc05b046654a4be8bf2220c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51249802\",\"name\":\"Qiubin Su\"}],\"doi\":\"10.1016/j.neucom.2019.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4888c5a5a3a6cfc4b518d41820801d46cb397da\",\"title\":\"Two-stage transfer network for weakly supervised action localization\",\"url\":\"https://www.semanticscholar.org/paper/e4888c5a5a3a6cfc4b518d41820801d46cb397da\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2012.10671\",\"authors\":[{\"authorId\":\"152957752\",\"name\":\"Shreyank N Gowda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"title\":\"SMART Frame Selection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.05667\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"title\":\"Explainable Deep Learning for Video Recognition Tasks: A Framework & Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18186434\",\"name\":\"Nudrat Nida\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1155/2019/2474865\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d0b838b40a3fffdc4e796e16a69f2e8b3ed210b\",\"title\":\"Instructor Activity Recognition through Deep Spatiotemporal Features and Feedforward Extreme Learning Machines\",\"url\":\"https://www.semanticscholar.org/paper/6d0b838b40a3fffdc4e796e16a69f2e8b3ed210b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.00030\",\"authors\":[{\"authorId\":\"73580712\",\"name\":\"S. Wang\"},{\"authorId\":\"145022667\",\"name\":\"A. Mesaros\"},{\"authorId\":\"2373836\",\"name\":\"Toni Heittola\"},{\"authorId\":\"50195877\",\"name\":\"T. Virtanen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9ebd69ccbf6e493abdac6f047b4bc8d3be88412\",\"title\":\"A Curated Dataset of Urban Scenes for Audio-Visual Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a9ebd69ccbf6e493abdac6f047b4bc8d3be88412\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.15781\",\"authors\":[{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58574-7_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"title\":\"LEMMA: A Multi-view Dataset for Learning Multi-agent Multi-task Activities\",\"url\":\"https://www.semanticscholar.org/paper/cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.08045\",\"authors\":[{\"authorId\":\"152516150\",\"name\":\"Aniket Agarwal\"},{\"authorId\":\"1703122502\",\"name\":\"Ayush Mangal\"},{\"authorId\":\"80465887\",\"name\":\"Vipul\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac73d0abab68604b9c7a2b98635516eda899c7b3\",\"title\":\"Visual Relationship Detection using Scene Graphs: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/ac73d0abab68604b9c7a2b98635516eda899c7b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143781496\",\"name\":\"Ke Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Yong Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"title\":\"TPC: Temporal Preservation Convolutional Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2001.05060\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f24594e87dd1b2139197c3b22e88518a6b05892c\",\"title\":\"Recognizing Video Events with Varying Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/f24594e87dd1b2139197c3b22e88518a6b05892c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.02602\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"title\":\"Human Action Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3206025.3206028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"title\":\"Dense Dilated Network for Few Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39796129\",\"name\":\"Hayden Faulkner\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":\"10.1109/DICTA.2017.8227494\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"title\":\"TenniSet: A Dataset for Dense Fine-Grained Event Recognition, Localisation and Description\",\"url\":\"https://www.semanticscholar.org/paper/4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1874862797\",\"name\":\"Boge Wen\"},{\"authorId\":\"122665402\",\"name\":\"Siyuan Chen\"},{\"authorId\":\"3090858\",\"name\":\"Chenhui Shao\"}],\"doi\":\"10.1016/j.compind.2020.103255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"title\":\"Temporal action proposal for online driver action monitoring using Dilated Convolutional Temporal Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"venue\":\"Comput. Ind.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01219-9_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"title\":\"Temporal Modular Networks for Retrieving Complex Compositional Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1906.02182\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2019.2921539\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95138f276b34cc84695b64ee5fc00c1e27091497\",\"title\":\"Two-Stream Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/95138f276b34cc84695b64ee5fc00c1e27091497\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1807.10706\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01219-9_16\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1786d26835e0add50c013ef5089afc5ff5796e1e\",\"title\":\"Diagnosing Error in Temporal Action Detectors\",\"url\":\"https://www.semanticscholar.org/paper/1786d26835e0add50c013ef5089afc5ff5796e1e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.03180\",\"authors\":[{\"authorId\":\"1399431057\",\"name\":\"Paola Cascante-Bonilla\"},{\"authorId\":\"1416539256\",\"name\":\"Kalpathy Sitaraman\"},{\"authorId\":\"31143971\",\"name\":\"Mengjia Luo\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"title\":\"Moviescope: Large-scale Analysis of Movies using Multiple Modalities\",\"url\":\"https://www.semanticscholar.org/paper/e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"3309893\",\"name\":\"G. Brostow\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7e7ff6237110e3d78be3bde42196b02935f207f\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/f7e7ff6237110e3d78be3bde42196b02935f207f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700535\",\"name\":\"Jichao Liu\"},{\"authorId\":\"50096175\",\"name\":\"Chuan-xu Wang\"},{\"authorId\":\"50623550\",\"name\":\"Y. Gong\"},{\"authorId\":\"145801443\",\"name\":\"Hao Xue\"}],\"doi\":\"10.1109/ACCESS.2019.2929684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"088002fd332f6684079ff0f9cebffd4ef5dd66cd\",\"title\":\"Deep Fully Connected Model for Collective Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/088002fd332f6684079ff0f9cebffd4ef5dd66cd\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"151b87de997e55db892b122c211f9c749f4293de\",\"title\":\"Joint Learning of Object and Action Detectors\",\"url\":\"https://www.semanticscholar.org/paper/151b87de997e55db892b122c211f9c749f4293de\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1563062373\",\"name\":\"Jiaxiin Wu\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f629a5cfc144bc08f7e3ecb411c909c4ccf6f1a3\",\"title\":\"VIREO-EURECOM @ TRECVID 2019: Ad-hoc Video Search (AVS)\",\"url\":\"https://www.semanticscholar.org/paper/f629a5cfc144bc08f7e3ecb411c909c4ccf6f1a3\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"1384716902\",\"name\":\"Jin Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"265010019d3d95568d237973b5d957c6aa80d7dd\",\"title\":\"SAFER : Fine-grained Activity Detection by Compositional Hypothesis Testing\",\"url\":\"https://www.semanticscholar.org/paper/265010019d3d95568d237973b5d957c6aa80d7dd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.04127\",\"authors\":[{\"authorId\":\"51266875\",\"name\":\"Chuming Lin\"},{\"authorId\":\"50683988\",\"name\":\"J. Li\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"20595955\",\"name\":\"Zhipeng Cui\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1609/AAAI.V34I07.6815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2534a3c894c93053341d514967c45c78657969c\",\"title\":\"Fast Learning of Temporal Action Proposal via Dense Boundary Generator\",\"url\":\"https://www.semanticscholar.org/paper/e2534a3c894c93053341d514967c45c78657969c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Liang Xu\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"46641540\",\"name\":\"W. Liu\"},{\"authorId\":\"152671983\",\"name\":\"Bin Feng\"}],\"doi\":\"10.1109/TCSVT.2019.2944430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"517c23e4dfc3c58270ef0475028a7adcffae2cbe\",\"title\":\"Cascaded Boundary Network for High-Quality Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/517c23e4dfc3c58270ef0475028a7adcffae2cbe\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1912.07872\",\"authors\":[{\"authorId\":\"8840460\",\"name\":\"Renchun You\"},{\"authorId\":\"66163465\",\"name\":\"Zhiyao Guo\"},{\"authorId\":\"145500846\",\"name\":\"Lei Cui\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"40106915\",\"name\":\"Sid Ying-Ze Bao\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/AAAI.V34I07.6964\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"913c70859584120374a886889508a1ed20f15824\",\"title\":\"Cross-Modality Attention with Semantic Graph Embedding for Multi-Label Classification\",\"url\":\"https://www.semanticscholar.org/paper/913c70859584120374a886889508a1ed20f15824\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145691225\",\"name\":\"Santiago Castro\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"1724416445\",\"name\":\"Cristina Noujaim\"},{\"authorId\":\"30646659\",\"name\":\"R. Wang\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"title\":\"LifeQA: A Real-life Dataset for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1801.10281\",\"authors\":[{\"authorId\":\"39168231\",\"name\":\"Guangyu Zhong\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"4642456\",\"name\":\"Z. Su\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV.2018.00192\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c050087b5af1bcdcd0a9c021efc0fe9f862a4e64\",\"title\":\"Learning Video-Story Composition via Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c050087b5af1bcdcd0a9c021efc0fe9f862a4e64\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1909.13474\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICMLA.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"title\":\"Spatio-Temporal FAST 3D Convolutions for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.02792\",\"authors\":[{\"authorId\":\"74480447\",\"name\":\"Manjot Bilkhu\"},{\"authorId\":\"14506569\",\"name\":\"S. Wang\"},{\"authorId\":\"70060571\",\"name\":\"Tushar Dobhal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2cb203f6b09a3bf734c705c999da706b7a7c031\",\"title\":\"Attention is all you need for Videos: Self-attention based Video Summarization using Universal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/b2cb203f6b09a3bf734c705c999da706b7a7c031\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144809605\",\"name\":\"Xiaolong Liu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2034194541\",\"name\":\"Jianghu Lu\"},{\"authorId\":\"2034240637\",\"name\":\"Cong Yao\"},{\"authorId\":\"47943518\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/LSP.2020.3037796\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"title\":\"Self-Similarity Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1709.02477\",\"authors\":[{\"authorId\":\"1782486\",\"name\":\"P. Varma\"},{\"authorId\":\"145522994\",\"name\":\"Bryan D. He\"},{\"authorId\":\"34765717\",\"name\":\"P. Bajaj\"},{\"authorId\":\"24576644\",\"name\":\"Nishith Khandwala\"},{\"authorId\":\"2080947\",\"name\":\"I. Banerjee\"},{\"authorId\":\"143648587\",\"name\":\"D. Rubin\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34e30aaf0dd80b3f630a3d9fab1db4eb6a15a593\",\"title\":\"Inferring Generative Model Structure with Static Analysis\",\"url\":\"https://www.semanticscholar.org/paper/34e30aaf0dd80b3f630a3d9fab1db4eb6a15a593\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1603.09439\",\"authors\":[{\"authorId\":\"1879100\",\"name\":\"P. Nguyen\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"title\":\"The Open World of Micro-Videos\",\"url\":\"https://www.semanticscholar.org/paper/f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1811.08264\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"49219434\",\"name\":\"Siyuan Zhou\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"47775885\",\"name\":\"Liang Xu\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"39547281\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"47905788\",\"name\":\"Y. Wang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8671a739a95f57946a625c3eada1f4addc60aea\",\"title\":\"Transferable Interactiveness Prior for Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/c8671a739a95f57946a625c3eada1f4addc60aea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1608.00797\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48596202\",\"name\":\"Hang Song\"},{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8d3b24cd4e6477e9dc7979580449db962d50e19\",\"title\":\"CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016\",\"url\":\"https://www.semanticscholar.org/paper/b8d3b24cd4e6477e9dc7979580449db962d50e19\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804033\",\"name\":\"K. Ueki\"},{\"authorId\":\"2495278\",\"name\":\"Takayuki Hori\"},{\"authorId\":\"1709528\",\"name\":\"T. Kobayashi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbb2e25ed8ace254327c4653f80ab99bc1a8131b\",\"title\":\"Waseda_Meisei_SoftBank at TRECVID 2019: Ad-hoc Video Search\",\"url\":\"https://www.semanticscholar.org/paper/dbb2e25ed8ace254327c4653f80ab99bc1a8131b\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":\"1707.09143\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.5244/C.31.22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49035023\",\"name\":\"T. Nguyen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"title\":\"Automatic Video Captioning using Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145396833\",\"name\":\"R. Kavitha\"},{\"authorId\":\"1581773209\",\"name\":\"D. Chitra\"}],\"doi\":\"10.1007/s12652-020-02157-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f11f4c85c20e8296151cf8cb57c8228e38b304a\",\"title\":\"An improved hybridized deep structured model for accurate video event recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f11f4c85c20e8296151cf8cb57c8228e38b304a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.06552\",\"authors\":[{\"authorId\":\"1879100\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/ICCV.2019.00560\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3682a78f3bd9b907c1c9890a847379b6ede82763\",\"title\":\"Weakly-Supervised Action Localization With Background Modeling\",\"url\":\"https://www.semanticscholar.org/paper/3682a78f3bd9b907c1c9890a847379b6ede82763\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"6615978\",\"name\":\"Yang Zhao\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"}],\"doi\":\"10.1007/978-3-030-58595-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"title\":\"A Flexible Recurrent Residual Pyramid Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941434\",\"name\":\"Yuanxi Li\"},{\"authorId\":\"3186016\",\"name\":\"Xiaohan Xia\"},{\"authorId\":\"1455832552\",\"name\":\"Dongmei Jiang\"},{\"authorId\":\"48077408\",\"name\":\"H. Sahli\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"}],\"doi\":\"10.1145/3395035.3425358\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"421ae1547c502a0908f3be111282778e35903c68\",\"title\":\"MEMOS: A Multi-modal Emotion Stream Database for Temporal Spontaneous Emotional State Detection\",\"url\":\"https://www.semanticscholar.org/paper/421ae1547c502a0908f3be111282778e35903c68\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07734\",\"authors\":[{\"authorId\":\"150084753\",\"name\":\"Da-Hye Yoon\"},{\"authorId\":\"2853939\",\"name\":\"Nam-Gyu Cho\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107396\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccb5500820669f70ea16f981cce0d32a0d5c0306\",\"title\":\"A Novel Online Action Detection Framework from Untrimmed Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/ccb5500820669f70ea16f981cce0d32a0d5c0306\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01252-6_13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9258ae3ad05e77555d3459dfbcfa9c70440c5f88\",\"title\":\"What Do I Annotate Next? An Empirical Study of Active Learning for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/9258ae3ad05e77555d3459dfbcfa9c70440c5f88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413975\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"title\":\"Dual Path Interaction Network for Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"title\":\"Constraining Temporal Relationship for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.06642\",\"authors\":[{\"authorId\":\"2022687\",\"name\":\"Hajar Sadeghi Sokeh\"},{\"authorId\":\"1689047\",\"name\":\"V. Argyriou\"},{\"authorId\":\"7158544\",\"name\":\"Dorothy Monekosso\"},{\"authorId\":\"1711669\",\"name\":\"Paolo Remagnino\"}],\"doi\":\"10.1109/ICPR.2018.8545723\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dacf112f821bfd775e69590fad02b23154419029\",\"title\":\"Superframes, A Temporal Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/dacf112f821bfd775e69590fad02b23154419029\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dba69f6d1e5b0ab75a5b317debec898a406a92bb\",\"title\":\"REAL-TIME HUMAN ACTIVITY RECOGNITION BASED ON RADAR A THESIS SUBMITTED TO THE GRADUATE SCHOOL IN PARTIAL FULFILLMENT OF THE REQUIREMENT FOR THE DEGREE MASTER OF SCIENCE BY HANQING GUO\",\"url\":\"https://www.semanticscholar.org/paper/dba69f6d1e5b0ab75a5b317debec898a406a92bb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1911.09963\",\"authors\":[{\"authorId\":\"1429148175\",\"name\":\"Pilhyeon Lee\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1609/AAAI.V34I07.6793\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89d28af38b1993d2cb3ab04d2c5e9aeaaf383286\",\"title\":\"Background Suppression Network for Weakly-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/89d28af38b1993d2cb3ab04d2c5e9aeaaf383286\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413954\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"title\":\"Towards More Explainability: Concept Knowledge Mining Network for Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.01007\",\"authors\":[{\"authorId\":\"33548956\",\"name\":\"Y. Xie\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"102786474\",\"name\":\"Yonglu Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"821ddd3782bdd4a6945ac69dc428d47b342256b5\",\"title\":\"DecAug: Augmenting HOI Detection via Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/821ddd3782bdd4a6945ac69dc428d47b342256b5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40547902\",\"name\":\"L. M. Dang\"},{\"authorId\":\"114915097\",\"name\":\"Kyungbok Min\"},{\"authorId\":\"1878085541\",\"name\":\"Hanxiang Wang\"},{\"authorId\":\"27648067\",\"name\":\"Md. Jalil Piran\"},{\"authorId\":\"115465984\",\"name\":\"Cheol Hee Lee\"},{\"authorId\":\"73078584\",\"name\":\"Hyeonjoon Moon\"}],\"doi\":\"10.1016/j.patcog.2020.107561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b6936905a1fcef9af31bdab49ec99581c03fd83\",\"title\":\"Sensor-based and vision-based human activity recognition: A comprehensive survey\",\"url\":\"https://www.semanticscholar.org/paper/5b6936905a1fcef9af31bdab49ec99581c03fd83\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2479610\",\"name\":\"O. Yalcinkaya\"},{\"authorId\":\"2540074\",\"name\":\"Eren Golge\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"}],\"doi\":\"10.1007/s00138-020-01079-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0b543a0aeca4a305eaf768c7c15957e53e8527f\",\"title\":\"I-ME: iterative model evolution for learning from weakly labeled images and videos\",\"url\":\"https://www.semanticscholar.org/paper/f0b543a0aeca4a305eaf768c7c15957e53e8527f\",\"venue\":\"Machine Vision and Applications\",\"year\":2020},{\"arxivId\":\"1511.02917\",\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"116230588\",\"name\":\"A. N. Gorban\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"195df1106f4d7aff0e9cb609358abbf80f54a716\",\"title\":\"Detecting Events and Key Actors in Multi-person Videos\",\"url\":\"https://www.semanticscholar.org/paper/195df1106f4d7aff0e9cb609358abbf80f54a716\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/ICASSP.2017.7952427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cdc9bb623bf7e587c8ffb9561aaab9a7e1f0a95\",\"title\":\"Action-vectors: Unsupervised movement modeling for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc9bb623bf7e587c8ffb9561aaab9a7e1f0a95\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144816684\",\"name\":\"K. Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"title\":\"Learning Video Representations using Contrastive Bidirectional Transformer\",\"url\":\"https://www.semanticscholar.org/paper/025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3452354\",\"name\":\"Caihong Yuan\"},{\"authorId\":\"2217316\",\"name\":\"Jingjuan Guo\"},{\"authorId\":\"144734887\",\"name\":\"P. Feng\"},{\"authorId\":\"2037865\",\"name\":\"Zhiqiang Zhao\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"8269333\",\"name\":\"Tianjiang Wang\"},{\"authorId\":\"40497566\",\"name\":\"Gwang-Min Choe\"},{\"authorId\":\"47075453\",\"name\":\"K. Duan\"}],\"doi\":\"10.1016/j.neucom.2018.11.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4de338e8d26501df6e8840aaba97414a14cee1d\",\"title\":\"A jointly learned deep embedding for person re-identification\",\"url\":\"https://www.semanticscholar.org/paper/c4de338e8d26501df6e8840aaba97414a14cee1d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1704.07945\",\"authors\":[{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2017.162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06184106c9a5dc602cac98f162b991707aaa4a80\",\"title\":\"Spatio-Temporal Person Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/06184106c9a5dc602cac98f162b991707aaa4a80\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"563734713a37f3db7d37eabde24e6184495a1567\",\"title\":\"AutoLoc: Weakly-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/563734713a37f3db7d37eabde24e6184495a1567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.07442\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df2f2591054080d069e563cb9ca4e0592bc6df08\",\"title\":\"V4D: 4D Convolutional Neural Networks for Video-level Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/df2f2591054080d069e563cb9ca4e0592bc6df08\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1804.01429\",\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2019.00135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9664f41b8e21125fed01fa3858ca40949fb73e01\",\"title\":\"Layout-Induced Video Representation for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/9664f41b8e21125fed01fa3858ca40949fb73e01\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.07915\",\"authors\":[{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"144742695\",\"name\":\"D. Xu\"},{\"authorId\":\"1491152801\",\"name\":\"Jinhu Dong\"},{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"title\":\"LAP-Net: Adaptive Features Sampling via Learning Action Progression for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1509.07225\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2015.298\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d925db7c9e3cca2e8fed644f750d218a48cd081\",\"title\":\"Automatic Concept Discovery from Parallel Text and Visual Corpora\",\"url\":\"https://www.semanticscholar.org/paper/4d925db7c9e3cca2e8fed644f750d218a48cd081\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/ICIP40778.2020.9190869\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"title\":\"A Feature Pair Fusion And Hierarchical Learning Framework For Video Re-Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490866837\",\"name\":\"Chan Zheng\"},{\"authorId\":\"50030933\",\"name\":\"X. Yang\"},{\"authorId\":\"46875450\",\"name\":\"Xunmu Zhu\"},{\"authorId\":\"2023742062\",\"name\":\"Chen Changxin\"},{\"authorId\":\"49681427\",\"name\":\"L. Wang\"},{\"authorId\":\"41157630\",\"name\":\"Shuqin Tu\"},{\"authorId\":\"46889237\",\"name\":\"Aqing Yang\"},{\"authorId\":\"3104125\",\"name\":\"Yueju Xue\"}],\"doi\":\"10.1016/j.biosystemseng.2020.04.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"title\":\"Automatic posture change analysis of lactating sows by action localisation and tube optimisation from untrimmed depth videos\",\"url\":\"https://www.semanticscholar.org/paper/c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.08944\",\"authors\":[{\"authorId\":\"144739319\",\"name\":\"R. Lienhart\"},{\"authorId\":\"35920821\",\"name\":\"Moritz Einfalt\"},{\"authorId\":\"2063137\",\"name\":\"D. Zecha\"}],\"doi\":\"10.2478/ijcss-2018-0005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2daf6d1b69c645be6931ea1550677b7ca797b393\",\"title\":\"Mining Automatically Estimated Poses from Video Recordings of Top Athletes\",\"url\":\"https://www.semanticscholar.org/paper/2daf6d1b69c645be6931ea1550677b7ca797b393\",\"venue\":\"Int. J. Comput. Sci. Sport\",\"year\":2018},{\"arxivId\":\"1804.09627\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1145/3265987.3265995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1802.02522\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"title\":\"Joint Attention in Driver-Pedestrian Interaction: from Theory to Practice\",\"url\":\"https://www.semanticscholar.org/paper/a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46174376\",\"name\":\"R. Wilson\"},{\"authorId\":\"69407115\",\"name\":\"E. Hancock\"},{\"authorId\":\"145242734\",\"name\":\"W. Smith\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7899d07c7caab3a0e5936efcd9a83088948e70\",\"title\":\"Video Stream Retrieval of Unseen Queries using Semantic Memory\",\"url\":\"https://www.semanticscholar.org/paper/dd7899d07c7caab3a0e5936efcd9a83088948e70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2008.09837\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2020.3016486\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"086057656b94de8bfd0d50ebe935e3d433f593d3\",\"title\":\"Revisiting Anchor Mechanisms for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/086057656b94de8bfd0d50ebe935e3d433f593d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2549731\",\"name\":\"Jian Shao\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1007/s11063-019-10003-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bf0b37ed005285b6cbef70a78434978ca065120\",\"title\":\"Hierarchical Temporal Fusion of Multi-grained Attention Features for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8bf0b37ed005285b6cbef70a78434978ca065120\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423585913\",\"name\":\"Thanyaporn Noiplab\"},{\"authorId\":\"3114320\",\"name\":\"Mongkon Sakdanupab\"},{\"authorId\":\"1423707557\",\"name\":\"Akara Supratak\"},{\"authorId\":\"2293824\",\"name\":\"T. Intharah\"}],\"doi\":\"10.1109/ISCIT.2019.8905136\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815e806daccb646a062782f6051739ec73b4ed2a\",\"title\":\"Construction of A Mobile Video Retrieval Dataset in the Cloud: Dos, Don\\u2019ts, and the Analysis\",\"url\":\"https://www.semanticscholar.org/paper/815e806daccb646a062782f6051739ec73b4ed2a\",\"venue\":\"2019 19th International Symposium on Communications and Information Technologies (ISCIT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122572973\",\"name\":\"Md. Moniruzzaman\"},{\"authorId\":\"1993660364\",\"name\":\"Zhaozheng Yin\"},{\"authorId\":\"1700714\",\"name\":\"Z. He\"},{\"authorId\":\"2777406\",\"name\":\"R. Qin\"},{\"authorId\":\"2281499\",\"name\":\"Ming C. Leu\"}],\"doi\":\"10.1145/3394171.3413687\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"393aaa45767018e184499556f078640fb016475b\",\"title\":\"Action Completeness Modeling with Background Aware Networks for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/393aaa45767018e184499556f078640fb016475b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.06496\",\"authors\":[{\"authorId\":\"50819719\",\"name\":\"Tian Wang\"},{\"authorId\":\"152384041\",\"name\":\"Shiye Lei\"},{\"authorId\":\"116503541\",\"name\":\"Youyou Jiang\"},{\"authorId\":\"97207595\",\"name\":\"Zihang Deng\"},{\"authorId\":\"50821858\",\"name\":\"Xin Su\"},{\"authorId\":\"2103629\",\"name\":\"Hichem Snoussi\"},{\"authorId\":\"145685544\",\"name\":\"Chang Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8041479e3018f7b0fa8e275beeda6998725ff7c3\",\"title\":\"Improving temporal action proposal generation by using high performance computing\",\"url\":\"https://www.semanticscholar.org/paper/8041479e3018f7b0fa8e275beeda6998725ff7c3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518145\",\"name\":\"Yantao Lu\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/GlobalSIP.2018.8646367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c28cadedb6b05ba3ed806be920f2730c5114633b\",\"title\":\"HUMAN ACTIVITY CLASSIFICATION INCORPORATING EGOCENTRIC VIDEO AND INERTIAL MEASUREMENT UNIT DATA\",\"url\":\"https://www.semanticscholar.org/paper/c28cadedb6b05ba3ed806be920f2730c5114633b\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.82\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c535d4d61aa0f1d8aadb4082bdcc19f4cbdf0eaf\",\"title\":\"Unsupervised Action Discovery and Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c535d4d61aa0f1d8aadb4082bdcc19f4cbdf0eaf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1706.08222\",\"authors\":[{\"authorId\":\"46802326\",\"name\":\"E. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f5d0e3db3260b334ab3d1ea99d788632b0f076a\",\"title\":\"YouTube-8M Video Understanding Challenge Approach and Applications\",\"url\":\"https://www.semanticscholar.org/paper/8f5d0e3db3260b334ab3d1ea99d788632b0f076a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2008.08716\",\"authors\":[{\"authorId\":\"152666334\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"title\":\"Text-based Localization of Moments in a Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09781\",\"authors\":[{\"authorId\":\"5115178\",\"name\":\"Y. Cai\"},{\"authorId\":\"2005455805\",\"name\":\"Chang Liu\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a7e6d2d2d8e704890c9665c0be20d0e1eb2c9e0\",\"title\":\"Towards Spatio-Temporal Video Scene Text Detection via Temporal Clustering\",\"url\":\"https://www.semanticscholar.org/paper/6a7e6d2d2d8e704890c9665c0be20d0e1eb2c9e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10033841\",\"name\":\"Xinzhe Zhou\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1145/3372278.3390687\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"title\":\"Google Helps YouTube: Learning Few-Shot Video Classification from Historic Tasks and Cross-Domain Sample Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1910.11285\",\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"45f395d2bb7cb41a7aff934cbecc9f567a27a070\",\"title\":\"Towards Train-Test Consistency for Semi-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/45f395d2bb7cb41a7aff934cbecc9f567a27a070\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7c75b16563d07069505cd07dd6466d86f6958f9\",\"title\":\"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/e7c75b16563d07069505cd07dd6466d86f6958f9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV45572.2020.9093612\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"title\":\"Learning Multimodal Representations for Unseen Activities\",\"url\":\"https://www.semanticscholar.org/paper/dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"13384075\",\"name\":\"Minzhi Zhu\"},{\"authorId\":\"2513605\",\"name\":\"Huiyuan Fu\"},{\"authorId\":\"40013029\",\"name\":\"Hua-Dong Ma\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3394171.3416298\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaf34194a0e86fc5ed29a258594fa580b828e997\",\"title\":\"Enhancing Anomaly Detection in Surveillance Videos with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eaf34194a0e86fc5ed29a258594fa580b828e997\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49402429\",\"name\":\"J. Yu\"},{\"authorId\":\"46533851\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"40322073\",\"name\":\"L. Wan\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TCSVT.2019.2919064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10129da014606c70b6fab077319491c772b01c04\",\"title\":\"Spatio-Temporal Deep Q-Networks for Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/10129da014606c70b6fab077319491c772b01c04\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1909.05010\",\"authors\":[{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"title\":\"Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":\"10.1145/3343031.3350998\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1e5fbf1440850bdea40aeee99956cb6e01e2e22\",\"title\":\"Exploring Background-bias for Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/e1e5fbf1440850bdea40aeee99956cb6e01e2e22\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/512\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"title\":\"Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.03911\",\"authors\":[{\"authorId\":\"3448729\",\"name\":\"\\u0141ukasz Borchmann\"},{\"authorId\":\"144744788\",\"name\":\"D. Wi\\u015bniewski\"},{\"authorId\":\"82974374\",\"name\":\"Andrzej Gretkowski\"},{\"authorId\":\"1400414712\",\"name\":\"Izabela Kosmala\"},{\"authorId\":\"1400414734\",\"name\":\"Dawid Jurkiewicz\"},{\"authorId\":\"1400414662\",\"name\":\"Lukasz Szalkiewicz\"},{\"authorId\":\"1400414730\",\"name\":\"G. Pa\\u0142ka\"},{\"authorId\":\"145104037\",\"name\":\"Karol Kaczmarek\"},{\"authorId\":\"69496188\",\"name\":\"Agnieszka K. Kaliska\"},{\"authorId\":\"2195272\",\"name\":\"F. Gralinski\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"612286e4ab099ad52b182eda94e91f59521f66ff\",\"title\":\"Contract Discovery: Dataset and a Few-shot Semantic Retrieval Challenge with Competitive Baselines\",\"url\":\"https://www.semanticscholar.org/paper/612286e4ab099ad52b182eda94e91f59521f66ff\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.13705\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1007/978-3-030-58580-8_9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2ae9cea622f68e1e32b7e6ae5a3c92213e192bf8\",\"title\":\"Learning to Localize Actions from Moments\",\"url\":\"https://www.semanticscholar.org/paper/2ae9cea622f68e1e32b7e6ae5a3c92213e192bf8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66471378\",\"name\":\"Allah Bux\"}],\"doi\":\"10.17635/LANCASTER/THESIS/186\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"title\":\"Vision-based human action recognition using machine learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"2028829514\",\"name\":\"Leming Guo\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TIP.2020.3038372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6648479157216bee1f31ef9718fcb64eeafa6843\",\"title\":\"A Pairwise Attentive Adversarial Spatiotemporal Network for Cross-Domain Few-Shot Action Recognition-R2\",\"url\":\"https://www.semanticscholar.org/paper/6648479157216bee1f31ef9718fcb64eeafa6843\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1906.01452\",\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"40474871\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1109/TPAMI.2019.2920899\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83a3fe38887880bccc15daa740d8d5041f826d91\",\"title\":\"Reconstruct and Represent Video Contents for Captioning via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/83a3fe38887880bccc15daa740d8d5041f826d91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.04052\",\"authors\":[{\"authorId\":\"152338671\",\"name\":\"Yiitan Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350985\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"745242c746b6f379048f6dbdfc009181d9027a60\",\"title\":\"Sentence Specified Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/745242c746b6f379048f6dbdfc009181d9027a60\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1906.11902\",\"authors\":[{\"authorId\":\"150282338\",\"name\":\"Roshan Prakash Rane\"},{\"authorId\":\"1573750032\",\"name\":\"Edit Szugyi\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"},{\"authorId\":\"2983978\",\"name\":\"S. Stober\"}],\"doi\":\"10.1145/3372278.3390694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48c39ab475793b349809d7af2d5797bc1e77f48d\",\"title\":\"PredNet and Predictive Coding: A Critical Review\",\"url\":\"https://www.semanticscholar.org/paper/48c39ab475793b349809d7af2d5797bc1e77f48d\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2005.10266\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"50563570\",\"name\":\"Bowen Cheng\"},{\"authorId\":\"31604982\",\"name\":\"Maxwell D. Collins\"},{\"authorId\":\"145071362\",\"name\":\"E. D. Cubuk\"},{\"authorId\":\"2368067\",\"name\":\"Barret Zoph\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"}],\"doi\":\"10.1007/978-3-030-58545-7_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df32921dbc13a65a5dae101db58a8d9d9d92ca16\",\"title\":\"Leveraging Semi-Supervised Learning in Video Sequences for Urban Scene Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/df32921dbc13a65a5dae101db58a8d9d9d92ca16\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.10229\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"title\":\"Intra- and Inter-Action Understanding via Temporal Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1910.05899\",\"authors\":[{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"50814744\",\"name\":\"Jia-xiang Wang\"},{\"authorId\":\"144081363\",\"name\":\"Chao Li\"},{\"authorId\":\"1390667177\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"983e99bf560edcee1676b68dc81b570f03fb5835\",\"title\":\"TruNet: Short Videos Generation from Long Videos via Story-Preserving Truncation\",\"url\":\"https://www.semanticscholar.org/paper/983e99bf560edcee1676b68dc81b570f03fb5835\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d44b837b8f9e1f03d6075059e1c07381c61576d\",\"title\":\"Tagging and Browsing Videos According to the Preferences of Differing Affinity Groups\",\"url\":\"https://www.semanticscholar.org/paper/7d44b837b8f9e1f03d6075059e1c07381c61576d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66589187\",\"name\":\"Hanjian Song\"},{\"authorId\":\"144569176\",\"name\":\"Lihua Tian\"},{\"authorId\":\"1414577137\",\"name\":\"Chen Li\"}],\"doi\":\"10.1007/s11042-020-08771-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"195bbbb21261fe1f1a7380646fc9042228989df8\",\"title\":\"Action temporal detection method based on confidence curve analysis\",\"url\":\"https://www.semanticscholar.org/paper/195bbbb21261fe1f1a7380646fc9042228989df8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1908.10899\",\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Surveillance Video\",\"url\":\"https://www.semanticscholar.org/paper/8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47971190\",\"name\":\"Yan Yan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"46689429\",\"name\":\"Dawen Cai\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2017.115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"848aadee1f7facae95ba38baf4e896757376c3d5\",\"title\":\"Weakly Supervised Actor-Action Segmentation via Robust Multi-task Ranking\",\"url\":\"https://www.semanticscholar.org/paper/848aadee1f7facae95ba38baf4e896757376c3d5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.07373\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c69040777e2b0e1d443e22f86e45e527381d79e7\",\"title\":\"ViCom: Benchmark and Methods for Video Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c69040777e2b0e1d443e22f86e45e527381d79e7\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"153216896\",\"name\":\"D. Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"title\":\"MSR Asia MSM at ActivityNet Challenge 2017: Trimmed Action Recognition, Temporal Action Proposals and Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"title\":\"ops Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"},{\"authorId\":\"50059546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1109/LSP.2018.2888758\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"afa59eb5fedbcabc895ca7b43d6669ad9bbeda87\",\"title\":\"End-to-End Temporal Action Detection Using Bag of Discriminant Snippets\",\"url\":\"https://www.semanticscholar.org/paper/afa59eb5fedbcabc895ca7b43d6669ad9bbeda87\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":\"1707.06750\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"title\":\"Temporal Convolution Based Action Proposal: Submission to ActivityNet 2017\",\"url\":\"https://www.semanticscholar.org/paper/af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Li\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1007/978-3-030-01231-1_32\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"74c19438c78a136677a7cb9004c53684a4ae56ff\",\"title\":\"RESOUND: Towards Action Recognition Without Representation Bias\",\"url\":\"https://www.semanticscholar.org/paper/74c19438c78a136677a7cb9004c53684a4ae56ff\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23183064\",\"name\":\"Roberto Menicatti\"},{\"authorId\":\"1761802\",\"name\":\"A. Sgorbissa\"}],\"doi\":\"10.1109/ROMAN.2017.8172472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a190e080ec07d4dec2b43b0e299eae45571c0e3\",\"title\":\"A cloud-based scene recognition framework for in-home assistive robots\",\"url\":\"https://www.semanticscholar.org/paper/5a190e080ec07d4dec2b43b0e299eae45571c0e3\",\"venue\":\"2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144196376\",\"name\":\"Z. Fang\"},{\"authorId\":\"2505157\",\"name\":\"Dezhi Hong\"},{\"authorId\":\"145170139\",\"name\":\"R. Gupta\"}],\"doi\":\"10.1145/3304109.3306221\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01fa5eb436db99529af2ab69722416afcb03d03e\",\"title\":\"Serving deep neural networks at the cloud edge for vision applications on mobile platforms\",\"url\":\"https://www.semanticscholar.org/paper/01fa5eb436db99529af2ab69722416afcb03d03e\",\"venue\":\"MMSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39042074\",\"name\":\"Ian Tu\"},{\"authorId\":\"145901092\",\"name\":\"A. Bhalerao\"},{\"authorId\":\"144482645\",\"name\":\"N. Griffiths\"},{\"authorId\":\"49625872\",\"name\":\"M. Delgado\"},{\"authorId\":\"2059974\",\"name\":\"Alasdair Thomason\"},{\"authorId\":\"2568126\",\"name\":\"T. Popham\"},{\"authorId\":\"2261735\",\"name\":\"A. Mouzakitis\"}],\"doi\":\"10.1109/IVS.2018.8500564\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27b06d8d09b0190f44597214627f0e8c65031ad9\",\"title\":\"Dual Viewpoint Passenger State Classification Using 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/27b06d8d09b0190f44597214627f0e8c65031ad9\",\"venue\":\"2018 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2018},{\"arxivId\":\"1907.09702\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"48032598\",\"name\":\"X. Liu\"},{\"authorId\":\"48568672\",\"name\":\"Xin Li\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faf5651d82885243f5d310ced0e39e0703add073\",\"title\":\"BMN: Boundary-Matching Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/faf5651d82885243f5d310ced0e39e0703add073\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15187304\",\"name\":\"Chien-Fang Chiu\"},{\"authorId\":\"1726411\",\"name\":\"Chien-Hao Kuo\"},{\"authorId\":\"145456212\",\"name\":\"P. Chang\"}],\"doi\":\"10.23919/APSIPA.2018.8659703\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"369e25b87bff71e350e995a890ab69965c20e488\",\"title\":\"Smoking Action Recognition Based on Spatial-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/369e25b87bff71e350e995a890ab69965c20e488\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"1903.02874\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50792340\",\"name\":\"Dajun Ding\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\"},{\"authorId\":\"145473095\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/CVPR.2019.00130\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"title\":\"COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.09568\",\"authors\":[{\"authorId\":\"38173241\",\"name\":\"Yu Luo\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"2164408\",\"name\":\"R. Adams\"},{\"authorId\":\"46275685\",\"name\":\"J. Li\"},{\"authorId\":\"46298867\",\"name\":\"M. Newman\"},{\"authorId\":\"1699550\",\"name\":\"J. Z. Wang\"}],\"doi\":\"10.1007/s11263-019-01215-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61482c061e0d12d94c8d66a259bd2cac76d65d49\",\"title\":\"ARBEE: Towards Automated Recognition of Bodily Expression of Emotion in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/61482c061e0d12d94c8d66a259bd2cac76d65d49\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1912.06992\",\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"title\":\"Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.12165\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.24963/ijcai.2019/610\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d145292fd11ca274693ec9ea6941a9147ae5868\",\"title\":\"Localizing Unseen Activities in Video via Image Query\",\"url\":\"https://www.semanticscholar.org/paper/5d145292fd11ca274693ec9ea6941a9147ae5868\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733072400\",\"name\":\"Min-Huan Fu\"},{\"authorId\":\"26958446\",\"name\":\"An-Zi Yen\"},{\"authorId\":\"2611607\",\"name\":\"Hen-Hsen Huang\"},{\"authorId\":\"153924342\",\"name\":\"Hsin-Hsi Chen\"}],\"doi\":\"10.1145/3372278.3390700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665576b67476e4f9e259fe831fab09657c323b80\",\"title\":\"Incorporating Semantic Knowledge for Visual Lifelog Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/665576b67476e4f9e259fe831fab09657c323b80\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.09812\",\"authors\":[{\"authorId\":\"107979102\",\"name\":\"Juan Leon Alcazar\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR42600.2020.01248\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34c8161a352bce60b64b6382b1ff7280433ad654\",\"title\":\"Active Speakers in Context\",\"url\":\"https://www.semanticscholar.org/paper/34c8161a352bce60b64b6382b1ff7280433ad654\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1812.05231\",\"authors\":[{\"authorId\":\"5911068\",\"name\":\"V. Kaushik\"},{\"authorId\":\"2550012\",\"name\":\"Prerana Mukherjee\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"}],\"doi\":\"10.1145/3293353.3293419\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d99fd437137b8562ed4f4ece533d4d363ebcf0b2\",\"title\":\"Nrityantar: Pose oblivious Indian classical dance sequence classification system\",\"url\":\"https://www.semanticscholar.org/paper/d99fd437137b8562ed4f4ece533d4d363ebcf0b2\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"2008.11254\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"title\":\"Temporal Action Localization with Variance-Aware Networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"66622154\",\"name\":\"Ray Ptucha\"}],\"doi\":\"10.1007/s10044-018-00770-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"title\":\"Understanding temporal structure for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":\"2009.09071\",\"authors\":[{\"authorId\":\"46533220\",\"name\":\"Saurabh Mishra\"},{\"authorId\":\"144901925\",\"name\":\"J. Clark\"},{\"authorId\":\"144735264\",\"name\":\"C. Perrault\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"188f52241dc6e6c5316420bc605d8ff829107403\",\"title\":\"Measurement in AI Policy: Opportunities and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/188f52241dc6e6c5316420bc605d8ff829107403\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9422489\",\"name\":\"Shuyan Li\"},{\"authorId\":\"1723853\",\"name\":\"Z. Chen\"},{\"authorId\":\"100475213\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"121856633\",\"name\":\"Xiu Li\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/ICCV.2019.00830\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"721b29aa20ad5b258c35a9c368a1e7af261996f5\",\"title\":\"Neighborhood Preserving Hashing for Scalable Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/721b29aa20ad5b258c35a9c368a1e7af261996f5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.12432\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00137\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0a98ef88bae12639d8770e5680564b8f9a188bec\",\"title\":\"AdaFrame: Adaptive Frame Selection for Fast Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0a98ef88bae12639d8770e5680564b8f9a188bec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11004839\",\"name\":\"Jiarui Gao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/3078971.3079030\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a8b17cdeccf37c113f66f276b7a3ff03ac7ecd3\",\"title\":\"Frame-Transformer Emotion Classification Network\",\"url\":\"https://www.semanticscholar.org/paper/2a8b17cdeccf37c113f66f276b7a3ff03ac7ecd3\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1906.06813\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/WACV.2018.00045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"title\":\"A Temporal Sequence Learning for Action Recognition and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2004.06971\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e389ac072b25305c8f17af292ede43115479077a\",\"title\":\"ActionSpotter: Deep Reinforcement Learning Framework for Temporal Action Spotting in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e389ac072b25305c8f17af292ede43115479077a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.05515\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e599d703e358d6e554da859cff116553053d0fa\",\"title\":\"AViD Dataset: Anonymized Videos from Diverse Countries\",\"url\":\"https://www.semanticscholar.org/paper/0e599d703e358d6e554da859cff116553053d0fa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2007.01065\",\"authors\":[{\"authorId\":\"1729393497\",\"name\":\"Ziyang Song\"},{\"authorId\":\"1508368547\",\"name\":\"Z. Yin\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":\"144535741\",\"name\":\"C. Zhang\"},{\"authorId\":\"34739761\",\"name\":\"W. Chi\"},{\"authorId\":\"3338873\",\"name\":\"Yonggen Ling\"},{\"authorId\":\"13936152\",\"name\":\"Shenghao Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef66cdc03eefd0b9f11b021da8bb20164b79a21b\",\"title\":\"Attention-Oriented Action Recognition for Real-Time Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ef66cdc03eefd0b9f11b021da8bb20164b79a21b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.03305\",\"authors\":[{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2da82a8deec0d5e72919c7139d467089334d63d\",\"title\":\"BAR: Bayesian Activity Recognition using variational inference\",\"url\":\"https://www.semanticscholar.org/paper/a2da82a8deec0d5e72919c7139d467089334d63d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.13367\",\"authors\":[{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"1752865048\",\"name\":\"M. J. Seikavandi\"},{\"authorId\":\"9714545\",\"name\":\"J. V. Dueholm\"},{\"authorId\":\"1803459\",\"name\":\"Kamal Nasrollahi\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"16282981d35e696afc70724b6cc6a186a404fe92\",\"title\":\"SoccerNet-v2 : A Dataset and Benchmarks for Holistic Understanding of Broadcast Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/16282981d35e696afc70724b6cc6a186a404fe92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.03707\",\"authors\":[{\"authorId\":\"145535703\",\"name\":\"T. Adams\"}],\"doi\":\"10.1109/WACVW.2019.00010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6ae8884f31f18a073113f0bcdb2ae6efdc39cfb\",\"title\":\"Continuous, Full-scope, Spatio-temporal Tracking Metric based on KL-divergence\",\"url\":\"https://www.semanticscholar.org/paper/d6ae8884f31f18a073113f0bcdb2ae6efdc39cfb\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3706363\",\"name\":\"Y. Zhou\"},{\"authorId\":\"3234063\",\"name\":\"Jiankang Deng\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/FG.2018.00077\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e4df9b008050bdda42670c020d6ebc88b086e36d\",\"title\":\"Improve Accurate Pose Alignment and Action Localization by Dense Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/e4df9b008050bdda42670c020d6ebc88b086e36d\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.11200\",\"authors\":[{\"authorId\":\"1729858\",\"name\":\"Hyunwoo Lee\"},{\"authorId\":\"1784186\",\"name\":\"J. Kim\"},{\"authorId\":\"32671800\",\"name\":\"Dojun Yang\"},{\"authorId\":\"49476694\",\"name\":\"Joon-Ho Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf77949b099348d8adffb14d5290b1db3fb0d2e0\",\"title\":\"Embedded Real-Time Fall Detection Using Deep Learning For Elderly Care\",\"url\":\"https://www.semanticscholar.org/paper/bf77949b099348d8adffb14d5290b1db3fb0d2e0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":\"1912.04465\",\"authors\":[{\"authorId\":\"50262695\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"1500377539\",\"name\":\"Leilei Chen\"},{\"authorId\":\"152745066\",\"name\":\"Can-jin Wang\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3422844.3423051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"189895b7f56f39d9e4ae5edf85eda866dd0412ff\",\"title\":\"SoccerDB: A Large-Scale Database for Comprehensive Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/189895b7f56f39d9e4ae5edf85eda866dd0412ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.08375\",\"authors\":[{\"authorId\":\"46314731\",\"name\":\"W. Wang\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"8424682\",\"name\":\"H. Liu\"},{\"authorId\":\"2019481\",\"name\":\"S. Wang\"},{\"authorId\":\"144569553\",\"name\":\"Jian Cheng\"}],\"doi\":\"10.1109/ICPR.2018.8545487\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"211b35befe51baf018e971d53d3c35cacbe6ad3e\",\"title\":\"Temporal Action Detection by Joint Identification-Verification\",\"url\":\"https://www.semanticscholar.org/paper/211b35befe51baf018e971d53d3c35cacbe6ad3e\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"144129720\",\"name\":\"Xiao Wang\"},{\"authorId\":\"145473096\",\"name\":\"Yu Zheng\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/ICPR.2018.8545513\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"288db6d3369ddb6aba5d753e0a46ee32e2383bcd\",\"title\":\"From Text to Video: Exploiting Mid-Level Semantics for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/288db6d3369ddb6aba5d753e0a46ee32e2383bcd\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"48953082\",\"name\":\"Y. Guan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"40799321\",\"name\":\"L. Shao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2cca16e8477f677b4a4c3f1ab572f7fc425ee99\",\"title\":\"ActivityNet Kernelised Representation Generalised Multiple Instance Learning Deep Features NMF with JSD Transfer Joint Matching Actions in Unknown Datasets Word 2 Vec New Concepts Deep Network Matching 1 2 3\",\"url\":\"https://www.semanticscholar.org/paper/b2cca16e8477f677b4a4c3f1ab572f7fc425ee99\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":\"50841852\",\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1109/TIP.2019.2917283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"title\":\"Dense Dilated Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1904.01693\",\"authors\":[{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"225dc18db507147de068710839941900996a7329\",\"title\":\"Multigrid Predictive Filter Flow for Unsupervised Learning on Videos\",\"url\":\"https://www.semanticscholar.org/paper/225dc18db507147de068710839941900996a7329\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1859790847\",\"name\":\"Na Feng\"},{\"authorId\":\"1860555990\",\"name\":\"Zikai Song\"},{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"152828944\",\"name\":\"Y. P. Chen\"},{\"authorId\":\"2627212\",\"name\":\"Y. Zhao\"},{\"authorId\":\"49990818\",\"name\":\"Yunfeng He\"},{\"authorId\":\"151470350\",\"name\":\"Tao Guan\"}],\"doi\":\"10.1007/s11042-020-09414-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b26c30b70a90b812423e668687db39332addfa0\",\"title\":\"SSET: a dataset for shot segmentation, event detection, player tracking in soccer videos\",\"url\":\"https://www.semanticscholar.org/paper/3b26c30b70a90b812423e668687db39332addfa0\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50241967\",\"name\":\"P. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38283e35371f2a426305dee60e80cd28abb4f349\",\"title\":\"CMU-AML Submission to Moments in Time Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/38283e35371f2a426305dee60e80cd28abb4f349\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1907.08340\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"title\":\"Only Time Can Tell: Discovering Temporal Data for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP7010110\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a87e37d43d4c47bef8992ace408de0f872739efc\",\"title\":\"A Comprehensive Review on Handcrafted and Learning-Based Action Representation Approaches for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a87e37d43d4c47bef8992ace408de0f872739efc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518145\",\"name\":\"Yantao Lu\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/JSEN.2019.2934678\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5541850d7b646107370c1448317e45ad1eb66b63\",\"title\":\"Autonomous Human Activity Classification From Wearable Multi-Modal Sensors\",\"url\":\"https://www.semanticscholar.org/paper/5541850d7b646107370c1448317e45ad1eb66b63\",\"venue\":\"IEEE Sensors Journal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123331898\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"title\":\"Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/cvpr42600.2020.01404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aeb56eee55d26fa845c7872b996c3d92bc45abd\",\"title\":\"Improving Action Segmentation via Graph-Based Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2aeb56eee55d26fa845c7872b996c3d92bc45abd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.11236\",\"authors\":[{\"authorId\":\"50081274\",\"name\":\"L. Zhang\"},{\"authorId\":\"3480262\",\"name\":\"Zenglin Shi\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"3459992\",\"name\":\"Jiawang Bian\"},{\"authorId\":\"3111797\",\"name\":\"Z. Zeng\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.1109/tpami.2020.2976969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07335131c3f8b032ad2ddca317ccbac0997ec6f7\",\"title\":\"Ordered or Orderless: A Revisit for Video based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/07335131c3f8b032ad2ddca317ccbac0997ec6f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR42600.2020.00125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"370298c893ebb3f55c0d869ea68c5ffa1805ca08\",\"title\":\"ActionBytes: Learning From Trimmed Videos to Localize Actions\",\"url\":\"https://www.semanticscholar.org/paper/370298c893ebb3f55c0d869ea68c5ffa1805ca08\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"46246550\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f26caf22fd05659802db690c7e6c9db289be340\",\"title\":\"Modeling Temporal Concept Receptive Field Dynamically for Untrimmed Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1f26caf22fd05659802db690c7e6c9db289be340\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2759213\",\"name\":\"Jiman Kim\"},{\"authorId\":\"2836541\",\"name\":\"Chan-Jong Park\"}],\"doi\":\"10.1109/CVPRW.2017.158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fdcf14b2908891f9f1ef0751854fcd7ce9bb7ed\",\"title\":\"End-To-End Ego Lane Estimation Based on Sequential Transfer Learning for Self-Driving Cars\",\"url\":\"https://www.semanticscholar.org/paper/1fdcf14b2908891f9f1ef0751854fcd7ce9bb7ed\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"38702014\",\"name\":\"D. Zhang\"},{\"authorId\":\"1698689\",\"name\":\"N. Jojic\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/CVPR.2017.227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"738e3a6759e68f678c4c5f98282ac10090aaf273\",\"title\":\"ER3: A Unified Framework for Event Retrieval, Recognition and Recounting\",\"url\":\"https://www.semanticscholar.org/paper/738e3a6759e68f678c4c5f98282ac10090aaf273\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"49219434\",\"name\":\"Siyuan Zhou\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"151484848\",\"name\":\"Liang Xu\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"46395525\",\"name\":\"Y. Wang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPR.2019.00370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de0db3e37424167c4d08f701beb0b0da0200abc1\",\"title\":\"Transferable Interactiveness Knowledge for Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/de0db3e37424167c4d08f701beb0b0da0200abc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1707.09074\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2017.562\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6e65e93566b909c04d2d74bc1ade1592e476adf\",\"title\":\"Learning from Video and Text via Large-Scale Discriminative Clustering\",\"url\":\"https://www.semanticscholar.org/paper/f6e65e93566b909c04d2d74bc1ade1592e476adf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.04409\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"143972875\",\"name\":\"Alan Sullivan\"}],\"doi\":\"10.1109/WACV.2019.00196\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cfe4f0ff9886092f1aa3dbfc32156c622140bde\",\"title\":\"Sem-GAN: Semantically-Consistent Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/8cfe4f0ff9886092f1aa3dbfc32156c622140bde\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1801.08100\",\"authors\":[{\"authorId\":\"1403813423\",\"name\":\"Carolina Redondo-Cabrera\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"}],\"doi\":\"10.1016/j.cviu.2018.08.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6855ed66c8a8643aa287078a130308e4a045d288\",\"title\":\"Unsupervised learning from videos using temporal coherency deep networks\",\"url\":\"https://www.semanticscholar.org/paper/6855ed66c8a8643aa287078a130308e4a045d288\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"2006.07006\",\"authors\":[{\"authorId\":\"1429148175\",\"name\":\"Pilhyeon Lee\"},{\"authorId\":\"49605749\",\"name\":\"J. Wang\"},{\"authorId\":\"1500380529\",\"name\":\"Y. Lu\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cb8bb50e4b84739b9d3477eead0707d8c3a84cd8\",\"title\":\"Background Modeling via Uncertainty Estimation for Weakly-supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/cb8bb50e4b84739b9d3477eead0707d8c3a84cd8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395615456\",\"name\":\"Elena Nicora\"},{\"authorId\":\"2442124\",\"name\":\"Gaurvi Goyal\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"2511943\",\"name\":\"A. Vignolo\"},{\"authorId\":\"1961676436\",\"name\":\"Alessandra Sciutti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"}],\"doi\":\"10.1038/s41597-020-00776-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"title\":\"The MoCA dataset, kinematic and multi-view visual streams of fine-grained cooking actions\",\"url\":\"https://www.semanticscholar.org/paper/bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"venue\":\"Scientific data\",\"year\":2020},{\"arxivId\":\"1711.10061\",\"authors\":[{\"authorId\":\"145759966\",\"name\":\"Amir Sadeghian\"},{\"authorId\":\"29836452\",\"name\":\"Ferdinand Legros\"},{\"authorId\":\"49158553\",\"name\":\"Maxime Voisin\"},{\"authorId\":\"11138817\",\"name\":\"Ricky Vesel\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1007/978-3-030-01252-6_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e36e6fbd7b33e37b9b68eab8d50ef49840987ea\",\"title\":\"CAR-Net: Clairvoyant Attentive Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/3e36e6fbd7b33e37b9b68eab8d50ef49840987ea\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2008.10850\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58607-2_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"title\":\"Discriminability Distillation in Group Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.07833\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2702234\",\"name\":\"A. Gupta\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1007/978-3-030-58542-6_29\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d9e98cbe813ead99c5f4f57be4ff6949fb51442a\",\"title\":\"Latent Embedding Feedback and Discriminative Features for Zero-Shot Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9e98cbe813ead99c5f4f57be4ff6949fb51442a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.04689\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.01015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"title\":\"Action Recognition From Single Timestamp Supervision in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.09525\",\"authors\":[{\"authorId\":\"50364466\",\"name\":\"Anand Ramakrishnan\"},{\"authorId\":\"29794370\",\"name\":\"Brian Zylich\"},{\"authorId\":\"2920948\",\"name\":\"Erin Ottmar\"},{\"authorId\":\"1403733761\",\"name\":\"Jennifer LoCasale-Crouch\"},{\"authorId\":\"143973061\",\"name\":\"Jacob Whitehill\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a590eb812fbaf1e00eb3dd148cd42c905e8a6d1f\",\"title\":\"Toward Automated Classroom Observation: Multimodal Machine Learning to Estimate CLASS Positive Climate and Negative Climate\",\"url\":\"https://www.semanticscholar.org/paper/a590eb812fbaf1e00eb3dd148cd42c905e8a6d1f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.00241\",\"authors\":[{\"authorId\":\"47287745\",\"name\":\"Ankit Shah\"},{\"authorId\":\"51434736\",\"name\":\"Harini Kesavamoorthy\"},{\"authorId\":\"51441023\",\"name\":\"Poorva Rane\"},{\"authorId\":\"1989712\",\"name\":\"Pramati Kalwad\"},{\"authorId\":\"7661726\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"1740721\",\"name\":\"Florian Metze\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72f4c415b5f3ecf63380b6985c95c5af2ba72632\",\"title\":\"Activity Recognition on a Large Scale in Short Videos - Moments in Time Dataset\",\"url\":\"https://www.semanticscholar.org/paper/72f4c415b5f3ecf63380b6985c95c5af2ba72632\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"144466591\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2018.2887061\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c372c9892fa0e3b36675bbf63b221696cd8a8b1f\",\"title\":\"Fast and Accurate Action Detection in Videos With Motion-Centric Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/c372c9892fa0e3b36675bbf63b221696cd8a8b1f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"62e42d5655b7553d8940ca2fd9b9b9a72e3bb51f\",\"title\":\"Supplementary Material Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/62e42d5655b7553d8940ca2fd9b9b9a72e3bb51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.00532\",\"authors\":[{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"3112203\",\"name\":\"Yongqiang Huang\"},{\"authorId\":\"1388011059\",\"name\":\"J. Meloncon\"},{\"authorId\":\"49696823\",\"name\":\"Y. Sun\"}],\"doi\":\"10.1109/IROS40897.2019.8967754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"160ac4e532722761c061cdbd88d754616c80d970\",\"title\":\"Manipulation Motion Taxonomy and Coding for Robots\",\"url\":\"https://www.semanticscholar.org/paper/160ac4e532722761c061cdbd88d754616c80d970\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"896b764cff4d71f917c485593ef78d2f1ed7124d\",\"title\":\"Online, Supervised and Unsupervised Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/896b764cff4d71f917c485593ef78d2f1ed7124d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1903.09868\",\"authors\":[{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00564\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"db439bcc9088fb9a05c2777cf39a99eeb4e4c5cd\",\"title\":\"StartNet: Online Detection of Action Start in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/db439bcc9088fb9a05c2777cf39a99eeb4e4c5cd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.08216\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2951229\",\"name\":\"Hisham Cholakkal\"},{\"authorId\":\"152256401\",\"name\":\"Fahad Khan\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1109/ICCV.2019.00877\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4a762c74d6c1f66b1d7a6a439f35c5c30e37c53f\",\"title\":\"3C-Net: Category Count and Center Loss for Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a762c74d6c1f66b1d7a6a439f35c5c30e37c53f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812342\",\"name\":\"Yeongtaek Song\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3745/JIPS.04.0059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1787c26e178fc26897c813ea76f0601ab0494470\",\"title\":\"DeepAct: A Deep Neural Network Model for Activity Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/1787c26e178fc26897c813ea76f0601ab0494470\",\"venue\":\"J. Inf. Process. Syst.\",\"year\":2018},{\"arxivId\":\"2007.05887\",\"authors\":[{\"authorId\":\"46319494\",\"name\":\"Feiyu Yang\"},{\"authorId\":\"118521983\",\"name\":\"Zanmei Song\"},{\"authorId\":\"3468819\",\"name\":\"Z. Xiao\"},{\"authorId\":\"9407280\",\"name\":\"Y. Chen\"},{\"authorId\":\"50210068\",\"name\":\"Zhe Pan\"},{\"authorId\":\"40205563\",\"name\":\"Min Zhang\"},{\"authorId\":\"144472561\",\"name\":\"M. Xue\"},{\"authorId\":\"9265776\",\"name\":\"Yaoyang Mo\"},{\"authorId\":\"1611287648\",\"name\":\"Yao Zhang\"},{\"authorId\":\"1810693940\",\"name\":\"Guoxiong Guan\"},{\"authorId\":\"2502376\",\"name\":\"Beibei Qian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06124e42be994772fc42bdb8fa975471544a589d\",\"title\":\"Train Your Data Processor: Distribution-Aware and Error-Compensation Coordinate Decoding for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/06124e42be994772fc42bdb8fa975471544a589d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"1794837\",\"name\":\"Siwei Lyu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/ICCV.2015.473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06a52ac1db1ee895dda730259494a2ce6cabe9f4\",\"title\":\"ML-MG: Multi-label Learning with Missing Labels Using a Mixed Graph\",\"url\":\"https://www.semanticscholar.org/paper/06a52ac1db1ee895dda730259494a2ce6cabe9f4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1804.00819\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/CVPR.2018.00911\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35ed258aede3df17ee20a6635364cb5fd2461049\",\"title\":\"End-to-End Dense Video Captioning with Masked Transformer\",\"url\":\"https://www.semanticscholar.org/paper/35ed258aede3df17ee20a6635364cb5fd2461049\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145741492\",\"name\":\"Bo Sun\"},{\"authorId\":\"9767548\",\"name\":\"K. Zhao\"},{\"authorId\":\"2308836\",\"name\":\"Yongkang Xiao\"},{\"authorId\":\"1434623735\",\"name\":\"J. He\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"},{\"authorId\":\"50118329\",\"name\":\"Y. Wu\"},{\"authorId\":\"83162482\",\"name\":\"Huanqing Yan\"}],\"doi\":\"10.1117/12.2539052\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bef084f8096a297cb0a8ab1706adea724348a29f\",\"title\":\"BNU-LCSAD: a video database for classroom student action recognition\",\"url\":\"https://www.semanticscholar.org/paper/bef084f8096a297cb0a8ab1706adea724348a29f\",\"venue\":\"SPIE/COS Photonics Asia\",\"year\":2019},{\"arxivId\":\"1912.01601\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"title\":\"LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"48566761\",\"name\":\"Jiang Zhu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3240876.3240885\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4e599fa3ca042d30321aa5502a135c1de87e688\",\"title\":\"Video question answering via multi-granularity temporal attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/e4e599fa3ca042d30321aa5502a135c1de87e688\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3191371\",\"name\":\"Yuanhao Zhai\"},{\"authorId\":\"48170174\",\"name\":\"L. Wang\"},{\"authorId\":\"49293454\",\"name\":\"Ziyi Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"144988569\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/ICIP.2019.8803447\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"badd8b78b8ff2278215a5effe503440508692366\",\"title\":\"Action Coherence Network for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/badd8b78b8ff2278215a5effe503440508692366\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2700261\",\"name\":\"Y. Lee\"},{\"authorId\":\"73047525\",\"name\":\"J. Fiscus\"},{\"authorId\":\"1781968\",\"name\":\"A. Godil\"},{\"authorId\":\"123306611\",\"name\":\"A. Delgado\"},{\"authorId\":\"71289522\",\"name\":\"Jim Golden\"},{\"authorId\":\"1888300\",\"name\":\"Lukas Diduch\"},{\"authorId\":\"47983546\",\"name\":\"M. Hubert\"}],\"doi\":\"10.1109/WACVW50321.2020.9096926\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def4f25a27d199981be51b88f28d5745cd9dad90\",\"title\":\"Summary of the 2019 Activity Detection in Extended Videos Prize Challenge\",\"url\":\"https://www.semanticscholar.org/paper/def4f25a27d199981be51b88f28d5745cd9dad90\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"2008.08257\",\"authors\":[{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":\"10.1145/3394171.3413967\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02e5188e19523140b82d05f00bee10933ccc3b50\",\"title\":\"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/02e5188e19523140b82d05f00bee10933ccc3b50\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9422489\",\"name\":\"Shuyan Li\"},{\"authorId\":\"1723853\",\"name\":\"Z. Chen\"},{\"authorId\":\"121856633\",\"name\":\"Xiu Li\"},{\"authorId\":\"100475213\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TMM.2019.2946096\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c7aa18a724edb175952c7820fd4838751b75f48a\",\"title\":\"Unsupervised Variational Video Hashing With 1D-CNN-LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/c7aa18a724edb175952c7820fd4838751b75f48a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-3-030-00767-6_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8435aa8c48dd41e0341ce7bc3b5966c4f28dc11d\",\"title\":\"VAL: Visual-Attention Action Localizer\",\"url\":\"https://www.semanticscholar.org/paper/8435aa8c48dd41e0341ce7bc3b5966c4f28dc11d\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48842639\",\"name\":\"Dotan Kaufman\"},{\"authorId\":\"36813724\",\"name\":\"Gil Levi\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"48519520\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1109/ICCV.2017.20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62e6b749ed5825739aa906021c5e613803d5cbe2\",\"title\":\"Temporal Tessellation: A Unified Approach for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/62e6b749ed5825739aa906021c5e613803d5cbe2\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"153146470\",\"name\":\"Dan Yang\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":\"10.1016/J.PATCOG.2020.107686\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc5af1aff1839364b448a29dedd06e43bd133ea2\",\"title\":\"Deep snippet selective network for weakly supervised temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/fc5af1aff1839364b448a29dedd06e43bd133ea2\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"51043468\",\"name\":\"Maksim Bolonkin\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ba0bf9323c2d79300f1a433ff8b4fe0a00ad889\",\"title\":\"VideoMCC: a New Benchmark for Video Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7ba0bf9323c2d79300f1a433ff8b4fe0a00ad889\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"}],\"doi\":\"10.1109/TCSVT.2019.2962063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d787811e26606b598ba22ad3b4b1e30096b3bedc\",\"title\":\"Joint Learning of Local and Global Context for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/d787811e26606b598ba22ad3b4b1e30096b3bedc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1007/978-3-319-46487-9_3\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"a900a0b5319d84e212943b63265050c05b51652b\",\"title\":\"Segmental Spatiotemporal CNNs for Fine-Grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a900a0b5319d84e212943b63265050c05b51652b\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47558252\",\"name\":\"Y. Chen\"},{\"authorId\":\"27423107\",\"name\":\"Shanzhen Lan\"},{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"46461170\",\"name\":\"Yan Yang\"},{\"authorId\":null,\"name\":\"You Wang\"}],\"doi\":\"10.1109/ICCST50977.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"805233f3398deb9cc9dd616ebf3e51cb351fbd51\",\"title\":\"Boundary Sensitive and Confidence Fusion Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/805233f3398deb9cc9dd616ebf3e51cb351fbd51\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":\"1609.03056\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TMM.2017.2666540\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"776ce1429272028e9c566369cf647177d3522e26\",\"title\":\"Sequential Deep Trajectory Descriptor for Action Recognition With Three-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/776ce1429272028e9c566369cf647177d3522e26\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"2009.02406\",\"authors\":[{\"authorId\":\"28064618\",\"name\":\"Xinli Yu\"},{\"authorId\":\"40031204\",\"name\":\"M. Malmir\"},{\"authorId\":\"6312396\",\"name\":\"C. He\"},{\"authorId\":\"100576986\",\"name\":\"Yue Liu\"},{\"authorId\":\"144667222\",\"name\":\"Rex Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b827558cb940ca4ca49c31575cb053da1c4dd9ff\",\"title\":\"Video Moment Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b827558cb940ca4ca49c31575cb053da1c4dd9ff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05826\",\"authors\":[{\"authorId\":\"6906187\",\"name\":\"Pengwan Yang\"},{\"authorId\":\"144084970\",\"name\":\"V. Hu\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/978-3-030-58571-6_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28cfd03c5cefaba413b43c17b0a367b1fbf0e1f8\",\"title\":\"Localizing the Common Action Among a Few Videos\",\"url\":\"https://www.semanticscholar.org/paper/28cfd03c5cefaba413b43c17b0a367b1fbf0e1f8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51050729\",\"name\":\"Hongtao Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2018.00157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"title\":\"One-Shot Action Localization by Learning Sequence Matching Network\",\"url\":\"https://www.semanticscholar.org/paper/bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.10937\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58548-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0732df185bdfcb9c908ec30bb441252593f58875\",\"title\":\"MovieNet: A Holistic Dataset for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0732df185bdfcb9c908ec30bb441252593f58875\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.02472\",\"authors\":[{\"authorId\":\"3361240\",\"name\":\"Manling Li\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"145653968\",\"name\":\"Q. Zeng\"},{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"152347526\",\"name\":\"Di Lu\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.18653/v1/2020.acl-main.230\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04f7834936bf8f455f804c4d84b52fcffc6784ee\",\"title\":\"Cross-media Structured Common Space for Multimedia Event Extraction\",\"url\":\"https://www.semanticscholar.org/paper/04f7834936bf8f455f804c4d84b52fcffc6784ee\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"title\":\"V4D: 4D Covolutional Neural Networks for Video-level Representations Learning\",\"url\":\"https://www.semanticscholar.org/paper/60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"15429809\",\"name\":\"Yangliu Hu\"}],\"doi\":\"10.1007/978-3-030-05716-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"title\":\"Soccer Video Event Detection Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153920582\",\"name\":\"Luk\\u00e1s Neumann\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPRW.2019.00354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"title\":\"Future Event Prediction: If and When\",\"url\":\"https://www.semanticscholar.org/paper/4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"19282988\",\"name\":\"Wenqi Xian\"},{\"authorId\":\"49069517\",\"name\":\"Yingying Chen\"},{\"authorId\":\"32324034\",\"name\":\"Fangchen Liu\"},{\"authorId\":\"46205754\",\"name\":\"Mike Liao\"},{\"authorId\":\"8309711\",\"name\":\"V. Madhavan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9a2361c146d977040aeab96562e6b9dfd3e59fa\",\"title\":\"BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling\",\"url\":\"https://www.semanticscholar.org/paper/b9a2361c146d977040aeab96562e6b9dfd3e59fa\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.00461\",\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"84426766\",\"name\":\"Dingcheng Yue\"},{\"authorId\":\"21160992\",\"name\":\"Yuchen Liang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/978-3-030-01228-1_36\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f054fdd7a36b569eae7627cf12a4d81322dea022\",\"title\":\"YouTube-VOS: Sequence-to-Sequence Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f054fdd7a36b569eae7627cf12a4d81322dea022\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.04687\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"73568726\",\"name\":\"H. Chen\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"19282988\",\"name\":\"Wenqi Xian\"},{\"authorId\":\"39125742\",\"name\":\"Yingying Chen\"},{\"authorId\":\"32324034\",\"name\":\"Fangchen Liu\"},{\"authorId\":\"8309711\",\"name\":\"V. Madhavan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/cvpr42600.2020.00271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f0b8f730273e9f11b2bfad2415485414b96299f\",\"title\":\"BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning\",\"url\":\"https://www.semanticscholar.org/paper/4f0b8f730273e9f11b2bfad2415485414b96299f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.06092\",\"authors\":[{\"authorId\":\"47125062\",\"name\":\"G. Yang\"},{\"authorId\":\"2204671\",\"name\":\"Igor Ganichev\"},{\"authorId\":\"2146534\",\"name\":\"X. Wang\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"3089810\",\"name\":\"David Sussillo\"}],\"doi\":\"10.1007/978-3-030-01249-6_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4efd4b08999758a3a80085fb674eb99f7c6f2e1\",\"title\":\"A dataset and architecture for visual reasoning with a working memory\",\"url\":\"https://www.semanticscholar.org/paper/d4efd4b08999758a3a80085fb674eb99f7c6f2e1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6022603\",\"name\":\"Shichuan Zhang\"},{\"authorId\":\"1387822299\",\"name\":\"Zengming Tang\"},{\"authorId\":\"49349259\",\"name\":\"H. Pan\"},{\"authorId\":\"151499994\",\"name\":\"Xinyu Wei\"},{\"authorId\":\"101573196\",\"name\":\"Jun Huang\"}],\"doi\":\"10.1145/3343031.3356074\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed43a7ab9a72c60cc37f69e3e22a52405a0e31ba\",\"title\":\"A Hierarchical Framwork with Improved Loss for Large-scale Multi-modal Video Identification\",\"url\":\"https://www.semanticscholar.org/paper/ed43a7ab9a72c60cc37f69e3e22a52405a0e31ba\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1907.12763\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145160922\",\"name\":\"Bryan Russell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e12a3e3f3f383f222b5d2007802d7b7944364301\",\"title\":\"Temporal Localization of Moments in Video Collections with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/e12a3e3f3f383f222b5d2007802d7b7944364301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.00975\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b4741f8e6667664f1b21c390830b2022eca2da0\",\"title\":\"SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7b4741f8e6667664f1b21c390830b2022eca2da0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82117332\",\"name\":\"E. An\"},{\"authorId\":\"119131638\",\"name\":\"Stanford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58a78d6e23c37a1859eaa2b3a5babc42ddda1898\",\"title\":\"Large scale video classification using both visual and audio features on YouTube-8 M dataset\",\"url\":\"https://www.semanticscholar.org/paper/58a78d6e23c37a1859eaa2b3a5babc42ddda1898\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1812.03849\",\"authors\":[{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"title\":\"Weakly Supervised Dense Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92599875\",\"name\":\"M. Nadeem\"},{\"authorId\":\"1828728\",\"name\":\"V. N. L. Franqueira\"},{\"authorId\":\"1881146\",\"name\":\"X. Zhai\"},{\"authorId\":\"1741168\",\"name\":\"F. Kurugollu\"}],\"doi\":\"10.1109/ACCESS.2019.2924733\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255485196a869c98aacce60a86074fccf07c01eb\",\"title\":\"A Survey of Deep Learning Solutions for Multimedia Visual Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/255485196a869c98aacce60a86074fccf07c01eb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"2007.04198\",\"authors\":[{\"authorId\":\"48574860\",\"name\":\"Y. Xiang\"},{\"authorId\":\"145059389\",\"name\":\"Hongzhe Wang\"},{\"authorId\":\"1518670989\",\"name\":\"Tianqing Su\"},{\"authorId\":\"50392026\",\"name\":\"Ruoyu Li\"},{\"authorId\":\"1602286151\",\"name\":\"Christine Brach\"},{\"authorId\":\"33927702\",\"name\":\"S. Mao\"},{\"authorId\":\"144312764\",\"name\":\"M. Geimer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4589a39324230c57de9df008708202c4a3a50bb\",\"title\":\"KIT MOMA: A Mobile Machines Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a4589a39324230c57de9df008708202c4a3a50bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.08548\",\"authors\":[{\"authorId\":\"47792983\",\"name\":\"J. Ma\"},{\"authorId\":\"46227885\",\"name\":\"Satya Krishna Gorti\"},{\"authorId\":\"1765951\",\"name\":\"Maksims Volkovs\"},{\"authorId\":\"93169948\",\"name\":\"Ilya Stanevich\"},{\"authorId\":\"46546800\",\"name\":\"Guangwei Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8283f38f9e027a38c454957297d4a685b453575\",\"title\":\"Cross-Class Relevance Learning for Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/d8283f38f9e027a38c454957297d4a685b453575\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.03612\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bebbd6a2e786fa5a33dd4bbd27310e116411188e\",\"title\":\"Learning Sparse 2D Temporal Adjacent Networks for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/bebbd6a2e786fa5a33dd4bbd27310e116411188e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152473412\",\"name\":\"Jingye Zheng\"},{\"authorId\":\"67059036\",\"name\":\"Dihu Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2933360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8b63ee3f2c625ce2ccd848a535c8309c1e550b1\",\"title\":\"Multi-Scale Proposal Regression Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/f8b63ee3f2c625ce2ccd848a535c8309c1e550b1\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51202149\",\"name\":\"Menglin Wang\"},{\"authorId\":\"35884242\",\"name\":\"Y. Zhu\"},{\"authorId\":\"13223807\",\"name\":\"Z. Sun\"},{\"authorId\":\"3748616\",\"name\":\"Zihao Cao\"},{\"authorId\":\"39790137\",\"name\":\"Peng Xiong\"},{\"authorId\":\"145473087\",\"name\":\"Y. Zheng\"},{\"authorId\":\"22686210\",\"name\":\"Shijin Song\"}],\"doi\":\"10.1109/ICCCBDA.2019.8725621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c8516ce328d55086dcdc3e20f49f33a882ffd5d\",\"title\":\"Abnormal Behavior Detection of ATM Surveillance Videos Based on Pseudo-3D Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/0c8516ce328d55086dcdc3e20f49f33a882ffd5d\",\"venue\":\"2019 IEEE 4th International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"46286184\",\"name\":\"Y. Yang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"46867455\",\"name\":\"Yin Sheng Zhang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123362\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49dbecc42e9bdd508279314509a85c0cf3a6a917\",\"title\":\"Detecting Temporal Proposal for Action Localization with Tree-structured Search Policy\",\"url\":\"https://www.semanticscholar.org/paper/49dbecc42e9bdd508279314509a85c0cf3a6a917\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/TMM.2018.2887021\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"title\":\"Unsupervised Universal Attribute Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1906.03340\",\"authors\":[{\"authorId\":\"144097992\",\"name\":\"I. Kwak\"},{\"authorId\":\"38998440\",\"name\":\"David A. Kriegman\"},{\"authorId\":\"2424812\",\"name\":\"K. Branson\"}],\"doi\":\"10.1109/WACV45572.2020.9093405\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66d7fe24f86504517a5a33679043379066676921\",\"title\":\"Detecting the Starting Frame of Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/66d7fe24f86504517a5a33679043379066676921\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2009.14661\",\"authors\":[{\"authorId\":\"1500399016\",\"name\":\"Tong Yu\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"title\":\"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150156982\",\"name\":\"Jungin Park\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"40257207\",\"name\":\"Jiyoung Lee\"},{\"authorId\":\"2352565\",\"name\":\"Sunok Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1145/3265987.3265989\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcc5da531e5b7241e181ff132c2cf533c0dc6059\",\"title\":\"Learning to Detect, Associate, and Recognize Human Actions and Surrounding Scenes in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/fcc5da531e5b7241e181ff132c2cf533c0dc6059\",\"venue\":\"CoVieW@MM\",\"year\":2018},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1806.11244\",\"authors\":[{\"authorId\":\"3461969\",\"name\":\"Wonjoon Goo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":\"10.1109/ICRA.2019.8793515\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7a5bd4faa9ba10e31e0e1b00acc520fb836919c\",\"title\":\"One-Shot Learning of Multi-Step Tasks from Observation via Activity Localization in Auxiliary Video\",\"url\":\"https://www.semanticscholar.org/paper/c7a5bd4faa9ba10e31e0e1b00acc520fb836919c\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682261\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e133e8cf792334969365ff7746ebed7b98fce702\",\"title\":\"Boundary Information Matters More: Accurate Temporal Action Detection with Temporal Boundary Network\",\"url\":\"https://www.semanticscholar.org/paper/e133e8cf792334969365ff7746ebed7b98fce702\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.11432\",\"authors\":[{\"authorId\":\"51504770\",\"name\":\"K. Kahatapitiya\"},{\"authorId\":\"144952844\",\"name\":\"R. Rodrigo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"592cbfdd16922ecddebb4fa737fd73bb32d077f0\",\"title\":\"Exploiting the Redundancy in Convolutional Filters for Parameter Reduction\",\"url\":\"https://www.semanticscholar.org/paper/592cbfdd16922ecddebb4fa737fd73bb32d077f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.03356\",\"authors\":[{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1679974562\",\"name\":\"Ahjeong Seo\"},{\"authorId\":\"1680054988\",\"name\":\"Youwon Jang\"},{\"authorId\":\"153311117\",\"name\":\"Seungchan Lee\"},{\"authorId\":\"1491775096\",\"name\":\"Minsu Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d21241b930b005847cf4350294c61d6c29ccd9f\",\"title\":\"DramaQA: Character-Centered Video Story Understanding with Hierarchical QA\",\"url\":\"https://www.semanticscholar.org/paper/4d21241b930b005847cf4350294c61d6c29ccd9f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1414089890\",\"name\":\"Javier Abellan-Abenza\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410755536\",\"name\":\"David Ivorra-Piqueres\"},{\"authorId\":\"145897522\",\"name\":\"J. Rodr\\u00edguez\"}],\"doi\":\"10.4018/IJCVIP.2017100101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c620e63a179562cab28ec9590815a1824a027dd\",\"title\":\"Classifying Behaviours in Videos with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c620e63a179562cab28ec9590815a1824a027dd\",\"venue\":\"Int. J. Comput. Vis. Image Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.721\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36e093e2c6142017e61c37200e915fd08d2456a1\",\"title\":\"Jointly Learning Energy Expenditures and Activities Using Egocentric Multimodal Signals\",\"url\":\"https://www.semanticscholar.org/paper/36e093e2c6142017e61c37200e915fd08d2456a1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"1764521\",\"name\":\"A. A. Salah\"}],\"doi\":\"10.1016/j.eswa.2015.06.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb657cd8729773cd9a52ed31c68f550be1f86323\",\"title\":\"Efficient large-scale action recognition in videos using extreme learning machines\",\"url\":\"https://www.semanticscholar.org/paper/eb657cd8729773cd9a52ed31c68f550be1f86323\",\"venue\":\"Expert Syst. Appl.\",\"year\":2015},{\"arxivId\":\"2011.13202\",\"authors\":[{\"authorId\":\"2029244883\",\"name\":\"Soroosh Poorgholi\"},{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"title\":\"t-EVA: Time-Efficient t-SNE Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1611.02145\",\"authors\":[{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1561/0600000073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c95a8db377c25d4280f188e9477569ab57281b\",\"title\":\"Crowdsourcing in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/84c95a8db377c25d4280f188e9477569ab57281b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1608.04339\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-319-46604-0_47\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9abd35b37a49ee1295e8197aac59bde802a934f3\",\"title\":\"Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9abd35b37a49ee1295e8197aac59bde802a934f3\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"2005.00463\",\"authors\":[{\"authorId\":\"144175619\",\"name\":\"K. Curtis\"},{\"authorId\":\"145876242\",\"name\":\"G. Awad\"},{\"authorId\":\"145228525\",\"name\":\"S. Rajput\"},{\"authorId\":\"144526707\",\"name\":\"I. Soboroff\"}],\"doi\":\"10.1145/3372278.3390742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7105d91c324e6118dbc5ec119ec93af6471638c6\",\"title\":\"HLVU: A New Challenge to Test Deep Understanding of Movies the Way Humans do\",\"url\":\"https://www.semanticscholar.org/paper/7105d91c324e6118dbc5ec119ec93af6471638c6\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1145/3132734.3132739\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0be49fc1e0c9a6a50e449015945dd1cf92ccd07e\",\"title\":\"PKU-MMD: A Large Scale Benchmark for Skeleton-Based Human Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0be49fc1e0c9a6a50e449015945dd1cf92ccd07e\",\"venue\":\"VSCC '17\",\"year\":2017},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d5d85a741f7926d8774e037c57a245ae6c94356\",\"title\":\"Online Action Detection in Untrimmed, Streaming Videos - Modeling and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/2d5d85a741f7926d8774e037c57a245ae6c94356\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"98738293\",\"name\":\"A. Kot\"},{\"authorId\":\"145603848\",\"name\":\"Anderson Rocha\"}],\"doi\":\"10.1109/ICASSP.2019.8683676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fed4a25ea4478e1eaf1622e78788d41cb291cfed\",\"title\":\"Detection of Real-world Fights in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/fed4a25ea4478e1eaf1622e78788d41cb291cfed\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1708.07632\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICCVW.2017.373\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"title\":\"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143995146\",\"name\":\"Hao Huang\"},{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"90638604\",\"name\":\"W. Zhang\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3341898f570384ce310445d6f3f0b6c598831a61\",\"title\":\"Dynamic Graph Modules for Modeling Object-Object Interactions in Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3341898f570384ce310445d6f3f0b6c598831a61\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00627\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96ce111119624888be47d998cf87c9df18988c4d\",\"title\":\"Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints\",\"url\":\"https://www.semanticscholar.org/paper/96ce111119624888be47d998cf87c9df18988c4d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"38748749\",\"name\":\"Wayner Barrios\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2017.338\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"551cddb9a5e20861b491ec39f3ced933f6364a17\",\"title\":\"SCC: Semantic Context Cascade for Efficient Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/551cddb9a5e20861b491ec39f3ced933f6364a17\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80496214\",\"name\":\"Sagar Shelke\"},{\"authorId\":\"1783275\",\"name\":\"Baris Aksanli\"}],\"doi\":\"10.3390/s19040804\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cfab246291020449152732321a6722eeed5056e\",\"title\":\"Static and Dynamic Activity Detection with Ambient Sensors in Smart Spaces\",\"url\":\"https://www.semanticscholar.org/paper/5cfab246291020449152732321a6722eeed5056e\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700535\",\"name\":\"Jichao Liu\"},{\"authorId\":\"50096175\",\"name\":\"Chuan-xu Wang\"},{\"authorId\":\"39798475\",\"name\":\"Yun Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2940407\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b63829ba8c1e3b791032bef87cb3168e04152cea\",\"title\":\"A Novel Method for Temporal Action Localization and Recognition in Untrimmed Video Based on Time Series Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b63829ba8c1e3b791032bef87cb3168e04152cea\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"David A. Ross\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"Rahul Sukthankar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"RoI Pooling DNN Classifier Person Bike Background 2 D Feature Map Input ImageMulti-scale Anchor Boxes Region Proposal Network Region Proposals 2 D ConvNet c DNN Classifier Dunk Background SoI Pooling\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1703.02716\",\"authors\":[{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"title\":\"A Pursuit of Temporal Accuracy in General Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/90298f9f80ebe03cb8b158fd724551ad711d4e71\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144392699\",\"name\":\"T. Ogawa\"},{\"authorId\":\"3493510\",\"name\":\"Y. Sasaka\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2018.2876710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e2f9966df1e270c32246d32cce722170d322f53\",\"title\":\"Favorite Video Classification Based on Multimodal Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/9e2f9966df1e270c32246d32cce722170d322f53\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1609.09430\",\"authors\":[{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"1680841\",\"name\":\"S. Chaudhuri\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"47380012\",\"name\":\"D. Platt\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"12812321\",\"name\":\"K. Wilson\"}],\"doi\":\"10.1109/ICASSP.2017.7952132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d8c68de09da69a608ceb149f40114f5538c5b1\",\"title\":\"CNN architectures for large-scale audio classification\",\"url\":\"https://www.semanticscholar.org/paper/59d8c68de09da69a608ceb149f40114f5538c5b1\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1708.02349\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"144091320\",\"name\":\"Guyue Zhang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"10727378\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCV.2017.610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f0167299d73b19d800953dd2859a0af2244a0c5\",\"title\":\"Temporal Context Network for Activity Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5f0167299d73b19d800953dd2859a0af2244a0c5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143966993\",\"name\":\"X. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bdbf483de5db6645106bb5a1b39b10381ccc74c\",\"title\":\"Frames in places: visual common sense knowledge in context\",\"url\":\"https://www.semanticscholar.org/paper/7bdbf483de5db6645106bb5a1b39b10381ccc74c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2010.03016\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2101cacd22060882e1ec6e787774e6b04f531e0\",\"title\":\"Online Action Detection in Streaming Videos with Time Buffers\",\"url\":\"https://www.semanticscholar.org/paper/a2101cacd22060882e1ec6e787774e6b04f531e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1608.07876\",\"authors\":[{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1007/978-3-319-49409-8_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04e96c69176030cf8d7c82d86c345b7f4bcf6a24\",\"title\":\"Human Action Recognition Without Human\",\"url\":\"https://www.semanticscholar.org/paper/04e96c69176030cf8d7c82d86c345b7f4bcf6a24\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79993756\",\"name\":\"Haruya Ishikawa\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"48589121\",\"name\":\"Shuichi Akizuki\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.23919/MVA.2019.8757896\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a019ef99567561824c50196f013eb73657b96232\",\"title\":\"Human-Object Maps for Daily Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a019ef99567561824c50196f013eb73657b96232\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845267\",\"name\":\"Da Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00394\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"daf161f0f763bf19246ad51338764c9f732d11f0\",\"title\":\"METAL: Minimum Effort Temporal Activity Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/daf161f0f763bf19246ad51338764c9f732d11f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1770771\",\"name\":\"N. Alharbi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bebb4393952052fec2c3b8cfb1adbf167b57737b\",\"title\":\"Describing human activities in video streams\",\"url\":\"https://www.semanticscholar.org/paper/bebb4393952052fec2c3b8cfb1adbf167b57737b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"101386498\",\"name\":\"T. T. Ogunwa\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.1109/THMS.2020.2971958\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"title\":\"A Multiviewpoint Outdoor Dataset for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2020},{\"arxivId\":\"1912.06640\",\"authors\":[{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"104382958\",\"name\":\"P. Xu\"},{\"authorId\":\"1401079497\",\"name\":\"David B. D'Ambrosio\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"2574014\",\"name\":\"H. Phan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"title\":\"SPIN: A High Speed, High Resolution Vision Dataset for Tracking and Action Recognition in Ping Pong\",\"url\":\"https://www.semanticscholar.org/paper/6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.09637\",\"authors\":[{\"authorId\":\"152614105\",\"name\":\"Z. Liu\"},{\"authorId\":\"48311072\",\"name\":\"B. Huang\"},{\"authorId\":\"145634433\",\"name\":\"Yuqi Cui\"},{\"authorId\":\"66607897\",\"name\":\"Yifan Xu\"},{\"authorId\":\"49846372\",\"name\":\"Bo Zhang\"},{\"authorId\":\"49835579\",\"name\":\"Lixia Zhu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143786564\",\"name\":\"Lei Jin\"},{\"authorId\":\"144855927\",\"name\":\"Dongrui Wu\"}],\"doi\":\"10.1109/ACCESS.2019.2937765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"061bfec49a0166d9071627b01553a19f0ba4a76f\",\"title\":\"Multi-Task Deep Learning With Dynamic Programming for Embryo Early Development Stage Classification From Time-Lapse Videos\",\"url\":\"https://www.semanticscholar.org/paper/061bfec49a0166d9071627b01553a19f0ba4a76f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1909.09300\",\"authors\":[{\"authorId\":\"3928052\",\"name\":\"T. Li\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2931940\",\"name\":\"M. Zhao\"},{\"authorId\":\"51149370\",\"name\":\"Yingcheng Liu\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1109/ICCV.2019.00096\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02ec4b311978f8a16ae4ecd232e2464c08e59d84\",\"title\":\"Making the Invisible Visible: Action Recognition Through Walls and Occlusions\",\"url\":\"https://www.semanticscholar.org/paper/02ec4b311978f8a16ae4ecd232e2464c08e59d84\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1906.01012\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"title\":\"Mining YouTube - A dataset for learning fine-grained action concepts from webly supervised video data\",\"url\":\"https://www.semanticscholar.org/paper/b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.06147\",\"authors\":[{\"authorId\":\"66520980\",\"name\":\"Yasufumi Moriya\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"143723939\",\"name\":\"G. Jones\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f657ddb2ece2f699e02d8b19ab363ac86482ac95\",\"title\":\"Grounding Object Detections With Transcriptions\",\"url\":\"https://www.semanticscholar.org/paper/f657ddb2ece2f699e02d8b19ab363ac86482ac95\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11955\",\"authors\":[{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"20574924\",\"name\":\"M. F. Chen\"},{\"authorId\":\"14123214\",\"name\":\"F. Sala\"},{\"authorId\":\"46908203\",\"name\":\"Sarah Hooper\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c9c0ba883c9d05bec79afb0c2a57dda53c5d93e\",\"title\":\"Fast and Three-rious: Speeding Up Weak Supervision with Triplet Methods\",\"url\":\"https://www.semanticscholar.org/paper/5c9c0ba883c9d05bec79afb0c2a57dda53c5d93e\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1809.03327\",\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"84426766\",\"name\":\"Dingcheng Yue\"},{\"authorId\":\"21160992\",\"name\":\"Yuchen Liang\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad\",\"title\":\"YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1706.04269\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d79e6077c47d6289ab89054f2b51653d887958\",\"title\":\"Action Search: Learning to Search for Human Activities in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c0d79e6077c47d6289ab89054f2b51653d887958\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1810.07212\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1007/978-3-030-01261-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"title\":\"Cross-Modal and Hierarchical Modeling of Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2345721\",\"name\":\"S. Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1145/3139958.3140055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40dd736c803720890d6bfc1e083f6050e35d8f7a\",\"title\":\"Large-Scale Mapping of Human Activity using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/40dd736c803720890d6bfc1e083f6050e35d8f7a\",\"venue\":\"SIGSPATIAL/GIS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15716390\",\"name\":\"Julian Tanke\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98e651a7956af6c67f4290cdd40e49e4155febb7\",\"title\":\"Bonn Activity Maps : Dataset Description A Preprint\",\"url\":\"https://www.semanticscholar.org/paper/98e651a7956af6c67f4290cdd40e49e4155febb7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3442125\",\"name\":\"Ines Chami\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f2d8795acbc19d235da6300a3f0f587066ae485d\",\"title\":\"CS 231 N Final Report : Single-Stream Action Proposals in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f2d8795acbc19d235da6300a3f0f587066ae485d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shivam Garg\"}],\"doi\":\"10.1007/978-3-030-11018-5_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87fe04045343686d0be09310ec4e2938e731305c\",\"title\":\"Learning Video Features for Multi-label Classification\",\"url\":\"https://www.semanticscholar.org/paper/87fe04045343686d0be09310ec4e2938e731305c\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119581637\",\"name\":\"J. Li\"},{\"authorId\":\"48218953\",\"name\":\"Borui Li\"},{\"authorId\":\"46947647\",\"name\":\"Zhengdong Li\"},{\"authorId\":\"71547767\",\"name\":\"J. Xia\"},{\"authorId\":\"47776519\",\"name\":\"Guanglei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b52cb7a7094615e2107bc2071023482965b0c05\",\"title\":\"A Temporal Concept Localization Method Integrating Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/7b52cb7a7094615e2107bc2071023482965b0c05\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.00394\",\"authors\":[{\"authorId\":\"1410307807\",\"name\":\"Yizhak Ben-Shabat\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"947b868aa1c38940df280ebeb8077d4e729fb988\",\"title\":\"The IKEA ASM Dataset: Understanding People Assembling Furniture through Actions, Objects and Pose\",\"url\":\"https://www.semanticscholar.org/paper/947b868aa1c38940df280ebeb8077d4e729fb988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93057792\",\"name\":\"Y. Yan\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"46689429\",\"name\":\"Dawen Cai\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/s11263-019-01244-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13c145a54f65949f3ab6ef86bd812bf9e26ba23b\",\"title\":\"A Weakly Supervised Multi-task Ranking Framework for Actor\\u2013Action Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/13c145a54f65949f3ab6ef86bd812bf9e26ba23b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804033\",\"name\":\"K. Ueki\"},{\"authorId\":\"34711903\",\"name\":\"Y. Nakagome\"},{\"authorId\":\"14410793\",\"name\":\"Koji Hirakawa\"},{\"authorId\":\"144177702\",\"name\":\"K. Kikuchi\"},{\"authorId\":\"32639661\",\"name\":\"Yoshihiko Hayashi\"},{\"authorId\":\"3279652\",\"name\":\"T. Ogawa\"},{\"authorId\":\"1709528\",\"name\":\"T. Kobayashi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fdd5f7170128769904cf49d7f0f7836f5005629\",\"title\":\"Waseda_Meisei at TRECVID 2018: Ad-hoc Video Search\",\"url\":\"https://www.semanticscholar.org/paper/0fdd5f7170128769904cf49d7f0f7836f5005629\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46842504\",\"name\":\"Zhixiang Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TCSVT.2017.2669095\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d89b7eb82a663187f63e7d69dca11f204c74fcb1\",\"title\":\"Nonlinear Structural Hashing for Scalable Video Search\",\"url\":\"https://www.semanticscholar.org/paper/d89b7eb82a663187f63e7d69dca11f204c74fcb1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1612.07403\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/WACV.2017.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e12226cf0da453dc4b9879d7af6b43af3c31d2b\",\"title\":\"Efficient Action Detection in Untrimmed Videos via Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/6e12226cf0da453dc4b9879d7af6b43af3c31d2b\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1901.00098\",\"authors\":[{\"authorId\":\"40264390\",\"name\":\"Tae-Hoon Kim\"},{\"authorId\":\"48493262\",\"name\":\"Dongmin Kang\"},{\"authorId\":\"1704409\",\"name\":\"K. Pulli\"},{\"authorId\":null,\"name\":\"Jonghyun Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"845865040cda3851459a1ed92eb58ca9ad484f06\",\"title\":\"Training with the Invisibles: Obfuscating Images to Share Safely for Learning Visual Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/845865040cda3851459a1ed92eb58ca9ad484f06\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.02189\",\"authors\":[{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682466\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d63dc4f0eb83ceea8c2bfcd71300b7c12eff13a1\",\"title\":\"BLP - Boundary Likelihood Pinpointing Networks for Accurate Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d63dc4f0eb83ceea8c2bfcd71300b7c12eff13a1\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1804.01373\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144188763\",\"name\":\"Jian Yao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1145/3184558.3186584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ba45c4f82b0328dfdf5dc93dfd88e3d9ac76bad\",\"title\":\"Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8ba45c4f82b0328dfdf5dc93dfd88e3d9ac76bad\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"34413657\",\"name\":\"G. Shen\"},{\"authorId\":\"51026885\",\"name\":\"W. Huang\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TMM.2019.2959977\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"320d212dd25dfdec58ac6d9f60198eb893d3744e\",\"title\":\"Relation Attention for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/320d212dd25dfdec58ac6d9f60198eb893d3744e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451334\",\"name\":\"Michelle Guo\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3340170\",\"name\":\"Shuran Song\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-01246-5_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7b5b9eaf519d9374428a0aeb4b659615884718a\",\"title\":\"Neural Graph Matching Networks for Fewshot 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a7b5b9eaf519d9374428a0aeb4b659615884718a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578530\",\"name\":\"Vishal Anand\"},{\"authorId\":\"1993691002\",\"name\":\"Raksha Ramesh\"},{\"authorId\":\"1993659768\",\"name\":\"Ziyin Wang\"},{\"authorId\":\"1993645840\",\"name\":\"Yijing Feng\"},{\"authorId\":\"1993660453\",\"name\":\"Jiana Feng\"},{\"authorId\":\"1993695696\",\"name\":\"Wenfeng Lyu\"},{\"authorId\":\"1993695801\",\"name\":\"Tianle Zhu\"},{\"authorId\":\"1993660605\",\"name\":\"Serena Yuan\"},{\"authorId\":\"153903099\",\"name\":\"Ching-Yung Lin\"}],\"doi\":\"10.1145/3394171.3416305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95327ce60abc25ea530a31d29a09a4be62d0e16f\",\"title\":\"Story Semantic Relationships from Multimodal Cognitions\",\"url\":\"https://www.semanticscholar.org/paper/95327ce60abc25ea530a31d29a09a4be62d0e16f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"144794678\",\"name\":\"Zi Huang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2017.2670782\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390593c6befa918e72fe72efaa367a9f5d36539f\",\"title\":\"Hierarchical Latent Concept Discovery for Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/390593c6befa918e72fe72efaa367a9f5d36539f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2004.08154\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"1500648246\",\"name\":\"Han Lu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"40370720\",\"name\":\"J. Liu\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f51b8b8fcdf881d2bb5b5fece37154907b17249b\",\"title\":\"Detailed 2D-3D Joint Representation for Human-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/f51b8b8fcdf881d2bb5b5fece37154907b17249b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443763209\",\"name\":\"Morgan Freeman\"},{\"authorId\":\"144255428\",\"name\":\"W. Sadler\"},{\"authorId\":null,\"name\":\"Larry Brandenburg\"},{\"authorId\":null,\"name\":\"Neil Giuntoli\"},{\"authorId\":null,\"name\":\"Brian Libby\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ea81dc0cedefcc547927b790a3062ea239df9be\",\"title\":\"Caption-Supervised Face Recognition: Training a State-of-the-Art Face Model without Manual Annotation\",\"url\":\"https://www.semanticscholar.org/paper/0ea81dc0cedefcc547927b790a3062ea239df9be\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"}],\"doi\":\"10.22028/D291-27156\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"title\":\"From perception over anticipation to manipulation\",\"url\":\"https://www.semanticscholar.org/paper/993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1706.03038\",\"authors\":[{\"authorId\":\"39393520\",\"name\":\"M. Barekatain\"},{\"authorId\":\"144294961\",\"name\":\"M. Mart\\u00ed\"},{\"authorId\":\"19185012\",\"name\":\"Hsueh-Fu Shih\"},{\"authorId\":\"153083684\",\"name\":\"S. Murray\"},{\"authorId\":\"1943224\",\"name\":\"K. Nakayama\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"},{\"authorId\":\"2356111\",\"name\":\"H. Prendinger\"}],\"doi\":\"10.1109/CVPRW.2017.267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd0e100a91ff179ee5c1d3383c75c85eddc81723\",\"title\":\"Okutama-Action: An Aerial View Video Dataset for Concurrent Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/bd0e100a91ff179ee5c1d3383c75c85eddc81723\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.06080\",\"authors\":[{\"authorId\":\"1409975963\",\"name\":\"Yushuai Hu\"},{\"authorId\":\"143618654\",\"name\":\"Y. Jin\"},{\"authorId\":\"48881611\",\"name\":\"R. Li\"},{\"authorId\":\"47958382\",\"name\":\"XiangXiang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20541068388f9555b0cbb9b5004b4afe56d8ec66\",\"title\":\"CMSN: Continuous Multi-stage Network and Variable Margin Cosine Loss for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/20541068388f9555b0cbb9b5004b4afe56d8ec66\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.03280\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"title\":\"Exploring Temporal Preservation Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.3390/drones3040082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5804fb20edd6df75f0d47782ffa1cd4ecf7252f0\",\"title\":\"Drone-Action: An Outdoor Recorded Drone Video Dataset for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5804fb20edd6df75f0d47782ffa1cd4ecf7252f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.11981\",\"authors\":[{\"authorId\":\"2129835\",\"name\":\"L. Huang\"},{\"authorId\":null,\"name\":\"Xin Zhao\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/TPAMI.2019.2957464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c75180ab22b80b7ac3c8853a934ac515313b9aad\",\"title\":\"GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/c75180ab22b80b7ac3c8853a934ac515313b9aad\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47892745\",\"name\":\"Hong-Ru Li\"},{\"authorId\":\"46477857\",\"name\":\"J. Yang\"},{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"47319743\",\"name\":\"Sumei Li\"}],\"doi\":\"10.1109/ICIP.2019.8803628\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ef9bd252c21464ec5ab1d735bd1c21d4cbb4ec3\",\"title\":\"Rethinking Temporal Structure Modeling Method for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2ef9bd252c21464ec5ab1d735bd1c21d4cbb4ec3\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005819\",\"name\":\"Hyun-Joo Jung\"},{\"authorId\":\"1748683\",\"name\":\"K. Hong\"}],\"doi\":\"10.1109/FG.2018.00054\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc9c56b17f6fe0fec4c987d23fb7dd58584f6fb0\",\"title\":\"Versatile Model for Activity Recognition: Sequencelet Corpus Model\",\"url\":\"https://www.semanticscholar.org/paper/bc9c56b17f6fe0fec4c987d23fb7dd58584f6fb0\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":\"1909.08453\",\"authors\":[{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"7533195\",\"name\":\"Desen Zhou\"},{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"2332078\",\"name\":\"Rongjie Li\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/ICCV.2019.00956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"title\":\"Pose-Aware Multi-Level Feature Network for Human Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5947095\",\"name\":\"Byeong Jo Kim\"},{\"authorId\":\"47634928\",\"name\":\"Yong Hoon Choi\"}],\"doi\":\"10.1145/3341105.3374063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"title\":\"Automatic baseball commentary generation using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"2011.14598\",\"authors\":[{\"authorId\":\"1753647133\",\"name\":\"Chen Zhao\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b19e442f6d313c211b522a791252de2c2468063b\",\"title\":\"Video Self-Stitching Graph Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b19e442f6d313c211b522a791252de2c2468063b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mehrdad Hosseinzadeh\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da8a8a0ce5a15d072c85e1bace61e28701547c12\",\"title\":\"Video Captioning of Future Frames\",\"url\":\"https://www.semanticscholar.org/paper/da8a8a0ce5a15d072c85e1bace61e28701547c12\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2004.00945\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"151484848\",\"name\":\"Liang Xu\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"1409933106\",\"name\":\"Yue Xu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"48622851\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00046\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"title\":\"PaStaNet: Toward Human Activity Knowledge Engine\",\"url\":\"https://www.semanticscholar.org/paper/37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47166264\",\"name\":\"Xiaojie Yu\"},{\"authorId\":\"1471155352\",\"name\":\"Min Qiu\"},{\"authorId\":\"2153551\",\"name\":\"Lizhi Peng\"}],\"doi\":\"10.1007/978-3-030-62460-6_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"037363aa9b5a25f32d9dc5311252ae5dd07d3310\",\"title\":\"A Novel Method to Classify Videos Based VBR Trace\",\"url\":\"https://www.semanticscholar.org/paper/037363aa9b5a25f32d9dc5311252ae5dd07d3310\",\"venue\":\"ML4CS\",\"year\":2020},{\"arxivId\":\"2003.12041\",\"authors\":[{\"authorId\":\"1405196499\",\"name\":\"Marcos Baptista-R\\u00edos\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"},{\"authorId\":\"1486455501\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"134228326\",\"name\":\"Jan C. Van Gemert\"},{\"authorId\":\"1402975934\",\"name\":\"F. J. Acevedo-Rodr\\u00edguez\"},{\"authorId\":\"1398470117\",\"name\":\"S. Maldonado-Basc\\u00f3n\"}],\"doi\":\"10.1109/ACCESS.2019.2961789\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4e45bad89d523b11ee3ae04f1b154e4e10f7fd4\",\"title\":\"Rethinking Online Action Detection in Untrimmed Videos: A Novel Online Evaluation Protocol\",\"url\":\"https://www.semanticscholar.org/paper/e4e45bad89d523b11ee3ae04f1b154e4e10f7fd4\",\"venue\":\"IEEE Access\",\"year\":2020}],\"corpusId\":1710722,\"doi\":\"10.1109/CVPR.2015.7298698\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":149,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Thumos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Thumos challenge\",\"url\":\"\",\"venue\":\"Thumos challenge\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mubarak Amir Roshan Zamir Khurram Soomro\"},{\"authorId\":null,\"name\":\"Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A dataset of 101 human action classes from videos in the wild\",\"url\":\"\",\"venue\":\"A dataset of 101 human action classes from videos in the wild\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-16817-3_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5b127ff7763ec87bc26c5c18233535db52d650a\",\"title\":\"Camera Motion and Surrounding Scene Appearance as Context for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5b127ff7763ec87bc26c5c18233535db52d650a\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-642-15549-9_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7de6028a3b6c07a5544b48e132862923d9c01bd\",\"title\":\"Object, Scene and Actions: Combining Multiple Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c7de6028a3b6c07a5544b48e132862923d9c01bd\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"YouTube statistics\",\"url\":\"\",\"venue\":\"YouTube statistics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"50170517\",\"name\":\"Moshe Blank\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/TPAMI.2007.70711\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45a7c9deb52e0326618a6220716fe8f45d5dca7d\",\"title\":\"Actions as Space-Time Shapes\",\"url\":\"https://www.semanticscholar.org/paper/45a7c9deb52e0326618a6220716fe8f45d5dca7d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Oneata\"},{\"authorId\":null,\"name\":\"J. Verbeek\"},{\"authorId\":null,\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The LEAR submission at Thumos\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2012.6247801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49435aab7cdf259335725acc96691f755e436f55\",\"title\":\"A database for fine grained activity detection of cooking activities\",\"url\":\"https://www.semanticscholar.org/paper/49435aab7cdf259335725acc96691f755e436f55\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Thumos challenge\",\"url\":\"\",\"venue\":\"Thumos challenge\",\"year\":2013},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c24f8e5725eb1bbc4acddea4cb5ea403e23d42a2\",\"title\":\"University of Amsterdam at THUMOS Challenge 2014\",\"url\":\"https://www.semanticscholar.org/paper/c24f8e5725eb1bbc4acddea4cb5ea403e23d42a2\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763954\",\"name\":\"I. Lillo\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2014.109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea29d044851b4d9bc767ea3933cc38594cfde084\",\"title\":\"Discriminative Hierarchical Modeling of Spatio-temporally Composable Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/ea29d044851b4d9bc767ea3933cc38594cfde084\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403834669\",\"name\":\"Gutemberg Guerra-Filho\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7139e09d4c9758bf3e50ec72b15ae3fb54d78328\",\"title\":\"Towards a Sensorimotor WordNet SM : Closing the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/7139e09d4c9758bf3e50ec72b15ae3fb54d78328\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/TPAMI.2008.128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d2b5c64a67f65c5dd812b89e07973f97699552\",\"title\":\"80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/54d2b5c64a67f65c5dd812b89e07973f97699552\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A R Z Khurram\"},{\"authorId\":null,\"name\":\"M Soomro\"},{\"authorId\":null,\"name\":\"Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"A dataset of 101 human action classes from videos in the wild\",\"url\":\"\",\"venue\":\"A dataset of 101 human action classes from videos in the wild\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771661\",\"name\":\"I. Atmosukarto\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/WACV.2015.124\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e55dfdb438c0ca607dc970b382ab3d820574586b\",\"title\":\"Action Recognition Using Discriminative Structured Trajectory Groups\",\"url\":\"https://www.semanticscholar.org/paper/e55dfdb438c0ca607dc970b382ab3d820574586b\",\"venue\":\"2015 IEEE Winter Conference on Applications of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"50678963\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/ICCV.2013.335\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a81719f9248ab89887af68833fbad9d9a85a526\",\"title\":\"Combining the Right Features for Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1a81719f9248ab89887af68833fbad9d9a85a526\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Verbeek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The LEAR submission at Thumos\",\"url\":\"\",\"venue\":\"ECCV THUMOS Challenge\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771661\",\"name\":\"I. Atmosukarto\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1ae218e6740e5f7e1b552f17a40cbfc036b4c8a2\",\"title\":\"Trajectory-based Fisher kernel representation for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/1ae218e6740e5f7e1b552f17a40cbfc036b4c8a2\",\"venue\":\"Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2009.5206557\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c26906b6dab02083ffd01fd27d9087597999bc0e\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/c26906b6dab02083ffd01fd27d9087597999bc0e\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4613996\",\"name\":\"B. Ainsworth\"},{\"authorId\":\"2796639\",\"name\":\"W. Haskell\"},{\"authorId\":\"40134159\",\"name\":\"S. Herrmann\"},{\"authorId\":\"3790176\",\"name\":\"N. Meckes\"},{\"authorId\":\"145633978\",\"name\":\"D. Bassett\"},{\"authorId\":\"1397356413\",\"name\":\"C. Tudor-Locke\"},{\"authorId\":\"50216445\",\"name\":\"J. Greer\"},{\"authorId\":\"5804293\",\"name\":\"Jesse W. Vezina\"},{\"authorId\":\"1398472503\",\"name\":\"M. Whitt-Glover\"},{\"authorId\":\"144252007\",\"name\":\"A. Leon\"}],\"doi\":\"10.1249/MSS.0b013e31821ece12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ab1cfd35edf7ad3af95092eea996184a27a925e\",\"title\":\"2011 Compendium of Physical Activities: a second update of codes and MET values.\",\"url\":\"https://www.semanticscholar.org/paper/1ab1cfd35edf7ad3af95092eea996184a27a925e\",\"venue\":\"Medicine and science in sports and exercise\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrej Karpathy\"},{\"authorId\":null,\"name\":\"George Toderici\"},{\"authorId\":null,\"name\":\"Sanketh Shetty\"},{\"authorId\":null,\"name\":\"Thomas Leung\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rahul Sukthankar , and Li Fei-Fei. Large-scale video classification with convolutional neural networks\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"988470995c4066e1fc0077042ece790b806356ee\",\"title\":\"The LEAR submission at Thumos 2014\",\"url\":\"https://www.semanticscholar.org/paper/988470995c4066e1fc0077042ece790b806356ee\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1145/2578726.2578775\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29f0a868644462aa7ebc21f4510d4209932a1b8c\",\"title\":\"Collecting and Annotating Human Activities in Web Videos\",\"url\":\"https://www.semanticscholar.org/paper/29f0a868644462aa7ebc21f4510d4209932a1b8c\",\"venue\":\"ICMR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1406.1881\",\"authors\":[{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_56\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ed4e6e8eecd26a2a38fe8e8c30a67dbdda88372\",\"title\":\"Fine-Grained Activity Recognition with Holistic and Pose Based Features\",\"url\":\"https://www.semanticscholar.org/paper/1ed4e6e8eecd26a2a38fe8e8c30a67dbdda88372\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"120896463\",\"name\":\"Chih-Wei Chen\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15552-9_29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"994a7b903b937f8b177c035db86852091fd26aa7\",\"title\":\"Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/994a7b903b937f8b177c035db86852091fd26aa7\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144096985\",\"name\":\"G. Miller\"}],\"doi\":\"10.1145/219717.219748\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68c03788224000794d5491ab459be0b2a2c38677\",\"title\":\"WordNet: a lexical database for English\",\"url\":\"https://www.semanticscholar.org/paper/68c03788224000794d5491ab459be0b2a2c38677\",\"venue\":\"CACM\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50562057\",\"name\":\"K. Pastra\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1098/rstb.2011.0123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f485cde67e163773b91d54d92c582612e5ce18d6\",\"title\":\"The minimalist grammar of action\",\"url\":\"https://www.semanticscholar.org/paper/f485cde67e163773b91d54d92c582612e5ce18d6\",\"venue\":\"Philosophical Transactions of the Royal Society B: Biological Sciences\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143712289\",\"name\":\"D. J. Patterson\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1007/s11263-012-0564-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a061e7eab865fc8d2ef00e029b7070719ad2e9a\",\"title\":\"Efficiently Scaling up Crowdsourced Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/7a061e7eab865fc8d2ef00e029b7070719ad2e9a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"1757665\",\"name\":\"Y. Zhao\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2013.389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66d9f5aef3fa5e0b8c5cd0c5e8b288dfc46d36d0\",\"title\":\"Concurrent Action Detection with Structural Prediction\",\"url\":\"https://www.semanticscholar.org/paper/66d9f5aef3fa5e0b8c5cd0c5e8b288dfc46d36d0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48336404\",\"name\":\"Daniel S. Hamermesh\"},{\"authorId\":\"83193756\",\"name\":\"Harley Frazis\"},{\"authorId\":\"32079337\",\"name\":\"J. Stewart\"}],\"doi\":\"10.1111/1468-232x.00222\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"08c06c651b4642b0072151316b4b92a2be8c8b92\",\"title\":\"The American Time Use Survey\",\"url\":\"https://www.semanticscholar.org/paper/08c06c651b4642b0072151316b4b92a2be8c8b92\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"2871555\",\"name\":\"P. Gehler\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2014.471\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da8d53f9a85b40a695585aa461286e373c6b74d4\",\"title\":\"2D Human Pose Estimation: New Benchmark and State of the Art Analysis\",\"url\":\"https://www.semanticscholar.org/paper/da8d53f9a85b40a695585aa461286e373c6b74d4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1007/s11263-014-0748-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9a6c7bfe831f2b154deac4409c35633c63ef326\",\"title\":\"SUN Database: Exploring a Large Collection of Scene Categories\",\"url\":\"https://www.semanticscholar.org/paper/c9a6c7bfe831f2b154deac4409c35633c63ef326\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dffe7498c67e9451db2d04bb8408f376ae86992\",\"title\":\"LEAR-INRIA submission for the THUMOS workshop\",\"url\":\"https://www.semanticscholar.org/paper/7dffe7498c67e9451db2d04bb8408f376ae86992\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Oneata\"},{\"authorId\":null,\"name\":\"J. Verbeek\"},{\"authorId\":null,\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The LEAR submission\",\"url\":\"\",\"venue\":\"Thumos\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCVW.2013.72\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4743bcbbf403fab7256bfa985c543d859d1cb5f\",\"title\":\"Spatio-temporal Human-Object Interactions for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4743bcbbf403fab7256bfa985c543d859d1cb5f\",\"venue\":\"2013 IEEE International Conference on Computer Vision Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A.R.Z. Khurram Soomro\"},{\"authorId\":null,\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"A dataset of 101 human action classes from videos in the wild\",\"url\":\"\",\"venue\":\"Technical report, University of Central Florida,\",\"year\":2012},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Freebase: A community-curated database of well-known people, places, and things\",\"url\":\"\",\"venue\":\"Freebase: A community-curated database of well-known people, places, and things\",\"year\":null}],\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"topics\":[{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Spatial variability\",\"topicId\":\"155512\",\"url\":\"https://www.semanticscholar.org/topic/155512\"}],\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"