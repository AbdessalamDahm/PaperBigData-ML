"{\"abstract\":\"This paper proposes a novel approach to action recognition from RGB-D cameras, in which depth features and RGB visual features are jointly used. Rich heterogeneous RGB and depth data are effectively compressed and projected to a learned shared space, in order to reduce noise and capture useful information for recognition. Knowledge from various sources can then be shared with others in the learned space to learn cross-modal features. This guides the discovery of valuable information for recognition. To capture complex spatiotemporal structural relationships in visual and depth features, we represent both RGB and depth data in a matrix form. We formulate the recognition task as a low-rank bilinear model composed of row and column parameter matrices. The rank of the model parameter is minimized to build a low-rank classifier, which is beneficial for improving the generalization power. The proposed method is extensively evaluated on two public RGB-D action datasets, and achieves state-of-the-art results. It also shows promising results if RGB or depth data are missing in training or testing procedure.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\",\"url\":\"https://www.semanticscholar.org/author/145873652\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\",\"url\":\"https://www.semanticscholar.org/author/46956675\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"Srijan Das\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"Fran\\u00e7ois Br\\u00e9mond\"}],\"doi\":\"10.1145/3293353.3293376\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"631a704edb53b0a4b852421891172ff785879727\",\"title\":\"Spatio-Temporal Grids for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/631a704edb53b0a4b852421891172ff785879727\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66506230\",\"name\":\"Tianshan Liu\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"46332897\",\"name\":\"Min Jiang\"},{\"authorId\":\"2254164\",\"name\":\"Hongtao Huo\"}],\"doi\":\"10.1117/1.JEI.28.2.023012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d646495c0c37941b127fb11f2c500dc9ebc51727\",\"title\":\"RGB-D action recognition based on discriminative common structure learning model\",\"url\":\"https://www.semanticscholar.org/paper/d646495c0c37941b127fb11f2c500dc9ebc51727\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2016.167\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"title\":\"3D Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9023907\",\"name\":\"B. Liu\"},{\"authorId\":\"152238857\",\"name\":\"Zhaojie Ju\"},{\"authorId\":\"145350352\",\"name\":\"N. Kubota\"},{\"authorId\":\"49957531\",\"name\":\"H. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"546a19dd66032b73c81c92834b10a1510c0be632\",\"title\":\"Online Action Recognition based on Skeleton Motion Distribution\",\"url\":\"https://www.semanticscholar.org/paper/546a19dd66032b73c81c92834b10a1510c0be632\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1604.02808\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.115\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"title\":\"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744109\",\"name\":\"C. Jia\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2016.2589320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"007e2c8333346f54fc754735728ab0e1320f763d\",\"title\":\"Low-Rank Tensor Subspace Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/007e2c8333346f54fc754735728ab0e1320f763d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1605.02260\",\"authors\":[{\"authorId\":\"3408031\",\"name\":\"Saihui Hou\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPRW.2016.140\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ad5c2668da869667152322263419f9bc95c523c\",\"title\":\"Deeply Exploit Depth Information for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/6ad5c2668da869667152322263419f9bc95c523c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94041056\",\"name\":\"Q. Liu\"},{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"144446381\",\"name\":\"Chengwu Liang\"},{\"authorId\":\"48447072\",\"name\":\"H. Liu\"}],\"doi\":\"10.3390/s20174673\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc19368b11d0f782fe321e55904b04b57bf6bdd3\",\"title\":\"Energy-Guided Temporal Segmentation Network for Multimodal Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc19368b11d0f782fe321e55904b04b57bf6bdd3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"}],\"doi\":\"10.32657/10356/69072\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e175109d071cdc8a77f0887f14293a3f9e813563\",\"title\":\"Activity recognition in depth videos\",\"url\":\"https://www.semanticscholar.org/paper/e175109d071cdc8a77f0887f14293a3f9e813563\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"},{\"authorId\":\"2196194\",\"name\":\"H. Zhang\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"41135049\",\"name\":\"Dong-Ying Gong\"},{\"authorId\":\"38187621\",\"name\":\"D. Cao\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1145/3177757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eee48babd9d42bb54f9a7391bceec3f8b98376b7\",\"title\":\"Multifeature Selection for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eee48babd9d42bb54f9a7391bceec3f8b98376b7\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1007/s11263-016-0982-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"048169db1243b6d4bd8c4d9bdccfd2526dcfe568\",\"title\":\"Max-Margin Heterogeneous Information Machine for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048169db1243b6d4bd8c4d9bdccfd2526dcfe568\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"66506230\",\"name\":\"Tianshan Liu\"},{\"authorId\":\"46332897\",\"name\":\"Min Jiang\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e320ffb26ca50d1ed5e9a4c06b69644a9c0896fa\",\"title\":\"Collaborative multimodal feature learning for RGB-D action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e320ffb26ca50d1ed5e9a4c06b69644a9c0896fa\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"}],\"doi\":\"10.1145/3115932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b26616644adfbfcba17438ed9336f31e01561226\",\"title\":\"Structure-Aware Multimodal Feature Fusion for RGB-D Scene Classification and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/b26616644adfbfcba17438ed9336f31e01561226\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36304959\",\"name\":\"Sebastien Mambou\"},{\"authorId\":\"1755574\",\"name\":\"O. Krejcar\"},{\"authorId\":\"144733650\",\"name\":\"K. Ku\\u010da\"},{\"authorId\":\"1749862\",\"name\":\"A. Selamat\"}],\"doi\":\"10.3390/fi10090089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9c34f28fa85f68e31c3d3fe9c58e80876700af1\",\"title\":\"Novel Cross-View Human Action Model Recognition Based on the Powerful View-Invariant Features Technique\",\"url\":\"https://www.semanticscholar.org/paper/c9c34f28fa85f68e31c3d3fe9c58e80876700af1\",\"venue\":\"Future Internet\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2017.2696786\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fef87e55a090fe0f1ec5cdaf24c8a37e8174dfb7\",\"title\":\"Deeply Learned View-Invariant Features for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fef87e55a090fe0f1ec5cdaf24c8a37e8174dfb7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2016.2556940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86150c90901ff7116d6620eb2bba293ddc4c3544\",\"title\":\"Discriminative Relational Representation Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/86150c90901ff7116d6620eb2bba293ddc4c3544\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9023907\",\"name\":\"B. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ec069624515091a95da618e4fb1dd35e251f010\",\"title\":\"Vision-based human activity analysis\",\"url\":\"https://www.semanticscholar.org/paper/4ec069624515091a95da618e4fb1dd35e251f010\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7680552\",\"name\":\"Ziliang Ren\"},{\"authorId\":\"51286715\",\"name\":\"Qieshi Zhang\"},{\"authorId\":\"46757766\",\"name\":\"X. Gao\"},{\"authorId\":\"51289240\",\"name\":\"Pengyi Hao\"},{\"authorId\":\"114675671\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1007/s11042-019-08576-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"683646753df25cb5ad91bdecc4bf6bb7bdf2f0bf\",\"title\":\"Multi-modality learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/683646753df25cb5ad91bdecc4bf6bb7bdf2f0bf\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1606.04992\",\"authors\":[{\"authorId\":\"1763954\",\"name\":\"I. Lillo\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/CVPR.2016.218\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a60a0a074570d245d0d9c8d505b5c9ae303fed5\",\"title\":\"A Hierarchical Pose-Based Approach to Complex Action Understanding Using Dictionaries of Actionlets and Motion Poselets\",\"url\":\"https://www.semanticscholar.org/paper/5a60a0a074570d245d0d9c8d505b5c9ae303fed5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145424954\",\"name\":\"L. Feng\"},{\"authorId\":\"2019709202\",\"name\":\"Qing Yuan\"},{\"authorId\":\"47908890\",\"name\":\"Y. Liu\"},{\"authorId\":\"1500555736\",\"name\":\"Qianxin Huang\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"},{\"authorId\":\"1527101232\",\"name\":\"Yingping Li\"}],\"doi\":\"10.1007/978-3-030-63823-8_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"567b50b98c55e0b4dea2e257e25971368eefa507\",\"title\":\"A Discriminative STGCN for Skeleton Oriented Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/567b50b98c55e0b4dea2e257e25971368eefa507\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2656603\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/DICTA.2017.8227505\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"title\":\"Viewpoint Invariant RGB-D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"1601.05511\",\"authors\":[{\"authorId\":\"47539715\",\"name\":\"Jing Zhang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"}],\"doi\":\"10.1016/j.patcog.2016.05.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a52a2d27a0d6f7f5508941998344df692216f4d\",\"title\":\"RGB-D-based action recognition datasets: A survey\",\"url\":\"https://www.semanticscholar.org/paper/6a52a2d27a0d6f7f5508941998344df692216f4d\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2017.8078548\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b9df1094d7db7e17702e785931a927bf568ae7\",\"title\":\"Action recognition based on a mixture of RGB and depth based skeleton\",\"url\":\"https://www.semanticscholar.org/paper/71b9df1094d7db7e17702e785931a927bf568ae7\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":\"1603.07120\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2691321\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"title\":\"Deep Multimodal Feature Analysis for Action Recognition in RGB+D Videos\",\"url\":\"https://www.semanticscholar.org/paper/a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"144664641\",\"name\":\"M. Fathy\"},{\"authorId\":\"31062038\",\"name\":\"A. A. Azirani\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"}],\"doi\":\"10.1007/s11042-020-08875-w\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"776c7ccb8b7193a60b48fec2248919d5c25dd1c0\",\"title\":\"Skeleton-based structured early activity prediction\",\"url\":\"https://www.semanticscholar.org/paper/776c7ccb8b7193a60b48fec2248919d5c25dd1c0\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9399859\",\"name\":\"C. Fan\"},{\"authorId\":\"4387605\",\"name\":\"Zhengyuan Zhai\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1698650\",\"name\":\"Lei Tian\"}],\"doi\":\"10.1117/1.JEI.28.2.023004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"964a14aace00c4e2a2759622d905467e79dc0ddb\",\"title\":\"Two-stream siamese network with contrastive-center losses for RGB-D action recognition\",\"url\":\"https://www.semanticscholar.org/paper/964a14aace00c4e2a2759622d905467e79dc0ddb\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1802.00421\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4ebf0a4f48275ecd8dbc2840b2a31cc07bd676d\",\"title\":\"A Fusion of Appearance based CNNs and Temporal evolution of Skeleton with LSTM for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4ebf0a4f48275ecd8dbc2840b2a31cc07bd676d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9023907\",\"name\":\"B. Liu\"},{\"authorId\":\"1694217\",\"name\":\"Haibin Cai\"},{\"authorId\":\"152238857\",\"name\":\"Zhaojie Ju\"},{\"authorId\":\"49957531\",\"name\":\"H. Liu\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb9f1122690fc6e856d472d5ab3f8b2e2863b3af\",\"title\":\"RGB-D sensing based human action and interaction analysis: A survey\",\"url\":\"https://www.semanticscholar.org/paper/eb9f1122690fc6e856d472d5ab3f8b2e2863b3af\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32749929\",\"name\":\"Mohammad M. Arzani\"},{\"authorId\":\"144664641\",\"name\":\"M. Fathy\"},{\"authorId\":\"32609045\",\"name\":\"H. Aghajan\"},{\"authorId\":\"31062038\",\"name\":\"A. A. Azirani\"},{\"authorId\":\"1719313\",\"name\":\"K. Raahemifar\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"}],\"doi\":\"10.1109/IROS.2017.8202208\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24fccbc0ed02dbceb559c4cd6cac4a934baf88bf\",\"title\":\"Structured prediction with short/long-range dependencies for human activity recognition from depth skeleton data\",\"url\":\"https://www.semanticscholar.org/paper/24fccbc0ed02dbceb559c4cd6cac4a934baf88bf\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1607.06972\",\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"144624889\",\"name\":\"Zhiyuan Shi\"},{\"authorId\":\"36064037\",\"name\":\"M. Kawade\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.5244/C.31.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72ccbde258d00f81386675a170d63ac52b47791\",\"title\":\"Kinematic-Layout-aware Random Forests for Depth-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c72ccbde258d00f81386675a170d63ac52b47791\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81390972a12e2b25af2e174b1082a797860a02f0\",\"title\":\"SharedSpecific SpecificSpecific Specific Feature ExtractionFeature Extraction { Joint learningX 1 X 4 X 3 X 2 { { {\",\"url\":\"https://www.semanticscholar.org/paper/81390972a12e2b25af2e174b1082a797860a02f0\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8520539\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"},{\"authorId\":\"1744844\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TPAMI.2016.2640292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5478e03e02c3af80be42614b745e214b9c8efa93\",\"title\":\"Jointly Learning Heterogeneous Features for RGB-D Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5478e03e02c3af80be42614b745e214b9c8efa93\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3065505\",\"name\":\"Y. Wu\"},{\"authorId\":\"47567384\",\"name\":\"L. Wei\"},{\"authorId\":\"145963973\",\"name\":\"Yucong Duan\"}],\"doi\":\"10.1111/coin.12207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d4fb7ddfd85ed45e10616c5342e78bbf48d14b6\",\"title\":\"Deep spatiotemporal LSTM network with temporal pattern feature for 3D human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d4fb7ddfd85ed45e10616c5342e78bbf48d14b6\",\"venue\":\"Comput. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51378475\",\"name\":\"L\\u00fd Qu\\u1ed1c Ng\\u1ecdc\"},{\"authorId\":\"50466312\",\"name\":\"V. Viet\"},{\"authorId\":\"2995376\",\"name\":\"T. T. Son\"},{\"authorId\":\"3059757\",\"name\":\"Pham Minh Hoang\"}],\"doi\":\"10.14569/IJACSA.2016.070526\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a11154cc857d83ba2edfff4746d4a404e437b49e\",\"title\":\"A Robust Approach for Action Recognition Based on Spatio-Temporal Features in RGB-D Sequences\",\"url\":\"https://www.semanticscholar.org/paper/a11154cc857d83ba2edfff4746d4a404e437b49e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1702.08652\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"35061362\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/CVPR.2017.52\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"title\":\"Scene Flow to Action Map: A New Representation for RGB-D Based Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1709.05087\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"3003408\",\"name\":\"Mian M. Ajmal\"}],\"doi\":\"10.1109/ACCESS.2018.2880231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"title\":\"Viewpoint Invariant Action Recognition Using RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.sigpro.2017.06.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0dfb43c0a2d16405b72df5e9404fc7e90c59be3\",\"title\":\"One-shot learning based pattern transition map for action early recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0dfb43c0a2d16405b72df5e9404fc7e90c59be3\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2544367\",\"name\":\"Zhanpeng Shao\"},{\"authorId\":\"1752206\",\"name\":\"Y. Li\"},{\"authorId\":\"39179094\",\"name\":\"Yao Guo\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"47196303\",\"name\":\"Zhenhua Wang\"}],\"doi\":\"10.1109/ICRA.2018.8460516\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"531da6ed46e9d5a3088fe4841c50955459f13497\",\"title\":\"A Hierarchical Model for Action Recognition Based on Body Parts\",\"url\":\"https://www.semanticscholar.org/paper/531da6ed46e9d5a3088fe4841c50955459f13497\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36304959\",\"name\":\"Sebastien Mambou\"},{\"authorId\":\"1755574\",\"name\":\"O. Krejcar\"},{\"authorId\":\"144733650\",\"name\":\"K. Ku\\u010da\"},{\"authorId\":\"1749862\",\"name\":\"A. Selamat\"}],\"doi\":\"10.1007/978-3-319-76081-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"551259850480842147de53448350cdc46368e4cb\",\"title\":\"Novel Human Action Recognition in RGB-D Videos Based on Powerful View Invariant Features Technique\",\"url\":\"https://www.semanticscholar.org/paper/551259850480842147de53448350cdc46368e4cb\",\"venue\":\"ACIIDS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50218246\",\"name\":\"Z. Wang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TCSVT.2018.2875441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a90a56267b66c060b235339a0080a00585fdeb41\",\"title\":\"Multi-Stream Deep Neural Networks for RGB-D Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a90a56267b66c060b235339a0080a00585fdeb41\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"},{\"authorId\":\"3397609\",\"name\":\"Ziyun Cai\"},{\"authorId\":\"2349140\",\"name\":\"Li Liu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"}],\"doi\":\"10.1016/j.ins.2017.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0123d8c98870516caaff8dd8326c0b85c82fe43\",\"title\":\"Performance evaluation of deep feature learning for RGB-D image/video classification\",\"url\":\"https://www.semanticscholar.org/paper/a0123d8c98870516caaff8dd8326c0b85c82fe43\",\"venue\":\"Inf. Sci.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1964987\",\"name\":\"W. Li\"},{\"authorId\":\"6289742\",\"name\":\"Yahui Ding\"}],\"doi\":\"10.1145/3007669.3007702\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af3fb559aca925832b4d25a4feea732a4665753f\",\"title\":\"Human Action Recognition by Fusion of Convolutional Neural Networks and spatial-temporal Information\",\"url\":\"https://www.semanticscholar.org/paper/af3fb559aca925832b4d25a4feea732a4665753f\",\"venue\":\"ICIMCS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2544367\",\"name\":\"Zhanpeng Shao\"},{\"authorId\":\"31583909\",\"name\":\"Y. Li\"},{\"authorId\":\"39179094\",\"name\":\"Yao Guo\"},{\"authorId\":\"47155354\",\"name\":\"Xiaolong Zhou\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2871660\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bf9355335e52c451a56a769e62be58c300a2dde\",\"title\":\"A Hierarchical Model for Human Action Recognition From Body-Parts\",\"url\":\"https://www.semanticscholar.org/paper/7bf9355335e52c451a56a769e62be58c300a2dde\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.02947\",\"authors\":[{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"},{\"authorId\":\"51131061\",\"name\":\"L. Anvitha\"},{\"authorId\":\"21858780\",\"name\":\"T. Lahari\"}],\"doi\":\"10.1007/s11042-020-08747-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73e0a1852cb4e5a9077c35b4cbc6e238542d2ed8\",\"title\":\"Human activity recognition in RGB-D videos by dynamic images\",\"url\":\"https://www.semanticscholar.org/paper/73e0a1852cb4e5a9077c35b4cbc6e238542d2ed8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1801.01080\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145590756\",\"name\":\"Xinwang Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"26702963c1718a29ed287b51ddd12793464cfdd2\",\"title\":\"Cooperative Training of Deep Aggregation Networks for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/26702963c1718a29ed287b51ddd12793464cfdd2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1904.12602\",\"authors\":[{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"145125621\",\"name\":\"B. Sun\"},{\"authorId\":\"4056993\",\"name\":\"J. P. Robinson\"},{\"authorId\":\"113933538\",\"name\":\"Taotao Jing\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f0fb321619915a20b29452f19697dbfa2cf6d2\",\"title\":\"EV-Action: Electromyography-Vision Multi-Modal Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/15f0fb321619915a20b29452f19697dbfa2cf6d2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744109\",\"name\":\"C. Jia\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1007/978-3-319-27004-3_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee8d4d064460e1e43ca9f86f315189ec16302427\",\"title\":\"Subspace Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee8d4d064460e1e43ca9f86f315189ec16302427\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1602.00749\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"7718545\",\"name\":\"Z. Li\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"}],\"doi\":\"10.1007/s11042-017-5335-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69092f38fe4f0cdcb4de444dfcfd48879760014a\",\"title\":\"Combining ConvNets with hand-crafted features for action recognition based on an HMM-SVM classifier\",\"url\":\"https://www.semanticscholar.org/paper/69092f38fe4f0cdcb4de444dfcfd48879760014a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3408031\",\"name\":\"Saihui Hou\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1016/j.neucom.2018.01.055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9a1d1ac99da2726c494b3b73053b625385427e5\",\"title\":\"Object detection via deeply exploiting depth information\",\"url\":\"https://www.semanticscholar.org/paper/f9a1d1ac99da2726c494b3b73053b625385427e5\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/AVSS.2016.7738023\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"efc5cf6e30ba5a175cff919be2c1642abf408565\",\"title\":\"Modeling spatial layout of features for real world scenario RGB-D action recognition\",\"url\":\"https://www.semanticscholar.org/paper/efc5cf6e30ba5a175cff919be2c1642abf408565\",\"venue\":\"2016 13th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"},{\"authorId\":\"49049934\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/CVPR.2015.7299172\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f06d9e9cbc98c19e7f10fd4a85c3b5e28185c4a5\",\"title\":\"Jointly learning heterogeneous features for RGB-D activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/f06d9e9cbc98c19e7f10fd4a85c3b5e28185c4a5\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"2196194\",\"name\":\"H. Zhang\"},{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"41135049\",\"name\":\"Dong-Ying Gong\"},{\"authorId\":\"38187621\",\"name\":\"D. Cao\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"}],\"doi\":\"10.1016/j.neucom.2018.02.056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9577c5d16a95e7e9d0d7cbae01dccdc8ab076c6a\",\"title\":\"Discriminative parts learning for 3D human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9577c5d16a95e7e9d0d7cbae01dccdc8ab076c6a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39963722\",\"name\":\"Raviteja Vemulapalli\"},{\"authorId\":\"1998286\",\"name\":\"Felipe Arrate\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1016/j.cviu.2016.04.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da1cc72354f70a187d46664c2318c58d8183c379\",\"title\":\"R3DG features: Relative 3D geometry-based skeletal representations for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da1cc72354f70a187d46664c2318c58d8183c379\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"144624889\",\"name\":\"Zhiyuan Shi\"},{\"authorId\":\"36064037\",\"name\":\"Masato Kawade\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f48e2d8655e04bc06c0d90eaa2e0be03466d69c9\",\"title\":\"Kinematic-aware random forest for static and dynamic action recognition from depth sequences\",\"url\":\"https://www.semanticscholar.org/paper/f48e2d8655e04bc06c0d90eaa2e0be03466d69c9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1016/j.patcog.2018.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c6f39799392aaacf2fb342518d420e30e24785\",\"title\":\"Learning principal orientations and residual descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2c6f39799392aaacf2fb342518d420e30e24785\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"47672151\",\"name\":\"Ning Xu\"},{\"authorId\":\"153576780\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TIP.2018.2872879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f96d433e91ddf46d8a7b174dfbdd8eed1087d40\",\"title\":\"Multi-Domain and Multi-Task Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f96d433e91ddf46d8a7b174dfbdd8eed1087d40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70272801\",\"name\":\"Atiqur Rahman Ahad\"}],\"doi\":\"10.4018/978-1-7998-2584-5.ch002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4be38d2bea1748d6157f6bfd528e7c6d3ea6a0a9\",\"title\":\"Vision and Sensor-Based Human Activity Recognition: Challenges Ahead\",\"url\":\"https://www.semanticscholar.org/paper/4be38d2bea1748d6157f6bfd528e7c6d3ea6a0a9\",\"venue\":\"\",\"year\":2020}],\"corpusId\":6474290,\"doi\":\"10.1109/CVPR.2015.7298708\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"90c88bf394008d23beff5a8e60f0cb4c57db10cd\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1162/089976600300015349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e85f7d59e37972ec52cbabfef0512588d87f125\",\"title\":\"Separating Style and Content with Bilinear Models\",\"url\":\"https://www.semanticscholar.org/paper/7e85f7d59e37972ec52cbabfef0512588d87f125\",\"venue\":\"Neural Computation\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1809184\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1109/CVPRW.2010.5543273\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"79465f3bac4fb9f8cc66dcbe676022ddcd9c05c6\",\"title\":\"Action recognition based on a bag of 3D points\",\"url\":\"https://www.semanticscholar.org/paper/79465f3bac4fb9f8cc66dcbe676022ddcd9c05c6\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/CVPR.2014.108\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ae76644810fa6ed28d2a0765f444fa0c950bf51a\",\"title\":\"Super Normal Vector for Activity Recognition Using Depth Sequences\",\"url\":\"https://www.semanticscholar.org/paper/ae76644810fa6ed28d2a0765f444fa0c950bf51a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50033175\",\"name\":\"A. Argyriou\"},{\"authorId\":\"1801089\",\"name\":\"T. Evgeniou\"},{\"authorId\":\"1704699\",\"name\":\"M. Pontil\"}],\"doi\":\"10.1007/s10994-007-5040-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e7b0395d7b34e9d34cca779afd0c10da6e135b5\",\"title\":\"Convex multi-task feature learning\",\"url\":\"https://www.semanticscholar.org/paper/9e7b0395d7b34e9d34cca779afd0c10da6e135b5\",\"venue\":\"Machine Learning\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"094f5e36dae2602e179f2c1d95a616df3dbe967f\",\"title\":\"Bilinear classifiers for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/094f5e36dae2602e179f2c1d95a616df3dbe967f\",\"venue\":\"NIPS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2013.342\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bc95b2fa949b0de6ef028fde359e2a60fceee04\",\"title\":\"Poselet Key-Framing: A Model for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9bc95b2fa949b0de6ef028fde359e2a60fceee04\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143774737\",\"name\":\"J. Shotton\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"34824003\",\"name\":\"T. Sharp\"},{\"authorId\":\"40636177\",\"name\":\"Mat Cook\"},{\"authorId\":\"2848295\",\"name\":\"M. Finocchio\"},{\"authorId\":\"144564063\",\"name\":\"R. Moore\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1716777\",\"name\":\"A. Criminisi\"},{\"authorId\":\"40016803\",\"name\":\"A. Kipman\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"}],\"doi\":\"10.1109/TPAMI.2012.241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"095d7cb463b0ea29d49b099860aa8ea1142cbcf6\",\"title\":\"Efficient Human Pose Estimation from Single Depth Images\",\"url\":\"https://www.semanticscholar.org/paper/095d7cb463b0ea29d49b099860aa8ea1142cbcf6\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1975564\",\"name\":\"M. Zanfir\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/ICCV.2013.342\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55541d61863f7c2171897db0a7d89465bea8420d\",\"title\":\"The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/55541d61863f7c2171897db0a7d89465bea8420d\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37077406\",\"name\":\"C. Teo\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"145713876\",\"name\":\"S. Vishwanathan\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.1145/1281192.1281270\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8ad078927375243a4dd937f745c60e884ebbf6b\",\"title\":\"A scalable modular convex solver for regularized risk minimization\",\"url\":\"https://www.semanticscholar.org/paper/b8ad078927375243a4dd937f745c60e884ebbf6b\",\"venue\":\"KDD '07\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"}],\"doi\":\"10.1109/CVPR.2013.365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"890b1f7946ada41e03dcc2807e74d64372716496\",\"title\":\"Spatio-temporal Depth Cuboid Similarity Feature for Activity Recognition Using Depth Camera\",\"url\":\"https://www.semanticscholar.org/paper/890b1f7946ada41e03dcc2807e74d64372716496\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1738471\",\"name\":\"Chenyang Zhang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1145/2393347.2396382\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48a4e78c12b0cb71f4c4343df709f0582fe0e128\",\"title\":\"Recognizing actions using depth motion maps-based histograms of oriented gradients\",\"url\":\"https://www.semanticscholar.org/paper/48a4e78c12b0cb71f4c4343df709f0582fe0e128\",\"venue\":\"ACM Multimedia\",\"year\":2012},{\"arxivId\":\"physics/0004057\",\"authors\":[{\"authorId\":\"1777660\",\"name\":\"Naftali Tishby\"},{\"authorId\":\"145366908\",\"name\":\"Fernando C Pereira\"},{\"authorId\":\"1762240\",\"name\":\"W. Bialek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c76c62c5ab6c076a80f925d277ef04dd36f6bf9c\",\"title\":\"The information bottleneck method\",\"url\":\"https://www.semanticscholar.org/paper/c76c62c5ab6c076a80f925d277ef04dd36f6bf9c\",\"venue\":\"ArXiv\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2014.2303090\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d6eea0a59e5c2c4a25e658ce4250b3442f6d300\",\"title\":\"Interactive Phrases: Semantic Descriptionsfor Human Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d6eea0a59e5c2c4a25e658ce4250b3442f6d300\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"31796215\",\"name\":\"Chao Xu\"}],\"doi\":\"10.1109/TPAMI.2013.2296528\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43996253f97d7023af1b1869a7ec2e6376ca1986\",\"title\":\"Large-Margin Multi-ViewInformation Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/43996253f97d7023af1b1869a7ec2e6376ca1986\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.1007/s11263-014-0709-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f84ab63e787c83a895fb2f1c3c5a45042f0f729d\",\"title\":\"Low-Rank Bilinear Classification: Efficient Convex Optimization and Extensions\",\"url\":\"https://www.semanticscholar.org/paper/f84ab63e787c83a895fb2f1c3c5a45042f0f729d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2257309\",\"name\":\"Jiajia Luo\"},{\"authorId\":\"49336726\",\"name\":\"Wei Wang\"},{\"authorId\":\"1698645\",\"name\":\"H. Qi\"}],\"doi\":\"10.1109/ICCV.2013.227\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a3a60d9205d11dc13f36b3e559c55e78140173f\",\"title\":\"Group Sparsity and Geometry Constrained Dictionary Learning for Action Recognition from Depth Maps\",\"url\":\"https://www.semanticscholar.org/paper/7a3a60d9205d11dc13f36b3e559c55e78140173f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"181e880a50d115b1fa5f291f67ed05c6a172c5d5\",\"title\":\"Learning Discriminative Representations from RGB-D Video Data\",\"url\":\"https://www.semanticscholar.org/paper/181e880a50d115b1fa5f291f67ed05c6a172c5d5\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5649543\",\"name\":\"T. Do\"},{\"authorId\":\"7364123\",\"name\":\"T. Arti\\u00e8res\"}],\"doi\":\"10.1145/1553374.1553408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"803abe8ba1aa314cc85ba01f4312a8a417933483\",\"title\":\"Large margin training for hidden Markov models with partially observed states\",\"url\":\"https://www.semanticscholar.org/paper/803abe8ba1aa314cc85ba01f4312a8a417933483\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2007.383099\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0234a8b7d43b22fb4f3998e768f668b38d362770\",\"title\":\"Modeling Appearances with Low-Rank SVM\",\"url\":\"https://www.semanticscholar.org/paper/0234a8b7d43b22fb4f3998e768f668b38d362770\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144651486\",\"name\":\"L. Bo\"},{\"authorId\":\"145258674\",\"name\":\"K. Lai\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"}],\"doi\":\"10.1109/CVPR.2011.5995719\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c610a7d6f5c89c40fde6b777cae29e45fdb1e30\",\"title\":\"Object recognition with hierarchical kernel descriptors\",\"url\":\"https://www.semanticscholar.org/paper/7c610a7d6f5c89c40fde6b777cae29e45fdb1e30\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2417546\",\"name\":\"S. Hadfield\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/CVPR.2013.436\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1dbd7653ede6af15d539f64cb2128752ca029e44\",\"title\":\"Hollywood 3D: Recognizing Actions in 3D Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/1dbd7653ede6af15d539f64cb2128752ca029e44\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lin Chen\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1109/CVPR.2014.184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aed57ca5070d68e18760402ec575070d81edcaa\",\"title\":\"Recognizing RGB Images by Learning from RGB-D Data\",\"url\":\"https://www.semanticscholar.org/paper/6aed57ca5070d68e18760402ec575070d81edcaa\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9275891\",\"name\":\"Chengcheng Jia\"},{\"authorId\":\"122835079\",\"name\":\"Yu Kong\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"145692771\",\"name\":\"Y. Fu\"}],\"doi\":\"10.1145/2647868.2654928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"274f87ad659cd90382ef38f7c6fafc4fc7f0d74d\",\"title\":\"Latent Tensor Transfer Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/274f87ad659cd90382ef38f7c6fafc4fc7f0d74d\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2012.6247813\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"321f519e2876e1fa086b36e1b3f91b1efe2ea532\",\"title\":\"Mining actionlet ensemble for action recognition with depth cameras\",\"url\":\"https://www.semanticscholar.org/paper/321f519e2876e1fa086b36e1b3f91b1efe2ea532\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"50678963\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/CVPR.2012.6247808\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6acdddc36ea57ec84581e9e196665f246e8157ab\",\"title\":\"Learning latent temporal structure for complex event detection\",\"url\":\"https://www.semanticscholar.org/paper/6acdddc36ea57ec84581e9e196665f246e8157ab\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2405613\",\"name\":\"Omar Oreifej\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1109/CVPR.2013.98\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bbe9a802c83f52f365e6cef799df9dc19f9dbdb\",\"title\":\"HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences\",\"url\":\"https://www.semanticscholar.org/paper/1bbe9a802c83f52f365e6cef799df9dc19f9dbdb\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143774737\",\"name\":\"J. Shotton\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"34824003\",\"name\":\"T. Sharp\"},{\"authorId\":\"40636177\",\"name\":\"Mat Cook\"},{\"authorId\":\"2848295\",\"name\":\"M. Finocchio\"},{\"authorId\":\"144564063\",\"name\":\"R. Moore\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1716777\",\"name\":\"A. Criminisi\"},{\"authorId\":\"40016803\",\"name\":\"A. Kipman\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"}],\"doi\":\"10.1109/TPAMI.2012.241\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1113b4fcf644616e2587eacead2bca4b794ac47d\",\"title\":\"Efficient Human Pose Estimation from Single Depth Images\",\"url\":\"https://www.semanticscholar.org/paper/1113b4fcf644616e2587eacead2bca4b794ac47d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103048455\",\"name\":\"Xuchang\"},{\"authorId\":\"73271184\",\"name\":\"TaoDacheng\"},{\"authorId\":\"102021381\",\"name\":\"Xuchao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed97a6251767d929fdc79df141365e6a367e2633\",\"title\":\"Large-Margin Multi-ViewInformation Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/ed97a6251767d929fdc79df141365e6a367e2633\",\"venue\":\"\",\"year\":2014}],\"title\":\"Bilinear heterogeneous information machine for RGB-D action recognition\",\"topics\":[{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Solver\",\"topicId\":\"6215\",\"url\":\"https://www.semanticscholar.org/topic/6215\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Bilinear transform\",\"topicId\":\"397622\",\"url\":\"https://www.semanticscholar.org/topic/397622\"},{\"topic\":\"Low-rank approximation\",\"topicId\":\"105913\",\"url\":\"https://www.semanticscholar.org/topic/105913\"},{\"topic\":\"CNS\",\"topicId\":\"61911\",\"url\":\"https://www.semanticscholar.org/topic/61911\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/90c88bf394008d23beff5a8e60f0cb4c57db10cd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"