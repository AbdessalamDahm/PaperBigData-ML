"{\"abstract\":\"This paper concerns action recognition from unseen and unknown views. We propose unsupervised learning of a non-linear model that transfers knowledge from multiple views to a canonical view. The proposed Non-linear Knowledge Transfer Model (NKTM) is a deep network, with weight decay and sparsity constraints, which finds a shared high-level virtual path from videos captured from different unknown viewpoints to the same canonical view. The strength of our technique is that we learn a single NKTM for all actions and all camera viewing directions. Thus, NKTM does not require action labels during learning and knowledge of the camera viewpoints during training or testing. NKTM is learned once only from dense trajectories of synthetic points fitted to mocap data and then applied to real video data. Trajectories are coded with a general codebook learned from the same mocap data. NKTM is scalable to new action classes and training data as it does not require re-learning. Experiments on the IXMAS and N-UCLA datasets show that NKTM outperforms existing state-of-the-art methods for cross-view action recognition.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\",\"url\":\"https://www.semanticscholar.org/author/1877377\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\",\"url\":\"https://www.semanticscholar.org/author/1747500\"}],\"citationVelocity\":23,\"citations\":[{\"arxivId\":\"1703.08274\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/ICCV.2017.233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b68cdb5eee1b5db18398efb0d2c5d727285e5e4\",\"title\":\"View Adaptive Recurrent Neural Networks for High Performance Human Action Recognition from Skeleton Data\",\"url\":\"https://www.semanticscholar.org/paper/5b68cdb5eee1b5db18398efb0d2c5d727285e5e4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1908.03057\",\"authors\":[{\"authorId\":\"31317272\",\"name\":\"R. Saputra\"},{\"authorId\":\"3287144\",\"name\":\"Nemanja Rakicevic\"},{\"authorId\":\"1686032\",\"name\":\"Petar Kormushev\"}],\"doi\":\"10.1109/IROS40897.2019.8967642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22a6fd0e72c283b82b033ac0f451b46765e54f9b\",\"title\":\"Sim-to-Real Learning for Casualty Detection from Ground Projected Point Cloud Data\",\"url\":\"https://www.semanticscholar.org/paper/22a6fd0e72c283b82b033ac0f451b46765e54f9b\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/ICCV.2019.00092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c17f395738bc3494974283ba9460c516a948f7ef\",\"title\":\"Toyota Smarthome: Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/c17f395738bc3494974283ba9460c516a948f7ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1701.01370\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143881914\",\"name\":\"J. Romero\"},{\"authorId\":\"144173710\",\"name\":\"X. Martin\"},{\"authorId\":\"1892850\",\"name\":\"Naureen Mahmood\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2017.492\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"661778ccef17289a07e3eb0ba2343b851762213e\",\"title\":\"Learning from Synthetic Humans\",\"url\":\"https://www.semanticscholar.org/paper/661778ccef17289a07e3eb0ba2343b851762213e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2004.13979\",\"authors\":[{\"authorId\":\"48317098\",\"name\":\"Bruce X. B. Yu\"},{\"authorId\":\"49422024\",\"name\":\"Y. Liu\"},{\"authorId\":\"145003402\",\"name\":\"K. C. Chan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"title\":\"Skeleton Focused Human Activity Recognition in RGB Video\",\"url\":\"https://www.semanticscholar.org/paper/ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1601.05511\",\"authors\":[{\"authorId\":\"47539715\",\"name\":\"Jing Zhang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"}],\"doi\":\"10.1016/j.patcog.2016.05.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a52a2d27a0d6f7f5508941998344df692216f4d\",\"title\":\"RGB-D-based action recognition datasets: A survey\",\"url\":\"https://www.semanticscholar.org/paper/6a52a2d27a0d6f7f5508941998344df692216f4d\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2016.167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"title\":\"3D Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47424035\",\"name\":\"Chengkun Zhang\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/ACCESS.2018.2815611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"301d70a4b38071c222ea8b095c42a09494fc9d88\",\"title\":\"Cross-View Action Recognition Based on Hierarchical View-Shared Dictionary Learning\",\"url\":\"https://www.semanticscholar.org/paper/301d70a4b38071c222ea8b095c42a09494fc9d88\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1706.08276\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2771306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5b83d6b4a3c1093edc9138ab9dfe4e965a80261\",\"title\":\"Skeleton-Based Action Recognition Using Spatio-Temporal LSTM Network with Trust Gates\",\"url\":\"https://www.semanticscholar.org/paper/d5b83d6b4a3c1093edc9138ab9dfe4e965a80261\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35035828\",\"name\":\"A. Ulhaq\"},{\"authorId\":\"49665006\",\"name\":\"Xiaoxia Yin\"},{\"authorId\":\"49122246\",\"name\":\"Jing He\"},{\"authorId\":\"34853026\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2765821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2d890c3b1055c363fc6fa98ae20b1fdb1e5c80e\",\"title\":\"On Space-Time Filtering Framework for Matching Human Actions Across Different Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/a2d890c3b1055c363fc6fa98ae20b1fdb1e5c80e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403939474\",\"name\":\"O. Mendoza-Schrock\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e397db8fb7f76b42981ba226ad84758185b39305\",\"title\":\"Diffusion Maps and Transfer Subspace Learning\",\"url\":\"https://www.semanticscholar.org/paper/e397db8fb7f76b42981ba226ad84758185b39305\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646571538\",\"name\":\"Mohamed Adel Musallam\"},{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"1646568928\",\"name\":\"Kassem Al Ismaeil\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"}],\"doi\":\"10.1109/CSCI49370.2019.00052\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"302e5769672f2897932f9f759b3246650fd62891\",\"title\":\"Temporal 3D Human Pose Estimation for Action Recognition from Arbitrary Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/302e5769672f2897932f9f759b3246650fd62891\",\"venue\":\"2019 International Conference on Computational Science and Computational Intelligence (CSCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"2646598\",\"name\":\"F. Hu\"},{\"authorId\":\"84175736\",\"name\":\"Qianyu Wu\"},{\"authorId\":\"50025538\",\"name\":\"Y. Li\"}],\"doi\":\"10.1117/1.JEI.29.4.043025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd4ae0706b11408070ef88390215b9237f58a0fe\",\"title\":\"Two-stream spatial-temporal neural networks for pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd4ae0706b11408070ef88390215b9237f58a0fe\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47949380\",\"name\":\"Guang Li\"},{\"authorId\":\"145538996\",\"name\":\"K. Liu\"},{\"authorId\":\"50759119\",\"name\":\"W. Ding\"},{\"authorId\":\"145293273\",\"name\":\"Fei Cheng\"},{\"authorId\":\"4086266\",\"name\":\"C. Ding\"}],\"doi\":\"10.1155/2019/8940807\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b1e686a9da190f59bdd0a33d8f25096a1fda637\",\"title\":\"Nonnegative Tensor-Based Linear Dynamical Systems for Recognizing Human Action from 3D Skeletons\",\"url\":\"https://www.semanticscholar.org/paper/3b1e686a9da190f59bdd0a33d8f25096a1fda637\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1612.06423\",\"authors\":[{\"authorId\":\"37405910\",\"name\":\"Alireza Rahimpour\"},{\"authorId\":\"2885826\",\"name\":\"A. Taalimi\"},{\"authorId\":\"1698645\",\"name\":\"H. Qi\"}],\"doi\":\"10.1109/ICASSP.2017.7952457\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b976f7bfa636d89510fe5ad7fb7a8057b86a57f\",\"title\":\"Feature encoding in band-limited distributed surveillance systems\",\"url\":\"https://www.semanticscholar.org/paper/9b976f7bfa636d89510fe5ad7fb7a8057b86a57f\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e912c725ff31fc54dc72b89c93989ea2ca6261d\",\"title\":\"Sim2real transfer learning for 3D human pose estimation: motion to the rescue\",\"url\":\"https://www.semanticscholar.org/paper/2e912c725ff31fc54dc72b89c93989ea2ca6261d\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-58583-9_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"title\":\"Multi-view Action Recognition Using Cross-View Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1814260\",\"name\":\"Enjie Ghorbel\"},{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"152741061\",\"name\":\"Himadri Pathak\"},{\"authorId\":\"2878772\",\"name\":\"Girum G. Demisse\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.5220/0007524405730582\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e205941d8439631f36a0d48ad342984c05c0fb34\",\"title\":\"A View-invariant Framework for Fast Skeleton-based Action Recognition using a Single RGB Camera\",\"url\":\"https://www.semanticscholar.org/paper/e205941d8439631f36a0d48ad342984c05c0fb34\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36304959\",\"name\":\"Sebastien Mambou\"},{\"authorId\":\"1755574\",\"name\":\"O. Krejcar\"},{\"authorId\":\"144733650\",\"name\":\"K. Ku\\u010da\"},{\"authorId\":\"1749862\",\"name\":\"A. Selamat\"}],\"doi\":\"10.1007/978-3-319-76081-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"551259850480842147de53448350cdc46368e4cb\",\"title\":\"Novel Human Action Recognition in RGB-D Videos Based on Powerful View Invariant Features Technique\",\"url\":\"https://www.semanticscholar.org/paper/551259850480842147de53448350cdc46368e4cb\",\"venue\":\"ACIIDS\",\"year\":2018},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.06190\",\"authors\":[{\"authorId\":\"1403909323\",\"name\":\"Orestes Manzanilla-Salazar\"},{\"authorId\":\"1952232\",\"name\":\"B. Sans\\u00f2\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46340af956f7f58986674cfc72c094d63319cc82\",\"title\":\"Privacy-preserving classifiers recognize shared mobility behaviours from WiFi network imperfect data\",\"url\":\"https://www.semanticscholar.org/paper/46340af956f7f58986674cfc72c094d63319cc82\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35035828\",\"name\":\"A. Ulhaq\"}],\"doi\":\"10.1109/IPAS.2018.8708853\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff4ff29985a61bb9cfb29e4bd4e2cc28985601b8\",\"title\":\"Deep Cross-view Convolutional Features for View-invariant Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ff4ff29985a61bb9cfb29e4bd4e2cc28985601b8\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19188327\",\"name\":\"Nghia Pham Trong\"},{\"authorId\":\"50852670\",\"name\":\"Anh Truong Minh\"},{\"authorId\":\"29916690\",\"name\":\"H. Nguyen\"},{\"authorId\":\"30973841\",\"name\":\"Kotani Kazunori\"},{\"authorId\":\"31129589\",\"name\":\"Bac Le Hoai\"}],\"doi\":\"10.23919/SICE.2017.8105762\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ccfcfa30dd12b0164263c7b617d4350c2823c7\",\"title\":\"A survey about view-invariant human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8ccfcfa30dd12b0164263c7b617d4350c2823c7\",\"venue\":\"2017 56th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414148\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2836323\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ecc2e1284f1cb19cafe723b25be3705f26609679\",\"title\":\"Action Recognition From Arbitrary Views Using Transferable Dictionary Learning\",\"url\":\"https://www.semanticscholar.org/paper/ecc2e1284f1cb19cafe723b25be3705f26609679\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2656603\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/DICTA.2017.8227505\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"title\":\"Viewpoint Invariant RGB-D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623626\",\"name\":\"Chien-Quang Le\"},{\"authorId\":\"3080041\",\"name\":\"Thanh Duc Ngo\"},{\"authorId\":\"1802416\",\"name\":\"D. Le\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"2258974\",\"name\":\"D. Duong\"}],\"doi\":\"10.1007/978-3-319-29451-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f98c169dc78a2ea36fe817704232da72cd44a919\",\"title\":\"Cross-View Action Recognition by Projection-Based Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/f98c169dc78a2ea36fe817704232da72cd44a919\",\"venue\":\"PSIVT\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36304959\",\"name\":\"Sebastien Mambou\"},{\"authorId\":\"1755574\",\"name\":\"O. Krejcar\"},{\"authorId\":\"144733650\",\"name\":\"K. Ku\\u010da\"},{\"authorId\":\"1749862\",\"name\":\"A. Selamat\"}],\"doi\":\"10.3390/fi10090089\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9c34f28fa85f68e31c3d3fe9c58e80876700af1\",\"title\":\"Novel Cross-View Human Action Model Recognition Based on the Powerful View-Invariant Features Technique\",\"url\":\"https://www.semanticscholar.org/paper/c9c34f28fa85f68e31c3d3fe9c58e80876700af1\",\"venue\":\"Future Internet\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.3389/frobt.2015.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90a754f597958a2717862fbaa313f67b25083bf9\",\"title\":\"A Review of Human Activity Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/90a754f597958a2717862fbaa313f67b25083bf9\",\"venue\":\"Front. Robot. AI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144755330\",\"name\":\"Brian Reily\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ee4a540b3a2bbfe263573852d2a5f6231002145\",\"title\":\"Human activity recognition and gymnastics analysis through depth imagery\",\"url\":\"https://www.semanticscholar.org/paper/4ee4a540b3a2bbfe263573852d2a5f6231002145\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48641406\",\"name\":\"Shuang Liu\"}],\"doi\":\"10.1109/JIOT.2017.2707518\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"8a230022f6550d7e625006310b5f931158c10a67\",\"title\":\"Class-Constrained Transfer LDA for Cross-View Action Recognition in Internet of Things\",\"url\":\"https://www.semanticscholar.org/paper/8a230022f6550d7e625006310b5f931158c10a67\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2018},{\"arxivId\":\"1907.02499\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"738df423b2c6272a14196b9b6f37931f8867417f\",\"title\":\"Sim2real transfer learning for 3D pose estimation: motion to the rescue\",\"url\":\"https://www.semanticscholar.org/paper/738df423b2c6272a14196b9b6f37931f8867417f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.10681\",\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21029564f3072ab3ff2368069001ba7cb2bd6a3f\",\"title\":\"A Large-scale Varying-view RGB-D Action Dataset for Arbitrary-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21029564f3072ab3ff2368069001ba7cb2bd6a3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.07453\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/TPAMI.2019.2896631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58027f532153b9f9c6ad884d85a175862fc16e6\",\"title\":\"View Adaptive Neural Networks for High Performance Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a58027f532153b9f9c6ad884d85a175862fc16e6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1604.02808\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"title\":\"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34834493\",\"name\":\"Carolina Pacheco\"},{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"1491796980\",\"name\":\"Elena Kokkoni\"},{\"authorId\":\"1748908\",\"name\":\"H. Tanner\"},{\"authorId\":\"144187890\",\"name\":\"R. Vidal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"630351ebae61fce9d37baaeaf7e57797276d1fbf\",\"title\":\"A Detection-based Approach to Multiview Action Classification in Infants\",\"url\":\"https://www.semanticscholar.org/paper/630351ebae61fce9d37baaeaf7e57797276d1fbf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40565271\",\"name\":\"He Li\"},{\"authorId\":\"144705313\",\"name\":\"K. Ota\"},{\"authorId\":\"1714082\",\"name\":\"M. Dong\"},{\"authorId\":\"1697293\",\"name\":\"M. Guo\"}],\"doi\":\"10.1109/MCOM.2018.1700083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15cac24a9f1142a9c8c979d5d9693cbf47a3bea3\",\"title\":\"Learning Human Activities through Wi-Fi Channel State Information with Multiple Access Points\",\"url\":\"https://www.semanticscholar.org/paper/15cac24a9f1142a9c8c979d5d9693cbf47a3bea3\",\"venue\":\"IEEE Communications Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16077215\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"48570960\",\"name\":\"Lining Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2836323\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ef9280d59388c359abb1127297db2b255cceadf\",\"title\":\"Arbitrary view action recognition via transfer dictionary learning on synthetic training data\",\"url\":\"https://www.semanticscholar.org/paper/6ef9280d59388c359abb1127297db2b255cceadf\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":\"2003.07564\",\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":\"48986077\",\"name\":\"D. Yan\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"133839875\",\"name\":\"D. Li\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"24ea00bd9e737c7dd0d66f1e2706ad97841eb9c8\",\"title\":\"Feedback Graph Convolutional Network for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24ea00bd9e737c7dd0d66f1e2706ad97841eb9c8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"145327287\",\"name\":\"Y. Jing\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2020.107511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fa2bda10a3dd6d3662d2b63af4b27daabd876dd\",\"title\":\"Skeleton-based action recognition with hierarchical spatial reasoning and temporal stack learning network\",\"url\":\"https://www.semanticscholar.org/paper/7fa2bda10a3dd6d3662d2b63af4b27daabd876dd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"title\":\"View-Invariant Deep Architecture for Human Action Recognition Using Two-Stream Motion and Shape Temporal Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2017.2696786\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"fef87e55a090fe0f1ec5cdaf24c8a37e8174dfb7\",\"title\":\"Deeply Learned View-Invariant Features for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fef87e55a090fe0f1ec5cdaf24c8a37e8174dfb7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1707.00823\",\"authors\":[{\"authorId\":\"79993273\",\"name\":\"Jian Liu\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/s11263-019-01192-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"57ba391f7462d2f6b7957d30682670c7f833009d\",\"title\":\"Learning Human Pose Models from Synthesized Data for Robust RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57ba391f7462d2f6b7957d30682670c7f833009d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1964987\",\"name\":\"W. Li\"},{\"authorId\":\"6289742\",\"name\":\"Yahui Ding\"}],\"doi\":\"10.1145/3007669.3007702\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af3fb559aca925832b4d25a4feea732a4665753f\",\"title\":\"Human Action Recognition by Fusion of Convolutional Neural Networks and spatial-temporal Information\",\"url\":\"https://www.semanticscholar.org/paper/af3fb559aca925832b4d25a4feea732a4665753f\",\"venue\":\"ICIMCS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2603501\",\"name\":\"Wanchen Sui\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1016/j.neucom.2016.01.051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"378912704f9c73c103fcfb49d8ab75189afa5b13\",\"title\":\"Heterogeneous discriminant analysis for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/378912704f9c73c103fcfb49d8ab75189afa5b13\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144446381\",\"name\":\"Chengwu Liang\"},{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"145953637\",\"name\":\"L. Qi\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/ISM.2016.0058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e75c64bc251c6c6b7e2e70ef3bee024a6904b65b\",\"title\":\"3D Action Recognition Using Depth-Based Feature and Locality-Constrained Affine Subspace Coding\",\"url\":\"https://www.semanticscholar.org/paper/e75c64bc251c6c6b7e2e70ef3bee024a6904b65b\",\"venue\":\"2016 IEEE International Symposium on Multimedia (ISM)\",\"year\":2016},{\"arxivId\":\"1709.05087\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"3003408\",\"name\":\"Mian M. Ajmal\"}],\"doi\":\"10.1109/ACCESS.2018.2880231\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"title\":\"Viewpoint Invariant Action Recognition Using RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"}],\"doi\":\"10.32657/10356/69072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e175109d071cdc8a77f0887f14293a3f9e813563\",\"title\":\"Activity recognition in depth videos\",\"url\":\"https://www.semanticscholar.org/paper/e175109d071cdc8a77f0887f14293a3f9e813563\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1909.13245\",\"authors\":[{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"48570813\",\"name\":\"L. Zhang\"},{\"authorId\":\"49502400\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9775814d9454fb805e4f77ed357c6b237aec45e\",\"title\":\"Spatiotemporal Co-attention Recurrent Neural Networks for Human-Skeleton Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f9775814d9454fb805e4f77ed357c6b237aec45e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1607.07043\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-319-46487-9_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9afbd70a4727df98a0c38c437b94b14eba6577c4\",\"title\":\"Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9afbd70a4727df98a0c38c437b94b14eba6577c4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8824176\",\"name\":\"Y. Li\"},{\"authorId\":\"47158096\",\"name\":\"X. Xu\"},{\"authorId\":\"46372471\",\"name\":\"J. Xu\"},{\"authorId\":\"146596908\",\"name\":\"Enyu Du\"}],\"doi\":\"10.1117/1.JEI.28.3.033016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"195e9abc3ffa45d7424dfa660968d81b11e3f1f8\",\"title\":\"Bilayer model for cross-view human action recognition based on transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/195e9abc3ffa45d7424dfa660968d81b11e3f1f8\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772962\",\"name\":\"Emre Dogan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc5c9f5528b873bc53a33c33e79352787d60acab\",\"title\":\"Human pose estimation and action recognition by multi-robot systems\",\"url\":\"https://www.semanticscholar.org/paper/dc5c9f5528b873bc53a33c33e79352787d60acab\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1610.09334\",\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/WACV.2017.25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7fe851e1acc8a974697fb74d913736a3a849003\",\"title\":\"Real-Time Online Action Detection Forests Using Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/c7fe851e1acc8a974697fb74d913736a3a849003\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1602.00828\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2017.2691768\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"e777c6a5f57e51d77b78d8eb04184a71951bd8e8\",\"title\":\"Learning a Deep Model for Human Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/e777c6a5f57e51d77b78d8eb04184a71951bd8e8\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1901.00488\",\"authors\":[{\"authorId\":\"46220439\",\"name\":\"Jianzhu Guo\"},{\"authorId\":\"8362374\",\"name\":\"Xiangyu Zhu\"},{\"authorId\":\"66358681\",\"name\":\"Jinchuan Xiao\"},{\"authorId\":\"145754448\",\"name\":\"Z. Lei\"},{\"authorId\":\"40366147\",\"name\":\"G. Wan\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/ICB45273.2019.8987415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e094f61a8d957000999dc03d0637df47bd05fe1a\",\"title\":\"Improving Face Anti-Spoofing by 3D Virtual Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/e094f61a8d957000999dc03d0637df47bd05fe1a\",\"venue\":\"2019 International Conference on Biometrics (ICB)\",\"year\":2019},{\"arxivId\":\"2007.03056\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1007/978-3-030-58545-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"title\":\"VPN: Learning Video-Pose Embedding for Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1007/978-3-030-00734-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1df703e236bbc36857fcec85da748c8a96c4380d\",\"title\":\"Deep Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/1df703e236bbc36857fcec85da748c8a96c4380d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50759119\",\"name\":\"W. Ding\"},{\"authorId\":\"49599759\",\"name\":\"Kai Liu\"},{\"authorId\":\"144717380\",\"name\":\"E. Belyaev\"},{\"authorId\":\"47900774\",\"name\":\"Fei Cheng\"}],\"doi\":\"10.1016/j.patcog.2017.12.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25a784695e5b0e33d3de81b09fbaf9d8500f9bac\",\"title\":\"Tensor-based linear dynamical systems for action recognition from 3D skeletons\",\"url\":\"https://www.semanticscholar.org/paper/25a784695e5b0e33d3de81b09fbaf9d8500f9bac\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1603.07120\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2691321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"title\":\"Deep Multimodal Feature Analysis for Action Recognition in RGB+D Videos\",\"url\":\"https://www.semanticscholar.org/paper/a0d8ebbc8d0f576cd1eeeca93944522fb2c2b1b9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"40245471\",\"name\":\"Haibo Wang\"},{\"authorId\":\"48513221\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1177/1729881417709079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c8992f255e06081a2e651e370ffe42589143b70\",\"title\":\"Collecting public RGB-D datasets for human daily activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/0c8992f255e06081a2e651e370ffe42589143b70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"}],\"doi\":\"10.1109/cvpr42600.2020.00020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"646a256e30cd244b668660c32b529ff31a874a78\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/646a256e30cd244b668660c32b529ff31a874a78\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/WACV45572.2020.9093575\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cdc241f90d578a1dd79db11081f291211986ac9\",\"title\":\"Looking deeper into Time for Activities of Daily Living Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc241f90d578a1dd79db11081f291211986ac9\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-3-030-01240-3_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2003d6e1de789b7fe60819257d8dfd54d267517\",\"title\":\"Dividing and Aggregating Network for Multi-view Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2003d6e1de789b7fe60819257d8dfd54d267517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30065390\",\"name\":\"Manh-Quan Bui\"},{\"authorId\":\"2345136\",\"name\":\"V. Duong\"},{\"authorId\":\"4604855\",\"name\":\"Tzu-Chiang Tai\"},{\"authorId\":\"3205648\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICIP.2018.8451232\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa41626f52e9940dfe839ec9ceff2ae72ec5fdf7\",\"title\":\"Depth Human Action Recognition Based on Convolution Neural Networks and Principal Component Analysis\",\"url\":\"https://www.semanticscholar.org/paper/aa41626f52e9940dfe839ec9ceff2ae72ec5fdf7\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1912.03632\",\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41d621492203f42a52317163b4091670a360324b\",\"title\":\"View-invariant Deep Architecture for Human Action Recognition using late fusion\",\"url\":\"https://www.semanticscholar.org/paper/41d621492203f42a52317163b4091670a360324b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1145/3240508.3240675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f888a870545af2735118bbd6358ffa68f1e386f\",\"title\":\"A Large-scale RGB-D Database for Arbitrary-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f888a870545af2735118bbd6358ffa68f1e386f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1702.08652\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"35061362\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/CVPR.2017.52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"title\":\"Scene Flow to Action Map: A New Representation for RGB-D Based Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2956458\",\"name\":\"Chenfanfu Jiang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"1713084\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"49719480\",\"name\":\"Jenny Lin\"},{\"authorId\":\"37397820\",\"name\":\"Lap-Fai Yu\"},{\"authorId\":\"1750924\",\"name\":\"Demetri Terzopoulos\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/s11263-018-1103-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d24ff1cde1673ba1ecb4890dd7eeaa85d464221c\",\"title\":\"Configurable 3D Scene Synthesis and 2D Image Rendering with Per-pixel Ground Truth Using Stochastic Grammars\",\"url\":\"https://www.semanticscholar.org/paper/d24ff1cde1673ba1ecb4890dd7eeaa85d464221c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2017.2758199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7df08c6c13002a2031334bba64674c272e525b15\",\"title\":\"Deep Domain Generalization With Structured Low-Rank Constraint\",\"url\":\"https://www.semanticscholar.org/paper/7df08c6c13002a2031334bba64674c272e525b15\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1897232\",\"name\":\"Q. Nie\"},{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"40066725\",\"name\":\"X. Wang\"},{\"authorId\":\"46398631\",\"name\":\"Yunhui Liu\"}],\"doi\":\"10.1109/TIP.2019.2907048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fbe869403b2d1b781843df663563c416322a062\",\"title\":\"View-Invariant Human Action Recognition Based on a 3D Bio-Constrained Skeleton Model\",\"url\":\"https://www.semanticscholar.org/paper/4fbe869403b2d1b781843df663563c416322a062\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2603501\",\"name\":\"Wanchen Sui\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"16208828\",\"name\":\"Wei Liang\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1007/978-3-319-26561-2_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbddc6e190cde0c5ae34555ce1fdd2b9342881c4\",\"title\":\"Heterogeneous Discriminant Analysis for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbddc6e190cde0c5ae34555ce1fdd2b9342881c4\",\"venue\":\"ICONIP\",\"year\":2015},{\"arxivId\":\"1805.04497\",\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/CVPR.2018.00869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"245138dfd9229ec4f737313267f2619f1902142e\",\"title\":\"Augmented Skeleton Space Transfer for Depth-Based Hand Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/245138dfd9229ec4f737313267f2619f1902142e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"38905965\",\"name\":\"Arpit Chaudhary\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1109/WACV.2019.00015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"title\":\"Where to Focus on for Human Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49538681\",\"name\":\"Z. Gao\"},{\"authorId\":\"47319814\",\"name\":\"S. Li\"},{\"authorId\":\"145040307\",\"name\":\"Y. Zhu\"},{\"authorId\":\"39631916\",\"name\":\"C. Wang\"},{\"authorId\":\"1682921\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/j.jvcir.2017.03.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3478bde28fdc1b208c513ba6bd2fe42a18432c29\",\"title\":\"Collaborative sparse representation leaning model for RGBD action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3478bde28fdc1b208c513ba6bd2fe42a18432c29\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144446381\",\"name\":\"Chengwu Liang\"},{\"authorId\":\"145953636\",\"name\":\"L. Qi\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/TCSVT.2017.2715045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69c9dad10330acad235b579104313d6cb7ea6595\",\"title\":\"3D Human Action Recognition Using a Single Depth Feature and Locality-Constrained Affine Subspace Coding\",\"url\":\"https://www.semanticscholar.org/paper/69c9dad10330acad235b579104313d6cb7ea6595\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144446381\",\"name\":\"Chengwu Liang\"},{\"authorId\":\"3338217\",\"name\":\"D. Liu\"},{\"authorId\":\"145953629\",\"name\":\"L. Qi\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/ACCESS.2020.2976496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44fba089ca3149ed30967e200aff77cb4d4892bf\",\"title\":\"Multi-Modal Human Action Recognition With Sub-Action Exploiting and Class-Privacy Preserved Collaborative Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/44fba089ca3149ed30967e200aff77cb4d4892bf\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145052381\",\"name\":\"A. Gupta\"}],\"doi\":\"10.14288/1.0305862\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e0a864793a45be2a105a252322453abbb5e1148\",\"title\":\"Using unlabeled 3D motion examples for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/9e0a864793a45be2a105a252322453abbb5e1148\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2001.09691\",\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00461\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10cf610ca725cdf459f6a4fa68999066b586b93a\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10cf610ca725cdf459f6a4fa68999066b586b93a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2475715\",\"name\":\"Chengkun Zhang\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"}],\"doi\":\"10.1117/1.JEI.27.4.043044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec5dfae45af33f32bd784fc172f4d42dc78bf6ba\",\"title\":\"Dual-codebook learning and hierarchical transfer for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec5dfae45af33f32bd784fc172f4d42dc78bf6ba\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/ICCV.2017.621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcefb761034daeef1e735cf0a1787bc379ae0673\",\"title\":\"Learning Action Recognition Model from Depth and Skeleton Videos\",\"url\":\"https://www.semanticscholar.org/paper/bcefb761034daeef1e735cf0a1787bc379ae0673\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1601.01006\",\"authors\":[{\"authorId\":\"144845024\",\"name\":\"Fei Han\"},{\"authorId\":\"144755330\",\"name\":\"Brian Reily\"},{\"authorId\":\"143790090\",\"name\":\"W. Hoff\"},{\"authorId\":\"38952862\",\"name\":\"Hao Zhang\"}],\"doi\":\"10.1016/j.cviu.2017.01.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7385f998caf17b2c6ae9f8808b6fd3a05205b438\",\"title\":\"Space-Time Representation of People Based on 3D Skeletal Data: A Review\",\"url\":\"https://www.semanticscholar.org/paper/7385f998caf17b2c6ae9f8808b6fd3a05205b438\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Han Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1049/iet-cvi.2016.0148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc7e6c4760efa93d52273b1a46aaccc76a1f2777\",\"title\":\"Heterogeneous domain adaptation method for video annotation\",\"url\":\"https://www.semanticscholar.org/paper/dc7e6c4760efa93d52273b1a46aaccc76a1f2777\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"1904.01698\",\"authors\":[{\"authorId\":\"46397014\",\"name\":\"X. Xie\"},{\"authorId\":\"3440176\",\"name\":\"H. Liu\"},{\"authorId\":\"2468581\",\"name\":\"Zhenliang Zhang\"},{\"authorId\":\"16461261\",\"name\":\"Yuxing Qiu\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1145/3321408.3322633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c937950ba2ed49cf51fe9656a1f4fd91d16431b\",\"title\":\"VRGym: a virtual testbed for physical and interactive AI\",\"url\":\"https://www.semanticscholar.org/paper/4c937950ba2ed49cf51fe9656a1f4fd91d16431b\",\"venue\":\"ACM TUR-C\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"1814260\",\"name\":\"Enjie Ghorbel\"},{\"authorId\":\"144561549\",\"name\":\"K. Papadopoulos\"},{\"authorId\":\"2878772\",\"name\":\"Girum G. Demisse\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.1109/ICASSP.2019.8682904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c37f1d439fcf4a22c20b384a31d7b754961df8b\",\"title\":\"View-invariant Action Recognition from RGB Data via 3D Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/5c37f1d439fcf4a22c20b384a31d7b754961df8b\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"title\":\"Action Recognition in Multi-view Videos\",\"url\":\"https://www.semanticscholar.org/paper/ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27687205\",\"name\":\"N. Efthymiou\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"30192180\",\"name\":\"P. P. Filntisis\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2018.8451146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b56a568799a0dee06587d8ab54032f7bf7712008\",\"title\":\"Multi- View Fusion for Action Recognition in Child-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/b56a568799a0dee06587d8ab54032f7bf7712008\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1802.07898\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CVPR.2018.00056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab45ab887b7c1379bba4179579568296448d16d6\",\"title\":\"Glimpse Clouds: Human Activity Recognition from Unstructured Feature Points\",\"url\":\"https://www.semanticscholar.org/paper/ab45ab887b7c1379bba4179579568296448d16d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.05941\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b11d14c5812e5f41348beebceaca84b46cc55346\",\"title\":\"Skepxels: Spatio-temporal Image Representation of Human Skeleton Joints for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b11d14c5812e5f41348beebceaca84b46cc55346\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1605.04988\",\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.imavis.2017.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"title\":\"Going deeper into action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3206025.3206041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"title\":\"Recognizing Actions in Wearable-Camera Videos by Training Classifiers on Fixed-Camera Videos\",\"url\":\"https://www.semanticscholar.org/paper/b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772962\",\"name\":\"Emre Dogan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fe41a944a16c744f64d4686b6e9296290550ed5\",\"title\":\"Estimation de pose humaine et reconnaissance d'action par un syst\\u00e8me multi-robots. (Human pose estimation and action recognition by multi-robot systems)\",\"url\":\"https://www.semanticscholar.org/paper/5fe41a944a16c744f64d4686b6e9296290550ed5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"Dinesh Kumar Vishwakarma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"title\":\"A Robust Framework for Abnormal Human Action Recognition Using <inline-formula> <tex-math notation=\\\"LaTeX\\\">$\\\\boldsymbol{\\\\mathcal{R}}$ </tex-math></inline-formula>-Transform and Zernike Moments in Depth Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"39271955\",\"name\":\"Zhiwen Fang\"}],\"doi\":\"10.1117/12.2285518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"title\":\"Action recognition in depth video from RGB perspective: A knowledge transfer manner\",\"url\":\"https://www.semanticscholar.org/paper/e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"1452347342\",\"name\":\"M. Saxena\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/BigMM.2019.00-21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea36c13fd2ae92c8f5ef27d985f074b9e93e62e0\",\"title\":\"Skeleton-Based View Invariant Deep Features for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea36c13fd2ae92c8f5ef27d985f074b9e93e62e0\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33347316\",\"name\":\"Tommi Kerola\"},{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1016/j.cviu.2016.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba742e934393efdcca68f81e759f87c6c6f81961\",\"title\":\"Cross-view human action recognition from depth maps using spectral graph sequences\",\"url\":\"https://www.semanticscholar.org/paper/ba742e934393efdcca68f81e759f87c6c6f81961\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48260254\",\"name\":\"Yan Feng\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"}],\"doi\":\"10.4108/eai.21-6-2018.2276579\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d22f51b5b925fb4b524b62beac45ef4f70bdbc6\",\"title\":\"Spatio-Temporal and View Attention Deep Network for Skeleton based View-invariant Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d22f51b5b925fb4b524b62beac45ef4f70bdbc6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.11091\",\"authors\":[{\"authorId\":\"1491169373\",\"name\":\"Mohamad Ballout\"},{\"authorId\":\"1381681564\",\"name\":\"Mohammad Tuqan\"},{\"authorId\":\"1790873\",\"name\":\"Daniel C. Asmar\"},{\"authorId\":\"48810394\",\"name\":\"Elie Shammas\"},{\"authorId\":\"1768700\",\"name\":\"George E. Sakr\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"title\":\"The benefits of synthetic data for action categorization\",\"url\":\"https://www.semanticscholar.org/paper/7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/JSEN.2019.2903645\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"title\":\"A Robust Framework for Abnormal Human Action Recognition Using $\\\\boldsymbol{\\\\mathcal{R}}$ -Transform and Zernike Moments in Depth Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d7b4deda08145ac8c88b49a3efddc4978501ba6\",\"venue\":\"IEEE Sensors Journal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"103483753\",\"name\":\"Yu-Hung Liu\"},{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"48458229\",\"name\":\"Zi-Jun Li\"},{\"authorId\":\"144906905\",\"name\":\"L. Fu\"}],\"doi\":\"10.1007/978-3-030-20890-5_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ed166936ad0602df83b6a4a008140f20545e35a\",\"title\":\"Cross-View Action Recognition Using View-Invariant Pose Feature Learned from Synthetic Data with Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/7ed166936ad0602df83b6a4a008140f20545e35a\",\"venue\":\"ACCV\",\"year\":2018}],\"corpusId\":9118111,\"doi\":\"10.1109/CVPR.2015.7298860\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"641f3b3cf91e11f77210447fe67375fdf350e983\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z Lin\"},{\"authorId\":null,\"name\":\"Z Jiang\"},{\"authorId\":null,\"name\":\"L Davis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Recognizing actions by shapemotion prototype trees\",\"url\":\"\",\"venue\":\"ICCV\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Yilmaz\"},{\"authorId\":null,\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Action sketch: a novel action rep\\u00ad resentation\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"2898850\",\"name\":\"R\\u00e9mi Ronfard\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"}],\"doi\":\"10.1016/j.cviu.2006.07.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f81eb3ea2d96629b220993151625419f79cf656a\",\"title\":\"Free viewpoint action recognition using motion history volumes\",\"url\":\"https://www.semanticscholar.org/paper/f81eb3ea2d96629b220993151625419f79cf656a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Lawrence\"},{\"authorId\":null,\"name\":\"C L Giles\"},{\"authorId\":null,\"name\":\"A C Tsoi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"What size neural network gives optimal generalization? convergence proper\\u00ad ties of backpropagation Camps, and M. Sznaier. Cross-view activity recog\\u00ad nition using hankelets\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2012},{\"arxivId\":\"1408.3809\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/978-3-319-10605-2_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e129ee3aaca9c9c2ddd7365c5ce09fd6017d2a36\",\"title\":\"HOPC: Histogram of Oriented Principal Components of 3D Pointclouds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e129ee3aaca9c9c2ddd7365c5ce09fd6017d2a36\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Parameswaran\"},{\"authorId\":null,\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"View invariance for hu\\u00ad man action recognition\",\"url\":\"\",\"venue\":\"In llCV,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"144994682\",\"name\":\"A. Pentland\"}],\"doi\":\"10.1109/34.546259\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67852293a05e4e9da899e99ba109a81b2af7fca4\",\"title\":\"Task-Specific Gesture Analysis in Real-Time Using Interpolated Views\",\"url\":\"https://www.semanticscholar.org/paper/67852293a05e4e9da899e99ba109a81b2af7fca4\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840115\",\"name\":\"S. Lawrence\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"},{\"authorId\":\"1733691\",\"name\":\"A. Tsoi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2893d64bb2ad5fb4cf69ee63f8de3abb7906481c\",\"title\":\"What Size Neural Network Gives Optimal Generalization? Convergence Properties of Backpropagation\",\"url\":\"https://www.semanticscholar.org/paper/2893d64bb2ad5fb4cf69ee63f8de3abb7906481c\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33458360\",\"name\":\"R. Li\"},{\"authorId\":\"1713451\",\"name\":\"Todd E. Zickler\"}],\"doi\":\"10.1109/CVPR.2012.6248011\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0aa318aea7fdd011167e22baed3c7be2a6e3dd0d\",\"title\":\"Discriminative virtual views for cross-view action recognition\",\"url\":\"https://www.semanticscholar.org/paper/0aa318aea7fdd011167e22baed3c7be2a6e3dd0d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37335907\",\"name\":\"G. Willems\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-540-88688-4_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"title\":\"An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector\",\"url\":\"https://www.semanticscholar.org/paper/117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14933480\",\"name\":\"V. Parameswaran\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/s11263-005-3671-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b549d86bd129d3d8e5822dcd244b75b891516673\",\"title\":\"View Invariance for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b549d86bd129d3d8e5822dcd244b75b891516673\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144647868\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1683416\",\"name\":\"Chunheng Wang\"},{\"authorId\":\"2658590\",\"name\":\"B. Xiao\"},{\"authorId\":\"145387913\",\"name\":\"W. Zhou\"},{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"1959339\",\"name\":\"C. Shi\"}],\"doi\":\"10.1109/CVPR.2013.347\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2023bbd150d4134acc54214ee87b8492f4232ae1\",\"title\":\"Cross-View Action Recognition via a Continuous Virtual Path\",\"url\":\"https://www.semanticscholar.org/paper/2023bbd150d4134acc54214ee87b8492f4232ae1\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144854796\",\"name\":\"D. Gavrila\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.1996.517056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc9b263c1af95ea803c4f5c8888ef8e37f0cef80\",\"title\":\"3-D model-based tracking of humans in action: a multi-view approach\",\"url\":\"https://www.semanticscholar.org/paper/cc9b263c1af95ea803c4f5c8888ef8e37f0cef80\",\"venue\":\"Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"2898850\",\"name\":\"R\\u00e9mi Ronfard\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"}],\"doi\":\"10.1016/j.cviu.2010.10.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"678b758cb1a057fd38d8e6808535f64686bfca71\",\"title\":\"A survey of vision-based methods for action representation, segmentation and recognition\",\"url\":\"https://www.semanticscholar.org/paper/678b758cb1a057fd38d8e6808535f64686bfca71\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145052381\",\"name\":\"A. Gupta\"},{\"authorId\":\"1718163\",\"name\":\"Alireza Shafaei\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"},{\"authorId\":\"1688682\",\"name\":\"R. Woodham\"}],\"doi\":\"10.5244/C.28.46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e625717377ee8c2e969df5a1a8cfe3332ebc1df4\",\"title\":\"Unlabelled 3D Motion Examples Improve Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e625717377ee8c2e969df5a1a8cfe3332ebc1df4\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1007/978-3-642-35289-8_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e95d3934e51107da7610acd0b1bcb6551671f9f1\",\"title\":\"A Practical Guide to Training Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/e95d3934e51107da7610acd0b1bcb6551671f9f1\",\"venue\":\"Neural Networks: Tricks of the Trade\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2009.5459184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5894aca916753fabd97cda127e8f9ce230c3fb61\",\"title\":\"Recognizing actions by shape-motion prototype trees\",\"url\":\"https://www.semanticscholar.org/paper/5894aca916753fabd97cda127e8f9ce230c3fb61\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750163\",\"name\":\"B. Li\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":\"10.1109/CVPR.2012.6247822\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"46d2f1a6393c99da2997f35ff8d3860ee44f4b6d\",\"title\":\"Cross-view activity recognition using Hankelets\",\"url\":\"https://www.semanticscholar.org/paper/46d2f1a6393c99da2997f35ff8d3860ee44f4b6d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"CMU Motion Capture Database\",\"url\":\"\",\"venue\":\"CMU Motion Capture Database\",\"year\":null},{\"arxivId\":\"1206.5533\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1007/978-3-642-35289-8_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"522e90b9fccfd3c1c0603359eb04757d770c1ab5\",\"title\":\"Practical Recommendations for Gradient-Based Training of Deep Architectures\",\"url\":\"https://www.semanticscholar.org/paper/522e90b9fccfd3c1c0603359eb04757d770c1ab5\",\"venue\":\"Neural Networks: Tricks of the Trade\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Wang\"},{\"authorId\":null,\"name\":\"A. KIser\"},{\"authorId\":null,\"name\":\"C. Schmid\"},{\"authorId\":null,\"name\":\"C. Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Action recogni\\u00ad tion by dense trajectories\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Katz\"},{\"authorId\":null,\"name\":\"A Tal\"},{\"authorId\":null,\"name\":\"R Basri\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Direct visibility of point sets 3, 8 I. Laptev. On space-time interest point\",\"url\":\"\",\"venue\":\"TOG IJCV\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3130645\",\"name\":\"Mostafa Kamali Tabrizi\"}],\"doi\":\"10.1007/978-3-540-88682-2_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af50372a852edfc12c8273fdaeb106dfca72ea04\",\"title\":\"Learning to Recognize Activities from the Wrong View Point\",\"url\":\"https://www.semanticscholar.org/paper/af50372a852edfc12c8273fdaeb106dfca72ea04\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33692583\",\"name\":\"Raghuraman Gopalan\"},{\"authorId\":\"33458360\",\"name\":\"R. Li\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/ICCV.2011.6126344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3edbfee56884d2b6d9aa51a6c525f9a05248802\",\"title\":\"Domain adaptation for object recognition: An unsupervised approach\",\"url\":\"https://www.semanticscholar.org/paper/d3edbfee56884d2b6d9aa51a6c525f9a05248802\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"},{\"authorId\":\"2898850\",\"name\":\"R\\u00e9mi Ronfard\"}],\"doi\":\"10.1109/ICCV.2007.4408849\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deb259adece9095000a79f86aabfb303580be1cd\",\"title\":\"Action Recognition from Arbitrary Views using 3D Exemplars\",\"url\":\"https://www.semanticscholar.org/paper/deb259adece9095000a79f86aabfb303580be1cd\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/WACV.2014.6836044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"642d8fdfd004d02134eefe61015656b18a3939ed\",\"title\":\"Real time action recognition using histograms of depth gradients and random decision forests\",\"url\":\"https://www.semanticscholar.org/paper/642d8fdfd004d02134eefe61015656b18a3939ed\",\"venue\":\"IEEE Winter Conference on Applications of Computer Vision\",\"year\":2014},{\"arxivId\":\"1405.2941\",\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"49289914\",\"name\":\"Y. Xia\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2014.339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5de214630011554bd07b41ec5bd493c7f65c532e\",\"title\":\"Cross-View Action Modeling, Learning, and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5de214630011554bd07b41ec5bd493c7f65c532e\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I Laptev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"On space-time interest point\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3130645\",\"name\":\"Mostafa Kamali Tabrizi\"},{\"authorId\":\"2831988\",\"name\":\"Ian Endres\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/ICCV.2009.5459350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e8360dacff1e0f37d5815c5406a6c05cc24b766\",\"title\":\"A latent model of discriminative aspect\",\"url\":\"https://www.semanticscholar.org/paper/5e8360dacff1e0f37d5815c5406a6c05cc24b766\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"}],\"doi\":\"10.1162/neco.2006.18.7.1527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8978cf7574ceb35f4c3096be768c7547b28a35d0\",\"title\":\"A Fast Learning Algorithm for Deep Belief Nets\",\"url\":\"https://www.semanticscholar.org/paper/8978cf7574ceb35f4c3096be768c7547b28a35d0\",\"venue\":\"Neural Computation\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145206607\",\"name\":\"C. Rao\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1023/A:1020350100748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1128c0cd1e504d555c57cb39cdd7b6be399eb5a7\",\"title\":\"View-Invariant Representation and Recognition of Actions\",\"url\":\"https://www.semanticscholar.org/paper/1128c0cd1e504d555c57cb39cdd7b6be399eb5a7\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":\"1408.3810\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/ICPR.2014.604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d08d999232199d7720a258d4864508975ed33681\",\"title\":\"Action Classification with Locality-Constrained Linear Coding\",\"url\":\"https://www.semanticscholar.org/paper/d08d999232199d7720a258d4864508975ed33681\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539228\",\"name\":\"S. Wu\"},{\"authorId\":\"2405613\",\"name\":\"Omar Oreifej\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2011.6126397\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac02a6c37a7913194496a914461caedd49febdc9\",\"title\":\"Action recognition in videos acquired by a moving camera using motion decomposition of Lagrangian particle trajectories\",\"url\":\"https://www.semanticscholar.org/paper/ac02a6c37a7913194496a914461caedd49febdc9\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145052381\",\"name\":\"A. Gupta\"},{\"authorId\":\"144442429\",\"name\":\"J. Martinez\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"},{\"authorId\":\"1688682\",\"name\":\"R. Woodham\"}],\"doi\":\"10.1109/CVPR.2014.333\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"504002dbd2de78f8d55c860a76a6ee322eb816a8\",\"title\":\"3D Pose from Motion for Cross-View Action Recognition via Non-linear Circulant Temporal Encoding\",\"url\":\"https://www.semanticscholar.org/paper/504002dbd2de78f8d55c860a76a6ee322eb816a8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2005.58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"487c37dce9b93d48f753ab2ec3fc997edb5639ce\",\"title\":\"Actions sketch: a novel action representation\",\"url\":\"https://www.semanticscholar.org/paper/487c37dce9b93d48f753ab2ec3fc997edb5639ce\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39157653\",\"name\":\"Fengjun Lv\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2007.383131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11969c1831902535c288145242eef40d6a66df04\",\"title\":\"Single View Human Action Recognition using Key Pose Matching and Viterbi Path Searching\",\"url\":\"https://www.semanticscholar.org/paper/11969c1831902535c288145242eef40d6a66df04\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1809614\",\"name\":\"Y. Song\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1016/j.patcog.2008.05.016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f19ab33e91c59f5e5f42c6c2d40dca84e799b9b9\",\"title\":\"Contour graph based human tracking and action sequence recognition\",\"url\":\"https://www.semanticscholar.org/paper/f19ab33e91c59f5e5f42c6c2d40dca84e799b9b9\",\"venue\":\"Pattern Recognit.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50021324\",\"name\":\"Jingjing Zheng\"},{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"}],\"doi\":\"10.1109/ICCV.2013.394\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df82925a7b2af2791825085d10972dd940ed59f3\",\"title\":\"Learning View-Invariant Sparse Representations for Cross-View Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df82925a7b2af2791825085d10972dd940ed59f3\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"},{\"authorId\":\"145585296\",\"name\":\"B. Kuipers\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/CVPR.2011.5995729\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5de73a9334fc34873030be8bab2be21fc8ddae69\",\"title\":\"Cross-view action recognition via view knowledge transfer\",\"url\":\"https://www.semanticscholar.org/paper/5de73a9334fc34873030be8bab2be21fc8ddae69\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2393145\",\"name\":\"S. Katz\"},{\"authorId\":\"3226509\",\"name\":\"A. Tal\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1145/1276377.1276407\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40e79c09c77cf2ce8150e376e995bb4173583104\",\"title\":\"Direct visibility of point sets\",\"url\":\"https://www.semanticscholar.org/paper/40e79c09c77cf2ce8150e376e995bb4173583104\",\"venue\":\"SIGGRAPH 2007\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011}],\"title\":\"Learning a non-linear knowledge transfer model for cross-view action recognition\",\"topics\":[{\"topic\":\"Codebook\",\"topicId\":\"14141\",\"url\":\"https://www.semanticscholar.org/topic/14141\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"},{\"topic\":\"Motion capture\",\"topicId\":\"76471\",\"url\":\"https://www.semanticscholar.org/topic/76471\"},{\"topic\":\"Nonlinear system\",\"topicId\":\"5329\",\"url\":\"https://www.semanticscholar.org/topic/5329\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"},{\"topic\":\"K-means clustering\",\"topicId\":\"130\",\"url\":\"https://www.semanticscholar.org/topic/130\"},{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"Pattern recognition\",\"topicId\":\"237\",\"url\":\"https://www.semanticscholar.org/topic/237\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Viewing angle\",\"topicId\":\"21724\",\"url\":\"https://www.semanticscholar.org/topic/21724\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Linear model\",\"topicId\":\"41514\",\"url\":\"https://www.semanticscholar.org/topic/41514\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"},{\"topic\":\"Synthetic intelligence\",\"topicId\":\"1588157\",\"url\":\"https://www.semanticscholar.org/topic/1588157\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"}],\"url\":\"https://www.semanticscholar.org/paper/641f3b3cf91e11f77210447fe67375fdf350e983\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"