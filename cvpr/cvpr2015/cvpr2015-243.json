"{\"abstract\":\"With the proliferation of wearable cameras, the number of videos of users documenting their personal lives using such devices is rapidly increasing. Since such videos may span hours, there is an important need for mechanisms that represent the information content in a compact form (i.e., shorter videos which are more easily browsable/sharable). Motivated by these applications, this paper focuses on the problem of egocentric video summarization. Such videos are usually continuous with significant camera shake and other quality issues. Because of these reasons, there is growing consensus that direct application of standard video summarization tools to such data yields unsatisfactory performance. In this paper, we demonstrate that using gaze tracking information (such as fixation and saccade) significantly helps the summarization task. It allows meaningful comparison of different image frames and enables deriving personalized summaries (gaze provides a sense of the camera wearer's intent). We formulate a summarization model which captures common-sense properties of a good summary, and show that it can be solved as a submodular function maximization with partition matroid constraints, opening the door to a rich body of work from combinatorial optimization. We evaluate our approach on a new gaze-enabled egocentric video dataset (over 15 hours), which will be a valuable standalone resource.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\",\"url\":\"https://www.semanticscholar.org/author/119858851\"},{\"authorId\":\"144324490\",\"name\":\"Lopamudra Mukherjee\",\"url\":\"https://www.semanticscholar.org/author/144324490\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\",\"url\":\"https://www.semanticscholar.org/author/1738814\"},{\"authorId\":\"40450406\",\"name\":\"J. Warner\",\"url\":\"https://www.semanticscholar.org/author/40450406\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\",\"url\":\"https://www.semanticscholar.org/author/144177248\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\",\"url\":\"https://www.semanticscholar.org/author/144711711\"}],\"citationVelocity\":24,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144221742\",\"name\":\"Yifang Yin\"},{\"authorId\":\"3417919\",\"name\":\"R. Thapliya\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.1109/TCSVT.2016.2602832\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1effbb26b34a468154efe42f89175f84fc3c901\",\"title\":\"Encoded Semantic Tree for Automatic User Profiling Applied to Personalized Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/f1effbb26b34a468154efe42f89175f84fc3c901\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476813805\",\"name\":\"M. Al-Naser\"},{\"authorId\":\"29005173\",\"name\":\"S. Siddiqui\"},{\"authorId\":\"151425311\",\"name\":\"Hiroki Ohashi\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1476817066\",\"name\":\"Nakamura Katsuyki\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1109/DICTA47822.2019.8945893\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"title\":\"OGaze: Gaze Prediction in Egocentric Videos for Attentional Object Selection\",\"url\":\"https://www.semanticscholar.org/paper/697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"}],\"doi\":\"10.1145/2964284.2971474\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5154ea0d4f43c387b34d250e904b4a40a6ba2207\",\"title\":\"First Person View Video Summarization Subject to the User Needs\",\"url\":\"https://www.semanticscholar.org/paper/5154ea0d4f43c387b34d250e904b4a40a6ba2207\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-319-46475-6_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2defb7ca6d4a0cfa6e5c39487c84650667aaaef5\",\"title\":\"Visual Motif Discovery via First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/2defb7ca6d4a0cfa6e5c39487c84650667aaaef5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145328424\",\"name\":\"M. Paul\"},{\"authorId\":\"134441577\",\"name\":\"Md. Musfequs Salehin\"}],\"doi\":\"10.1109/TCSVT.2018.2844780\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9b853385f045b0e24e40b279b2a637f17b0d0ae\",\"title\":\"Spatial and Motion Saliency Prediction Method Using Eye Tracker Data for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/a9b853385f045b0e24e40b279b2a637f17b0d0ae\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581863540\",\"name\":\"Aidean Sharghi Karganroodi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"550b08b659d3b8e7f45bdc09602af2184791d082\",\"title\":\"Visual-Textual Video Synopsis Generation\",\"url\":\"https://www.semanticscholar.org/paper/550b08b659d3b8e7f45bdc09602af2184791d082\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"48947242\",\"name\":\"Fang Jiao\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1016/j.neucom.2020.04.132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e824b1cdd3e227933f18e7ebf54c4fa3cbcc2534\",\"title\":\"Deep attentive and semantic preserving video summarization\",\"url\":\"https://www.semanticscholar.org/paper/e824b1cdd3e227933f18e7ebf54c4fa3cbcc2534\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380729056\",\"name\":\"Anuj Rathore\"},{\"authorId\":\"9361887\",\"name\":\"Pravin Nagar\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"},{\"authorId\":\"1380374163\",\"name\":\"C.V. Jawahar\"}],\"doi\":\"10.1145/3343031.3350880\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b844e3eb550758d907c44729279760e4f981a6a\",\"title\":\"Generating 1 Minute Summaries of Day Long Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/4b844e3eb550758d907c44729279760e4f981a6a\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1109/TIP.2016.2601147\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f21e314934cdbdda9dc1bce1986bf5aa24b8f42a\",\"title\":\"Ranking Highlights in Personal Videos by Analyzing Edited Videos\",\"url\":\"https://www.semanticscholar.org/paper/f21e314934cdbdda9dc1bce1986bf5aa24b8f42a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"}],\"doi\":\"10.1007/978-3-030-58520-4_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8a596261cfd846538811edf7db7d5f754b1159\",\"title\":\"Is Sharing of Egocentric Video Giving Away Your Biometric Signature?\",\"url\":\"https://www.semanticscholar.org/paper/5e8a596261cfd846538811edf7db7d5f754b1159\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22611622\",\"name\":\"Samriddhi Jain\"},{\"authorId\":\"1697162\",\"name\":\"Renu M. Rameshan\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"}],\"doi\":\"10.1007/978-3-319-64698-5_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7bd1bddbf7e032e9a576bb9b094428d6c01f6a5\",\"title\":\"Object Triggered Egocentric Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/c7bd1bddbf7e032e9a576bb9b094428d6c01f6a5\",\"venue\":\"CAIP\",\"year\":2017},{\"arxivId\":\"1910.03483\",\"authors\":[{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"48778972\",\"name\":\"H. Wendt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc796d165f1f9dcad89db30be9ea9cfd790c2222\",\"title\":\"Learning event representations in image sequences by dynamic graph embedding\",\"url\":\"https://www.semanticscholar.org/paper/cc796d165f1f9dcad89db30be9ea9cfd790c2222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.11420\",\"authors\":[{\"authorId\":null,\"name\":\"Kai Han\"},{\"authorId\":\"47060313\",\"name\":\"Z. Cao\"},{\"authorId\":\"1576498826\",\"name\":\"Shuang Cui\"},{\"authorId\":\"151363061\",\"name\":\"Benwei Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dbfc909b331261a03626aef4d3a3a630e87a5e4\",\"title\":\"Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time\",\"url\":\"https://www.semanticscholar.org/paper/6dbfc909b331261a03626aef4d3a3a630e87a5e4\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7756290\",\"name\":\"H. Kera\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPRW.2016.52\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"05894308622f55d5e197a5b1cb53030e3f9cc027\",\"title\":\"Discovering Objects of Joint Attention via First-Person Sensing\",\"url\":\"https://www.semanticscholar.org/paper/05894308622f55d5e197a5b1cb53030e3f9cc027\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211964\",\"name\":\"Md. Musfequs Salehin\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1007/978-3-319-30285-0_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01b8ce2cc358ea6c67da8bb6130f1e783ff3fceb\",\"title\":\"Fusion of Foreground Object, Spatial and Frequency Domain Motion Information for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/01b8ce2cc358ea6c67da8bb6130f1e783ff3fceb\",\"venue\":\"PSIVT Workshops\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/s11042-018-5953-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"title\":\"Foveated convolutional neural networks for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1903.00859\",\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"title\":\"Less Is More: Learning Highlight Detection From Video Duration\",\"url\":\"https://www.semanticscholar.org/paper/85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2261494\",\"name\":\"K. Apostolidis\"},{\"authorId\":\"9436583\",\"name\":\"Evlampios E. Apostolidis\"},{\"authorId\":\"1737436\",\"name\":\"V. Mezaris\"}],\"doi\":\"10.1007/978-3-319-73603-7_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a2875bfd125c6c4d659e96cf925a608fe47fbb7\",\"title\":\"A Motion-Driven Approach for Fine-Grained Temporal Segmentation of User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/2a2875bfd125c6c4d659e96cf925a608fe47fbb7\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":\"2006.05569\",\"authors\":[{\"authorId\":\"1741509773\",\"name\":\"Alan Carvalho Neves\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf40ebb97a893efbedf6feee05a328c16e6d2b2c\",\"title\":\"A gaze driven fast-forward method for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/cf40ebb97a893efbedf6feee05a328c16e6d2b2c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2817435\",\"name\":\"M. Nishiyama\"},{\"authorId\":\"32653524\",\"name\":\"Riku Matsumoto\"},{\"authorId\":\"102876476\",\"name\":\"Hiroki Yoshimura\"},{\"authorId\":\"143805337\",\"name\":\"Y. Iwai\"}],\"doi\":\"10.1016/j.patrec.2018.08.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f70f1feb82ac0929057c5cd810cccd9969d3cbcf\",\"title\":\"Extracting discriminative features using task-oriented gaze maps measured from observers for personal attribute classification\",\"url\":\"https://www.semanticscholar.org/paper/f70f1feb82ac0929057c5cd810cccd9969d3cbcf\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490659630\",\"name\":\"Yi Dong\"},{\"authorId\":\"9401670\",\"name\":\"C. Liu\"},{\"authorId\":\"49019678\",\"name\":\"Z. Shen\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"50855055\",\"name\":\"P. Wang\"},{\"authorId\":\"7923976\",\"name\":\"Changgong Zhang\"},{\"authorId\":\"3246404\",\"name\":\"P. Ren\"},{\"authorId\":\"65863521\",\"name\":\"Xuansong Xie\"},{\"authorId\":\"46493397\",\"name\":\"Han Yu\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3338533.3366603\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"329b8e635e641648860b3ead887a8ecb4990b2e1\",\"title\":\"Domain Specific and Idiom Adaptive Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/329b8e635e641648860b3ead887a8ecb4990b2e1\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.12.040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0adddb83eb89da8ecd14a296fa016773dc774646\",\"title\":\"Video summarization via spatio-temporal deep architecture\",\"url\":\"https://www.semanticscholar.org/paper/0adddb83eb89da8ecd14a296fa016773dc774646\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2017.118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06dc33896f94554d67514c8a5e34cad5ff9749bc\",\"title\":\"Enhancing Video Summarization via Vision-Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/06dc33896f94554d67514c8a5e34cad5ff9749bc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1808.09559\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"title\":\"Temporal Saliency Adaptation in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"144106250\",\"name\":\"K. Lu\"}],\"doi\":\"10.1109/ICPR.2016.7899706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd577e2a3819b24674a82328acc4869608d03b85\",\"title\":\"Egocentric hand detection via region growth\",\"url\":\"https://www.semanticscholar.org/paper/cd577e2a3819b24674a82328acc4869608d03b85\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"144135496\",\"name\":\"Jianteng Peng\"},{\"authorId\":\"144240366\",\"name\":\"X. Jin\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/TNNLS.2018.2885591\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a83bb87aed237448bb035dde0b9af8275881080\",\"title\":\"Submodular Function Optimization for Motion Clustering and Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1a83bb87aed237448bb035dde0b9af8275881080\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1909.12948\",\"authors\":[{\"authorId\":\"1405222115\",\"name\":\"K. VivekrajV.\"},{\"authorId\":\"144789994\",\"name\":\"D. Sen\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3347712\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"title\":\"Video Skimming\",\"url\":\"https://www.semanticscholar.org/paper/8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759761\",\"name\":\"F. Hopfgartner\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1798501\",\"name\":\"Hideo Joho\"}],\"doi\":\"10.1007/978-3-030-37734-2_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"219ee3e9e2ab8731c919c17003f1a18b679d0d69\",\"title\":\"Rethinking the Test Collection Methodology for Personal Self-tracking Data\",\"url\":\"https://www.semanticscholar.org/paper/219ee3e9e2ab8731c919c17003f1a18b679d0d69\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211964\",\"name\":\"Md. Musfequs Salehin\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1109/ICMEW.2016.7574675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b003c6958aaeee39c3e0216f352b75ea7681c681\",\"title\":\"Human visual field based saliency prediction method using Eye Tracker data for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/b003c6958aaeee39c3e0216f352b75ea7681c681\",\"venue\":\"2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"144362750\",\"name\":\"A. Tan\"}],\"doi\":\"10.1109/THMS.2016.2623480\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"title\":\"Summarization of Egocentric Videos: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404083509\",\"name\":\"P. Ingav\\u00e9lez-Guerra\"},{\"authorId\":\"1414903708\",\"name\":\"I. Cuzco-Calle\"},{\"authorId\":\"1410405248\",\"name\":\"D. Calle-L\\u00f3pez\"},{\"authorId\":\"1404083516\",\"name\":\"C. Oyola-Flores\"},{\"authorId\":\"1410802812\",\"name\":\"In\\u00e9s Yambay-Aulla\"},{\"authorId\":\"1403953313\",\"name\":\"V. Robles-Bykbaev\"},{\"authorId\":\"1698905\",\"name\":\"J. Hilera\"}],\"doi\":\"10.1007/978-3-319-60018-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d9edef7353f5e4e498bf2e26a3f15a41d505ffc\",\"title\":\"An Intelligent System to Automatically Generate Video-Summaries for Accessible Learning Objects for People with Hearing Loss\",\"url\":\"https://www.semanticscholar.org/paper/8d9edef7353f5e4e498bf2e26a3f15a41d505ffc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150285792\",\"name\":\"Ryo Sobue\"},{\"authorId\":\"150223556\",\"name\":\"Mitsuru Nakazawa\"},{\"authorId\":\"23630916\",\"name\":\"Yeongnam Chae\"},{\"authorId\":\"153162517\",\"name\":\"B. Stenger\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"46236306\",\"name\":\"H. Fujiyoshi\"}],\"doi\":\"10.23919/MVA.2019.8757903\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f23d0dbbddd690bb079348e997c12dcc8a1dfe52\",\"title\":\"Cooking Video Summarization Guided By Matching with Step-By-Step Recipe Photos\",\"url\":\"https://www.semanticscholar.org/paper/f23d0dbbddd690bb079348e997c12dcc8a1dfe52\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3025453.3025821\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"835680aa3c770a2360e62e467d82760936e52431\",\"title\":\"EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines\",\"url\":\"https://www.semanticscholar.org/paper/835680aa3c770a2360e62e467d82760936e52431\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mensink\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5227e03fff66f7ce58c93c962b6da0bde4d752\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Music-Guided Video Summarization using Quadratic Assignments\",\"url\":\"https://www.semanticscholar.org/paper/af5227e03fff66f7ce58c93c962b6da0bde4d752\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/978-3-030-00767-6_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c9222c188866351c994fee3ac2a2beaa843cc8\",\"title\":\"Gaze Aware Deep Learning Model for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/09c9222c188866351c994fee3ac2a2beaa843cc8\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2379129\",\"name\":\"Patrizia Varini\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TMM.2017.2705915\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6465d833e1a050fd959d21eecdee613c1cc869e3\",\"title\":\"Personalized Egocentric Video Summarization of Cultural Tour on User Preferences Input\",\"url\":\"https://www.semanticscholar.org/paper/6465d833e1a050fd959d21eecdee613c1cc869e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1961187\",\"name\":\"A. Zemmari\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1007/978-3-319-57687-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25a4355c69e90f0ebd182a90e4748742721a4b1b\",\"title\":\"Deep Saliency: Prediction of Interestingness in Video with CNN\",\"url\":\"https://www.semanticscholar.org/paper/25a4355c69e90f0ebd182a90e4748742721a4b1b\",\"venue\":\"Visual Content Indexing and Retrieval with Psycho-Visual Models\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2144763\",\"name\":\"Z. Gomolka\"},{\"authorId\":\"34332007\",\"name\":\"Boguslaw Twarog\"},{\"authorId\":\"50054065\",\"name\":\"E. \\u017bes\\u0142awska\"}],\"doi\":\"10.1007/978-3-319-59060-8_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4834e1fc80edd7046c58b3454ace7b597aa53238\",\"title\":\"Cognitive Investigation on Pilot Attention During Take-Offs and Landings Using Flight Simulator\",\"url\":\"https://www.semanticscholar.org/paper/4834e1fc80edd7046c58b3454ace7b597aa53238\",\"venue\":\"ICAISC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81138290\",\"name\":\"Naoyuki Kan\"},{\"authorId\":\"31132392\",\"name\":\"Nagisa Kondo\"},{\"authorId\":\"30526356\",\"name\":\"Warapon Chinsatit\"},{\"authorId\":\"2317420\",\"name\":\"T. Saitoh\"}],\"doi\":\"10.23919/SICE.2018.8492593\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f567a5f0a8ab016e17838990cee66e637fbcdbe\",\"title\":\"Effectiveness of Data Augmentation for CNN-Based Pupil Center Point Detection\",\"url\":\"https://www.semanticscholar.org/paper/4f567a5f0a8ab016e17838990cee66e637fbcdbe\",\"venue\":\"2018 57th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"50437531\",\"name\":\"Zhiyuan Liang\"},{\"authorId\":\"2233009\",\"name\":\"J. Liu\"},{\"authorId\":\"6887440\",\"name\":\"H. Sun\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TCYB.2018.2803217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1db6dbce1a7e89cbab88cb20865a16e1c93981d9\",\"title\":\"Multiobject Tracking by Submodular Optimization\",\"url\":\"https://www.semanticscholar.org/paper/1db6dbce1a7e89cbab88cb20865a16e1c93981d9\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2019},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"1809.08854\",\"authors\":[{\"authorId\":\"3333118\",\"name\":\"Vishal Kaushal\"},{\"authorId\":\"152398665\",\"name\":\"R. Iyer\"},{\"authorId\":\"9745898\",\"name\":\"S. Kothawade\"},{\"authorId\":null,\"name\":\"Sandeep Subramanian\"},{\"authorId\":\"145799547\",\"name\":\"Ganesh Ramakrishnan\"}],\"doi\":\"10.1109/WACV.2019.00076\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a2637ae9b1c6eb35340a517af4cbebca9e92a98\",\"title\":\"A Framework Towards Domain Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/2a2637ae9b1c6eb35340a517af4cbebca9e92a98\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143802014\",\"name\":\"Ngu Nguyen\"},{\"authorId\":\"1710108\",\"name\":\"Stephan Sigg\"}],\"doi\":\"10.1109/PERCOMW.2017.7917528\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6f373c3fbc18870eb60ac05b70a23150c2e68a0\",\"title\":\"Demo of PassFrame: Generating image-based passwords from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b6f373c3fbc18870eb60ac05b70a23150c2e68a0\",\"venue\":\"2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)\",\"year\":2017},{\"arxivId\":\"1808.02289\",\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"144362750\",\"name\":\"A. Tan\"}],\"doi\":\"10.1145/3240508.3240624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e9422a01cde94e5bd1aaa3bebcee1ac04adb58d\",\"title\":\"Predicting Visual Context for Unsupervised Event Segmentation in Continuous Photo-streams\",\"url\":\"https://www.semanticscholar.org/paper/1e9422a01cde94e5bd1aaa3bebcee1ac04adb58d\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1612.06209\",\"authors\":[{\"authorId\":\"8001568\",\"name\":\"Le Ngu Nguyen\"},{\"authorId\":\"1710108\",\"name\":\"Stephan Sigg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"709a18c79ca2b48978ccc22fa33ffdb39b02a9b1\",\"title\":\"Personalized Image-based User Authentication using Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/709a18c79ca2b48978ccc22fa33ffdb39b02a9b1\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024334\",\"name\":\"Y. Li\"},{\"authorId\":\"1896187\",\"name\":\"Zhenni Li\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"}],\"doi\":\"10.1109/ACCESS.2019.2908010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a416cd77a30dd2dbfc8ba9b5351bced43f7b35aa\",\"title\":\"An  $\\\\ell_{1/2}$ -Norm Regularizer-Based Sparse Coding Framework for Gaze Prediction in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/a416cd77a30dd2dbfc8ba9b5351bced43f7b35aa\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737436\",\"name\":\"V. Mezaris\"},{\"authorId\":\"145465280\",\"name\":\"L. Nixon\"},{\"authorId\":\"48594399\",\"name\":\"S. Papadopoulos\"},{\"authorId\":\"35548096\",\"name\":\"Denis Teyssou\"}],\"doi\":\"10.1007/978-3-030-26752-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e85d9d0d271f1ea530af4e1a686e9577b2e716a4\",\"title\":\"Video Verification in the Fake News Era\",\"url\":\"https://www.semanticscholar.org/paper/e85d9d0d271f1ea530af4e1a686e9577b2e716a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1607.05177\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-319-46484-8_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"083986588bdef41ce5f154f9decdd7dc6d39292e\",\"title\":\"Query-Focused Extractive Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/083986588bdef41ce5f154f9decdd7dc6d39292e\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1007/s11263-017-1042-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22894791cb1e139177cef3fbb1ebda417a4b549f\",\"title\":\"Attentive Systems: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/22894791cb1e139177cef3fbb1ebda417a4b549f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1707.04347\",\"authors\":[{\"authorId\":\"144871760\",\"name\":\"L. Chen\"},{\"authorId\":\"40546894\",\"name\":\"M. Feldman\"},{\"authorId\":\"1697131\",\"name\":\"Amin Karbasi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53b2ed67bff74b8b9d825ebbe470740c81ebd0c3\",\"title\":\"Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?\",\"url\":\"https://www.semanticscholar.org/paper/53b2ed67bff74b8b9d825ebbe470740c81ebd0c3\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICIP.2016.7532345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"970046775bfe397ecbd9c4267a91d9afe77473dc\",\"title\":\"Embedded sparse coding for summarizing multi-view videos\",\"url\":\"https://www.semanticscholar.org/paper/970046775bfe397ecbd9c4267a91d9afe77473dc\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2760194\",\"name\":\"Yunyang Xiong\"},{\"authorId\":\"66185025\",\"name\":\"Hyun-woo Kim\"},{\"authorId\":\"97658883\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2019.00793\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"649b03e22186cbbe921c31d8bfa3399ae475d85d\",\"title\":\"Mixed Effects Neural Networks (MeNets) With Applications to Gaze Estimation\",\"url\":\"https://www.semanticscholar.org/paper/649b03e22186cbbe921c31d8bfa3399ae475d85d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48517072\",\"name\":\"Federica Fergnani\"},{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"7375777\",\"name\":\"Joaquim De Mira\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2016.51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1327ae18e700a2bf4bbe256430613cb4554b953\",\"title\":\"Body Part Based Re-Identification from an Egocentric Perspective\",\"url\":\"https://www.semanticscholar.org/paper/e1327ae18e700a2bf4bbe256430613cb4554b953\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40977902\",\"name\":\"Seita Kayukawa\"},{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144086483\",\"name\":\"M. Nakamura\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"}],\"doi\":\"10.1145/3170427.3186501\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94d177db3f198a3571576e562b4d3d9e816eb3cf\",\"title\":\"Dynamic Object Scanning: Object-Based Elastic Timeline for Quickly Browsing First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/94d177db3f198a3571576e562b4d3d9e816eb3cf\",\"venue\":\"CHI Extended Abstracts\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2920056\",\"name\":\"Julian Steil\"},{\"authorId\":\"143965164\",\"name\":\"Michael Xuelin Huang\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/3204493.3204538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be7bb84581b09f47668966d0cb70df0876c84a21\",\"title\":\"Fixation detection for head-mounted eye tracking based on visual similarity of gaze targets\",\"url\":\"https://www.semanticscholar.org/paper/be7bb84581b09f47668966d0cb70df0876c84a21\",\"venue\":\"ETRA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409985550\",\"name\":\"Linardos Panagiotis\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b02efcd0b2c26c9e68b3807d7e958af763b56ab\",\"title\":\"The impact of temporal regularisation in egocentric saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/1b02efcd0b2c26c9e68b3807d7e958af763b56ab\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1706.03114\",\"authors\":[{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2017.455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a5220d70148a900ae12864b4d028ea80fc9e094\",\"title\":\"Collaborative Summarization of Topic-Related Videos\",\"url\":\"https://www.semanticscholar.org/paper/8a5220d70148a900ae12864b4d028ea80fc9e094\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1609.08758\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"},{\"authorId\":\"1771769\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1007/978-3-319-54193-8_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79f2bc7bf4c37e66bfc35b2de99d51c1f5e77a5f\",\"title\":\"Video Summarization Using Deep Semantic Features\",\"url\":\"https://www.semanticscholar.org/paper/79f2bc7bf4c37e66bfc35b2de99d51c1f5e77a5f\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"3190022\",\"name\":\"Danping Liao\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICCVW.2019.00543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"title\":\"Learning Spatiotemporal Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2018.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"title\":\"Personal-location-based temporal segmentation of egocentric videos for lifelogging applications\",\"url\":\"https://www.semanticscholar.org/paper/79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450354\",\"name\":\"Warapon Chinsatitf\"},{\"authorId\":\"2317420\",\"name\":\"T. Saitoh\"}],\"doi\":\"10.1155/2017/8718956\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66bd4056cef30b9d1e724c943b1c5ae959fab14c\",\"title\":\"CNN-Based Pupil Center Detection for Wearable Gaze Estimation System\",\"url\":\"https://www.semanticscholar.org/paper/66bd4056cef30b9d1e724c943b1c5ae959fab14c\",\"venue\":\"Appl. Comput. Intell. Soft Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82971051\",\"name\":\"M. Basavarajaiah\"},{\"authorId\":\"48267651\",\"name\":\"P. Sharma\"}],\"doi\":\"10.1145/3355398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bbc7bf67fd048bf699e1e90d734cd2ad53e3c23\",\"title\":\"Survey of Compressed Domain Video Summarization Techniques\",\"url\":\"https://www.semanticscholar.org/paper/4bbc7bf67fd048bf699e1e90d734cd2ad53e3c23\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143667153\",\"name\":\"N. Mastorakis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ee50c8487e212b91a6cba733127e1bb06cf37c8\",\"title\":\"Video Summarization in Social Media Based on Users \\u2019 Geolocation Klimis Ntalianis\",\"url\":\"https://www.semanticscholar.org/paper/8ee50c8487e212b91a6cba733127e1bb06cf37c8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72a49fa5e305499e7b7f088ec0c853027b23f2f0\",\"title\":\"EgoSampling: Wide View Hyperlapse from Single and Multiple Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/72a49fa5e305499e7b7f088ec0c853027b23f2f0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1707.04960\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"20947424\",\"name\":\"Jacob S. Laurel\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/CVPR.2017.229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19ce02ad53571ebffd194eef670989ff3d6eaef4\",\"title\":\"Query-Focused Video Summarization: Dataset, Evaluation, and a Memory Network Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/19ce02ad53571ebffd194eef670989ff3d6eaef4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1807.03089\",\"authors\":[{\"authorId\":\"9368124\",\"name\":\"K. Zhou\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c65232de4ca3809b0765577a1197bd6027f98a39\",\"title\":\"Video Summarisation by Classification with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c65232de4ca3809b0765577a1197bd6027f98a39\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143802014\",\"name\":\"Ngu Nguyen\"},{\"authorId\":\"1710108\",\"name\":\"Stephan Sigg\"}],\"doi\":\"10.1109/PERCOMW.2017.7917518\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8835abdf807442304bcf05e14b8517a7ae560dae\",\"title\":\"PassFrame: Generating image-based passwords from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/8835abdf807442304bcf05e14b8517a7ae560dae\",\"venue\":\"2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380141\",\"name\":\"Y. Zhang\"},{\"authorId\":\"33610144\",\"name\":\"X. Chen\"},{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"145977984\",\"name\":\"Wei Teng\"},{\"authorId\":\"46219960\",\"name\":\"Haokun Song\"}],\"doi\":\"10.1109/TIP.2018.2806995\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"457b9977e7733cd9c54b8cb921bcc7ad152d8e96\",\"title\":\"Exploring Weakly Labeled Images for Video Object Segmentation With Submodular Proposal Selection\",\"url\":\"https://www.semanticscholar.org/paper/457b9977e7733cd9c54b8cb921bcc7ad152d8e96\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3132818.3132831\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fdac02fd55308be6580ba289134a91376906b1f\",\"title\":\"Egoscanning: quickly scanning first-person videos with egocentric elastic timelines\",\"url\":\"https://www.semanticscholar.org/paper/1fdac02fd55308be6580ba289134a91376906b1f\",\"venue\":\"SIGGRAPH ASIA Emerging Technologies\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211964\",\"name\":\"Md. Musfequs Salehin\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1109/ICMEW.2017.8026294\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0aa5b118e971bf87e7fd5968ce87d7374990545f\",\"title\":\"A novel framework for video summarization based on smooth pursuit information from eye tracker data\",\"url\":\"https://www.semanticscholar.org/paper/0aa5b118e971bf87e7fd5968ce87d7374990545f\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TPAMI.2017.2771767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"762311d26be8c774f2ad0ae74e3f12458662dd91\",\"title\":\"Ego-Surfing: Person Localization in First-Person Videos Using Ego-Motion Signatures\",\"url\":\"https://www.semanticscholar.org/paper/762311d26be8c774f2ad0ae74e3f12458662dd91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2097156\",\"name\":\"M. Fei\"},{\"authorId\":\"152889332\",\"name\":\"Wei Jiang\"},{\"authorId\":\"39721136\",\"name\":\"Weijie Mao\"}],\"doi\":\"10.1016/J.ESWA.2020.114036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef76b3d6c7095c6e86eeb2d3a574c42859a7d406\",\"title\":\"Learning user interest with improved triplet deep ranking and web-image priors for topic-related video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ef76b3d6c7095c6e86eeb2d3a574c42859a7d406\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153196291\",\"name\":\"F. Li\"},{\"authorId\":\"145396994\",\"name\":\"D. Chen\"},{\"authorId\":\"1868611\",\"name\":\"Mingming Fan\"},{\"authorId\":\"1752847\",\"name\":\"Khai N. Truong\"}],\"doi\":\"10.1145/3351253\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e88dd91b028e26beaf669462429f0458fd9ada0\",\"title\":\"FMT: A Wearable Camera-Based Object Tracking Memory Aid for Older Adults\",\"url\":\"https://www.semanticscholar.org/paper/7e88dd91b028e26beaf669462429f0458fd9ada0\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2019},{\"arxivId\":\"1610.02714\",\"authors\":[{\"authorId\":\"7233152\",\"name\":\"J. Finocchiaro\"},{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2017.132\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05441a4e03e15e6d307030daa68fcddc88bdbd8a\",\"title\":\"Egocentric Height Estimation\",\"url\":\"https://www.semanticscholar.org/paper/05441a4e03e15e6d307030daa68fcddc88bdbd8a\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"1824641\",\"name\":\"F. Zou\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"145487536\",\"name\":\"Kai Zheng\"}],\"doi\":\"10.1016/j.neucom.2016.03.083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08728bd75bde86c095832d84232d17a6b05cecce\",\"title\":\"Spatial and temporal scoring for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/08728bd75bde86c095832d84232d17a6b05cecce\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2016.288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16461bc1f06c781b5357cb1157248d28dc3672a0\",\"title\":\"Recognizing Micro-Actions and Reactions from Paired Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/16461bc1f06c781b5357cb1157248d28dc3672a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.06604\",\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.1145/3240508.3240599\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"916218b7fd637d75f644c5ef5f7590c05fabca75\",\"title\":\"PHD-GIFs: Personalized Highlight Detection for Automatic GIF Creation\",\"url\":\"https://www.semanticscholar.org/paper/916218b7fd637d75f644c5ef5f7590c05fabca75\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1016/j.patcog.2017.07.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"968695df20f365ad05733f6f0a7d421d60f996df\",\"title\":\"Gaze latent support vector machine for image classification\",\"url\":\"https://www.semanticscholar.org/paper/968695df20f365ad05733f6f0a7d421d60f996df\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49285357\",\"name\":\"M. Sreeja\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1016/J.JVCIR.2019.06.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1213369d1fb77b381a94917007b80500ba3b20b\",\"title\":\"Towards genre-specific frameworks for video summarisation: A survey\",\"url\":\"https://www.semanticscholar.org/paper/f1213369d1fb77b381a94917007b80500ba3b20b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106014\",\"name\":\"Denis Teyssou\"},{\"authorId\":\"36657932\",\"name\":\"J. Leung\"},{\"authorId\":\"9436583\",\"name\":\"Evlampios E. Apostolidis\"},{\"authorId\":\"2261494\",\"name\":\"K. Apostolidis\"},{\"authorId\":\"144178604\",\"name\":\"S. Papadopoulos\"},{\"authorId\":\"2309222\",\"name\":\"M. Zampoglou\"},{\"authorId\":\"144447962\",\"name\":\"O. Papadopoulou\"},{\"authorId\":\"1737436\",\"name\":\"V. Mezaris\"}],\"doi\":\"10.1145/3132384.3132387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12228ffc68759880c9699e11e3f44d336833c0f8\",\"title\":\"The InVID Plug-in: Web Video Verification on the Browser\",\"url\":\"https://www.semanticscholar.org/paper/12228ffc68759880c9699e11e3f44d336833c0f8\",\"venue\":\"MuVer@MM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116093616\",\"name\":\"M. .\"},{\"authorId\":null,\"name\":\"USFEQUS\"},{\"authorId\":null,\"name\":\"ALEHIN\"},{\"authorId\":null,\"name\":\"ANORANJAN\"},{\"authorId\":\"41181527\",\"name\":\"Aul\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"85541cc4d8efb18cc556dc139016202411d9955f\",\"title\":\"Adaptive Fusion of Human Visual Sensitive Features for Surveillance Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/85541cc4d8efb18cc556dc139016202411d9955f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"143775793\",\"name\":\"J. Kumar\"},{\"authorId\":\"49488800\",\"name\":\"Sriganesh Madhvanath\"},{\"authorId\":\"40327196\",\"name\":\"Palghat Ramesh\"},{\"authorId\":\"145652623\",\"name\":\"R. Bala\"}],\"doi\":\"10.1109/TMM.2017.2726187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30bb55d3ef6905cfeedc12aa0dc70ccbf85c8293\",\"title\":\"Deep Temporal Multimodal Fusion for Medical Procedure Monitoring Using Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/30bb55d3ef6905cfeedc12aa0dc70ccbf85c8293\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9436583\",\"name\":\"Evlampios E. Apostolidis\"},{\"authorId\":\"2261494\",\"name\":\"K. Apostolidis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"},{\"authorId\":\"1737436\",\"name\":\"V. Mezaris\"}],\"doi\":\"10.1007/978-3-030-26752-0_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78d17222390a017c72d1d2a8be86d499c0b19ad\",\"title\":\"Video Fragmentation and Reverse Search on the Web\",\"url\":\"https://www.semanticscholar.org/paper/e78d17222390a017c72d1d2a8be86d499c0b19ad\",\"venue\":\"Video Verification in the Fake News Era\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41194352\",\"name\":\"Mengxiong Han\"},{\"authorId\":\"2938403\",\"name\":\"H. Hu\"},{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"},{\"authorId\":\"30171553\",\"name\":\"Rong-Peng Tian\"},{\"authorId\":\"4366965\",\"name\":\"Jin Zheng\"}],\"doi\":\"10.1007/s11042-017-4485-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b85ffee23de683ffb573ef1f353bbfbb6a46c483\",\"title\":\"An auto-encoder-based summarization algorithm for unstructured videos\",\"url\":\"https://www.semanticscholar.org/paper/b85ffee23de683ffb573ef1f353bbfbb6a46c483\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"},{\"authorId\":\"2065653\",\"name\":\"L. Paletta\"},{\"authorId\":\"2386156\",\"name\":\"R. Perko\"}],\"doi\":\"10.1109/LSP.2016.2523339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e632641321aff694788104c06d3e6736e0b8c39b\",\"title\":\"Novelty-based Spatiotemporal Saliency Detection for Prediction of Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/e632641321aff694788104c06d3e6736e0b8c39b\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":\"2010.07891\",\"authors\":[{\"authorId\":\"51235014\",\"name\":\"Ekta Sood\"},{\"authorId\":\"87863676\",\"name\":\"Simon Tannert\"},{\"authorId\":\"1605986895\",\"name\":\"Philipp M\\u00fcller\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d1079968596ea2ffe17ef3eeb854ef488b4882\",\"title\":\"Improving Natural Language Processing Tasks with Human Gaze-Guided Neural Attention\",\"url\":\"https://www.semanticscholar.org/paper/54d1079968596ea2ffe17ef3eeb854ef488b4882\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3067968\",\"name\":\"M. Cirne\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/s11042-016-4300-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffb9b279574d6158b18ab14276fa3867089777d3\",\"title\":\"VISCOM: A robust video summarization approach using color co-occurrence matrices\",\"url\":\"https://www.semanticscholar.org/paper/ffb9b279574d6158b18ab14276fa3867089777d3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40977902\",\"name\":\"Seita Kayukawa\"},{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144086483\",\"name\":\"M. Nakamura\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"}],\"doi\":\"10.1145/3170427.3189085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12e28bf2af2b2c12ad041bf949bff66718d84899\",\"title\":\"Dynamic Object Scanning: Object-Based Elastic Timeline for Quickly Browsing First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/12e28bf2af2b2c12ad041bf949bff66718d84899\",\"venue\":\"CHI Extended Abstracts\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145495264\",\"name\":\"Zhiwei Fan\"},{\"authorId\":\"24668624\",\"name\":\"C. Chen\"},{\"authorId\":\"40570471\",\"name\":\"T. Jiang\"}],\"doi\":\"10.1109/ICMEW.2017.8026213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f178ac72886007802c0db67ef8d264c8b2107cb7\",\"title\":\"A semi-automatic editing method for surgery videos\",\"url\":\"https://www.semanticscholar.org/paper/f178ac72886007802c0db67ef8d264c8b2107cb7\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":\"1603.03369\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2016.120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3db6c8086082acd55f6c95070ad309ecb834517\",\"title\":\"Summary Transfer: Exemplar-Based Subset Selection for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/e3db6c8086082acd55f6c95070ad309ecb834517\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1886245\",\"name\":\"Yudai Tanaka\"},{\"authorId\":\"2795240\",\"name\":\"S. Wakisaka\"},{\"authorId\":\"145916013\",\"name\":\"M. Inami\"}],\"doi\":\"10.1145/3338286.3344403\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bed515837b1f31ab0f4df587b7865c66c7a00ed\",\"title\":\"A Formative Study for Record-time Manual Annotation of First-person Videos\",\"url\":\"https://www.semanticscholar.org/paper/9bed515837b1f31ab0f4df587b7865c66c7a00ed\",\"venue\":\"MobileHCI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1007/978-3-319-46604-0_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c0e70c97f065ad10d2a24963439d3892183ac99\",\"title\":\"Temporal Segmentation of Egocentric Videos to Highlight Personal Locations of Interest\",\"url\":\"https://www.semanticscholar.org/paper/9c0e70c97f065ad10d2a24963439d3892183ac99\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145445616\",\"name\":\"Zheng Ma\"},{\"authorId\":\"11288121\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"}],\"doi\":\"10.1109/MC.2019.2903246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98f6e6abd75260ebeb61442302903f6f8b78867f\",\"title\":\"Human Eye Movements Reveal Video Frame Importance\",\"url\":\"https://www.semanticscholar.org/paper/98f6e6abd75260ebeb61442302903f6f8b78867f\",\"venue\":\"Computer\",\"year\":2019},{\"arxivId\":\"1910.05899\",\"authors\":[{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"50814744\",\"name\":\"Jia-xiang Wang\"},{\"authorId\":\"144081363\",\"name\":\"Chao Li\"},{\"authorId\":\"1390667177\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"983e99bf560edcee1676b68dc81b570f03fb5835\",\"title\":\"TruNet: Short Videos Generation from Long Videos via Story-Preserving Truncation\",\"url\":\"https://www.semanticscholar.org/paper/983e99bf560edcee1676b68dc81b570f03fb5835\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211964\",\"name\":\"Md. Musfequs Salehin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fef7925953544fde78149c3aa8c0b5b35424986e\",\"title\":\"Innovative Approaches for Video Summarisation in the Challenging Environment\",\"url\":\"https://www.semanticscholar.org/paper/fef7925953544fde78149c3aa8c0b5b35424986e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799538\",\"name\":\"Costas Panagiotakis\"},{\"authorId\":\"2542688\",\"name\":\"H. Papadakis\"},{\"authorId\":\"3099265\",\"name\":\"P. Fragopoulou\"}],\"doi\":\"10.1007/978-3-030-45442-5_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91f345861ffc505dba0ff2d10d7b90967855ce3b\",\"title\":\"Personalized Video Summarization Based Exclusively on User Preferences\",\"url\":\"https://www.semanticscholar.org/paper/91f345861ffc505dba0ff2d10d7b90967855ce3b\",\"venue\":\"ECIR\",\"year\":2020},{\"arxivId\":\"2006.15412\",\"authors\":[{\"authorId\":\"152398665\",\"name\":\"R. Iyer\"},{\"authorId\":\"1779718056\",\"name\":\"Ninad Khargoankar\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"},{\"authorId\":\"1779939937\",\"name\":\"Himanshu Asanani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fad858c100895a7171f4420132f862ce1685572a\",\"title\":\"Submodular Combinatorial Information Measures with Applications in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/fad858c100895a7171f4420132f862ce1685572a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14552\",\"authors\":[{\"authorId\":\"46999304\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeafc087178102645be19fb6975f53b798061b4\",\"title\":\"Compare and Select: Video Summarization with Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/beeafc087178102645be19fb6975f53b798061b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1606.04637\",\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TPAMI.2017.2771767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c21563f77cbb670f0f3be2b6040e16ad986bdfc\",\"title\":\"Ego-surfing first person videos\",\"url\":\"https://www.semanticscholar.org/paper/5c21563f77cbb670f0f3be2b6040e16ad986bdfc\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1807.04219\",\"authors\":[{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"49681507\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-030-01237-3_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdc254119ff7166d67aeedb544b987ccb8b9eae6\",\"title\":\"How Local is the Local Diversity? Reinforcing Sequential Determinantal Point Processes with Dynamic Ground Sets for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/cdc254119ff7166d67aeedb544b987ccb8b9eae6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.11228\",\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1145/3321408.3322622\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"title\":\"DTR-GAN: dilated temporal relational adversarial network for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"venue\":\"ACM TUR-C\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2506370\",\"name\":\"Sinnu Susan Thomas\"},{\"authorId\":\"144879221\",\"name\":\"S. Gupta\"},{\"authorId\":\"32325586\",\"name\":\"V. Subramanian\"}],\"doi\":\"10.1109/TITS.2017.2769719\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a70b25da6934526a549cbc3acb05db844fe61278\",\"title\":\"Event Detection on Roads Using Perceptual Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/a70b25da6934526a549cbc3acb05db844fe61278\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2018},{\"arxivId\":\"1904.06090\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14286fdc78b3039fc724274c18aa24caee8b59e\",\"title\":\"Digging Deeper Into Egocentric Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b14286fdc78b3039fc724274c18aa24caee8b59e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1007/s11042-019-08175-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"title\":\"Dilated temporal relational adversarial network for generic video summarization\",\"url\":\"https://www.semanticscholar.org/paper/5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1762686\",\"name\":\"T. Sato\"},{\"authorId\":\"1771769\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1007/s11042-016-4061-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd961668b885fb6e421af897ed72a7f99408bf5a\",\"title\":\"Video summarization using textual descriptions for authoring video blogs\",\"url\":\"https://www.semanticscholar.org/paper/fd961668b885fb6e421af897ed72a7f99408bf5a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103678890\",\"name\":\"Humaira A. Ghafoor\"},{\"authorId\":\"144865166\",\"name\":\"A. Javed\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"51260966\",\"name\":\"H. Dawood\"},{\"authorId\":\"145337997\",\"name\":\"H. Dawood\"},{\"authorId\":\"2823041\",\"name\":\"Ameen Banjar\"}],\"doi\":\"10.1155/2018/7586417\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87da2e37fb6464e3664aa27625cf5e25ece8fe6f\",\"title\":\"Egocentric Video Summarization Based on People Interaction Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/87da2e37fb6464e3664aa27625cf5e25ece8fe6f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Badmapriya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f2a799e3f3d3bb95214baff57dd916ac1245729\",\"title\":\"Fusion of Foreground Object in Domain Motion Information for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/8f2a799e3f3d3bb95214baff57dd916ac1245729\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"11053243\",\"name\":\"Thomas Jongstra\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1145/3078971.3079024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6220f567ab7ef381ea3386be0a7e62b4ca8158c7\",\"title\":\"Music-Guided Video Summarization using Quadratic Assignments\",\"url\":\"https://www.semanticscholar.org/paper/6220f567ab7ef381ea3386be0a7e62b4ca8158c7\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/TIP.2017.2666039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0696b633404183479bf57bc337de2e2121cf0a5e\",\"title\":\"Semantic Highlight Retrieval and Term Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0696b633404183479bf57bc337de2e2121cf0a5e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/THMS.2020.2965429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97429331740c98c6d03d59f63789db183784c79b\",\"title\":\"An Ego-Vision System for Discovering Human Joint Attention\",\"url\":\"https://www.semanticscholar.org/paper/97429331740c98c6d03d59f63789db183784c79b\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620571\",\"name\":\"X. Wang\"},{\"authorId\":\"145314012\",\"name\":\"B. Zhou\"},{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144035013\",\"name\":\"Yifan Zhao\"}],\"doi\":\"10.1016/j.cag.2018.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f792ccb5539d859a7434633649ce8eaa5eca95e3\",\"title\":\"Deep style estimator for 3D indoor object collection organization and scene synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f792ccb5539d859a7434633649ce8eaa5eca95e3\",\"venue\":\"Comput. Graph.\",\"year\":2018},{\"arxivId\":\"1604.07741\",\"authors\":[{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/TCSVT.2017.2651051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4287cf846c327271fbf2db4574d913d15b3e5441\",\"title\":\"EgoSampling: Wide View Hyperlapse From Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/4287cf846c327271fbf2db4574d913d15b3e5441\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1711.08922\",\"authors\":[{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"350fc542f1a6a93b74d74aee14d83bed8782afcd\",\"title\":\"Summarizing First-Person Videos from Third Persons' Points of Views\",\"url\":\"https://www.semanticscholar.org/paper/350fc542f1a6a93b74d74aee14d83bed8782afcd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.03483\",\"authors\":[{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"48778972\",\"name\":\"H. Wendt\"}],\"doi\":\"10.1109/TIP.2020.3044448\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b86148d123ca85cb025f55c745ba360f7c8a17fe\",\"title\":\"Learning event representations for temporal segmentation of image sequences by dynamic graph embedding.\",\"url\":\"https://www.semanticscholar.org/paper/b86148d123ca85cb025f55c745ba360f7c8a17fe\",\"venue\":\"IEEE transactions on image processing : a publication of the IEEE Signal Processing Society\",\"year\":2020}],\"corpusId\":416449,\"doi\":\"10.1109/CVPR.2015.7298836\",\"fieldsOfStudy\":[\"Computer Science\",\"Medicine\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144477854\",\"name\":\"N. Shapovalova\"},{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b541127473598a121e7f1d565e27d21a15c66fad\",\"title\":\"Action is in the Eye of the Beholder: Eye-gaze Driven Model for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b541127473598a121e7f1d565e27d21a15c66fad\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1210.4871\",\"authors\":[{\"authorId\":\"46933412\",\"name\":\"H. Lin\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"516873139bc82faaf567332b1705740d1d9cd915\",\"title\":\"Learning Mixtures of Submodular Shells with Application to Document Summarization\",\"url\":\"https://www.semanticscholar.org/paper/516873139bc82faaf567332b1705740d1d9cd915\",\"venue\":\"UAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"},{\"authorId\":\"1906906\",\"name\":\"Raphael Bacco\"},{\"authorId\":\"33801124\",\"name\":\"Arnaud Hocevar\"},{\"authorId\":\"79426786\",\"name\":\"P. Lambert\"},{\"authorId\":\"2260487\",\"name\":\"Gr\\u00e9gory Pa\\u00efs\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"}],\"doi\":\"10.1145/1463563.1463590\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"507f252bcb89e97688e5b50b88eade4ead65506e\",\"title\":\"Video summarization from spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/507f252bcb89e97688e5b50b88eade4ead65506e\",\"venue\":\"TVS '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10599-4_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"title\":\"Category-Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Michael Gygli\"},{\"authorId\":null,\"name\":\"Helmut Grabner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hayko Riemenschneider, and Luc Van Gool. Creating summaries from user videos\",\"url\":\"\",\"venue\":\"Proc. ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782194\",\"name\":\"Y. Liu\"},{\"authorId\":\"145874826\",\"name\":\"K. Wei\"},{\"authorId\":\"1783839\",\"name\":\"K. Kirchhoff\"},{\"authorId\":\"1905180\",\"name\":\"Yisong Song\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"}],\"doi\":\"10.1109/ICASSP.2013.6639057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c5966153d57e2c53c17fce8a5ed6c0e3bc9f89a\",\"title\":\"Submodular feature selection for high-dimensional acoustic score spaces\",\"url\":\"https://www.semanticscholar.org/paper/6c5966153d57e2c53c17fce8a5ed6c0e3bc9f89a\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143616798\",\"name\":\"Zheng Lu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.350\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"title\":\"Story-Driven Summarization for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46933412\",\"name\":\"H. Lin\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5ce3e9636bed47b377405cd85d3a4abc3b3a234\",\"title\":\"A Class of Submodular Functions for Document Summarization\",\"url\":\"https://www.semanticscholar.org/paper/f5ce3e9636bed47b377405cd85d3a4abc3b3a234\",\"venue\":\"ACL\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"},{\"authorId\":\"29746945\",\"name\":\"A. Singh\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.1145/1390681.1390689\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d6380aebd96a1a0fdd5734067db814b91e5179a8\",\"title\":\"Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies\",\"url\":\"https://www.semanticscholar.org/paper/d6380aebd96a1a0fdd5734067db814b91e5179a8\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3351294\",\"name\":\"Yu-Fei Ma\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"40659377\",\"name\":\"L. Lu\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/TMM.2005.854410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4541e6605c73c2499d145fb3c8621b91fddf3a78\",\"title\":\"A generic framework of user attention model and its application in video summarization\",\"url\":\"https://www.semanticscholar.org/paper/4541e6605c73c2499d145fb3c8621b91fddf3a78\",\"venue\":\"IEEE Trans. Multim.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1207.6083\",\"authors\":[{\"authorId\":\"145500336\",\"name\":\"A. Kulesza\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"}],\"doi\":\"10.1561/2200000044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016\",\"title\":\"Determinantal Point Processes for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016\",\"venue\":\"Found. Trends Mach. Learn.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144340937\",\"name\":\"J. Gillenwater\"},{\"authorId\":\"145500336\",\"name\":\"A. Kulesza\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15acca25f75076b80b0bd24c5710c70733308c11\",\"title\":\"Near-Optimal MAP Inference for Determinantal Point Processes\",\"url\":\"https://www.semanticscholar.org/paper/15acca25f75076b80b0bd24c5710c70733308c11\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"Proc . ICCV\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-10584-0_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"title\":\"Creating Summaries from User Videos\",\"url\":\"https://www.semanticscholar.org/paper/799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":\"1311.2106\",\"authors\":[{\"authorId\":\"145074006\",\"name\":\"R. Iyer\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923445ab98ddf321a14bff989c9b38c236711aae\",\"title\":\"Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints\",\"url\":\"https://www.semanticscholar.org/paper/923445ab98ddf321a14bff989c9b38c236711aae\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46792849\",\"name\":\"A. Mishra\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/TPAMI.2011.171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e44c2685799373039d058c50f9e74a73c63dbc9c\",\"title\":\"Active Visual Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e44c2685799373039d058c50f9e74a73c63dbc9c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2537143\",\"name\":\"Suporn Pongnumkul\"},{\"authorId\":\"36541522\",\"name\":\"J. Wang\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1145/1449715.1449720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"102771ee6f39c056851c1c5f36421ed300e27adc\",\"title\":\"Creating map-based storyboards for browsing tour videos\",\"url\":\"https://www.semanticscholar.org/paper/102771ee6f39c056851c1c5f36421ed300e27adc\",\"venue\":\"UIST '08\",\"year\":2008},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"3351294\",\"name\":\"Yu-Fei Ma\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/ICCV.2003.1238320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b00391c156aee70682c5ed2c45c372b7312578\",\"title\":\"Automatic video summarization by graph modeling\",\"url\":\"https://www.semanticscholar.org/paper/20b00391c156aee70682c5ed2c45c372b7312578\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"31604982\",\"name\":\"Maxwell D. Collins\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2013.246\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fb4689e7ceca687c33b89fb6c43d4e9ea077aa\",\"title\":\"Incorporating User Interaction and Topological Constraints within Contour Completion via Discrete Calculus\",\"url\":\"https://www.semanticscholar.org/paper/17fb4689e7ceca687c33b89fb6c43d4e9ea077aa\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1406.5824\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a31da018246f4d67c5702574b7c16e14d261541\",\"title\":\"VideoSET: Video Summary Evaluation through Text\",\"url\":\"https://www.semanticscholar.org/paper/3a31da018246f4d67c5702574b7c16e14d261541\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2013.352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"title\":\"First-Person Activity Recognition: What Are They Doing to Me?\",\"url\":\"https://www.semanticscholar.org/paper/aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38510381\",\"name\":\"Jon Lee\"},{\"authorId\":\"1728881\",\"name\":\"V. Mirrokni\"},{\"authorId\":\"33633146\",\"name\":\"V. Nagarajan\"},{\"authorId\":\"145917065\",\"name\":\"M. Sviridenko\"}],\"doi\":\"10.1137/090750020\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"42214ef7379f192a71fe4cae313956dcd5c31bff\",\"title\":\"Maximizing Nonmonotone Submodular Functions under Matroid or Knapsack Constraints\",\"url\":\"https://www.semanticscholar.org/paper/42214ef7379f192a71fe4cae313956dcd5c31bff\",\"venue\":\"SIAM J. Discret. Math.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1145/1141911.1141967\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4548f9fbd5cc6fd149d92e4657b893e1b873b9a6\",\"title\":\"Schematic storyboarding for video visualization and editing\",\"url\":\"https://www.semanticscholar.org/paper/4548f9fbd5cc6fd149d92e4657b893e1b873b9a6\",\"venue\":\"SIGGRAPH 2006\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34616723\",\"name\":\"Mehdi Ellouze\"},{\"authorId\":\"1741155\",\"name\":\"N. Boujemaa\"},{\"authorId\":\"144000830\",\"name\":\"A. Alimi\"}],\"doi\":\"10.1016/j.jvcir.2010.01.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c9de80bb4f532f2a039ad65fd2aadc3c965fed5\",\"title\":\"IM(S)2: Interactive movie summarization system\",\"url\":\"https://www.semanticscholar.org/paper/5c9de80bb4f532f2a039ad65fd2aadc3c965fed5\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"Proc . ICCV\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39005747\",\"name\":\"D. Liu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/TPAMI.2010.31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfca01c257ca6ad4003ae7b736460b8da0a649b6\",\"title\":\"A Hierarchical Visual Model for Video Object Summarization\",\"url\":\"https://www.semanticscholar.org/paper/cfca01c257ca6ad4003ae7b736460b8da0a649b6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143979267\",\"name\":\"R. Hamid\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"},{\"authorId\":\"145507437\",\"name\":\"N. Sundaresan\"}],\"doi\":\"10.1109/CVPR.2013.348\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4b1fd34dabc3bc37aad39279bae9fa06b4a9dac\",\"title\":\"Large-Scale Video Summarization Using Web-Image Priors\",\"url\":\"https://www.semanticscholar.org/paper/e4b1fd34dabc3bc37aad39279bae9fa06b4a9dac\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1720424\",\"name\":\"Y. Guo\"},{\"authorId\":\"29565908\",\"name\":\"Yanshu Zhu\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"},{\"authorId\":\"2933335\",\"name\":\"Chuanming Song\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/TMM.2010.2052025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58142662e4b38e4a31ae8c7113793cb222445c9f\",\"title\":\"Multi-View Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/58142662e4b38e4a31ae8c7113793cb222445c9f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2010},{\"arxivId\":\"1204.4526\",\"authors\":[{\"authorId\":\"2363320\",\"name\":\"Yuval Filmus\"},{\"authorId\":\"144131927\",\"name\":\"Justin Ward\"}],\"doi\":\"10.1109/FOCS.2012.55\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4ec12f1467122269175c7a0dc5f22fc3b070894\",\"title\":\"A Tight Combinatorial Algorithm for Submodular Maximization Subject to a Matroid Constraint\",\"url\":\"https://www.semanticscholar.org/paper/b4ec12f1467122269175c7a0dc5f22fc3b070894\",\"venue\":\"2012 IEEE 53rd Annual Symposium on Foundations of Computer Science\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":null,\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2013.101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad2c0ae801c9e8adece483e74725e12a8544d440\",\"title\":\"Studying Relationships between Human Gaze, Description, and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/ad2c0ae801c9e8adece483e74725e12a8544d440\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/CVPR.2014.322\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91ee61105749d187f980a1995ace548516969a83\",\"title\":\"Quasi Real-Time Summarization for Consumer Videos\",\"url\":\"https://www.semanticscholar.org/paper/91ee61105749d187f980a1995ace548516969a83\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687322\",\"name\":\"O. Aghazadeh\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPR.2011.5995731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53dff6a36e9537a9d2547d471004d83e29cb8e19\",\"title\":\"Novelty detection from an ego-centric perspective\",\"url\":\"https://www.semanticscholar.org/paper/53dff6a36e9537a9d2547d471004d83e29cb8e19\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"39599498\",\"name\":\"C. Gu\"}],\"doi\":\"10.1109/CVPR.2010.5540074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"title\":\"Figure-ground segmentation improves handled object recognition in egocentric video\",\"url\":\"https://www.semanticscholar.org/paper/04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3243508\",\"name\":\"M. Kassner\"},{\"authorId\":\"2954413\",\"name\":\"William Patera\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8b2c8a6b15c84afd7f2fc4cb97ed21f8afbe3c7\",\"title\":\"PUPIL : constructing the space of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/e8b2c8a6b15c84afd7f2fc4cb97ed21f8afbe3c7\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"1695820\",\"name\":\"Guangda Li\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TMM.2012.2185041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e9a943f6f0160fc868b77cdb95e35b53f455faa\",\"title\":\"Event Driven Web Video Summarization by Tag Localization and Key-Shot Identification\",\"url\":\"https://www.semanticscholar.org/paper/7e9a943f6f0160fc868b77cdb95e35b53f455faa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.1145/1989734.1989736\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6971427e8f616e5e33d24674fa47b7a2ac69c0df\",\"title\":\"Submodularity and its applications in optimized information gathering\",\"url\":\"https://www.semanticscholar.org/paper/6971427e8f616e5e33d24674fa47b7a2ac69c0df\",\"venue\":\"TIST\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145136049\",\"name\":\"W. Wolf\"}],\"doi\":\"10.1109/ICASSP.1996.543588\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"16a48cbc05cff687e099266f9ab2d0b5ee508406\",\"title\":\"Key frame selection by motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/16a48cbc05cff687e099266f9ab2d0b5ee508406\",\"venue\":\"1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"title\":\"Diverse Sequential Subset Selection for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"},{\"authorId\":\"1756125\",\"name\":\"N. J. Leite\"},{\"authorId\":\"1679686\",\"name\":\"R. Torres\"}],\"doi\":\"10.1016/j.patrec.2011.08.007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"023dafbf5a0ce6228579c32a6590219162ebbcfb\",\"title\":\"VISON: VIdeo Summarization for ONline applications\",\"url\":\"https://www.semanticscholar.org/paper/023dafbf5a0ce6228579c32a6590219162ebbcfb\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713424\",\"name\":\"S. Fujishige\"}],\"doi\":\"10.1016/s0167-5060(05)x8001-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940bbae0fb3826e7dddfac290db3051eae2fee22\",\"title\":\"Submodular functions and optimization\",\"url\":\"https://www.semanticscholar.org/paper/940bbae0fb3826e7dddfac290db3051eae2fee22\",\"venue\":\"\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2013.326\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3955eba240340ff793003dd17aedbbce9305c9bb\",\"title\":\"Model Recommendation with Virtual Probes for Egocentric Hand Detection\",\"url\":\"https://www.semanticscholar.org/paper/3955eba240340ff793003dd17aedbbce9305c9bb\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733122\",\"name\":\"C. Chekuri\"},{\"authorId\":\"1733259\",\"name\":\"J. Vondr\\u00e1k\"},{\"authorId\":\"1746159\",\"name\":\"R. Zenklusen\"},{\"authorId\":\"1746159\",\"name\":\"R. Zenklusen\"}],\"doi\":\"10.1137/110839655\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c6017ac2ead8e2efcbd915ea484bf15f30e70391\",\"title\":\"Submodular Function Maximization via the Multilinear Relaxation and Contention Resolution Schemes\",\"url\":\"https://www.semanticscholar.org/paper/c6017ac2ead8e2efcbd915ea484bf15f30e70391\",\"venue\":\"\",\"year\":2014}],\"title\":\"Gaze-enabled egocentric video summarization via constrained submodular maximization\",\"topics\":[{\"topic\":\"Submodular set function\",\"topicId\":\"86\",\"url\":\"https://www.semanticscholar.org/topic/86\"},{\"topic\":\"Expectation\\u2013maximization algorithm\",\"topicId\":\"52938\",\"url\":\"https://www.semanticscholar.org/topic/52938\"},{\"topic\":\"Combinatorial optimization\",\"topicId\":\"30344\",\"url\":\"https://www.semanticscholar.org/topic/30344\"},{\"topic\":\"Partition matroid\",\"topicId\":\"1247340\",\"url\":\"https://www.semanticscholar.org/topic/1247340\"},{\"topic\":\"Shake\",\"topicId\":\"1137464\",\"url\":\"https://www.semanticscholar.org/topic/1137464\"},{\"topic\":\"Self-information\",\"topicId\":\"14163\",\"url\":\"https://www.semanticscholar.org/topic/14163\"},{\"topic\":\"Personalization\",\"topicId\":\"2873\",\"url\":\"https://www.semanticscholar.org/topic/2873\"},{\"topic\":\"Software documentation\",\"topicId\":\"10212\",\"url\":\"https://www.semanticscholar.org/topic/10212\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Expectation Maximization Algorithm\",\"topicId\":\"235204\",\"url\":\"https://www.semanticscholar.org/topic/235204\"},{\"topic\":\"Documented\",\"topicId\":\"4766\",\"url\":\"https://www.semanticscholar.org/topic/4766\"},{\"topic\":\"Frame (physical object)\",\"topicId\":\"4537\",\"url\":\"https://www.semanticscholar.org/topic/4537\"},{\"topic\":\"Digital camera\",\"topicId\":\"55559\",\"url\":\"https://www.semanticscholar.org/topic/55559\"},{\"topic\":\"Wearable computer\",\"topicId\":\"30581\",\"url\":\"https://www.semanticscholar.org/topic/30581\"},{\"topic\":\"videocassette\",\"topicId\":\"20721\",\"url\":\"https://www.semanticscholar.org/topic/20721\"},{\"topic\":\"Eye tracking\",\"topicId\":\"7621\",\"url\":\"https://www.semanticscholar.org/topic/7621\"},{\"topic\":\"Automatic summarization\",\"topicId\":\"36919\",\"url\":\"https://www.semanticscholar.org/topic/36919\"},{\"topic\":\"Used Quit Cigarette Smoking Videos\",\"topicId\":\"323362\",\"url\":\"https://www.semanticscholar.org/topic/323362\"},{\"topic\":\"Saccades\",\"topicId\":\"13584\",\"url\":\"https://www.semanticscholar.org/topic/13584\"}],\"url\":\"https://www.semanticscholar.org/paper/2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"