"{\"abstract\":\"Most state-of-the-art action feature extractors involve differential operators, which act as highpass filters and tend to attenuate low frequency action information. This attenuation introduces bias to the resulting features and generates ill-conditioned feature matrices. The Gaussian Pyramid has been used as a feature enhancing technique that encodes scale-invariant characteristics into the feature space in an attempt to deal with this attenuation. However, at the core of the Gaussian Pyramid is a convolutional smoothing operation, which makes it incapable of generating new features at coarse scales. In order to address this problem, we propose a novel feature enhancing technique called Multi-skIp Feature Stacking (MIFS), which stacks features extracted using a family of differential filters parameterized with multiple time skips and encodes shift-invariance into the frequency space. MIFS compensates for information lost from using differential operators by recapturing information at coarse scales. This recaptured information allows us to match actions at different speeds and ranges of motion. We prove that MIFS enhances the learnability of differential-based features exponentially. The resulting feature matrices from MIFS have much smaller conditional numbers and variances than those from conventional methods. Experimental results show significantly improved performance on challenging action recognition and event detection tasks. Specifically, our method exceeds the state-of-the-arts on Hollywood2, UCF101 and UCF50 datasets and is comparable to state-of-the-arts on HMDB51 and Olympics Sports datasets. MIFS can also be used as a speedup strategy for feature extraction with minimal or no accuracy cost.\",\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\",\"url\":\"https://www.semanticscholar.org/author/2362534\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\",\"url\":\"https://www.semanticscholar.org/author/144247571\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\",\"url\":\"https://www.semanticscholar.org/author/2314980\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\",\"url\":\"https://www.semanticscholar.org/author/7661726\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\",\"url\":\"https://www.semanticscholar.org/author/1681921\"}],\"citationVelocity\":37,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"152245395\",\"name\":\"Zexin Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2933303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"title\":\"Refined Spatial Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"46276092\",\"name\":\"Jiaming Li\"},{\"authorId\":\"144488755\",\"name\":\"H. Cheng\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1007/978-3-319-54526-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44e68bb3b0652fb51beab1db90c3762e8733f386\",\"title\":\"Multi-cue Information Fusion for Two-Layer Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/44e68bb3b0652fb51beab1db90c3762e8733f386\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-319-69900-4_70\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"title\":\"Two-Stream Convolutional Network with Multi-level Feature Fusion for Categorization of Human Action from Videos\",\"url\":\"https://www.semanticscholar.org/paper/bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Min Li\"},{\"authorId\":\"1500382990\",\"name\":\"Yuezhu Qi\"},{\"authorId\":\"72086292\",\"name\":\"Jian Yang\"},{\"authorId\":\"48379006\",\"name\":\"Y. Zhang\"},{\"authorId\":\"120532950\",\"name\":\"Junxing Ren\"},{\"authorId\":\"143859789\",\"name\":\"H. Du\"}],\"doi\":\"10.1109/ICTAI.2019.00250\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cabfd83ffc5109e7e26bb0f5a0045ddfa15ba379\",\"title\":\"3D Convolutional Two-Stream Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cabfd83ffc5109e7e26bb0f5a0045ddfa15ba379\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TSMC.2016.2625840\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"title\":\"Group Sparse-Based Mid-Level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1612.00558\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW.2017.205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57c59011614c43f51a509e10717e47505c776389\",\"title\":\"Unsupervised Human Action Detection by Action Matching\",\"url\":\"https://www.semanticscholar.org/paper/57c59011614c43f51a509e10717e47505c776389\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.05045\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"839a2155995acc0a053a326e283be12068b35cb8\",\"title\":\"Handcrafted Local Features are Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/839a2155995acc0a053a326e283be12068b35cb8\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/CVPR.2017.604\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143846985\",\"name\":\"Z. Li\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"3258842\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532921\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d691440030394c2e00a2ab47aba4f8b5fca5f25a\",\"title\":\"Tube ConvNets: Better exploiting motion for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d691440030394c2e00a2ab47aba4f8b5fca5f25a\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1505.06250\",\"authors\":[{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7608bc2f1901cb7711bf921b91e1d653c079e046\",\"title\":\"Efficient Large Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/7608bc2f1901cb7711bf921b91e1d653c079e046\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1608.08395\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1007/978-3-319-49409-8_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"31625522950e82ad4dffef7ed0df00fdd2401436\",\"title\":\"Motion Representation with Acceleration Images\",\"url\":\"https://www.semanticscholar.org/paper/31625522950e82ad4dffef7ed0df00fdd2401436\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39750827\",\"name\":\"A. Edison\"},{\"authorId\":\"46640675\",\"name\":\"C. Jiji\"}],\"doi\":\"10.1007/S11760-019-01428-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edbca157b8ebae3f5619f3a0a1c2969bca5e853e\",\"title\":\"Automated video analysis for action recognition using descriptors derived from optical acceleration\",\"url\":\"https://www.semanticscholar.org/paper/edbca157b8ebae3f5619f3a0a1c2969bca5e853e\",\"venue\":\"Signal Image Video Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.5244/c.31.125\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55934f5326f7c86f4a00bc2070723d49e250b307\",\"title\":\"Feature Sequence Representation Via Slow Feature Analysis For Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/55934f5326f7c86f4a00bc2070723d49e250b307\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/TMM.2018.2887021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"title\":\"Unsupervised Universal Attribute Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66471378\",\"name\":\"Allah Bux\"}],\"doi\":\"10.17635/LANCASTER/THESIS/186\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"title\":\"Vision-based human action recognition using machine learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"}],\"doi\":\"10.1109/TMM.2017.2749159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"title\":\"Two-Stream 3-D convNet Fusion for Action Recognition in Videos With Arbitrary Size and Length\",\"url\":\"https://www.semanticscholar.org/paper/93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"},{\"authorId\":\"2452789\",\"name\":\"L. Wang\"},{\"authorId\":\"2095855\",\"name\":\"B. Ma\"},{\"authorId\":\"1859062\",\"name\":\"Xingjian Gu\"}],\"doi\":\"10.1016/j.jvcir.2018.08.014\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6bb7e36612564868a7c880f8bd968250a1f3b40e\",\"title\":\"Evolution modeling with multi-scale smoothing for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6bb7e36612564868a7c880f8bd968250a1f3b40e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1909.04410\",\"authors\":[{\"authorId\":\"51294823\",\"name\":\"Chunxue Wu\"},{\"authorId\":\"152356699\",\"name\":\"Bobo Ju\"},{\"authorId\":\"145826495\",\"name\":\"N. Xiong\"},{\"authorId\":\"143887777\",\"name\":\"Guisong Yang\"},{\"authorId\":\"48607277\",\"name\":\"Y. Wu\"},{\"authorId\":\"49424575\",\"name\":\"H. Yang\"},{\"authorId\":\"103184509\",\"name\":\"Jiaying Huang\"},{\"authorId\":\"40285803\",\"name\":\"Z. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a2344fbaf24cf30e425533f88edcaecd25ef1d3\",\"title\":\"U-net super-neural segmentation and similarity calculation to realize vegetation change assessment in satellite imagery\",\"url\":\"https://www.semanticscholar.org/paper/7a2344fbaf24cf30e425533f88edcaecd25ef1d3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/VCIP47243.2019.8965878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"title\":\"A Spatio-temporal Hybrid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/s13735-016-0117-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"title\":\"Learning hierarchical video representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50589536\",\"name\":\"Fang Guo\"},{\"authorId\":\"2035901\",\"name\":\"Jianyu Zhao\"},{\"authorId\":\"50624383\",\"name\":\"Ping Jiang\"}],\"doi\":\"10.1109/CCDC.2019.8833046\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cdb3853c54c0bdc98807bb61c494e9d0afb2c10\",\"title\":\"Target Search via Feature Cutting Strategy of Visual Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/5cdb3853c54c0bdc98807bb61c494e9d0afb2c10\",\"venue\":\"2019 Chinese Control And Decision Conference (CCDC)\",\"year\":2019},{\"arxivId\":\"1605.04988\",\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.imavis.2017.01.010\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"title\":\"Going deeper into action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.1109/ICCV.2017.600\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"703c9c8f20860a1b1be63e6df1622b2021b003ca\",\"title\":\"Flip-Invariant Motion Representation\",\"url\":\"https://www.semanticscholar.org/paper/703c9c8f20860a1b1be63e6df1622b2021b003ca\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145594181\",\"name\":\"B. Zhu\"}],\"doi\":\"10.1007/978-3-030-03338-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"title\":\"Feature Aggregation Tree: Capture Temporal Motion Information for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144397879\",\"name\":\"S. N. Gowda\"}],\"doi\":\"10.1109/CVPRW.2017.203\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9df46ca568e4feda02cbe7fe87f7184d3daa773\",\"title\":\"Human Activity Recognition Using Combinatorial Deep Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/c9df46ca568e4feda02cbe7fe87f7184d3daa773\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48922817\",\"name\":\"Shuqing Xu\"},{\"authorId\":\"1886341\",\"name\":\"Haiyin Zhou\"},{\"authorId\":\"2682518\",\"name\":\"Jiongqi Wang\"},{\"authorId\":\"9239597\",\"name\":\"Zhangming He\"},{\"authorId\":\"9091627\",\"name\":\"D. Wang\"}],\"doi\":\"10.3390/s19132917\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72d0501edb740e59a8b9ee8dd0f9ea0c444f12f0\",\"title\":\"SINS/Landmark Integrated Navigation Based on Landmark Attitude Determination\",\"url\":\"https://www.semanticscholar.org/paper/72d0501edb740e59a8b9ee8dd0f9ea0c444f12f0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050512\",\"name\":\"Eman Mohammadi\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"145278886\",\"name\":\"M. Saif\"},{\"authorId\":\"2864059\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.097\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9edb61556c353340f53bddae2dea1145f4f11c6d\",\"title\":\"Hierarchical feature representation for unconstrained video analysis\",\"url\":\"https://www.semanticscholar.org/paper/9edb61556c353340f53bddae2dea1145f4f11c6d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.06.071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"title\":\"Action recognition using spatial-optical data organization and sequential learning framework\",\"url\":\"https://www.semanticscholar.org/paper/f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1503.04144\",\"authors\":[{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"1689313\",\"name\":\"Florian Luisier\"},{\"authorId\":\"144941335\",\"name\":\"Walter Andrews\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.5244/C.29.60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"title\":\"Exploiting Image-trained CNN Architectures for Unconstrained Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b47402a9a68f23b548ae6e0349700ea651b7a373\",\"title\":\"Action Recognition and Video Description using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/b47402a9a68f23b548ae6e0349700ea651b7a373\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"40508553\",\"name\":\"Y. Yu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/TPAMI.2016.2608901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc8fb68a7e3b79c37108588671c0e1abf374f501\",\"title\":\"Semantic Pooling for Complex Event Analysis in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/fc8fb68a7e3b79c37108588671c0e1abf374f501\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707706\",\"name\":\"Xiaoyu Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db1f48a7e11174d4a724a4edb3a0f1571d649670\",\"title\":\"Joint Constrained Clustering and Feature Learning based on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/db1f48a7e11174d4a724a4edb3a0f1571d649670\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3031655\",\"name\":\"Stavros Tachos\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1713991\",\"name\":\"Alexia Briassouli\"},{\"authorId\":\"1715604\",\"name\":\"Yiannis Kompatsiaris\"}],\"doi\":\"10.1016/j.cviu.2017.04.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b2812cf37440cc09a7e2734b927986b4027539b\",\"title\":\"Mining discriminative descriptors for goal-based activity detection\",\"url\":\"https://www.semanticscholar.org/paper/5b2812cf37440cc09a7e2734b927986b4027539b\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12277476\",\"name\":\"Lifei Song\"},{\"authorId\":\"1779987\",\"name\":\"Liguo Weng\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"47715056\",\"name\":\"Min Xia\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2018.8451662\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"title\":\"Two-Stream Designed 2D/3D Residual Networks with Lstms for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"},{\"authorId\":\"50656755\",\"name\":\"Qing Yuan Zhou\"},{\"authorId\":\"50424096\",\"name\":\"Nicolas Christou\"},{\"authorId\":\"145081360\",\"name\":\"Alan Loddon Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"title\":\"Electronic Theses and Dissertations Title Mining Spatial and Spatio-Temporal ROIs for Action Recognition Permalink\",\"url\":\"https://www.semanticscholar.org/paper/4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.05705\",\"authors\":[{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"2202745\",\"name\":\"Shicheng Xu\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"2228773\",\"name\":\"Zexi Mao\"},{\"authorId\":\"1727419\",\"name\":\"Zhigang Ma\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"1775194\",\"name\":\"H. Li\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144811744\",\"name\":\"L. Jiang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2742322\",\"name\":\"Xingzhong Du\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"}],\"doi\":\"10.3169/MTA.4.227\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da22f15a2fd190c743268e762fa188347dbede33\",\"title\":\"Strategies for Searching Video Content with Text Queries or Video Examples\",\"url\":\"https://www.semanticscholar.org/paper/da22f15a2fd190c743268e762fa188347dbede33\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1602.00224\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2019.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"title\":\"Order-aware Convolutional Pooling for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"134151536\",\"name\":\"J. Del Ser\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"},{\"authorId\":\"51905607\",\"name\":\"V. H. C. de Albuquerque\"}],\"doi\":\"10.1109/TIE.2018.2881943\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67683171c2000e5194e50996802d39c72000b5e6\",\"title\":\"Activity Recognition Using Temporal Optical Flow Convolutional Features and Multilayer LSTM\",\"url\":\"https://www.semanticscholar.org/paper/67683171c2000e5194e50996802d39c72000b5e6\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/TIP.2019.2922826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"title\":\"Compact and Low-Complexity Binary Feature Descriptor and Fisher Vectors for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"33890734\",\"name\":\"Georgios D. Evangelidis\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1109/WACV.2017.31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11b87cf0b9fbf404a77d02c20f45521cd52c081e\",\"title\":\"Recognition of Group Activities in Videos Based on Single-and Two-Person Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/11b87cf0b9fbf404a77d02c20f45521cd52c081e\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"1481734737\",\"name\":\"Lu Jiang\"},{\"authorId\":\"47420553\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"34692532\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"2202745\",\"name\":\"Shicheng Xu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"2228773\",\"name\":\"Zexi Mao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"2742322\",\"name\":\"Xingzhong Du\"},{\"authorId\":\"1515708419\",\"name\":\"Y. Cai\"},{\"authorId\":\"143945660\",\"name\":\"L. Martin\"},{\"authorId\":\"48978819\",\"name\":\"Nikolas Wolfe\"},{\"authorId\":\"47311290\",\"name\":\"Anurag Kumar\"},{\"authorId\":\"30841900\",\"name\":\"H. Li\"},{\"authorId\":\"144247566\",\"name\":\"M. Lin\"},{\"authorId\":\"1727419\",\"name\":\"Zhigang Ma\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"26957307\",\"name\":\"Deyu Meng\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"144804455\",\"name\":\"S. Burger\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1798727\",\"name\":\"R. Singh\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"},{\"authorId\":\"152439009\",\"name\":\"R. Stern\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bffc7e6e7b752ba631dfa65d244b60c63c7d2a46\",\"title\":\"CMU Informedia@TRECVID 2015: MED/SIN/LNK/SED\",\"url\":\"https://www.semanticscholar.org/paper/bffc7e6e7b752ba631dfa65d244b60c63c7d2a46\",\"venue\":\"TRECVID\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7769579\",\"name\":\"Zhikang Liu\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"}],\"doi\":\"10.1109/ICIP.2017.8296405\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81d232e1f432db7de67baf4f30f240c62d1a9055\",\"title\":\"Improving human action recognitionby temporal attention\",\"url\":\"https://www.semanticscholar.org/paper/81d232e1f432db7de67baf4f30f240c62d1a9055\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145123117\",\"name\":\"Rui Zhao\"},{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145984784\",\"name\":\"Hui Su\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1109/CVPR.2019.00792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc2597d0e7824d8d2db28bf3859428d6f17e0b04\",\"title\":\"Bayesian Hierarchical Dynamic Model for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc2597d0e7824d8d2db28bf3859428d6f17e0b04\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2dc29e0db76122dfed075c3b9ee48503b027809\",\"title\":\"How scenes imply actions in realistic videos?\",\"url\":\"https://www.semanticscholar.org/paper/c2dc29e0db76122dfed075c3b9ee48503b027809\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24944572\",\"name\":\"Shahela Saif\"},{\"authorId\":\"51935429\",\"name\":\"Samabia Tehseen\"},{\"authorId\":\"1880755\",\"name\":\"Sumaira Kausar\"}],\"doi\":\"10.3390/s18113979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe4aa088362d371daf15ccf9290291c8867e4f23\",\"title\":\"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/fe4aa088362d371daf15ccf9290291c8867e4f23\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708998\",\"name\":\"Nguyen Anh Tu\"},{\"authorId\":\"1402997421\",\"name\":\"Thien Huynh-The\"},{\"authorId\":\"46581230\",\"name\":\"K. Khan\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/TCSVT.2018.2816960\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c0d23485c0ece214000ff8c0dcb3042bc114048\",\"title\":\"ML-HDP: A Hierarchical Bayesian Nonparametric Model for Recognizing Human Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/5c0d23485c0ece214000ff8c0dcb3042bc114048\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9521309\",\"name\":\"Reem Alfaifi\"},{\"authorId\":\"46845102\",\"name\":\"A M Artoli\"}],\"doi\":\"10.1007/s42979-020-00293-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"title\":\"Human Action Prediction with 3D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1502.07209\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"49606697\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TPAMI.2017.2670560\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"title\":\"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677670\",\"name\":\"H. Kim\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"14090815\",\"name\":\"Seunghyeon Ko\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1117/1.OE.55.5.053108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9642adb0999d035d7589012d6ec05d618a223d33\",\"title\":\"Weighing classes and streams: toward better methods for two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/9642adb0999d035d7589012d6ec05d618a223d33\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145309464\",\"name\":\"Min Jiang\"},{\"authorId\":\"51010977\",\"name\":\"N. Pan\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"}],\"doi\":\"10.1016/j.jvcir.2020.102846\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"title\":\"Spatial-temporal saliency action mask attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2964284.2964328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"899be93e14d991017b1f8a4afdf907cbc03cf300\",\"title\":\"Multi-Stream Multi-Class Fusion of Deep Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/899be93e14d991017b1f8a4afdf907cbc03cf300\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c285082615c8ef7301321e457c91905b40d2a39\",\"title\":\"UTS-CMU at THUMOS 2015\",\"url\":\"https://www.semanticscholar.org/paper/4c285082615c8ef7301321e457c91905b40d2a39\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727419\",\"name\":\"Zhigang Ma\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TNNLS.2017.2709308\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cec70cf159b51a18b39c80fac1ad34f65f3691ef\",\"title\":\"Joint Attributes and Event Analysis for Multimedia Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/cec70cf159b51a18b39c80fac1ad34f65f3691ef\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30075877\",\"name\":\"W. Ye\"},{\"authorId\":\"120971374\",\"name\":\"J. Cheng\"},{\"authorId\":\"145976802\",\"name\":\"F. Yang\"},{\"authorId\":\"48615395\",\"name\":\"Y. Xu\"}],\"doi\":\"10.1109/access.2019.2918808\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"title\":\"Two-Stream Convolutional Network for Improving Activity Recognition Using Convolutional Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e28779e52455967a942a28cd35a135b42509ed8\",\"title\":\"Deep Learning Models for Unsupervised and Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/4e28779e52455967a942a28cd35a135b42509ed8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":null,\"name\":\"Gedas Bertasius\"},{\"authorId\":null,\"name\":\"Tae-Hyun Oh\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"38203359\",\"name\":\"Jialie Shen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2911451.2914765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbbc93afd4b3ac2a9641c6081f1fe75f4a6b2148\",\"title\":\"Which Information Sources are More Effective and Reliable in Video Search\",\"url\":\"https://www.semanticscholar.org/paper/dbbc93afd4b3ac2a9641c6081f1fe75f4a6b2148\",\"venue\":\"SIGIR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7671146\",\"name\":\"Shugang Zhang\"},{\"authorId\":\"145815630\",\"name\":\"Z. Wei\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"48545182\",\"name\":\"L. Huang\"},{\"authorId\":\"50695608\",\"name\":\"S. Wang\"},{\"authorId\":\"1700892\",\"name\":\"Z. Li\"}],\"doi\":\"10.1155/2017/3090343\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bbbe65f6b4a01152b467a1376dfcf9203690013\",\"title\":\"A Review on Human Activity Recognition Using Vision-Based Method\",\"url\":\"https://www.semanticscholar.org/paper/8bbbe65f6b4a01152b467a1376dfcf9203690013\",\"venue\":\"Journal of healthcare engineering\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26946124\",\"name\":\"I. Bakkouri\"},{\"authorId\":\"2505117\",\"name\":\"K. Afdel\"}],\"doi\":\"10.1007/s11042-018-6267-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7e6585303e7b5a566ed4c75e903c3ad150170f5\",\"title\":\"Multi-scale CNN based on region proposals for efficient breast abnormality recognition\",\"url\":\"https://www.semanticscholar.org/paper/f7e6585303e7b5a566ed4c75e903c3ad150170f5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1604.08826\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2859204\",\"name\":\"Masatoshi Hidaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"title\":\"Improved Dense Trajectory with Cross Streams\",\"url\":\"https://www.semanticscholar.org/paper/da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1512.06498\",\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"69fb98e11df56b5d7ec7d45442af274889e4be52\",\"title\":\"Harnessing the Deep Net Object Models for Enhancing Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69fb98e11df56b5d7ec7d45442af274889e4be52\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1807.08259\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/978-3-030-01225-0_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fef65bd7287b57f0c3b36bf8e6bc987fd161b7d\",\"title\":\"Deep Discriminative Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/6fef65bd7287b57f0c3b36bf8e6bc987fd161b7d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1705.10420\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-017-1030-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5615d6045301ecbc5be35e46cab711f676aadf3a\",\"title\":\"Discriminatively Learned Hierarchical Rank Pooling Networks\",\"url\":\"https://www.semanticscholar.org/paper/5615d6045301ecbc5be35e46cab711f676aadf3a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1503.07274\",\"authors\":[{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc5bdb98ff97581d7c1e5eb2d24d3f10714aa192\",\"title\":\"Initialization Strategies of Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fc5bdb98ff97581d7c1e5eb2d24d3f10714aa192\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1701.01821\",\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"3378457\",\"name\":\"Boya Peng\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"title\":\"Unsupervised Learning of Long-Term Motion Dynamics for Videos\",\"url\":\"https://www.semanticscholar.org/paper/cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"title\":\"Multi-Level ResNets with Stacked SRUs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1710.03383\",\"authors\":[{\"authorId\":\"2682151\",\"name\":\"Cheng-Bin Jin\"},{\"authorId\":\"2707231\",\"name\":\"Shengzhe Li\"},{\"authorId\":\"1697362\",\"name\":\"H. Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"208e903211ddc62b997afb5a1bd3c2c43e0e69ee\",\"title\":\"Real-Time Action Detection in Video Surveillance using Sub-Action Descriptor with Multi-CNN\",\"url\":\"https://www.semanticscholar.org/paper/208e903211ddc62b997afb5a1bd3c2c43e0e69ee\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144997028\",\"name\":\"L. Li\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"title\":\"Deep Temporal Feature Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"72399895\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"title\":\"Multi-kernel learning of deep convolutional features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2088899\",\"name\":\"Daria Stefic\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":\"10.1016/j.imavis.2016.06.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3898c085d2f72b516c072f083a45a31fb2b9415f\",\"title\":\"Action recognition using saliency learned from recorded human gaze\",\"url\":\"https://www.semanticscholar.org/paper/3898c085d2f72b516c072f083a45a31fb2b9415f\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"38203359\",\"name\":\"Jialie Shen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95b02c332acea3908ab0f008e17e407eb949d7aa\",\"title\":\"CMU-SMU@TRECVID 2015: Video Hyperlinking\",\"url\":\"https://www.semanticscholar.org/paper/95b02c332acea3908ab0f008e17e407eb949d7aa\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037859\",\"name\":\"Saddam Bekhet\"},{\"authorId\":\"143629707\",\"name\":\"Amr Ahmed\"}],\"doi\":\"10.1145/3190784\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"43c3b6a564b284382fdf8ae33f974f4e7a89600e\",\"title\":\"An Integrated Signature-Based Framework for Efficient Visual Similarity Detection and Measurement in Video Shots\",\"url\":\"https://www.semanticscholar.org/paper/43c3b6a564b284382fdf8ae33f974f4e7a89600e\",\"venue\":\"ACM Trans. Inf. Syst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"}],\"doi\":\"10.1016/j.neucom.2018.02.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"title\":\"Action recognition with motion map 3D network\",\"url\":\"https://www.semanticscholar.org/paper/c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1512.03740\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a990a90bd2fec01f198821c01be4e34d840be644\",\"title\":\"Improving Human Activity Recognition Through Ranking and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/a990a90bd2fec01f198821c01be4e34d840be644\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"145067864\",\"name\":\"De Cheng\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/ICCV.2017.86\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce028bc6cf5dfb1a403c8d2972a540d295959c1c\",\"title\":\"Complex Event Detection by Identifying Reliable Shots from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/ce028bc6cf5dfb1a403c8d2972a540d295959c1c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18080084\",\"name\":\"Qingya Huang\"},{\"authorId\":\"145107805\",\"name\":\"S. Sun\"},{\"authorId\":\"47939010\",\"name\":\"Feng Wang\"}],\"doi\":\"10.1109/ICASSP.2017.7952460\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67ba3524e135c1375c74fe53ebb03684754aae56\",\"title\":\"A compact pairwise trajectory representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67ba3524e135c1375c74fe53ebb03684754aae56\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"},{\"authorId\":\"2452789\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.neucom.2017.07.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33fdaa747900d8952c0d371e8903c6531e357f93\",\"title\":\"Action recognition by Latent Duration Model\",\"url\":\"https://www.semanticscholar.org/paper/33fdaa747900d8952c0d371e8903c6531e357f93\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40867803\",\"name\":\"L. He\"},{\"authorId\":\"47447118\",\"name\":\"M. Wang\"},{\"authorId\":\"89486785\",\"name\":\"Y. Zhu\"},{\"authorId\":\"47702580\",\"name\":\"X. Chang\"},{\"authorId\":\"48971514\",\"name\":\"Xiaoxiao Feng\"}],\"doi\":\"10.3390/s19112619\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bdf6b203358d91b8fb43b7a00bc49e19c0490aa\",\"title\":\"Image Fusion for High-Resolution Optical Satellites Based on Panchromatic Spectral Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/0bdf6b203358d91b8fb43b7a00bc49e19c0490aa\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"40495154\",\"name\":\"M. Hayashi\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.5244/C.30.12\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b063f4a71a7561ea401ea52d49c8fb8348021355\",\"title\":\"Recognition of Transitional Action for Short-Term Action Prediction using Discriminative Temporal CNN Feature\",\"url\":\"https://www.semanticscholar.org/paper/b063f4a71a7561ea401ea52d49c8fb8348021355\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50177300\",\"name\":\"X. Hua\"},{\"authorId\":\"144221448\",\"name\":\"Xinqing Wang\"},{\"authorId\":null,\"name\":\"Dong Wang\"},{\"authorId\":\"50535195\",\"name\":\"Jie Huang\"},{\"authorId\":\"72381424\",\"name\":\"X. Hu\"}],\"doi\":\"10.3390/ELECTRONICS7100216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb7fb93abe4149732e9b08816c92b5e165129043\",\"title\":\"Military Object Real-Time Detection Technology Combined with Visual Salience and Psychology\",\"url\":\"https://www.semanticscholar.org/paper/bb7fb93abe4149732e9b08816c92b5e165129043\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1049/iet-cvi.2017.0005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"title\":\"Fully convolutional networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"40546560\",\"name\":\"Qingquan Sun\"}],\"doi\":\"10.1016/j.neucom.2016.09.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"title\":\"Action recognition by saliency-based dense sampling\",\"url\":\"https://www.semanticscholar.org/paper/6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1904.11953\",\"authors\":[{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"8280915\",\"name\":\"Yunpeng Song\"},{\"authorId\":\"27899522\",\"name\":\"J. Zhang\"},{\"authorId\":\"1783892\",\"name\":\"J. Han\"},{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61367718a07bafbd696871be25e11815f1dd85c4\",\"title\":\"Temporal Unet: Sample Level Human Action Recognition using WiFi\",\"url\":\"https://www.semanticscholar.org/paper/61367718a07bafbd696871be25e11815f1dd85c4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1706.04508\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TMM.2018.2823900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"title\":\"Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1007/s11263-016-0918-1\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"6c9e1a9c1136a557a2f4a36eba43442c0a731010\",\"title\":\"Complex\\u00a0Activity\\u00a0Recognition Via Attribute\\u00a0Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/6c9e1a9c1136a557a2f4a36eba43442c0a731010\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845611487\",\"name\":\"L. Chen\"},{\"authorId\":null,\"name\":\"Liu Rui\"},{\"authorId\":null,\"name\":\"Zhou Dongsheng\"},{\"authorId\":null,\"name\":\"Xin Yang\"},{\"authorId\":null,\"name\":\"Qiang Zhang\"},{\"authorId\":null,\"name\":\"Wei Xiaopeng\"}],\"doi\":\"10.1007/978-3-030-63426-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"title\":\"ESENet: A Human Behavior Recognition Model Based on Extended Squeeze-and-Excitation Network\",\"url\":\"https://www.semanticscholar.org/paper/62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"1702330\",\"name\":\"R. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"title\":\"Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP7010110\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a87e37d43d4c47bef8992ace408de0f872739efc\",\"title\":\"A Comprehensive Review on Handcrafted and Learning-Based Action Representation Approaches for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a87e37d43d4c47bef8992ace408de0f872739efc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144861485\",\"name\":\"Z. Ma\"},{\"authorId\":\"3261741\",\"name\":\"Z. Sun\"}],\"doi\":\"10.1007/s11042-018-6260-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8613fef2738325a5697e253276b160099100528d\",\"title\":\"Time-varying LSTM networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8613fef2738325a5697e253276b160099100528d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145674667\",\"name\":\"J. Miao\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"2704537\",\"name\":\"Shuoyang Qiu\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2015.2490551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e1e195f294c463f4832c4686775bf386b3de39\",\"title\":\"Temporal Variance Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93e1e195f294c463f4832c4686775bf386b3de39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877834352\",\"name\":\"Sukrit Bhattacharya\"},{\"authorId\":\"1877778893\",\"name\":\"Vaibhav Shaw\"},{\"authorId\":\"143730686\",\"name\":\"P. Singh\"},{\"authorId\":\"70680168\",\"name\":\"R. Sarkar\"},{\"authorId\":\"89542097\",\"name\":\"D. Bhattacharjee\"}],\"doi\":\"10.1007/978-3-030-49345-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae92267620dcebcc38ffb1258344ab8dd21fa635\",\"title\":\"SV-NET: A Deep Learning Approach to Video Based Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae92267620dcebcc38ffb1258344ab8dd21fa635\",\"venue\":\"SoCPaR\",\"year\":2019},{\"arxivId\":\"1504.01561\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2733373.2806222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fd06a73e7970181bfd87fa4d6c340bc99373069\",\"title\":\"Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/2fd06a73e7970181bfd87fa4d6c340bc99373069\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"1721819\",\"name\":\"D. Zhan\"},{\"authorId\":\"144788045\",\"name\":\"Ying Fan\"},{\"authorId\":\"2192443\",\"name\":\"Yuan Jiang\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"bc8e11b8cdf0cfbedde798a53a0318e8d6f67e17\",\"title\":\"Deep Learning for Fixed Model Reuse\",\"url\":\"https://www.semanticscholar.org/paper/bc8e11b8cdf0cfbedde798a53a0318e8d6f67e17\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"}],\"doi\":\"10.1109/ICME.2018.8486452\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"title\":\"Temporal Attentive Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35153466\",\"name\":\"E. M. Pereira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c6a9c4590b260600f9554af5696304fb65925aa\",\"title\":\"Humans in Action at Different Levels: the group, the whole, and the parts\",\"url\":\"https://www.semanticscholar.org/paper/5c6a9c4590b260600f9554af5696304fb65925aa\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151443666\",\"name\":\"Shaharyar Alam Ansari\"},{\"authorId\":\"11287311\",\"name\":\"A. Zafar\"}],\"doi\":\"10.1007/978-981-15-0339-9_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59f6cd5794825780dda7b608a92d5506503270a7\",\"title\":\"A Review on Video Analytics Its Challenges and Applications\",\"url\":\"https://www.semanticscholar.org/paper/59f6cd5794825780dda7b608a92d5506503270a7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1512.07155\",\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1016/j.patcog.2017.01.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"title\":\"Do less and achieve more: Training CNNs for action recognition utilizing action images from the Web\",\"url\":\"https://www.semanticscholar.org/paper/ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.08652\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"35061362\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/CVPR.2017.52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"title\":\"Scene Flow to Action Map: A New Representation for RGB-D Based Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.04339\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-319-46604-0_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9abd35b37a49ee1295e8197aac59bde802a934f3\",\"title\":\"Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9abd35b37a49ee1295e8197aac59bde802a934f3\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"1706028\",\"name\":\"L. Yang\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"2864709\",\"name\":\"F. Chao\"},{\"authorId\":\"48968697\",\"name\":\"R. Song\"},{\"authorId\":\"31851271\",\"name\":\"YanPeng Qu\"}],\"doi\":\"10.1109/TII.2019.2957268\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3bbe379ef5f12cab36ba86d93ec40b1fbe133b7\",\"title\":\"Histogram of Fuzzy Local Spatio-Temporal Descriptors for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3bbe379ef5f12cab36ba86d93ec40b1fbe133b7\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153122996\",\"name\":\"Josep Maria Carmona\"},{\"authorId\":\"145105992\",\"name\":\"J. Climent\"}],\"doi\":\"10.1016/j.patcog.2018.04.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17334201466dae9a7fa0c74e93472e1bb278fa80\",\"title\":\"Human action recognition by means of subtensor projections and dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/17334201466dae9a7fa0c74e93472e1bb278fa80\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"49308184\",\"name\":\"Y. Yang\"},{\"authorId\":\"143822920\",\"name\":\"He Jiang\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"2585506\",\"name\":\"G. Wang\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/RCAR.2018.8621829\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"title\":\"Action Recognition and Localization with Instance FCNN\",\"url\":\"https://www.semanticscholar.org/paper/ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"venue\":\"2018 IEEE International Conference on Real-time Computing and Robotics (RCAR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"143792007\",\"name\":\"Peng Duan\"},{\"authorId\":\"2095855\",\"name\":\"B. Ma\"},{\"authorId\":\"144044737\",\"name\":\"P. Wu\"},{\"authorId\":\"2882531\",\"name\":\"Weizhi Lu\"}],\"doi\":\"10.1016/J.JVCIR.2019.04.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"735ddb487ed4efdbffd83239019662ba6c584c63\",\"title\":\"Action recognition using dynamic hierarchical trees\",\"url\":\"https://www.semanticscholar.org/paper/735ddb487ed4efdbffd83239019662ba6c584c63\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1609.02770\",\"authors\":[{\"authorId\":\"1954884\",\"name\":\"A. Gilbert\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1016/j.cviu.2017.02.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f484475fb5b25212e541ec153babf1a2ad9ab546\",\"title\":\"Image and video mining through online learning\",\"url\":\"https://www.semanticscholar.org/paper/f484475fb5b25212e541ec153babf1a2ad9ab546\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.01.016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"title\":\"Video you only look once: Overall temporal convolutions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143627655\",\"name\":\"Guan Luo\"},{\"authorId\":\"1387518609\",\"name\":\"Jiutong Wei\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2019.2955561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be8d5cc013082e9ac8b5588c04177953a2d5047e\",\"title\":\"Tangent Fisher Vector on Matrix Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be8d5cc013082e9ac8b5588c04177953a2d5047e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shoou-I Yu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":null,\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Shicheng Xu\"},{\"authorId\":null,\"name\":\"Deyu Meng\"},{\"authorId\":null,\"name\":\"Zexi Mao\"},{\"authorId\":null,\"name\":\"Zhigang Ma\"},{\"authorId\":null,\"name\":\"Ming Lin\"},{\"authorId\":null,\"name\":\"Xuanchong Li\"},{\"authorId\":null,\"name\":\"Huan Li\"},{\"authorId\":null,\"name\":\"Zhenzhong Lan\"},{\"authorId\":null,\"name\":\"Lu Jiang\"},{\"authorId\":null,\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":null,\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Xingzhong Du\"},{\"authorId\":null,\"name\":\"Xiaojun Chang\"}],\"doi\":\"10.3169/MTA.4.227\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f5e4f489260bf7713e361b0a24e999d345daacf\",\"title\":\"[Invited Paper] Strategies for Searching Video Content with Text Queries or Video Examples: Features, Semantic Detectors, Fusion, Efficient Search and Reranking\",\"url\":\"https://www.semanticscholar.org/paper/4f5e4f489260bf7713e361b0a24e999d345daacf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571637\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/TIP.2018.2866688\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"title\":\"Learning Match Kernels on Grassmann Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1909.01954\",\"authors\":[{\"authorId\":\"20772402\",\"name\":\"B. Gatto\"},{\"authorId\":\"2657966\",\"name\":\"E. M. D. Santos\"},{\"authorId\":\"1808179\",\"name\":\"Alessandro Lameiras Koerich\"},{\"authorId\":\"1770128\",\"name\":\"K. Fukui\"},{\"authorId\":\"144996736\",\"name\":\"Waldir S. S. Junior\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc8395a520a79ffe636dd3fb2d03889529baa211\",\"title\":\"Tensor Analysis with n-Mode Generalized Difference Subspace\",\"url\":\"https://www.semanticscholar.org/paper/bc8395a520a79ffe636dd3fb2d03889529baa211\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1509.06086\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":null,\"name\":\"Jun Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc9443e3ae2fe70282b1b30e3eda3717b58c0808\",\"title\":\"Fusing Multi-Stream Deep Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc9443e3ae2fe70282b1b30e3eda3717b58c0808\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"1612.00881\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1109/CVPR.2017.278\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f31de384bee955d8faffa1efe5f7b51cb299381\",\"title\":\"Procedural Generation of Videos to Train Deep Action Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f31de384bee955d8faffa1efe5f7b51cb299381\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.08089\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1016/j.cviu.2016.10.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"title\":\"A bag-of-words equivalent recurrent neural network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1016/j.patcog.2018.07.028\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"756532d707209f13c44b96e6306ac0c96e6733a5\",\"title\":\"Asymmetric 3D Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/756532d707209f13c44b96e6306ac0c96e6733a5\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1872087\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"7824818\",\"name\":\"X. Li\"},{\"authorId\":\"2930187\",\"name\":\"Xiangyin Zhang\"}],\"doi\":\"10.1117/1.JEI.27.1.013021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ff85791b84e146c47e5b0e3828d34b47d5edf4c\",\"title\":\"Weighted score-level feature fusion based on Dempster\\u2013Shafer evidence theory for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ff85791b84e146c47e5b0e3828d34b47d5edf4c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136515\",\"name\":\"Hanmo Wang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"145770650\",\"name\":\"Lei Shi\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":\"10.24963/ijcai.2018/134\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5245dc1ed49e9f5e39df28226613804ddcaa2c51\",\"title\":\"Uncertainty Sampling for Action Recognition via Maximizing Expected Average Precision\",\"url\":\"https://www.semanticscholar.org/paper/5245dc1ed49e9f5e39df28226613804ddcaa2c51\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"47059230\",\"name\":\"L. Zhang\"},{\"authorId\":\"46665820\",\"name\":\"Lin Mei\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"}],\"doi\":\"10.1109/ICPR.2016.7899601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1866a3671c9af4dcf6f0236e13a960851669ea6\",\"title\":\"Large-scale Isolated Gesture Recognition using pyramidal 3D convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/c1866a3671c9af4dcf6f0236e13a960851669ea6\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1708.09522\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c51069d03974bd28dd821142a852ec24ce7546a\",\"title\":\"Action Classification and Highlighting in Videos\",\"url\":\"https://www.semanticscholar.org/paper/2c51069d03974bd28dd821142a852ec24ce7546a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2751145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4289f9f727af39414537a97e5eef90b06115a5db\",\"title\":\"Global-Local Temporal Saliency Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4289f9f727af39414537a97e5eef90b06115a5db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145821437\",\"name\":\"X. Shen\"},{\"authorId\":\"34853867\",\"name\":\"Lelin Zhang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1109/MMSP.2015.7340811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82d756d1ccc0577f44c096ac5069f6e0584ab5fc\",\"title\":\"Spatial-temporal correlation for trajectory based action video retrieval\",\"url\":\"https://www.semanticscholar.org/paper/82d756d1ccc0577f44c096ac5069f6e0584ab5fc\",\"venue\":\"2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3379311\",\"name\":\"Slawomir Wojciechowski\"},{\"authorId\":\"3043492\",\"name\":\"M. Kulbacki\"},{\"authorId\":\"2554241\",\"name\":\"J. Segen\"},{\"authorId\":\"3366961\",\"name\":\"Rafal Wycislok\"},{\"authorId\":\"49829226\",\"name\":\"Artur Bak\"},{\"authorId\":\"2722816\",\"name\":\"Kamil Wereszczynski\"},{\"authorId\":\"1758579\",\"name\":\"K. Wojciechowski\"}],\"doi\":\"10.1007/978-3-662-49390-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6226918e098fb9570519656ebab83a6d76bda674\",\"title\":\"Selected Space-Time Based Methods for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6226918e098fb9570519656ebab83a6d76bda674\",\"venue\":\"ACIIDS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2024681181\",\"name\":\"Meng Bo\"},{\"authorId\":\"2024647262\",\"name\":\"Liu Xuejun\"},{\"authorId\":\"2024198442\",\"name\":\"Wang Xiaolin\"}],\"doi\":\"10.1007/S11042-018-5893-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e312094275173ea0eb07633de9fae0a36cb41574\",\"title\":\"Human action recognition based on quaternion spatial-temporal convolutional neural network and LSTM in RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/e312094275173ea0eb07633de9fae0a36cb41574\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":\"1706.07911\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"50152762\",\"name\":\"Sen Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"title\":\"Large-Scale Human Activity Mapping using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.05465\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f257300b2b4141aab73f93c146bf94846aef5fa1\",\"title\":\"Eigen Evolution Pooling for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f257300b2b4141aab73f93c146bf94846aef5fa1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145188795\",\"name\":\"Eman M. Nejad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b54f5d3cb2ff5102e2bd9a6ab01d4ef858c1aa2\",\"title\":\"Simple and Complex Human Action Recognition in Constrained and Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/7b54f5d3cb2ff5102e2bd9a6ab01d4ef858c1aa2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2050485\",\"name\":\"Bo Meng\"},{\"authorId\":\"2473922\",\"name\":\"X. Liu\"},{\"authorId\":\"1695583\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/s11042-018-5893-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f57a427072604126ca65e907f985534289ffb73\",\"title\":\"Human action recognition based on quaternion spatial-temporal convolutional neural network and LSTM in RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/1f57a427072604126ca65e907f985534289ffb73\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1705.06709\",\"authors\":[{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"},{\"authorId\":\"32484187\",\"name\":\"S. Adali\"}],\"doi\":\"10.1109/CVPRW.2017.44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94abe0f71c6270ce67ab74d296fa56e5a00ca965\",\"title\":\"Learning Spatiotemporal Features for Infrared Action Recognition with 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/94abe0f71c6270ce67ab74d296fa56e5a00ca965\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"8025372\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/DICTA.2016.7797041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91f1c7c6f272a1d194ac6e845e348b90b965680d\",\"title\":\"Fast Binary-Based Video Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/91f1c7c6f272a1d194ac6e845e348b90b965680d\",\"venue\":\"2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"4509077\",\"name\":\"Xiaowei Gu\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"152734957\",\"name\":\"Zulfiqar Habib\"}],\"doi\":\"10.1007/s11042-020-09381-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"title\":\"Human action recognition using deep rule-based classifier\",\"url\":\"https://www.semanticscholar.org/paper/8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7821599\",\"name\":\"M. Fan\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"3779849\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Di Wang\"},{\"authorId\":\"47622465\",\"name\":\"Liang Du\"}],\"doi\":\"10.24963/ijcai.2017/228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a888b9064c18c2f8a1b1ff2b8f553f5f07ff5abd\",\"title\":\"Top-k Supervise Feature Selection via ADMM for Integer Programming\",\"url\":\"https://www.semanticscholar.org/paper/a888b9064c18c2f8a1b1ff2b8f553f5f07ff5abd\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34692532\",\"name\":\"Zhenzhong Lan\"}],\"doi\":\"10.1145/2733373.2807996\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"68f8983e9db7322c88587bfe679af1b5734a1148\",\"title\":\"Learn to Recognize Actions Through Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68f8983e9db7322c88587bfe679af1b5734a1148\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1601.02129\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a82860d11fcbf12628724333f1e7ada8f3cd255\",\"title\":\"Action Temporal Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/0a82860d11fcbf12628724333f1e7ada8f3cd255\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.imavis.2016.02.006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7a5fcb9ddaf3232b33aead57141577aaf8e7c2e\",\"title\":\"Action recognition via spatio-temporal local features: A comprehensive study\",\"url\":\"https://www.semanticscholar.org/paper/b7a5fcb9ddaf3232b33aead57141577aaf8e7c2e\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"145375983\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1109/CYBConf.2017.7985816\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2d8363021947b6ecee6f8f8da6f6571cd58d88a\",\"title\":\"Temporal Evolution of Motion Superpixel for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e2d8363021947b6ecee6f8f8da6f6571cd58d88a\",\"venue\":\"2017 3rd IEEE International Conference on Cybernetics (CYBCON)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/TMM.2017.2771462\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c09fb7fe1886072670e0c4dd632d052102a3733\",\"title\":\"Content-Attention Representation by Factorized Action-Scene Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c09fb7fe1886072670e0c4dd632d052102a3733\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67022347\",\"name\":\"Yanchen Wan\"},{\"authorId\":\"40457380\",\"name\":\"Y. Liu\"},{\"authorId\":\"48514727\",\"name\":\"Y. Li\"},{\"authorId\":\"3730074\",\"name\":\"P. Zhang\"}],\"doi\":\"10.1007/978-3-030-00916-8_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c0774b619c24b99ce4ae79b0cef974ac53b6dcc\",\"title\":\"p-Faster R-CNN Algorithm for Food Detection\",\"url\":\"https://www.semanticscholar.org/paper/6c0774b619c24b99ce4ae79b0cef974ac53b6dcc\",\"venue\":\"CollaborateCom\",\"year\":2017},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13916641\",\"name\":\"Jiarong Song\"},{\"authorId\":\"48599025\",\"name\":\"Zhong Yang\"},{\"authorId\":\"49347069\",\"name\":\"Qiuyan Zhang\"},{\"authorId\":\"49363806\",\"name\":\"Ting Fang\"},{\"authorId\":\"49433951\",\"name\":\"Guoxiong Hu\"},{\"authorId\":\"4945374\",\"name\":\"Jiaming Han\"},{\"authorId\":\"46729542\",\"name\":\"C. Chen\"}],\"doi\":\"10.1007/978-3-030-04167-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ff10c914e6905a9ab78da6a001650625451b52e\",\"title\":\"Human Action Recognition with 3D Convolution Skip-Connections and RNNs\",\"url\":\"https://www.semanticscholar.org/paper/3ff10c914e6905a9ab78da6a001650625451b52e\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"1706.04589\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"19320138\",\"name\":\"Ansh Kapil\"},{\"authorId\":\"144387494\",\"name\":\"N. Liu\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1016/j.cviu.2017.08.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e444db884b5272f3a41e4b68dc0d453d4ec1f4c\",\"title\":\"Learning without Prejudice: Avoiding Bias in Webly-Supervised Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4e444db884b5272f3a41e4b68dc0d453d4ec1f4c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheyuan Liu\"},{\"authorId\":\"9642011\",\"name\":\"Xiaoteng Zhang\"},{\"authorId\":\"33055674\",\"name\":\"L. Song\"},{\"authorId\":\"2261516\",\"name\":\"Zhengyan Ding\"},{\"authorId\":\"1730199\",\"name\":\"Huixian Duan\"}],\"doi\":\"10.1007/s10586-017-1309-2\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"title\":\"More efficient and effective tricks for deep action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1769315\",\"name\":\"D. Koelma\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1145/3377875\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83288d73e85700698168f07d7c2290864fa32198\",\"title\":\"Shuffled ImageNet Banks for Video Event Detection and Search\",\"url\":\"https://www.semanticscholar.org/paper/83288d73e85700698168f07d7c2290864fa32198\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18080084\",\"name\":\"Qingya Huang\"},{\"authorId\":\"145107805\",\"name\":\"Shan Sun\"},{\"authorId\":\"49451223\",\"name\":\"Feng Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81a142c751bf0b23315fb6717bc467aa4fdfbc92\",\"title\":\"PAIRWISE TRAJECTORY REPRESENTATION FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/81a142c751bf0b23315fb6717bc467aa4fdfbc92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144675600\",\"name\":\"H. Jin\"},{\"authorId\":null,\"name\":\"Meng Zhang\"},{\"authorId\":\"2760487\",\"name\":\"Zhaolin Xiao\"},{\"authorId\":\"48514207\",\"name\":\"Y. Li\"}],\"doi\":\"10.1177/1550147718815841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3779cf958d93e2b5460a3dca6ceab807957ffcf2\",\"title\":\"Multi-sensor image fusion based on contrast and directional features optimization\",\"url\":\"https://www.semanticscholar.org/paper/3779cf958d93e2b5460a3dca6ceab807957ffcf2\",\"venue\":\"Int. J. Distributed Sens. Networks\",\"year\":2018},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798305\",\"name\":\"Georgios Tsatiris\"},{\"authorId\":\"1715144\",\"name\":\"K. Karpouzis\"},{\"authorId\":\"1707243\",\"name\":\"S. Kollias\"}],\"doi\":\"10.1109/INISTA.2018.8466317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d983f554d331ad6dfe2baedb032a2bc921d2ae65\",\"title\":\"Applications of human action analysis and recognition on wireless network infrastructures: State of the art and real world challenges\",\"url\":\"https://www.semanticscholar.org/paper/d983f554d331ad6dfe2baedb032a2bc921d2ae65\",\"venue\":\"2018 Innovations in Intelligent Systems and Applications (INISTA)\",\"year\":2018},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1602.01168\",\"authors\":[{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"1691470\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"144941335\",\"name\":\"Walter Andrews\"},{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"}],\"doi\":\"10.1109/WACV.2017.30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"90b1e6081425e5ccd1d647a7a8bf59dbe45c7c1f\",\"title\":\"Learning Discriminative Features via Label Consistent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/90b1e6081425e5ccd1d647a7a8bf59dbe45c7c1f\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1604.06182\",\"authors\":[{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40633675\",\"name\":\"Alex Gorban\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2016.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c57a070724b48962935ff46ab1384d919e1d1089\",\"title\":\"The THUMOS challenge on action recognition for videos \\\"in the wild\\\"\",\"url\":\"https://www.semanticscholar.org/paper/c57a070724b48962935ff46ab1384d919e1d1089\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350339\",\"name\":\"Chirag I. Patel\"},{\"authorId\":\"2042647646\",\"name\":\"Dileep Labana\"},{\"authorId\":\"47706103\",\"name\":\"S. Pandya\"},{\"authorId\":\"3438822\",\"name\":\"Kirit Modi\"},{\"authorId\":\"3424424\",\"name\":\"H. Ghayvat\"},{\"authorId\":\"1622021877\",\"name\":\"Muhammad Awais\"}],\"doi\":\"10.3390/s20247299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"title\":\"Histogram of Oriented Gradient-Based Fusion of Features for Human Action Recognition in Action Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-319-46487-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5498b3cc5ac12ac5209ec3c8c751e87b59e9c31\",\"title\":\"Webly-Supervised Video Recognition by Mutually Voting for Relevant Web Images and Web Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/c5498b3cc5ac12ac5209ec3c8c751e87b59e9c31\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TCSVT.2017.2746092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20970f0db883b76b56bbf080da79f7fc4c4fc805\",\"title\":\"Cross-Agent Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/20970f0db883b76b56bbf080da79f7fc4c4fc805\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7560130\",\"name\":\"L. Zhang\"},{\"authorId\":\"2238957\",\"name\":\"Xuezhi Xiang\"}],\"doi\":\"10.1007/s11042-019-08457-5\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"title\":\"Video event classification based on two-stage neural network\",\"url\":\"https://www.semanticscholar.org/paper/c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3303577\",\"name\":\"Y. Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"}],\"doi\":\"10.1109/ICMEW.2017.8026246\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f7094ba898a248e1e6b37e3d9fb795e59131cdc\",\"title\":\"Frame-skip Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f7094ba898a248e1e6b37e3d9fb795e59131cdc\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2396114\",\"name\":\"T. Moreira\"},{\"authorId\":\"50534501\",\"name\":\"D. Menotti\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1016/j.jvcir.2020.102771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49278c84a9c0204319a62073d1d42556dee3ff4e\",\"title\":\"Video action recognition based on visual rhythm representation\",\"url\":\"https://www.semanticscholar.org/paper/49278c84a9c0204319a62073d1d42556dee3ff4e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1007/978-3-319-57687-9_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"961c880bb487dd77eafc066da6c014ab8eab543c\",\"title\":\"Saliency Prediction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/961c880bb487dd77eafc066da6c014ab8eab543c\",\"venue\":\"Visual Content Indexing and Retrieval with Psycho-Visual Models\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2911996.2912001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"title\":\"Action Recognition by Learning Deep Multi-Granular Spatio-Temporal Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"1701.07368\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/CVPRW.2017.161\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"title\":\"Deep Local Video Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1611.09053\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/CVPR.2017.147\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"533d14e539ae5cdca0ece392487a2b19106d468a\",\"title\":\"Bidirectional Multirate Reconstruction for Temporal Modeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/533d14e539ae5cdca0ece392487a2b19106d468a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.08238\",\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"225fb9181545f8750061c7693661b62d715dc542\",\"title\":\"Multi-Level Recurrent Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/225fb9181545f8750061c7693661b62d715dc542\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Li\"},{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2016.215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca818c89b1589549ad91ff67223053ec75fa9ac5\",\"title\":\"VLAD3: Encoding Dynamics of Deep Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca818c89b1589549ad91ff67223053ec75fa9ac5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"32281398\",\"name\":\"V. Q. Tran\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"}],\"doi\":\"10.1109/FG.2018.00076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bb36c875754a2a8919f2f9b00a336c00006e453\",\"title\":\"Eigen-Evolution Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2bb36c875754a2a8919f2f9b00a336c00006e453\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144147949\",\"name\":\"Jacqueline Bobo\"},{\"authorId\":\"52420561\",\"name\":\"Xiong Nai-xue\"},{\"authorId\":null,\"name\":\"Y. GUISONG\"},{\"authorId\":\"145596277\",\"name\":\"Weisha Yan\"},{\"authorId\":\"66935899\",\"name\":\"Ye Hongming\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a2344fbaf24cf30e425533f88edcaecd25ef1d3\",\"title\":\"THE SEVENTH ANNUAL CONFERENCE ON ADVANCES IN COGNITIVE SYSTEMS\",\"url\":\"https://www.semanticscholar.org/paper/7a2344fbaf24cf30e425533f88edcaecd25ef1d3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"34692532\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"2202745\",\"name\":\"Shicheng Xu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"2228773\",\"name\":\"Zexi Mao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"2742322\",\"name\":\"Xingzhong Du\"},{\"authorId\":\"144220860\",\"name\":\"Y. Cai\"},{\"authorId\":\"145262322\",\"name\":\"Lara J. Martin\"},{\"authorId\":\"48978819\",\"name\":\"Nikolas Wolfe\"},{\"authorId\":\"22308253\",\"name\":\"A. Kumar\"},{\"authorId\":\"31843208\",\"name\":\"H. Li\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"1727419\",\"name\":\"Zhigang Ma\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"144804455\",\"name\":\"S. Burger\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1798727\",\"name\":\"R. Singh\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"},{\"authorId\":\"1697819\",\"name\":\"R. Stern\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c6daffd092d02574efbf746d086e6dc0d3b1e91\",\"title\":\"Informedia@TrecVID 2014: MED and MER\",\"url\":\"https://www.semanticscholar.org/paper/4c6daffd092d02574efbf746d086e6dc0d3b1e91\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144811737\",\"name\":\"Lu Jiang\"},{\"authorId\":\"47420553\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"2202745\",\"name\":\"Shicheng Xu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Zexi\"},{\"authorId\":\"123871664\",\"name\":\"Mao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"2742322\",\"name\":\"Xingzhong Du\"},{\"authorId\":\"144220860\",\"name\":\"Y. Cai\"},{\"authorId\":\"143945660\",\"name\":\"L. Martin\"},{\"authorId\":\"48978819\",\"name\":\"Nikolas Wolfe\"},{\"authorId\":\"39862695\",\"name\":\"Anurag Kumar\"},{\"authorId\":\"47892776\",\"name\":\"Huan Li\"},{\"authorId\":\"144247537\",\"name\":\"Ming Lin\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"26957307\",\"name\":\"Deyu Meng\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"66119910\",\"name\":\"Susanne\"},{\"authorId\":\"118874987\",\"name\":\"Burger\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"153915824\",\"name\":\"R. Singh\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"145784487\",\"name\":\"Teruko Mitamura\"},{\"authorId\":\"49479435\",\"name\":\"R. Stern\"},{\"authorId\":\"121514744\",\"name\":\"Alexander\"},{\"authorId\":\"120365678\",\"name\":\"Hauptmann\"},{\"authorId\":\"2026473728\",\"name\":\"Pinar Duygulu-Sahin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"47827562\",\"name\":\"Yicheng Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1f6ee518b3d1d966f2757d2624d526dd8b833eb\",\"title\":\"Semantic Indexing\",\"url\":\"https://www.semanticscholar.org/paper/c1f6ee518b3d1d966f2757d2624d526dd8b833eb\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2177258\",\"name\":\"X. Liu\"},{\"authorId\":\"9308370\",\"name\":\"Tianyu You\"},{\"authorId\":\"2682749\",\"name\":\"X. Ma\"},{\"authorId\":\"2975899\",\"name\":\"Hailan Kuang\"}],\"doi\":\"10.1109/ICMTMA.2018.00131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc36badb6606b8162d821a227dda09a94aac537f\",\"title\":\"An Optimization Model for Human Activity Recognition Inspired by Information on Human-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/bc36badb6606b8162d821a227dda09a94aac537f\",\"venue\":\"2018 10th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47916686\",\"name\":\"K. Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"}],\"doi\":\"10.1587/TRANSINF.2017EDL8049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"title\":\"Trajectory-Set Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/ICASSP.2017.7952427\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cdc9bb623bf7e587c8ffb9561aaab9a7e1f0a95\",\"title\":\"Action-vectors: Unsupervised movement modeling for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc9bb623bf7e587c8ffb9561aaab9a7e1f0a95\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.212\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"641421832f237b280644261a77eca3974ac9c0c1\",\"title\":\"Discriminative Hierarchical Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/641421832f237b280644261a77eca3974ac9c0c1\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.5244/C.29.57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67fa5ac0aeae6dbcf98c7039a2e11fbe494fe5f4\",\"title\":\"A BoW-equivalent Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/67fa5ac0aeae6dbcf98c7039a2e11fbe494fe5f4\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479904\",\"name\":\"Tiantian Xu\"},{\"authorId\":\"3314902\",\"name\":\"E. K. Wong\"}],\"doi\":\"10.5244/C.31.160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6406d59456c4b468df3d9fa88e93d852c409b8d\",\"title\":\"Learning temporal structures for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6406d59456c4b468df3d9fa88e93d852c409b8d\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144675600\",\"name\":\"H. Jin\"},{\"authorId\":null,\"name\":\"Meng Zhang\"},{\"authorId\":\"48514207\",\"name\":\"Y. Li\"},{\"authorId\":\"2760487\",\"name\":\"Zhaolin Xiao\"},{\"authorId\":\"47057536\",\"name\":\"Xiuxiu Li\"}],\"doi\":\"10.1109/HPCC/SmartCity/DSS.2018.00169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0d44bead45433c4fface2543752667c20220094\",\"title\":\"An Improved Visible and Infrared Image Fusion Based on Contrast with Directional Filter Banks and Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b0d44bead45433c4fface2543752667c20220094\",\"venue\":\"2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413858223\",\"name\":\"M. Al-habib\"},{\"authorId\":\"2258587\",\"name\":\"D. Huang\"},{\"authorId\":\"1411261544\",\"name\":\"Majjed Al-Qatf\"},{\"authorId\":\"1388813797\",\"name\":\"Kamal Al-Sabahi\"}],\"doi\":\"10.1145/3316615.3316722\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aef7731abe7a17f05bbfa1a3185e98c0aee8490d\",\"title\":\"Cooperative Hierarchical Framework for Group Activity Recognition: From Group Detection to Multi-activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aef7731abe7a17f05bbfa1a3185e98c0aee8490d\",\"venue\":\"ICSCA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1109/WACV.2016.7477589\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"title\":\"Combining multiple sources of knowledge in deep CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"title\":\"Mining Spatial and Spatio-Temporal ROIs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037859\",\"name\":\"Saddam Bekhet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"274be0f6a343c0c75e792f4fa9f598bf7d1924c8\",\"title\":\"Signature-based videos' visual similarity detection and measurement\",\"url\":\"https://www.semanticscholar.org/paper/274be0f6a343c0c75e792f4fa9f598bf7d1924c8\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46737362\",\"name\":\"P. Zhao\"},{\"authorId\":\"144145103\",\"name\":\"Qiguang Miao\"},{\"authorId\":\"1757283\",\"name\":\"Jianfeng Song\"},{\"authorId\":\"3084747\",\"name\":\"Yutao Qi\"},{\"authorId\":\"1957459\",\"name\":\"Ruyi Liu\"},{\"authorId\":\"51467264\",\"name\":\"Daohui Ge\"}],\"doi\":\"10.1109/ACCESS.2018.2869976\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa1babdce11a58344f92c9294b4ad201dd0db56c\",\"title\":\"Architectural Style Classification Based on Feature Extraction Module\",\"url\":\"https://www.semanticscholar.org/paper/fa1babdce11a58344f92c9294b4ad201dd0db56c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"title\":\"Recognition Prediction ? ? ? ? ? ? ? ? Gap fi lling\",\"url\":\"https://www.semanticscholar.org/paper/5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1505.04427\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"1711953\",\"name\":\"Dezhong Yao\"},{\"authorId\":\"144247537\",\"name\":\"Ming Lin\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPRW.2016.152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e42377ef3aad1b22172079ed70a69a4848c76367\",\"title\":\"The Best of BothWorlds: Combining Data-Independent and Data-Driven Approaches for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e42377ef3aad1b22172079ed70a69a4848c76367\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682151\",\"name\":\"Cheng-Bin Jin\"},{\"authorId\":\"2772929\",\"name\":\"T. D. Do\"},{\"authorId\":\"47842167\",\"name\":\"M. Liu\"},{\"authorId\":\"1697362\",\"name\":\"H. Kim\"}],\"doi\":\"10.5772/INTECHOPEN.76086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d017d99aba5a39a6e70d96155bec849fed1311b\",\"title\":\"Real-Time Action Recognition Using Multi-level Action Descriptor and DNN\",\"url\":\"https://www.semanticscholar.org/paper/2d017d99aba5a39a6e70d96155bec849fed1311b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2805804\",\"name\":\"Mennan G\\u00fcder\"},{\"authorId\":\"1699030\",\"name\":\"N. Cicekli\"}],\"doi\":\"10.1007/s00530-017-0535-z\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cdd09dc965e00c7ce7d1dda839cc4da2ef8e037\",\"title\":\"Multi-modal video event recognition based on association rules and decision fusion\",\"url\":\"https://www.semanticscholar.org/paper/2cdd09dc965e00c7ce7d1dda839cc4da2ef8e037\",\"venue\":\"Multimedia Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3241032\",\"name\":\"M. Z. Uddin\"},{\"authorId\":\"1757843\",\"name\":\"W. Khaksar\"},{\"authorId\":\"9395911\",\"name\":\"J. T\\u00f8rresen\"}],\"doi\":\"10.3390/s18072027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16810e9d90de52aa1e310e0b8b2e594cc4e0d86d\",\"title\":\"Ambient Sensors for Elderly Care and Independent Living: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/16810e9d90de52aa1e310e0b8b2e594cc4e0d86d\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020}],\"corpusId\":13269760,\"doi\":\"10.1109/CVPR.2015.7298616\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":25,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"145150387\",\"name\":\"Tsung-Han Chan\"},{\"authorId\":\"50313556\",\"name\":\"Y. Fang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/CVPR.2014.336\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1b0296ed47cf3f906f6e24683d9f5444406be53\",\"title\":\"DL-SFA: Deeply-Learned Slow Feature Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c1b0296ed47cf3f906f6e24683d9f5444406be53\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930329\",\"name\":\"P. Matikainen\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/ICCVW.2009.5457659\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b155538a9079e4d8476e11afe09a7ebf5543fd50\",\"title\":\"Trajectons: Action recognition through the motion analysis of tracked features\",\"url\":\"https://www.semanticscholar.org/paper/b155538a9079e4d8476e11afe09a7ebf5543fd50\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TCYB.2013.2273174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b60a6c16399cc0e5ce2d7b117807854891042de4\",\"title\":\"Spatio-Temporal Laplacian Pyramid Coding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b60a6c16399cc0e5ce2d7b117807854891042de4\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-013-0677-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d83c2948c37421913c425a76c3dcc292fac0471d\",\"title\":\"Activity representation with motion hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/d83c2948c37421913c425a76c3dcc292fac0471d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.1109/CVPR.2013.330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"title\":\"Better Exploiting Motion for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"145986798\",\"name\":\"K. Ramakrishnan\"}],\"doi\":\"10.1109/CVPR.2014.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fcead8c3b491076165f6c5168eaa147dcc550f2\",\"title\":\"A Cause and Effect Analysis of Motion Trajectories for Modeling Actions\",\"url\":\"https://www.semanticscholar.org/paper/7fcead8c3b491076165f6c5168eaa147dcc550f2\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"144994682\",\"name\":\"A. Pentland\"}],\"doi\":\"10.1109/CVPR.1993.341109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1807058512ae2934b2be0b43f395d8583ef67303\",\"title\":\"Space-time gestures\",\"url\":\"https://www.semanticscholar.org/paper/1807058512ae2934b2be0b43f395d8583ef67303\",\"venue\":\"Proceedings of IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144706338\",\"name\":\"Ju Sun\"},{\"authorId\":\"47150103\",\"name\":\"Xiao Wu\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/cvprw.2009.5206721\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c3815f4d17dc96af64f17075f0f349926297a0f\",\"title\":\"Hierarchical spatio-temporal context modeling for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/0c3815f4d17dc96af64f17075f0f349926297a0f\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1007/BF01469346\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8385d733a5d41f79ec6cc34be147ec39f592de56\",\"title\":\"Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention\",\"url\":\"https://www.semanticscholar.org/paper/8385d733a5d41f79ec6cc34be147ec39f592de56\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":\"1312.6229\",\"authors\":[{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2060028\",\"name\":\"D. Eigen\"},{\"authorId\":\"46447747\",\"name\":\"X. Zhang\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1109b663453e78a59e4f66446d71720ac58cec25\",\"title\":\"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1109b663453e78a59e4f66446d71720ac58cec25\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dffe7498c67e9451db2d04bb8408f376ae86992\",\"title\":\"LEAR-INRIA submission for the THUMOS workshop\",\"url\":\"https://www.semanticscholar.org/paper/7dffe7498c67e9451db2d04bb8408f376ae86992\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. S. Goodwin Ciptadi\"},{\"authorId\":null,\"name\":\"J. M. Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pyramid methods in image processing Human activity analysis : A review\",\"url\":\"\",\"venue\":\"ACM Computing Surveys ( CSUR )\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"120896463\",\"name\":\"Chih-Wei Chen\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15552-9_29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"994a7b903b937f8b177c035db86852091fd26aa7\",\"title\":\"Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/994a7b903b937f8b177c035db86852091fd26aa7\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145096334\",\"name\":\"K. Reddy\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s00138-012-0450-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7eee57d8a8c057ab1f599105d16d0e8489a61e0\",\"title\":\"Recognizing 50 human action categories of web videos\",\"url\":\"https://www.semanticscholar.org/paper/c7eee57d8a8c057ab1f599105d16d0e8489a61e0\",\"venue\":\"Machine Vision and Applications\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710918\",\"name\":\"J. Yamato\"},{\"authorId\":\"1708785\",\"name\":\"J. Ohya\"},{\"authorId\":\"46562570\",\"name\":\"K. Ishii\"}],\"doi\":\"10.1109/CVPR.1992.223161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45336e96c04ea005b203ff3fc84aa4f4159e8cb0\",\"title\":\"Recognizing human action in time-sequential images using hidden Markov model\",\"url\":\"https://www.semanticscholar.org/paper/45336e96c04ea005b203ff3fc84aa4f4159e8cb0\",\"venue\":\"Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3244141\",\"name\":\"A. Ciptadi\"},{\"authorId\":\"1769348\",\"name\":\"Matthew S. Goodwin\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-319-10605-2_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc0254d2fc53bb81cfb21318fed8b71eb5757785\",\"title\":\"Movement Pattern Histogram for Action Recognition and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bc0254d2fc53bb81cfb21318fed8b71eb5757785\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1004.4389\",\"authors\":[{\"authorId\":\"1788107\",\"name\":\"J. Tropp\"}],\"doi\":\"10.1007/s10208-011-9099-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14b4b81303cc6e746a27eefbc4989e200be1b10e\",\"title\":\"User-Friendly Tail Bounds for Sums of Random Matrices\",\"url\":\"https://www.semanticscholar.org/paper/14b4b81303cc6e746a27eefbc4989e200be1b10e\",\"venue\":\"Found. Comput. Math.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644050191\",\"name\":\"G. LoweDavid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84362927\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"123108776\",\"name\":\"M.S. Ryoo\"}],\"doi\":\"10.1145/1922649.1922653\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"title\":\"Human activity analysis: A review\",\"url\":\"https://www.semanticscholar.org/paper/56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"venue\":\"CSUR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693446\",\"name\":\"L. Florack\"},{\"authorId\":\"1699027\",\"name\":\"B. T. H. Romeny\"},{\"authorId\":\"1716904\",\"name\":\"J. Koenderink\"},{\"authorId\":\"1704117\",\"name\":\"M. Viergever\"}],\"doi\":\"10.1007/BF01262401\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e2e645e7d1a4a80ec7fd05f1fbc544c3355153ab\",\"title\":\"Linear scale-space\",\"url\":\"https://www.semanticscholar.org/paper/e2e645e7d1a4a80ec7fd05f1fbc544c3355153ab\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144720855\",\"name\":\"D. Marr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52df763d69ed5fe609a4a88f07e97a6cfaadf59f\",\"title\":\"Vision: A computational investigation into the human representation\",\"url\":\"https://www.semanticscholar.org/paper/52df763d69ed5fe609a4a88f07e97a6cfaadf59f\",\"venue\":\"\",\"year\":1982},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716904\",\"name\":\"J. Koenderink\"}],\"doi\":\"10.1007/BF00336961\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58b6b9e9f5472048468bac161bdaa3ae99eecd01\",\"title\":\"The structure of images\",\"url\":\"https://www.semanticscholar.org/paper/58b6b9e9f5472048468bac161bdaa3ae99eecd01\",\"venue\":\"Biological Cybernetics\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1007/978-3-642-33715-4_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b071b910f8dc0c64c26730da144cddbedc29ed07\",\"title\":\"Trajectory-Based Modeling of Human Actions with Motion Reference Points\",\"url\":\"https://www.semanticscholar.org/paper/b071b910f8dc0c64c26730da144cddbedc29ed07\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. S. Goodwin A. Ciptadi\"},{\"authorId\":null,\"name\":\"J. M. Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pyramid methods in image processing Human activity analysis : A review\",\"url\":\"\",\"venue\":\"ACM Computing Surveys ( CSUR )\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1405.7545\",\"authors\":[{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e3f305dac4fbb813e60ac778d6929012b4b745a\",\"title\":\"Feature sampling and partitioning for visual vocabulary generation on large action classification datasets\",\"url\":\"https://www.semanticscholar.org/paper/3e3f305dac4fbb813e60ac778d6929012b4b745a\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"2302358\",\"name\":\"P. Burt\"},{\"authorId\":\"143718183\",\"name\":\"C. Anderson\"},{\"authorId\":\"40577945\",\"name\":\"J. Ogden\"},{\"authorId\":\"116003860\",\"name\":\"J. Bergen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e49793511ba203e26b99e7e81fd15a7d505b5cea\",\"title\":\"PYRAMID METHODS IN IMAGE PROCESSING.\",\"url\":\"https://www.semanticscholar.org/paper/e49793511ba203e26b99e7e81fd15a7d505b5cea\",\"venue\":\"\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"},{\"authorId\":\"1699027\",\"name\":\"B. T. H. Romeny\"}],\"doi\":\"10.1007/978-94-017-1699-4_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7a0005c9d3afb467a5ca5cd86296a6861efd447\",\"title\":\"Linear Scale-Space I: Basic Theory\",\"url\":\"https://www.semanticscholar.org/paper/d7a0005c9d3afb467a5ca5cd86296a6861efd447\",\"venue\":\"Geometry-Driven Diffusion in Computer Vision\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"144064571\",\"name\":\"I. Pitas\"}],\"doi\":\"10.1109/ICASSP.2014.6854640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d774f6108ace7679f4d99a91892ee19f2d41bdcc\",\"title\":\"Minimum Variance Extreme Learning Machine for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d774f6108ace7679f4d99a91892ee19f2d41bdcc\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/cvprw.2009.5206557\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fd485daa491c0debcd900b3f6bc141c3883812d\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/1fd485daa491c0debcd900b3f6bc141c3883812d\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327729\",\"name\":\"Feng Shi\"},{\"authorId\":\"1745632\",\"name\":\"E. Petriu\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CVPR.2013.335\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b360fdc731997ad2efe4ab0687057f691f365c62\",\"title\":\"Sampling Strategies for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b360fdc731997ad2efe4ab0687057f691f365c62\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Y. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pyramid methods in image processing Human activity analysis : A review\",\"url\":\"\",\"venue\":\"ACM Computing Surveys ( CSUR )\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2974372\",\"name\":\"Brian Antonishek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4e37705ee574fb61a67d49b19d48ab0c22f8b7c\",\"title\":\"TRECVID 2010 \\u2013 An Introduction to the Goals , Tasks , Data , Evaluation Mechanisms , and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/e4e37705ee574fb61a67d49b19d48ab0c22f8b7c\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724907\",\"name\":\"W. W. Chu\"},{\"authorId\":\"1772322\",\"name\":\"T. Y. Lin\"}],\"doi\":\"10.1007/B104039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68859113bdfe92eb76a72840999ce7be45f885a3\",\"title\":\"Foundations and Advances in Data Mining\",\"url\":\"https://www.semanticscholar.org/paper/68859113bdfe92eb76a72840999ce7be45f885a3\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143645506\",\"name\":\"P. Over\"},{\"authorId\":\"145876242\",\"name\":\"G. Awad\"},{\"authorId\":\"3241934\",\"name\":\"J. Fiscus\"},{\"authorId\":\"2974372\",\"name\":\"Brian Antonishek\"},{\"authorId\":\"33765735\",\"name\":\"M. Michel\"},{\"authorId\":\"1740640\",\"name\":\"Wessel Kraaij\"},{\"authorId\":\"1680223\",\"name\":\"A. Smeaton\"},{\"authorId\":\"1693391\",\"name\":\"G. Qu\\u00e9not\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"760f81db6dabbbd0744595e9fc3d55138e5cb88e\",\"title\":\"TRECVID 2015 - An Overview of the Goals, Tasks, Data, Evaluation Mechanisms and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/760f81db6dabbbd0744595e9fc3d55138e5cb88e\",\"venue\":\"TRECVID\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2981641\",\"name\":\"S. Park\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"}],\"doi\":\"10.1007/s00530-004-0148-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"273ba92bd0ec36ffff803ee30bed3bc41fa3260b\",\"title\":\"A hierarchical Bayesian network for event recognition of human actions and interactions\",\"url\":\"https://www.semanticscholar.org/paper/273ba92bd0ec36ffff803ee30bed3bc41fa3260b\",\"venue\":\"Multimedia Systems\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014}],\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"topics\":[{\"topic\":\"Stacking\",\"topicId\":\"100839\",\"url\":\"https://www.semanticscholar.org/topic/100839\"},{\"topic\":\"Feature extraction\",\"topicId\":\"4259\",\"url\":\"https://www.semanticscholar.org/topic/4259\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"Smoothing\",\"topicId\":\"16185\",\"url\":\"https://www.semanticscholar.org/topic/16185\"},{\"topic\":\"Learnability\",\"topicId\":\"4569\",\"url\":\"https://www.semanticscholar.org/topic/4569\"},{\"topic\":\"Condition number\",\"topicId\":\"5434\",\"url\":\"https://www.semanticscholar.org/topic/5434\"},{\"topic\":\"Speedup\",\"topicId\":\"4162\",\"url\":\"https://www.semanticscholar.org/topic/4162\"}],\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"