"{\"abstract\":\"Visual saliency has been shown to depend on the unpredictability of the visual stimulus given its surround. Various previous works have advocated the equivalence between stimulus saliency and uncompressibility. We propose a direct measure of this quantity, namely the number of bits required by an optimal video compressor to encode a given video patch, and show that features derived from this measure are highly predictive of eye fixations. To account for global saliency effects, these are embedded in a Markov random field model. The resulting saliency measure is shown to achieve state-of-the-art accuracy for the prediction of fixations, at a very low computational cost. Since most modern cameras incorporate video encoders, this paves the way for in-camera saliency estimation, which could be useful in a variety of computer vision applications.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2675203\",\"name\":\"Seyed Hossein Khatoonabadi\",\"url\":\"https://www.semanticscholar.org/author/2675203\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\",\"url\":\"https://www.semanticscholar.org/author/1699559\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\",\"url\":\"https://www.semanticscholar.org/author/1730101\"},{\"authorId\":\"37207452\",\"name\":\"Yufeng Shan\",\"url\":\"https://www.semanticscholar.org/author/37207452\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"8189996\",\"name\":\"Jingxian Liu\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TMM.2017.2767784\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"title\":\"Saliency Detection in Face Videos: A Data-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50543166\",\"name\":\"Anne-Flore Perrin\"},{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1007/978-3-030-29888-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"title\":\"How Well Current Saliency Prediction Models Perform on UAVs Videos?\",\"url\":\"https://www.semanticscholar.org/paper/3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"venue\":\"CAIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1603.08199\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"title\":\"Recurrent Mixture Density Network for Spatiotemporal Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32783928\",\"name\":\"Mohammadsadegh alizadeh\"},{\"authorId\":\"2916686\",\"name\":\"M. Sharifkhani\"}],\"doi\":\"10.1109/TCSVT.2019.2895921\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c8b65a3deabba7e7c8c38b9329dadc245ffd6b7\",\"title\":\"Compressed Domain Moving Object Detection Based on CRF\",\"url\":\"https://www.semanticscholar.org/paper/9c8b65a3deabba7e7c8c38b9329dadc245ffd6b7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"}],\"doi\":\"10.1007/978-3-319-58838-4_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2472dea017eb6a3be9441263124641ef3d97721\",\"title\":\"What Do Datasets Say About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/a2472dea017eb6a3be9441263124641ef3d97721\",\"venue\":\"IbPRIA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":null,\"name\":\"Songyang Zhang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2017.343\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"title\":\"Predicting Salient Face in Multiple-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3387551\",\"name\":\"M. Startsev\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":\"10.1109/ACCESS.2019.2961835\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c45cfde00d5cf07fff6f004931a4856cb531cd3\",\"title\":\"Supersaliency: A Novel Pipeline for Predicting Smooth Pursuit-Based Attention Improves Generalisability of Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/2c45cfde00d5cf07fff6f004931a4856cb531cd3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1690844\",\"name\":\"F. Silva\"},{\"authorId\":\"3087384\",\"name\":\"S. Gul\"},{\"authorId\":\"46493237\",\"name\":\"Daniel Becker\"},{\"authorId\":\"46624407\",\"name\":\"M. Schmidt\"},{\"authorId\":\"1691172\",\"name\":\"C. Hellge\"}],\"doi\":\"10.1109/MMSP.2018.8547120\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43ca75ff98e43937ca4292e9974246d042cc9d00\",\"title\":\"Efficient Object Tracking in Compressed Video Streams with Graph Cuts\",\"url\":\"https://www.semanticscholar.org/paper/43ca75ff98e43937ca4292e9974246d042cc9d00\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145975332\",\"name\":\"X. Dai\"},{\"authorId\":\"74338570\",\"name\":\"Charith Abhayaratne\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e40783a7cd2cea2878cd2abbc444e5ab35aad97\",\"title\":\"Visual Saliency Estimation Via HEVC Bitstream Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7e40783a7cd2cea2878cd2abbc444e5ab35aad97\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"145143111\",\"name\":\"R. Hu\"},{\"authorId\":\"143684018\",\"name\":\"F. He\"}],\"doi\":\"10.1109/TIP.2018.2837106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1a854d574d0bd14786c41247db272be6062581\",\"title\":\"Find Who to Look at: Turning From Action to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/9f1a854d574d0bd14786c41247db272be6062581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2016.11.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf54a133c89f730adc5ea12c3ac646971120781c\",\"title\":\"A comparative study for feature integration strategies in dynamic saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/cf54a133c89f730adc5ea12c3ac646971120781c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46781563\",\"name\":\"R. Yang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/ICME.2016.7552864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1a94cd95e65bf045cef1075bfef302c81924aa0\",\"title\":\"Subjective-quality-optimized complexity control for HEVC decoding\",\"url\":\"https://www.semanticscholar.org/paper/a1a94cd95e65bf045cef1075bfef302c81924aa0\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46500724\",\"name\":\"Ron M. Hecht\"},{\"authorId\":\"3202488\",\"name\":\"Ariel Telpaz\"},{\"authorId\":\"1754704\",\"name\":\"G. Kamhi\"},{\"authorId\":\"1400556488\",\"name\":\"Aharon Bar-Hillel\"},{\"authorId\":\"1777660\",\"name\":\"Naftali Tishby\"}],\"doi\":\"10.1109/ICASSP.2019.8683281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a88b8817e53a3a46f53561f3d37a51ee476f8ee9\",\"title\":\"Information Constrained Control for Visual Detection of Important Areas\",\"url\":\"https://www.semanticscholar.org/paper/a88b8817e53a3a46f53561f3d37a51ee476f8ee9\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743039\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"}],\"doi\":\"10.1109/ACCESS.2017.2689776\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55092057c690d6460faeed108dc40d605c7b237d\",\"title\":\"Learning-Based Saliency Detection of Face Images\",\"url\":\"https://www.semanticscholar.org/paper/55092057c690d6460faeed108dc40d605c7b237d\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153385438\",\"name\":\"A. Mane\"},{\"authorId\":\"151440546\",\"name\":\"S. Mali\"},{\"authorId\":\"90315386\",\"name\":\"Priyanka D. Mali\"},{\"authorId\":\"151426605\",\"name\":\"Sonam Mulik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9066cd93949c29c0197f4e4fceaf00888532f46d\",\"title\":\"International Journal of Scientific Research in Computer Science, Engineering and Information Technology\",\"url\":\"https://www.semanticscholar.org/paper/9066cd93949c29c0197f4e4fceaf00888532f46d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1760977\",\"name\":\"V. Lebor\\u00e1n\"},{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398517622\",\"name\":\"Xose R. Fdez-Vidal\"},{\"authorId\":\"1397906798\",\"name\":\"Xose M. Pardo\"}],\"doi\":\"10.1109/TPAMI.2016.2567391\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"822cf4868af46453dd7e9232ad8011e62c9c0400\",\"title\":\"Dynamic Whitening Saliency\",\"url\":\"https://www.semanticscholar.org/paper/822cf4868af46453dd7e9232ad8011e62c9c0400\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1016/j.patcog.2020.107234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"947b42503e78f29fd64ab864a76721dae8cad26e\",\"title\":\"DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/947b42503e78f29fd64ab864a76721dae8cad26e\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114300968\",\"name\":\"Mohammad Manjur Rashed Khan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfa1ff7295396939f3f257bf1c25dfed1ffd2fe1\",\"title\":\"HEVC-SIM: A Simulation and analysis tool for H.265 packet transmission\",\"url\":\"https://www.semanticscholar.org/paper/cfa1ff7295396939f3f257bf1c25dfed1ffd2fe1\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1709.06316\",\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"title\":\"Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70044512\",\"name\":\"Sayed Hossein Khatoonabadi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ba7c7a1736a84bca219d4cade277226a8e5c3fd\",\"title\":\"Saliency and Tracking in Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/3ba7c7a1736a84bca219d4cade277226a8e5c3fd\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48551624\",\"name\":\"Z. Wu\"},{\"authorId\":\"145235481\",\"name\":\"Li Su\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2018.2870954\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"title\":\"Learning Coupled Convolutional Networks Fusion for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50320765\",\"name\":\"B. Rekha\"},{\"authorId\":\"116702540\",\"name\":\"Ravi Kumar Av\"}],\"doi\":\"10.11591/IJEECS.V7.I3.PP761-772\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"17c5cf0eedf6f5e4ea7c8d89a5fbbbd7eb8a77da\",\"title\":\"High Quality Video Assessment Using Salient Features\",\"url\":\"https://www.semanticscholar.org/paper/17c5cf0eedf6f5e4ea7c8d89a5fbbbd7eb8a77da\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2018.00783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a2fae46c67189fb2aea33f12091772e635361f1\",\"title\":\"Going from Image to Video Saliency: Augmenting Image Salience with Dynamic Attentional Push\",\"url\":\"https://www.semanticscholar.org/paper/9a2fae46c67189fb2aea33f12091772e635361f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"79439415\",\"name\":\"Haoyu Dong\"},{\"authorId\":\"2560900\",\"name\":\"Shengxi Li\"}],\"doi\":\"10.1109/CVPRW.2017.208\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7d81091f909f718425eb428336ff72de5f3ad0e\",\"title\":\"Learning Dynamic GMM for Attention Distribution on Single-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/f7d81091f909f718425eb428336ff72de5f3ad0e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36014747\",\"name\":\"K. B. Rekha\"},{\"authorId\":\"152167930\",\"name\":\"A. R. Kumar\"}],\"doi\":\"10.21917/IJIVP.2017.0222\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"c6b0fd487eb46d85c5ff89632b329d92880d80e6\",\"title\":\"EFFICIENT HIGH QUALITY VIDEO ASSESSMENT USING SALIENT FEATURES\",\"url\":\"https://www.semanticscholar.org/paper/c6b0fd487eb46d85c5ff89632b329d92880d80e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1710.10755\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2858783\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"title\":\"Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67016734\",\"name\":\"S. Zhu\"},{\"authorId\":\"39772032\",\"name\":\"C. Liu\"},{\"authorId\":\"1765822\",\"name\":\"Ziyao Xu\"}],\"doi\":\"10.1109/TCSVT.2019.2911396\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"47abf02a79bb70cc9fd4ac14b6c9dc7b5063978b\",\"title\":\"High-Definition Video Compression System Based on Perception Guidance of Salient Information of a Convolutional Neural Network and HEVC Compression Domain\",\"url\":\"https://www.semanticscholar.org/paper/47abf02a79bb70cc9fd4ac14b6c9dc7b5063978b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145989383\",\"name\":\"M. Ammar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"911fe5aa3bd832ba2d448af6d182c41159931d27\",\"title\":\"Visual saliency extraction from compressed streams\",\"url\":\"https://www.semanticscholar.org/paper/911fe5aa3bd832ba2d448af6d182c41159931d27\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50556969\",\"name\":\"Chunyang Liu\"},{\"authorId\":\"1722956\",\"name\":\"Zemin Wu\"},{\"authorId\":\"50316184\",\"name\":\"Zhaofeng Zhang\"},{\"authorId\":\"2340544\",\"name\":\"Qingzhu Jiang\"},{\"authorId\":\"50675141\",\"name\":\"L. Hu\"}],\"doi\":\"10.1109/ICCWAMTIP.2016.8079841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5396c986a438643440af4229232866e20b7a191f\",\"title\":\"Video saliency from compressed domain coding length\",\"url\":\"https://www.semanticscholar.org/paper/5396c986a438643440af4229232866e20b7a191f\",\"venue\":\"2016 13th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)\",\"year\":2016},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"150054776\",\"name\":\"Carlos Guillermo Bermudez Cruces\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/FG.2019.8756540\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de5bd367907404eb1cf25e8d9f06b389b9312fdb\",\"title\":\"Learning to Detect Genuine versus Posed Pain from Facial Expressions using Residual Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/de5bd367907404eb1cf25e8d9f06b389b9312fdb\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685776\",\"name\":\"Y. Li\"},{\"authorId\":\"2721212\",\"name\":\"Yunsong Li\"}],\"doi\":\"10.1007/s11042-016-4118-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba83d73dfda173a81d26925abad70750d3133305\",\"title\":\"A fast and efficient saliency detection model in video compressed-domain for human fixations prediction\",\"url\":\"https://www.semanticscholar.org/paper/ba83d73dfda173a81d26925abad70750d3133305\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145989383\",\"name\":\"M. Ammar\"},{\"authorId\":\"38708414\",\"name\":\"M. Mitrea\"},{\"authorId\":\"31768924\",\"name\":\"M. Hasnaoui\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1016/j.image.2017.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1f7883213752523d61b05d7a56f3a4871d2680f\",\"title\":\"MPEG-4 AVC stream-based saliency detection. Application to robust watermarking\",\"url\":\"https://www.semanticscholar.org/paper/c1f7883213752523d61b05d7a56f3a4871d2680f\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1801.08925\",\"authors\":[{\"authorId\":\"145305263\",\"name\":\"M. Startsev\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9ada4f4a7297f3a955735aa4d54587512cc6948\",\"title\":\"Supersaliency: Predicting Smooth Pursuit-Based Attention with Slicing CNNs Improves Fixation Prediction for Naturalistic Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9ada4f4a7297f3a955735aa4d54587512cc6948\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66357786\",\"name\":\"Yongjun Li\"},{\"authorId\":\"7771261\",\"name\":\"Y. Li\"},{\"authorId\":\"51051489\",\"name\":\"W. Liu\"},{\"authorId\":\"152316824\",\"name\":\"J. Hu\"},{\"authorId\":\"7392362\",\"name\":\"C. Ge\"}],\"doi\":\"10.1117/1.JEI.26.1.013008\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5accd7df31d2436410225214d4430781e185e49e\",\"title\":\"Human fixation detection model in video compressed domain based on Markov random field\",\"url\":\"https://www.semanticscholar.org/paper/5accd7df31d2436410225214d4430781e185e49e\",\"venue\":\"J. Electronic Imaging\",\"year\":2017},{\"arxivId\":\"1604.07339\",\"authors\":[{\"authorId\":\"2675203\",\"name\":\"Seyed Hossein Khatoonabadi\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"},{\"authorId\":\"37207452\",\"name\":\"Yufeng Shan\"}],\"doi\":\"10.1007/s11042-016-4124-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f73fcbbb33969d45f83cf72fdc4035df29575e8\",\"title\":\"Compressed-domain visual saliency models: a comparative study\",\"url\":\"https://www.semanticscholar.org/paper/1f73fcbbb33969d45f83cf72fdc4035df29575e8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.12185\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1007/978-3-030-58568-6_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61b166040abff8309e23d804551fc3d3acc833f6\",\"title\":\"Action Localization through Continual Predictive Learning\",\"url\":\"https://www.semanticscholar.org/paper/61b166040abff8309e23d804551fc3d3acc833f6\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c67a441e1ebaa3773bb7734a7eb1690236f81a6\",\"title\":\"Modeling Attention in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/6c67a441e1ebaa3773bb7734a7eb1690236f81a6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.07480\",\"authors\":[{\"authorId\":\"50251712\",\"name\":\"Ziqi Zhou\"},{\"authorId\":\"40514580\",\"name\":\"Z. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"47673404\",\"name\":\"S. Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1016/j.patcog.2020.107275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7de478275fdc5e154f6d904b910e8d291033edd\",\"title\":\"Global and Local Sensitivity Guided Key Salient Object Re-augmentation for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7de478275fdc5e154f6d904b910e8d291033edd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2852900\",\"name\":\"M. L\\u00f3pez\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"}],\"doi\":\"10.1016/J.PATREC.2020.09.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e913489a252eb36009ac3835946f6f6f5457d190\",\"title\":\"Self-supervised pain intensity estimation from facial videos via statistical spatiotemporal distillation\",\"url\":\"https://www.semanticscholar.org/paper/e913489a252eb36009ac3835946f6f6f5457d190\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1996319848\",\"name\":\"Bing Li\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1007/978-3-030-58565-5_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"title\":\"Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145989383\",\"name\":\"M. Ammar\"},{\"authorId\":\"38708414\",\"name\":\"M. Mitrea\"},{\"authorId\":\"41127231\",\"name\":\"Ismail Boujelbane\"}],\"doi\":\"10.1109/IPTA.2017.8310117\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"687cd01a2a326a63183f8f2600899e530bc3471f\",\"title\":\"HEVC stream saliency extraction: Synergies between FIT and information theory principles\",\"url\":\"https://www.semanticscholar.org/paper/687cd01a2a326a63183f8f2600899e530bc3471f\",\"venue\":\"2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145305263\",\"name\":\"M. Startsev\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":\"10.1109/CVPRW.2018.00264\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d09eb9267a3031411bfeb0ad131ffe33b0d48289\",\"title\":\"Increasing Video Saliency Model Generalizability by Training for Smooth Pursuit Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d09eb9267a3031411bfeb0ad131ffe33b0d48289\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50320765\",\"name\":\"B. Rekha\"},{\"authorId\":\"116702540\",\"name\":\"Ravi Kumar Av\"}],\"doi\":\"10.11591/ijeecs.v7.i3.pp708-717\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef446a5b2417a9b8ec1a18b299510afd7da6c72f\",\"title\":\"High Definition Video Compression Using Saliency Features\",\"url\":\"https://www.semanticscholar.org/paper/ef446a5b2417a9b8ec1a18b299510afd7da6c72f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144494743\",\"name\":\"Zhe Wu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"143847266\",\"name\":\"Bo Wu\"},{\"authorId\":\"33122401\",\"name\":\"J. Li\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"}],\"doi\":\"10.1109/ICME.2016.7552929\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3252c6c520ae06bfa82084822f857519e262103b\",\"title\":\"Video saliency prediction with optimized optical flow and gravity center bias\",\"url\":\"https://www.semanticscholar.org/paper/3252c6c520ae06bfa82084822f857519e262103b\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":\"1610.02516\",\"authors\":[{\"authorId\":\"145653633\",\"name\":\"R. Yang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TBC.2018.2795459\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfbc779750453b6bc3ee0ddbeec4dcf3c556677b\",\"title\":\"Saliency-Guided Complexity Control for HEVC Decoding\",\"url\":\"https://www.semanticscholar.org/paper/cfbc779750453b6bc3ee0ddbeec4dcf3c556677b\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"3238659\",\"name\":\"Zhaoting Ye\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TIP.2016.2628583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3ed9103b9f9eee87ee0b1d3430b44c32bc140bc\",\"title\":\"Learning to Detect Video Saliency With HEVC Features\",\"url\":\"https://www.semanticscholar.org/paper/d3ed9103b9f9eee87ee0b1d3430b44c32bc140bc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51245102\",\"name\":\"Shafin Rahman\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":\"10.1145/2857491.2857495\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"511a475863e24dcee9e814eaf9253af03c97dd53\",\"title\":\"Factors underlying inter-observer agreement in gaze patterns: predictive modelling and analysis\",\"url\":\"https://www.semanticscholar.org/paper/511a475863e24dcee9e814eaf9253af03c97dd53\",\"venue\":\"ETRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-020-01371-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"title\":\"DeepVS2.0: A Saliency-Structured Deep Learning Method for Predicting Dynamic Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.11580\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"144227173\",\"name\":\"A. Bagavathi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"title\":\"Unsupervised Gaze Prediction in Egocentric Videos by Energy-based Surprise Modeling\",\"url\":\"https://www.semanticscholar.org/paper/af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":55301,\"doi\":\"10.1109/CVPR.2015.7299189\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":16,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"12c1df9b8c6e55bd6597b335dd9d9bac9fe5ee26\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"4467252\",\"name\":\"F. Attneave\"}],\"doi\":\"10.1037/H0054663\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d0198460198fdb49b89d1646049712b3a0683df\",\"title\":\"Some informational aspects of visual perception.\",\"url\":\"https://www.semanticscholar.org/paper/6d0198460198fdb49b89d1646049712b3a0683df\",\"venue\":\"Psychological review\",\"year\":1954},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685004\",\"name\":\"H. Hadizadeh\"},{\"authorId\":\"3347231\",\"name\":\"Mario J. Enriquez\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":\"10.1109/TIP.2011.2165292\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1efdc78aee3be8af7e12941817d8c70797c48ef\",\"title\":\"Eye-Tracking Database for a Set of Standard Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/b1efdc78aee3be8af7e12941817d8c70797c48ef\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144072130\",\"name\":\"Gaurav Agarwal\"},{\"authorId\":\"145581361\",\"name\":\"A. Anbu\"},{\"authorId\":\"1803883\",\"name\":\"Aniruddha Sinha\"}],\"doi\":\"10.1109/ICME.2003.1221571\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf9663019893f4a1c20caae474da2f4115b44ea7\",\"title\":\"A fast algorithm to find the region-of-interest in the compressed MPEG domain\",\"url\":\"https://www.semanticscholar.org/paper/cf9663019893f4a1c20caae474da2f4115b44ea7\",\"venue\":\"2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144246983\",\"name\":\"H. Barlow\"}],\"doi\":\"10.1080/net.12.3.241.253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"633aee4e98d45d25e6ce9d1e623cffd77308f00c\",\"title\":\"Redundancy reduction revisited\",\"url\":\"https://www.semanticscholar.org/paper/633aee4e98d45d25e6ce9d1e623cffd77308f00c\",\"venue\":\"Network\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2061773\",\"name\":\"D. Knill\"},{\"authorId\":\"31913541\",\"name\":\"W. Richards\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d7622922c38532a0e4d138675482dd5358a0031\",\"title\":\"Perception as Bayesian Inference\",\"url\":\"https://www.semanticscholar.org/paper/3d7622922c38532a0e4d138675482dd5358a0031\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732207\",\"name\":\"G. Sullivan\"},{\"authorId\":\"145758269\",\"name\":\"J. Ohm\"},{\"authorId\":\"33906477\",\"name\":\"W. Han\"},{\"authorId\":\"1745395\",\"name\":\"T. Wiegand\"}],\"doi\":\"10.1109/TCSVT.2012.2221191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d94750bc374747d3e90c99e25ab2e238882f46ae\",\"title\":\"Overview of the High Efficiency Video Coding (HEVC) Standard\",\"url\":\"https://www.semanticscholar.org/paper/d94750bc374747d3e90c99e25ab2e238882f46ae\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36877598\",\"name\":\"Campbell B. Read\"},{\"authorId\":\"48775815\",\"name\":\"Y. Hochberg\"},{\"authorId\":\"3248364\",\"name\":\"A. Tamhane\"}],\"doi\":\"10.2307/2531790\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af550ab465b983a9673ee5319882d3f7b2c7fdfe\",\"title\":\"Multiple Comparison Procedures.\",\"url\":\"https://www.semanticscholar.org/paper/af550ab465b983a9673ee5319882d3f7b2c7fdfe\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3072213\",\"name\":\"J. Besag\"}],\"doi\":\"10.1111/J.2517-6161.1986.TB01412.X\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47865b56fee61d9c9ff477f7c79f090cc6663d3a\",\"title\":\"On the Statistical Analysis of Dirty Pictures\",\"url\":\"https://www.semanticscholar.org/paper/47865b56fee61d9c9ff477f7c79f090cc6663d3a\",\"venue\":\"\",\"year\":1986},{\"arxivId\":\"cond-mat/9805244\",\"authors\":[{\"authorId\":\"120115636\",\"name\":\"Helbing\"},{\"authorId\":\"49098097\",\"name\":\"Moln\\u00e1r\"}],\"doi\":\"10.1103/PhysRevE.51.4282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f129124da1d10b1a4b33e2dc7e01d6a4349886e7\",\"title\":\"Social force model for pedestrian dynamics.\",\"url\":\"https://www.semanticscholar.org/paper/f129124da1d10b1a4b33e2dc7e01d6a4349886e7\",\"venue\":\"Physical review. E, Statistical physics, plasmas, fluids, and related interdisciplinary topics\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39738097\",\"name\":\"Xiaohui Li\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2013.370\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2583797b4e5ee1a4bfc9da9d76e44ece4329170e\",\"title\":\"Saliency Detection via Dense and Sparse Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/2583797b4e5ee1a4bfc9da9d76e44ece4329170e\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3351294\",\"name\":\"Yu-Fei Ma\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/ICIP.2002.1037976\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"867f804ef2e6e0eb226927bdd965a18813f66ce2\",\"title\":\"A model of motion attention for video skimming\",\"url\":\"https://www.semanticscholar.org/paper/867f804ef2e6e0eb226927bdd965a18813f66ce2\",\"venue\":\"Proceedings. International Conference on Image Processing\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"116003860\",\"name\":\"J. Bergen\"}],\"doi\":\"10.1364/JOSAA.2.000284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33ce6c2f2d5128be710fb3ddd8f1117758b9b4a9\",\"title\":\"Spatiotemporal energy models for the perception of motion.\",\"url\":\"https://www.semanticscholar.org/paper/33ce6c2f2d5128be710fb3ddd8f1117758b9b4a9\",\"venue\":\"Journal of the Optical Society of America. A, Optics and image science\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1007/s12559-010-9074-z\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"title\":\"Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion\",\"url\":\"https://www.semanticscholar.org/paper/27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48294115\",\"name\":\"A. Srivastava\"},{\"authorId\":\"144714653\",\"name\":\"A. B. Lee\"},{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"},{\"authorId\":\"2438486\",\"name\":\"S.-C. Zhu\"}],\"doi\":\"10.1023/A:1021889010444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10119ba4225fa520e953f826a6fb43777756fea5\",\"title\":\"On Advances in Statistical Modeling of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/10119ba4225fa520e953f826a6fb43777756fea5\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2922977\",\"name\":\"Karthik Muthuswamy\"},{\"authorId\":\"145383458\",\"name\":\"D. Rajan\"}],\"doi\":\"10.1109/LSP.2013.2277884\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1d57378a1f39069a49a180581a0b6f5cc2f3268\",\"title\":\"Salient Motion Detection in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/f1d57378a1f39069a49a180581a0b6f5cc2f3268\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49820277\",\"name\":\"S. Anstis\"}],\"doi\":\"10.1098/rstb.1982.0100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8aa8023d72efed8cedda9c672b3f41c0528fc4a\",\"title\":\"Errata: The Perception of Apparent Movement [and Discussion]\",\"url\":\"https://www.semanticscholar.org/paper/d8aa8023d72efed8cedda9c672b3f41c0528fc4a\",\"venue\":\"\",\"year\":1982},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752732\",\"name\":\"T. Cover\"},{\"authorId\":\"37918227\",\"name\":\"J. Thomas\"}],\"doi\":\"10.1002/0471200611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dbdb4209626fd92d2436a058663206216036e68\",\"title\":\"Elements of Information Theory\",\"url\":\"https://www.semanticscholar.org/paper/7dbdb4209626fd92d2436a058663206216036e68\",\"venue\":\"\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1007/978-1-84800-279-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb77f2398d4f5c7e283572c97ed6ce300f1192a0\",\"title\":\"Markov Random Field Modeling in Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb77f2398d4f5c7e283572c97ed6ce300f1192a0\",\"venue\":\"Advances in Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3351294\",\"name\":\"Yu-Fei Ma\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/ICIP.2001.958142\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"99778b298bb7d4ed4d9e53251e650286a94f6894\",\"title\":\"A new perceived motion based shot content representation\",\"url\":\"https://www.semanticscholar.org/paper/99778b298bb7d4ed4d9e53251e650286a94f6894\",\"venue\":\"Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Geman\"},{\"authorId\":null,\"name\":\"D.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Geman . Stochastic relaxation , gibbs distribution and the Bayesian restoration of images\",\"url\":\"\",\"venue\":\"Image and Vision Computing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47206779\",\"name\":\"J. Cornell\"}],\"doi\":\"10.1080/00401706.1971.10488872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4172d0d6d2b33c6d6c75fd8f43f976260248b5a7\",\"title\":\"Introductory Mathematical Statistics: Principles and Methods\",\"url\":\"https://www.semanticscholar.org/paper/4172d0d6d2b33c6d6c75fd8f43f976260248b5a7\",\"venue\":\"\",\"year\":1970},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48531638\",\"name\":\"T. Wiegand\"},{\"authorId\":\"1732207\",\"name\":\"G. Sullivan\"},{\"authorId\":\"66302887\",\"name\":\"Gisle Bj\\u00f8ntegaard\"},{\"authorId\":\"2402670\",\"name\":\"A. Luthra\"}],\"doi\":\"10.1109/TCSVT.2003.815165\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa8183ac0429f9b0240c0e21eb534b21ace08bb7\",\"title\":\"Overview of the H.264/AVC video coding standard\",\"url\":\"https://www.semanticscholar.org/paper/aa8183ac0429f9b0240c0e21eb534b21ace08bb7\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/S0167-8655(02)00192-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"957e31a2ccbcb2e166aad737d7e873fec7e60b52\",\"title\":\"Comparing salient point detectors\",\"url\":\"https://www.semanticscholar.org/paper/957e31a2ccbcb2e166aad737d7e873fec7e60b52\",\"venue\":\"IEEE International Conference on Multimedia and Expo, 2001. ICME 2001.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3072213\",\"name\":\"J. Besag\"}],\"doi\":\"10.1111/J.2517-6161.1974.TB00999.X\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bf730243ed967afd5349bef053641a6043517a0\",\"title\":\"Spatial Interaction and the Statistical Analysis of Lattice Systems\",\"url\":\"https://www.semanticscholar.org/paper/8bf730243ed967afd5349bef053641a6043517a0\",\"venue\":\"\",\"year\":1974},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5791639\",\"name\":\"B. Moulden\"},{\"authorId\":\"144687985\",\"name\":\"J. Renshaw\"},{\"authorId\":\"145585671\",\"name\":\"G. Mather\"}],\"doi\":\"10.1068/p130387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3086c550b038e52aa74c4b7dfd3a970d99899c38\",\"title\":\"Two Channels for Flicker in the Human Visual System\",\"url\":\"https://www.semanticscholar.org/paper/3086c550b038e52aa74c4b7dfd3a970d99899c38\",\"venue\":\"Perception\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48775815\",\"name\":\"Y. Hochberg\"},{\"authorId\":\"3248364\",\"name\":\"A. Tamhane\"}],\"doi\":\"10.1002/9780470316672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d49b166f8c11dabebedb85339d8b8620af18efc4\",\"title\":\"Multiple Comparison Procedures\",\"url\":\"https://www.semanticscholar.org/paper/d49b166f8c11dabebedb85339d8b8620af18efc4\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34526725\",\"name\":\"Wonjun Kim\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2011.2125450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b96e94d318b583066df5fa946d5c2010d1704892\",\"title\":\"Spatiotemporal Saliency Detection and Its Applications in Static and Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b96e94d318b583066df5fa946d5c2010d1704892\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2498246\",\"name\":\"J. Swets\"}],\"doi\":\"10.4324/9781315806167\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d541a0ca017e28fde23f415c9d565ccbf8a97cf\",\"title\":\"Signal Detection Theory and ROC Analysis in Psychology and Diagnostics: Collected Papers\",\"url\":\"https://www.semanticscholar.org/paper/8d541a0ca017e28fde23f415c9d565ccbf8a97cf\",\"venue\":\"\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036170\",\"name\":\"Dashan Gao\"},{\"authorId\":\"8943140\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1167/8.7.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5afb01354798707950112bb4cde06ef2e4983819\",\"title\":\"On the plausibility of the discriminant center-surround hypothesis for visual saliency.\",\"url\":\"https://www.semanticscholar.org/paper/5afb01354798707950112bb4cde06ef2e4983819\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"34224146\",\"name\":\"C. Tsai\"},{\"authorId\":\"1685088\",\"name\":\"Chia-Wen Lin\"}],\"doi\":\"10.1109/TCSVT.2013.2273613\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4bda701ba50feb0344bea852f4db908b2cc9352\",\"title\":\"A Video Saliency Detection Model in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/b4bda701ba50feb0344bea852f4db908b2cc9352\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708655\",\"name\":\"B. Olshausen\"},{\"authorId\":\"49649079\",\"name\":\"D. Field\"}],\"doi\":\"10.1038/381607A0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8012c4a1e2ca663f1a04e80cbb19631a00cbab27\",\"title\":\"Emergence of simple-cell receptive field properties by learning a sparse code for natural images\",\"url\":\"https://www.semanticscholar.org/paper/8012c4a1e2ca663f1a04e80cbb19631a00cbab27\",\"venue\":\"Nature\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"1707642\",\"name\":\"D. Geman\"}],\"doi\":\"10.1109/TPAMI.1984.4767596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"459b30a9a960080f3b313e41886b1aa0e51e882c\",\"title\":\"Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images\",\"url\":\"https://www.semanticscholar.org/paper/459b30a9a960080f3b313e41886b1aa0e51e882c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746242\",\"name\":\"S. Mallat\"}],\"doi\":\"10.1109/34.192463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b78626ce1a562c05b1c06f9c805e839f9760b9ab\",\"title\":\"A Theory for Multiresolution Signal Decomposition: The Wavelet Representation\",\"url\":\"https://www.semanticscholar.org/paper/b78626ce1a562c05b1c06f9c805e839f9760b9ab\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34712076\",\"name\":\"C. Stauffer\"},{\"authorId\":\"1719838\",\"name\":\"W. Grimson\"}],\"doi\":\"10.1109/CVPR.1999.784637\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eac7287d7ef69252358c1fbddedf123e11012370\",\"title\":\"Adaptive background mixture models for real-time tracking\",\"url\":\"https://www.semanticscholar.org/paper/eac7287d7ef69252358c1fbddedf123e11012370\",\"venue\":\"Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1478477219\",\"name\":\"G.\"}],\"doi\":\"10.1515/9781400827268.494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e38d70587c55c3ef11dec6d23481046d04e19b02\",\"title\":\"A Theory for Multiresolution Signal Decomposition : The Wavelet Representation\",\"url\":\"https://www.semanticscholar.org/paper/e38d70587c55c3ef11dec6d23481046d04e19b02\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803883\",\"name\":\"Aniruddha Sinha\"},{\"authorId\":\"144072130\",\"name\":\"Gaurav Agarwal\"},{\"authorId\":\"145581361\",\"name\":\"A. Anbu\"}],\"doi\":\"10.1109/ICASSP.2004.1326506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"454ca4252fd8fa95ac21d1d4186560bb0fbf8202\",\"title\":\"Region-of-interest based compressed domain video transcoding scheme\",\"url\":\"https://www.semanticscholar.org/paper/454ca4252fd8fa95ac21d1d4186560bb0fbf8202\",\"venue\":\"2004 IEEE International Conference on Acoustics, Speech, and Signal Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482345\",\"name\":\"C. Wang\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"1680727\",\"name\":\"N. Paragios\"}],\"doi\":\"10.1016/j.cviu.2013.07.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89d5ba36428d640814c1c4f1fa36faea3f45762d\",\"title\":\"Markov Random Field modeling, inference & learning in computer vision & image understanding: A survey\",\"url\":\"https://www.semanticscholar.org/paper/89d5ba36428d640814c1c4f1fa36faea3f45762d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144246987\",\"name\":\"H. Barlow\"}],\"doi\":\"10.1007/978-94-009-3833-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58f6ff10a2d5c531b7f49dbd7c6fe9abb8efbb7\",\"title\":\"Cerebral Cortex as Model Builder\",\"url\":\"https://www.semanticscholar.org/paper/a58f6ff10a2d5c531b7f49dbd7c6fe9abb8efbb7\",\"venue\":\"\",\"year\":1987},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2550392\",\"name\":\"B. Efron\"},{\"authorId\":\"1761784\",\"name\":\"R. Tibshirani\"}],\"doi\":\"10.1007/978-1-4899-4541-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"040cf85e53e48aab1512ed8dd02d994eea0e4bcc\",\"title\":\"An Introduction to the Bootstrap\",\"url\":\"https://www.semanticscholar.org/paper/040cf85e53e48aab1512ed8dd02d994eea0e4bcc\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. N. Sihite A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention model\",\"url\":\"\",\"venue\":\"IEEE Trans . Pattern Anal . Mach . Intell .\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49820277\",\"name\":\"S. Anstis\"}],\"doi\":\"10.1098/RSTB.1980.0088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"149bb3471d98bb9168c0f71aa2f83176df144c95\",\"title\":\"The perception of apparent movement.\",\"url\":\"https://www.semanticscholar.org/paper/149bb3471d98bb9168c0f71aa2f83176df144c95\",\"venue\":\"Philosophical transactions of the Royal Society of London. Series B, Biological sciences\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1016/j.imavis.2011.11.007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b089afcf58bfdc73a956e015c82a8005ec313dac\",\"title\":\"Saliency from hierarchical adaptation through decorrelation and variance normalization\",\"url\":\"https://www.semanticscholar.org/paper/b089afcf58bfdc73a956e015c82a8005ec313dac\",\"venue\":\"Image Vis. Comput.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"2984143\",\"name\":\"R. Zabih\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"1922280\",\"name\":\"Olga Veksler\"},{\"authorId\":\"144653005\",\"name\":\"V. Kolmogorov\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"},{\"authorId\":\"1802944\",\"name\":\"M. Tappen\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"}],\"doi\":\"10.1007/11744047_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9820932d30bca5828701fd4fe351a2bd0d8883a\",\"title\":\"A Comparative Study of Energy Minimization Methods for Markov Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/a9820932d30bca5828701fd4fe351a2bd0d8883a\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"1707642\",\"name\":\"D. Geman\"}],\"doi\":\"10.1016/B978-0-08-051581-6.50057-X\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1e99c01e2f1f5783d476b78c8d0503623f3891c\",\"title\":\"Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images\",\"url\":\"https://www.semanticscholar.org/paper/b1e99c01e2f1f5783d476b78c8d0503623f3891c\",\"venue\":\"\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6105822\",\"name\":\"Pamela Reinagel\"},{\"authorId\":\"47500001\",\"name\":\"A. Zador\"}],\"doi\":\"10.1088/0954-898X_10_4_304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"559c26761e288404911b333326cb19a8a5f768ff\",\"title\":\"Natural scene statistics at the centre of gaze.\",\"url\":\"https://www.semanticscholar.org/paper/559c26761e288404911b333326cb19a8a5f768ff\",\"venue\":\"Network\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144410381\",\"name\":\"R. Margolin\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"}],\"doi\":\"10.1109/CVPR.2013.151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bde473538f4837120ab0349932376c8ffd4a0f53\",\"title\":\"What Makes a Patch Distinct?\",\"url\":\"https://www.semanticscholar.org/paper/bde473538f4837120ab0349932376c8ffd4a0f53\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2401039\",\"name\":\"Derrick J. Parkhurst\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1163/15685680360511645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfaea99353a30bbca2431ae23c7742605334d950\",\"title\":\"Scene content selected by active vision.\",\"url\":\"https://www.semanticscholar.org/paper/cfaea99353a30bbca2431ae23c7742605334d950\",\"venue\":\"Spatial vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"2408900\",\"name\":\"Viral Bhalodia\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2010.5539872\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d3f0d47449c7db37d1bae3b70db2928610a8db7\",\"title\":\"Anomaly detection in crowded scenes\",\"url\":\"https://www.semanticscholar.org/paper/9d3f0d47449c7db37d1bae3b70db2928610a8db7\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Harel\"},{\"authorId\":null,\"name\":\"C Koch\"},{\"authorId\":null,\"name\":\"P Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph-based visual saliency Advances in neural information processing systems\",\"url\":\"\",\"venue\":\"Graph-based visual saliency Advances in neural information processing systems\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1016/S0079-6123(06)55002-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d94fc289d82738a4d1071470b16ba861ea12169\",\"title\":\"Building the gist of a scene: the role of global image features in recognition.\",\"url\":\"https://www.semanticscholar.org/paper/9d94fc289d82738a4d1071470b16ba861ea12169\",\"venue\":\"Progress in brain research\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"34931109\",\"name\":\"R. Baddeley\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"}],\"doi\":\"10.1016/j.visres.2004.09.017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae38ed953333fb39eb671fce0247db65a09b3a80\",\"title\":\"Visual correlates of fixation selection: effects of scale and time\",\"url\":\"https://www.semanticscholar.org/paper/ae38ed953333fb39eb671fce0247db65a09b3a80\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. N. Sihite Borji\"},{\"authorId\":null,\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"State - ofthe - art in visual attention model\",\"url\":\"\",\"venue\":\"IEEE Trans . Pattern Anal . Mach . Intell .\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2400157\",\"name\":\"M. Kenward\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75f8a4d7ed6a0f32fa098cac967de247938d9ce5\",\"title\":\"An Introduction to the Bootstrap\",\"url\":\"https://www.semanticscholar.org/paper/75f8a4d7ed6a0f32fa098cac967de247938d9ce5\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"},{\"authorId\":\"2413415\",\"name\":\"Hongbo Yan\"},{\"authorId\":\"1683512\",\"name\":\"Liquan Shen\"},{\"authorId\":\"1998244\",\"name\":\"Yongfang Wang\"},{\"authorId\":\"35678920\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1109/ICIS.2009.165\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f44bd88dcda1b8fac106c7bd95bda6c3de5dc2e7\",\"title\":\"A Motion Attention Model Based Rate Control Algorithm for H.264/AVC\",\"url\":\"https://www.semanticscholar.org/paper/f44bd88dcda1b8fac106c7bd95bda6c3de5dc2e7\",\"venue\":\"2009 Eighth IEEE/ACIS International Conference on Computer and Information Science\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2004.834657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"title\":\"Automatic foveation for video compression using a neurobiological model of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"144902513\",\"name\":\"P. Baldi\"}],\"doi\":\"10.1016/j.visres.2008.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aebd8bab5cff769fed204dba35112e364a47e504\",\"title\":\"Bayesian surprise attracts human attention\",\"url\":\"https://www.semanticscholar.org/paper/aebd8bab5cff769fed204dba35112e364a47e504\",\"venue\":\"Vision Research\",\"year\":2009}],\"title\":\"How many bits does it take for a stimulus to be salient?\",\"topics\":[{\"topic\":\"Self-information\",\"topicId\":\"14163\",\"url\":\"https://www.semanticscholar.org/topic/14163\"},{\"topic\":\"Markov random field\",\"topicId\":\"10898\",\"url\":\"https://www.semanticscholar.org/topic/10898\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Complexity\",\"topicId\":\"167521\",\"url\":\"https://www.semanticscholar.org/topic/167521\"},{\"topic\":\"Turing completeness\",\"topicId\":\"97258\",\"url\":\"https://www.semanticscholar.org/topic/97258\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"High-level programming language\",\"topicId\":\"212045\",\"url\":\"https://www.semanticscholar.org/topic/212045\"},{\"topic\":\"Embedded system\",\"topicId\":\"4423\",\"url\":\"https://www.semanticscholar.org/topic/4423\"},{\"topic\":\"Algorithmic efficiency\",\"topicId\":\"19973\",\"url\":\"https://www.semanticscholar.org/topic/19973\"},{\"topic\":\"Mean squared error\",\"topicId\":\"49130\",\"url\":\"https://www.semanticscholar.org/topic/49130\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Markov chain\",\"topicId\":\"5418\",\"url\":\"https://www.semanticscholar.org/topic/5418\"}],\"url\":\"https://www.semanticscholar.org/paper/12c1df9b8c6e55bd6597b335dd9d9bac9fe5ee26\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"