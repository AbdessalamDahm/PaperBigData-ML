"{\"abstract\":\"While egocentric cameras like GoPro are gaining popularity, the videos they capture are long, boring, and difficult to watch from start to end. Fast forwarding (i.e. frame sampling) is a natural choice for faster video browsing. However, this accentuates the shake caused by natural head motion, making the fast forwarded video useless. We propose EgoSampling, an adaptive frame sampling that gives more stable fast forwarded videos. Adaptive frame sampling is formulated as energy minimization, whose optimal solution can be found in polynomial time. In addition, egocentric video taken while walking suffers from the left-right movement of the head as the body weight shifts from one leg to another. We turn this drawback into a feature: Stereo video can be created by sampling the frames from the left most and right most head positions of each step, forming approximate stereo-pairs.\",\"arxivId\":\"1412.3596\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\",\"url\":\"https://www.semanticscholar.org/author/2926663\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\",\"url\":\"https://www.semanticscholar.org/author/3203099\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\",\"url\":\"https://www.semanticscholar.org/author/145676235\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\",\"url\":\"https://www.semanticscholar.org/author/144406261\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":\"1811.09791\",\"authors\":[{\"authorId\":\"153362999\",\"name\":\"Y. Jung\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1609/aaai.v33i01.33018537\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69b3b29c6fabaea88d382922346d9157395a3226\",\"title\":\"Discriminative Feature Learning for Unsupervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/69b3b29c6fabaea88d382922346d9157395a3226\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1805.10538\",\"authors\":[{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-01258-8_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c413c2ee66664909d8c194f3f3e08c5f109c3c1\",\"title\":\"Video Summarization Using Fully Convolutional Sequence Networks\",\"url\":\"https://www.semanticscholar.org/paper/8c413c2ee66664909d8c194f3f3e08c5f109c3c1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.02792\",\"authors\":[{\"authorId\":\"46218538\",\"name\":\"Shuyue Lan\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"144400477\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2018.00708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82662d6680ae0444f5d76e637c414721cc6f0583\",\"title\":\"FFNet: Video Fast-Forwarding via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/82662d6680ae0444f5d76e637c414721cc6f0583\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.5753/sibgrapi.est.2019.8302\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f1c2aa137332732a0ecc9b9818dee767896f4b0\",\"title\":\"Semantic Hyperlapse: a sparse coding based and multi-importance approach for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/9f1c2aa137332732a0ecc9b9818dee767896f4b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.04160\",\"authors\":[{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/ICIP.2016.7532977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1d9effff545d429bd41e0d65cd5f39aa177860e\",\"title\":\"Fast-forward video based on semantic extraction\",\"url\":\"https://www.semanticscholar.org/paper/a1d9effff545d429bd41e0d65cd5f39aa177860e\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1802.08722\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR.2018.00253\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"title\":\"A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.12655\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/WACV45572.2020.9093330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0155df608af9c0024c6d557b16bdc15af78c5133\",\"title\":\"Personalizing Fast-Forward Videos Based on Visual and Textual Features from Social Network\",\"url\":\"https://www.semanticscholar.org/paper/0155df608af9c0024c6d557b16bdc15af78c5133\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143667768\",\"name\":\"Biao Ma\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"}],\"doi\":\"10.1109/MMSP.2017.8122223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11f5c36cd3c64ffdfa0f4c432865052e384a6bc7\",\"title\":\"Enhancing viewability for first-person videos based on a human perception model\",\"url\":\"https://www.semanticscholar.org/paper/11f5c36cd3c64ffdfa0f4c432865052e384a6bc7\",\"venue\":\"2017 IEEE 19th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1016/j.jvcir.2018.02.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4398b6dc8c524ba69cf44ba7e5a22bad703d9a5d\",\"title\":\"Making a long story short: A multi-importance fast-forwarding egocentric videos with the emphasis on relevant objects\",\"url\":\"https://www.semanticscholar.org/paper/4398b6dc8c524ba69cf44ba7e5a22bad703d9a5d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1610.02714\",\"authors\":[{\"authorId\":\"7233152\",\"name\":\"J. Finocchiaro\"},{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2017.132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05441a4e03e15e6d307030daa68fcddc88bdbd8a\",\"title\":\"Egocentric Height Estimation\",\"url\":\"https://www.semanticscholar.org/paper/05441a4e03e15e6d307030daa68fcddc88bdbd8a\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de2e8127105a37ff1f59be13a010ab0d3f4fa650\",\"title\":\"Analyzing hands with first-person computer vision\",\"url\":\"https://www.semanticscholar.org/paper/de2e8127105a37ff1f59be13a010ab0d3f4fa650\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7791948\",\"name\":\"Xufeng He\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"145147423\",\"name\":\"Tao Song\"},{\"authorId\":\"47294714\",\"name\":\"Zongpu Zhang\"},{\"authorId\":\"50774410\",\"name\":\"Zhengui Xue\"},{\"authorId\":\"1840514\",\"name\":\"R. Ma\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"},{\"authorId\":\"145676478\",\"name\":\"H. Guan\"}],\"doi\":\"10.1145/3343031.3351056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81b4f76a767b4393b2db876e3b7fd85d3f7cd820\",\"title\":\"Unsupervised Video Summarization with Attentive Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/81b4f76a767b4393b2db876e3b7fd85d3f7cd820\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"title\":\"First Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1708.04146\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"40834129\",\"name\":\"Jo\\u00e3o Pedro Klock Ferreira\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1007/978-3-319-46604-0_40\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"79ca84296f1869b1b4e986edb31de69ec113fb28\",\"title\":\"Towards Semantic Fast-Forward and Stabilized Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/79ca84296f1869b1b4e986edb31de69ec113fb28\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121638702\",\"name\":\"Jungin Park\"},{\"authorId\":\"82536700\",\"name\":\"J. Lee\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICCVW.2019.00193\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"title\":\"Video Summarization by Learning Relationships between Action and Scene\",\"url\":\"https://www.semanticscholar.org/paper/62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41051074\",\"name\":\"Kai Toyama\"},{\"authorId\":\"1717358\",\"name\":\"Y. Sumi\"}],\"doi\":\"10.1007/978-3-319-90740-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"261973e1fe559be74531f4a922750c9f7ed5825c\",\"title\":\"Quick Browsing of Shared Experience Videos Based on Conversational Field Detection\",\"url\":\"https://www.semanticscholar.org/paper/261973e1fe559be74531f4a922750c9f7ed5825c\",\"venue\":\"MobiCASE\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"8700083\",\"name\":\"Y. Huang\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"31790403\",\"name\":\"C. Buehler\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/TVCG.2017.2750671\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54201d4044b8c78b51f687321b826c3a2af099e9\",\"title\":\"Semantic-Driven Generation of Hyperlapse from 360 Degree Video\",\"url\":\"https://www.semanticscholar.org/paper/54201d4044b8c78b51f687321b826c3a2af099e9\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":\"1701.04743\",\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"49871207\",\"name\":\"Himanshu Aggarwal\"},{\"authorId\":\"49583376\",\"name\":\"Himani Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":\"10.1109/WACV.2017.57\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a55504c724d8d8bee0893f5469e6b8685dbeb1c1\",\"title\":\"Computing Egomotion with Local Loop Closures for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/a55504c724d8d8bee0893f5469e6b8685dbeb1c1\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"2003.14229\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"46464798\",\"name\":\"M. Silva\"},{\"authorId\":\"152396628\",\"name\":\"E. Ara\\u00fajo\"},{\"authorId\":\"2211313\",\"name\":\"Leandro Soriano Marcolino\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR42600.2020.01094\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"title\":\"Straight to the Point: Fast-Forwarding Videos via Reinforcement Learning Using Textual Data\",\"url\":\"https://www.semanticscholar.org/paper/bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153362999\",\"name\":\"Y. Jung\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1007/978-3-030-58595-2_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96424fde14891eb15709fab65577b2b8b146c4ce\",\"title\":\"Global-and-Local Relative Position Embedding for Unsupervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/96424fde14891eb15709fab65577b2b8b146c4ce\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.14552\",\"authors\":[{\"authorId\":\"46999304\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeafc087178102645be19fb6975f53b798061b4\",\"title\":\"Compare and Select: Video Summarization with Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/beeafc087178102645be19fb6975f53b798061b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.04437\",\"authors\":[{\"authorId\":\"46218538\",\"name\":\"Shuyue Lan\"},{\"authorId\":\"1492126885\",\"name\":\"Zhilu Wang\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1452357651\",\"name\":\"Ermin Wei\"},{\"authorId\":\"1409972269\",\"name\":\"Qi Zhu\"}],\"doi\":\"10.1145/3394171.3413767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff4f4b34cc3df01b2e278e52f7eb69f1fcebd651\",\"title\":\"Distributed Multi-agent Video Fast-forwarding\",\"url\":\"https://www.semanticscholar.org/paper/ff4f4b34cc3df01b2e278e52f7eb69f1fcebd651\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"22192364\",\"name\":\"Kartikeya Gupta\"},{\"authorId\":\"25732952\",\"name\":\"F. Ahmad\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"}],\"doi\":\"10.1109/WACV.2019.00011\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"9ac4863f4d5c0868c6151c6b0eb78d23debd063b\",\"title\":\"EGO-SLAM: A Robust Monocular SLAM for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/9ac4863f4d5c0868c6151c6b0eb78d23debd063b\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1703.10798\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"8700083\",\"name\":\"Y. Huang\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bacf9a26e10fc87fab22fbcb8a43d3741f1a83ef\",\"title\":\"Semantic-driven Generation of Hyperlapse from 360\\u00b0 Video\",\"url\":\"https://www.semanticscholar.org/paper/bacf9a26e10fc87fab22fbcb8a43d3741f1a83ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.03473\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"Michel Melo Silva\"},{\"authorId\":\"144151841\",\"name\":\"Washington Luis Souza Ramos\"},{\"authorId\":\"146694654\",\"name\":\"Felipe Cadar Chamone\"},{\"authorId\":\"40834129\",\"name\":\"Jo\\u00e3o Pedro Klock Ferreira\"},{\"authorId\":\"4661295\",\"name\":\"Mario Fernando Montenegro Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1016/j.jvcir.2018.02.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c693855b597cf2c15af9fafc9e14bd2d7c05e61\",\"title\":\"Making a long story short: A Multi-Importance Semantic for Fast-Forwarding Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/8c693855b597cf2c15af9fafc9e14bd2d7c05e61\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39765532\",\"name\":\"Miao Wang\"},{\"authorId\":\"17291694\",\"name\":\"Jun-Bang Liang\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"3075033\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TIP.2017.2749143\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3835c94da7047896760ef9cc3b65c335f180f923\",\"title\":\"Hyper-Lapse From Multiple Spatially-Overlapping Videos\",\"url\":\"https://www.semanticscholar.org/paper/3835c94da7047896760ef9cc3b65c335f180f923\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11438057\",\"name\":\"H. Bouma\"},{\"authorId\":\"145445122\",\"name\":\"J. Baan\"},{\"authorId\":\"133982738\",\"name\":\"Frank B. ter Haar\"},{\"authorId\":\"1889881\",\"name\":\"P. Eendebak\"},{\"authorId\":\"134632765\",\"name\":\"R. D. den Hollander\"},{\"authorId\":\"1909303\",\"name\":\"G. Burghouts\"},{\"authorId\":\"144502717\",\"name\":\"R. Wijn\"},{\"authorId\":\"134767384\",\"name\":\"Sebastiaan P. van den Broek\"},{\"authorId\":\"134228379\",\"name\":\"Jeroen H. C. van Rest\"}],\"doi\":\"10.1117/12.2194436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c32a94283945cd467b91cfbbe04b265a974447e8\",\"title\":\"Video content analysis on body-worn cameras for retrospective investigation\",\"url\":\"https://www.semanticscholar.org/paper/c32a94283945cd467b91cfbbe04b265a974447e8\",\"venue\":\"SPIE Security + Defence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46567493\",\"name\":\"C. Bai\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"}],\"doi\":\"10.1016/j.jvcir.2018.05.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78cd4291d123c4835b0298045aa89ba6674581b5\",\"title\":\"Image quality assessment in first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/78cd4291d123c4835b0298045aa89ba6674581b5\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3132818.3132831\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fdac02fd55308be6580ba289134a91376906b1f\",\"title\":\"Egoscanning: quickly scanning first-person videos with egocentric elastic timelines\",\"url\":\"https://www.semanticscholar.org/paper/1fdac02fd55308be6580ba289134a91376906b1f\",\"venue\":\"SIGGRAPH ASIA Emerging Technologies\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3025453.3025821\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"835680aa3c770a2360e62e467d82760936e52431\",\"title\":\"EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines\",\"url\":\"https://www.semanticscholar.org/paper/835680aa3c770a2360e62e467d82760936e52431\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1707.05564\",\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"22192364\",\"name\":\"Kartikeya Gupta\"},{\"authorId\":\"25732952\",\"name\":\"F. Ahmad\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57d55ecd850ce02e95e7f8a0b942a0debaf63a1f\",\"title\":\"Batch based Monocular SLAM for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/57d55ecd850ce02e95e7f8a0b942a0debaf63a1f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9361887\",\"name\":\"Pravin Nagar\"},{\"authorId\":\"67153756\",\"name\":\"Mansi Khemka\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"}],\"doi\":\"10.1145/3394171.3413713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25df842658e7adb7535f4d154d49bb9961b0eb6e\",\"title\":\"Concept Drift Detection for Multivariate Data Streams and Temporal Segmentation of Daylong Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/25df842658e7adb7535f4d154d49bb9961b0eb6e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388323535\",\"name\":\"Hadar Averbuch-Elor\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"}],\"doi\":\"10.1111/cgf.12823\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d348accd49cd7997a8ef116005a66d5104b27ce\",\"title\":\"Smooth Image Sequences for Data\\u2010driven Morphing\",\"url\":\"https://www.semanticscholar.org/paper/5d348accd49cd7997a8ef116005a66d5104b27ce\",\"venue\":\"Comput. Graph. Forum\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87116461\",\"name\":\"M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"80510807\",\"name\":\"E. Nascimento\"}],\"doi\":\"10.1109/SIBGRAPI-T.2019.00009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"title\":\"Fast-Forward Methods for Egocentric Videos: A Review\",\"url\":\"https://www.semanticscholar.org/paper/380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2379129\",\"name\":\"Patrizia Varini\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TMM.2017.2705915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6465d833e1a050fd959d21eecdee613c1cc869e3\",\"title\":\"Personalized Egocentric Video Summarization of Cultural Tour on User Preferences Input\",\"url\":\"https://www.semanticscholar.org/paper/6465d833e1a050fd959d21eecdee613c1cc869e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/CVPR.2016.287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46567493\",\"name\":\"C. Bai\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"}],\"doi\":\"10.1109/ICIP.2017.8296289\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"849b4d73511fafced9c4ee8b8fcfb64f3a1eb347\",\"title\":\"Mutual reference frame-quality assessment for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/849b4d73511fafced9c4ee8b8fcfb64f3a1eb347\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46567493\",\"name\":\"C. Bai\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"}],\"doi\":\"10.2352/ISSN.2470-1173.2017.14.HVEI-125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80c07876af0a9677b5c26f6189843d40626f3d26\",\"title\":\"Subjective evaluation of distortions in first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/80c07876af0a9677b5c26f6189843d40626f3d26\",\"venue\":\"HVEI\",\"year\":2017},{\"arxivId\":\"2007.08809\",\"authors\":[{\"authorId\":\"121638702\",\"name\":\"Jungin Park\"},{\"authorId\":\"1601207488\",\"name\":\"Jiyoung Lee\"},{\"authorId\":\"1646563572\",\"name\":\"Ig-Jae Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1007/978-3-030-58595-2_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20a56ec4fce1039476f1d9cd9248badb1c706df3\",\"title\":\"SumGraph: Video Summarization via Recursive Graph Modeling\",\"url\":\"https://www.semanticscholar.org/paper/20a56ec4fce1039476f1d9cd9248badb1c706df3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.06130\",\"authors\":[{\"authorId\":\"19310335\",\"name\":\"Sagie Benaim\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"3829997\",\"name\":\"M. Rubinstein\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"}],\"doi\":\"10.1109/cvpr42600.2020.00994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1708ca69799e5ae2614cc61f79ff164fd6d6baa4\",\"title\":\"SpeedNet: Learning the Speediness in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1708ca69799e5ae2614cc61f79ff164fd6d6baa4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143667768\",\"name\":\"Biao Ma\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"}],\"doi\":\"10.1145/3126686.3126748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1db6fc09b7e823c4d0d497519d38826779bd7888\",\"title\":\"Measuring and Improving the Viewing Experience of First-person Videos\",\"url\":\"https://www.semanticscholar.org/paper/1db6fc09b7e823c4d0d497519d38826779bd7888\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"47772841\",\"name\":\"Michael Lam\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2017.318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"620fe6c786d15efca7f553ad70f295e2b693b391\",\"title\":\"Unsupervised Video Summarization with Adversarial LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/620fe6c786d15efca7f553ad70f295e2b693b391\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"144362750\",\"name\":\"A. Tan\"}],\"doi\":\"10.1109/THMS.2016.2623480\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"title\":\"Summarization of Egocentric Videos: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285973\",\"name\":\"Vito Santarcangelo\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1007/978-3-319-46604-0_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41c3a2091aec6e629a85faed5b538daf26678fe6\",\"title\":\"Egocentric Vision for Visual Market Basket Analysis\",\"url\":\"https://www.semanticscholar.org/paper/41c3a2091aec6e629a85faed5b538daf26678fe6\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143667768\",\"name\":\"Biao Ma\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"}],\"doi\":\"10.3390/jimaging4090106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"075e6fcb9b6ce4750b95e5aa14b7fadacf70b051\",\"title\":\"Viewing Experience Model of First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/075e6fcb9b6ce4750b95e5aa14b7fadacf70b051\",\"venue\":\"J. Imaging\",\"year\":2018},{\"arxivId\":\"1604.02115\",\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.patcog.2016.07.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45b6562ffd8df53de69e39c91b1f28abece412d9\",\"title\":\"Trajectory aligned features for first person action recognition\",\"url\":\"https://www.semanticscholar.org/paper/45b6562ffd8df53de69e39c91b1f28abece412d9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1709.10214\",\"authors\":[{\"authorId\":\"40241141\",\"name\":\"X. Zhang\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"}],\"doi\":\"10.1111/cgf.13276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"148a45f5c5f850c5e68276fe118e74590aa6d0e4\",\"title\":\"Photometric Stabilization for Fast\\u2010forward Videos\",\"url\":\"https://www.semanticscholar.org/paper/148a45f5c5f850c5e68276fe118e74590aa6d0e4\",\"venue\":\"Comput. Graph. Forum\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"144007359\",\"name\":\"W. Kienzle\"},{\"authorId\":\"2441615\",\"name\":\"Mike Toelle\"},{\"authorId\":\"143711233\",\"name\":\"Matthew Uyttendaele\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1145/2766954\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b70d6c2fba3539d45fa0f2e15ec5a0ba3ba248\",\"title\":\"Real-time hyperlapse creation via optimal frame selection\",\"url\":\"https://www.semanticscholar.org/paper/19b70d6c2fba3539d45fa0f2e15ec5a0ba3ba248\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":\"2009.11063\",\"authors\":[{\"authorId\":\"46464798\",\"name\":\"M. Silva\"},{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"152471790\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/TPAMI.2020.2983929\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac374b7696e72c40c660c9dc5722d73b93667ec8\",\"title\":\"A Sparse Sampling-based framework for Semantic Fast-Forward of First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/ac374b7696e72c40c660c9dc5722d73b93667ec8\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1504.07469\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":\"10.1109/WACV.2016.7477708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f2b075d527e7d3b29219e5955f294f539c4764f\",\"title\":\"Compact CNN for indexing egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6f2b075d527e7d3b29219e5955f294f539c4764f\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1604.07741\",\"authors\":[{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/TCSVT.2017.2651051\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4287cf846c327271fbf2db4574d913d15b3e5441\",\"title\":\"EgoSampling: Wide View Hyperlapse From Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/4287cf846c327271fbf2db4574d913d15b3e5441\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285973\",\"name\":\"Vito Santarcangelo\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1016/j.patrec.2018.06.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bff5d681d469d2348364cb3aa5507a8bf328d275\",\"title\":\"Market basket analysis from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/bff5d681d469d2348364cb3aa5507a8bf328d275\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145634606\",\"name\":\"Daniel Gongora\"},{\"authorId\":\"2099156\",\"name\":\"Hikaru Nagano\"},{\"authorId\":\"1737580\",\"name\":\"M. Konyo\"},{\"authorId\":\"1794952\",\"name\":\"S. Tadokoro\"}],\"doi\":\"10.1007/978-3-319-93399-3_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a20a2952d34e3d9211fb6a771ae923543a273025\",\"title\":\"Vibrotactile Feedback Improves Collision Detection in Fast Playback of First-Person View Videos\",\"url\":\"https://www.semanticscholar.org/paper/a20a2952d34e3d9211fb6a771ae923543a273025\",\"venue\":\"EuroHaptics\",\"year\":2018},{\"arxivId\":\"2009.07833\",\"authors\":[{\"authorId\":\"31803091\",\"name\":\"Erika Lu\"},{\"authorId\":\"39578349\",\"name\":\"F. Cole\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"3829997\",\"name\":\"M. Rubinstein\"}],\"doi\":\"10.1145/3414685.3417760\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0277d8a16307084f1840a22ad60477b7eb5e9246\",\"title\":\"Layered neural rendering for retiming people in video\",\"url\":\"https://www.semanticscholar.org/paper/0277d8a16307084f1840a22ad60477b7eb5e9246\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":207807,\"doi\":\"10.1109/CVPR.2015.7299109\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6ce71f5bd42cf343a0f33deb2174b165d3463e89\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2013.352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"title\":\"First-Person Activity Recognition: What Are They Doing to Me?\",\"url\":\"https://www.semanticscholar.org/paper/aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2012.6247805\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"title\":\"Social interactions: A first-person perspective\",\"url\":\"https://www.semanticscholar.org/paper/014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144789467\",\"name\":\"C. Forster\"},{\"authorId\":\"1695026\",\"name\":\"Matia Pizzoli\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":\"10.1109/ICRA.2014.6906584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"035c0a712e7d153cc138efea14f85e3bb98e11c7\",\"title\":\"SVO: Fast semi-direct monocular visual odometry\",\"url\":\"https://www.semanticscholar.org/paper/035c0a712e7d153cc138efea14f85e3bb98e11c7\",\"venue\":\"2014 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ayala Triangle Run with GoPro Hero 3+ Black Edition. https://www.youtube.com/watch?v=WbWnWojOtIs\",\"url\":\"\",\"venue\":\"Ayala Triangle Run with GoPro Hero 3+ Black Edition. https://www.youtube.com/watch?v=WbWnWojOtIs\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1145/1531326.1531350\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd5bfc40da29c48cdb54571d149f05a3222d1775\",\"title\":\"Content-preserving warps for 3D video stabilization\",\"url\":\"https://www.semanticscholar.org/paper/dd5bfc40da29c48cdb54571d149f05a3222d1775\",\"venue\":\"ACM Trans. Graph.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582552\",\"name\":\"Ofir Pele\"},{\"authorId\":\"27379268\",\"name\":\"M. Werman\"}],\"doi\":\"10.1109/ICCV.2009.5459199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ab6d616f812a3108ae85b4ab130b62b650c5677\",\"title\":\"Fast and robust Earth Mover's Distances\",\"url\":\"https://www.semanticscholar.org/paper/8ab6d616f812a3108ae85b4ab130b62b650c5677\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"F Liu\"},{\"authorId\":null,\"name\":\"M Gleicher\"},{\"authorId\":null,\"name\":\"J Wang\"},{\"authorId\":null,\"name\":\"H Jin\"},{\"authorId\":null,\"name\":\"A Agarwala\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Subspace video stabilization. SIGGRAPH\",\"url\":\"\",\"venue\":\"Subspace video stabilization. SIGGRAPH\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40588702\",\"name\":\"B. D. Lucas\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd\",\"title\":\"An Iterative Image Registration Technique with an Application to Stereo Vision\",\"url\":\"https://www.semanticscholar.org/paper/a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd\",\"venue\":\"IJCAI\",\"year\":1981},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-10602-1_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"title\":\"Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gopro Inc\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"GoPro Hero Cameras\",\"url\":\"\",\"venue\":\"GoPro Hero Cameras\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2014.325\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"title\":\"Temporal Segmentation of Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3234559\",\"name\":\"E. Dijkstra\"}],\"doi\":\"10.1007/BF01386390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45786063578e814444b8247028970758bbbd0488\",\"title\":\"A note on two problems in connexion with graphs\",\"url\":\"https://www.semanticscholar.org/paper/45786063578e814444b8247028970758bbbd0488\",\"venue\":\"Numerische Mathematik\",\"year\":1959},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48613105\",\"name\":\"A. Goldstein\"},{\"authorId\":\"3230440\",\"name\":\"R. Fattal\"}],\"doi\":\"10.1145/2231816.2231824\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"223688b097f7780099e4bfd77b0e02c641a33375\",\"title\":\"Video stabilization using epipolar geometry\",\"url\":\"https://www.semanticscholar.org/paper/223688b097f7780099e4bfd77b0e02c641a33375\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"34604722\",\"name\":\"Ping Tan\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1145/2461912.2461995\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bf92ec41dfa60a1f2c4195849b7ee3f3b854035\",\"title\":\"Bundled camera paths for video stabilization\",\"url\":\"https://www.semanticscholar.org/paper/9bf92ec41dfa60a1f2c4195849b7ee3f3b854035\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"145604260\",\"name\":\"Ping Tan\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPR.2014.536\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c51db7f72bcccc5d487488d5dac4691f724b8319\",\"title\":\"SteadyFlow: Spatially Smooth Optical Flow for Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/c51db7f72bcccc5d487488d5dac4691f724b8319\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2638394\",\"name\":\"D. Sazbon\"},{\"authorId\":\"1705597\",\"name\":\"H. Rotstein\"},{\"authorId\":\"1747801\",\"name\":\"E. Rivlin\"}],\"doi\":\"10.1007/s00138-004-0152-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b528ac891506f17e615e58e9f210d1425cb0d27c\",\"title\":\"Finding the focus of expansion and estimating range using optical flow images and a matched filter\",\"url\":\"https://www.semanticscholar.org/paper/b528ac891506f17e615e58e9f210d1425cb0d27c\",\"venue\":\"Machine Vision and Applications\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38654707\",\"name\":\"F. Liu\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1145/1576246.1531350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"208048c39a9a627bb3441cbb2b7681b0c4bddcd2\",\"title\":\"Content-preserving warps for 3D video stabilization\",\"url\":\"https://www.semanticscholar.org/paper/208048c39a9a627bb3441cbb2b7681b0c4bddcd2\",\"venue\":\"SIGGRAPH '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Kopf\"},{\"authorId\":null,\"name\":\"M Cohen\"},{\"authorId\":null,\"name\":\"R Szeliski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"First- person Hyperlapse Videos - Supplemental Material\",\"url\":\"\",\"venue\":\"First- person Hyperlapse Videos - Supplemental Material\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"J. K. Hodgins\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Social interactions : A first - person perspective\",\"url\":\"\",\"venue\":\"LSD - SLAM : Large - scale direct monocular SLAM , booktitle = ECCV , year =\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/CVPR.2011.5995406\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8848d1abd31873594fc372e0022789f153112174\",\"title\":\"Fast unsupervised ego-action learning for first-person sports videos\",\"url\":\"https://www.semanticscholar.org/paper/8848d1abd31873594fc372e0022789f153112174\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1145/1899404.1899408\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52eb16e24b5b68a4f3de6820128376841b0e7e99\",\"title\":\"Subspace video stabilization\",\"url\":\"https://www.semanticscholar.org/paper/52eb16e24b5b68a4f3de6820128376841b0e7e99\",\"venue\":\"TOGS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2050315\",\"name\":\"M. Grundmann\"},{\"authorId\":\"1706355\",\"name\":\"Vivek Kwatra\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1109/CVPR.2011.5995525\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49941c788b9dd8a639b33b4208b32a740b8c7bf8\",\"title\":\"Auto-directed video stabilization with robust L1 optimal camera paths\",\"url\":\"https://www.semanticscholar.org/paper/49941c788b9dd8a639b33b4208b32a740b8c7bf8\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"2352765\",\"name\":\"Yinting Wang\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"145383433\",\"name\":\"J. Bu\"},{\"authorId\":\"145604260\",\"name\":\"Ping Tan\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPR.2012.6247662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f178dd56c2e914ded498e9fee78324520507484f\",\"title\":\"Video stabilization with a depth camera\",\"url\":\"https://www.semanticscholar.org/paper/f178dd56c2e914ded498e9fee78324520507484f\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d3ad3770ea08455de14149f77a5144882dcb124\",\"title\":\"First-person Hyperlapse Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d3ad3770ea08455de14149f77a5144882dcb124\",\"venue\":\"SIGGRAPH 2014\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17173992\",\"name\":\"B. Wrobel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"339093c7ed71919ce59a7e78979a77abd25bad0c\",\"title\":\"Multiple View Geometry in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/339093c7ed71919ce59a7e78979a77abd25bad0c\",\"venue\":\"K\\u00fcnstliche Intell.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Google\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Google Glass. https://www.google.com/glass/start\",\"url\":\"\",\"venue\":\"Google Glass. https://www.google.com/glass/start\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1145/2601097.2601195\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c445a9ca786225d08b68cda9662dec50046ed559\",\"title\":\"First-person hyper-lapse videos\",\"url\":\"https://www.semanticscholar.org/paper/c445a9ca786225d08b68cda9662dec50046ed559\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35152266\",\"name\":\"Jakob Engel\"},{\"authorId\":\"2982639\",\"name\":\"Thomas Sch\\u00f6ps\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"}],\"doi\":\"10.1007/978-3-319-10605-2_54\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c13cb6dfd26a1b545d50d05b52c99eb87b1c82b2\",\"title\":\"LSD-SLAM: Large-Scale Direct Monocular SLAM\",\"url\":\"https://www.semanticscholar.org/paper/c13cb6dfd26a1b545d50d05b52c99eb87b1c82b2\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VisualSFM : A Visual Structure from Motion System, Changchang Wu, http://ccwu.me/vsfm\",\"url\":\"\",\"venue\":\"VisualSFM : A Visual Structure from Motion System, Changchang Wu, http://ccwu.me/vsfm\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143616798\",\"name\":\"Zheng Lu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.350\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"title\":\"Story-Driven Summarization for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"GoPro Trucking! -Yukon to Alaska 1080p. https://www.youtube.com/watch?v=3dOrN6-V7V0\",\"url\":\"\",\"venue\":\"GoPro Trucking! -Yukon to Alaska 1080p. https://www.youtube.com/watch?v=3dOrN6-V7V0\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Cohen\"},{\"authorId\":null,\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"First - person Hyperlapse Videos - Supplemental Material\",\"url\":\"\",\"venue\":\"In CVPR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2173574\",\"name\":\"N. Petrovic\"},{\"authorId\":\"1698689\",\"name\":\"N. Jojic\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/s11042-005-0895-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"294ffe6c81f311a9bc8d26e3d763c9d05beb4c1b\",\"title\":\"Adaptive Video Fast Forward\",\"url\":\"https://www.semanticscholar.org/paper/294ffe6c81f311a9bc8d26e3d763c9d05beb4c1b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2005}],\"title\":\"EgoSampling: Fast-forward and stereo for egocentric videos\",\"topics\":[{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"3D reconstruction\",\"topicId\":\"63486\",\"url\":\"https://www.semanticscholar.org/topic/63486\"},{\"topic\":\"Fast forward\",\"topicId\":\"244726\",\"url\":\"https://www.semanticscholar.org/topic/244726\"},{\"topic\":\"Rendering (computer graphics)\",\"topicId\":\"15667\",\"url\":\"https://www.semanticscholar.org/topic/15667\"},{\"topic\":\"Time complexity\",\"topicId\":\"3448\",\"url\":\"https://www.semanticscholar.org/topic/3448\"},{\"topic\":\"Energy minimization\",\"topicId\":\"49183\",\"url\":\"https://www.semanticscholar.org/topic/49183\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Human body weight\",\"topicId\":\"191093\",\"url\":\"https://www.semanticscholar.org/topic/191093\"},{\"topic\":\"Approximation algorithm\",\"topicId\":\"87\",\"url\":\"https://www.semanticscholar.org/topic/87\"},{\"topic\":\"Travis CI\",\"topicId\":\"805619\",\"url\":\"https://www.semanticscholar.org/topic/805619\"},{\"topic\":\"Frame language\",\"topicId\":\"224664\",\"url\":\"https://www.semanticscholar.org/topic/224664\"}],\"url\":\"https://www.semanticscholar.org/paper/6ce71f5bd42cf343a0f33deb2174b165d3463e89\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"