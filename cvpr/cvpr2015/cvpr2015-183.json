"{\"abstract\":\"We introduce a realtime facial tracking system specifically designed for performance capture in unconstrained settings using a consumer-level RGB-D sensor. Our framework provides uninterrupted 3D facial tracking, even in the presence of extreme occlusions such as those caused by hair, hand-to-face gestures, and wearable accessories. Anyone's face can be instantly tracked and the users can be switched without an extra calibration step. During tracking, we explicitly segment face regions from any occluding parts by detecting outliers in the shape and appearance input using an exponentially smoothed and user-adaptive tracking model as prior. Our face segmentation combines depth and RGB input data and is also robust against illumination changes. To enable continuous and reliable facial feature tracking in the color channels, we synthesize plausible face textures in the occluded regions. Our tracking model is personalized on-the-fly by progressively refining the user's identity, expressions, and texture with reliable samples and temporal filtering. We demonstrate robust and high-fidelity facial tracking on a wide range of subjects with highly incomplete and largely occluded data. Our system works in everyday environments and is fully unobtrusive to the user, impacting consumer AR applications and surveillance.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2519072\",\"name\":\"Pei-Lun Hsieh\",\"url\":\"https://www.semanticscholar.org/author/2519072\"},{\"authorId\":\"1797422\",\"name\":\"Chongyang Ma\",\"url\":\"https://www.semanticscholar.org/author/1797422\"},{\"authorId\":\"2977637\",\"name\":\"J. Yu\",\"url\":\"https://www.semanticscholar.org/author/2977637\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\",\"url\":\"https://www.semanticscholar.org/author/1706574\"}],\"citationVelocity\":17,\"citations\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5770dd225501ff3764f9023f19a76fad28127d4\",\"title\":\"Real Time Online Facial Expression Transfer with Single Video Camera\",\"url\":\"https://www.semanticscholar.org/paper/f5770dd225501ff3764f9023f19a76fad28127d4\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2980179.2982419\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5f470993c9028cd2f4dffd914c74085e5c8d0f9\",\"title\":\"Corrective 3D reconstruction of lips from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/f5f470993c9028cd2f4dffd914c74085e5c8d0f9\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"2048839\",\"name\":\"Laura C. Trutoiu\"},{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"1792471\",\"name\":\"Lingyu Wei\"},{\"authorId\":\"2476056\",\"name\":\"Tristan Trutna\"},{\"authorId\":\"2519072\",\"name\":\"Pei-Lun Hsieh\"},{\"authorId\":\"40362211\",\"name\":\"A. Nicholls\"},{\"authorId\":\"1797422\",\"name\":\"Chongyang Ma\"}],\"doi\":\"10.1145/2766939\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bac3b434276b4a2151c966977ac2b5e6bdaf1954\",\"title\":\"Facial performance sensing head-mounted display\",\"url\":\"https://www.semanticscholar.org/paper/bac3b434276b4a2151c966977ac2b5e6bdaf1954\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"51150529\",\"name\":\"L\\u00e1szl\\u00f3 A. Jeni\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TPAMI.2017.2750687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f201baf618574108bcee50e9a8b65f5174d832ee\",\"title\":\"Viewpoint-Consistent 3D Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/f201baf618574108bcee50e9a8b65f5174d832ee\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51152514\",\"name\":\"G. Zoss\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"144877481\",\"name\":\"M. Gross\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"}],\"doi\":\"10.1145/3306346.3323044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5358cfb6d91d07208c31c0630bba4fd60e6697b0\",\"title\":\"Accurate markerless jaw tracking for facial performance capture\",\"url\":\"https://www.semanticscholar.org/paper/5358cfb6d91d07208c31c0630bba4fd60e6697b0\",\"venue\":\"TOGS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780750\",\"name\":\"Timo Bolkart\"},{\"authorId\":\"1792200\",\"name\":\"Stefanie Wuhrer\"}],\"doi\":\"10.1109/CVPR.2016.531\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ada022763782fd9ce8b830cbff5bc35972a2d08e\",\"title\":\"A Robust Multilinear Model Learning Framework for 3D Faces\",\"url\":\"https://www.semanticscholar.org/paper/ada022763782fd9ce8b830cbff5bc35972a2d08e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.06536\",\"authors\":[{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"3468872\",\"name\":\"Antti Herva\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"9965153\",\"name\":\"Ronald Yu\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":\"10.1145/3099564.3099581\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e519ec5b979330a77db97b0605d67b229ec2ddf\",\"title\":\"Production-level facial performance capture using deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/0e519ec5b979330a77db97b0605d67b229ec2ddf\",\"venue\":\"Symposium on Computer Animation\",\"year\":2017},{\"arxivId\":\"1812.07603\",\"authors\":[{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"39600032\",\"name\":\"F. Bernard\"},{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"3090007\",\"name\":\"Gaurav Bharaj\"},{\"authorId\":\"48857539\",\"name\":\"M. Elgharib\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/CVPR.2019.01107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f09070b62123f6662bc77f4b670d54cc7156bcc5\",\"title\":\"FML: Face Model Learning From Videos\",\"url\":\"https://www.semanticscholar.org/paper/f09070b62123f6662bc77f4b670d54cc7156bcc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.05323\",\"authors\":[{\"authorId\":\"8280113\",\"name\":\"Y. Guo\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"145042667\",\"name\":\"L. Cai\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1693057\",\"name\":\"J. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"693905c29feb7f9be3517308c8a9c2dc68aa8682\",\"title\":\"Self-supervised CNN for Unconstrained 3D Facial Performance Capture from an RGB-D Camera\",\"url\":\"https://www.semanticscholar.org/paper/693905c29feb7f9be3517308c8a9c2dc68aa8682\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1610.03151\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3084822.3084841\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b82576f647e74f83cf02023ece6610cc7c2eff7f\",\"title\":\"Demo of FaceVR: real-time facial reenactment and eye gaze control in virtual reality\",\"url\":\"https://www.semanticscholar.org/paper/b82576f647e74f83cf02023ece6610cc7c2eff7f\",\"venue\":\"SIGGRAPH Emerging Technologies\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"2766399\",\"name\":\"X. Yang\"},{\"authorId\":\"47196655\",\"name\":\"Z. Wang\"},{\"authorId\":\"145665810\",\"name\":\"Zhidong Xiao\"},{\"authorId\":\"2662243\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1002/cav.1697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8a43ba60926ea59d09a5a0e41a5ede7cd666e06\",\"title\":\"Real\\u2010time facial expression transfer with single video camera\",\"url\":\"https://www.semanticscholar.org/paper/e8a43ba60926ea59d09a5a0e41a5ede7cd666e06\",\"venue\":\"Comput. Animat. Virtual Worlds\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2394458\",\"name\":\"C. Siegl\"},{\"authorId\":\"2782622\",\"name\":\"V. Lange\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"145914862\",\"name\":\"F. Bauer\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"}],\"doi\":\"10.1109/TVCG.2017.2734428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c7baff9c74f7eb565b3a72d0371f3547d9de99b\",\"title\":\"FaceForge: Markerless Non-Rigid Face Multi-Projection Mapping\",\"url\":\"https://www.semanticscholar.org/paper/2c7baff9c74f7eb565b3a72d0371f3547d9de99b\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67251988\",\"name\":\"L. Ma\"},{\"authorId\":\"145140508\",\"name\":\"Zhigang Deng\"}],\"doi\":\"10.1145/3306131.3317016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"080cf74b658ac518d91c78d6cc3ff75808cd73b1\",\"title\":\"Real-time hierarchical facial performance capture\",\"url\":\"https://www.semanticscholar.org/paper/080cf74b658ac518d91c78d6cc3ff75808cd73b1\",\"venue\":\"I3D\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36706427\",\"name\":\"Fuhao Shi\"}],\"doi\":\"10.1007/978-3-319-30808-1_189-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e69324ee93b6afefd7231e1c3e9eeb7986b4c1\",\"title\":\"Video-Based Performance Driven Facial Animation\",\"url\":\"https://www.semanticscholar.org/paper/c0e69324ee93b6afefd7231e1c3e9eeb7986b4c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404255981\",\"name\":\"Hayato Onizuka\"},{\"authorId\":\"39492787\",\"name\":\"Diego Thomas\"},{\"authorId\":\"47849822\",\"name\":\"H. Uchiyama\"},{\"authorId\":\"2175502\",\"name\":\"Rin-ichiro Taniguchi\"}],\"doi\":\"10.1109/ICCVW.2019.00265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2edf178640432489ee09928e75a6e4a75ca19201\",\"title\":\"Landmark-Guided Deformation Transfer of Template Facial Expressions for Automatic Generation of Avatar Blendshapes\",\"url\":\"https://www.semanticscholar.org/paper/2edf178640432489ee09928e75a6e4a75ca19201\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67251988\",\"name\":\"L. Ma\"},{\"authorId\":\"123580486\",\"name\":\"Zhi-gang Deng\"}],\"doi\":\"10.1145/3384382.3384519\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e9217a61e3c5a2d3ddb87a09b3b3ed709e8759d\",\"title\":\"Real-time Face Video Swapping From A Single Portrait\",\"url\":\"https://www.semanticscholar.org/paper/8e9217a61e3c5a2d3ddb87a09b3b3ed709e8759d\",\"venue\":\"I3D\",\"year\":2020},{\"arxivId\":\"2008.01332\",\"authors\":[{\"authorId\":\"28903267\",\"name\":\"Elo\\u00efse Berson\"},{\"authorId\":\"1704722\",\"name\":\"Catherine Soladi\\u00e9\"},{\"authorId\":\"1688878\",\"name\":\"Nicolas Stoiber\"}],\"doi\":\"10.1145/3406971.3406985\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8f961b9df7046e102ec29985b1e046f44bb5640\",\"title\":\"Real-Time Cleaning and Refinement of Facial Animation Signals\",\"url\":\"https://www.semanticscholar.org/paper/b8f961b9df7046e102ec29985b1e046f44bb5640\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Yu\"},{\"authorId\":\"9206411\",\"name\":\"Kenneth Alberto Funes Mora\"},{\"authorId\":\"1719610\",\"name\":\"Jean-Marc Odobez\"}],\"doi\":\"10.1109/TPAMI.2018.2841403\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4da3b3888a74365fead3057f34d986c0a439fb84\",\"title\":\"HeadFusion: 360<inline-formula><tex-math notation=\\\"LaTeX\\\">${^\\\\circ }$</tex-math> <alternatives><inline-graphic xlink:href=\\\"yu-ieq1-2841403.gif\\\"/></alternatives></inline-formula> Head Pose Tracking Combining 3D Morphable Model and 3D Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/4da3b3888a74365fead3057f34d986c0a439fb84\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3182644\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0af15b37d9a24c05df92d9004d11f78fa69b00c8\",\"title\":\"FaceVR: Real-Time Gaze-Aware Facial Reenactment in Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/0af15b37d9a24c05df92d9004d11f78fa69b00c8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1812.02897\",\"authors\":[{\"authorId\":\"2785037\",\"name\":\"Michael Bao\"},{\"authorId\":\"1993512\",\"name\":\"D. Hyde\"},{\"authorId\":\"41156173\",\"name\":\"Xinru Hua\"},{\"authorId\":\"1688994\",\"name\":\"Ronald Fedkiw\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f19d1cab7afbe3d6e174ddc443599870241dec97\",\"title\":\"Improved Search Strategies with Application to Estimating Facial Blendshape Parameters.\",\"url\":\"https://www.semanticscholar.org/paper/f19d1cab7afbe3d6e174ddc443599870241dec97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152483517\",\"name\":\"Cunkuan Yuan\"},{\"authorId\":\"145139010\",\"name\":\"K. Li\"},{\"authorId\":\"144891983\",\"name\":\"Yu-Kun Lai\"},{\"authorId\":\"119924337\",\"name\":\"Y. Liu\"},{\"authorId\":\"145308166\",\"name\":\"Jing-Yu Yang\"}],\"doi\":\"10.1109/ICME.2019.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8428e4a1c1edefb03cae69c4ec3572085c8e169\",\"title\":\"3D Face Reprentation and Reconstruction with Multi-scale Graph Convolutional Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/d8428e4a1c1edefb03cae69c4ec3572085c8e169\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48641400\",\"name\":\"Shuang Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f74e4cb8b563e9f075fccb5fa48aeb9370157fa\",\"title\":\"3D facial performance capture from monocular RGB video\",\"url\":\"https://www.semanticscholar.org/paper/1f74e4cb8b563e9f075fccb5fa48aeb9370157fa\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1702.05619\",\"authors\":[{\"authorId\":\"38349449\",\"name\":\"L. Jiang\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"2964129\",\"name\":\"Bailin Deng\"},{\"authorId\":\"47892305\",\"name\":\"H. Li\"},{\"authorId\":\"1724542\",\"name\":\"Ligang Liu\"}],\"doi\":\"10.1109/TIP.2018.2845697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3a6106ecb69204a6fd64e82e7a8184ab564082a\",\"title\":\"3D Face Reconstruction With Geometry Details From a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/e3a6106ecb69204a6fd64e82e7a8184ab564082a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46926723\",\"name\":\"Adelaide Burt\"},{\"authorId\":\"4735756\",\"name\":\"D. Crewther\"}],\"doi\":\"10.3389/fpsyg.2020.01842\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"027b548863608ddfd72320ac238cf83797d5107f\",\"title\":\"The 4D Space-Time Dimensions of Facial Perception\",\"url\":\"https://www.semanticscholar.org/paper/027b548863608ddfd72320ac238cf83797d5107f\",\"venue\":\"Frontiers in Psychology\",\"year\":2020},{\"arxivId\":\"2004.10557\",\"authors\":[{\"authorId\":\"39492787\",\"name\":\"D. Thomas\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c94c7c4ef1ad8a496915ea1510ab0d2d64eab129\",\"title\":\"Real-time Simultaneous 3D Head Modeling and Facial Motion Capture with an RGB-D camera\",\"url\":\"https://www.semanticscholar.org/paper/c94c7c4ef1ad8a496915ea1510ab0d2d64eab129\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2316162\",\"name\":\"Wanxin Xu\"},{\"authorId\":\"2074615\",\"name\":\"S. Cheung\"}],\"doi\":\"10.1109/ICMEW.2019.00095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4addf2e6a5c3f6574ea76bf6d555e77d652f2bce\",\"title\":\"Fully Automatic Photorealistic Facial Expression and Eye Gaze Transfer with a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/4addf2e6a5c3f6574ea76bf6d555e77d652f2bce\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":\"1809.04763\",\"authors\":[{\"authorId\":\"144219155\",\"name\":\"Shu Liang\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1007/978-3-319-46475-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"105f8fa53b9a0fc8037b7cf5b4d8729bbf053ac3\",\"title\":\"Head Reconstruction from Internet Photos\",\"url\":\"https://www.semanticscholar.org/paper/105f8fa53b9a0fc8037b7cf5b4d8729bbf053ac3\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1707.05653\",\"authors\":[{\"authorId\":\"51177106\",\"name\":\"Chandrasekhar Bhagavatula\"},{\"authorId\":\"47894545\",\"name\":\"Chenchen Zhu\"},{\"authorId\":\"1769788\",\"name\":\"K. Luu\"},{\"authorId\":\"1794486\",\"name\":\"M. Savvides\"}],\"doi\":\"10.1109/ICCV.2017.429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b558f5ae01e48f104a1d7f081df32b3497e64610\",\"title\":\"Faster than Real-Time Facial Alignment: A 3D Spatial Transformer Network Approach in Unconstrained Poses\",\"url\":\"https://www.semanticscholar.org/paper/b558f5ae01e48f104a1d7f081df32b3497e64610\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41031702\",\"name\":\"Victoria Fern\\u00e1ndez Abrevaya\"},{\"authorId\":\"1792200\",\"name\":\"Stefanie Wuhrer\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"}],\"doi\":\"10.1109/3DV.2018.00050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ddf59fddd97a40f77ba169298bde80cd38d0d82\",\"title\":\"Spatiotemporal Modeling for Efficient Registration of Dynamic 3D Faces\",\"url\":\"https://www.semanticscholar.org/paper/0ddf59fddd97a40f77ba169298bde80cd38d0d82\",\"venue\":\"2018 International Conference on 3D Vision (3DV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2935689\",\"name\":\"Yilong Liu\"},{\"authorId\":\"143979425\",\"name\":\"F. Xu\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"},{\"authorId\":\"49144235\",\"name\":\"X. Tong\"},{\"authorId\":\"40476154\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"2316043\",\"name\":\"Q. Huo\"}],\"doi\":\"10.1145/2816795.2818122\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e656deb595c384026d901f3c23b4e9dcafb02182\",\"title\":\"Video-audio driven real-time facial animation\",\"url\":\"https://www.semanticscholar.org/paper/e656deb595c384026d901f3c23b4e9dcafb02182\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042608\",\"name\":\"Songnan Li\"},{\"authorId\":\"3841174\",\"name\":\"Fanzi Wu\"},{\"authorId\":\"144857882\",\"name\":\"Tianhao Zhao\"},{\"authorId\":\"143889690\",\"name\":\"R. Shi\"},{\"authorId\":\"1684869\",\"name\":\"K. N. Ngan\"}],\"doi\":\"10.1109/APSIPA.2016.7820866\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b95023870b21653a3777c640aeb32c342a3d906e\",\"title\":\"A facial expression model with generative albedo texture\",\"url\":\"https://www.semanticscholar.org/paper/b95023870b21653a3777c640aeb32c342a3d906e\",\"venue\":\"2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34659390\",\"name\":\"Umur Aybars Ciftci\"},{\"authorId\":\"46447561\",\"name\":\"X. Zhang\"},{\"authorId\":\"35262624\",\"name\":\"Lijun Tin\"}],\"doi\":\"10.1109/ICME.2017.8019545\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d62356b0b6490aad238adf0a29016140245735b3\",\"title\":\"Partially occluded facial action recognition and interaction in virtual reality applications\",\"url\":\"https://www.semanticscholar.org/paper/d62356b0b6490aad238adf0a29016140245735b3\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"144149529\",\"name\":\"Andrew Feng\"},{\"authorId\":\"2875539\",\"name\":\"O. Alexander\"},{\"authorId\":\"1968170\",\"name\":\"G. Fyffe\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"},{\"authorId\":\"1748095\",\"name\":\"Ryosuke Ichikari\"},{\"authorId\":\"47892305\",\"name\":\"H. Li\"},{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"2817315\",\"name\":\"Evan A. Suma\"},{\"authorId\":\"145109163\",\"name\":\"Ari Shapiro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32be839a8cd7c71fb4ba93a60251f05c87a3d286\",\"title\":\"1 . RELATED WORK 1 . 1 3 D Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/32be839a8cd7c71fb4ba93a60251f05c87a3d286\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2135194\",\"name\":\"Evgeny Nuger\"},{\"authorId\":\"1719617\",\"name\":\"B. Benhabib\"}],\"doi\":\"10.1007/s10846-018-0773-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5aec1d1787749f0deb6f6dd8e341f3d7e68478ac\",\"title\":\"Multi-Camera Active-Vision for Markerless Shape Recovery of Unknown Deforming Objects\",\"url\":\"https://www.semanticscholar.org/paper/5aec1d1787749f0deb6f6dd8e341f3d7e68478ac\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1454630096\",\"name\":\"Jo\\u00e3o Ot\\u00e1vio de Lucena\"},{\"authorId\":\"145056169\",\"name\":\"J. P. Lima\"},{\"authorId\":\"39492787\",\"name\":\"D. Thomas\"},{\"authorId\":\"1395570439\",\"name\":\"Veronica Teichrieb\"}],\"doi\":\"10.1109/SVR.2019.00034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fe081e8a99885328628db866ed67eaea1141966\",\"title\":\"Real-Time Facial Motion Capture Using RGB-D Images Under Complex Motion and Occlusions\",\"url\":\"https://www.semanticscholar.org/paper/0fe081e8a99885328628db866ed67eaea1141966\",\"venue\":\"2019 21st Symposium on Virtual and Augmented Reality (SVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145287266\",\"name\":\"Quan Wen\"},{\"authorId\":\"143979428\",\"name\":\"F. Xu\"},{\"authorId\":\"143865487\",\"name\":\"Jun-Hai Yong\"}],\"doi\":\"10.1109/TVCG.2016.2641442\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5efdf48ca56b78e34dc2f2f0ce107a25793d3fc2\",\"title\":\"Real-Time 3D Eye Performance Reconstruction for RGBD Cameras\",\"url\":\"https://www.semanticscholar.org/paper/5efdf48ca56b78e34dc2f2f0ce107a25793d3fc2\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2017},{\"arxivId\":\"1604.02647\",\"authors\":[{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"50290121\",\"name\":\"Tianye Li\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1007/978-3-319-46484-8_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd8a517b6435b58c59a77678db16db2cdd69f835\",\"title\":\"Real-Time Facial Segmentation and Performance Capture from RGB Input\",\"url\":\"https://www.semanticscholar.org/paper/dd8a517b6435b58c59a77678db16db2cdd69f835\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2316162\",\"name\":\"Wanxin Xu\"}],\"doi\":\"10.13023/ETD.2018.303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"784b91dd2fa8ad5af854606132a5fb643309b2fa\",\"title\":\"AFFECT-PRESERVING VISUAL PRIVACY PROTECTION\",\"url\":\"https://www.semanticscholar.org/paper/784b91dd2fa8ad5af854606132a5fb643309b2fa\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974737\",\"name\":\"Peter Schickel\"},{\"authorId\":\"150329275\",\"name\":\"Ulrich Seng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"feb27d8c0a26ff57850d38d350832854f7bcecd0\",\"title\":\"Apparatus and method for overlaying at least a portion of an object with a virtual surface\",\"url\":\"https://www.semanticscholar.org/paper/feb27d8c0a26ff57850d38d350832854f7bcecd0\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23728438\",\"name\":\"P. Adrian\"}],\"doi\":\"10.22028/D291-26785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15a3c96a0cf4c0d7f4abd025572255f82e017ff7\",\"title\":\"High-quality face capture, animation and editing from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/15a3c96a0cf4c0d7f4abd025572255f82e017ff7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50812076\",\"name\":\"J. Yu\"},{\"authorId\":\"3050542\",\"name\":\"L. Yu\"}],\"doi\":\"10.1109/ICIP.2018.8451618\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dc51e2bcda3a104edd3fd45b4d2b7e447a7b774\",\"title\":\"Synthesizing Photo-Realistic 3D Talking Head: Learning Lip Synchronicity and Emotion from Audio and Video\",\"url\":\"https://www.semanticscholar.org/paper/5dc51e2bcda3a104edd3fd45b4d2b7e447a7b774\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"47196655\",\"name\":\"Z. Wang\"},{\"authorId\":\"2766399\",\"name\":\"X. Yang\"},{\"authorId\":\"38465624\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/ICCVW.2017.97\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1331042f6a02db689d907da52a7ef660b3a80e8c\",\"title\":\"Realtime Dynamic 3D Facial Reconstruction for Monocular Video In-the-Wild\",\"url\":\"https://www.semanticscholar.org/paper/1331042f6a02db689d907da52a7ef660b3a80e8c\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1968170\",\"name\":\"G. Fyffe\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"143682166\",\"name\":\"L. Huynh\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"2815984\",\"name\":\"Jay Busch\"},{\"authorId\":\"145776381\",\"name\":\"A. Jones\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"}],\"doi\":\"10.1111/cgf.13127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79096aa11fb5f293f7f63e71924fe7b0b702520b\",\"title\":\"Multi\\u2010View Stereo on Consistent Face Topology\",\"url\":\"https://www.semanticscholar.org/paper/79096aa11fb5f293f7f63e71924fe7b0b702520b\",\"venue\":\"Comput. Graph. Forum\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126419\",\"name\":\"Kekai Sheng\"},{\"authorId\":\"38690089\",\"name\":\"Weiming Dong\"},{\"authorId\":\"40311083\",\"name\":\"Yan Kong\"},{\"authorId\":\"143700357\",\"name\":\"X. Mei\"},{\"authorId\":\"47786559\",\"name\":\"J. Li\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"39495638\",\"name\":\"B. Hu\"}],\"doi\":\"10.1111/cgf.12760\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64e82b42e1c41250bdf9eb952686631287cfd410\",\"title\":\"Evaluating the Quality of Face Alignment without Ground Truth\",\"url\":\"https://www.semanticscholar.org/paper/64e82b42e1c41250bdf9eb952686631287cfd410\",\"venue\":\"Comput. Graph. Forum\",\"year\":2015},{\"arxivId\":\"1610.08481\",\"authors\":[{\"authorId\":\"2613340\",\"name\":\"Yajie Zhao\"},{\"authorId\":\"50537003\",\"name\":\"Q. Xu\"},{\"authorId\":\"2257812\",\"name\":\"Xinyu Huang\"},{\"authorId\":\"153518023\",\"name\":\"Rui-gang Yang\"}],\"doi\":\"10.1109/VR.2019.8797925\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdca4b00ffcb7a352d89766b84f96c5a4eb07af4\",\"title\":\"Mask-off: Synthesizing Face Images in the Presence of Head-mounted Displays\",\"url\":\"https://www.semanticscholar.org/paper/fdca4b00ffcb7a352d89766b84f96c5a4eb07af4\",\"venue\":\"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"},{\"authorId\":\"36572049\",\"name\":\"ShiHong Xia\"}],\"doi\":\"10.1109/TVCG.2019.2938165\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be8a386bdc318ebbd03975da0d081577071bf252\",\"title\":\"Realtime and Accurate 3D Eye Gaze Capture with DCNN-Based Iris and Pupil Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/be8a386bdc318ebbd03975da0d081577071bf252\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2021},{\"arxivId\":\"1706.01820\",\"authors\":[{\"authorId\":\"49268985\",\"name\":\"M. Kowalski\"},{\"authorId\":\"1930272\",\"name\":\"J. Naruniec\"}],\"doi\":\"10.1109/LSP.2016.2608139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a843206fde4b95ed590787709cc308d4bd25d7b\",\"title\":\"Face Alignment Using K-Cluster Regression Forests With Weighted Splitting\",\"url\":\"https://www.semanticscholar.org/paper/7a843206fde4b95ed590787709cc308d4bd25d7b\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152398039\",\"name\":\"J. M. D. Barros\"},{\"authorId\":\"3407706\",\"name\":\"Vladislav Golyanik\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":\"10.1109/ICIP.2019.8803330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4a3a495217fd06fcbe7a895060bcaaf67368781\",\"title\":\"Face It!: A Pipeline for Real-Time Performance-Driven Facial Animation\",\"url\":\"https://www.semanticscholar.org/paper/f4a3a495217fd06fcbe7a895060bcaaf67368781\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2872629\",\"name\":\"G. Koulieris\"},{\"authorId\":\"2413675\",\"name\":\"K. Aksit\"},{\"authorId\":\"2267017\",\"name\":\"M. Stengel\"},{\"authorId\":\"145394421\",\"name\":\"Rafa\\u0142 K. Mantiuk\"},{\"authorId\":\"1694233\",\"name\":\"K. Mania\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"}],\"doi\":\"10.1111/cgf.13654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a629c78964eb6b6b0736eb0ac2901856dd6bb9ad\",\"title\":\"Near\\u2010Eye Display and Tracking Technologies for Virtual and Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/a629c78964eb6b6b0736eb0ac2901856dd6bb9ad\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3408696\",\"name\":\"Vincent Barrielle\"},{\"authorId\":\"1688878\",\"name\":\"Nicolas Stoiber\"},{\"authorId\":\"2782397\",\"name\":\"Cedric Cagniart\"}],\"doi\":\"10.1111/cgf.12836\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3eb5f2b0ad0b807212212d49b20b90e4b1769313\",\"title\":\"BlendForces: A Dynamic Framework for Facial Animation\",\"url\":\"https://www.semanticscholar.org/paper/3eb5f2b0ad0b807212212d49b20b90e4b1769313\",\"venue\":\"Comput. Graph. Forum\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768641\",\"name\":\"M. Klaudiny\"},{\"authorId\":\"40513205\",\"name\":\"Steven G. McDonagh\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"3315742\",\"name\":\"K. Mitchell\"}],\"doi\":\"10.1111/cgf.13129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a12dc0ae6ea356565d29dfc32cfa195eb0c1b27d\",\"title\":\"Real\\u2010Time Multi\\u2010View Facial Capture with Synthetic Training\",\"url\":\"https://www.semanticscholar.org/paper/a12dc0ae6ea356565d29dfc32cfa195eb0c1b27d\",\"venue\":\"Comput. Graph. Forum\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144398246\",\"name\":\"Yu Yu\"},{\"authorId\":\"9206411\",\"name\":\"Kenneth Alberto Funes Mora\"},{\"authorId\":\"1719610\",\"name\":\"Jean-Marc Odobez\"}],\"doi\":\"10.1109/TPAMI.2018.2841403\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4da3b3888a74365fead3057f34d986c0a439fb84\",\"title\":\"HeadFusion: 360\\u00b0 Head Pose Tracking Combining 3D Morphable Model and 3D Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/4da3b3888a74365fead3057f34d986c0a439fb84\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144398235\",\"name\":\"Yu Yu\"},{\"authorId\":\"9206411\",\"name\":\"K. Mora\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1109/FG.2017.90\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f7f532c4a59d41616c87b898b794858a7c2c894\",\"title\":\"Robust and Accurate 3D Head Pose Estimation through 3DMM and Online Head Model Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/6f7f532c4a59d41616c87b898b794858a7c2c894\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116000590\",\"name\":\"Yuping Ye\"},{\"authorId\":\"50780806\",\"name\":\"Zhan Song\"},{\"authorId\":\"1490771743\",\"name\":\"Junguang Guo\"},{\"authorId\":\"152739311\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/ACCESS.2020.2979518\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0871fc4bae12eff00c344b001a9abbc5898439c\",\"title\":\"SIAT-3DFE: A High-Resolution 3D Facial Expression Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e0871fc4bae12eff00c344b001a9abbc5898439c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.02114\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"},{\"authorId\":\"143686397\",\"name\":\"KingNgi Ngan\"}],\"doi\":\"10.1109/TPAMI.2018.2877675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"77024298c8f8796574978ceadb01af4f73b34cd6\",\"title\":\"Visibility Constrained Generative Model for Depth-Based 3D Facial Pose Tracking\",\"url\":\"https://www.semanticscholar.org/paper/77024298c8f8796574978ceadb01af4f73b34cd6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51152514\",\"name\":\"G. Zoss\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"32363579\",\"name\":\"P. B\\u00e9rard\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"}],\"doi\":\"10.1145/3197517.3201382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53f8202cd27cbe70cd87143e020d37f9a6829ccf\",\"title\":\"An empirical rig for jaw animation\",\"url\":\"https://www.semanticscholar.org/paper/53f8202cd27cbe70cd87143e020d37f9a6829ccf\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144618612\",\"name\":\"D. Hyde\"},{\"authorId\":\"2785037\",\"name\":\"Michael Bao\"},{\"authorId\":\"1688994\",\"name\":\"Ronald Fedkiw\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50e2a94bb31eb662d65067dd8c2a5e4f901f4f96\",\"title\":\"On Obtaining Sparse Semantic Solutions for Inverse Problems, Control, and Neural Network Training\",\"url\":\"https://www.semanticscholar.org/paper/50e2a94bb31eb662d65067dd8c2a5e4f901f4f96\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"2149730\",\"name\":\"A. Feng\"},{\"authorId\":\"2875539\",\"name\":\"O. Alexander\"},{\"authorId\":\"1968170\",\"name\":\"G. Fyffe\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"},{\"authorId\":\"1748095\",\"name\":\"Ryosuke Ichikari\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"2817315\",\"name\":\"Evan A. Suma\"},{\"authorId\":\"145109163\",\"name\":\"Ari Shapiro\"}],\"doi\":\"10.1145/2915926.2915936\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2de933e2468682e95bf9321ed294e46ac1b3bcd\",\"title\":\"Rapid Photorealistic Blendshape Modeling from RGB-D Sensors\",\"url\":\"https://www.semanticscholar.org/paper/f2de933e2468682e95bf9321ed294e46ac1b3bcd\",\"venue\":\"CASA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021652\",\"name\":\"Changwei Luo\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/TMM.2019.2903724\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"669db9c8307859aad14a3c40172b89b73e3466db\",\"title\":\"Real-Time Head Pose Estimation and Face Modeling From a Depth Image\",\"url\":\"https://www.semanticscholar.org/paper/669db9c8307859aad14a3c40172b89b73e3466db\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"2004.12452\",\"authors\":[{\"authorId\":\"10745567\",\"name\":\"Sitao Xiang\"},{\"authorId\":\"49986481\",\"name\":\"Yu-ming Gu\"},{\"authorId\":\"31044670\",\"name\":\"P. Xiang\"},{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"47666365\",\"name\":\"H. Chen\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37e8ac88190fef3de23c1f441e25b0944e2d9dfa\",\"title\":\"One-Shot Identity-Preserving Portrait Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/37e8ac88190fef3de23c1f441e25b0944e2d9dfa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3408696\",\"name\":\"Vincent Barrielle\"},{\"authorId\":\"1688878\",\"name\":\"Nicolas Stoiber\"}],\"doi\":\"10.1111/cgf.13450\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42c68757a810f2d6bb2e154e01cec0dc5bd0fc18\",\"title\":\"Realtime Performance\\u2010Driven Physical Simulation for Facial Animation\",\"url\":\"https://www.semanticscholar.org/paper/42c68757a810f2d6bb2e154e01cec0dc5bd0fc18\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10798523\",\"name\":\"C. C. Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/TPAMI.2018.2824816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"title\":\"Towards Personalized Image Captioning via Multimodal Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39492787\",\"name\":\"D. Thomas\"},{\"authorId\":\"144370212\",\"name\":\"R. Taniguchi\"}],\"doi\":\"10.1109/CVPR.2016.359\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"2918bd6c139e691fd46f4fa36846ef4459e8a333\",\"title\":\"Augmented Blendshapes for Real-Time Simultaneous 3D Head Modeling and Facial Motion Capture\",\"url\":\"https://www.semanticscholar.org/paper/2918bd6c139e691fd46f4fa36846ef4459e8a333\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"1897190\",\"name\":\"Haiyang Li\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"}],\"doi\":\"10.1016/j.neucom.2018.03.045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"049432957ad52969f9ecb0b72fcfbf7fe8802e09\",\"title\":\"Photo-realistic 2D expression transfer based on FFT and modified Poisson image editing\",\"url\":\"https://www.semanticscholar.org/paper/049432957ad52969f9ecb0b72fcfbf7fe8802e09\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2810757\",\"name\":\"Muhammad Sikandar Lal Khan\"},{\"authorId\":\"49915572\",\"name\":\"A. Halawani\"},{\"authorId\":\"46933981\",\"name\":\"Shafiq ur R\\u00e9hman\"},{\"authorId\":\"47893075\",\"name\":\"Haibo Li\"}],\"doi\":\"10.1109/TCDS.2018.2828865\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fc0f800152807eddcc55d57ee977092b348b516\",\"title\":\"Action Augmented Real Virtuality: A Design for Presence\",\"url\":\"https://www.semanticscholar.org/paper/4fc0f800152807eddcc55d57ee977092b348b516\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1706.01789\",\"authors\":[{\"authorId\":\"49268985\",\"name\":\"M. Kowalski\"},{\"authorId\":\"1930272\",\"name\":\"J. Naruniec\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"}],\"doi\":\"10.1109/CVPRW.2017.254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98b83d56ebc4714dcb6b72bfdb426d739b7fb86f\",\"title\":\"Deep Alignment Network: A Convolutional Neural Network for Robust Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/98b83d56ebc4714dcb6b72bfdb426d739b7fb86f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145287266\",\"name\":\"Quan Wen\"},{\"authorId\":\"143979434\",\"name\":\"Feng Xu\"},{\"authorId\":\"145871213\",\"name\":\"M. Lu\"},{\"authorId\":\"143865487\",\"name\":\"Jun-Hai Yong\"}],\"doi\":\"10.1145/3130800.3130837\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b286ed9f36240e1d11b585d65133db84b52122c\",\"title\":\"Real-time 3D eyelids tracking from semantic edges\",\"url\":\"https://www.semanticscholar.org/paper/2b286ed9f36240e1d11b585d65133db84b52122c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"18141691\",\"name\":\"P. Eastwood\"}],\"doi\":\"10.1016/j.patcog.2017.04.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1aa5e6c61e6e3c37e68039ce05d8d0a3b5687f08\",\"title\":\"Deep, dense and accurate 3D face correspondence for generating population specific deformable models\",\"url\":\"https://www.semanticscholar.org/paper/1aa5e6c61e6e3c37e68039ce05d8d0a3b5687f08\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2816795.2818056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"890f137efc064f82450c776e6a4141eb9f08fabc\",\"title\":\"Real-time expression transfer for facial reenactment\",\"url\":\"https://www.semanticscholar.org/paper/890f137efc064f82450c776e6a4141eb9f08fabc\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2768528\",\"name\":\"C. Wang\"},{\"authorId\":\"36706427\",\"name\":\"Fuhao Shi\"},{\"authorId\":\"2314567\",\"name\":\"S. Xia\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"}],\"doi\":\"10.1145/2897824.2925947\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b285337ba61c2bb54181dbbb4f4863efe1aa6ec2\",\"title\":\"Realtime 3D eye gaze animation using a single RGB camera\",\"url\":\"https://www.semanticscholar.org/paper/b285337ba61c2bb54181dbbb4f4863efe1aa6ec2\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1703.08738\",\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"37278009\",\"name\":\"Fangda Han\"},{\"authorId\":\"102737340\",\"name\":\"X. Peng\"},{\"authorId\":\"49470520\",\"name\":\"X. Zhang\"},{\"authorId\":\"143980996\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"},{\"authorId\":\"1387332262\",\"name\":\"Dimitris N. Metaxas\"}],\"doi\":\"10.1016/j.cag.2019.01.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34ad523bfefd8307e8b98187d9bf0a199fa81fc6\",\"title\":\"Sketch-based Face Editing in Video Using Identity Deformation Transfer\",\"url\":\"https://www.semanticscholar.org/paper/34ad523bfefd8307e8b98187d9bf0a199fa81fc6\",\"venue\":\"Comput. Graph.\",\"year\":2019},{\"arxivId\":\"2007.14808\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3292039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"title\":\"Face2Face: real-time face capture and reenactment of RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"venue\":\"Commun. ACM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35756782\",\"name\":\"Jascha Achenbach\"},{\"authorId\":\"3165678\",\"name\":\"T. Waltemate\"},{\"authorId\":\"1701376\",\"name\":\"Marc Erich Latoschik\"},{\"authorId\":\"1716234\",\"name\":\"M. Botsch\"}],\"doi\":\"10.1145/3139131.3139154\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eec1bd6c600ddf36c3d82557313101feeb669d0\",\"title\":\"Fast generation of realistic virtual humans\",\"url\":\"https://www.semanticscholar.org/paper/2eec1bd6c600ddf36c3d82557313101feeb669d0\",\"venue\":\"VRST\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34760532\",\"name\":\"Xuhui Jia\"},{\"authorId\":\"143727905\",\"name\":\"H. Yang\"},{\"authorId\":\"35130187\",\"name\":\"Xiaolong Zhu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"1939702\",\"name\":\"Yifeng Niu\"},{\"authorId\":\"40392393\",\"name\":\"K. Chan\"}],\"doi\":\"10.5244/C.30.135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb87045600da73b07f0757f345a937b1c8097463\",\"title\":\"Reflective Regression of 2D-3D Face Shape Across Large Pose\",\"url\":\"https://www.semanticscholar.org/paper/fb87045600da73b07f0757f345a937b1c8097463\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883542\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/VR.2019.8798288\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"818ce1e96569e19567ab3c9b5711504b4a9e3b51\",\"title\":\"A Real-Time Music VR System for 3D External and Internal Articulators\",\"url\":\"https://www.semanticscholar.org/paper/818ce1e96569e19567ab3c9b5711504b4a9e3b51\",\"venue\":\"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48708284\",\"name\":\"Z. Wang\"},{\"authorId\":\"50031238\",\"name\":\"X. Yang\"},{\"authorId\":\"40648819\",\"name\":\"Jianjun Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6f4be3f6171292d3895f83ab784cf2574563968\",\"title\":\"Realtime Dynamic 3 D Facial Reconstruction for Monocular Video Inthe-Wild Shuang\",\"url\":\"https://www.semanticscholar.org/paper/c6f4be3f6171292d3895f83ab784cf2574563968\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1390801159\",\"name\":\"Chang Wen Chen\"},{\"authorId\":\"152763940\",\"name\":\"Zengfu Wang\"}],\"doi\":\"10.1145/3343031.3350865\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e1426e33714c40434bf9dc820aac663bf533537\",\"title\":\"3D Singing Head for Music VR: Learning External and Internal Articulatory Synchronicity from Lyric, Audio and Notes\",\"url\":\"https://www.semanticscholar.org/paper/2e1426e33714c40434bf9dc820aac663bf533537\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1902.10744\",\"authors\":[{\"authorId\":\"25022309\",\"name\":\"B. Chaudhuri\"},{\"authorId\":\"3407986\",\"name\":\"Noranart Vesdapunt\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00995\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e722e37748c487748db743d2d0cbe7868489738b\",\"title\":\"Joint Face Detection and Facial Motion Retargeting for Multiple Faces\",\"url\":\"https://www.semanticscholar.org/paper/e722e37748c487748db743d2d0cbe7868489738b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88026659\",\"name\":\"T. Ma\"},{\"authorId\":\"49121187\",\"name\":\"B. Peng\"},{\"authorId\":\"46315010\",\"name\":\"W. Wang\"},{\"authorId\":\"143863957\",\"name\":\"J. Dong\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96077b4fdb828b09cfce969d7da037ebeccb41f7\",\"title\":\"Any-to-one Face Reenactment Based on Conditional Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/96077b4fdb828b09cfce969d7da037ebeccb41f7\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904114\",\"name\":\"E. Kim\"},{\"authorId\":\"145534401\",\"name\":\"C. Moritz\"}],\"doi\":\"10.1007/978-3-319-50835-1_61\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af8974835e20173417e72d77d558a04fafdf580d\",\"title\":\"Enhancing the Communication Spectrum in Collaborative Virtual Environments\",\"url\":\"https://www.semanticscholar.org/paper/af8974835e20173417e72d77d558a04fafdf580d\",\"venue\":\"ISVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/cgf.13382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fda48e021f7c1445406fa7db32a443726e0ef8d3\",\"title\":\"State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/fda48e021f7c1445406fa7db32a443726e0ef8d3\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018},{\"arxivId\":\"1910.01403\",\"authors\":[{\"authorId\":\"1387997460\",\"name\":\"Kimia Dinashi\"},{\"authorId\":\"81287136\",\"name\":\"Ramin Toosi\"},{\"authorId\":\"1697566\",\"name\":\"M. A. Akhaee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"835d33271fe306ac3ef1fdc83e8dd2740c022fab\",\"title\":\"Face Manifold: Manifold Learning for Synthetic Face Generation\",\"url\":\"https://www.semanticscholar.org/paper/835d33271fe306ac3ef1fdc83e8dd2740c022fab\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153275560\",\"name\":\"Jiahao Geng\"},{\"authorId\":\"34620893\",\"name\":\"T. Shao\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"143663883\",\"name\":\"Y. Weng\"},{\"authorId\":\"144078074\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/3272127.3275043\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c654d13b3e228a15e83853d23b85dce106f994\",\"title\":\"Warp-guided GANs for single-photo facial animation\",\"url\":\"https://www.semanticscholar.org/paper/59c654d13b3e228a15e83853d23b85dce106f994\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144698110\",\"name\":\"L. Hu\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"1792471\",\"name\":\"Lingyu Wei\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"2567921\",\"name\":\"Jaewoo Seo\"},{\"authorId\":\"2112520\",\"name\":\"Jens Fursund\"},{\"authorId\":\"3132226\",\"name\":\"I. Sadeghi\"},{\"authorId\":\"30331199\",\"name\":\"C. Sun\"},{\"authorId\":null,\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1145/3130800.31310887\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6ae7941dcec920d5726d50d1b1cdfe4dde34d35\",\"title\":\"Avatar digitization from a single image for real-time rendering\",\"url\":\"https://www.semanticscholar.org/paper/d6ae7941dcec920d5726d50d1b1cdfe4dde34d35\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1145/2980179.2980252\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f7c8dd0d2a4de4a75880ee5b382f9bccd63488f\",\"title\":\"High-fidelity facial and speech animation for VR HMDs\",\"url\":\"https://www.semanticscholar.org/paper/7f7c8dd0d2a4de4a75880ee5b382f9bccd63488f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140064\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1109/CVPR.2016.262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba11b4feb04a472cb5e5962697ed6faa653dc647\",\"title\":\"Face2Face: Real-Time Face Capture and Reenactment of RGB Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba11b4feb04a472cb5e5962697ed6faa653dc647\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"2567921\",\"name\":\"Jaewoo Seo\"},{\"authorId\":\"144521811\",\"name\":\"J. Xing\"},{\"authorId\":\"1792471\",\"name\":\"Lingyu Wei\"},{\"authorId\":\"2825680\",\"name\":\"Zimo Li\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"51153125\",\"name\":\"Aviral Agarwal\"},{\"authorId\":\"2112520\",\"name\":\"Jens Fursund\"},{\"authorId\":\"46178891\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3272127.3275075\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38bb99d876d91dbd5b2223de55c271e2b3d39f4d\",\"title\":\"paGAN: real-time avatars using dynamic textures\",\"url\":\"https://www.semanticscholar.org/paper/38bb99d876d91dbd5b2223de55c271e2b3d39f4d\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1704.06485\",\"authors\":[{\"authorId\":\"47465525\",\"name\":\"Cesc Chunseong Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"title\":\"Attend to You: Personalized Image Captioning with Context Sequence Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.11729\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3197517.3201350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99079538a5b3fbcb7ef2c259e7675004dec28e7d\",\"title\":\"HeadOn: Real-time Reenactment of Human Portrait Videos\",\"url\":\"https://www.semanticscholar.org/paper/99079538a5b3fbcb7ef2c259e7675004dec28e7d\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"2012.03065\",\"authors\":[{\"authorId\":\"47131172\",\"name\":\"Guy Gafni\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"51283751\",\"name\":\"Michael Zollhofer\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"890398bb6364141f8b4a798fbc1c1605a871bd1d\",\"title\":\"Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/890398bb6364141f8b4a798fbc1c1605a871bd1d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"49657607\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2890493\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"052b01ba3c128a8965b8943c7973e1a9b6b66c24\",\"title\":\"Reconstruction of Personalized 3D Face Rigs from Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/052b01ba3c128a8965b8943c7973e1a9b6b66c24\",\"venue\":\"TOGS\",\"year\":2016},{\"arxivId\":\"2010.00560\",\"authors\":[{\"authorId\":\"22133106\",\"name\":\"Jiaman Li\"},{\"authorId\":\"80324884\",\"name\":\"Zheng-Fei Kuang\"},{\"authorId\":\"49339501\",\"name\":\"Y. Zhao\"},{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":\"30467754\",\"name\":\"Karl Bladin\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3414685.3417817\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e4db0399b7c7d33e58b6e876b81fbc061cae758\",\"title\":\"Dynamic facial asset and rig generation from a single scan\",\"url\":\"https://www.semanticscholar.org/paper/1e4db0399b7c7d33e58b6e876b81fbc061cae758\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"},{\"authorId\":\"1684869\",\"name\":\"K. N. Ngan\"}],\"doi\":\"10.1109/CVPR.2017.489\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"57f42653d34980a92c1bd73a12df360ca68b0ba3\",\"title\":\"A Generative Model for Depth-Based Robust 3D Facial Pose Tracking\",\"url\":\"https://www.semanticscholar.org/paper/57f42653d34980a92c1bd73a12df360ca68b0ba3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"}],\"doi\":\"10.2312/2631994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4b03bb5ef6bae133a5ee6f6989d2c79220696b4\",\"title\":\"Face2Face: Real-time Facial Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/c4b03bb5ef6bae133a5ee6f6989d2c79220696b4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2785037\",\"name\":\"Michael Bao\"},{\"authorId\":\"41156173\",\"name\":\"Xinru Hua\"},{\"authorId\":\"1688994\",\"name\":\"Ronald Fedkiw\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b41a3268430e8c6d8a1072b704386657e60a7bb\",\"title\":\"Improved Search Strategies for Determining Facial Expression\",\"url\":\"https://www.semanticscholar.org/paper/9b41a3268430e8c6d8a1072b704386657e60a7bb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"39040964\",\"name\":\"J. Romero\"},{\"authorId\":\"1403428213\",\"name\":\"Gerard Pons-Moll\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"1892850\",\"name\":\"Naureen Mahmood\"}],\"doi\":\"10.1145/2897826.2927326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37eae9174dc8eabdacf79f1eaa9e844ddc44110a\",\"title\":\"Learning human body shapes in motion\",\"url\":\"https://www.semanticscholar.org/paper/37eae9174dc8eabdacf79f1eaa9e844ddc44110a\",\"venue\":\"SIGGRAPH Courses\",\"year\":2016},{\"arxivId\":\"1909.01815\",\"authors\":[{\"authorId\":\"34460642\",\"name\":\"B. Egger\"},{\"authorId\":\"145242734\",\"name\":\"W. Smith\"},{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"1792200\",\"name\":\"Stefanie Wuhrer\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"39600032\",\"name\":\"F. Bernard\"},{\"authorId\":\"1780750\",\"name\":\"Timo Bolkart\"},{\"authorId\":\"2780587\",\"name\":\"Adam Kortylewski\"},{\"authorId\":\"3293655\",\"name\":\"S. Romdhani\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2880906\",\"name\":\"V. Blanz\"},{\"authorId\":\"152979813\",\"name\":\"T. Vetter\"}],\"doi\":\"10.1145/3395208\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"579fe5fa694cf6b27229fd0f0ce7dc487e0ceb18\",\"title\":\"3D Morphable Face Models\\u2014Past, Present, and Future\",\"url\":\"https://www.semanticscholar.org/paper/579fe5fa694cf6b27229fd0f0ce7dc487e0ceb18\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020}],\"corpusId\":14046631,\"doi\":\"10.1109/CVPR.2015.7298776\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"973953b488324d569fff89b2297620cc7e742427\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"},{\"authorId\":\"1808760\",\"name\":\"S. Omohundro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56efe7bf4bd52a6369d9ebbe55033e81e716f7d0\",\"title\":\"Surface Learning with Applications to Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/56efe7bf4bd52a6369d9ebbe55033e81e716f7d0\",\"venue\":\"NIPS\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246174\",\"name\":\"T. Weise\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/1599470.1599472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b56de69c598ebdf9a53e5c4c16fa11e07a3e24b1\",\"title\":\"Face/Off: live facial puppetry\",\"url\":\"https://www.semanticscholar.org/paper/b56de69c598ebdf9a53e5c4c16fa11e07a3e24b1\",\"venue\":\"SCA '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40565290\",\"name\":\"Haibo Li\"},{\"authorId\":\"2402858\",\"name\":\"P. Roivainen\"},{\"authorId\":\"1767736\",\"name\":\"R. Forchheimer\"}],\"doi\":\"10.1109/34.216724\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac38092add978eefedede183c0d07702fb05a711\",\"title\":\"3-D Motion Estimation in Model-Based Facial Image Coding\",\"url\":\"https://www.semanticscholar.org/paper/ac38092add978eefedede183c0d07702fb05a711\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716234\",\"name\":\"M. Botsch\"},{\"authorId\":\"1398656181\",\"name\":\"O. Sorkine-Hornung\"}],\"doi\":\"10.1109/TVCG.2007.1054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"087fb59f5fe1911797f06dc041864939efa52894\",\"title\":\"On Linear Variational Surface Deformation Methods\",\"url\":\"https://www.semanticscholar.org/paper/087fb59f5fe1911797f06dc041864939efa52894\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2075613\",\"name\":\"Y. Chen\"},{\"authorId\":\"1775992\",\"name\":\"H. Wu\"},{\"authorId\":\"36706427\",\"name\":\"Fuhao Shi\"},{\"authorId\":\"49144235\",\"name\":\"X. Tong\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"}],\"doi\":\"10.1109/ICCV.2013.449\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c68085a64289f6efa3c868e6962445ccf0635322\",\"title\":\"Accurate and Robust 3D Facial Capture Using a Single RGBD Camera\",\"url\":\"https://www.semanticscholar.org/paper/c68085a64289f6efa3c868e6962445ccf0635322\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7205190\",\"name\":\"T. Cootes\"},{\"authorId\":\"50564384\",\"name\":\"G. Edwards\"},{\"authorId\":\"144482985\",\"name\":\"C. Taylor\"}],\"doi\":\"10.1109/34.927467\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1cd4b045f47c567ea6ecb997f415a847b4982ab\",\"title\":\"Active Appearance Models\",\"url\":\"https://www.semanticscholar.org/paper/c1cd4b045f47c567ea6ecb997f415a847b4982ab\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1964574\",\"name\":\"Y. Yacoob\"}],\"doi\":\"10.1109/ICCV.1995.466915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ef915fa9e5b2260d4b45927c0033a7ba53bf66e\",\"title\":\"Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion\",\"url\":\"https://www.semanticscholar.org/paper/4ef915fa9e5b2260d4b45927c0033a7ba53bf66e\",\"venue\":\"Proceedings of IEEE International Conference on Computer Vision\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817134\",\"name\":\"F. Pighin\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"}],\"doi\":\"10.1109/ICCV.1999.791210\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70daf7471194bec2db140f968067a935de657b5a\",\"title\":\"Resynthesizing facial animation through 3D model-based tracking\",\"url\":\"https://www.semanticscholar.org/paper/70daf7471194bec2db140f968067a935de657b5a\",\"venue\":\"Proceedings of the Seventh IEEE International Conference on Computer Vision\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36005450\",\"name\":\"Chen Cao\"},{\"authorId\":\"7939453\",\"name\":\"Q. Hou\"},{\"authorId\":\"144078074\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/2601097.2601204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ed53365aace52cae1128aacc84b51536fe10ca\",\"title\":\"Displaced dynamic expression regression for real-time facial tracking and animation\",\"url\":\"https://www.semanticscholar.org/paper/75ed53365aace52cae1128aacc84b51536fe10ca\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684626\",\"name\":\"B. Heisele\"}],\"doi\":\"10.1007/springerreference_70864\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f62b496bdb22a9169f5af4ca755229356588069\",\"title\":\"Face Detection\",\"url\":\"https://www.semanticscholar.org/paper/0f62b496bdb22a9169f5af4ca755229356588069\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"152761038\",\"name\":\"F. Hahn\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"3083909\",\"name\":\"B. Bickel\"},{\"authorId\":\"1777539\",\"name\":\"P. Beardsley\"},{\"authorId\":\"1724072\",\"name\":\"C. Gotsman\"},{\"authorId\":\"1693475\",\"name\":\"R. W. Sumner\"},{\"authorId\":\"143720818\",\"name\":\"M. Gro\\u00df\"}],\"doi\":\"10.1145/1964921.1964970\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e48437eddcacfbeff01c3edd409369c9637a3357\",\"title\":\"High-quality passive facial performance capture using anchor frames\",\"url\":\"https://www.semanticscholar.org/paper/e48437eddcacfbeff01c3edd409369c9637a3357\",\"venue\":\"SIGGRAPH '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246174\",\"name\":\"T. Weise\"},{\"authorId\":\"35119991\",\"name\":\"Sofien Bouaziz\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/2010324.1964972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88129ed70b949058308f293b38de0d5b0fd9b360\",\"title\":\"Realtime performance-based facial animation\",\"url\":\"https://www.semanticscholar.org/paper/88129ed70b949058308f293b38de0d5b0fd9b360\",\"venue\":\"SIGGRAPH 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381836\",\"name\":\"T. Sugimoto\"},{\"authorId\":\"1684580\",\"name\":\"M. Fukushima\"},{\"authorId\":\"73755947\",\"name\":\"T. Ibaraki\"}],\"doi\":\"10.1016/0377-0427(94)00093-G\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0db099cee4062b6948101f107aade82f192ba35\",\"title\":\"A parallel relaxation method for quadratic programming problems with interval constraints\",\"url\":\"https://www.semanticscholar.org/paper/d0db099cee4062b6948101f107aade82f192ba35\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"2977637\",\"name\":\"J. Yu\"},{\"authorId\":\"40508248\",\"name\":\"Yuting Ye\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1145/2461912.2462019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eca7098c427567c4d5f4c37872d8f3b7f5427c26\",\"title\":\"Realtime facial animation with on-the-fly correctives\",\"url\":\"https://www.semanticscholar.org/paper/eca7098c427567c4d5f4c37872d8f3b7f5427c26\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702706\",\"name\":\"H. Zhang\"},{\"authorId\":\"3276873\",\"name\":\"O. V. Kaick\"},{\"authorId\":\"50599471\",\"name\":\"R. Dyer\"}],\"doi\":\"10.1111/j.1467-8659.2010.01655.x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e863e533ee2b419eb9bdeb124db055b9ce7c837d\",\"title\":\"Spectral Mesh Processing\",\"url\":\"https://www.semanticscholar.org/paper/e863e533ee2b419eb9bdeb124db055b9ce7c837d\",\"venue\":\"Comput. Graph. Forum\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706573\",\"name\":\"L. Williams\"}],\"doi\":\"10.1145/97879.97906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5569fc532eb94ec167f8ffc204ef17585e040c8c\",\"title\":\"Performance-driven facial animation\",\"url\":\"https://www.semanticscholar.org/paper/5569fc532eb94ec167f8ffc204ef17585e040c8c\",\"venue\":\"SIGGRAPH\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4457581\",\"name\":\"M. Omizo\"},{\"authorId\":\"117742811\",\"name\":\"Susan H. Radner\"},{\"authorId\":\"152546078\",\"name\":\"R. M. McPherson\"}],\"doi\":\"10.1177/105345128301800314\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7130af16b91ce2d26dee12e9fd5b4891d2f769\",\"title\":\"Modeling\",\"url\":\"https://www.semanticscholar.org/paper/ff7130af16b91ce2d26dee12e9fd5b4891d2f769\",\"venue\":\"\",\"year\":1983},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898210\",\"name\":\"G. Ghiasi\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/CVPR.2014.306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65126e0b1161fc8212643b8ff39c1d71d262fbc1\",\"title\":\"Occlusion Coherence: Localizing Occluded Faces with a Hierarchical Deformable Part Model\",\"url\":\"https://www.semanticscholar.org/paper/65126e0b1161fc8212643b8ff39c1d71d262fbc1\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32857606\",\"name\":\"B. Guenter\"},{\"authorId\":\"33901780\",\"name\":\"C. Grimm\"},{\"authorId\":\"145242174\",\"name\":\"D. Wood\"},{\"authorId\":\"1704103\",\"name\":\"H. Malvar\"},{\"authorId\":\"1817134\",\"name\":\"F. Pighin\"}],\"doi\":\"10.1145/280814.280822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f310f764c47633a4d4e8ccc77cefbb3eb22631\",\"title\":\"Making faces\",\"url\":\"https://www.semanticscholar.org/paper/e0f310f764c47633a4d4e8ccc77cefbb3eb22631\",\"venue\":\"SIGGRAPH '98\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32176501\",\"name\":\"E. Chuang\"},{\"authorId\":\"9223633\",\"name\":\"C. Bregler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"429d73f95aac6d26c24f7eef1754bfee0051e489\",\"title\":\"Performance Driven Facial Animation using Blendshape Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/429d73f95aac6d26c24f7eef1754bfee0051e489\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"8611534\",\"name\":\"Sumit Basu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"144994682\",\"name\":\"A. Pentland\"}],\"doi\":\"10.1109/CA.1996.540489\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89686ce7e6985b9a9b3c6e19886e365fff6f04b2\",\"title\":\"Modeling, tracking and interactive animation of faces and heads//using input from video\",\"url\":\"https://www.semanticscholar.org/paper/89686ce7e6985b9a9b3c6e19886e365fff6f04b2\",\"venue\":\"Proceedings Computer Animation '96\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716722\",\"name\":\"D. DeCarlo\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1023/A:1008122917811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e8aa06aa2125008a1baea0dafb4a945892abe61\",\"title\":\"Optical Flow Constraints on Deformable Models with Applications to Face Tracking\",\"url\":\"https://www.semanticscholar.org/paper/8e8aa06aa2125008a1baea0dafb4a945892abe61\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403267733\",\"name\":\"X. Burgos-Artizzu\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/ICCV.2013.191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2724ba85ec4a66de18da33925e537f3902f21249\",\"title\":\"Robust Face Landmark Estimation under Occlusion\",\"url\":\"https://www.semanticscholar.org/paper/2724ba85ec4a66de18da33925e537f3902f21249\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2880906\",\"name\":\"V. Blanz\"},{\"authorId\":\"152979813\",\"name\":\"T. Vetter\"}],\"doi\":\"10.1145/311535.311556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae0ef252d1b42df430ffb90724132040abf20341\",\"title\":\"A morphable model for the synthesis of 3D faces\",\"url\":\"https://www.semanticscholar.org/paper/ae0ef252d1b42df430ffb90724132040abf20341\",\"venue\":\"SIGGRAPH '99\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33731953\",\"name\":\"R. Gross\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"},{\"authorId\":\"145347688\",\"name\":\"S. Baker\"}],\"doi\":\"10.1016/j.imavis.2005.08.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"398e6e4305d5db275537fbff919b80dee8e821ef\",\"title\":\"Active appearance models with occlusion\",\"url\":\"https://www.semanticscholar.org/paper/398e6e4305d5db275537fbff919b80dee8e821ef\",\"venue\":\"Image Vis. Comput.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3060344\",\"name\":\"Hongjun Jia\"},{\"authorId\":\"153366834\",\"name\":\"A. Martinez\"}],\"doi\":\"10.1109/CVPR.2009.5206862\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba6cfa6dca22175d7a833f08e4d2d75392f93d57\",\"title\":\"Support Vector Machines in face recognition with occlusions\",\"url\":\"https://www.semanticscholar.org/paper/ba6cfa6dca22175d7a833f08e4d2d75392f93d57\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1798912\",\"name\":\"Y. Furukawa\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"}],\"doi\":\"10.1109/CVPRW.2009.5206868\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51e923d0c245e00205d7ba9543dc54dbe5dcf85e\",\"title\":\"Dense 3D motion capture for human faces\",\"url\":\"https://www.semanticscholar.org/paper/51e923d0c245e00205d7ba9543dc54dbe5dcf85e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36005450\",\"name\":\"Chen Cao\"},{\"authorId\":\"143663883\",\"name\":\"Y. Weng\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"144078074\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/2461912.2462012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9515674638d0c1aa8ac6944efb5b6d23e93b725f\",\"title\":\"3D shape regression for real-time facial animation\",\"url\":\"https://www.semanticscholar.org/paper/9515674638d0c1aa8ac6944efb5b6d23e93b725f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398245\",\"name\":\"Jason M. Saragih\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"}],\"doi\":\"10.1007/s11263-010-0380-4\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4998462014c907c519ae801af39cf58a4c538bc9\",\"title\":\"Deformable Model Fitting by Regularized Landmark Mean-Shift\",\"url\":\"https://www.semanticscholar.org/paper/4998462014c907c519ae801af39cf58a4c538bc9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571367\",\"name\":\"L. Zhang\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1145/1186562.1015759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2c2f2cd5c5d80f743cbe9559917e076ca9146e3\",\"title\":\"Spacetime faces: high resolution capture for modeling and animation\",\"url\":\"https://www.semanticscholar.org/paper/b2c2f2cd5c5d80f743cbe9559917e076ca9146e3\",\"venue\":\"ACM Trans. Graph.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37730528\",\"name\":\"Hao Li\"},{\"authorId\":\"38865207\",\"name\":\"B. Adams\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/1661412.1618521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce069e20685e21c418b03f808e906f2cf0a9b752\",\"title\":\"Robust single-view geometry and motion reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/ce069e20685e21c418b03f808e906f2cf0a9b752\",\"venue\":\"SIGGRAPH Asia '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113750975\",\"name\":\"L. Williams\"}],\"doi\":\"10.1145/1185657.1185856\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c17d0bd66a5da5cff4d277d39fb89d84f974d71f\",\"title\":\"Performance-driven facial animation\",\"url\":\"https://www.semanticscholar.org/paper/c17d0bd66a5da5cff4d277d39fb89d84f974d71f\",\"venue\":\"SIGGRAPH '06\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145116421\",\"name\":\"S. W. Roberts\"}],\"doi\":\"10.2307/1271439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e49d6fa66c1cf846d562471ffa854e299ce15f21\",\"title\":\"Control chart tests based on geometric moving averages\",\"url\":\"https://www.semanticscholar.org/paper/e49d6fa66c1cf846d562471ffa854e299ce15f21\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118589\",\"name\":\"R. Achanta\"},{\"authorId\":\"2863792\",\"name\":\"A. Shaji\"},{\"authorId\":\"145548651\",\"name\":\"K. Smith\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1109/TPAMI.2012.120\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3c785b99ec147049caa47f707f337b717705970\",\"title\":\"SLIC Superpixels Compared to State-of-the-Art Superpixel Methods\",\"url\":\"https://www.semanticscholar.org/paper/b3c785b99ec147049caa47f707f337b717705970\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144966714\",\"name\":\"Hao Li\"},{\"authorId\":\"2246174\",\"name\":\"T. Weise\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/1833351.1778769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe4d92bb02d50a37547cf92604546309458c679a\",\"title\":\"Example-based facial rigging\",\"url\":\"https://www.semanticscholar.org/paper/fe4d92bb02d50a37547cf92604546309458c679a\",\"venue\":\"ACM Trans. Graph.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Weng C. Cao\"},{\"authorId\":null,\"name\":\"S. Zhou\"},{\"authorId\":null,\"name\":\"Y. Tong\"},{\"authorId\":null,\"name\":\"K. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zhou . 3 D shape regression for real - time facial animation\",\"url\":\"\",\"venue\":\"ACM Trans . Graph .\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3097467\",\"name\":\"David Cristinacce\"},{\"authorId\":\"143955660\",\"name\":\"T. Cootes\"}],\"doi\":\"10.1016/j.patcog.2008.01.024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c3428d5c47e613fb394f2ffbd9668aa82e9e035\",\"title\":\"Automatic feature localisation with constrained local models\",\"url\":\"https://www.semanticscholar.org/paper/5c3428d5c47e613fb394f2ffbd9668aa82e9e035\",\"venue\":\"Pattern Recognit.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"},{\"authorId\":\"37652085\",\"name\":\"W. Friesen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1566cf20e2ba91ca8857c30083419bf7c127094b\",\"title\":\"Facial action coding system: a technique for the measurement of facial movement\",\"url\":\"https://www.semanticscholar.org/paper/1566cf20e2ba91ca8857c30083419bf7c127094b\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2432463\",\"name\":\"E. Hjelm\\u00e5s\"},{\"authorId\":\"25612369\",\"name\":\"B. K. Low\"}],\"doi\":\"10.1006/cviu.2001.0921\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"887567782cb859ecd339693589056903b0071353\",\"title\":\"Face Detection: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/887567782cb859ecd339693589056903b0071353\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32542103\",\"name\":\"Xiangxin Zhu\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb12b81196df90cad4a964bb14edfdb113aeb4ce\",\"title\":\"Face detection, pose estimation, and landmark localization in the wild\",\"url\":\"https://www.semanticscholar.org/paper/bb12b81196df90cad4a964bb14edfdb113aeb4ce\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143773131\",\"name\":\"C. Cao\"},{\"authorId\":\"143663883\",\"name\":\"Y. Weng\"},{\"authorId\":\"14547116\",\"name\":\"S. Zhou\"},{\"authorId\":\"3225345\",\"name\":\"Y. Tong\"},{\"authorId\":\"48918534\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1109/TVCG.2013.249\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df3a207258f3febb98d3dcaf890e8a0f09cd5c12\",\"title\":\"FaceWarehouse: A 3D Facial Expression Database for Visual Computing\",\"url\":\"https://www.semanticscholar.org/paper/df3a207258f3febb98d3dcaf890e8a0f09cd5c12\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1109/CVPR.2013.75\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2b942261c49553bba62c340b197cf6ef373fd5a4\",\"title\":\"Supervised Descent Method and Its Applications to Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2b942261c49553bba62c340b197cf6ef373fd5a4\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7723706\",\"name\":\"S. Rusinkiewicz\"},{\"authorId\":\"1801789\",\"name\":\"M. Levoy\"}],\"doi\":\"10.1109/IM.2001.924423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d4da2841588fc75ccedcfb443d73772413d98e\",\"title\":\"Efficient variants of the ICP algorithm\",\"url\":\"https://www.semanticscholar.org/paper/19d4da2841588fc75ccedcfb443d73772413d98e\",\"venue\":\"Proceedings Third International Conference on 3-D Digital Imaging and Modeling\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"},{\"authorId\":\"48363848\",\"name\":\"J. Xiao\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"}],\"doi\":\"10.2312/SCA03/193-206\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b68749da2de9e85c857ea32b28718ea28f8f538e\",\"title\":\"Vision-based control of 3D facial animation\",\"url\":\"https://www.semanticscholar.org/paper/b68749da2de9e85c857ea32b28718ea28f8f538e\",\"venue\":\"SCA '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2508363.2508380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"976208323fd68f403e3d7c66f66d39f8788fe24c\",\"title\":\"Reconstructing detailed dynamic face geometry from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/976208323fd68f403e3d7c66f66d39f8788fe24c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35119991\",\"name\":\"Sofien Bouaziz\"},{\"authorId\":\"47906224\",\"name\":\"Yangang Wang\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/2461912.2461976\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"944a54f54b156ffced95c0ea0bb47b35ee1a62d1\",\"title\":\"Online modeling for realtime facial animation\",\"url\":\"https://www.semanticscholar.org/paper/944a54f54b156ffced95c0ea0bb47b35ee1a62d1\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013}],\"title\":\"Unconstrained realtime facial performance capture\",\"topics\":[{\"topic\":\"Facial motion capture\",\"topicId\":\"200345\",\"url\":\"https://www.semanticscholar.org/topic/200345\"},{\"topic\":\"Unobtrusive JavaScript\",\"topicId\":\"164683\",\"url\":\"https://www.semanticscholar.org/topic/164683\"},{\"topic\":\"Motion estimation\",\"topicId\":\"21398\",\"url\":\"https://www.semanticscholar.org/topic/21398\"},{\"topic\":\"Tracking system\",\"topicId\":\"14341\",\"url\":\"https://www.semanticscholar.org/topic/14341\"},{\"topic\":\"Channel (digital image)\",\"topicId\":\"42512\",\"url\":\"https://www.semanticscholar.org/topic/42512\"},{\"topic\":\"Personalization\",\"topicId\":\"2873\",\"url\":\"https://www.semanticscholar.org/topic/2873\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Smoothing\",\"topicId\":\"16185\",\"url\":\"https://www.semanticscholar.org/topic/16185\"},{\"topic\":\"Wearable technology\",\"topicId\":\"27874\",\"url\":\"https://www.semanticscholar.org/topic/27874\"}],\"url\":\"https://www.semanticscholar.org/paper/973953b488324d569fff89b2297620cc7e742427\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"