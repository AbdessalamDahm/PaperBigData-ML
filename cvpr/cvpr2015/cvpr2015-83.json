"{\"abstract\":\"We address the problem of action detection in videos. Driven by the latest progress in object detection from 2D images, we build action models using rich feature hierarchies derived from shape and kinematic cues. We incorporate appearance and motion in two ways. First, starting from image region proposals we select those that are motion salient and thus are more likely to contain the action. This leads to a significant reduction in the number of regions being processed and allows for faster computations. Second, we extract spatio-temporal feature representations to build strong classifiers using Convolutional Neural Networks. We link our predictions to produce detections consistent in time, which we call action tubes. We show that our approach outperforms other techniques in the task of action detection.\",\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\",\"url\":\"https://www.semanticscholar.org/author/2082991\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\",\"url\":\"https://www.semanticscholar.org/author/143751119\"}],\"citationVelocity\":93,\"citations\":[{\"arxivId\":\"1802.08362\",\"authors\":[{\"authorId\":\"1388811741\",\"name\":\"Alaaeldin El-Nouby\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CRV.2018.00015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6e9099320eca16c6959194d6d9113649ba88a2a\",\"title\":\"Real-Time End-to-End Action Detection with Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/b6e9099320eca16c6959194d6d9113649ba88a2a\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.5244/C.31.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"title\":\"End-to-End, Single-Stream Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1709.05087\",\"authors\":[{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"3003408\",\"name\":\"Mian M. Ajmal\"}],\"doi\":\"10.1109/ACCESS.2018.2880231\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"title\":\"Viewpoint Invariant Action Recognition Using RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ac2c5c2bdbcd139306955ac59a4055278cfe80c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51931034\",\"name\":\"Khari Jarrett\"},{\"authorId\":\"1411317532\",\"name\":\"Joachim Lohn-Jaramillo\"},{\"authorId\":\"39517986\",\"name\":\"Elijah F. W. Bowen\"},{\"authorId\":\"144089674\",\"name\":\"L. Ray\"},{\"authorId\":\"144297712\",\"name\":\"Richard Granger\"}],\"doi\":\"10.5220/0007313603770387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e90813779746afae2112eb58f5fe3e4d83fdef6b\",\"title\":\"Feedforward and Feedback Processing of Spatiotemporal Tubes for Efficient Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/e90813779746afae2112eb58f5fe3e4d83fdef6b\",\"venue\":\"ICPRAM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"Bharat Singh\"}],\"doi\":\"10.13016/M2FX7423N\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4391b692d6b7a242f719e4d219b4b7db155bccea\",\"title\":\"Detecting Objects and Actions with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4391b692d6b7a242f719e4d219b4b7db155bccea\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"}],\"doi\":\"10.3384/DISS.DIVA-147543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6f6e34dbd54c6a552e39d89e0abd0b0a9e4a0c\",\"title\":\"Learning Convolution Operators for Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/1c6f6e34dbd54c6a552e39d89e0abd0b0a9e4a0c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"title\":\"Mining Spatial and Spatio-Temporal ROIs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdde8d08733b4d9840089f8af07f042749675f\",\"title\":\"Deep network for human action recognition using Weber motion\",\"url\":\"https://www.semanticscholar.org/paper/66cdde8d08733b4d9840089f8af07f042749675f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240659\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ecb4bab5296224bdedd389cf18748c2ff0050100\",\"title\":\"Online Action Tube Detection via Resolving the Spatio-temporal Context Pattern\",\"url\":\"https://www.semanticscholar.org/paper/ecb4bab5296224bdedd389cf18748c2ff0050100\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICIP.2018.8451741\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de82346e5df5ca7e7bbfc84bbae1c1a9922e71b5\",\"title\":\"An Active Action Proposal Method Based on Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/de82346e5df5ca7e7bbfc84bbae1c1a9922e71b5\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"30118739\",\"name\":\"X. Zhang\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1109/TMM.2017.2674622\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e2f61d4897b092ee7f7df82a43a5532e0aa2370\",\"title\":\"A Hierarchical Spatio-Temporal Model for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e2f61d4897b092ee7f7df82a43a5532e0aa2370\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153481070\",\"name\":\"Mingliang Gao\"},{\"authorId\":\"47911204\",\"name\":\"J. Jiang\"},{\"authorId\":\"1801828\",\"name\":\"Lixiu Ma\"},{\"authorId\":\"152856621\",\"name\":\"Shuwen Zhou\"},{\"authorId\":\"153376260\",\"name\":\"Guofeng Zou\"},{\"authorId\":\"49106674\",\"name\":\"Jinfeng Pan\"},{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1109/CCDC.2019.8832598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba882f39456ff300977103e293bfb402cdd351c1\",\"title\":\"Violent crowd behavior detection using deep learning and compressive sensing\",\"url\":\"https://www.semanticscholar.org/paper/ba882f39456ff300977103e293bfb402cdd351c1\",\"venue\":\"2019 Chinese Control And Decision Conference (CCDC)\",\"year\":2019},{\"arxivId\":\"1811.08496\",\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"48467498\",\"name\":\"Rajeev Ranjan\"},{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"145668757\",\"name\":\"Carlos Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/WACV.2019.00021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"title\":\"A Proposal-Based Solution to Spatio-Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11043267\",\"name\":\"J. George\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"767a8eb619f1c2e76b998c80e0139434269a4638\",\"title\":\"Machine Learning to Enable AR Technology-Paper Review ( Working Title )\",\"url\":\"https://www.semanticscholar.org/paper/767a8eb619f1c2e76b998c80e0139434269a4638\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"09926ed62511c340f4540b5bc53cf2480e8063f8\",\"title\":\"Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/09926ed62511c340f4540b5bc53cf2480e8063f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36302865\",\"name\":\"L. Chen\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCVW.2017.47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22d43e998c66a44a0418aef596891df71fd0b06f\",\"title\":\"Attending to Distinctive Moments: Weakly-Supervised Attention Models for Action Localization in Video\",\"url\":\"https://www.semanticscholar.org/paper/22d43e998c66a44a0418aef596891df71fd0b06f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"2040199\",\"name\":\"Yinhe Du\"},{\"authorId\":\"40035911\",\"name\":\"J. Liu\"},{\"authorId\":\"145584603\",\"name\":\"J. Lv\"},{\"authorId\":\"2858139\",\"name\":\"L. Yang\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1016/j.neucom.2016.05.094\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e54c4d86e9801af1663265c0e42938358e8eb13\",\"title\":\"InfAR dataset: Infrared action recognition at different times\",\"url\":\"https://www.semanticscholar.org/paper/2e54c4d86e9801af1663265c0e42938358e8eb13\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423738380\",\"name\":\"Zakia Yahya\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"}],\"doi\":\"10.1109/HONET.2019.8908040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"title\":\"Classification and Temporal Localization of Robbery Events in CCTV Videos through Multi-Stream Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"venue\":\"2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT and AI (HONET-ICT)\",\"year\":2019},{\"arxivId\":\"1607.02003\",\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-017-1023-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9dd21511fc70f9b7ed1d095a51f09c60f9f1efe1\",\"title\":\"Tubelets: Unsupervised Action Proposals from Spatiotemporal Super-Voxels\",\"url\":\"https://www.semanticscholar.org/paper/9dd21511fc70f9b7ed1d095a51f09c60f9f1efe1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2016.211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bac994dda1385cd709e08e24170c711d8c573676\",\"title\":\"Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bac994dda1385cd709e08e24170c711d8c573676\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2008.00836\",\"authors\":[{\"authorId\":\"1785114557\",\"name\":\"Qiao Liu\"},{\"authorId\":\"1503438566\",\"name\":\"Xin Li\"},{\"authorId\":\"48427193\",\"name\":\"Zhenyu He\"},{\"authorId\":\"50876591\",\"name\":\"Chenglong Li\"},{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"1485000269\",\"name\":\"Zikun Zhou\"},{\"authorId\":\"2002049\",\"name\":\"Di Yuan\"},{\"authorId\":\"1492113723\",\"name\":\"Jing Li\"},{\"authorId\":\"1637401447\",\"name\":\"Kai Yang\"},{\"authorId\":\"40443545\",\"name\":\"N. Fan\"},{\"authorId\":\"46643741\",\"name\":\"Feng Zheng\"}],\"doi\":\"10.1145/3394171.3413922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b8708a9d4a3a72e20386d6647afd9ef57711614\",\"title\":\"LSOTB-TIR: A Large-Scale High-Diversity Thermal Infrared Object Tracking Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/0b8708a9d4a3a72e20386d6647afd9ef57711614\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24735756\",\"name\":\"Zhengkui Weng\"},{\"authorId\":\"40641593\",\"name\":\"Y. Guan\"}],\"doi\":\"10.1117/1.JEI.28.2.021004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"title\":\"Trajectory-aware three-stream CNN for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1608.08851\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"title\":\"Efficient Two-Stream Motion and Appearance 3D CNNs for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1604.04053\",\"authors\":[{\"authorId\":\"144813536\",\"name\":\"Kai Kang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.95\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"title\":\"Object Detection from Video Tubelets with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2004.00451\",\"authors\":[{\"authorId\":\"1573843594\",\"name\":\"Daniel Cores\"},{\"authorId\":\"1725529\",\"name\":\"V. Brea\"},{\"authorId\":\"1734140\",\"name\":\"M. Mucientes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"title\":\"Spatio-temporal Tubelet Feature Aggregation and Object Linking in Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"},{\"authorId\":\"50656755\",\"name\":\"Qing Yuan Zhou\"},{\"authorId\":\"50424096\",\"name\":\"Nicolas Christou\"},{\"authorId\":\"145081360\",\"name\":\"Alan Loddon Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"title\":\"Electronic Theses and Dissertations Title Mining Spatial and Spatio-Temporal ROIs for Action Recognition Permalink\",\"url\":\"https://www.semanticscholar.org/paper/4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812342\",\"name\":\"Yeongtaek Song\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3390/s19051085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"title\":\"Spatio-Temporal Action Detection in Untrimmed Videos by Using Multimodal Features and Region Proposals\",\"url\":\"https://www.semanticscholar.org/paper/be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1016/j.neucom.2018.05.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2cda38655d3f216430969b5b864b96c1b011c1\",\"title\":\"Detecting action tubes via spatial action estimation and temporal path inference\",\"url\":\"https://www.semanticscholar.org/paper/de2cda38655d3f216430969b5b864b96c1b011c1\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682151\",\"name\":\"Cheng-Bin Jin\"},{\"authorId\":\"2772929\",\"name\":\"T. D. Do\"},{\"authorId\":\"47842167\",\"name\":\"M. Liu\"},{\"authorId\":\"1697362\",\"name\":\"H. Kim\"}],\"doi\":\"10.5772/INTECHOPEN.76086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d017d99aba5a39a6e70d96155bec849fed1311b\",\"title\":\"Real-Time Action Recognition Using Multi-level Action Descriptor and DNN\",\"url\":\"https://www.semanticscholar.org/paper/2d017d99aba5a39a6e70d96155bec849fed1311b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114820691\",\"name\":\"Y. Guo\"},{\"authorId\":\"4945728\",\"name\":\"J. Wrammert\"},{\"authorId\":\"153866164\",\"name\":\"K. Singh\"},{\"authorId\":\"1403193815\",\"name\":\"C. AshishK.\"},{\"authorId\":\"48220850\",\"name\":\"Kira Bradford\"},{\"authorId\":\"153024381\",\"name\":\"A. Krishnamurthy\"}],\"doi\":\"10.1109/ICCABS.2016.7802775\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"045e83272db5e92aa4dc8bdfee908534c2608711\",\"title\":\"Automatic analysis of neonatal video data to evaluate resuscitation prformance\",\"url\":\"https://www.semanticscholar.org/paper/045e83272db5e92aa4dc8bdfee908534c2608711\",\"venue\":\"2016 IEEE 6th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc2ba7caaf440ab28c5a223f5093d3faa62a2413\",\"title\":\"Deep learning for human motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/fc2ba7caaf440ab28c5a223f5093d3faa62a2413\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"}],\"doi\":\"10.1145/3115932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b26616644adfbfcba17438ed9336f31e01561226\",\"title\":\"Structure-Aware Multimodal Feature Fusion for RGB-D Scene Classification and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/b26616644adfbfcba17438ed9336f31e01561226\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1016/j.jvcir.2020.102772\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46302cdf6eb829ba2f7582469ad50dd0a40fd856\",\"title\":\"Multimodal hand gesture recognition combining temporal and pose information based on CNN descriptors and histogram of cumulative magnitudes\",\"url\":\"https://www.semanticscholar.org/paper/46302cdf6eb829ba2f7582469ad50dd0a40fd856\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/CVPR.2016.214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"title\":\"Learning Activity Progression in LSTMs for Activity Detection and Early Detection\",\"url\":\"https://www.semanticscholar.org/paper/e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"101386498\",\"name\":\"T. T. Ogunwa\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.1109/THMS.2020.2971958\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"title\":\"A Multiviewpoint Outdoor Dataset for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2020},{\"arxivId\":\"1704.01358\",\"authors\":[{\"authorId\":\"145560551\",\"name\":\"Harkirat Singh Behl\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"961fd8da3102e9c8696f70375507eee89d37ef61\",\"title\":\"Incremental Tube Construction for Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/961fd8da3102e9c8696f70375507eee89d37ef61\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"},{\"authorId\":\"144620591\",\"name\":\"X. Wu\"},{\"authorId\":\"51104559\",\"name\":\"Ruilong Li\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"29962444\",\"name\":\"Zhao-Heng Zheng\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TMM.2018.2790163\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bdadc478d0290f8b275a4efedccf5395f70bb80\",\"title\":\"Detecting and Removing Visual Distractors for Video Aesthetic Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/1bdadc478d0290f8b275a4efedccf5395f70bb80\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691251\",\"name\":\"J. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.jvcir.2018.03.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3780f56d2563dcdea4a3ce178acd265456f05dd\",\"title\":\"Temporally enhanced image object proposals for online video object and action detections\",\"url\":\"https://www.semanticscholar.org/paper/e3780f56d2563dcdea4a3ce178acd265456f05dd\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40085868\",\"name\":\"Kai Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6e067098fa86ee3f96365f28669b06f9ce0c7a\",\"title\":\"generate action proposals by calculating actionness scores and solving a maximum set coverage problem\",\"url\":\"https://www.semanticscholar.org/paper/1c6e067098fa86ee3f96365f28669b06f9ce0c7a\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-M\\u00e1adeed\"}],\"doi\":\"10.1007/s00138-019-01039-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"title\":\"Action recognition in poor-quality spectator crowd videos using head distribution-based person segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"venue\":\"Machine Vision and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144925873\",\"name\":\"N. Kumaran\"},{\"authorId\":\"3846423\",\"name\":\"U. S. Reddy\"},{\"authorId\":\"46574794\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"title\":\"Multiple Action Recognition for Human Object with Motion Video Sequence using the Properties of HSV Color Space Applying with Region of Interest\",\"url\":\"https://www.semanticscholar.org/paper/80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.11333\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-018-1120-4\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"90f457c30a678ea879827b6d576ec4b97e404c28\",\"title\":\"Pointly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/90f457c30a678ea879827b6d576ec4b97e404c28\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"39952920\",\"name\":\"Q. Qin\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.patcog.2018.01.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa733992a236258adf36a41413b96707c8e9f4c\",\"title\":\"Multi-stream CNN: Learning representations based on human-related regions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/baa733992a236258adf36a41413b96707c8e9f4c\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5434752\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.5120/IJCA2019918660\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43c22ebb5ff264a5ea996c163464cf761035a405\",\"title\":\"Multi-Feature Fusion for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/43c22ebb5ff264a5ea996c163464cf761035a405\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695589\",\"name\":\"Shiqing Zhang\"},{\"authorId\":\"88197189\",\"name\":\"X. Pan\"},{\"authorId\":\"2858733\",\"name\":\"Y. Cui\"},{\"authorId\":\"48551029\",\"name\":\"Xiaoming Zhao\"},{\"authorId\":\"47968161\",\"name\":\"L. Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2901521\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df822090bb4fcaa78db8a281b55fb249e1c39605\",\"title\":\"Learning Affective Video Features for Facial Expression Recognition via Hybrid Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/df822090bb4fcaa78db8a281b55fb249e1c39605\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1805.06749\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89d7aa10ad97251089d0204916f784f137f3a1ec\",\"title\":\"Action Completion: A Temporal Model for Moment Detection\",\"url\":\"https://www.semanticscholar.org/paper/89d7aa10ad97251089d0204916f784f137f3a1ec\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2010.09211\",\"authors\":[{\"authorId\":\"40930518\",\"name\":\"Nakul Agarwal\"},{\"authorId\":\"73365400\",\"name\":\"Y. Chen\"},{\"authorId\":\"1387979739\",\"name\":\"Behzad Dariush\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"017484d832e0b217897adc889f9becbf1f8f3bcb\",\"title\":\"Unsupervised Domain Adaptation for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/017484d832e0b217897adc889f9becbf1f8f3bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1793532\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TMM.2016.2631881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9182cd457884a91c461f2b7b7677fe92e06d165c\",\"title\":\"Dancelets Mining for Video Recommendation Based on Dance Styles\",\"url\":\"https://www.semanticscholar.org/paper/9182cd457884a91c461f2b7b7677fe92e06d165c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"2010.12573\",\"authors\":[{\"authorId\":\"34973011\",\"name\":\"Qichuan Geng\"},{\"authorId\":\"9184786\",\"name\":\"H. Zhang\"},{\"authorId\":\"48272798\",\"name\":\"N. Jiang\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"47059724\",\"name\":\"L. Zhang\"},{\"authorId\":\"1750157\",\"name\":\"Zhong Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d1ef00c8029a42cf0faeb11c4e1f9965a8329a\",\"title\":\"Object-aware Feature Aggregation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4d1ef00c8029a42cf0faeb11c4e1f9965a8329a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.00097\",\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"title\":\"Budget-Aware Activity Detection with A Recurrent Policy Network\",\"url\":\"https://www.semanticscholar.org/paper/11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1507.00448\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2016.309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53d1e022961e241164ecb6ec58378d7033a280f8\",\"title\":\"Cross Modal Distillation for Supervision Transfer\",\"url\":\"https://www.semanticscholar.org/paper/53d1e022961e241164ecb6ec58378d7033a280f8\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2009.09660\",\"authors\":[{\"authorId\":\"1409338179\",\"name\":\"Ruibing Jin\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"153028998\",\"name\":\"Changyun Wen\"},{\"authorId\":\"48093969\",\"name\":\"J. Wang\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3929c621fd93d21619d77f29e3e4d76d821ee62\",\"title\":\"Feature Flow: In-network Feature Flow Estimation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d3929c621fd93d21619d77f29e3e4d76d821ee62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.02171\",\"authors\":[{\"authorId\":\"67267687\",\"name\":\"Kurt Degiorgio\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9141857d0592503496544af5e213b42ed68039c4\",\"title\":\"Spatio-Temporal Action Localization in a Weakly Supervised Setting\",\"url\":\"https://www.semanticscholar.org/paper/9141857d0592503496544af5e213b42ed68039c4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/ICIP.2017.8297080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e5690cdb4dfa30d98dff653be459e1c270cde7f\",\"title\":\"Multiple path search for action tube detection in videos\",\"url\":\"https://www.semanticscholar.org/paper/9e5690cdb4dfa30d98dff653be459e1c270cde7f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"47775167\",\"name\":\"Teng Li\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/TNNLS.2017.2731775\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4d7b8eb0a8e6d2bb5b90b027c1bf32bad320ba5\",\"title\":\"Learning Semantic-Aligned Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/e4d7b8eb0a8e6d2bb5b90b027c1bf32bad320ba5\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10376365\",\"name\":\"Sourabh Kulhare\"},{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"8262287\",\"name\":\"Suhas Pillai\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/ICPR.2016.7899739\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10df1d4b278da991848fb71b572f687bd189c10e\",\"title\":\"Key frame extraction for salient activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/10df1d4b278da991848fb71b572f687bd189c10e\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1604.00427\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8926471921ff608f70c6c81777782974a91086ae\",\"title\":\"Leaving Some Stones Unturned: Dynamic Feature Prioritization for Activity Detection in Streaming Video\",\"url\":\"https://www.semanticscholar.org/paper/8926471921ff608f70c6c81777782974a91086ae\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1803.11496\",\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.1007/978-3-030-01240-3_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb503d90c0bd9a555a6b99429991c4d6f39e0f70\",\"title\":\"Predicting Future Instance Segmentations by Forecasting Convolutional Features\",\"url\":\"https://www.semanticscholar.org/paper/cb503d90c0bd9a555a6b99429991c4d6f39e0f70\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.12993\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"title\":\"A Study on Action Detection in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.07388\",\"authors\":[{\"authorId\":\"118242229\",\"name\":\"D. Castro\"},{\"authorId\":\"2935619\",\"name\":\"Steven Hickson\"},{\"authorId\":\"3430745\",\"name\":\"Patsorn Sangkloy\"},{\"authorId\":\"145389008\",\"name\":\"Bhavishya Mittal\"},{\"authorId\":\"35459529\",\"name\":\"Sean Dai\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e25cab2251a8ded43c44b28a87f4c62e3a548a\",\"title\":\"Let's Dance: Learning From Online Dance Videos\",\"url\":\"https://www.semanticscholar.org/paper/a6e25cab2251a8ded43c44b28a87f4c62e3a548a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eded9b910588d1d2936f527281a98ba3dac7ea4\",\"title\":\"Supervised Learning Approaches for Automatic Structuring of Videos. (M\\u00e9thodes d'apprentissage supervis\\u00e9 pour la structuration automatique de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/8eded9b910588d1d2936f527281a98ba3dac7ea4\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1710.03958\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.330\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb3948152788cfaf8a829aab2f02a6ec7de7c7d1\",\"title\":\"Detect to Track and Track to Detect\",\"url\":\"https://www.semanticscholar.org/paper/fb3948152788cfaf8a829aab2f02a6ec7de7c7d1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119924024\",\"name\":\"Yinan Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"}],\"doi\":\"10.1109/ACCESS.2017.2753830\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c90427085909029afd2af01d1967e80b78e01b88\",\"title\":\"Gaze-Assisted Multi-Stream Deep Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c90427085909029afd2af01d1967e80b78e01b88\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":\"1607.08584\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-319-46493-0_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18994755100686833b92c34af8ec1b35934e23d6\",\"title\":\"Connectionist Temporal Modeling for Weakly Supervised Action Labeling\",\"url\":\"https://www.semanticscholar.org/paper/18994755100686833b92c34af8ec1b35934e23d6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"8060096\",\"name\":\"Sheng-hung Hu\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ICIP.2016.7533150\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06f39834e870278243dda826658319be2d5d8ded\",\"title\":\"Recognizing unseen actions in a domain-adapted embedding space\",\"url\":\"https://www.semanticscholar.org/paper/06f39834e870278243dda826658319be2d5d8ded\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"2001.04608\",\"authors\":[{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58517-4_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6e3034cd8855616533d091dc1d70e969c20a42b\",\"title\":\"Actions as Moving Points\",\"url\":\"https://www.semanticscholar.org/paper/e6e3034cd8855616533d091dc1d70e969c20a42b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28933059\",\"name\":\"Jiangchuan Wei\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50130622\",\"name\":\"Yun Yi\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"8312366\",\"name\":\"De-Shuang Huang\"}],\"doi\":\"10.1109/ICIP.2019.8802979\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c4e7471cd845223b852efe09e5985544332b22a\",\"title\":\"P3D-CTN: Pseudo-3D Convolutional Tube Network for Spatio-Temporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c4e7471cd845223b852efe09e5985544332b22a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1808.07712\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-11015-4_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffcf3435b1e7a984836bac25800481fb5140d97\",\"title\":\"Predicting Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/7ffcf3435b1e7a984836bac25800481fb5140d97\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8341577\",\"name\":\"P. Yu\"},{\"authorId\":\"36650957\",\"name\":\"Jiang Wang\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.5244/C.31.164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3d1707d85b1d667585805ff3e43cfea6106da50\",\"title\":\"Human Action Segmentation using 3D Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/b3d1707d85b1d667585805ff3e43cfea6106da50\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1707.06005\",\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.31.51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89597f719e7fc8022016da6b5cabb3e1fa1c775e\",\"title\":\"Detecting Parts for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/89597f719e7fc8022016da6b5cabb3e1fa1c775e\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1846234260\",\"name\":\"Xiaoyan Meng\"},{\"authorId\":\"1845981156\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"47057083\",\"name\":\"Xiuzhi Li\"},{\"authorId\":\"1846054590\",\"name\":\"Xiangyin Zhang\"}],\"doi\":\"10.1007/s00371-020-01931-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625829da4b74fbcf217615eadd852e5ff4387a17\",\"title\":\"Auxiliary criterion conversion via spatiotemporal semantic encoding and feature entropy for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/625829da4b74fbcf217615eadd852e5ff4387a17\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3388303\",\"name\":\"Yinzhong Qian\"},{\"authorId\":\"50504489\",\"name\":\"W. Chen\"},{\"authorId\":\"1715728\",\"name\":\"I. Shen\"}],\"doi\":\"10.1049/iet-cvi.2017.0233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b86c8e2204347ad1f55d01b7a397410eb7fe3d2e\",\"title\":\"Action recognition from mutually incoherent pose bases in static image\",\"url\":\"https://www.semanticscholar.org/paper/b86c8e2204347ad1f55d01b7a397410eb7fe3d2e\",\"venue\":\"IET Comput. Vis.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"title\":\"Discovering Multi-Label Actor-Action Association in a Weakly Supervised Setting\",\"url\":\"https://www.semanticscholar.org/paper/1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145532503\",\"name\":\"Marco Leo\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.cviu.2016.09.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aef8eeff5f532dcdad95043ba464720be664ab8\",\"title\":\"Computer vision for assistive technologies\",\"url\":\"https://www.semanticscholar.org/paper/6aef8eeff5f532dcdad95043ba464720be664ab8\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1109/SIBGRAPI.2018.00019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5ad27ac1c33c4964848fdc85427ba2465b5b3f5\",\"title\":\"Multimodal Human Action Recognition Based on a Fusion of Dynamic Images Using CNN Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/f5ad27ac1c33c4964848fdc85427ba2465b5b3f5\",\"venue\":\"SIBGRAPI\",\"year\":2018},{\"arxivId\":\"1707.09145\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/ICCV.2017.476\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af2896e36cec58c2acca03001d7f19db48e9e5c3\",\"title\":\"Spatial-Aware Object Embeddings for Zero-Shot Localization and Classification of Actions\",\"url\":\"https://www.semanticscholar.org/paper/af2896e36cec58c2acca03001d7f19db48e9e5c3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1706.08218\",\"authors\":[{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"39514690\",\"name\":\"Xi Peng\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"}],\"doi\":\"10.1109/TIP.2018.2806279\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baac20337b7fcdb54547abf2984be8ee753f4c3b\",\"title\":\"YoTube: Searching Action Proposal Via Recurrent and Static Regression Networks\",\"url\":\"https://www.semanticscholar.org/paper/baac20337b7fcdb54547abf2984be8ee753f4c3b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"1704531\",\"name\":\"Novi Quadrianto\"}],\"doi\":\"10.1109/CVPR.2016.430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5a7b5f30b3d1503d67b7ea40337b5657fe1f28c\",\"title\":\"Learning from the Mistakes of Others: Matching Errors in Cross-Dataset Learning\",\"url\":\"https://www.semanticscholar.org/paper/f5a7b5f30b3d1503d67b7ea40337b5657fe1f28c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae02e601eae125ce137324c678ab68e9ab272ea0\",\"title\":\"Self-supervised learning of predictive segmentation models from video\",\"url\":\"https://www.semanticscholar.org/paper/ae02e601eae125ce137324c678ab68e9ab272ea0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121405052\",\"name\":\"S. V. Kiran\"},{\"authorId\":\"116372419\",\"name\":\"Raj Singh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09275e4157969c0606efc4c085fd3db43c2186a5\",\"title\":\"Contextual Action Recognition using Tube Convolutional Neural Network (T-CNN)\",\"url\":\"https://www.semanticscholar.org/paper/09275e4157969c0606efc4c085fd3db43c2186a5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39453466\",\"name\":\"T. Zhang\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/VCIP.2017.8305139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5fd22f59041a0fd405805b46a7fb9b32fce9a90\",\"title\":\"Action proposals using hierarchical clustering of super-trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d5fd22f59041a0fd405805b46a7fb9b32fce9a90\",\"venue\":\"2017 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"}],\"doi\":\"10.1016/J.CVIU.2019.04.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3917d925dac0abf6e7b452fa2916c25f9e72fc2c\",\"title\":\"TAB: Temporally aggregated bag-of-discriminant-words for temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/3917d925dac0abf6e7b452fa2916c25f9e72fc2c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145509163\",\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-46732-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f72f936bc42673eed62a215983c516656f5d519a\",\"title\":\"Spatio-Temporal Action Instance Segmentation and Localisation\",\"url\":\"https://www.semanticscholar.org/paper/f72f936bc42673eed62a215983c516656f5d519a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50981113\",\"name\":\"Muhamad Risqi U. Saputra\"},{\"authorId\":\"34401562\",\"name\":\"A. Markham\"},{\"authorId\":\"3641238\",\"name\":\"A. Trigoni\"}],\"doi\":\"10.1145/3177853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cabecdfab3dcae6ecb70b1507acbf2a484c40552\",\"title\":\"Visual SLAM and Structure from Motion in Dynamic Environments\",\"url\":\"https://www.semanticscholar.org/paper/cabecdfab3dcae6ecb70b1507acbf2a484c40552\",\"venue\":\"ACM Comput. Surv.\",\"year\":2018},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39796129\",\"name\":\"Hayden Faulkner\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":\"10.1109/DICTA.2017.8227494\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"title\":\"TenniSet: A Dataset for Dense Fine-Grained Event Recognition, Localisation and Description\",\"url\":\"https://www.semanticscholar.org/paper/4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/LSP.2017.2778190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35b84c0b3e20cf27e08a200e9c17dcf215263ed7\",\"title\":\"PMHI: Proposals From Motion History Images for Temporal Segmentation of Long Uncut Videos\",\"url\":\"https://www.semanticscholar.org/paper/35b84c0b3e20cf27e08a200e9c17dcf215263ed7\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49402429\",\"name\":\"J. Yu\"},{\"authorId\":\"46533851\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"40322073\",\"name\":\"L. Wan\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TCSVT.2019.2919064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10129da014606c70b6fab077319491c772b01c04\",\"title\":\"Spatio-Temporal Deep Q-Networks for Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/10129da014606c70b6fab077319491c772b01c04\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145634568\",\"name\":\"H. Hu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"}],\"doi\":\"10.1109/CVPRW.2017.272\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dee6609615b73b10540f32537a242baa3c9fca4d\",\"title\":\"Temporal Domain Neural Encoder for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/dee6609615b73b10540f32537a242baa3c9fca4d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1810.11438\",\"authors\":[{\"authorId\":\"49340538\",\"name\":\"Bowen Shi\"},{\"authorId\":\"51518798\",\"name\":\"Aurora Martinez Del Rio\"},{\"authorId\":\"7185426\",\"name\":\"J. Keane\"},{\"authorId\":\"145195878\",\"name\":\"Jonathan Michaux\"},{\"authorId\":\"3192685\",\"name\":\"D. Brentari\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/SLT.2018.8639639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c840615f7e079db25bd45b8baf36b3523c2c2474\",\"title\":\"American Sign Language Fingerspelling Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/c840615f7e079db25bd45b8baf36b3523c2c2474\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"1604959773\",\"name\":\"Yichu Liu\"}],\"doi\":\"10.1007/s11063-019-10091-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"title\":\"Action Recognition with Multiple Relative Descriptors of Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406678671\",\"name\":\"\\u00d8yvind Meinich-Bache\"},{\"authorId\":\"2691592\",\"name\":\"K. Engan\"},{\"authorId\":\"1704325\",\"name\":\"Ivar Austvoll\"},{\"authorId\":\"8985915\",\"name\":\"T. Eftest\\u00f8l\"},{\"authorId\":\"2665808\",\"name\":\"H. Myklebust\"},{\"authorId\":\"1403607107\",\"name\":\"L. Yarrot\"},{\"authorId\":\"143762843\",\"name\":\"H. Kidanto\"},{\"authorId\":\"40423610\",\"name\":\"H. Ersdal\"}],\"doi\":\"10.1109/JBHI.2019.2924808\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"544bbbec4ffd92ac8d49f221f6f27f40fcf1d169\",\"title\":\"Object Detection During Newborn Resuscitation Activities\",\"url\":\"https://www.semanticscholar.org/paper/544bbbec4ffd92ac8d49f221f6f27f40fcf1d169\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67267687\",\"name\":\"K. Degiorgio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb4fc543bb24f5793aa797fd36907dcfebd4cfe6\",\"title\":\"Automatic Localization and Annotation of Spatio-Temporal Actions in Weakly Labelled Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb4fc543bb24f5793aa797fd36907dcfebd4cfe6\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1904.01665\",\"authors\":[{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"}],\"doi\":\"10.1109/CVPR.2019.00303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbd8bd944f883f465679248493bc097a4b7ab4ef\",\"title\":\"Activity Driven Weakly Supervised Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbd8bd944f883f465679248493bc097a4b7ab4ef\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.01847\",\"authors\":[{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"144585903\",\"name\":\"L. Huang\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"title\":\"Deformable Tube Network for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116940452\",\"name\":\"Ahmad Karambakhsh\"},{\"authorId\":\"47134020\",\"name\":\"Bin Sheng\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"},{\"authorId\":\"144861562\",\"name\":\"Po Yang\"},{\"authorId\":\"38237611\",\"name\":\"Younhyun Jung\"},{\"authorId\":\"1737093\",\"name\":\"D. Feng\"}],\"doi\":\"10.1109/ACCESS.2020.2987177\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"34d1f9f022790dc10063f47f236dfa99adc0ba52\",\"title\":\"VoxRec: Hybrid Convolutional Neural Network for Active 3D Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/34d1f9f022790dc10063f47f236dfa99adc0ba52\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51936306\",\"name\":\"Swati Dewan\"},{\"authorId\":\"50230202\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"2204983\",\"name\":\"N. Singh\"}],\"doi\":\"10.1117/12.2309445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84fdbbe6e85ee5280af2d58f3fe24cf9d4944295\",\"title\":\"A deep learning pipeline for Indian dance style classification\",\"url\":\"https://www.semanticscholar.org/paper/84fdbbe6e85ee5280af2d58f3fe24cf9d4944295\",\"venue\":\"International Conference on Machine Vision\",\"year\":2018},{\"arxivId\":\"1704.02112\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.172\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"faae39b8708de562a78b2b4294694a935442844a\",\"title\":\"Generalized Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/faae39b8708de562a78b2b4294694a935442844a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TSMC.2016.2625840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"title\":\"Group Sparse-Based Mid-Level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":\"1705.10861\",\"authors\":[{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"49152600\",\"name\":\"Zhiwei Deng\"},{\"authorId\":\"1410048460\",\"name\":\"M. S. Ibrahim\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/WACV.2018.00044\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a62ef5a5e94d72256fc335f5193616601f36fdea\",\"title\":\"Generic Tubelet Proposals for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a62ef5a5e94d72256fc335f5193616601f36fdea\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"}],\"doi\":\"10.15781/T2QR4P68H\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"title\":\"Natural Language Video Description using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1908.09511\",\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00712\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1376675731b8dc3d87464ff54905b9f5233169b5\",\"title\":\"Relation Distillation Networks for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1376675731b8dc3d87464ff54905b9f5233169b5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.13870\",\"authors\":[{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"40303375\",\"name\":\"V. Rathod\"},{\"authorId\":\"69423660\",\"name\":\"Ronny Votel\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.01468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7b7742b617320c9abf077f853de971259ae0182\",\"title\":\"RetinaTrack: Online Single Stage Joint Detection and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/d7b7742b617320c9abf077f853de971259ae0182\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1902.05176\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"22314707\",\"name\":\"Ekta U. Samani\"},{\"authorId\":\"49085454\",\"name\":\"R. Hendrix\"},{\"authorId\":\"46529550\",\"name\":\"S. Singh\"},{\"authorId\":\"1840866\",\"name\":\"S. Devasia\"},{\"authorId\":\"145026397\",\"name\":\"Ashis G. Banerjee\"}],\"doi\":\"10.1109/LRA.2019.2925305\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec5d6990c3a0e32d4cd41405f7cd85dbc470812e\",\"title\":\"Predicting Ergonomic Risks During Indoor Object Manipulation Using Spatiotemporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/ec5d6990c3a0e32d4cd41405f7cd85dbc470812e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.10000\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1995717\",\"name\":\"Bingyi Kang\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12479dcd4808b96d6a149919183ef15afcf6a89e\",\"title\":\"Similarity R-C3D for Few-shot Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/12479dcd4808b96d6a149919183ef15afcf6a89e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICIP.2019.8803650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b28c19bc1dd8d6db7fa65c1aa5aa6714463c0e5\",\"title\":\"Hierarchical Graph-Rnns for Action Detection of Multiple Activities\",\"url\":\"https://www.semanticscholar.org/paper/0b28c19bc1dd8d6db7fa65c1aa5aa6714463c0e5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2008.13196\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145527065\",\"name\":\"Tao Wang\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"}],\"doi\":\"10.1609/AAAI.V34I07.6811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b66ea4e404cc119f2f7970486cee19bc300a198\",\"title\":\"Finding Action Tubes with a Sparse-to-Dense Framework\",\"url\":\"https://www.semanticscholar.org/paper/7b66ea4e404cc119f2f7970486cee19bc300a198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7272302\",\"name\":\"Minsi Wang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/CVPR.2017.783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89ae6715e6e581046074935912ad50e104a6a8c0\",\"title\":\"Recurrent Modeling of Interaction Context for Collective Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89ae6715e6e581046074935912ad50e104a6a8c0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10376365\",\"name\":\"Sourabh Kulhare\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af5b71c042e2bf39e5085ad5b5f1215e129989df\",\"title\":\"Deep Learning for Semantic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/af5b71c042e2bf39e5085ad5b5f1215e129989df\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"144061516\",\"name\":\"L. Tao\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1109/WACV.2017.20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b3aaa685bcfe24081f33005b3be051f079a5411\",\"title\":\"Deep Moving Poselets for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3aaa685bcfe24081f33005b3be051f079a5411\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740496\",\"name\":\"P. Gao\"},{\"authorId\":\"12020218\",\"name\":\"Yipeng Ma\"},{\"authorId\":\"47950422\",\"name\":\"Ke Song\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"143751006\",\"name\":\"Liyi Xiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6132d1bd9e945c06d662363b8f2ae40e0db3d08b\",\"title\":\"Deep Appearance Features Deep Motion Features VGG Shallow Deep ActionTubes Crop Cropped Image TIR Optical Flow Support correlation filters Continuous Response Map\",\"url\":\"https://www.semanticscholar.org/paper/6132d1bd9e945c06d662363b8f2ae40e0db3d08b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"title\":\"Enhancing human action recognition with region proposals\",\"url\":\"https://www.semanticscholar.org/paper/30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"venue\":\"ICRA 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"46286184\",\"name\":\"Y. Yang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"46867455\",\"name\":\"Yin Sheng Zhang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123362\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49dbecc42e9bdd508279314509a85c0cf3a6a917\",\"title\":\"Detecting Temporal Proposal for Action Localization with Tree-structured Search Policy\",\"url\":\"https://www.semanticscholar.org/paper/49dbecc42e9bdd508279314509a85c0cf3a6a917\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145154822\",\"name\":\"Cheng Pang\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1793532\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1007/s11042-018-5957-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23e85d879c37fad1e6c07fa13b896cb99535c297\",\"title\":\"Exploring part-aware segmentation for fine-grained visual categorization\",\"url\":\"https://www.semanticscholar.org/paper/23e85d879c37fad1e6c07fa13b896cb99535c297\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2343931\",\"name\":\"Miao Ma\"},{\"authorId\":\"3330806\",\"name\":\"N. Marturi\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"},{\"authorId\":\"102679833\",\"name\":\"R. Stolkin\"}],\"doi\":\"10.1016/j.patcog.2017.11.026\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"12ffd26b3f88c721bef2a97323f17e38b99e86d3\",\"title\":\"Region-sequence based six-stream CNN features for general and fine-grained human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/12ffd26b3f88c721bef2a97323f17e38b99e86d3\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1912.10982\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"16040476\",\"name\":\"S. A. Bargal\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"846fca8fa98753223f464b187cb59b02a8a1ccae\",\"title\":\"DMCL: Distillation Multiple Choice Learning for Multimodal Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/846fca8fa98753223f464b187cb59b02a8a1ccae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65863515\",\"name\":\"X. Xie\"},{\"authorId\":\"145063584\",\"name\":\"M. W. Jones\"},{\"authorId\":\"1888880\",\"name\":\"G. Tam\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"603e20e189aaf2324318e4168e615d317142d26a\",\"title\":\"APT: Action localization Proposals from dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/603e20e189aaf2324318e4168e615d317142d26a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2007.03560\",\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/tmm.2020.2990070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57c38661af2d1ac5ac79cc51a443f5f1cca4b03b\",\"title\":\"Single Shot Video Object Detector\",\"url\":\"https://www.semanticscholar.org/paper/57c38661af2d1ac5ac79cc51a443f5f1cca4b03b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"David A. Ross\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"Rahul Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"RoI Pooling DNN Classifier Person Bike Background 2 D Feature Map Input ImageMulti-scale Anchor Boxes Region Proposal Network Region Proposals 2 D ConvNet c DNN Classifier Dunk Background SoI Pooling\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"title\":\"Sentence Encoder Video Encoder Frame-Specific Sentence Representation Cross Gating Matching Aggregation Self Interactor Segment Localizer Cross Modal\",\"url\":\"https://www.semanticscholar.org/paper/631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.10278\",\"authors\":[{\"authorId\":\"51114471\",\"name\":\"Junho Koh\"},{\"authorId\":\"9028688\",\"name\":\"Jaekyum Kim\"},{\"authorId\":\"2027606803\",\"name\":\"Younji Shin\"},{\"authorId\":\"150936578\",\"name\":\"Byeongwon Lee\"},{\"authorId\":\"3246975\",\"name\":\"Seungji Yang\"},{\"authorId\":\"1789522\",\"name\":\"J. W. Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48c00a9f3f12f6bf35b59ec5a2986283ffc4fa2\",\"title\":\"Joint Representation of Temporal Image Sequences and Object Motion for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/a48c00a9f3f12f6bf35b59ec5a2986283ffc4fa2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1602.00828\",\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2017.2691768\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e777c6a5f57e51d77b78d8eb04184a71951bd8e8\",\"title\":\"Learning a Deep Model for Human Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/e777c6a5f57e51d77b78d8eb04184a71951bd8e8\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-016-0980-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a03a2154f9aaff21c190634c888ed6d4f8d52150\",\"title\":\"Space-Time Tree Ensemble for Action Recognition and Localization\",\"url\":\"https://www.semanticscholar.org/paper/a03a2154f9aaff21c190634c888ed6d4f8d52150\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"144910981\",\"name\":\"Michel Antunes\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.5220/0006648703800386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"766893e08f288d50ad457ed32e27331cc0d12347\",\"title\":\"Anticipating Suspicious Actions using a Small Dataset of Action Templates\",\"url\":\"https://www.semanticscholar.org/paper/766893e08f288d50ad457ed32e27331cc0d12347\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350413\",\"name\":\"Zijian Kang\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-19823-7_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"title\":\"Extracting Action Sensitive Features to Facilitate Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"venue\":\"AIAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":\"50841852\",\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1109/TIP.2019.2917283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"title\":\"Dense Dilated Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1145/3264706.3264716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"title\":\"PhD thesis: objects for spatio-temporal activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"venue\":\"ACMMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458333\",\"name\":\"Adel Saleh\"},{\"authorId\":\"46717559\",\"name\":\"Mohamed Abdel-Nasser\"},{\"authorId\":\"35257513\",\"name\":\"Miguel \\u00c1ngel Garc\\u00eda\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1016/j.patrec.2017.06.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dfbf2eb54e7307cbd7a4274f9368172e93645e7\",\"title\":\"Aggregating the temporal coherent descriptors in videos using multiple learning kernel for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1dfbf2eb54e7307cbd7a4274f9368172e93645e7\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867157\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47364599\",\"name\":\"Mingli Ding\"},{\"authorId\":\"2860057\",\"name\":\"Yancheng Bai\"},{\"authorId\":\"48928816\",\"name\":\"Dandan Liu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1016/j.patrec.2019.10.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d277ff82da3cb6bdfe9987f1be12998cccbf3c37\",\"title\":\"Learning a strong detector for action localization in videos\",\"url\":\"https://www.semanticscholar.org/paper/d277ff82da3cb6bdfe9987f1be12998cccbf3c37\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2288399\",\"name\":\"J. Ullah\"},{\"authorId\":\"144889214\",\"name\":\"M. Jaffar\"}],\"doi\":\"10.1007/s10586-017-0825-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe0b61e8204ac32199a941aba55f5d8b50ed6c34\",\"title\":\"Object and motion cues based collaborative approach for human activity localization and recognition in unconstrained videos\",\"url\":\"https://www.semanticscholar.org/paper/fe0b61e8204ac32199a941aba55f5d8b50ed6c34\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"9372088\",\"name\":\"Quan-Feng Yan\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1016/j.jvcir.2018.11.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bc2067187f80df348a9bdf4dfed2268a1ba591c\",\"title\":\"Detection and tracking based tubelet generation for video object detection\",\"url\":\"https://www.semanticscholar.org/paper/1bc2067187f80df348a9bdf4dfed2268a1ba591c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8060096\",\"name\":\"Sheng-hung Hu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ICPR.2016.7899735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f6ab4543cc38f23d0339e3037a952df7bcf696b\",\"title\":\"Video2vec: Learning semantic spatio-temporal embeddings for video representation\",\"url\":\"https://www.semanticscholar.org/paper/5f6ab4543cc38f23d0339e3037a952df7bcf696b\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"1384716902\",\"name\":\"Jin Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"265010019d3d95568d237973b5d957c6aa80d7dd\",\"title\":\"SAFER : Fine-grained Activity Detection by Compositional Hypothesis Testing\",\"url\":\"https://www.semanticscholar.org/paper/265010019d3d95568d237973b5d957c6aa80d7dd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"1895652\",\"name\":\"\\u00c0. Pardo\"},{\"authorId\":\"32462570\",\"name\":\"O. Vila\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/s00138-018-0931-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6576b653dedd46f5356c4d12e9785c8c1dca36d1\",\"title\":\"Action detection fusing multiple Kinects and a WIMU: an application to in-home assistive technology for the elderly\",\"url\":\"https://www.semanticscholar.org/paper/6576b653dedd46f5356c4d12e9785c8c1dca36d1\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"10225694\",\"name\":\"F. Xiao\"},{\"authorId\":\"2914175\",\"name\":\"Wan-kou Yang\"}],\"doi\":\"10.1016/j.neucom.2020.02.096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9682c70b844cb35eb602d165933d83a369c986c2\",\"title\":\"Multilayer deep features with multiple kernel learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9682c70b844cb35eb602d165933d83a369c986c2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2010.01204\",\"authors\":[{\"authorId\":\"2146623\",\"name\":\"Kourosh Meshgi\"},{\"authorId\":\"31095396\",\"name\":\"Maryam Sadat Mirzaei\"},{\"authorId\":\"38809507\",\"name\":\"S. Oba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45084e6ee329bde87f1ac882994fe017431a1834\",\"title\":\"Leveraging Tacit Information Embedded in CNN Layers for Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/45084e6ee329bde87f1ac882994fe017431a1834\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10356\",\"authors\":[{\"authorId\":\"2298523\",\"name\":\"Achal Dave\"},{\"authorId\":\"51265481\",\"name\":\"Tarasha Khurana\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1007/978-3-030-58558-7_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"982cb4421cedce057ae2fc864efac8e43d9c0a5a\",\"title\":\"TAO: A Large-Scale Benchmark for Tracking Any Object\",\"url\":\"https://www.semanticscholar.org/paper/982cb4421cedce057ae2fc864efac8e43d9c0a5a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1505718218\",\"name\":\"Shusheng Li\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/BigData47090.2019.9006260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ac91d8a72268deed399f6813cd7417b3440ddcf\",\"title\":\"VidAnomaly: LSTM-Autoencoder-Based Adversarial Learning for One-Class Video Classification With Multiple Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/3ac91d8a72268deed399f6813cd7417b3440ddcf\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67267687\",\"name\":\"K. Degiorgio\"},{\"authorId\":\"66747080\",\"name\":\"Oxford Brookes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a953ad6cd0375bb1b72098df1caa4c2d17ae8adf\",\"title\":\"Automatic Localization of Spatio-Temporal Actions in Weakly Supervised Video\",\"url\":\"https://www.semanticscholar.org/paper/a953ad6cd0375bb1b72098df1caa4c2d17ae8adf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1612.06615\",\"authors\":[{\"authorId\":\"8161428\",\"name\":\"Susanna Gladh\"},{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":\"10.1109/ICPR.2016.7899807\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e7e3b4eb8bc0a7f29ca560b1cceb986a1dcd977\",\"title\":\"Deep motion features for visual tracking\",\"url\":\"https://www.semanticscholar.org/paper/2e7e3b4eb8bc0a7f29ca560b1cceb986a1dcd977\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.09283\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/WACV.2019.00027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ced33344402d74f69367caa163e94918f307ab78\",\"title\":\"Coupled Generative Adversarial Network for Continuous Fine-Grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ced33344402d74f69367caa163e94918f307ab78\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1605.05197\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"144173710\",\"name\":\"X. Martin\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"08d40ee6e1c0060d3b706b6b627e03d4b123377a\",\"title\":\"Towards Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/08d40ee6e1c0060d3b706b6b627e03d4b123377a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"33379011\",\"name\":\"E. Gati\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.5244/C.29.177\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21ef7e01de0e1feb4b21c89ccb0423e4213bb9e0\",\"title\":\"APT: Action localization proposals from dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/21ef7e01de0e1feb4b21c89ccb0423e4213bb9e0\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390937493\",\"name\":\"Alaaeldin Ali\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"title\":\"Spatiotemporal Representation Learning For Human Action Recognition And Localization\",\"url\":\"https://www.semanticscholar.org/paper/54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"47842446\",\"name\":\"MingYu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360{\\\\deg} Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"144624889\",\"name\":\"Zhiyuan Shi\"},{\"authorId\":\"36064037\",\"name\":\"Masato Kawade\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f48e2d8655e04bc06c0d90eaa2e0be03466d69c9\",\"title\":\"Kinematic-aware random forest for static and dynamic action recognition from depth sequences\",\"url\":\"https://www.semanticscholar.org/paper/f48e2d8655e04bc06c0d90eaa2e0be03466d69c9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.219\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"151b87de997e55db892b122c211f9c749f4293de\",\"title\":\"Joint Learning of Object and Action Detectors\",\"url\":\"https://www.semanticscholar.org/paper/151b87de997e55db892b122c211f9c749f4293de\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":\"1701.04925\",\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"}],\"doi\":\"10.1109/ICRA.2017.7989361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48cad609886bec3fdcc4417343e3e1dfb117bdd2\",\"title\":\"Action recognition: From static datasets to moving robots\",\"url\":\"https://www.semanticscholar.org/paper/48cad609886bec3fdcc4417343e3e1dfb117bdd2\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":\"1710.03383\",\"authors\":[{\"authorId\":\"2682151\",\"name\":\"Cheng-Bin Jin\"},{\"authorId\":\"2707231\",\"name\":\"Shengzhe Li\"},{\"authorId\":\"1697362\",\"name\":\"H. Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"208e903211ddc62b997afb5a1bd3c2c43e0e69ee\",\"title\":\"Real-Time Action Detection in Video Surveillance using Sub-Action Descriptor with Multi-CNN\",\"url\":\"https://www.semanticscholar.org/paper/208e903211ddc62b997afb5a1bd3c2c43e0e69ee\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.08561\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e03e86ac61cfac9148b371d75ce81a55e8b332ca\",\"title\":\"Unsupervised Learning using Sequential Verification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e03e86ac61cfac9148b371d75ce81a55e8b332ca\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/ICCV.2017.619\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"44a3e466743add34a34567b4566ebe6c98bd2abf\",\"title\":\"TORNADO: A Spatio-Temporal Convolutional Regression Network for Video Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/44a3e466743add34a34567b4566ebe6c98bd2abf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"2226422\",\"name\":\"Bin-Bin Gao\"},{\"authorId\":\"144349436\",\"name\":\"G. Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b30259a8ab07394d4dac971f3d3bd633beac811\",\"title\":\"Representing Sets of Instances for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b30259a8ab07394d4dac971f3d3bd633beac811\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1807.11332\",\"authors\":[{\"authorId\":\"143716515\",\"name\":\"V. Fontana\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"51152717\",\"name\":\"Stephen Akrigg\"},{\"authorId\":\"51149466\",\"name\":\"Manuele Di Maio\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd71ae9599e8a51d8a61e31e6faaaf4a23a17d81\",\"title\":\"Action Detection from a Robot-Car Perspective\",\"url\":\"https://www.semanticscholar.org/paper/fd71ae9599e8a51d8a61e31e6faaaf4a23a17d81\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145625472\",\"name\":\"Qing Han\"},{\"authorId\":\"150129692\",\"name\":\"Haoyu Zhao\"},{\"authorId\":\"34924661\",\"name\":\"Weidong Min\"},{\"authorId\":\"144557888\",\"name\":\"H. Cui\"},{\"authorId\":\"1491232321\",\"name\":\"X. Zhou\"},{\"authorId\":\"1491243878\",\"name\":\"Ke Zuo\"},{\"authorId\":\"1389207398\",\"name\":\"Ruikang Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2962778\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa047afa0119449387fce48394d5071d42a99ff3\",\"title\":\"A Two-Stream Approach to Fall Detection With MobileVGG\",\"url\":\"https://www.semanticscholar.org/paper/aa047afa0119449387fce48394d5071d42a99ff3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1707.07213\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"060caad01a56ac543bc8847308ff436ebd3ec5a2\",\"title\":\"Spatio-temporal human action localisation and instance segmentation in temporally untrimmed videos\",\"url\":\"https://www.semanticscholar.org/paper/060caad01a56ac543bc8847308ff436ebd3ec5a2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35605350\",\"name\":\"Kankana Roy\"},{\"authorId\":\"31629324\",\"name\":\"R. R. Sahay\"}],\"doi\":\"10.1145/3293353.3293398\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1ed110bffa5b07de5e6c52cb8878de1cb76d0f9\",\"title\":\"Dynamic Gesture Recognition with Pose-based CNN Features derived from videos using LSTM\",\"url\":\"https://www.semanticscholar.org/paper/d1ed110bffa5b07de5e6c52cb8878de1cb76d0f9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1703.10664\",\"authors\":[{\"authorId\":\"151185786\",\"name\":\"R. Hou\"},{\"authorId\":\"145430739\",\"name\":\"C. Chen\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.620\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"065f55d40d473b63becccc890fe8a57c2f840548\",\"title\":\"Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065f55d40d473b63becccc890fe8a57c2f840548\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"3309893\",\"name\":\"G. Brostow\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7e7ff6237110e3d78be3bde42196b02935f207f\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/f7e7ff6237110e3d78be3bde42196b02935f207f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48625207\",\"name\":\"W. Li\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1007/978-3-319-97289-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"473c74782b0120aa0a8b0e94f49fea6542a6d7da\",\"title\":\"Get the Whole Action Event by Action Stage Classification\",\"url\":\"https://www.semanticscholar.org/paper/473c74782b0120aa0a8b0e94f49fea6542a6d7da\",\"venue\":\"PKAW\",\"year\":2018},{\"arxivId\":\"1905.04668\",\"authors\":[{\"authorId\":\"2133342\",\"name\":\"Mohammadreza Babaee\"},{\"authorId\":\"119389363\",\"name\":\"David Full\"},{\"authorId\":\"145512909\",\"name\":\"Gerhard Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"138aedf23346d7d5a4a8c38c935735a436f7c839\",\"title\":\"On Flow Profile Image for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/138aedf23346d7d5a4a8c38c935735a436f7c839\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143781496\",\"name\":\"Ke Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Yong Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"title\":\"TPC: Temporal Preservation Convolutional Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.11122\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"51150048\",\"name\":\"Kyle Buettner\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"title\":\"Story Understanding in Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.82\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c535d4d61aa0f1d8aadb4082bdcc19f4cbdf0eaf\",\"title\":\"Unsupervised Action Discovery and Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c535d4d61aa0f1d8aadb4082bdcc19f4cbdf0eaf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.02349\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"144091320\",\"name\":\"Guyue Zhang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"10727378\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCV.2017.610\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f0167299d73b19d800953dd2859a0af2244a0c5\",\"title\":\"Temporal Context Network for Activity Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5f0167299d73b19d800953dd2859a0af2244a0c5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"30118739\",\"name\":\"X. Zhang\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1109/ICASSP.2017.7952428\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbb5adf82ee210782d0afd66de6a5e257b1b9578\",\"title\":\"Learning a hierarchical spatio-temporal model for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbb5adf82ee210782d0afd66de6a5e257b1b9578\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1612.07403\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/WACV.2017.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e12226cf0da453dc4b9879d7af6b43af3c31d2b\",\"title\":\"Efficient Action Detection in Untrimmed Videos via Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/6e12226cf0da453dc4b9879d7af6b43af3c31d2b\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1610.09334\",\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/WACV.2017.25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7fe851e1acc8a974697fb74d913736a3a849003\",\"title\":\"Real-Time Online Action Detection Forests Using Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/c7fe851e1acc8a974697fb74d913736a3a849003\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3318552\",\"name\":\"Francesco Turchini\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1016/j.cviu.2016.11.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2851efe83633a1c80272ba2c9302a1333dd32523\",\"title\":\"Understanding and localizing activities from correspondences of clustered trajectories\",\"url\":\"https://www.semanticscholar.org/paper/2851efe83633a1c80272ba2c9302a1333dd32523\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38932510\",\"name\":\"J. Matas\"},{\"authorId\":\"34788950\",\"name\":\"N. Sebe\"},{\"authorId\":\"144026434\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eef65ed4a246a15fb1dd0a3816fef9c9988ee22\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5eef65ed4a246a15fb1dd0a3816fef9c9988ee22\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1905.13417\",\"authors\":[{\"authorId\":\"143629372\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"144254616\",\"name\":\"Hongbin Sun\"}],\"doi\":\"10.1109/CVPR.2019.01226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"518512621412fd76d47ef9225a45fcc99d0247d2\",\"title\":\"TACNet: Transition-Aware Context Network for Spatio-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/518512621412fd76d47ef9225a45fcc99d0247d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":null,\"name\":\"Nannan Li\"}],\"doi\":\"10.1109/ACCESS.2018.2842088\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1312b0b0fd660de87fa42de39316b28f9336e70\",\"title\":\"Action Extraction in Continuous Unconstrained Video for Cloud-Based Intelligent Service Robot\",\"url\":\"https://www.semanticscholar.org/paper/e1312b0b0fd660de87fa42de39316b28f9336e70\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145182602\",\"name\":\"Dong Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01231-1_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"title\":\"Recurrent Tubelet Proposal and Recognition Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"40013571\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/WCICA.2018.8630333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e6695e24f9f6e74f57f26925d7ace2a34d49574\",\"title\":\"Kinematics Features for 3D Action Recognition Using Two-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/6e6695e24f9f6e74f57f26925d7ace2a34d49574\",\"venue\":\"2018 13th World Congress on Intelligent Control and Automation (WCICA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144957857\",\"name\":\"H. Nishimura\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":\"10.3169/mta.8.269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a1ba4af7caa08a2dd5a69dd99499d544dd2178d\",\"title\":\"[Paper] Multiple Human Tracking with Alternately Updating Trajectories and Multi-Frame Action Features\",\"url\":\"https://www.semanticscholar.org/paper/3a1ba4af7caa08a2dd5a69dd99499d544dd2178d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"49308184\",\"name\":\"Y. Yang\"},{\"authorId\":\"143822920\",\"name\":\"He Jiang\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"2585506\",\"name\":\"G. Wang\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/RCAR.2018.8621829\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"title\":\"Action Recognition and Localization with Instance FCNN\",\"url\":\"https://www.semanticscholar.org/paper/ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"venue\":\"2018 IEEE International Conference on Real-time Computing and Robotics (RCAR)\",\"year\":2018},{\"arxivId\":\"2003.14065\",\"authors\":[{\"authorId\":\"153216912\",\"name\":\"Dong Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350978\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"title\":\"Long Short-Term Relation Networks for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1748978266\",\"name\":\"Francis Kaping\\u2019a\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f35ada2c1739ce47f9e8e30cba1c41392efbe7c3\",\"title\":\"Deep learning for action and event detection in endoscopic videos for robotic assisted laparoscopy\",\"url\":\"https://www.semanticscholar.org/paper/f35ada2c1739ce47f9e8e30cba1c41392efbe7c3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"145823372\",\"name\":\"Scott Cohen\"},{\"authorId\":\"145907577\",\"name\":\"Walter Chang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145159523\",\"name\":\"Ahmed M. Elgammal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d93a346caab9ba9788a190c1f95aa626b63f3149\",\"title\":\"Sherlock: Modeling Structured Knowledge in Images\",\"url\":\"https://www.semanticscholar.org/paper/d93a346caab9ba9788a190c1f95aa626b63f3149\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.01494\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"title\":\"Two-Stream AMTnet for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.06724\",\"authors\":[{\"authorId\":\"32082024\",\"name\":\"Ali Javidani\"},{\"authorId\":\"2757076\",\"name\":\"Ahmad Mahmoudi Aznaveh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"075ec6ce86828da112558e4c73e7135e0a7a269f\",\"title\":\"Learning Representative Temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/075ec6ce86828da112558e4c73e7135e0a7a269f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.09403\",\"authors\":[{\"authorId\":\"41049768\",\"name\":\"Amlaan Bhoi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"title\":\"Spatio-temporal Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01225-0_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62c1a6558a2a0d5fd6df4c0fec99dd9027d1c448\",\"title\":\"End-to-End Joint Semantic Segmentation of Actors and Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/62c1a6558a2a0d5fd6df4c0fec99dd9027d1c448\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145547128\",\"name\":\"D. Sawyer\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/WACVW.2019.00014\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"56eddb8ecbcf5090b0a03daa703e0824700a0d22\",\"title\":\"Fine-grained Action Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/56eddb8ecbcf5090b0a03daa703e0824700a0d22\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1923910\",\"name\":\"A. Sciutti\"},{\"authorId\":\"2096166\",\"name\":\"F. Rea\"}],\"doi\":\"10.1007/978-3-030-46732-6_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"642877762bae43cfb65135934eda142daab44516\",\"title\":\"Modeling Human Motion: A Task at the Crossroads of Neuroscience, Computer Vision and Robotics\",\"url\":\"https://www.semanticscholar.org/paper/642877762bae43cfb65135934eda142daab44516\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.00696\",\"authors\":[{\"authorId\":\"4712803\",\"name\":\"Jiaojiao Zhao\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2019.01017\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"title\":\"Dance With Flow: Two-In-One Stream Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1606.04702\",\"authors\":[{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-017-1006-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f168d6933ba90c241ad0295b01e43538883d524\",\"title\":\"DeepProposals: Hunting Objects and Actions by Cascading Deep Convolutional Layers\",\"url\":\"https://www.semanticscholar.org/paper/5f168d6933ba90c241ad0295b01e43538883d524\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1705.01759\",\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.153\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba227bb94ea9414bad8846673c904a10d813e443\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360\\u00b0 Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba227bb94ea9414bad8846673c904a10d813e443\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1103/PHYSREVD.94.065007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"edbdb4de4367d245cb5f78d77de68464f9bdcde1\",\"title\":\"Learning a Deep Model for Human Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/edbdb4de4367d245cb5f78d77de68464f9bdcde1\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754854\",\"name\":\"Venice Erin Liong\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"1689805\",\"name\":\"Y. Tan\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TMM.2016.2645404\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e32c482f2ba4cdfe321aa8eea7ff11679679cdc\",\"title\":\"Deep Video Hashing\",\"url\":\"https://www.semanticscholar.org/paper/9e32c482f2ba4cdfe321aa8eea7ff11679679cdc\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8708983\",\"name\":\"Nour El Din Elmadany\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/TIP.2018.2855438\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"3e28bb5189c06ac97cf2b7702dbdf0b4fece14da\",\"title\":\"Information Fusion for Human Action Recognition via Biset/Multiset Globality Locality Preserving Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3e28bb5189c06ac97cf2b7702dbdf0b4fece14da\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1807.02800\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7e10cee568b9251c894e002c5304fb1205eb4ea\",\"title\":\"Spatio-Temporal Instance Learning: Action Tubes from Class Supervision\",\"url\":\"https://www.semanticscholar.org/paper/c7e10cee568b9251c894e002c5304fb1205eb4ea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7618968\",\"name\":\"Panos Sourtzinos\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"},{\"authorId\":\"144112491\",\"name\":\"M. Jara\"},{\"authorId\":\"144919173\",\"name\":\"P. Zegers\"},{\"authorId\":\"143920053\",\"name\":\"D. Makris\"}],\"doi\":\"10.1007/978-3-319-48881-3_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f124342299ea42da49d3906e1447b5b863089bd7\",\"title\":\"People Counting in Videos by Fusing Temporal Cues from Spatial Context-Aware Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f124342299ea42da49d3906e1447b5b863089bd7\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754854\",\"name\":\"Venice Erin Liong\"}],\"doi\":\"10.32657/10220/48655\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c350c8aeec9163e9b3c0c1d96a0cdabf732ff6e\",\"title\":\"Compact feature learning for multimedia retrieval\",\"url\":\"https://www.semanticscholar.org/paper/1c350c8aeec9163e9b3c0c1d96a0cdabf732ff6e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3031655\",\"name\":\"Stavros Tachos\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1713991\",\"name\":\"Alexia Briassouli\"},{\"authorId\":\"1715604\",\"name\":\"Yiannis Kompatsiaris\"}],\"doi\":\"10.1016/j.cviu.2017.04.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b2812cf37440cc09a7e2734b927986b4027539b\",\"title\":\"Mining discriminative descriptors for goal-based activity detection\",\"url\":\"https://www.semanticscholar.org/paper/5b2812cf37440cc09a7e2734b927986b4027539b\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1704.07945\",\"authors\":[{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2017.162\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06184106c9a5dc602cac98f162b991707aaa4a80\",\"title\":\"Spatio-Temporal Person Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/06184106c9a5dc602cac98f162b991707aaa4a80\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1601.06615\",\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.3389/frobt.2015.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"412b3ef02c85087e5f1721176114672c722b17a4\",\"title\":\"A Taxonomy of Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/412b3ef02c85087e5f1721176114672c722b17a4\",\"venue\":\"Front. Robot. AI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9102201\",\"name\":\"Yaxiang Fan\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"},{\"authorId\":\"144334479\",\"name\":\"Gongjian Wen\"},{\"authorId\":\"3437649\",\"name\":\"Shaohua Qiu\"}],\"doi\":\"10.1016/j.neucom.2017.02.082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fe7239546e34ede6579fad5d7f36317c850fefd\",\"title\":\"A deep neural network for real-time detection of falling humans in naturally occurring scenes\",\"url\":\"https://www.semanticscholar.org/paper/9fe7239546e34ede6579fad5d7f36317c850fefd\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"1790580\",\"name\":\"Bharath Hariharan\"},{\"authorId\":\"145579476\",\"name\":\"Abhishek Kar\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"}],\"doi\":\"10.1016/j.patrec.2016.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37314dbf2d7680b0545223abefbb58cf476273bd\",\"title\":\"The three R's of computer vision: Recognition, reconstruction and reorganization\",\"url\":\"https://www.semanticscholar.org/paper/37314dbf2d7680b0545223abefbb58cf476273bd\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123503107\",\"name\":\"Kuldeep Biradar\"},{\"authorId\":\"70525493\",\"name\":\"Sachin Dube\"},{\"authorId\":\"145353981\",\"name\":\"S. K. Vipparthi\"}],\"doi\":\"10.1109/ICIINFS.2018.8721378\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a14bfc876e1e479a821be4c64b6055d6880c8845\",\"title\":\"DEARESt: Deep Convolutional Aberrant Behavior Detection in Real-world Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/a14bfc876e1e479a821be4c64b6055d6880c8845\",\"venue\":\"2018 IEEE 13th International Conference on Industrial and Information Systems (ICIIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"},{\"authorId\":\"49922196\",\"name\":\"Goutam Bhat\"},{\"authorId\":\"8161428\",\"name\":\"Susanna Gladh\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":\"10.1016/J.PATREC.2018.03.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25923d596be46903443bd480f1f64377a4d21822\",\"title\":\"Deep motion and appearance cues for visual tracking\",\"url\":\"https://www.semanticscholar.org/paper/25923d596be46903443bd480f1f64377a4d21822\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49663634\",\"name\":\"W. Liu\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"18318910\",\"name\":\"J. Zhang\"},{\"authorId\":\"10784631\",\"name\":\"Zhonghao Wu\"}],\"doi\":\"10.1109/ICIP.2018.8451095\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"901aba97a30b6e7a7aa6093fa72f5b9f7cd9d896\",\"title\":\"Global for Coarse and Part for Fine: A Hierarchical Action Recognition Framework\",\"url\":\"https://www.semanticscholar.org/paper/901aba97a30b6e7a7aa6093fa72f5b9f7cd9d896\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1109/CVPR.2016.216\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"title\":\"A Multi-stream Bi-directional Recurrent Neural Network for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145292119\",\"name\":\"Espinosa Oviedo\"},{\"authorId\":\"72847519\",\"name\":\"J. Ernesto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e3c0687c7fe33d43c802d8ceb3ec3dced14c83b\",\"title\":\"Detection and tracking of motorcycles in urban environments by using video sequences with high level of oclussion\",\"url\":\"https://www.semanticscholar.org/paper/6e3c0687c7fe33d43c802d8ceb3ec3dced14c83b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d83ae5926b05894fcda0bc89bdc621e4f21272da\",\"title\":\"Frugal Forests : Learning a Dynamic and Cost Sensitive Feature Extraction Policy for Anytime Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/d83ae5926b05894fcda0bc89bdc621e4f21272da\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2008.08332\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"46961961\",\"name\":\"Cong Yang\"}],\"doi\":\"10.1007/978-3-030-58517-4_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"title\":\"CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134835107\",\"name\":\"Van Gemert\"},{\"authorId\":\"48038845\",\"name\":\"Elena Gati\"},{\"authorId\":\"49418951\",\"name\":\"Xueliang Xie\"},{\"authorId\":\"145063584\",\"name\":\"Mark W. Jones\"},{\"authorId\":\"1888880\",\"name\":\"Gary K. L. Tam\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76e0dac1af110cf11f31ff08e205e4ee082af285\",\"title\":\"UvA-DARE ( Digital Academic Repository ) APT : Action localization Proposals from dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/76e0dac1af110cf11f31ff08e205e4ee082af285\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145064562\",\"name\":\"Kenneth Jung\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d915e634aec40d7ee00cbea96d735d3e69602f1a\",\"title\":\"Two-Stream convolutional nets for action recognition in untrimmed video\",\"url\":\"https://www.semanticscholar.org/paper/d915e634aec40d7ee00cbea96d735d3e69602f1a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.5244/C.31.91\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e899061f8ac891f39f197fbbb5cc64ab57bebd6a\",\"title\":\"Real-Time Temporal Action Localization in Untrimmed Videos by Sub-Action Discovery\",\"url\":\"https://www.semanticscholar.org/paper/e899061f8ac891f39f197fbbb5cc64ab57bebd6a\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1610.04997\",\"authors\":[{\"authorId\":\"1975564\",\"name\":\"M. Zanfir\"},{\"authorId\":\"2045166\",\"name\":\"Elisabeta Marinoiu\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1007/978-3-319-54190-7_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ed613b6f0427d3ec4cad6c51dcc451786812959\",\"title\":\"Spatio-Temporal Attention Models for Grounded Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4ed613b6f0427d3ec4cad6c51dcc451786812959\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1806.11328\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a230350dc8a135fc390f9bb634249d08a07cea4e\",\"title\":\"A flexible model for training action localization with varying levels of supervision\",\"url\":\"https://www.semanticscholar.org/paper/a230350dc8a135fc390f9bb634249d08a07cea4e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"48981507\",\"name\":\"J. Cao\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ICPR.2016.7900180\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d2f054bc1f66cc9443956d5ac7501aee54e4e33\",\"title\":\"MSR-CNN: Applying motion salient region based descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d2f054bc1f66cc9443956d5ac7501aee54e4e33\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29448130\",\"name\":\"Rico Thomanek\"},{\"authorId\":\"71502945\",\"name\":\"Tony Rolletschke\"},{\"authorId\":\"72743860\",\"name\":\"Benny Platte\"},{\"authorId\":\"120976709\",\"name\":\"Claudia H\\u00f6sel\"},{\"authorId\":\"29334132\",\"name\":\"Christian Roschke\"},{\"authorId\":\"3243773\",\"name\":\"R. Manthey\"},{\"authorId\":\"3282581\",\"name\":\"Manuel Heinzig\"},{\"authorId\":\"36000053\",\"name\":\"R. Vogel\"},{\"authorId\":\"144084779\",\"name\":\"F. Zimmer\"},{\"authorId\":\"1861810\",\"name\":\"M. Vodel\"},{\"authorId\":\"34738835\",\"name\":\"M. Eibl\"},{\"authorId\":\"152432592\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/WACVW50321.2020.9096936\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"437466ec6eb15c157d17251b8c118255258ed8f6\",\"title\":\"Real-Time Activity Detection of Human Movement in Videos via Smartphone Based on Synthetic Training Data\",\"url\":\"https://www.semanticscholar.org/paper/437466ec6eb15c157d17251b8c118255258ed8f6\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13723092\",\"name\":\"J. Chauhan\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/CRV.2018.00039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2945e982dd21d4efc3103a6c8aae7b7bd367414\",\"title\":\"Context-Aware Action Detection in Untrimmed Videos Using Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/b2945e982dd21d4efc3103a6c8aae7b7bd367414\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1902.03715\",\"authors\":[{\"authorId\":\"2298523\",\"name\":\"Achal Dave\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCVW.2019.00187\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"189ba8260ecd0376503de41e659d9ed666750932\",\"title\":\"Towards Segmenting Anything That Moves\",\"url\":\"https://www.semanticscholar.org/paper/189ba8260ecd0376503de41e659d9ed666750932\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22015276\",\"name\":\"Y. Wu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1007/978-3-030-00767-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"069ab36fee71b15e9e6e8652e066f59d768ea071\",\"title\":\"Three-Stream Action Tubelet Detector for Spatiotemporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/069ab36fee71b15e9e6e8652e066f59d768ea071\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"47634649\",\"name\":\"Akshay Dudhane\"},{\"authorId\":\"1430720118\",\"name\":\"Prashant W. Patil\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/AVSS.2019.8909835\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cee3f7cb4e13944404d8e92c2ff205cb990e3dc2\",\"title\":\"Pose Guided Dynamic Image Network for Human Action Recognition in Person Centric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cee3f7cb4e13944404d8e92c2ff205cb990e3dc2\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798691\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144323097\",\"name\":\"W. Yu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9695232daa85651937569d1b7b2541faf2633dc\",\"title\":\"Actionness-pooled Deep-convolutional Descriptor for fine-grained action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9695232daa85651937569d1b7b2541faf2633dc\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2010.08946\",\"authors\":[{\"authorId\":\"1572302655\",\"name\":\"S. Innocenti\"},{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"2619131\",\"name\":\"F. Pernici\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bdf618e4d75d565ca9305a6ad31b4f6318d30402\",\"title\":\"Temporal Binary Representation for Event-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bdf618e4d75d565ca9305a6ad31b4f6318d30402\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1016/B978-0-12-810408-8.00003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783cd91797aad234b1558099689e794b48694092\",\"title\":\"An Introduction to Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/783cd91797aad234b1558099689e794b48694092\",\"venue\":\"Deep Learning for Medical Image Analysis\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193978\",\"name\":\"Y. C. Song\"},{\"authorId\":\"2296971\",\"name\":\"Iftekhar Naim\"},{\"authorId\":\"50059663\",\"name\":\"A. Mamun\"},{\"authorId\":\"145930781\",\"name\":\"Kaustubh Kulkarni\"},{\"authorId\":\"35108153\",\"name\":\"Parag Singla\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1793218\",\"name\":\"Daniel Gildea\"},{\"authorId\":\"1690271\",\"name\":\"Henry A. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a639e9bc9c630d917b02b29b37b03e4efd2f63fc\",\"title\":\"Unsupervised Alignment of Actions in Video with Text Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a639e9bc9c630d917b02b29b37b03e4efd2f63fc\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"2003.12185\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1007/978-3-030-58568-6_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61b166040abff8309e23d804551fc3d3acc833f6\",\"title\":\"Action Localization through Continual Predictive Learning\",\"url\":\"https://www.semanticscholar.org/paper/61b166040abff8309e23d804551fc3d3acc833f6\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"819d1dcea397e6e671acf74adccdef5750550873\",\"title\":\"Representations for Visually Guided Actions\",\"url\":\"https://www.semanticscholar.org/paper/819d1dcea397e6e671acf74adccdef5750550873\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.00297\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-20876-9_27\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"563fcc87934a4e6c8843c81b58273cb366918bfb\",\"title\":\"TraMNet - Transition Matrix Network for Efficient Action Tube Proposals\",\"url\":\"https://www.semanticscholar.org/paper/563fcc87934a4e6c8843c81b58273cb366918bfb\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"081a05d88f0442915c1402548fc82e48ee8133a2\",\"title\":\"Weakly Labeled Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/081a05d88f0442915c1402548fc82e48ee8133a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1109/TIP.2019.2942814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"title\":\"Deep Reinforcement Learning for Weak Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51023221\",\"name\":\"Daochang Liu\"},{\"authorId\":\"145427096\",\"name\":\"T. Jiang\"},{\"authorId\":\"26960212\",\"name\":\"Yizhou Wang\"}],\"doi\":\"10.1109/CVPR.2019.00139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1976a516fda5e0e164c5ae7d7ad89dd09387116\",\"title\":\"Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e1976a516fda5e0e164c5ae7d7ad89dd09387116\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1609.09220\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1109/ICIP.2016.7532693\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d518d5310aaeb98a8c6a56a0aadd3c2c73363199\",\"title\":\"CNN-aware binary MAP for general semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d518d5310aaeb98a8c6a56a0aadd3c2c73363199\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2017.8078548\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b9df1094d7db7e17702e785931a927bf568ae7\",\"title\":\"Action recognition based on a mixture of RGB and depth based skeleton\",\"url\":\"https://www.semanticscholar.org/paper/71b9df1094d7db7e17702e785931a927bf568ae7\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153850291\",\"name\":\"K. Sullivan\"},{\"authorId\":\"145168853\",\"name\":\"W. Lawson\"}],\"doi\":\"10.1109/ROMAN.2017.8172497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fae839083b72d51c8c720acad0d767ebe6e81a0\",\"title\":\"Representing motion information from event-based cameras\",\"url\":\"https://www.semanticscholar.org/paper/7fae839083b72d51c8c720acad0d767ebe6e81a0\",\"venue\":\"2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1837431\",\"name\":\"Iveel Jargalsaikhan\"}],\"doi\":\"10.1145/3264706.3264714\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61ca694cbfb3d0d5c72d2b4a8a8c66770eb9d078\",\"title\":\"PhD thesis: an action recognition framework for uncontrolled video capture based on a spatio-temporal video graph\",\"url\":\"https://www.semanticscholar.org/paper/61ca694cbfb3d0d5c72d2b4a8a8c66770eb9d078\",\"venue\":\"ACMMR\",\"year\":2018},{\"arxivId\":\"1804.08208\",\"authors\":[{\"authorId\":\"144740496\",\"name\":\"P. Gao\"},{\"authorId\":\"12020218\",\"name\":\"Yipeng Ma\"},{\"authorId\":\"145592727\",\"name\":\"K. Song\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"143751006\",\"name\":\"Liyi Xiao\"},{\"authorId\":\"36124320\",\"name\":\"Yan Zhang\"}],\"doi\":\"10.1016/j.knosys.2018.08.008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58d54408ef40d89281028f0b59ed95c3e19d608c\",\"title\":\"High Performance Visual Tracking with Circular and Structural Operators\",\"url\":\"https://www.semanticscholar.org/paper/58d54408ef40d89281028f0b59ed95c3e19d608c\",\"venue\":\"Knowl. Based Syst.\",\"year\":2018},{\"arxivId\":\"1807.10982\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-01252-6_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"title\":\"Actor-Centric Relation Network\",\"url\":\"https://www.semanticscholar.org/paper/6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145184141\",\"name\":\"Yifan Wang\"},{\"authorId\":\"40403685\",\"name\":\"J. Song\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"2531379\",\"name\":\"Otmar Hilliges\"}],\"doi\":\"10.5244/C.30.108\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b09b693708f412823053508578df289b8403100a\",\"title\":\"Two-Stream SR-CNNs for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b09b693708f412823053508578df289b8403100a\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/VCIP.2018.8698697\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7282988a5173d02203abc5d3a2ae898768ce60\",\"title\":\"Multi-task CNN Model for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ff7282988a5173d02203abc5d3a2ae898768ce60\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712247436\",\"name\":\"Felix Hertlein\"},{\"authorId\":\"153443035\",\"name\":\"D. M\\u00fcnch\"},{\"authorId\":\"144006867\",\"name\":\"M. Arens\"}],\"doi\":\"10.1109/WACVW50321.2020.9096934\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"title\":\"Context Sensitivity of Spatio-Temporal Activity Detection using Hierarchical Deep Neural Networks in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963395\",\"name\":\"P. Tang\"},{\"authorId\":\"48586124\",\"name\":\"Chun-Yu Wang\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/TPAMI.2019.2910529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a69c19846bdf04a179308c824c076f1a62a46e1d\",\"title\":\"Object Detection in Videos by High Quality Object Linking\",\"url\":\"https://www.semanticscholar.org/paper/a69c19846bdf04a179308c824c076f1a62a46e1d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2130614\",\"name\":\"B. Zhao\"},{\"authorId\":\"10146913\",\"name\":\"Boya Zhao\"},{\"authorId\":\"153781465\",\"name\":\"L. Tang\"},{\"authorId\":\"143692666\",\"name\":\"Yuqi Han\"},{\"authorId\":\"2468781\",\"name\":\"W. Wang\"}],\"doi\":\"10.3390/s18030774\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67be52a0c2ba337814df25434f1051fb9acd6037\",\"title\":\"Deep Spatial-Temporal Joint Feature Representation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/67be52a0c2ba337814df25434f1051fb9acd6037\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1704.00758\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2017.06.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"079ca5438664c8fc529bfbf2749747515c098e8a\",\"title\":\"Unsupervised action proposal ranking through proposal recombination\",\"url\":\"https://www.semanticscholar.org/paper/079ca5438664c8fc529bfbf2749747515c098e8a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"146761298\",\"name\":\"Fu Xiaoc\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TCSVT.2019.2918591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"title\":\"Discriminative Multi-View Subspace Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"38748749\",\"name\":\"Wayner Barrios\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2017.338\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"551cddb9a5e20861b491ec39f3ced933f6364a17\",\"title\":\"SCC: Semantic Context Cascade for Efficient Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/551cddb9a5e20861b491ec39f3ced933f6364a17\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.09823\",\"authors\":[{\"authorId\":\"144963395\",\"name\":\"P. Tang\"},{\"authorId\":\"121900578\",\"name\":\"Chunyu Wang\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"46641540\",\"name\":\"W. Liu\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"816184ba9e9dddbe0e62ae2db423124ef87241d6\",\"title\":\"Object Detection in Videos by Short and Long Range Object Linking\",\"url\":\"https://www.semanticscholar.org/paper/816184ba9e9dddbe0e62ae2db423124ef87241d6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"1702330\",\"name\":\"R. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"title\":\"Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2656603\",\"name\":\"J. Liu\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/DICTA.2017.8227505\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"title\":\"Viewpoint Invariant RGB-D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/852ac88edc8c1336f0c9ac62ecc5ce437fc07ca7\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"1810.06827\",\"authors\":[{\"authorId\":\"3415077\",\"name\":\"Sameera Ramasinghe\"},{\"authorId\":\"32548363\",\"name\":\"Jathushan Rajasegaran\"},{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"48430646\",\"name\":\"Kanchana Ranasinghe\"},{\"authorId\":\"144952844\",\"name\":\"R. Rodrigo\"},{\"authorId\":\"144224514\",\"name\":\"A. Pasqual\"}],\"doi\":\"10.1109/TCSVT.2017.2760858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"title\":\"Combined Static and Motion Features for Deep-Networks-Based Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e98a7f4e73f49248c912b141c43031a241d4ac33\",\"title\":\"Self-supervised learning of predictive segmentation models from video. (Apprentissage autosupervis\\u00e9 de mod\\u00e8les pr\\u00e9dictifs de segmentation \\u00e0 partir de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/e98a7f4e73f49248c912b141c43031a241d4ac33\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.01233\",\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"title\":\"Classifying Collisions with Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890560\",\"name\":\"Ryota Yoshihashi\"},{\"authorId\":\"38621343\",\"name\":\"T. Trinh\"},{\"authorId\":\"48727803\",\"name\":\"Rei Kawakami\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"144801845\",\"name\":\"M. Iida\"},{\"authorId\":\"143851958\",\"name\":\"T. Naemura\"}],\"doi\":\"10.1186/s41074-018-0048-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"087a6baef9d81178f2f8f001aa9be4c0d4ed7733\",\"title\":\"Pedestrian detection with motion features via two-stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/087a6baef9d81178f2f8f001aa9be4c0d4ed7733\",\"venue\":\"IPSJ Transactions on Computer Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"118098028\",\"name\":\"Linchao He\"},{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47180213\",\"name\":\"Shifu Zhang\"},{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"153671183\",\"name\":\"Boxiong Yang\"}],\"doi\":\"10.1016/j.patcog.2020.107312\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79921dc4596e36efb431077208a73a46995d8a2c\",\"title\":\"Learning motion representation for real-time spatio-temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/79921dc4596e36efb431077208a73a46995d8a2c\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1810.08437\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/TPAMI.2019.2929038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d0a881e0c580acc7770c212396171cc64aa76c\",\"title\":\"Learning with Privileged Information via Adversarial Discriminative Modality Distillation\",\"url\":\"https://www.semanticscholar.org/paper/67d0a881e0c580acc7770c212396171cc64aa76c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740496\",\"name\":\"P. Gao\"},{\"authorId\":\"12020218\",\"name\":\"Yipeng Ma\"},{\"authorId\":\"145592727\",\"name\":\"K. Song\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"40160812\",\"name\":\"Yan Zhang\"},{\"authorId\":\"143751006\",\"name\":\"Liyi Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e3f576724049323aa1742644984e83d2f99a35a\",\"title\":\"Efficient Object Tracking based on Circular and Structural Multi-level Learners\",\"url\":\"https://www.semanticscholar.org/paper/8e3f576724049323aa1742644984e83d2f99a35a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10376365\",\"name\":\"Sourabh Kulhare\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1959ba4637739dcc6cc6995e10fd41fd6604713\",\"title\":\"Deep Learning for Semantic Video Understanding by Sourabh Kulhare\",\"url\":\"https://www.semanticscholar.org/paper/d1959ba4637739dcc6cc6995e10fd41fd6604713\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7675e7d657b3dfe25022ad918a09b588ea0d2e30\",\"title\":\"Motion in action : optical flow estimation and action localization in videos. (Le mouvement en action : estimation du flot optique et localisation d'actions dans les vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/7675e7d657b3dfe25022ad918a09b588ea0d2e30\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138115\",\"name\":\"F. Negin\"},{\"authorId\":\"40939344\",\"name\":\"A. Goel\"},{\"authorId\":\"31056622\",\"name\":\"Abdelrahman G. Abubakr\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2018.8639471\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"240cead6dabc50986a25b18dca414b538b937a51\",\"title\":\"Online Detection of Long-Term Daily Living Activities by Weakly Supervised Recognition of Sub-Activities\",\"url\":\"https://www.semanticscholar.org/paper/240cead6dabc50986a25b18dca414b538b937a51\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8744711\",\"name\":\"K. Yamada\"},{\"authorId\":\"65954842\",\"name\":\"Seiya Ito\"},{\"authorId\":\"6965816\",\"name\":\"N. Kaneko\"},{\"authorId\":\"145441213\",\"name\":\"K. Sumi\"}],\"doi\":\"10.1007/978-3-030-21074-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f35f1424c9409f94868bd5a05a9cf291183b20\",\"title\":\"Human Action Recognition via Body Part Region Segmented Dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/88f35f1424c9409f94868bd5a05a9cf291183b20\",\"venue\":\"ACCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9385562\",\"name\":\"Minwen Zhang\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"48934185\",\"name\":\"Q. Li\"},{\"authorId\":\"48169955\",\"name\":\"L. Wang\"},{\"authorId\":\"49050577\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11042-017-5116-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"954ce390c9e762b2c34b0c6cc8d8829bc6932d4c\",\"title\":\"Action detection based on tracklets with the two-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/954ce390c9e762b2c34b0c6cc8d8829bc6932d4c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1923910\",\"name\":\"A. Sciutti\"},{\"authorId\":\"2096166\",\"name\":\"F. Rea\"},{\"authorId\":\"5861924\",\"name\":\"P. Hilt\"}],\"doi\":\"10.1007/978-3-030-46732-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c18d06d4ad7b1c54286f7dff79c4610d6c0ae8\",\"title\":\"Modelling Human Motion: From Human Perception to Robot Design\",\"url\":\"https://www.semanticscholar.org/paper/84c18d06d4ad7b1c54286f7dff79c4610d6c0ae8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"144173710\",\"name\":\"X. Martin\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3daafe6389d877fe15d8823cdf5ac15fd919676f\",\"title\":\"Human Action Localization with Sparse Spatial Supervision\",\"url\":\"https://www.semanticscholar.org/paper/3daafe6389d877fe15d8823cdf5ac15fd919676f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1809.03193\",\"authors\":[{\"authorId\":\"51443250\",\"name\":\"Shivang Agarwal\"},{\"authorId\":\"143610045\",\"name\":\"Jean Ogier du Terrail\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"433000c371d0d8121cc7699f93987ade7ddd1055\",\"title\":\"Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/433000c371d0d8121cc7699f93987ade7ddd1055\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2019.2921655\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"title\":\"Sports Video Captioning via Attentive Motion Representation and Group Relationship Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8897402\",\"name\":\"Feng-Ping An\"}],\"doi\":\"10.1109/ACCESS.2018.2874022\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f1ef5156eccee6c845bb9f0a99a3943218e145a3\",\"title\":\"Human Action Recognition Algorithm Based on Adaptive Initialization of Deep Learning Model Parameters and Support Vector Machine\",\"url\":\"https://www.semanticscholar.org/paper/f1ef5156eccee6c845bb9f0a99a3943218e145a3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1eb4ea011a3122dc7ef3447e10c1dad5b69b0642\",\"title\":\"Contextual Visual Recognition from Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/1eb4ea011a3122dc7ef3447e10c1dad5b69b0642\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2298523\",\"name\":\"Achal Dave\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a0f23dcb731762f9cc968d63385183b301eef89\",\"title\":\"Stream Appearance & Stream Joint & Training\",\"url\":\"https://www.semanticscholar.org/paper/3a0f23dcb731762f9cc968d63385183b301eef89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"2765994\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"246c1e49f956063e28ba7941b6cc6242d753d303\",\"title\":\"CNN Activity : Tumbling Complete Tumbling ? Yes\",\"url\":\"https://www.semanticscholar.org/paper/246c1e49f956063e28ba7941b6cc6242d753d303\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1612.01194\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2018.2797266\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"title\":\"Online Localization and Prediction of Actions and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1708.03280\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"title\":\"Exploring Temporal Preservation Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355949\",\"name\":\"Tang-Wei Hsu\"},{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"144906905\",\"name\":\"L. Fu\"},{\"authorId\":\"38878708\",\"name\":\"Y. Zeng\"}],\"doi\":\"10.1109/SMC.2016.7844868\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b22208ef1a40d6d969d4c57c4da6d4cafa3a6b6\",\"title\":\"Privacy free indoor action detection system using top-view depth camera based on key-poses\",\"url\":\"https://www.semanticscholar.org/paper/1b22208ef1a40d6d969d4c57c4da6d4cafa3a6b6\",\"venue\":\"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2016},{\"arxivId\":\"1504.04792\",\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"2226422\",\"name\":\"Bin-Bin Gao\"},{\"authorId\":\"144349436\",\"name\":\"G. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"260f369827ac7cd76097ff61b3eda6c1d30b8668\",\"title\":\"Visual Recognition Using Directional Distribution Distance\",\"url\":\"https://www.semanticscholar.org/paper/260f369827ac7cd76097ff61b3eda6c1d30b8668\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1501.06993\",\"authors\":[{\"authorId\":\"1746008\",\"name\":\"Youjie Zhou\"},{\"authorId\":\"1730682\",\"name\":\"Hongkai Yu\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICIP.2017.8297027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0be0dcbd7284994145d072f7a24db52a210f22ed\",\"title\":\"Feature sampling strategies for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/0be0dcbd7284994145d072f7a24db52a210f22ed\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1902.10024\",\"authors\":[{\"authorId\":\"143884578\",\"name\":\"W. McNally\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"144304939\",\"name\":\"J. McPhee\"}],\"doi\":\"10.1109/CRV.2019.00015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf3e15a9392621c45da6141a78a60d341ab2e506\",\"title\":\"STAR-Net: Action Recognition using Spatio-Temporal Activation Reprojection\",\"url\":\"https://www.semanticscholar.org/paper/bf3e15a9392621c45da6141a78a60d341ab2e506\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1909.08171\",\"authors\":[{\"authorId\":\"144957857\",\"name\":\"H. Nishimura\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"84caa8a506e47b322cf9dc116806b06bca0c0981\",\"title\":\"Multiple Human Tracking using Multi-Cues including Primitive Action Features\",\"url\":\"https://www.semanticscholar.org/paper/84caa8a506e47b322cf9dc116806b06bca0c0981\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.09288\",\"authors\":[{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"145879186\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2019.00035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"title\":\"STEP: Spatio-Temporal Progressive Learning for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.01923\",\"authors\":[{\"authorId\":\"49890236\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1007/978-3-030-11024-6_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba577c7cd74b6999dadc3c9b2e7863628cf72426\",\"title\":\"An Empirical Study towards Understanding How Deep Convolutional Nets Recognize Falls\",\"url\":\"https://www.semanticscholar.org/paper/ba577c7cd74b6999dadc3c9b2e7863628cf72426\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121033030\",\"name\":\"D. Papadopoulos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc710563c48317bbd1b107c62dadf61bfb41a76f\",\"title\":\"Efficient human annotation schemes for training object class detectors\",\"url\":\"https://www.semanticscholar.org/paper/cc710563c48317bbd1b107c62dadf61bfb41a76f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"title\":\"Learning to Recognize Actions with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1902.01078\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICIP.2019.8803153\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a307c21fdd9a3edff092fe0485399714e53fd7a\",\"title\":\"Saliency Tubes: Visual Explanations for Spatio-Temporal Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7a307c21fdd9a3edff092fe0485399714e53fd7a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1507.05738\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"47243342\",\"name\":\"N. Jin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-017-1013-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"title\":\"Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1604.06506\",\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-46454-1_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"574ab231627eadc1056162c38d0895f372121250\",\"title\":\"Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/574ab231627eadc1056162c38d0895f372121250\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2001.11657\",\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/tip.2020.2967577\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"title\":\"Modality Compensation Network: Cross-Modal Adaptation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01240-3_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78c4086c392d03e206d2a25be55768cd58ce3462\",\"title\":\"Action Search: Spotting Actions in Videos and Its Application to Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/78c4086c392d03e206d2a25be55768cd58ce3462\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"35223779\",\"name\":\"Daniel Sawyer\"},{\"authorId\":\"1801614\",\"name\":\"Michal Balazia\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d891ebddb3f378774255cfb91aa06f45d211fca7\",\"title\":\"An Examination of Proposal-based Approaches to Fine-grained Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d891ebddb3f378774255cfb91aa06f45d211fca7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1505.04474\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c5f9f5083b9fca4dcdbc4b122099ac1f630728b\",\"title\":\"Visual Semantic Role Labeling\",\"url\":\"https://www.semanticscholar.org/paper/0c5f9f5083b9fca4dcdbc4b122099ac1f630728b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46521926\",\"name\":\"Xinran Liu\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":\"10.1007/978-3-319-73600-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95ea887b1692ae21e2fafae960ccca89fc55f82b\",\"title\":\"Effective Action Detection Using Temporal Context and Posterior Probability of Length\",\"url\":\"https://www.semanticscholar.org/paper/95ea887b1692ae21e2fafae960ccca89fc55f82b\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d3c288cdeeeba045514f32f8a5c5f75aa19fd7\",\"title\":\"Five years after the Deep Learning revolution of computer vision : State of the art methods for online image and video analysis\",\"url\":\"https://www.semanticscholar.org/paper/58d3c288cdeeeba045514f32f8a5c5f75aa19fd7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1601.02129\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a82860d11fcbf12628724333f1e7ada8f3cd255\",\"title\":\"Action Temporal Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/0a82860d11fcbf12628724333f1e7ada8f3cd255\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2007.08814\",\"authors\":[{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"72347323\",\"name\":\"X. Yang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-030-58539-6_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13ee363f71e07112210ac2ff27d46625f6f8edab\",\"title\":\"Visual Relation Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/13ee363f71e07112210ac2ff27d46625f6f8edab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772962\",\"name\":\"Emre Dogan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fe41a944a16c744f64d4686b6e9296290550ed5\",\"title\":\"Estimation de pose humaine et reconnaissance d'action par un syst\\u00e8me multi-robots. (Human pose estimation and action recognition by multi-robot systems)\",\"url\":\"https://www.semanticscholar.org/paper/5fe41a944a16c744f64d4686b6e9296290550ed5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1837431\",\"name\":\"Iveel Jargalsaikhan\"},{\"authorId\":\"145777795\",\"name\":\"S. Little\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/AVSS.2017.8078555\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42a5e275bc6af3e16ba06c4f8cf54d4bc7fca109\",\"title\":\"Action localization in video using a graph-based feature representation\",\"url\":\"https://www.semanticscholar.org/paper/42a5e275bc6af3e16ba06c4f8cf54d4bc7fca109\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1608.05267\",\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"3417987\",\"name\":\"F. Boussaid\"}],\"doi\":\"10.1109/TMM.2017.2778559\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83f8c54605689f093199bea52fdabaa9902ff4aa\",\"title\":\"Leveraging Structural Context Models and Ranking Score Fusion for Human Interaction Prediction\",\"url\":\"https://www.semanticscholar.org/paper/83f8c54605689f093199bea52fdabaa9902ff4aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.06495\",\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"34692827\",\"name\":\"Zhenqiang Ying\"},{\"authorId\":\"143846985\",\"name\":\"Z. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1007/978-3-319-54184-6_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fa832841daef04ec2865577d9e73b2d8d47ae1d\",\"title\":\"Searching Action Proposals via Spatial Actionness Estimation and Temporal Path Inference and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/6fa832841daef04ec2865577d9e73b2d8d47ae1d\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007998\",\"name\":\"Lars Andersson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46332770\",\"name\":\"M. Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"766691a5537bdc8d6dbba2f84f17593acd85849c\",\"title\":\"A Study on Vibration Source Localization Using High-speed Vision\",\"url\":\"https://www.semanticscholar.org/paper/766691a5537bdc8d6dbba2f84f17593acd85849c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.07006\",\"authors\":[{\"authorId\":\"144740496\",\"name\":\"P. Gao\"},{\"authorId\":\"12020218\",\"name\":\"Yipeng Ma\"},{\"authorId\":\"145592727\",\"name\":\"K. Song\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"143751006\",\"name\":\"Liyi Xiao\"}],\"doi\":\"10.1109/ICPR.2018.8545716\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88b29bfc7329854a5ffc1adb355b7bdde7fa3a0c\",\"title\":\"Large Margin Structured Convolution Operator for Thermal Infrared Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/88b29bfc7329854a5ffc1adb355b7bdde7fa3a0c\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00622\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.03544\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2019.01021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0181eb5f6f94df18586fea79d6ad37e583ff6f0c\",\"title\":\"A Structured Model for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/0181eb5f6f94df18586fea79d6ad37e583ff6f0c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"2003.08429\",\"authors\":[{\"authorId\":\"3488419\",\"name\":\"Ali Athar\"},{\"authorId\":\"46196169\",\"name\":\"S. Mahadevan\"},{\"authorId\":\"3331304\",\"name\":\"Aljosa Osep\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":\"10.1007/978-3-030-58621-8_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"17b349dd34e93e6744c7f316f0cb45a1e2a8729d\",\"title\":\"STEm-Seg: Spatio-temporal Embeddings for Instance Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/17b349dd34e93e6744c7f316f0cb45a1e2a8729d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1804.01824\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2019.102886\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a427fc1fde8206136075785eda3d757278adfb44\",\"title\":\"Guess Where? Actor-Supervision for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a427fc1fde8206136075785eda3d757278adfb44\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403961741\",\"name\":\"Nour El-Din El-Madany\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"},{\"authorId\":\"49210768\",\"name\":\"Ling Guan\"}],\"doi\":\"10.1109/ICIP.2017.8296807\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e40dd69ebc0a41e5a07835f3c3fa67e702183f8\",\"title\":\"Human action recognition by fusing deep features with Globality Locality Preserving Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/2e40dd69ebc0a41e5a07835f3c3fa67e702183f8\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.06764\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad969a415f126c8ca6597038c4c1ed8ffff01029\",\"title\":\"Efficient Convolutional Neural Network with Binary Quantization Layer\",\"url\":\"https://www.semanticscholar.org/paper/ad969a415f126c8ca6597038c4c1ed8ffff01029\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1016/j.neucom.2016.08.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b04aa6b89670dc078915adf16c524a1187353453\",\"title\":\"A novel mid-level distinctive feature learning for action recognition via diffusion map\",\"url\":\"https://www.semanticscholar.org/paper/b04aa6b89670dc078915adf16c524a1187353453\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-59126-1_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"81ede08b36f3abd423424804da8ff240606b3a5d\",\"title\":\"Top-Down Deep Appearance Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/81ede08b36f3abd423424804da8ff240606b3a5d\",\"venue\":\"SCIA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145738619\",\"name\":\"T. T. Pham\"},{\"authorId\":\"27174491\",\"name\":\"Dinh-Duc Nguyen\"},{\"authorId\":\"1556707881\",\"name\":\"Ba Hoang Phuc Ta\"},{\"authorId\":\"47523619\",\"name\":\"Thuy-Binh Nguyen\"},{\"authorId\":\"40407063\",\"name\":\"Thi-Ngoc-Diep Do\"},{\"authorId\":\"10128454\",\"name\":\"Thi-Lan Le\"}],\"doi\":\"10.1007/978-981-15-3380-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91cfd7a150609e086a85f88ad19010b8990335a2\",\"title\":\"Person Search by Queried Description in Vietnamese Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/91cfd7a150609e086a85f88ad19010b8990335a2\",\"venue\":\"ACIIDS\",\"year\":2020},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1511.02917\",\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"116230588\",\"name\":\"A. N. Gorban\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.332\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"195df1106f4d7aff0e9cb609358abbf80f54a716\",\"title\":\"Detecting Events and Key Actors in Multi-person Videos\",\"url\":\"https://www.semanticscholar.org/paper/195df1106f4d7aff0e9cb609358abbf80f54a716\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1607.06972\",\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"144624889\",\"name\":\"Zhiyuan Shi\"},{\"authorId\":\"36064037\",\"name\":\"M. Kawade\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.5244/C.31.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72ccbde258d00f81386675a170d63ac52b47791\",\"title\":\"Kinematic-Layout-aware Random Forests for Depth-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c72ccbde258d00f81386675a170d63ac52b47791\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1802.09745\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Li\"},{\"authorId\":\"144811861\",\"name\":\"M. Chuah\"}],\"doi\":\"10.1109/WACV.2018.00046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"162148b5dcabd9354a722ad75e5390596f3ae4c3\",\"title\":\"ReHAR: Robust and Efficient Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/162148b5dcabd9354a722ad75e5390596f3ae4c3\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1906.02549\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/P19-1183\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"title\":\"Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.472\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2009.14635\",\"authors\":[{\"authorId\":\"2146623\",\"name\":\"Kourosh Meshgi\"},{\"authorId\":\"31095396\",\"name\":\"Maryam Sadat Mirzaei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"910a5ed98d7ac0a5015474d6a4c9cfd8d64ab4af\",\"title\":\"Adversarial Semi-Supervised Multi-Domain Tracking\",\"url\":\"https://www.semanticscholar.org/paper/910a5ed98d7ac0a5015474d6a4c9cfd8d64ab4af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404403\",\"name\":\"Longteng Kong\"},{\"authorId\":\"145022824\",\"name\":\"D. Huang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2893318\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef022983983d8b948ab27a686da4e76cf92d18b1\",\"title\":\"A Joint Framework for Athlete Tracking and Action Recognition in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ef022983983d8b948ab27a686da4e76cf92d18b1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2376695\",\"name\":\"Annapurna P. Patil\"},{\"authorId\":\"1390000527\",\"name\":\"A. Srinath\"},{\"authorId\":\"1389892592\",\"name\":\"Atif Adib\"},{\"authorId\":\"40928888\",\"name\":\"Dimple Doshi\"},{\"authorId\":\"40928160\",\"name\":\"Darshan Dalsaniya\"}],\"doi\":\"10.1109/ICACCP.2019.8882987\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da93b22cfcb35d242351670ca3f68974db83769d\",\"title\":\"Scalable Activity Recognition Framework using Ensemble Models\",\"url\":\"https://www.semanticscholar.org/paper/da93b22cfcb35d242351670ca3f68974db83769d\",\"venue\":\"2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31092565\",\"name\":\"Talha Ali Khan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9df23768db7b6f68adb4441a3d50070649cc6a03\",\"title\":\"Masters Thesis: Multi-frame deep learning models for action detection in surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/9df23768db7b6f68adb4441a3d50070649cc6a03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8161428\",\"name\":\"Susanna Gladh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebf204e0a3e137b6c24e271b0d55fa49a6c52b41\",\"title\":\"Visual Tracking Using Deep Motion Features\",\"url\":\"https://www.semanticscholar.org/paper/ebf204e0a3e137b6c24e271b0d55fa49a6c52b41\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1505.01197\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"title\":\"Contextual Action Recognition with R*CNN\",\"url\":\"https://www.semanticscholar.org/paper/1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49029424\",\"name\":\"K. Krishnan\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/SPCOM.2016.7746614\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bf56072760c1264956de70c3eb079245fe8ad34\",\"title\":\"ARRNET: Action recognition through recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9bf56072760c1264956de70c3eb079245fe8ad34\",\"venue\":\"2016 International Conference on Signal Processing and Communications (SPCOM)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711125\",\"name\":\"M. Pobar\"},{\"authorId\":\"1409933182\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.3390/s20051475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e651f496621ded0585386125ce5be4b9580af67\",\"title\":\"Active Player Detection in Handball Scenes Based on Activity Measures\",\"url\":\"https://www.semanticscholar.org/paper/2e651f496621ded0585386125ce5be4b9580af67\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2016.167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"title\":\"3D Action Recognition from Novel Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/0d6f20680b33ffcc4d83a01dc908df5cb856eb9b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1512.01848\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/TPAMI.2016.2558148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4defba71c686946351f5e7a090c7aa8136d32f\",\"title\":\"Rank Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4defba71c686946351f5e7a090c7aa8136d32f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"9637828\",\"name\":\"Junho Jin\"},{\"authorId\":\"144396280\",\"name\":\"Yongjin Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"144341935\",\"name\":\"K. Park\"}],\"doi\":\"10.4218/ETRIJ.17.0116.0054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58c692a2ac35d4beab97836c4c95881d52beb61\",\"title\":\"Extensible Hierarchical Method of Detecting Interactive Actions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e58c692a2ac35d4beab97836c4c95881d52beb61\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1604.07602\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/978-3-319-46454-1_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ea1e828256feee129eae3497f41e21bce36a34\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/b1ea1e828256feee129eae3497f41e21bce36a34\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1109/ICPR.2016.7899945\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6db7e4db648e8a9550d802ab6e3cbb7ac708a021\",\"title\":\"Building semantic understanding beyond deep learning from sound and vision\",\"url\":\"https://www.semanticscholar.org/paper/6db7e4db648e8a9550d802ab6e3cbb7ac708a021\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"title\":\"Image-set, Temporal and Spatiotemporal Representations of Videos for Recognizing, Localizing and Quantifying Actions\",\"url\":\"https://www.semanticscholar.org/paper/c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.00180\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2683916\",\"name\":\"Lizhi Yang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"title\":\"Spatio-Temporal Action Detection with Multi-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"22314707\",\"name\":\"Ekta U. Samani\"},{\"authorId\":\"49085454\",\"name\":\"R. Hendrix\"},{\"authorId\":\"40088150\",\"name\":\"Cameron Devine\"},{\"authorId\":\"46529550\",\"name\":\"S. Singh\"},{\"authorId\":\"1840866\",\"name\":\"S. Devasia\"},{\"authorId\":\"145026397\",\"name\":\"Ashis G. Banerjee\"}],\"doi\":\"10.1109/LRA.2019.2925305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25d54a74eaf7ed90f98acebff6c817f28f51f6ee\",\"title\":\"Toward Ergonomic Risk Prediction via Segmentation of Indoor Object Manipulation Actions Using Spatiotemporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/25d54a74eaf7ed90f98acebff6c817f28f51f6ee\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":\"2007.00046\",\"authors\":[{\"authorId\":\"31274862\",\"name\":\"A. Hafiz\"},{\"authorId\":\"22261301\",\"name\":\"G. M. Bhat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9228c2f14c3bd27da5a89806cc89f1c469e4506\",\"title\":\"Fast Training of Deep Networks with One-Class CNNs\",\"url\":\"https://www.semanticscholar.org/paper/e9228c2f14c3bd27da5a89806cc89f1c469e4506\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12649937\",\"name\":\"Y. Chen\"},{\"authorId\":\"2069934\",\"name\":\"Shyi-Chyi Cheng\"},{\"authorId\":\"35493143\",\"name\":\"Chen-Kuai Yang\"}],\"doi\":\"10.1109/ISCIT.2017.8261171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f92224e019ee35ceeaa8fbd5eaf9fc1a0361bef9\",\"title\":\"Unsupervised learning of space-time symmetric patterns in RGB-D videos for 4D human activity detection\",\"url\":\"https://www.semanticscholar.org/paper/f92224e019ee35ceeaa8fbd5eaf9fc1a0361bef9\",\"venue\":\"2017 17th International Symposium on Communications and Information Technologies (ISCIT)\",\"year\":2017},{\"arxivId\":\"1905.11575\",\"authors\":[{\"authorId\":\"144045444\",\"name\":\"R. Su\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"6578587\",\"name\":\"L. Zhou\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1109/CVPR.2019.01229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d445c883a396501acf3b5f2cd7680b2b953903\",\"title\":\"Improving Action Localization by Progressive Cross-Stream Cooperation\",\"url\":\"https://www.semanticscholar.org/paper/c3d445c883a396501acf3b5f2cd7680b2b953903\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1802.00421\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4ebf0a4f48275ecd8dbc2840b2a31cc07bd676d\",\"title\":\"A Fusion of Appearance based CNNs and Temporal evolution of Skeleton with LSTM for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4ebf0a4f48275ecd8dbc2840b2a31cc07bd676d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803285\",\"name\":\"Tianci Liu\"},{\"authorId\":\"2172914\",\"name\":\"Z. Shi\"},{\"authorId\":\"2556853\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/LSP.2018.2829106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11bb2abe0ca614c15701961428eb2f260e3e2eef\",\"title\":\"Joint Normalization and Dimensionality Reduction on Grassmannian: A Generalized Perspective\",\"url\":\"https://www.semanticscholar.org/paper/11bb2abe0ca614c15701961428eb2f260e3e2eef\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3257750\",\"name\":\"Christos Varytimidis\"},{\"authorId\":\"97748801\",\"name\":\"Kostas Rapantzikos\"},{\"authorId\":\"2218076\",\"name\":\"C. Loukas\"},{\"authorId\":\"1707243\",\"name\":\"S. Kollias\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"542066b0fb6d020eef7ea5e867cececbda5d3c9e\",\"title\":\"Surgical video retrieval using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/542066b0fb6d020eef7ea5e867cececbda5d3c9e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"896b764cff4d71f917c485593ef78d2f1ed7124d\",\"title\":\"Online, Supervised and Unsupervised Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/896b764cff4d71f917c485593ef78d2f1ed7124d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9297383\",\"name\":\"Rana Elnaggar\"},{\"authorId\":\"145359879\",\"name\":\"M. Khalil\"},{\"authorId\":\"2173290\",\"name\":\"H. Abdelmunim\"},{\"authorId\":\"1706882\",\"name\":\"H. Abbas\"}],\"doi\":\"10.1109/ICCES.2015.7393079\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8855879fbe36aba24d6d95e1e71e441cd61a4ffa\",\"title\":\"Optical flow-based enhancement of spatio-temporal detection in videos\",\"url\":\"https://www.semanticscholar.org/paper/8855879fbe36aba24d6d95e1e71e441cd61a4ffa\",\"venue\":\"2015 Tenth International Conference on Computer Engineering & Systems (ICCES)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67054241\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"51394016\",\"name\":\"Guillermo Camara Chavez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a295c14cb9b00eff47438c77a2ff1062998fc214\",\"title\":\"Multimodal Human Action Recognition Based on a Fusion of Dynamic Images Using CNN Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/a295c14cb9b00eff47438c77a2ff1062998fc214\",\"venue\":\"2018 31st SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2018},{\"arxivId\":\"1707.00823\",\"authors\":[{\"authorId\":\"79993273\",\"name\":\"Jian Liu\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/s11263-019-01192-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57ba391f7462d2f6b7957d30682670c7f833009d\",\"title\":\"Learning Human Pose Models from Synthesized Data for Robust RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57ba391f7462d2f6b7957d30682670c7f833009d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1908.10546\",\"authors\":[{\"authorId\":\"49340538\",\"name\":\"Bowen Shi\"},{\"authorId\":\"51518798\",\"name\":\"Aurora Martinez Del Rio\"},{\"authorId\":\"7185426\",\"name\":\"J. Keane\"},{\"authorId\":\"48718348\",\"name\":\"Diane Brentari\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/ICCV.2019.00550\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e112053a93beba08a998d71ba7e27620c43a0d4\",\"title\":\"Fingerspelling Recognition in the Wild With Iterative Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/0e112053a93beba08a998d71ba7e27620c43a0d4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.3390/drones3040082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5804fb20edd6df75f0d47782ffa1cd4ecf7252f0\",\"title\":\"Drone-Action: An Outdoor Recorded Drone Video Dataset for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5804fb20edd6df75f0d47782ffa1cd4ecf7252f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.01194\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/WACV.2017.27\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"cdd828917bfafd1b7d876f48abeae094d2ba3bcf\",\"title\":\"Two Stream LSTM: A Deep Fusion Framework for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdd828917bfafd1b7d876f48abeae094d2ba3bcf\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"48211108\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/TIP.2018.2818328\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3a68a1a76ebc94a3db66d0c3fd450d0e78fe609\",\"title\":\"Spatio-Temporal Attention-Based LSTM Networks for 3D Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/b3a68a1a76ebc94a3db66d0c3fd450d0e78fe609\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16077215\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"48570960\",\"name\":\"Lining Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2836323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef9280d59388c359abb1127297db2b255cceadf\",\"title\":\"Arbitrary view action recognition via transfer dictionary learning on synthetic training data\",\"url\":\"https://www.semanticscholar.org/paper/6ef9280d59388c359abb1127297db2b255cceadf\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961634\",\"name\":\"Yutang Wu\"},{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"47672901\",\"name\":\"Shuheng Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054394\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"886653a4a10986596d39c45711f6f1f49b9d4e70\",\"title\":\"Enhanced Action Tubelet Detector for Spatio-Temporal Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/886653a4a10986596d39c45711f6f1f49b9d4e70\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"10376365\",\"name\":\"Sourabh Kulhare\"},{\"authorId\":\"116409536\",\"name\":\"A. Gray\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1401154472\",\"name\":\"Emily Tucker Prud'hommeaux\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/WACV.2017.115\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9aea006e80cf215b72693860c3234b61006c911\",\"title\":\"Semantic Text Summarization of Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9aea006e80cf215b72693860c3234b61006c911\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1911.04469\",\"authors\":[{\"authorId\":\"48212782\",\"name\":\"A. Hammam\"},{\"authorId\":\"1782978\",\"name\":\"M. Soliman\"},{\"authorId\":\"1697259\",\"name\":\"A. Hassanien\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fe6f034179cfe95317abf579d8b7f0b5bfd328e\",\"title\":\"A Proposed Artificial intelligence Model for Real-Time Human Action Localization and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/7fe6f034179cfe95317abf579d8b7f0b5bfd328e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.09003\",\"authors\":[{\"authorId\":\"2280644\",\"name\":\"Aiden Nibali\"},{\"authorId\":\"1787185\",\"name\":\"Z. He\"},{\"authorId\":\"31548192\",\"name\":\"S. Morgan\"},{\"authorId\":\"144172685\",\"name\":\"Daniel Greenwood\"}],\"doi\":\"10.1109/CVPRW.2017.18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5a64aee4a5c672cb4f93f4464b9ddb21cbaf0f2\",\"title\":\"Extraction and Classification of Diving Clips from Continuous Video Footage\",\"url\":\"https://www.semanticscholar.org/paper/a5a64aee4a5c672cb4f93f4464b9ddb21cbaf0f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001513508\",\"name\":\"Takashi Hosono\"},{\"authorId\":\"97711590\",\"name\":\"Kiyohito Sawada\"},{\"authorId\":\"2000311125\",\"name\":\"Yongqing Sun\"},{\"authorId\":\"40048288\",\"name\":\"K. Hayase\"},{\"authorId\":\"145475360\",\"name\":\"J. Shimamura\"}],\"doi\":\"10.1109/ICIP40778.2020.9190884\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9218999067514016dee35fecdbd9dc588462ea9\",\"title\":\"Activity Normalization for Activity Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/a9218999067514016dee35fecdbd9dc588462ea9\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1905.08685\",\"authors\":[{\"authorId\":\"1409877474\",\"name\":\"Jen-Yen Chang\"},{\"authorId\":\"1399435786\",\"name\":\"Antonio Tejero-de-Pablos\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICRA.2019.8793825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf61b3eb9679182f50b61a4ab4373e893898bf9\",\"title\":\"Improved Optical Flow for Gesture-based Human-robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/1cf61b3eb9679182f50b61a4ab4373e893898bf9\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2041359638\",\"name\":\"Jaekyum Kim\"},{\"authorId\":\"144085626\",\"name\":\"J. Koh\"},{\"authorId\":\"1789522\",\"name\":\"J. W. Choi\"}],\"doi\":\"10.1109/ICTC49870.2020.9289386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c72388c9ac73fabd016bc775e3ab5c01036ed589\",\"title\":\"Video Object Detection Using Motion Context and Feature Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/c72388c9ac73fabd016bc775e3ab5c01036ed589\",\"venue\":\"2020 International Conference on Information and Communication Technology Convergence (ICTC)\",\"year\":2020},{\"arxivId\":\"2011.13399\",\"authors\":[{\"authorId\":\"151136071\",\"name\":\"Mattia Segu\"},{\"authorId\":\"1781788981\",\"name\":\"Federico Pirovano\"},{\"authorId\":\"2029237675\",\"name\":\"Gianmario Fumagalli\"},{\"authorId\":\"1557389943\",\"name\":\"Amedeo Fabris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"title\":\"Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal Heatmaps\",\"url\":\"https://www.semanticscholar.org/paper/ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2016.290\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"68bd9fa880a368b82782f617deefbde9552cac28\",\"title\":\"Predicting the Where and What of Actors and Actions through Online Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/68bd9fa880a368b82782f617deefbde9552cac28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TCSVT.2018.2887283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"title\":\"CNN-Based Multiple Path Search for Action Tube Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1707.09143\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.5244/C.31.22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31729722\",\"name\":\"Kento Masui\"},{\"authorId\":\"3356451\",\"name\":\"A. Ochiai\"},{\"authorId\":\"2405577\",\"name\":\"S. Yoshizawa\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.1109/ISM.2017.20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75bf811670e6aa344f1cb360d43cd6ba10919ad4\",\"title\":\"Recurrent Visual Relationship Recognition with Triplet Unit\",\"url\":\"https://www.semanticscholar.org/paper/75bf811670e6aa344f1cb360d43cd6ba10919ad4\",\"venue\":\"2017 IEEE International Symposium on Multimedia (ISM)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28108620\",\"name\":\"Eli Chen\"},{\"authorId\":\"1904028\",\"name\":\"Oren Haik\"},{\"authorId\":\"1779830\",\"name\":\"Yitzhak Yitzhaky\"}],\"doi\":\"10.1117/12.2534670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"934265518e2f3a15698132a997b8266e1f7f1f84\",\"title\":\"Action localization and classification in long-distance surveillance\",\"url\":\"https://www.semanticscholar.org/paper/934265518e2f3a15698132a997b8266e1f7f1f84\",\"venue\":\"Security + Defence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01252-6_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9258ae3ad05e77555d3459dfbcfa9c70440c5f88\",\"title\":\"What Do I Annotate Next? An Empirical Study of Active Learning for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/9258ae3ad05e77555d3459dfbcfa9c70440c5f88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.02602\",\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"153339954\",\"name\":\"J. Chahl\"}],\"doi\":\"10.1007/978-3-030-11012-3_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98e03938bea024eadf96dae49b98b026f7c72b0\",\"title\":\"UAV-GESTURE: A Dataset for UAV Control and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b98e03938bea024eadf96dae49b98b026f7c72b0\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150965117\",\"name\":\"Daniel Alejandro Castro Chin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"title\":\"Understanding The Motion of A Human State In Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772962\",\"name\":\"Emre Dogan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc5c9f5528b873bc53a33c33e79352787d60acab\",\"title\":\"Human pose estimation and action recognition by multi-robot systems\",\"url\":\"https://www.semanticscholar.org/paper/dc5c9f5528b873bc53a33c33e79352787d60acab\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9393888\",\"name\":\"Qingtian Wu\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":\"143959713\",\"name\":\"Yimin Zhou\"},{\"authorId\":null,\"name\":\"Nannan Li\"}],\"doi\":\"10.1109/ICIP.2017.8296903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b534f6ceeb1b4553718a158d9a90c43751a64f72\",\"title\":\"Fast action localization based on spatio-temporal path search\",\"url\":\"https://www.semanticscholar.org/paper/b534f6ceeb1b4553718a158d9a90c43751a64f72\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"153585940\",\"name\":\"Hang Gao\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCVW.2019.00288\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3be602c7c3812397a29c64e544981a362de80f27\",\"title\":\"Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/3be602c7c3812397a29c64e544981a362de80f27\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414148\",\"name\":\"Jingtian Zhang\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2836323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecc2e1284f1cb19cafe723b25be3705f26609679\",\"title\":\"Action Recognition From Arbitrary Views Using Transferable Dictionary Learning\",\"url\":\"https://www.semanticscholar.org/paper/ecc2e1284f1cb19cafe723b25be3705f26609679\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2430872\",\"name\":\"Ming-Xin Jiang\"},{\"authorId\":\"144551292\",\"name\":\"C. Deng\"},{\"authorId\":\"48985254\",\"name\":\"Ming-min Zhang\"},{\"authorId\":\"66379624\",\"name\":\"Jing-song Shan\"},{\"authorId\":\"40259910\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1155/2018/5676095\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4b2a4449e9c6dbd50d9ebd8525991e395ff079\",\"title\":\"Multimodal Deep Feature Fusion (MMDFF) for RGB-D Tracking\",\"url\":\"https://www.semanticscholar.org/paper/9f4b2a4449e9c6dbd50d9ebd8525991e395ff079\",\"venue\":\"Complex.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1007/978-3-319-75193-1_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fad604ab6c0f7b9047e92e114004b63a990d6f3e\",\"title\":\"Fusion of Deep Learning Descriptors for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fad604ab6c0f7b9047e92e114004b63a990d6f3e\",\"venue\":\"CIARP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"143629371\",\"name\":\"L. Song\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2019.2959425\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8006397de84196e07ee4b520100940f2fd46483\",\"title\":\"GLNet: Global Local Network for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b8006397de84196e07ee4b520100940f2fd46483\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1511.04891\",\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"145907577\",\"name\":\"W. Chang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1aead75afc2fe709b80d6416488ccd157a2a079\",\"title\":\"Sherlock: Scalable Fact Learning in Images\",\"url\":\"https://www.semanticscholar.org/paper/c1aead75afc2fe709b80d6416488ccd157a2a079\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"title\":\"Learning to Recognize Actions with Weak Supervision. (Reconnaissance d'actions de mani\\u00e8re faiblement supervis\\u00e9e)\",\"url\":\"https://www.semanticscholar.org/paper/d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138115\",\"name\":\"F. Negin\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.3390/s19194237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"title\":\"An Unsupervised Framework for Online Spatiotemporal Detection of Activities of Daily Living by Hierarchical Activity Models\",\"url\":\"https://www.semanticscholar.org/paper/4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1803.11556\",\"authors\":[{\"authorId\":\"10805888\",\"name\":\"Zhongzheng Ren\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/978-3-030-01246-5_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211\",\"title\":\"Learning to Anonymize Faces for Privacy Preserving Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.12248\",\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.12.019\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac360c948a81738b892869fafe950e05cf477618\",\"title\":\"Discovering Spatio-Temporal Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/ac360c948a81738b892869fafe950e05cf477618\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.06644\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"50652944\",\"name\":\"Xiangyu Wei\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"title\":\"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1504.07469\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":\"10.1109/WACV.2016.7477708\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6f2b075d527e7d3b29219e5955f294f539c4764f\",\"title\":\"Compact CNN for indexing egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6f2b075d527e7d3b29219e5955f294f539c4764f\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549298\",\"name\":\"J. Li\"},{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"}],\"doi\":\"10.1109/ICME.2017.8019535\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2606d7b1351af521aa43a99e3765e648f32233ed\",\"title\":\"Learning to generate video object segment proposals\",\"url\":\"https://www.semanticscholar.org/paper/2606d7b1351af521aa43a99e3765e648f32233ed\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"1390631689\",\"name\":\"Shan Liu\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/TCSVT.2019.2923712\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71780727bad491d006a97ee365c08ea616b707c3\",\"title\":\"Spatial\\u2013Temporal Context-Aware Online Action Detection and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/71780727bad491d006a97ee365c08ea616b707c3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1811.07157\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"title\":\"Recurrence to the Rescue: Towards Causal Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.11421\",\"authors\":[{\"authorId\":\"2794289\",\"name\":\"Z. Jiang\"},{\"authorId\":\"4397101\",\"name\":\"P. Chazot\"},{\"authorId\":\"145214646\",\"name\":\"M. E. Celebi\"},{\"authorId\":\"143964618\",\"name\":\"D. Crookes\"},{\"authorId\":\"144725605\",\"name\":\"R. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2917000\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"be0f7e3b205c16c643aa77b7727b6a397c9c2682\",\"title\":\"Social Behavioral Phenotyping of Drosophila With a 2D\\u20133D Hybrid CNN Framework\",\"url\":\"https://www.semanticscholar.org/paper/be0f7e3b205c16c643aa77b7727b6a397c9c2682\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1604.06397\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2016.295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae7122103f0868995ea2b53695479af553ab1361\",\"title\":\"Improving Human Action Recognition by Non-action Classification\",\"url\":\"https://www.semanticscholar.org/paper/ae7122103f0868995ea2b53695479af553ab1361\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1909.03877\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.00043\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"title\":\"Gaussian Temporal Awareness Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267f3674d02ab3b53e0ac58e082380547b0bbf1c\",\"title\":\"Beyond Labels and Captions: Contextualizing Grounded Semantics for Explainable Visual Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/267f3674d02ab3b53e0ac58e082380547b0bbf1c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"8547960\",\"name\":\"Lijun Yu\"},{\"authorId\":\"72399893\",\"name\":\"Yijun Qian\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"1970583\",\"name\":\"Liangke Gui\"},{\"authorId\":\"32058482\",\"name\":\"Jing Wen\"},{\"authorId\":\"144675264\",\"name\":\"Peng Chen\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1109/WACVW50321.2020.9096929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"703015f87eb089a70e882af715a81fd100114bbd\",\"title\":\"Argus: Efficient Activity Detection System for Extended Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/703015f87eb089a70e882af715a81fd100114bbd\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"1706.04269\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d79e6077c47d6289ab89054f2b51653d887958\",\"title\":\"Action Search: Learning to Search for Human Activities in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c0d79e6077c47d6289ab89054f2b51653d887958\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"}],\"doi\":\"10.7282/T3QC05T7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"630bff5280f7195e999532c21c9efb13c7f937be\",\"title\":\"Language guided visual perception\",\"url\":\"https://www.semanticscholar.org/paper/630bff5280f7195e999532c21c9efb13c7f937be\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1704.07863\",\"authors\":[{\"authorId\":\"145848547\",\"name\":\"A. Romero\"},{\"authorId\":\"49648929\",\"name\":\"J. Le\\u00f3n\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"}],\"doi\":\"10.1016/J.IMAVIS.2018.09.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f618cbf19917ce5b8703adbc14e15b0bf0d35cc\",\"title\":\"Multi-View Dynamic Facial Action Unit Detection\",\"url\":\"https://www.semanticscholar.org/paper/4f618cbf19917ce5b8703adbc14e15b0bf0d35cc\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1511.04067\",\"authors\":[{\"authorId\":\"39963722\",\"name\":\"Raviteja Vemulapalli\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"}],\"doi\":\"10.1109/CVPR.2016.519\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f71bb02fe5fb2719e588f7cb275e6effd1bf4858\",\"title\":\"Deep Gaussian Conditional Random Field Network: A Model-Based Deep Network for Discriminative Denoising\",\"url\":\"https://www.semanticscholar.org/paper/f71bb02fe5fb2719e588f7cb275e6effd1bf4858\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1712.01111\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb8806e90aaa882ffc212864ae6d6e28c9092aa4\",\"title\":\"An End-to-end 3D Convolutional Neural Network for Action Detection and Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cb8806e90aaa882ffc212864ae6d6e28c9092aa4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46332770\",\"name\":\"M. Jiang\"},{\"authorId\":\"1752849\",\"name\":\"T. Aoyama\"},{\"authorId\":\"145091856\",\"name\":\"T. Takaki\"},{\"authorId\":\"1766560\",\"name\":\"I. Ishii\"}],\"doi\":\"10.3390/s16111842\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b72091b0398467bbe4280d78fea3d60c16d5331\",\"title\":\"Pixel-Level and Robust Vibration Source Sensing in High-Frame-Rate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7b72091b0398467bbe4280d78fea3d60c16d5331\",\"venue\":\"Sensors\",\"year\":2016},{\"arxivId\":\"1908.08178\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"48696416\",\"name\":\"Y. Cao\"},{\"authorId\":\"1761508\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803564\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"title\":\"Multi-Stream Single Shot Spatial-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"73365425\",\"name\":\"Y. Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCV.2019.00015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b76da17a060f1edb80b26f489f4b6256d785c57\",\"title\":\"Hierarchical Self-Attention Network for Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b76da17a060f1edb80b26f489f4b6256d785c57\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39948784\",\"name\":\"Jia-Hao Syu\"},{\"authorId\":\"1844181\",\"name\":\"Mu-En Wu\"},{\"authorId\":\"1459935354\",\"name\":\"Shin-Huah Lee\"},{\"authorId\":\"1786429\",\"name\":\"J. Ho\"}],\"doi\":\"10.1007/978-981-15-3380-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0c8efb5161451ef471542cde78b0dffe08dac3a\",\"title\":\"Intelligent Information and Database Systems: 12th Asian Conference, ACIIDS 2020, Phuket, Thailand, March 23\\u201326, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/b0c8efb5161451ef471542cde78b0dffe08dac3a\",\"venue\":\"ACIIDS\",\"year\":2020},{\"arxivId\":\"1606.02467\",\"authors\":[{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-49409-8_65\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6e633c9c41bc61358e9b742ac4585b4f66449d0\",\"title\":\"Point-Wise Mutual Information-Based Video Segmentation with High Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/e6e633c9c41bc61358e9b742ac4585b4f66449d0\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1708.00042\",\"authors\":[{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.95\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae6fc9fa6dba7a20567671b9f1b0815b343bc152\",\"title\":\"Spatio-Temporal Action Detection with Cascade Proposal and Location Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/ae6fc9fa6dba7a20567671b9f1b0815b343bc152\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1912.03538\",\"authors\":[{\"authorId\":\"31937047\",\"name\":\"Sara Beery\"},{\"authorId\":\"3490569\",\"name\":\"Guanhang Wu\"},{\"authorId\":\"40303375\",\"name\":\"V. Rathod\"},{\"authorId\":\"69423660\",\"name\":\"Ronny Votel\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.01309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ac36b31c7c4ea9dc8b1962ea80ed5f117430cee\",\"title\":\"Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/9ac36b31c7c4ea9dc8b1962ea80ed5f117430cee\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3265845.3265851\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"title\":\"Sports Video Captioning by Attentive Motion Representation based Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"venue\":\"MMSports@MM\",\"year\":2018},{\"arxivId\":\"1912.07148\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICCV.2019.00566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b4960bb3997105073779651a54255b2c129d3d6\",\"title\":\"Predicting the Future: A Jointly Learnt Model for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2b4960bb3997105073779651a54255b2c129d3d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"1740321\",\"name\":\"Jian Yu\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1016/j.neucom.2019.01.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f38d00417e5e6655caf8eeea224aaceffbe20606\",\"title\":\"Action recognition and localization with spatial and temporal contexts\",\"url\":\"https://www.semanticscholar.org/paper/f38d00417e5e6655caf8eeea224aaceffbe20606\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"2621738\",\"name\":\"Xuejian Rong\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1145/2911996.2912046\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c720c0da64d6e2e4e04cfa70216215bd33eade5\",\"title\":\"Region Trajectories for Video Semantic Concept Detection\",\"url\":\"https://www.semanticscholar.org/paper/1c720c0da64d6e2e4e04cfa70216215bd33eade5\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"2004.08352\",\"authors\":[{\"authorId\":\"49061635\",\"name\":\"V. Mehta\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"2556975\",\"name\":\"Sujata Pal\"},{\"authorId\":\"145123077\",\"name\":\"Shehroz Khan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52ab1e80d7a7a73d9cea73238c5f8d51e24fcf49\",\"title\":\"Motion and Region Aware Adversarial Learning for Fall Detection with Thermal Imaging\",\"url\":\"https://www.semanticscholar.org/paper/52ab1e80d7a7a73d9cea73238c5f8d51e24fcf49\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":1035098,\"doi\":\"10.1109/CVPR.2015.7298676\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":80,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.imavis.2009.11.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d984b580e02da76cd4d991953e6d430fadf3d578\",\"title\":\"A survey on vision-based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d984b580e02da76cd4d991953e6d430fadf3d578\",\"venue\":\"Image Vis. Comput.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a2ed19ac684022aa3186887cd4893484ab8f80c\",\"title\":\"The PASCAL visual object classes challenge 2006 (VOC2006) results\",\"url\":\"https://www.semanticscholar.org/paper/6a2ed19ac684022aa3186887cd4893484ab8f80c\",\"venue\":\"\",\"year\":2006},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"}],\"doi\":\"10.1109/ICCV.2007.4408988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"124d967683544973581f951ee93b3f7c069e3ced\",\"title\":\"A Biologically Inspired System for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/124d967683544973581f951ee93b3f7c069e3ced\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862000\",\"name\":\"A. Prest\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2012.175\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f930a56632a7e436a2b3d39f3383f0adcc54306\",\"title\":\"Explicit Modeling of Human-Object Interactions in Realistic Videos\",\"url\":\"https://www.semanticscholar.org/paper/0f930a56632a7e436a2b3d39f3383f0adcc54306\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-642-35749-7_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07fd302320449434f52fdfcf30feda50c0450909\",\"title\":\"Human Focused Action Localization in Video\",\"url\":\"https://www.semanticscholar.org/paper/07fd302320449434f52fdfcf30feda50c0450909\",\"venue\":\"ECCV Workshops\",\"year\":2010},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Berg\"},{\"authorId\":null,\"name\":\"S. Satheesh\"},{\"authorId\":null,\"name\":\"H. Su\"},{\"authorId\":null,\"name\":\"A. Khosla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ImageNet Large Scale Visual Recognition Competition 2012 ( ILSVRC 2012 )\",\"url\":\"\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1007/978-3-642-33709-3_60\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bef862006a045d846d716346b0d27d3ca6cbf21b\",\"title\":\"Dynamic Eye Movement Datasets and Learnt Saliency Models for Visual Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bef862006a045d846d716346b0d27d3ca6cbf21b\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145989594\",\"name\":\"M. Goodale\"},{\"authorId\":\"2471113\",\"name\":\"A. Milner\"}],\"doi\":\"10.1016/0166-2236(92)90344-8\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0a995afa8d3c114b2b431c4e2737777a0e051bff\",\"title\":\"Separate visual pathways for perception and action\",\"url\":\"https://www.semanticscholar.org/paper/0a995afa8d3c114b2b431c4e2737777a0e051bff\",\"venue\":\"Trends in Neurosciences\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2014.100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"title\":\"Action Localization with Tubelets from Motion\",\"url\":\"https://www.semanticscholar.org/paper/377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"},{\"authorId\":\"48509230\",\"name\":\"F. Marqu\\u00e9s\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83d1118c2b2995a3e0cf9b6159e4c59e85cabb7e\",\"title\":\"Multiscale Combinatorial Grouping\",\"url\":\"https://www.semanticscholar.org/paper/83d1118c2b2995a3e0cf9b6159e4c59e85cabb7e\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1756979\",\"name\":\"K. V. D. Sande\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1007/s11263-013-0620-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"38b6540ddd5beebffd05047c78183f7575559fb2\",\"title\":\"Selective Search for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/38b6540ddd5beebffd05047c78183f7575559fb2\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644066790\",\"name\":\"EveringhamMark\"},{\"authorId\":\"1644080676\",\"name\":\"M. EslamiS.\"},{\"authorId\":\"1644017278\",\"name\":\"GoolLuc\"},{\"authorId\":\"1644074763\",\"name\":\"K. WilliamsChristopher\"},{\"authorId\":\"1644080846\",\"name\":\"WinnJohn\"},{\"authorId\":\"1643953626\",\"name\":\"ZissermanAndrew\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"535995b77ae23f1a075d2e38be5b670e9c339290\",\"title\":\"The Pascal Visual Object Classes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/535995b77ae23f1a075d2e38be5b670e9c339290\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.1109/CVPR.2013.330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"title\":\"Better Exploiting Motion for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84362927\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"123108776\",\"name\":\"M.S. Ryoo\"}],\"doi\":\"10.1145/1922649.1922653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"title\":\"Human activity analysis: A review\",\"url\":\"https://www.semanticscholar.org/paper/56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"venue\":\"CSUR\",\"year\":2011},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49049934\",\"name\":\"J. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"title\":\"The PASCAL Visual Object Classes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1715959\",\"name\":\"Stefano Soatto\"}],\"doi\":\"10.1109/CVPR.2012.6247807\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a973c756b50869e918b1dd43f6add5dbcdc5f791\",\"title\":\"Discovering discriminative action parts from mid-level video representations\",\"url\":\"https://www.semanticscholar.org/paper/a973c756b50869e918b1dd43f6add5dbcdc5f791\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Klaser\"},{\"authorId\":null,\"name\":\"M. Marszalek\"},{\"authorId\":null,\"name\":\"C. Schmid\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Focused Action Localization in Video\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10602-1_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"title\":\"Video Action Detection with Relational Dynamic-Poselets\",\"url\":\"https://www.semanticscholar.org/paper/d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50170517\",\"name\":\"Moshe Blank\"},{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/ICCV.2005.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"title\":\"Actions as space-time shapes\",\"url\":\"https://www.semanticscholar.org/paper/1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCV.2011.6126472\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"title\":\"Discriminative figure-centric models for joint action localization and recognition\",\"url\":\"https://www.semanticscholar.org/paper/40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Dong\"},{\"authorId\":null,\"name\":\"R. Socher\"},{\"authorId\":null,\"name\":\"L.-J. Li\"},{\"authorId\":null,\"name\":\"K. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ImageNet Large Scale Visual Recognition Competition 2012 ( ILSVRC 2012 )\",\"url\":\"\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685089\",\"name\":\"Pedro F. Felzenszwalb\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/TPAMI.2009.167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e79272fe3d65197100eae8be9fec6469107969ae\",\"title\":\"Object Detection with Discriminatively Trained Part Based Models\",\"url\":\"https://www.semanticscholar.org/paper/e79272fe3d65197100eae8be9fec6469107969ae\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2219581\",\"name\":\"B. Boser\"},{\"authorId\":\"49869599\",\"name\":\"J. Denker\"},{\"authorId\":\"37274089\",\"name\":\"D. Henderson\"},{\"authorId\":\"32295804\",\"name\":\"R. Howard\"},{\"authorId\":\"34859193\",\"name\":\"W. Hubbard\"},{\"authorId\":\"2307573\",\"name\":\"L. Jackel\"}],\"doi\":\"10.1162/neco.1989.1.4.541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8e8f3c8d4418c8d62e306538c9c1292635e9d27\",\"title\":\"Backpropagation Applied to Handwritten Zip Code Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8e8f3c8d4418c8d62e306538c9c1292635e9d27\",\"venue\":\"Neural Computation\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8193421\",\"name\":\"Yicong Tian\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2013.341\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eea7842025dad6b4cf53445c161538536020b412\",\"title\":\"Spatiotemporal Deformable Part Models for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eea7842025dad6b4cf53445c161538536020b412\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Deng\"},{\"authorId\":null,\"name\":\"A. Berg\"},{\"authorId\":null,\"name\":\"S. Satheesh\"},{\"authorId\":null,\"name\":\"H. Su\"},{\"authorId\":null,\"name\":\"A. Khosla\"},{\"authorId\":null,\"name\":\"L. Fei- Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ImageNet Large Scale Visual Recognition Competition 2012 (ILSVRC2012). http://www.image-net.org/ challenges/LSVRC/2012\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Deng\"},{\"authorId\":null,\"name\":\"A Berg\"},{\"authorId\":null,\"name\":\"S Satheesh\"},{\"authorId\":null,\"name\":\"H Su\"},{\"authorId\":null,\"name\":\"A Khosla\"},{\"authorId\":null,\"name\":\"L Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ImageNet Large Scale Visual Recognition Competition 2012 (ILSVRC2012). http://www.image-net.org/ challenges\",\"url\":\"\",\"venue\":\"ImageNet Large Scale Visual Recognition Competition 2012 (ILSVRC2012). http://www.image-net.org/ challenges\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2003.1238420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"804d86dd7ab3498266922244e73a88c1add5a6ab\",\"title\":\"Recognizing action at a distance\",\"url\":\"https://www.semanticscholar.org/paper/804d86dd7ab3498266922244e73a88c1add5a6ab\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"2898850\",\"name\":\"R\\u00e9mi Ronfard\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"}],\"doi\":\"10.1016/j.cviu.2010.10.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"678b758cb1a057fd38d8e6808535f64686bfca71\",\"title\":\"A survey of vision-based methods for action representation, segmentation and recognition\",\"url\":\"https://www.semanticscholar.org/paper/678b758cb1a057fd38d8e6808535f64686bfca71\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2011},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644050191\",\"name\":\"G. LoweDavid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"venue\":\"\",\"year\":2004}],\"title\":\"Finding action tubes\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"},{\"topic\":\"Object detection\",\"topicId\":\"14349\",\"url\":\"https://www.semanticscholar.org/topic/14349\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Regular expression\",\"topicId\":\"48721\",\"url\":\"https://www.semanticscholar.org/topic/48721\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"}],\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"