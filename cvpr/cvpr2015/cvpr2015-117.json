"{\"abstract\":\"Saliency in Context (SALICON) is an ongoing effort that aims at understanding and predicting visual attention. This paper presents a new method to collect large-scale human data during natural explorations on images. While current datasets present a rich set of images and task-specific annotations such as category labels and object segments, this work focuses on recording and logging how humans shift their attention during visual exploration. The goal is to offer new possibilities to (1) complement task-specific annotations to advance the ultimate goal in visual understanding, and (2) understand visual attention and learn saliency models, all with human attentional data at a much larger scale. We designed a mouse-contingent multi-resolutional paradigm based on neurophysiological and psychophysical studies of peripheral vision, to simulate the natural viewing behavior of humans. The new paradigm allowed using a general-purpose mouse instead of an eye tracker to record viewing behaviors, thus enabling large-scale data collection. The paradigm was validated with controlled laboratory as well as large-scale online data. We report in this paper a proof-of-concept SALICON dataset of human \\u201cfree-viewing\\u201d data on 10,000 images from the Microsoft COCO (MS COCO) dataset with rich contextual information. We evaluated the use of the collected data in the context of saliency prediction, and demonstrated them a good source as ground truth for the evaluation of saliency algorithms.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\",\"url\":\"https://www.semanticscholar.org/author/144645142\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\",\"url\":\"https://www.semanticscholar.org/author/1961257\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\",\"url\":\"https://www.semanticscholar.org/author/2104164\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\",\"url\":\"https://www.semanticscholar.org/author/49033321\"}],\"citationVelocity\":80,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1429655276\",\"name\":\"Avishek Majumder\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"},{\"authorId\":\"1429640900\",\"name\":\"Anirban Chakraborty\"}],\"doi\":\"10.1007/s11042-019-08388-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcfb8263d4085e4b83fbbe998968eab5510953c\",\"title\":\"PerSeg : segmenting salient objects from bag of single image perturbations\",\"url\":\"https://www.semanticscholar.org/paper/dbcfb8263d4085e4b83fbbe998968eab5510953c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"46759203\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"}],\"doi\":\"10.24963/ijcai.2020/689\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"title\":\"Human Gaze Assisted Artificial Intelligence: A Review\",\"url\":\"https://www.semanticscholar.org/paper/97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"144785138\",\"name\":\"P. Li\"},{\"authorId\":\"145312326\",\"name\":\"Y. Han\"},{\"authorId\":\"145233508\",\"name\":\"Lei Wu\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"9315669\",\"name\":\"Weimin Wu\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e6b579a40169e2158858f75e36b1be54969cf4\",\"title\":\"Saliency prediction by Mahalanobis distance of topological feature on deep color components\",\"url\":\"https://www.semanticscholar.org/paper/d7e6b579a40169e2158858f75e36b1be54969cf4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380248807\",\"name\":\"Mona Abid\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/ICIP40778.2020.9191064\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"541e39d603f52341f867e00188037e6d8253bc9b\",\"title\":\"Towards Visual Saliency Computation on 3D Graphical Contents for Interactive Visualization\",\"url\":\"https://www.semanticscholar.org/paper/541e39d603f52341f867e00188037e6d8253bc9b\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2001.04568\",\"authors\":[{\"authorId\":\"34692827\",\"name\":\"Zhenqiang Ying\"},{\"authorId\":\"1747569\",\"name\":\"A. Bovik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c7c146e54a7f444b8deab11692eb33c94f2220\",\"title\":\"180-degree Outpainting from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/d2c7c146e54a7f444b8deab11692eb33c94f2220\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1968574\",\"name\":\"Sezer Karaoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a9dc8dee0c7fc7d0c8d3245e6b288a8f547ec18\",\"title\":\"Recognition and detection of objects using visual and textual cues\",\"url\":\"https://www.semanticscholar.org/paper/2a9dc8dee0c7fc7d0c8d3245e6b288a8f547ec18\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36264491\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"14898199\",\"name\":\"Cen Han\"},{\"authorId\":\"144499600\",\"name\":\"Kun Ma\"},{\"authorId\":\"14349261\",\"name\":\"C. Liu\"},{\"authorId\":\"145090773\",\"name\":\"Gangyi Ding\"},{\"authorId\":\"1754751\",\"name\":\"E. Liu\"}],\"doi\":\"10.1016/j.jvcir.2017.11.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7097289a40e740378f5973bee7e068151ef7597\",\"title\":\"Optimal feature combination analysis for crowd saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/a7097289a40e740378f5973bee7e068151ef7597\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2017.370\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"title\":\"Attentional Push: A Deep Convolutional Network for Augmenting Image Salience with Shared Attention Modeling in Social Scenes\",\"url\":\"https://www.semanticscholar.org/paper/9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47415361\",\"name\":\"Tao Deng\"},{\"authorId\":\"48506762\",\"name\":\"Hongmei Yan\"},{\"authorId\":\"40548435\",\"name\":\"L. Qin\"},{\"authorId\":\"40092548\",\"name\":\"Thuyen Ngo\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/TITS.2019.2915540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f612076edfc2959d2bab2bfa470654845bf84a5d\",\"title\":\"How Do Drivers Allocate Their Potential Attention? Driving Fixation Prediction via Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f612076edfc2959d2bab2bfa470654845bf84a5d\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"},{\"authorId\":\"46382323\",\"name\":\"Hao Li\"}],\"doi\":\"10.1109/ACCESS.2019.2915630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75405582ec7883539fd15ceedb999a569f77ce93\",\"title\":\"A Convolutional Encoder-Decoder Network With Skip Connections for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/75405582ec7883539fd15ceedb999a569f77ce93\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1805.08819\",\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"46242703\",\"name\":\"Dan Scheibler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.32470/CCN.2018.1113-0\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"title\":\"Global-and-local attention networks for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.02872\",\"authors\":[{\"authorId\":\"47192865\",\"name\":\"H. Kato\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"597123ebb110fa887a53dcf455fd63c5a8df1c70\",\"title\":\"Visual Language Modeling on CNN Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/597123ebb110fa887a53dcf455fd63c5a8df1c70\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152424508\",\"name\":\"M. Sarret\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d42a5e7c97db2c89f9c358c23685fc7375a7045\",\"title\":\"EgoMon Gaze and Video Dataset for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5d42a5e7c97db2c89f9c358c23685fc7375a7045\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2301300\",\"name\":\"Zhongping Cao\"},{\"authorId\":\"48737933\",\"name\":\"Guoli Wang\"},{\"authorId\":\"15357581\",\"name\":\"Xuemei Guo\"}],\"doi\":\"10.1007/978-3-030-31723-2_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41dfa78544e5186a74c6b6938e7513c4c50084de\",\"title\":\"Stage-by-Stage Based Design Paradigm of Two-Pathway Model for Gaze Following\",\"url\":\"https://www.semanticscholar.org/paper/41dfa78544e5186a74c6b6938e7513c4c50084de\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1708.08016\",\"authors\":[{\"authorId\":\"22239413\",\"name\":\"Viraj Mavani\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"},{\"authorId\":\"2573270\",\"name\":\"Krishna P. Miyapuram\"}],\"doi\":\"10.1109/ICCVW.2017.327\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2f2f0ad484d2697828419b08e26acbbbc7fe2af\",\"title\":\"Facial Expression Recognition Using Visual Saliency and Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/b2f2f0ad484d2697828419b08e26acbbbc7fe2af\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2002.11020\",\"authors\":[{\"authorId\":\"9113556\",\"name\":\"E. Aksoy\"},{\"authorId\":\"144502488\",\"name\":\"A. Yazici\"},{\"authorId\":\"28260984\",\"name\":\"Mahmut Kasap\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"51332a711c575934a3a28299290b69a80f8f060b\",\"title\":\"See, Attend and Brake: An Attention-based Saliency Map Prediction Model for End-to-End Driving\",\"url\":\"https://www.semanticscholar.org/paper/51332a711c575934a3a28299290b69a80f8f060b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120317507\",\"name\":\"Makhmudov Farrukh\"},{\"authorId\":\"152325076\",\"name\":\"H. Ge\"}],\"doi\":\"10.1109/ICIST.2019.8836755\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3d4c9b96e7ebe25b03d6478640b141dfd250d8a5\",\"title\":\"Saliency Detection in Images with Complex Background by End-to-End Sparse Maxout CNN\",\"url\":\"https://www.semanticscholar.org/paper/3d4c9b96e7ebe25b03d6478640b141dfd250d8a5\",\"venue\":\"2019 9th International Conference on Information Science and Technology (ICIST)\",\"year\":2019},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73919690\",\"name\":\"Nidhinandana Salian\"}],\"doi\":\"10.1007/978-981-13-2907-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2a0048e23a2e88768d155eac351443573cd4f5d\",\"title\":\"Visual Attention and Memory Augmented Activity Recognition and Behavioral Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b2a0048e23a2e88768d155eac351443573cd4f5d\",\"venue\":\"ATIS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8dc540300335e27773e2b5f16c481476448d5b83\",\"title\":\"An Integrated Model for Effective Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8dc540300335e27773e2b5f16c481476448d5b83\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"50708949\",\"name\":\"Mei Su\"},{\"authorId\":\"37777082\",\"name\":\"M. Schlesinger\"},{\"authorId\":\"47901325\",\"name\":\"J. Qin\"}],\"doi\":\"10.1109/TCDS.2017.2696439\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6546a9b48810edfb527e3af45cb5ee36f573cf5a\",\"title\":\"A Comparison Study of Saliency Models for Fixation Prediction on Infants and Adults\",\"url\":\"https://www.semanticscholar.org/paper/6546a9b48810edfb527e3af45cb5ee36f573cf5a\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14bfde3b760bc09d4c93f81dc029429fca734c48\",\"title\":\"DIDEC: The Dutch Image Description and Eye-tracking Corpus\",\"url\":\"https://www.semanticscholar.org/paper/14bfde3b760bc09d4c93f81dc029429fca734c48\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152130996\",\"name\":\"F. Dai\"},{\"authorId\":\"9227279\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"144888439\",\"name\":\"Hong-liang Li\"},{\"authorId\":\"145668003\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053888\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7161bd888c9bc449e825a2d17cfca8263720efe\",\"title\":\"Dilated Convolutional Neural Networks for Panoramic Image Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c7161bd888c9bc449e825a2d17cfca8263720efe\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1903.06754\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"2619658\",\"name\":\"Zhuode Liu\"},{\"authorId\":\"144190085\",\"name\":\"L. Guan\"},{\"authorId\":\"13800723\",\"name\":\"L. Zhang\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1609/AAAI.V34I04.6161\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9dea72f5a7ca7a6e928eb4dca3962c24df6ca50\",\"title\":\"Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d9dea72f5a7ca7a6e928eb4dca3962c24df6ca50\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2005.12073\",\"authors\":[{\"authorId\":\"1716202788\",\"name\":\"Mancas Matei\"},{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"98d6b0b58cfbf1caece6fa7f65d83d61b8168552\",\"title\":\"Visual Attention: Deep Rare Features\",\"url\":\"https://www.semanticscholar.org/paper/98d6b0b58cfbf1caece6fa7f65d83d61b8168552\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"title\":\"Attentive Models in Vision 3 Input Image Human Fixation Map Loss Function Final Convolutional Layers Learned Prior Low , Medium and High Level Features Predicted Saliency Map Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2019.2905607\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"title\":\"Inferring Salient Objects from Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865728407\",\"name\":\"Avishek Siris\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"1888880\",\"name\":\"G. Tam\"},{\"authorId\":\"1388037008\",\"name\":\"Xianghua Xie\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/cvpr42600.2020.01215\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"06348f0f10a9599fe4c9b18fb7a2a972c49ba806\",\"title\":\"Inferring Attention Shift Ranks of Objects for Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/06348f0f10a9599fe4c9b18fb7a2a972c49ba806\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2016.14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9037fd1a7c309921a058f3831145db2639105537\",\"title\":\"DR(eye)VE: A Dataset for Attention-Based Tasks with Applications to Autonomous and Assisted Driving\",\"url\":\"https://www.semanticscholar.org/paper/9037fd1a7c309921a058f3831145db2639105537\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48462171\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"49990648\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/CVPR.2019.00618\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"791fa4797683469f91b27940253c7725c9717f24\",\"title\":\"CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/791fa4797683469f91b27940253c7725c9717f24\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1512.01722\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"40117581\",\"name\":\"Mengyang Feng\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1167/16.14.18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d515a89e8235460dac3afe6eb32c358890813ecf\",\"title\":\"Vanishing point attracts gaze in free-viewing and visual search tasks\",\"url\":\"https://www.semanticscholar.org/paper/d515a89e8235460dac3afe6eb32c358890813ecf\",\"venue\":\"Journal of vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19223274\",\"name\":\"Erol Citak\"},{\"authorId\":\"51211514\",\"name\":\"Mustafa Furkan Eseoglu\"},{\"authorId\":\"51211295\",\"name\":\"I. Celik\"},{\"authorId\":\"51211832\",\"name\":\"Onur Disanli\"},{\"authorId\":\"2684370\",\"name\":\"Sezer Kutluk\"},{\"authorId\":\"2853710\",\"name\":\"N. Arica\"}],\"doi\":\"10.1109/SIU.2018.8404222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bc0c6af17dc133ed1bed11e49d7c71b2a8cce92\",\"title\":\"Automatically inserting ads into images\",\"url\":\"https://www.semanticscholar.org/paper/3bc0c6af17dc133ed1bed11e49d7c71b2a8cce92\",\"venue\":\"2018 26th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2494584\",\"name\":\"G. Dimas\"},{\"authorId\":\"1656259484\",\"name\":\"Dimitris E Diamantis\"},{\"authorId\":\"1656258878\",\"name\":\"P. Kalozoumis\"},{\"authorId\":\"46484755\",\"name\":\"Dimitris K. Iakovidis\"}],\"doi\":\"10.3390/s20082385\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e4a93ca7996f5faaeda5fb50b7fe12fd84a04cb\",\"title\":\"Uncertainty-Aware Visual Perception System for Outdoor Navigation of the Visually Challenged\",\"url\":\"https://www.semanticscholar.org/paper/4e4a93ca7996f5faaeda5fb50b7fe12fd84a04cb\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112355\",\"name\":\"Daniel S. Ferreira\"},{\"authorId\":\"2005560\",\"name\":\"G. Ramalho\"},{\"authorId\":\"89658165\",\"name\":\"D. Torres\"},{\"authorId\":\"143948090\",\"name\":\"A. H. G. Tobias\"},{\"authorId\":\"31434323\",\"name\":\"M. T. Rezende\"},{\"authorId\":\"145730933\",\"name\":\"F. Medeiros\"},{\"authorId\":\"49667365\",\"name\":\"Andrea G. C. Bianchi\"},{\"authorId\":\"143717689\",\"name\":\"C. Carneiro\"},{\"authorId\":\"1811543\",\"name\":\"D. Ushizima\"}],\"doi\":\"10.1016/j.cmpb.2019.105053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2a5e8b15e5efa4ad54db2c4c3d6767cea6f2fb\",\"title\":\"Saliency-driven system models for cell analysis with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/1a2a5e8b15e5efa4ad54db2c4c3d6767cea6f2fb\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145481136\",\"name\":\"M. Islam\"},{\"authorId\":\"2038094312\",\"name\":\"VS Vibashan\"},{\"authorId\":\"7528360\",\"name\":\"C. M. Lim\"},{\"authorId\":\"145095690\",\"name\":\"Hongliang Ren\"}],\"doi\":\"10.1016/j.media.2020.101837\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3813f8768adbbe89bb1b42b3454da4704e6f59c\",\"title\":\"ST-MTL: Spatio-Temporal multitask learning model to predict scanpath while tracking instruments in robotic surgery\",\"url\":\"https://www.semanticscholar.org/paper/e3813f8768adbbe89bb1b42b3454da4704e6f59c\",\"venue\":\"Medical Image Anal.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"1843875\",\"name\":\"V. Ferrera\"}],\"doi\":\"10.1007/978-1-4939-3435-5_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2415ccae19b4e0413e42b0a6b3ff87ac5750c665\",\"title\":\"How to Measure Attention\",\"url\":\"https://www.semanticscholar.org/paper/2415ccae19b4e0413e42b0a6b3ff87ac5750c665\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4c02e071432a9a986501b7317b524f216e87ec8\",\"title\":\"Visual saliency prediction using deep learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/b4c02e071432a9a986501b7317b524f216e87ec8\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/2858036.2858479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6384a0b3940a71c2abe2447d9180a1d075a1a189\",\"title\":\"Spatio-Temporal Modeling and Prediction of Visual Attention in Graphical User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/6384a0b3940a71c2abe2447d9180a1d075a1a189\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40257358\",\"name\":\"He Tang\"},{\"authorId\":\"2500502\",\"name\":\"Chuanbo Chen\"},{\"authorId\":\"31564288\",\"name\":\"Xiaobing Pei\"}],\"doi\":\"10.1109/LSP.2016.2617340\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f09e22ab4ff7dfdca3a3843a1c0bb28c38a3b71\",\"title\":\"Visual Saliency Detection via Sparse Residual and Outlier Detection\",\"url\":\"https://www.semanticscholar.org/paper/1f09e22ab4ff7dfdca3a3843a1c0bb28c38a3b71\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":\"1811.03736\",\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"title\":\"Semantic and Contrast-Aware Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48293098\",\"name\":\"G. M. Venkatesh\"},{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"72191633\",\"name\":\"A. F. Smeaton\"},{\"authorId\":\"121937587\",\"name\":\"Zhen Yang\"},{\"authorId\":\"145777795\",\"name\":\"S. Little\"}],\"doi\":\"10.1109/CBMI.2019.8877460\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa947bb53386556bf10d87aa762787a95f9e7632\",\"title\":\"Saliency Guided 2D-Object Annotation for Instrumented Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/aa947bb53386556bf10d87aa762787a95f9e7632\",\"venue\":\"2019 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21242765\",\"name\":\"Steven R. Gomez\"},{\"authorId\":\"2819751\",\"name\":\"Radu Jianu\"},{\"authorId\":\"2494284\",\"name\":\"Ryan P. Cabeen\"},{\"authorId\":\"143887795\",\"name\":\"H. Guo\"},{\"authorId\":\"145514676\",\"name\":\"D. Laidlaw\"}],\"doi\":\"10.1109/TVCG.2016.2532331\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"722cd92595c372ac3f27378166802429b9b87ff0\",\"title\":\"Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks\",\"url\":\"https://www.semanticscholar.org/paper/722cd92595c372ac3f27378166802429b9b87ff0\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiao Li\"},{\"authorId\":\"7489463\",\"name\":\"Si-yi Wang\"},{\"authorId\":\"144469725\",\"name\":\"C. Zhu\"},{\"authorId\":\"144157729\",\"name\":\"L. Song\"},{\"authorId\":\"144509678\",\"name\":\"Rong Xie\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/BMSB47279.2019.8971933\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c512d2010a6de275cf7d36c6fee18eac6c45f758\",\"title\":\"Viewport Prediction for Panoramic Video with Multi-CNN\",\"url\":\"https://www.semanticscholar.org/paper/c512d2010a6de275cf7d36c6fee18eac6c45f758\",\"venue\":\"2019 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)\",\"year\":2019},{\"arxivId\":\"1504.06755\",\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"2507239\",\"name\":\"Y. Zhang\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"1697413\",\"name\":\"S. Kulkarni\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3433627f803953280b66ae1576d083fc9a68385a\",\"title\":\"TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking\",\"url\":\"https://www.semanticscholar.org/paper/3433627f803953280b66ae1576d083fc9a68385a\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25049311\",\"name\":\"R. Kumar\"},{\"authorId\":\"3423323\",\"name\":\"Jogendra Garain\"},{\"authorId\":\"1810015\",\"name\":\"Dakshina Ranjan Kisku\"},{\"authorId\":\"91464062\",\"name\":\"G. Sanyal\"}],\"doi\":\"10.1007/978-981-10-5520-1_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ce895477c573ed76bf5f77e24fc4a91ed6972db\",\"title\":\"Attending Prominent Face in the Set of Multiple Faces Through Relative Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/7ce895477c573ed76bf5f77e24fc4a91ed6972db\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34570209\",\"name\":\"Kshitij Dwivedi\"},{\"authorId\":\"145729589\",\"name\":\"Nitin Singh\"},{\"authorId\":\"1392783891\",\"name\":\"Sabari R. Shanmugham\"},{\"authorId\":\"153792660\",\"name\":\"M. Kumar\"}],\"doi\":\"10.1007/978-981-32-9291-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"title\":\"DeepAttent: Saliency Prediction with Deep Multi-scale Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":\"1902.06634\",\"authors\":[{\"authorId\":\"144373348\",\"name\":\"A. Kroner\"},{\"authorId\":\"2581474\",\"name\":\"Mario Senden\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"},{\"authorId\":\"145960031\",\"name\":\"R. Goebel\"}],\"doi\":\"10.1016/j.neunet.2020.05.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa6aac2143c713561603083a5f953c395ba2131\",\"title\":\"Contextual Encoder-Decoder Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4fa6aac2143c713561603083a5f953c395ba2131\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/CVPR.2019.00415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"title\":\"Emotion-Aware Human Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"Vittorio Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"Martial Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"30400079\",\"name\":\"Yair Weiss\"}],\"doi\":\"10.1007/978-3-030-01264-9\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5e47ada58f5b7817acc46240f1090ba51dd0c637\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/5e47ada58f5b7817acc46240f1090ba51dd0c637\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90357138\",\"name\":\"Marta Coll Pol\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"be0947fa430a3bf16436d20239550c39d1425d08\",\"title\":\"The importance of time in visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/be0947fa430a3bf16436d20239550c39d1425d08\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/TPAMI.2018.2840724\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"title\":\"A Deep Network Solution for Attention and Aesthetics Aware Photo Cropping\",\"url\":\"https://www.semanticscholar.org/paper/55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430029\",\"name\":\"Ishwarya Thirunarayanan\"},{\"authorId\":\"38562041\",\"name\":\"Khimya Khetarpal\"},{\"authorId\":\"2724462\",\"name\":\"S. Koppal\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"143741342\",\"name\":\"J. Shea\"},{\"authorId\":\"2617152\",\"name\":\"E. Jain\"}],\"doi\":\"10.1145/3078836\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88943c5373d8d3a7999313e809204dfd01bd4483\",\"title\":\"Creating Segments and Effects on Comics by Clustering Gaze Data\",\"url\":\"https://www.semanticscholar.org/paper/88943c5373d8d3a7999313e809204dfd01bd4483\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2017},{\"arxivId\":\"2012.11863\",\"authors\":[{\"authorId\":\"1739174065\",\"name\":\"Ke Wang\"},{\"authorId\":\"1400359889\",\"name\":\"Sai Ma\"},{\"authorId\":\"1740146246\",\"name\":\"Junlan Chen\"},{\"authorId\":\"49301701\",\"name\":\"Jianbo Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"title\":\"Salient Bundle Adjustment for Visual SLAM\",\"url\":\"https://www.semanticscholar.org/paper/4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380248807\",\"name\":\"Mona Abid\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/MMSP.2019.8901782\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"61bf1cebab0e8317a1b57233f9b06dc8aa276214\",\"title\":\"On the usage of visual saliency models for computer generated objects\",\"url\":\"https://www.semanticscholar.org/paper/61bf1cebab0e8317a1b57233f9b06dc8aa276214\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/CVPR.2019.01045\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145953640\",\"name\":\"Lin Qi\"},{\"authorId\":\"50125812\",\"name\":\"Y. Xu\"},{\"authorId\":\"30426887\",\"name\":\"Xiaowei Shang\"},{\"authorId\":\"1964397\",\"name\":\"J. Dong\"}],\"doi\":\"10.1109/CVPRW.2018.00263\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"27e41ebd2c1f570276838c02683e1cb30d12b095\",\"title\":\"Fusing Visual Saliency for Material Recognition\",\"url\":\"https://www.semanticscholar.org/paper/27e41ebd2c1f570276838c02683e1cb30d12b095\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"2001.04461\",\"authors\":[{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"144508258\",\"name\":\"B. McNamara\"},{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"7638730\",\"name\":\"Matthew Tancik\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1145/3313831.3376799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf10a7687378ce02dfdef60202bf86f6b4b88c46\",\"title\":\"TurkEyes: A Web-Based Toolbox for Crowdsourcing Attention Data\",\"url\":\"https://www.semanticscholar.org/paper/bf10a7687378ce02dfdef60202bf86f6b4b88c46\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/15.12.898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10cf966f0fea583f048e2321ca0e38b7f59f680e\",\"title\":\"Attention in Low Resolution: Learning Proto-Object Representations with a Deep Network.\",\"url\":\"https://www.semanticscholar.org/paper/10cf966f0fea583f048e2321ca0e38b7f59f680e\",\"venue\":\"Journal of vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144499600\",\"name\":\"Kun Ma\"},{\"authorId\":\"36264491\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"145090773\",\"name\":\"Gangyi Ding\"},{\"authorId\":\"14349261\",\"name\":\"C. Liu\"},{\"authorId\":\"1754751\",\"name\":\"E. Liu\"}],\"doi\":\"10.1109/WCSP.2016.7752552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b332661697566277edb68dd534d398b570ae8047\",\"title\":\"Crowd saliency prediction with optimal feature combinations\",\"url\":\"https://www.semanticscholar.org/paper/b332661697566277edb68dd534d398b570ae8047\",\"venue\":\"2016 8th International Conference on Wireless Communications & Signal Processing (WCSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"46286370\",\"name\":\"Yiwei Yang\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"title\":\"A Saliency Dataset of Head and Eye Movements for Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.03571\",\"authors\":[{\"authorId\":\"144545126\",\"name\":\"S. Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TMM.2019.2947352\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"023b11c04e5ea605fe999b015cbf62502cab068b\",\"title\":\"A Dilated Inception Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/023b11c04e5ea605fe999b015cbf62502cab068b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1709.06505\",\"authors\":[{\"authorId\":\"145030054\",\"name\":\"R. Monroy\"},{\"authorId\":\"32882525\",\"name\":\"S. Lutz\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1016/j.image.2018.05.005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"title\":\"SalNet360: Saliency Maps for omni-directional images with CNN\",\"url\":\"https://www.semanticscholar.org/paper/b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2018.00250\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"title\":\"SAM: Pushing the Limits of Saliency Prediction Models\",\"url\":\"https://www.semanticscholar.org/paper/cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"}],\"doi\":\"10.1016/j.patrec.2017.06.015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9acda127ca506e1b2a4641eab1bc14292b304c8\",\"title\":\"Saliency-guided Pairwise Matching\",\"url\":\"https://www.semanticscholar.org/paper/a9acda127ca506e1b2a4641eab1bc14292b304c8\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37447505\",\"name\":\"K. Guo\"},{\"authorId\":\"36358117\",\"name\":\"Danielle Pratt\"},{\"authorId\":\"145186935\",\"name\":\"A. MacDonald\"},{\"authorId\":\"31791248\",\"name\":\"Paul Schrater\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a0087276bc502e9d10579b7f708c31cd5f7c52a7\",\"title\":\"Labeling Images by Interpretation from Natural Viewing\",\"url\":\"https://www.semanticscholar.org/paper/a0087276bc502e9d10579b7f708c31cd5f7c52a7\",\"venue\":\"IUI Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71670265\",\"name\":\"Weiqian Liu\"},{\"authorId\":\"46674323\",\"name\":\"Yunfeng Sui\"},{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"145070239\",\"name\":\"Z. Cheng\"},{\"authorId\":\"47601467\",\"name\":\"Shixuan Zhao\"}],\"doi\":\"10.1109/ITNEC.2019.8729365\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b59fd61c89153802b6f4622f7b1b09e1b658ef63\",\"title\":\"Multiscope Contextual Information for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b59fd61c89153802b6f4622f7b1b09e1b658ef63\",\"venue\":\"2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3185668\",\"name\":\"Haoran Liang\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1145/3200767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df36f11cddb2cfd01cd062b53f10d206db752e5\",\"title\":\"CapVis: Toward Better Understanding of Visual-Verbal Saliency Consistency\",\"url\":\"https://www.semanticscholar.org/paper/4df36f11cddb2cfd01cd062b53f10d206db752e5\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2019},{\"arxivId\":\"2012.06170\",\"authors\":[{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"title\":\"AViNet: Diving Deep into Audio-Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1803.00127\",\"authors\":[{\"authorId\":\"3345547\",\"name\":\"Huai-Jen Liang\"},{\"authorId\":\"9217768\",\"name\":\"N. J. Sanket\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1109/TASE.2019.2900980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52e19729230252b7f77b20a644921949f755aa37\",\"title\":\"SalientDSO: Bringing Attention to Direct Sparse Odometry\",\"url\":\"https://www.semanticscholar.org/paper/52e19729230252b7f77b20a644921949f755aa37\",\"venue\":\"IEEE Transactions on Automation Science and Engineering\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2787873\",\"name\":\"Kai-Fu Yang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"2171904\",\"name\":\"Chao-Yi Li\"},{\"authorId\":\"6960951\",\"name\":\"Yong-Jie Li\"}],\"doi\":\"10.1109/TIP.2016.2572600\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6438cdd6d1ec30b58c47f45c5271f778f6173248\",\"title\":\"A Unified Framework for Salient Structure Detection by Contour-Guided Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/6438cdd6d1ec30b58c47f45c5271f778f6173248\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1711.10795\",\"authors\":[{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CBMI.2018.8516500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e303b9f18cf5096ed04d6d902321fa77e49dd74\",\"title\":\"Saliency Weighted Convolutional Features for Instance Search\",\"url\":\"https://www.semanticscholar.org/paper/9e303b9f18cf5096ed04d6d902321fa77e49dd74\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"1843875\",\"name\":\"V. Ferrera\"},{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"}],\"doi\":\"10.1007/978-1-4939-3435-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1f498b4e08181dc717cf229fccb74d276081a77\",\"title\":\"The Future of Attention Models: Information Seeking and Self-awareness\",\"url\":\"https://www.semanticscholar.org/paper/a1f498b4e08181dc717cf229fccb74d276081a77\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"70249755\",\"name\":\"Zachary Wharton\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"1522002795\",\"name\":\"Morteza Ghahremani\"},{\"authorId\":\"40578964\",\"name\":\"S. Kumar\"},{\"authorId\":\"2004428132\",\"name\":\"Nikolaos Bessis\"}],\"doi\":\"10.1109/taffc.2020.3031841\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d48d644758dd74fae7265bd0db13d73f98bf3b7a\",\"title\":\"Regional Attention Network (RAN) for Head Pose and Fine-grained Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d48d644758dd74fae7265bd0db13d73f98bf3b7a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51307429\",\"name\":\"Alena Selimovi\\u0107\"},{\"authorId\":\"51313054\",\"name\":\"Blaz Meden\"},{\"authorId\":\"34862665\",\"name\":\"P. Peer\"},{\"authorId\":\"32100962\",\"name\":\"Ale\\u0161 Hladnik\"}],\"doi\":\"10.1109/IWOBI.2018.8464188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e22e78419876dfe7e5ea5f587094f9e6a74729f9\",\"title\":\"Analysis of Content-Aware Image Compression with VGG16\",\"url\":\"https://www.semanticscholar.org/paper/e22e78419876dfe7e5ea5f587094f9e6a74729f9\",\"venue\":\"2018 IEEE International Work Conference on Bioinspired Intelligence (IWOBI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dan Shiebler Drew Linsley\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a23fe7786f969de21be8541e87259a4d0807a47\",\"title\":\"L EARNING WHAT AND WHERE TO ATTEND\",\"url\":\"https://www.semanticscholar.org/paper/8a23fe7786f969de21be8541e87259a4d0807a47\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.01231\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"23993939\",\"name\":\"Suiyi Ling\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"title\":\"Adversarial Attacks against Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.11603\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"145777800\",\"name\":\"S. Little\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"777c3ecbffeae2ef84ad400983f9270a1550ea54\",\"title\":\"MediaEval 2019: Concealed FGSM Perturbations for Privacy Preservation\",\"url\":\"https://www.semanticscholar.org/paper/777c3ecbffeae2ef84ad400983f9270a1550ea54\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":\"1803.05753\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ce33cd6c192f3226d52e59f5f26b2091727780f\",\"title\":\"What Catches the Eye? Visualizing and Understanding Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/4ce33cd6c192f3226d52e59f5f26b2091727780f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.01432\",\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"145140331\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"150344105\",\"name\":\"Xiaofu Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"title\":\"An End-to-End Neural Network for Image Cropping by Learning Composition from Aesthetic Photos\",\"url\":\"https://www.semanticscholar.org/paper/dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33610144\",\"name\":\"X. Chen\"},{\"authorId\":\"28964350\",\"name\":\"Anlin Zheng\"},{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"145053996\",\"name\":\"Feng Lu\"}],\"doi\":\"10.1109/ICCV.2017.119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42ab23233586d626d49b422ac8cc238a8e14bf8a\",\"title\":\"Look, Perceive and Segment: Finding the Salient Objects in Images via Two-stream Fixation-Semantic CNNs\",\"url\":\"https://www.semanticscholar.org/paper/42ab23233586d626d49b422ac8cc238a8e14bf8a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653181\",\"name\":\"Guangyong Chen\"},{\"authorId\":\"47180076\",\"name\":\"Shengyu Zhang\"},{\"authorId\":\"48926781\",\"name\":\"Di Lin\"},{\"authorId\":\"30605738\",\"name\":\"Hui Huang\"},{\"authorId\":\"1714602\",\"name\":\"P. Heng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d72fe1900a97da6ae50fd9fe5f13dc995865a3a3\",\"title\":\"Learning to Aggregate Ordinal Labels by Maximizing Separating Width\",\"url\":\"https://www.semanticscholar.org/paper/d72fe1900a97da6ae50fd9fe5f13dc995865a3a3\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"77a4096c59f51711469d4a2d8936fc5ef62ffdf8\",\"title\":\"BubbleView: a validation of a mouse-contingent interface for crowdsourcing image importance and tracking visual attention\",\"url\":\"https://www.semanticscholar.org/paper/77a4096c59f51711469d4a2d8936fc5ef62ffdf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117562053\",\"name\":\"M. A. Reina\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1f1996c60dec75d575f20880a49d646a42584f3a\",\"title\":\"The temporal dimension of visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/1f1996c60dec75d575f20880a49d646a42584f3a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1808.09559\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"title\":\"Temporal Saliency Adaptation in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.06803\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"134585167\",\"name\":\"P. le Callet\"}],\"doi\":\"10.1109/TIP.2019.2945857\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"183802f07521d16b78d27c5229002d49a789b298\",\"title\":\"How is Gaze Influenced by Image Transformations? Dataset and Model\",\"url\":\"https://www.semanticscholar.org/paper/183802f07521d16b78d27c5229002d49a789b298\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-01270-0_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9a484f6ffd5fc006401dee749493142623ba4c9\",\"title\":\"Saliency Benchmarking Made Easy: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/d9a484f6ffd5fc006401dee749493142623ba4c9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2868174\",\"name\":\"Yudong Tao\"},{\"authorId\":\"144987531\",\"name\":\"M. Shyu\"}],\"doi\":\"10.1109/ICMEW.2019.00124\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa83333a10501ac62a21fdbb70638e378e5abb69\",\"title\":\"SP-ASDNet: CNN-LSTM Based ASD Classification Model using Observer ScanPaths\",\"url\":\"https://www.semanticscholar.org/paper/fa83333a10501ac62a21fdbb70638e378e5abb69\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"47ce131f8904027f18eaf8f55fccbcedef351d11\",\"title\":\"The Time Dimension of Visual Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/47ce131f8904027f18eaf8f55fccbcedef351d11\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423637490\",\"name\":\"Konstantinos Stavridis\"},{\"authorId\":\"1423689097\",\"name\":\"Athanasios Psaltis\"},{\"authorId\":\"47381330\",\"name\":\"Anastasios Dimou\"},{\"authorId\":\"33961149\",\"name\":\"Georgios Th. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"Petros Daras\"}],\"doi\":\"10.23919/EUSIPCO.2019.8902990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8aa1373310558613c470a610751c270e5d9c8bd\",\"title\":\"Deep Spatio-Temporal Modeling for Object-Level Gaze-Based Relevance Assessment\",\"url\":\"https://www.semanticscholar.org/paper/e8aa1373310558613c470a610751c270e5d9c8bd\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-70169-1_29\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"title\":\"Attentive Models in Vision: Computing Saliency Maps in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"venue\":\"AI*IA\",\"year\":2017},{\"arxivId\":\"2005.14310\",\"authors\":[{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/cvpr42600.2020.00027\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b9346af26e460bc37d0e3a4e957a6c42beb3677\",\"title\":\"Predicting Goal-Directed Human Attention Using Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8b9346af26e460bc37d0e3a4e957a6c42beb3677\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740586345\",\"name\":\"Naoyuki Awano\"},{\"authorId\":\"1740584291\",\"name\":\"Y. Hayashi\"}],\"doi\":\"10.1007/s41095-020-0169-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"431dddd3de684ac0d208f46dceef3fe206444e1d\",\"title\":\"Psychological potential field and human eye fixation on binary line-drawing images: A comparative experimental study\",\"url\":\"https://www.semanticscholar.org/paper/431dddd3de684ac0d208f46dceef3fe206444e1d\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"776f18ba98b7028b72dccc579b2771f1aeff199f\",\"title\":\"Emergence of Proto-Object Representations via Fixations in Low-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/776f18ba98b7028b72dccc579b2771f1aeff199f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d42142285c46207a16bd4294e437d504e419a9b7\",\"title\":\"Varying image description tasks: spoken versus written descriptions\",\"url\":\"https://www.semanticscholar.org/paper/d42142285c46207a16bd4294e437d504e419a9b7\",\"venue\":\"VarDial@COLING 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1016/j.image.2018.06.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e3510517f900dce12167622c5da0656ecfc39b14\",\"title\":\"Scanpath and saliency prediction on 360 degree images\",\"url\":\"https://www.semanticscholar.org/paper/e3510517f900dce12167622c5da0656ecfc39b14\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003405618\",\"name\":\"\\u00d6zkan \\u00c7ayl\\u0131\"},{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"144089638\",\"name\":\"Volkan Kilic\"},{\"authorId\":\"27824077\",\"name\":\"Aytu\\u011f Onan\"}],\"doi\":\"10.1007/978-3-030-51156-2_178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaad0463da348df4b83438c3d635267303792a63\",\"title\":\"Mobile Application Based Automatic Caption Generation for Visually Impaired\",\"url\":\"https://www.semanticscholar.org/paper/eaad0463da348df4b83438c3d635267303792a63\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39879254\",\"name\":\"J. Zhang\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":null,\"name\":\"Jun Gao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1145/3107956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c53d869a767acb7f25488dbb00668c8c9f72466d\",\"title\":\"Saliency Detection on Light Field\",\"url\":\"https://www.semanticscholar.org/paper/c53d869a767acb7f25488dbb00668c8c9f72466d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2017},{\"arxivId\":\"1804.06236\",\"authors\":[{\"authorId\":\"2912641\",\"name\":\"I. Kavasidis\"},{\"authorId\":\"1681089\",\"name\":\"S. Palazzo\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"145587660\",\"name\":\"C. Pino\"},{\"authorId\":\"144027622\",\"name\":\"D. Giordano\"},{\"authorId\":\"39097156\",\"name\":\"D. Giuffrida\"},{\"authorId\":\"144136542\",\"name\":\"P. Messina\"}],\"doi\":\"10.1007/978-3-030-30645-8_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"03672cfa599950f208d424d5298cdc12b72c2492\",\"title\":\"A Saliency-based Convolutional Neural Network for Table and Chart Detection in Digitized Documents\",\"url\":\"https://www.semanticscholar.org/paper/03672cfa599950f208d424d5298cdc12b72c2492\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":\"1808.00262\",\"authors\":[{\"authorId\":\"6475449\",\"name\":\"C. Flores\"},{\"authorId\":\"1403268002\",\"name\":\"Abel Gonzalez-Garcia\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"3262395\",\"name\":\"B. Raducanu\"}],\"doi\":\"10.1016/j.patcog.2019.05.002\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3efc9872196e4b0bcb2e0d7b26581eb8db097469\",\"title\":\"Saliency for Fine-grained Object Recognition in Domains with Scarce Training Data\",\"url\":\"https://www.semanticscholar.org/paper/3efc9872196e4b0bcb2e0d7b26581eb8db097469\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500422873\",\"name\":\"Pengcheng Hao\"},{\"authorId\":\"98828095\",\"name\":\"S. Wang\"},{\"authorId\":\"1390903689\",\"name\":\"Shupei Li\"},{\"authorId\":\"48857452\",\"name\":\"M. Yang\"}],\"doi\":\"10.1109/CAC48633.2019.8996493\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c53e13e5315fac2fe904055e035c64e080530ff7\",\"title\":\"Low-Light Image Enhancement Based On Retinex and Saliency Theories\",\"url\":\"https://www.semanticscholar.org/paper/c53e13e5315fac2fe904055e035c64e080530ff7\",\"venue\":\"2019 Chinese Automation Congress (CAC)\",\"year\":2019},{\"arxivId\":\"2007.12104\",\"authors\":[{\"authorId\":\"150343399\",\"name\":\"Xianyu Chen\"},{\"authorId\":\"1410304992\",\"name\":\"Ming Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b02f8478f1cfac459e0959fe2371583bf257f3aa\",\"title\":\"Leveraging Bottom-Up and Top-Down Attention for Few-Shot Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b02f8478f1cfac459e0959fe2371583bf257f3aa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10455\",\"authors\":[{\"authorId\":\"151453388\",\"name\":\"Anwesan Pal\"},{\"authorId\":\"152211532\",\"name\":\"Sayan Mondal\"},{\"authorId\":\"1723059\",\"name\":\"H. Christensen\"}],\"doi\":\"10.1109/cvpr42600.2020.01190\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8df4510bfa55f10002d59d2affdc4b533de9e67a\",\"title\":\"\\u201cLooking at the Right Stuff\\u201d \\u2013 Guided Semantic-Gaze for Autonomous Driving\",\"url\":\"https://www.semanticscholar.org/paper/8df4510bfa55f10002d59d2affdc4b533de9e67a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"8025545\",\"name\":\"Christopher Catton\"},{\"authorId\":\"8464855\",\"name\":\"S. Janjic\"}],\"doi\":\"10.1109/CVPR.2016.62\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"title\":\"A Deeper Look at Saliency: Feature Contrast, Semantics, and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1903.02939\",\"authors\":[{\"authorId\":\"81269354\",\"name\":\"B. V. D. Akker\"},{\"authorId\":\"145258872\",\"name\":\"I. Markov\"},{\"authorId\":\"1696030\",\"name\":\"M. Rijke\"}],\"doi\":\"10.1145/3308558.3313419\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9de9117dcda20166766878564344d8ac5f8fcaf\",\"title\":\"ViTOR: Learning to Rank Webpages Based on Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/a9de9117dcda20166766878564344d8ac5f8fcaf\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2504382\",\"name\":\"Marc Spicker\"},{\"authorId\":\"1409955806\",\"name\":\"Franz G\\u00f6tz-Hahn\"},{\"authorId\":\"2075142\",\"name\":\"T. Lindemeier\"},{\"authorId\":\"1775428\",\"name\":\"D. Saupe\"},{\"authorId\":\"1850438\",\"name\":\"O. Deussen\"}],\"doi\":\"10.1145/3301414\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61213df425513babcf62ced840225b6b796ae464\",\"title\":\"Quantifying Visual Abstraction Quality for Computer-Generated Illustrations\",\"url\":\"https://www.semanticscholar.org/paper/61213df425513babcf62ced840225b6b796ae464\",\"venue\":\"ACM Trans. Appl. Percept.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"153448727\",\"name\":\"M. Shehata\"},{\"authorId\":\"152293645\",\"name\":\"P. McGuire\"}],\"doi\":\"10.1109/CCECE47787.2020.9255692\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b95ad78e7aeb9c32e4bba9f9a079bc2257fb6694\",\"title\":\"Performance Evaluation of Pre-Trained CNN Models for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b95ad78e7aeb9c32e4bba9f9a079bc2257fb6694\",\"venue\":\"2020 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144065939\",\"name\":\"W. Qi\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"8474575\",\"name\":\"L. Bai\"}],\"doi\":\"10.1007/s41095-015-0028-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f00a6dbe565ec9feae2a8f68958a8e002bc81bf\",\"title\":\"SaliencyRank: Two-stage manifold ranking for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/8f00a6dbe565ec9feae2a8f68958a8e002bc81bf\",\"venue\":\"Computational Visual Media\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3185668\",\"name\":\"Haoran Liang\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/SMC.2017.8123171\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ebb90d21b947edd2f1dd1d001b8153f572367520\",\"title\":\"Visual-verbal consistency of image saliency\",\"url\":\"https://www.semanticscholar.org/paper/ebb90d21b947edd2f1dd1d001b8153f572367520\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380248807\",\"name\":\"Mona Abid\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/ICIP.2019.8803552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1fcb71c85746f45ac75bb400d63e0728900f63f\",\"title\":\"Influence of Viewpoint on Visual Saliency Models for Volumetric Content\",\"url\":\"https://www.semanticscholar.org/paper/e1fcb71c85746f45ac75bb400d63e0728900f63f\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51149716\",\"name\":\"Taiki Oyama\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1109/ACPR.2017.143\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d702248cf46124600c680608a510e03a30b4d63b\",\"title\":\"Fully Convolutional DenseNet for Saliency-Map Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d702248cf46124600c680608a510e03a30b4d63b\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c01a827fd687791b92e393b203028fa1bca4c5ff\",\"title\":\"Leverage eye-movement data for saliency modeling: Invariance Analysis and a Robust New Model\",\"url\":\"https://www.semanticscholar.org/paper/c01a827fd687791b92e393b203028fa1bca4c5ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"7503327\",\"name\":\"Vennela Gudisa\"},{\"authorId\":\"2313878\",\"name\":\"Jaley H. Dholakiya\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/CVPR.2016.623\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ca43c217aceabea4cff14bff1d81df2debe058f\",\"title\":\"Saliency Unified: A Deep Architecture for simultaneous Eye Fixation Prediction and Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1ca43c217aceabea4cff14bff1d81df2debe058f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412870585\",\"name\":\"Pol Caselles Rico\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6badd633f974013393353fb856534af30cece3e\",\"title\":\"Integrating low-level motion cues in deep video saliency\",\"url\":\"https://www.semanticscholar.org/paper/e6badd633f974013393353fb856534af30cece3e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48515258\",\"name\":\"Y. Li\"},{\"authorId\":\"1693839\",\"name\":\"X. Mou\"}],\"doi\":\"10.1117/12.2537895\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"014c4adda977457bdfd6152fbd9e1bf8ea50dadc\",\"title\":\"A competition-based image saliency model\",\"url\":\"https://www.semanticscholar.org/paper/014c4adda977457bdfd6152fbd9e1bf8ea50dadc\",\"venue\":\"SPIE/COS Photonics Asia\",\"year\":2019},{\"arxivId\":\"1805.00192\",\"authors\":[{\"authorId\":\"47443313\",\"name\":\"Ashu Sharma\"},{\"authorId\":\"40625609\",\"name\":\"Jayanta Kumar Ghosh\"},{\"authorId\":\"46194470\",\"name\":\"Saptrarshi Kolay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5617119ea9cdb186fc57eb4b5e25fbcc70abc7ca\",\"title\":\"Fixation Data Analysis for High Resolution Satellite Images\",\"url\":\"https://www.semanticscholar.org/paper/5617119ea9cdb186fc57eb4b5e25fbcc70abc7ca\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40016715\",\"name\":\"A. Fernandez\"}],\"doi\":\"10.1007/978-3-030-33723-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed65da06354403ac4e6236784af31c2dfb7699ce\",\"title\":\"On the Salience of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/ed65da06354403ac4e6236784af31c2dfb7699ce\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":\"1803.05759\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1da3e74e10b8fe2708c81ddabb480e8d7929a589\",\"title\":\"Salient Region Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1da3e74e10b8fe2708c81ddabb480e8d7929a589\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1007/s11263-017-1042-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22894791cb1e139177cef3fbb1ebda417a4b549f\",\"title\":\"Attentive Systems: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/22894791cb1e139177cef3fbb1ebda417a4b549f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878895877\",\"name\":\"Yucheng Zhu\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"}],\"doi\":\"10.1109/TMM.2019.2957986\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"title\":\"The Prediction of Saliency Map for Head and Eye Movements in 360 Degree Images\",\"url\":\"https://www.semanticscholar.org/paper/42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144418344\",\"name\":\"Ran Xu\"},{\"authorId\":\"50140777\",\"name\":\"X. Su\"},{\"authorId\":\"9213847\",\"name\":\"Haishan Xia\"}],\"doi\":\"10.1080/13467581.2019.1666013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c210e805b9ca22c39e30c911ab4817d7b6b7599\",\"title\":\"Understanding and evaluating visual guidance quality inside passenger terminals - a cognitive and quantified approach\",\"url\":\"https://www.semanticscholar.org/paper/2c210e805b9ca22c39e30c911ab4817d7b6b7599\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"3411472\",\"name\":\"G. Panagiotaropoulou\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2018.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"113eda25ece35fd7ecb51cb104182a973ea2313e\",\"title\":\"Audio-Visual Temporal Saliency Modeling Validated by fMRI Data\",\"url\":\"https://www.semanticscholar.org/paper/113eda25ece35fd7ecb51cb104182a973ea2313e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1702.00372\",\"authors\":[{\"authorId\":\"143635238\",\"name\":\"Samuel F. Dodge\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/TIP.2018.2834826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fc290cec880b22ca61544eca84157821ea7b0c6\",\"title\":\"Visual Saliency Prediction Using a Mixture of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fc290cec880b22ca61544eca84157821ea7b0c6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1708.02660\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"1411051436\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"145899760\",\"name\":\"Sami Alsheikh\"},{\"authorId\":\"7232330\",\"name\":\"Spandan Madan\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"}],\"doi\":\"10.1145/3126594.3126653\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"title\":\"Learning Visual Importance for Graphic Designs and Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"venue\":\"UIST\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2733405\",\"name\":\"H. Li\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/J.JVCIR.2019.102611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"title\":\"A multiscale dilated dense convolutional network for saliency prediction with instance-level attention competition\",\"url\":\"https://www.semanticscholar.org/paper/6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1707.06029\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"4945045\",\"name\":\"Yeonhwa Kim\"},{\"authorId\":\"143912065\",\"name\":\"Kyung Yoo\"},{\"authorId\":\"2135453\",\"name\":\"S. Lee\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"title\":\"Supervising Neural Attention Models for Video Captioning by Human Gaze Data\",\"url\":\"https://www.semanticscholar.org/paper/1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2494584\",\"name\":\"G. Dimas\"},{\"authorId\":\"143932347\",\"name\":\"D. Iakovidis\"},{\"authorId\":\"47352212\",\"name\":\"A. Koulaouzidis\"}],\"doi\":\"10.1109/BIBE.2019.00071\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8b496b2ba8490c9b8463d9757ee719f32700362\",\"title\":\"MedGaze: Gaze Estimation on WCE Images Based on a CNN Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/b8b496b2ba8490c9b8463d9757ee719f32700362\",\"venue\":\"2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xinyi Wu\"},{\"authorId\":\"153006222\",\"name\":\"Zhenyao Wu\"},{\"authorId\":\"24392163\",\"name\":\"J. Zhang\"},{\"authorId\":\"47668707\",\"name\":\"Li-li Ju\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6927\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"title\":\"SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation-Based ConvLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2705863\",\"name\":\"C. Ozcinar\"},{\"authorId\":\"1409495745\",\"name\":\"Nevrez Imamoglu\"},{\"authorId\":\"144812978\",\"name\":\"Weimin Wang\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1007/s11760-020-01769-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30b517573f4efec43e3ecae7ab3ef5f0019ed32f\",\"title\":\"Delivery of omnidirectional video using saliency prediction and optimal bitrate allocation\",\"url\":\"https://www.semanticscholar.org/paper/30b517573f4efec43e3ecae7ab3ef5f0019ed32f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1708.02031\",\"authors\":[{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"40562844\",\"name\":\"D. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"46507431\",\"name\":\"H. Wang\"},{\"authorId\":\"1714354\",\"name\":\"B. Yin\"}],\"doi\":\"10.1109/ICCV.2017.32\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"37f8e2749308294b31f0c222f703ef65af6e0e2b\",\"title\":\"Learning Uncertain Convolutional Features for Accurate Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/37f8e2749308294b31f0c222f703ef65af6e0e2b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/ICCV.2017.513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2120951\",\"name\":\"Alina Kloss\"},{\"authorId\":\"2435984\",\"name\":\"D. Kappler\"},{\"authorId\":\"51207321\",\"name\":\"H. P. Lensch\"},{\"authorId\":\"1732540\",\"name\":\"M. Butz\"},{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/IROS.2016.7759770\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e93ea7263dabafef4405a72d5c1e34ea5e5c6d11\",\"title\":\"Self-supervised regrasping using spatio-temporal tactile features and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e93ea7263dabafef4405a72d5c1e34ea5e5c6d11\",\"venue\":\"IROS 2016\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"J. Laaksonen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"title\":\"Can Saliency Information Benefit Image Captioning Models?\",\"url\":\"https://www.semanticscholar.org/paper/204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2008.13227\",\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7dd07f677210aa27defdd0f471771860566f674\",\"title\":\"A Compact Deep Architecture for Real-time Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b7dd07f677210aa27defdd0f471771860566f674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10004\",\"authors\":[{\"authorId\":\"21319564\",\"name\":\"J. Li\"},{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"title\":\"Visual Attention on the Sun: What Do Existing Models Actually Predict?\",\"url\":\"https://www.semanticscholar.org/paper/6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80937411\",\"name\":\"Quanlong Zheng\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"143864954\",\"name\":\"Y. Cao\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1007/978-3-030-01264-9_18\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83990b5527c2447085125fd79cffb3ce34a7b517\",\"title\":\"Task-Driven Webpage Saliency\",\"url\":\"https://www.semanticscholar.org/paper/83990b5527c2447085125fd79cffb3ce34a7b517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27651985\",\"name\":\"Austin Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"title\":\"Predicting Visual Saliency : Where Do People Look ?\",\"url\":\"https://www.semanticscholar.org/paper/0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c89d3b0945d60697dbfd2a93e2dba30f767eb0a4\",\"title\":\"UNDERSTANDING AND PREDICTING HUMAN VISUAL ATTENTION\",\"url\":\"https://www.semanticscholar.org/paper/c89d3b0945d60697dbfd2a93e2dba30f767eb0a4\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"315511e474b59b6469f5697e8b4e4abd14663b66\",\"title\":\"Human attention simulation on nature scenes in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/315511e474b59b6469f5697e8b4e4abd14663b66\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103410654\",\"name\":\"A. Bornet\"},{\"authorId\":\"40647726\",\"name\":\"Jacques Kaiser\"},{\"authorId\":\"144373348\",\"name\":\"A. Kroner\"},{\"authorId\":\"1714652\",\"name\":\"E. Falotico\"},{\"authorId\":\"3429627\",\"name\":\"Alessandro Ambrosano\"},{\"authorId\":\"73427445\",\"name\":\"Kepa Cantero\"},{\"authorId\":\"2102793\",\"name\":\"M. Herzog\"},{\"authorId\":\"49903084\",\"name\":\"G. Francis\"}],\"doi\":\"10.3389/fnbot.2019.00033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8501bd29d7f6a175c9a1338296dea3000280263d\",\"title\":\"Running Large-Scale Simulations on the Neurorobotics Platform to Understand Vision \\u2013 The Case of Visual Crowding\",\"url\":\"https://www.semanticscholar.org/paper/8501bd29d7f6a175c9a1338296dea3000280263d\",\"venue\":\"Front. Neurorobot.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"173edc84319ad918cddca75de022f740bf155847\",\"title\":\"Towards Laws of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/173edc84319ad918cddca75de022f740bf155847\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40075749\",\"name\":\"P. Zhang\"},{\"authorId\":\"1456179809\",\"name\":\"Chenhui Li\"},{\"authorId\":\"121900636\",\"name\":\"Changbo Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102780\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf79bcbb3d562d26c41e98efc30e0ebe59f59186\",\"title\":\"Smarttext: Learning To Generate Harmonious Textual Layout Over Natural Image\",\"url\":\"https://www.semanticscholar.org/paper/bf79bcbb3d562d26c41e98efc30e0ebe59f59186\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.13066\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"1390040513\",\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"40538374\",\"name\":\"Xos\\u00e9 M. Pardo\"}],\"doi\":\"10.1109/ICCV.2019.00888\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d24f772368b77ac9d67eb72fa6b95d880dc64b97\",\"title\":\"SID4VAM: A Benchmark Dataset With Synthetic Images for Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/d24f772368b77ac9d67eb72fa6b95d880dc64b97\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77510553\",\"name\":\"Yo Umeki\"},{\"authorId\":\"81503758\",\"name\":\"Isana Funahashi\"},{\"authorId\":\"1901907107\",\"name\":\"Taichi Yoshida\"},{\"authorId\":\"1739625\",\"name\":\"M. Iwahashi\"}],\"doi\":\"10.1109/ACCESS.2020.3014886\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8146cdd1fd72b8a674d93691107a95f0e21ae6f\",\"title\":\"Salient Object Detection With Importance Degree\",\"url\":\"https://www.semanticscholar.org/paper/f8146cdd1fd72b8a674d93691107a95f0e21ae6f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"153448727\",\"name\":\"M. Shehata\"},{\"authorId\":\"2810321\",\"name\":\"P. Mcguire\"}],\"doi\":\"10.3390/INFO10080257\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"816094379592bb9faeebbaeea4275340c731fa82\",\"title\":\"Visual Saliency Prediction Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/816094379592bb9faeebbaeea4275340c731fa82\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48020855\",\"name\":\"A. Jones\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"988fc5de4e00e966474a4b8f3215d438930cc39d\",\"title\":\"Computational modeling of visual attention and saliency in the Smart Playroom\",\"url\":\"https://www.semanticscholar.org/paper/988fc5de4e00e966474a4b8f3215d438930cc39d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152425750\",\"name\":\"W. Ding\"},{\"authorId\":\"150257036\",\"name\":\"Ping An\"},{\"authorId\":\"143702938\",\"name\":\"C. Yang\"},{\"authorId\":\"3281642\",\"name\":\"Xinpeng Huang\"}],\"doi\":\"10.1117/12.2575107\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a7f727add2e92a96c8af56bc1d2816e4fda6b29\",\"title\":\"Panoramic video assessment based on cascaded network using saliency map\",\"url\":\"https://www.semanticscholar.org/paper/9a7f727add2e92a96c8af56bc1d2816e4fda6b29\",\"venue\":\"SPIE/COS Photonics Asia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380248807\",\"name\":\"Mona Abid\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1145/3423328.3423498\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b280d2d77a9145d474c916a54dc15084ff274065\",\"title\":\"Perceptual Characterization of 3D Graphical Contents based on Attention Complexity Measures\",\"url\":\"https://www.semanticscholar.org/paper/b280d2d77a9145d474c916a54dc15084ff274065\",\"venue\":\"QoEVMA @ ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152347102\",\"name\":\"F. Yu\"},{\"authorId\":\"30490097\",\"name\":\"Haonan Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3343031.3350931\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c47e8c51d8293eb59416456179c606cb3ae08692\",\"title\":\"Instance of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/c47e8c51d8293eb59416456179c606cb3ae08692\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423668854\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"47319689\",\"name\":\"Shuai Li\"},{\"authorId\":\"46674323\",\"name\":\"Yunfeng Sui\"},{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"143754861\",\"name\":\"Ce Zhu\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023127\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"540bdbf95acdeb1a05102b995b4ffc3d3a04bf51\",\"title\":\"Integrating Action-aware Features for Saliency Prediction via Weakly Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/540bdbf95acdeb1a05102b995b4ffc3d3a04bf51\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2504382\",\"name\":\"Marc Spicker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"907ba99560ec45988e4684c738d484eb0d4a12eb\",\"title\":\"Quantitative Models for Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/907ba99560ec45988e4684c738d484eb0d4a12eb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410115885\",\"name\":\"Miguel-\\u00c1ngel Fern\\u00e1ndez-Torres\"},{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"1397907559\",\"name\":\"F. D\\u00edaz-de-Mar\\u00eda\"}],\"doi\":\"10.1109/TCSVT.2019.2909427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08a33526d8777104a2c2766d5df51299a504f8a7\",\"title\":\"Probabilistic Topic Model for Context-Driven Visual Attention Understanding\",\"url\":\"https://www.semanticscholar.org/paper/08a33526d8777104a2c2766d5df51299a504f8a7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1910.10603\",\"authors\":[{\"authorId\":\"3427162\",\"name\":\"Z. Chang\"},{\"authorId\":\"5159509\",\"name\":\"J. Matias Di Martino\"},{\"authorId\":\"83277545\",\"name\":\"Qiang Qiu\"},{\"authorId\":\"8698514\",\"name\":\"Steven Espinosa\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"}],\"doi\":\"10.1109/ICCVW.2019.00148\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"401e127a7a7def6f6154e9ab200dc36d6fdcb837\",\"title\":\"SalGaze: Personalizing Gaze Estimation using Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/401e127a7a7def6f6154e9ab200dc36d6fdcb837\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/WACV.2017.63\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eba9452ba55a9d37e84dae7a4caf11c6ddd377d5\",\"title\":\"Learning Attributes from Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/eba9452ba55a9d37e84dae7a4caf11c6ddd377d5\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"456983805a8781d6429bed1ed66dc9f3902767af\",\"title\":\"Seeing with Humans : Gaze-Assisted Neural Image\",\"url\":\"https://www.semanticscholar.org/paper/456983805a8781d6429bed1ed66dc9f3902767af\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ef\\u00decient Inef\\u00decient\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0630721ed0128f0155da81c916a98ed5898cbc2a\",\"title\":\"Realization maps derived from Clicktionary for \\u00d2ef\\u00decient\\u00d3 ( above median performance ) versus\",\"url\":\"https://www.semanticscholar.org/paper/0630721ed0128f0155da81c916a98ed5898cbc2a\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2018.00783\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a2fae46c67189fb2aea33f12091772e635361f1\",\"title\":\"Going from Image to Video Saliency: Augmenting Image Salience with Dynamic Attentional Push\",\"url\":\"https://www.semanticscholar.org/paper/9a2fae46c67189fb2aea33f12091772e635361f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fd369da5f97e9d3ca6863030ec10a689754bcbb6\",\"title\":\"LINARDOS ET AL: TEMPORAL RECURRENCES FOR VIDEO SALIENCY PREDICTION 1 Temporal Recurrences for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd369da5f97e9d3ca6863030ec10a689754bcbb6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1807.10657\",\"authors\":[{\"authorId\":\"51149716\",\"name\":\"Taiki Oyama\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1049/TRIT.2018.1012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5df11c59e3b47189486445f5833675bf08359bfe\",\"title\":\"Influence of Image Classification Accuracy on Saliency Map Estimation\",\"url\":\"https://www.semanticscholar.org/paper/5df11c59e3b47189486445f5833675bf08359bfe\",\"venue\":\"CAAI Trans. Intell. Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37503295\",\"name\":\"J. Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"102937546\",\"name\":\"Weimin Wu\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"17668082\",\"name\":\"Baiyan Zhang\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802611\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"title\":\"Saliency Detection via Topological Feature Modulated Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1709.05307\",\"authors\":[{\"authorId\":\"2004177\",\"name\":\"F. Murabito\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"3403160\",\"name\":\"Konstantin Pogorelov\"},{\"authorId\":\"1410046696\",\"name\":\"Michael Riegler\"}],\"doi\":\"10.1016/j.cviu.2018.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"706f314f3b66f0ede47ec9ca7157426915739244\",\"title\":\"Top-Down Saliency Detection Driven by Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/706f314f3b66f0ede47ec9ca7157426915739244\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1968574\",\"name\":\"Sezer Karaoglu\"},{\"authorId\":\"47599820\",\"name\":\"Ran Tao\"},{\"authorId\":\"134228326\",\"name\":\"Jan C. Van Gemert\"},{\"authorId\":\"1695527\",\"name\":\"T. Gevers\"}],\"doi\":\"10.1109/TIP.2017.2707805\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0969aa7d4557699b7460e4159658828efafed8bd\",\"title\":\"Con-Text: Text Detection for Fine-Grained Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/0969aa7d4557699b7460e4159658828efafed8bd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1907.01869\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"144011211\",\"name\":\"J. J. Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"title\":\"Simple vs complex temporal recurrences for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52164159\",\"name\":\"Yuya Moroto\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ICCE-Taiwan49838.2020.9258340\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"282dba81d9b91487744fc301f25c9afdc2dc352a\",\"title\":\"Estimation of Person-Specific Visual Attention via Selection of Similar Persons\",\"url\":\"https://www.semanticscholar.org/paper/282dba81d9b91487744fc301f25c9afdc2dc352a\",\"venue\":\"2020 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692476780\",\"name\":\"Dongwen Chen\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"},{\"authorId\":\"39421976\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"1692947016\",\"name\":\"Huansheng Zhu\"}],\"doi\":\"10.1109/VR46266.2020.1581216087067\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ca61a3453b7f70989d24af16021d4e94670e4221\",\"title\":\"SalBiNet360: Saliency Prediction on 360\\u00b0 Images with Local-Global Bifurcated Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/ca61a3453b7f70989d24af16021d4e94670e4221\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2342453\",\"name\":\"Wentao Bao\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.03.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7e4167fc24c7a64953cbabdd0a6d7790d45102\",\"title\":\"Human scanpath prediction based on deep convolutional saccadic model\",\"url\":\"https://www.semanticscholar.org/paper/0d7e4167fc24c7a64953cbabdd0a6d7790d45102\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2426112\",\"name\":\"N. Kim\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6fefcfdfe517e2e670bf345bc2a4fc2c52a9db35\",\"title\":\"BubbleView: An Interface for Crowdsourcing Image Importance Maps and Tracking Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6fefcfdfe517e2e670bf345bc2a4fc2c52a9db35\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41213934\",\"name\":\"Y. Fang\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"1931825703\",\"name\":\"Fangyu Shi\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"}],\"doi\":\"10.1109/ICIP40778.2020.9190831\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fff0945afdceb738742b004c313fa27803768f27\",\"title\":\"Identifying Children with Autism Spectrum Disorder Based on Gaze-Following\",\"url\":\"https://www.semanticscholar.org/paper/fff0945afdceb738742b004c313fa27803768f27\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1810.02426\",\"authors\":[{\"authorId\":\"9543926\",\"name\":\"Mahmoud Kalash\"},{\"authorId\":\"3240989\",\"name\":\"Md. Amirul Islam\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":\"10.1109/TPAMI.2019.2927203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87fe38a79ee12531bb618d4006a476b3a5256f3e\",\"title\":\"Relative Saliency and Ranking: Models, Metrics, Data and Benchmarks\",\"url\":\"https://www.semanticscholar.org/paper/87fe38a79ee12531bb618d4006a476b3a5256f3e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1007/s11263-017-1018-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44855e53801d09763c1fb5f90ab73e5c3758a728\",\"title\":\"Sentence Directed Video Object Codiscovery\",\"url\":\"https://www.semanticscholar.org/paper/44855e53801d09763c1fb5f90ab73e5c3758a728\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"2007.05104\",\"authors\":[{\"authorId\":\"71395340\",\"name\":\"Yan Luo\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58598-3_30\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f6488dbc831f5fe055ae8000768e5761ed169745\",\"title\":\"n-Reference Transfer Learning for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f6488dbc831f5fe055ae8000768e5761ed169745\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2772489\",\"name\":\"Eghbal G. Mansoori\"},{\"authorId\":\"145105283\",\"name\":\"M. Yazdi\"}],\"doi\":\"10.1016/J.JVCIR.2020.102931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"title\":\"Exploiting object features in deep gaze prediction models\",\"url\":\"https://www.semanticscholar.org/paper/20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2007.13839\",\"authors\":[{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"4ba67b0734477ff392367f52542ad2dab179da83\",\"title\":\"Saliency Prediction with External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/4ba67b0734477ff392367f52542ad2dab179da83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.04544\",\"authors\":[{\"authorId\":\"51054223\",\"name\":\"Zhenyue Qin\"},{\"authorId\":\"40235164\",\"name\":\"J. Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28ee6d316f646e7067eb8d2f364119a6218699df\",\"title\":\"Visual Saliency Maps Can Apply to Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/28ee6d316f646e7067eb8d2f364119a6218699df\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"7382216\",\"name\":\"John Tstotsos\"}],\"doi\":\"10.1109/CVPR.2016.63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2774dfff4416ffc51679aadd83905147e7dcb95e\",\"title\":\"Spatially Binned ROC: A Comprehensive Saliency Metric\",\"url\":\"https://www.semanticscholar.org/paper/2774dfff4416ffc51679aadd83905147e7dcb95e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1809.00644\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"title\":\"Learning Saliency Prediction From Sparse Fixation Pixel Map\",\"url\":\"https://www.semanticscholar.org/paper/155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.03011\",\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"},{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"46380769\",\"name\":\"Jingyi Yu\"}],\"doi\":\"10.1109/TPAMI.2018.2866563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"title\":\"Personalized Saliency and Its Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2008.02912\",\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"24026083\",\"name\":\"Vincent Casser\"},{\"authorId\":\"1682200\",\"name\":\"Amish Kumar Bedi\"},{\"authorId\":\"1411051422\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1145/3379337.3415825\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e7693331d4536bec5f38b2338936439cd821b5b0\",\"title\":\"Predicting Visual Importance Across Graphic Design Types\",\"url\":\"https://www.semanticscholar.org/paper/e7693331d4536bec5f38b2338936439cd821b5b0\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"},{\"authorId\":\"1993250191\",\"name\":\"Tugdual Le Pen\"},{\"authorId\":\"1993250955\",\"name\":\"R\\u00e9mi Cozot\"}],\"doi\":\"10.1371/journal.pone.0239980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ab2027e9e9939f5fbad8652b8c017821a4c545\",\"title\":\"Can we accurately predict where we look at paintings?\",\"url\":\"https://www.semanticscholar.org/paper/52ab2027e9e9939f5fbad8652b8c017821a4c545\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"47319689\",\"name\":\"Shuai Li\"},{\"authorId\":\"1423668854\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"71222824\",\"name\":\"Y. Liu\"},{\"authorId\":\"143754859\",\"name\":\"C. Zhu\"}],\"doi\":\"10.1109/CCHI.2019.8901953\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9cb8ec27e942758268f869f2b5a7e0c708553443\",\"title\":\"Multiple Context Aggregation Network for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9cb8ec27e942758268f869f2b5a7e0c708553443\",\"venue\":\"2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI)\",\"year\":2019},{\"arxivId\":\"2005.06583\",\"authors\":[{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f003e9630253d6f94708b10492ce747c7dfca13c\",\"title\":\"Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations\",\"url\":\"https://www.semanticscholar.org/paper/f003e9630253d6f94708b10492ce747c7dfca13c\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1702.05150\",\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/3131275\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fc2e0b445dc1825c634768517de557ba4bf22e81\",\"title\":\"BubbleView\",\"url\":\"https://www.semanticscholar.org/paper/fc2e0b445dc1825c634768517de557ba4bf22e81\",\"venue\":\"ACM Trans. Comput. Hum. Interact.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2851379\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"117396297\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.1101/2020.07.27.221499\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8381ae03629962ab8bd0782f6a8075597c1e63f7\",\"title\":\"COCO-Search18: A Dataset for Predicting Goal-directed Attention Control\",\"url\":\"https://www.semanticscholar.org/paper/8381ae03629962ab8bd0782f6a8075597c1e63f7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40063957\",\"name\":\"Eric Arazo Sanchez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55761bdf5cbbff5fbede8ee9d0573d1561a9254b\",\"title\":\"The impact of visual saliency prediction in image classification\",\"url\":\"https://www.semanticscholar.org/paper/55761bdf5cbbff5fbede8ee9d0573d1561a9254b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23535421\",\"name\":\"A. Flechsenhar\"},{\"authorId\":\"52055641\",\"name\":\"O. Larson\"},{\"authorId\":\"4850937\",\"name\":\"A. End\"},{\"authorId\":\"1712636\",\"name\":\"M. Gamer\"}],\"doi\":\"10.1167/18.12.11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0ed134a594bd12cecd2f982a9138dcbb21d3920\",\"title\":\"Investigating overt and covert shifts of attention within social naturalistic scenes.\",\"url\":\"https://www.semanticscholar.org/paper/f0ed134a594bd12cecd2f982a9138dcbb21d3920\",\"venue\":\"Journal of vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25049311\",\"name\":\"R. Kumar\"},{\"authorId\":\"3423323\",\"name\":\"Jogendra Garain\"},{\"authorId\":\"1810015\",\"name\":\"Dakshina Ranjan Kisku\"},{\"authorId\":\"2490911\",\"name\":\"G. Sanyal\"}],\"doi\":\"10.1016/J.PATREC.2018.01.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae27bee4ec124af62b547eaee75253a597514e99\",\"title\":\"Constraint saliency based intelligent camera for enhancing viewers attention towards intended face\",\"url\":\"https://www.semanticscholar.org/paper/ae27bee4ec124af62b547eaee75253a597514e99\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1806.01320\",\"authors\":[{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"50993085\",\"name\":\"Chun-Hung Chao\"},{\"authorId\":\"46181955\",\"name\":\"Jin-Dong Dong\"},{\"authorId\":\"2486384\",\"name\":\"Hao-Kai Wen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2018.00154\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"title\":\"Cube Padding for Weakly-Supervised Saliency Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.3233/IA-170033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"title\":\"Attentive models in vision: Computing saliency maps in the deep learning era\",\"url\":\"https://www.semanticscholar.org/paper/9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"venue\":\"Intelligenza Artificiale\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.10492\",\"authors\":[{\"authorId\":\"145779450\",\"name\":\"Y. Tu\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"47749019\",\"name\":\"W. Zhao\"},{\"authorId\":\"2476347\",\"name\":\"Dawei Cheng\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cb36b1cd622756d1bfc4bedbb05c6dc51bc9bad\",\"title\":\"Image Cropping with Composition and Saliency Aware Aesthetic Score Map\",\"url\":\"https://www.semanticscholar.org/paper/0cb36b1cd622756d1bfc4bedbb05c6dc51bc9bad\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a654db1b4955fb58930f292716a60214113e159a\",\"title\":\"Early Salient Region Selection Does Not Drive Rapid Visual Categorization\",\"url\":\"https://www.semanticscholar.org/paper/a654db1b4955fb58930f292716a60214113e159a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390936291\",\"name\":\"Haoran Liang\"},{\"authorId\":\"1410304992\",\"name\":\"Ming Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1016/j.neucom.2019.09.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"title\":\"A structure-guided approach to the prediction of natural image saliency\",\"url\":\"https://www.semanticscholar.org/paper/126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2001.11921\",\"authors\":[{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"32363057\",\"name\":\"H. Adeli\"},{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"48801624\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1167/jov.20.11.1632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b2900d14b7ef87decfdbc092c55d4ff944dfafa\",\"title\":\"Predicting Goal-directed Attention Control Using Inverse-Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2b2900d14b7ef87decfdbc092c55d4ff944dfafa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"2003.04820\",\"authors\":[{\"authorId\":\"48038691\",\"name\":\"Richard Tran\"},{\"authorId\":\"144818220\",\"name\":\"D. Patrick\"},{\"authorId\":\"152928286\",\"name\":\"M. Geyer\"},{\"authorId\":\"144391871\",\"name\":\"A. Fernandez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"007f2de17df925e2bee01bcde1d4d220f1b1ad23\",\"title\":\"SAD: Saliency-based Defenses Against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/007f2de17df925e2bee01bcde1d4d220f1b1ad23\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134310797\",\"name\":\"Luis A. Leiva\"},{\"authorId\":\"46364507\",\"name\":\"Y. Xue\"},{\"authorId\":\"1977519209\",\"name\":\"Avya Bansal\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1977535062\",\"name\":\"Tu\\u00f0\\u00e7e K\\u00f6ro\\u00f0lu\"},{\"authorId\":\"1977523763\",\"name\":\"Jingzhou Du\"},{\"authorId\":\"3229795\",\"name\":\"N. Dayama\"},{\"authorId\":\"2663734\",\"name\":\"Antti Oulasvirta\"}],\"doi\":\"10.1145/3379503.3403557\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a74c3af655784448f353620b86a2cf69e937ed8\",\"title\":\"Understanding Visual Saliency in Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/7a74c3af655784448f353620b86a2cf69e937ed8\",\"venue\":\"MobileHCI\",\"year\":2020},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2120951\",\"name\":\"Alina Kloss\"},{\"authorId\":\"2435984\",\"name\":\"D. Kappler\"},{\"authorId\":\"1809190\",\"name\":\"H. Lensch\"},{\"authorId\":\"1732540\",\"name\":\"M. Butz\"},{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/iros.2016.7759770\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f732788f8a511344ee91e76e6412f67cec7b4921\",\"title\":\"Learning where to search using visual attention\",\"url\":\"https://www.semanticscholar.org/paper/f732788f8a511344ee91e76e6412f67cec7b4921\",\"venue\":\"2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1810.06679\",\"authors\":[{\"authorId\":\"2892103\",\"name\":\"Jiaxin Lu\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"46781563\",\"name\":\"R. Yang\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TIP.2020.2975957\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3e974aa4fbcc8f048bff4f05bb1283a44801f5a\",\"title\":\"Understanding and Predicting the Memorability of Outdoor Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/d3e974aa4fbcc8f048bff4f05bb1283a44801f5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1710.08014\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/ICCV.2017.240\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"title\":\"Deep Cropping via Attention Box Prediction and Aesthetics Assessment\",\"url\":\"https://www.semanticscholar.org/paper/b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cb7b53aa874fa97484f7bc77ca55c461116a15cc\",\"title\":\"SUPPLEMENTAL MATERIAL : Where should saliency models look next ?\",\"url\":\"https://www.semanticscholar.org/paper/cb7b53aa874fa97484f7bc77ca55c461116a15cc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52164159\",\"name\":\"Yuya Moroto\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ICCE-TW46550.2019.8991811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72d76f90357c7b6e252e2e21b07e8d0ef14c2051\",\"title\":\"User-Specific Visual Attention Estimation Based on Visual Similarity and Spatial Information in Images\",\"url\":\"https://www.semanticscholar.org/paper/72d76f90357c7b6e252e2e21b07e8d0ef14c2051\",\"venue\":\"2019 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121033030\",\"name\":\"D. Papadopoulos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc710563c48317bbd1b107c62dadf61bfb41a76f\",\"title\":\"Efficient human annotation schemes for training object class detectors\",\"url\":\"https://www.semanticscholar.org/paper/cc710563c48317bbd1b107c62dadf61bfb41a76f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"40588149\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"143621876\",\"name\":\"X. Peng\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"042a825ca52d51b7e4766fd43715e4dcd330b767\",\"title\":\"Aesthetic guided deep regression network for image cropping\",\"url\":\"https://www.semanticscholar.org/paper/042a825ca52d51b7e4766fd43715e4dcd330b767\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2019.00248\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1612.08712\",\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":\"33072734\",\"name\":\"N. Moran\"},{\"authorId\":\"50304331\",\"name\":\"Solomon Garber\"},{\"authorId\":\"39432646\",\"name\":\"Antonella DiLillo\"},{\"authorId\":\"1770857\",\"name\":\"J. Storer\"}],\"doi\":\"10.1109/DCC.2017.56\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0e780a9c5e9ef81f5c74bf5d88c83273ab3cd14\",\"title\":\"Semantic Perceptual Image Compression Using Deep Convolution Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0e780a9c5e9ef81f5c74bf5d88c83273ab3cd14\",\"venue\":\"2017 Data Compression Conference (DCC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"50313388\",\"name\":\"Y. Fang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"1431724385\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1109/TCSVT.2020.2985427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64a6b2773c24291cddbea984fbf2a7c6b1d65a55\",\"title\":\"Multi-Exposure Decomposition-Fusion Model for High Dynamic Range Image Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/64a6b2773c24291cddbea984fbf2a7c6b1d65a55\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"title\":\"EML-NET : An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1901.05002\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"title\":\"Light-weighted Saliency Detection with Distinctively Lower Memory Cost and Model Size\",\"url\":\"https://www.semanticscholar.org/paper/8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144539624\",\"name\":\"B. Yan\"},{\"authorId\":\"1789710\",\"name\":\"Haoqian Wang\"},{\"authorId\":\"3291129\",\"name\":\"X. Wang\"},{\"authorId\":\"5094646\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICIP.2017.8296700\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6d1d71e0149bc601363f7e24825b06b36af13f5f\",\"title\":\"An accurate saliency prediction method based on generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/6d1d71e0149bc601363f7e24825b06b36af13f5f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52164159\",\"name\":\"Yuya Moroto\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.3390/s20082170\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f72a875502d619c16a78cef5c885cd781c15e45\",\"title\":\"Few-Shot Personalized Saliency Prediction Based on Adaptive Image Selection Considering Object and Visual Attention\\u2020\",\"url\":\"https://www.semanticscholar.org/paper/3f72a875502d619c16a78cef5c885cd781c15e45\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-48881-3_21\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"title\":\"Multi-level Net: A Visual Saliency Prediction Model\",\"url\":\"https://www.semanticscholar.org/paper/874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145855479\",\"name\":\"C. Fernandez\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fad552aa486e27fd3efbff95b6e11235ca4d98f\",\"title\":\"Saliency Map Optimization\",\"url\":\"https://www.semanticscholar.org/paper/6fad552aa486e27fd3efbff95b6e11235ca4d98f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"title\":\"GazeGAN: A Generative Adversarial Saliency Model based on Invariance Analysis of Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"166aa31fc7b37b1a4c4abc64b1c56f34ceb81bdc\",\"title\":\"Supplementary Material for Paper \\u201c Emotion-Aware Human Attention Prediction \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/166aa31fc7b37b1a4c4abc64b1c56f34ceb81bdc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.05971\",\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"1474358241\",\"name\":\"Ke Gu\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"title\":\"Toward Better Understanding of Saliency Prediction in Augmented 360 Degree Videos\",\"url\":\"https://www.semanticscholar.org/paper/0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/ICCV.2017.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1904.09146\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0167e98f6d2e4c44b505c0f74f91425f62dfc62c\",\"title\":\"Salient Object Detection in the Deep Learning Era: An In-Depth Survey\",\"url\":\"https://www.semanticscholar.org/paper/0167e98f6d2e4c44b505c0f74f91425f62dfc62c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"144082175\",\"name\":\"T. Sharma\"},{\"authorId\":\"1731845\",\"name\":\"P. Gupta\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCVW.2017.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"012876a5f45da258675add1614ad7608a210141a\",\"title\":\"What are the Visual Features Underlying Human Versus Machine Vision?\",\"url\":\"https://www.semanticscholar.org/paper/012876a5f45da258675add1614ad7608a210141a\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102300440\",\"name\":\"Jakob Wiesinger\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"title\":\"Video Saliency Detection Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40565055\",\"name\":\"Shiwei Cheng\"},{\"authorId\":\"152223743\",\"name\":\"Jing Fan\"},{\"authorId\":\"2000421283\",\"name\":\"Yilin Hu\"}],\"doi\":\"10.1007/S00779-020-01463-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"226a09bc91d7b1cd99c4b6206623dd0ec97ee68b\",\"title\":\"Visual saliency model based on crowdsourcing eye tracking data and its application in visual design\",\"url\":\"https://www.semanticscholar.org/paper/226a09bc91d7b1cd99c4b6206623dd0ec97ee68b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"2426112\",\"name\":\"N. Kim\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1007/978-3-319-47024-5_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67089163a209c68318f17b25d744d680d73a7f80\",\"title\":\"Eye Fixation Metrics for Large Scale Evaluation and Comparison of Information Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/67089163a209c68318f17b25d744d680d73a7f80\",\"venue\":\"ETVIS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2018.00785\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"title\":\"Emotional Attention: A Study of Image Sentiment and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"144812765\",\"name\":\"S. Khan\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba651908d6cb9dd10635ee4d44069d9cb7399eb7\",\"title\":\"Human vs Machine Attention in Neural Networks: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/ba651908d6cb9dd10635ee4d44069d9cb7399eb7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51245102\",\"name\":\"Shafin Rahman\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27318149a1fc136202c5b5f48ea8d21d0574d9ed\",\"title\":\"Saliency, Scale and Information: Towards a Unifying Theory\",\"url\":\"https://www.semanticscholar.org/paper/27318149a1fc136202c5b5f48ea8d21d0574d9ed\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1937240\",\"name\":\"Tariq Alshawi\"}],\"doi\":\"10.1109/IEEECONF44664.2019.9048740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09af315002dd893b4946256ba18eeffbc7ad929d\",\"title\":\"Ultra-Fast Saliency Detection Using Qr Factorization\",\"url\":\"https://www.semanticscholar.org/paper/09af315002dd893b4946256ba18eeffbc7ad929d\",\"venue\":\"2019 53rd Asilomar Conference on Signals, Systems, and Computers\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67054334\",\"name\":\"Erik Perillo\"},{\"authorId\":\"2210164\",\"name\":\"Esther Colombini\"}],\"doi\":\"10.1109/SMC.2018.00290\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c1cec446da3af680e256838793de0e8831ec6d3\",\"title\":\"Efficient Visual Saliency Detection with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8c1cec446da3af680e256838793de0e8831ec6d3\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122137635\",\"name\":\"G. Luz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5c69b2b45648531bc831c457dd1202bc95d4f4e\",\"title\":\"Omnidirectional Video : Adaptive Coding based on Saliency\",\"url\":\"https://www.semanticscholar.org/paper/e5c69b2b45648531bc831c457dd1202bc95d4f4e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2003.04942\",\"authors\":[{\"authorId\":\"1557425970\",\"name\":\"Navyasri Reddy\"},{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46d71e96013107c1d2be0b6ec44f4def7ac7fbe2\",\"title\":\"Tidying Deep Saliency Prediction Architectures\",\"url\":\"https://www.semanticscholar.org/paper/46d71e96013107c1d2be0b6ec44f4def7ac7fbe2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1610.01708\",\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2817047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"title\":\"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"48048f2fe3705d7d645450f31696045bf3c8312e\",\"title\":\"BubbleView: an alternative to eye-tracking for crowdsourcing image importance\",\"url\":\"https://www.semanticscholar.org/paper/48048f2fe3705d7d645450f31696045bf3c8312e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9279766\",\"name\":\"Tuozhong Yao\"},{\"authorId\":\"50185828\",\"name\":\"Jiatao Song\"},{\"authorId\":\"1690791\",\"name\":\"P. An\"},{\"authorId\":\"3023524\",\"name\":\"Liangxu Liu\"}],\"doi\":\"10.1109/ICINFA.2016.7832104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0b9a6123fa8113ad3ddc44614941c73512b9dca\",\"title\":\"Multi-class object segmentation based on jointly integrating segment-level and image-level object priors\",\"url\":\"https://www.semanticscholar.org/paper/a0b9a6123fa8113ad3ddc44614941c73512b9dca\",\"venue\":\"2016 IEEE International Conference on Information and Automation (ICIA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2469700\",\"name\":\"Mesut Pak\"},{\"authorId\":\"1825302\",\"name\":\"U. Bayazit\"}],\"doi\":\"10.1007/s11042-020-08686-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb9381801748f42576f8b6f793e55c4ada887092\",\"title\":\"Regional bit allocation with visual attention and distortion sensitivity\",\"url\":\"https://www.semanticscholar.org/paper/eb9381801748f42576f8b6f793e55c4ada887092\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1911.07682\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"23993939\",\"name\":\"Suiyi Ling\"},{\"authorId\":\"47786935\",\"name\":\"J. Li\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1609/AAAI.V34I04.5743\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2486a746caed1860cbda16f1342b95ca75b84ad3\",\"title\":\"A New Ensemble Adversarial Attack Powered by Long-term Gradient Memories\",\"url\":\"https://www.semanticscholar.org/paper/2486a746caed1860cbda16f1342b95ca75b84ad3\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458302\",\"name\":\"P. Lu\"},{\"authorId\":\"1971910\",\"name\":\"J. Liu\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1145/3394171.3413824\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1edd24878b5d72628c07f4a4b00fc1c45f4b977\",\"title\":\"Weakly Supervised Real-time Image Cropping based on Aesthetic Distributions\",\"url\":\"https://www.semanticscholar.org/paper/f1edd24878b5d72628c07f4a4b00fc1c45f4b977\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000900657\",\"name\":\"Yung-Yuan Tseng\"},{\"authorId\":\"35323140\",\"name\":\"Tien-Ruey Hsiang\"}],\"doi\":\"10.1109/MLSP49062.2020.9231937\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f32400b6d0a3b6a0d4af726790fbf20f02efa02\",\"title\":\"A Multi-Patch Aggregated Aesthetic Rating System Based on Eyefixation\",\"url\":\"https://www.semanticscholar.org/paper/7f32400b6d0a3b6a0d4af726790fbf20f02efa02\",\"venue\":\"2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2020},{\"arxivId\":\"2002.10540\",\"authors\":[{\"authorId\":null,\"name\":\"Sen Jia\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":\"10.1109/cvpr42600.2020.00274\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2860038\",\"name\":\"Pierre Marighetto\"},{\"authorId\":\"30170254\",\"name\":\"I. Abdelkader\"},{\"authorId\":\"49031335\",\"name\":\"S. Duzelier\"},{\"authorId\":\"3265104\",\"name\":\"M. Decombas\"},{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"34913672\",\"name\":\"J\\u00e9r\\u00e9mie Jakubowicz\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/ICIP.2016.7532866\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a93534f8bd1304cc3311b54321cdd3f60a609a41\",\"title\":\"FUNNRAR: Hybrid rarity/learning visual saliency\",\"url\":\"https://www.semanticscholar.org/paper/a93534f8bd1304cc3311b54321cdd3f60a609a41\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49637078\",\"name\":\"W. Shan\"},{\"authorId\":\"2272337\",\"name\":\"Guangling Sun\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"}],\"doi\":\"10.1007/978-3-319-67777-4_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d6b7f92c05161ac3d65ad9e10571ab2bf507945\",\"title\":\"Two-Stage Transfer Learning of End-to-End Convolutional Neural Networks for Webpage Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4d6b7f92c05161ac3d65ad9e10571ab2bf507945\",\"venue\":\"IScIDE\",\"year\":2017},{\"arxivId\":\"1612.04335\",\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"title\":\"How do people explore virtual environments\",\"url\":\"https://www.semanticscholar.org/paper/c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1701.02704\",\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"47764827\",\"name\":\"T. Sharma\"},{\"authorId\":\"46479974\",\"name\":\"Pankaj Gupta\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"023f449d7b4f59e0f88d7bdf49aef28ee930083b\",\"title\":\"Clicktionary: A Web-based Game for Exploring the Atoms of Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/023f449d7b4f59e0f88d7bdf49aef28ee930083b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1712.02142\",\"authors\":[{\"authorId\":\"47119743\",\"name\":\"Xi Wang\"},{\"authorId\":\"1751554\",\"name\":\"Marc Alexa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c138e780db882893631567329bfa6e031c967a0\",\"title\":\"Maps of Visual Importance\",\"url\":\"https://www.semanticscholar.org/paper/3c138e780db882893631567329bfa6e031c967a0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00184\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"41aa48241071f8fa15145c3452679aa91c13459e\",\"title\":\"Salient Object Detection Driven by Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/41aa48241071f8fa15145c3452679aa91c13459e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":null,\"name\":\"Patr Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae447685c5dddac6b961079d2c15cf92fa1a8d0a\",\"title\":\"How Many Glances? Modeling Multi-duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/ae447685c5dddac6b961079d2c15cf92fa1a8d0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50492493\",\"name\":\"Anuradha Kar\"},{\"authorId\":\"145419165\",\"name\":\"P. Corcoran\"}],\"doi\":\"10.3390/vision3040055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5570e37a2d1caf2e69220b8e60b154733aed5cb2\",\"title\":\"Development of Open-source Software and Gaze Data Repositories for Performance Evaluation of Eye Tracking Systems\",\"url\":\"https://www.semanticscholar.org/paper/5570e37a2d1caf2e69220b8e60b154733aed5cb2\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382850128\",\"name\":\"L. R. Edmondson\"},{\"authorId\":\"1477624914\",\"name\":\"Alejandro Jim\\u00e9nez-Rodriguez\"},{\"authorId\":\"2682750\",\"name\":\"Hannes P. Saal\"}],\"doi\":\"10.15131/SHEF.DATA.11298953.V1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dc41ecffa060af1f7a7e66ca8eacad2a26ff787\",\"title\":\"Nonlinear scaling of resource allocation in sensory bottlenecks\",\"url\":\"https://www.semanticscholar.org/paper/5dc41ecffa060af1f7a7e66ca8eacad2a26ff787\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1605.01101\",\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1915908\",\"name\":\"Anirban Santara\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c73f015ab7c90f4cc97efad29c27361cec87d351\",\"title\":\"WEPSAM: Weakly Pre-Learnt Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/c73f015ab7c90f4cc97efad29c27361cec87d351\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1802.07931\",\"authors\":[{\"authorId\":\"10814650\",\"name\":\"Sikun Lin\"},{\"authorId\":\"143966172\",\"name\":\"P. Hui\"}],\"doi\":\"10.14711/thesis-991012554569603412\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a1fdf45e6649b0020eb533c70d6062b9183561ff\",\"title\":\"Where's YOUR focus: Personalized Attention\",\"url\":\"https://www.semanticscholar.org/paper/a1fdf45e6649b0020eb533c70d6062b9183561ff\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410010039\",\"name\":\"Hao Zhao\"},{\"authorId\":\"123554573\",\"name\":\"M. Lu\"},{\"authorId\":\"1405606408\",\"name\":\"Anbang Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"48571207\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s11263-019-01263-4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"title\":\"Learning to Draw Sight Lines\",\"url\":\"https://www.semanticscholar.org/paper/5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1901.04908\",\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"}],\"doi\":\"10.1371/journal.pone.0224306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c5965c95288ed05f220ee3250b85391ee7016aa\",\"title\":\"Rapid visual categorization is not guided by early salience-based selection\",\"url\":\"https://www.semanticscholar.org/paper/8c5965c95288ed05f220ee3250b85391ee7016aa\",\"venue\":\"PloS one\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"1618896088\",\"name\":\"Hong Kong\"}],\"doi\":\"10.1109/cvpr42600.2020.00453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffc481c86d46ca812eff85030f812588bb20b80\",\"title\":\"How Much Time Do You Have? Modeling Multi-Duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cffc481c86d46ca812eff85030f812588bb20b80\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.08136\",\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/TPAMI.2019.2963387\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"52b94fb0e0bad38835662d1fb3e86a7be584f8f6\",\"title\":\"Direction Concentration Learning: Enhancing Congruency in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/52b94fb0e0bad38835662d1fb3e86a7be584f8f6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICMEW.2017.8026277\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"88a9504f6a1e9b6b56393fde313fc0076e0f27b3\",\"title\":\"Visual saliency for image captioning in new multimedia services\",\"url\":\"https://www.semanticscholar.org/paper/88a9504f6a1e9b6b56393fde313fc0076e0f27b3\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2019.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"title\":\"Cross-Modality Personalization for Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"151469503\",\"name\":\"Yifan Zhao\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"}],\"doi\":\"10.1109/MIPR49039.2020.00011\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"title\":\"Cross-Domain Visual Attention Model Adaption with One-Shot GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":\"1907.00214\",\"authors\":[{\"authorId\":\"145481136\",\"name\":\"M. Islam\"},{\"authorId\":\"4047650\",\"name\":\"Y. Li\"},{\"authorId\":\"38523451\",\"name\":\"H. Ren\"}],\"doi\":\"10.1007/978-3-030-32254-0_46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb3fcea6ad8cdbea541798f97e6a0294b7ebccb\",\"title\":\"Learning Where to Look While Tracking Instruments in Robot-assisted Surgery\",\"url\":\"https://www.semanticscholar.org/paper/acb3fcea6ad8cdbea541798f97e6a0294b7ebccb\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8443337\",\"name\":\"Xinsheng Zhang\"},{\"authorId\":\"47242215\",\"name\":\"Teng Gao\"},{\"authorId\":\"2611471\",\"name\":\"Dongdong Gao\"}],\"doi\":\"10.1007/s10617-018-9209-0\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e94ad50b60653b28c878a96883d6a253473960b4\",\"title\":\"A new deep spatial transformer convolutional neural network for image saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/e94ad50b60653b28c878a96883d6a253473960b4\",\"venue\":\"Des. Autom. Embed. Syst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.18653/v1/N18-2119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f5110d544ca484bd8fd43cfe37db005e93c4648\",\"title\":\"An Evaluation of Image-Based Verb Prediction Models against Human Eye-Tracking Data\",\"url\":\"https://www.semanticscholar.org/paper/8f5110d544ca484bd8fd43cfe37db005e93c4648\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1709.06308\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fafe70edc7067015ca2d49aef2773c22a71647d\",\"title\":\"Exploring Human-like Attention Supervision in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3fafe70edc7067015ca2d49aef2773c22a71647d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"51431789\",\"name\":\"Dan Shiebler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"title\":\"Learning what and where to attend\",\"url\":\"https://www.semanticscholar.org/paper/136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144545118\",\"name\":\"Sheng Yang\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"}],\"doi\":\"10.1117/12.2521507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73a3861710b7d89b5b702d49df5e7a2996ee2792\",\"title\":\"Predicting visual saliency via a dilated inception module-based model\",\"url\":\"https://www.semanticscholar.org/paper/73a3861710b7d89b5b702d49df5e7a2996ee2792\",\"venue\":\"Other Conferences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795037\",\"name\":\"Y. Chen\"},{\"authorId\":\"2976416\",\"name\":\"K. Chang\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"05001ed38ce1be0d96c22fadf09571526f7fd684\",\"title\":\"Guide Your Eyes: Learning Image Manipulation under Saliency Guidance\",\"url\":\"https://www.semanticscholar.org/paper/05001ed38ce1be0d96c22fadf09571526f7fd684\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2008.01874\",\"authors\":[{\"authorId\":\"46675382\",\"name\":\"Yutong Sun\"},{\"authorId\":\"3458098\",\"name\":\"M. Prabhushankar\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1109/ICIP40778.2020.9191186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6e9dcec9c8447983af63f7d52378456f06731d5\",\"title\":\"Implicit Saliency In Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e6e9dcec9c8447983af63f7d52378456f06731d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947664\",\"name\":\"S. Egner\"},{\"authorId\":\"3187578\",\"name\":\"R. H\\u00f6ger\"},{\"authorId\":\"152835399\",\"name\":\"S. Reimann\"},{\"authorId\":\"2728222\",\"name\":\"W. Zangemeister\"}],\"doi\":\"10.16910/JEMR.11.6.4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a321c3305be9e1d991013e8d330bdfe88dd4a5c1\",\"title\":\"Attention and Information Acquisition: Comparison of Mouse-Click with Eye-Movement Attention Tracking\",\"url\":\"https://www.semanticscholar.org/paper/a321c3305be9e1d991013e8d330bdfe88dd4a5c1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"title\":\"Computational modeling for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"title\":\"Visual context for verb sense disambiguation and multilingual representation learning\",\"url\":\"https://www.semanticscholar.org/paper/49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36195510\",\"name\":\"S. Hegde\"},{\"authorId\":\"15328368\",\"name\":\"Jitender Maurya\"},{\"authorId\":\"3177394\",\"name\":\"R. Hebbalaguppe\"},{\"authorId\":\"1699607987\",\"name\":\"Aniruddha Kalkar\"}],\"doi\":\"10.1109/WACV45572.2020.9093587\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"520f2aaa00ed05239f497e617472490a96900e92\",\"title\":\"SmartOverlays: A Visual Saliency Driven Label Placement for Intelligent Human-Computer Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/520f2aaa00ed05239f497e617472490a96900e92\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700619\",\"name\":\"Jing Liu\"},{\"authorId\":\"3493187\",\"name\":\"Jincheng Lv\"},{\"authorId\":\"2026992233\",\"name\":\"Min Yuan\"},{\"authorId\":\"50560979\",\"name\":\"J. Zhang\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/LSP.2020.3035065\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"title\":\"ABSNet: Aesthetics-Based Saliency Network Using Multi-Task Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2001.11580\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"144227173\",\"name\":\"A. Bagavathi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"title\":\"Unsupervised Gaze Prediction in Egocentric Videos by Energy-based Surprise Modeling\",\"url\":\"https://www.semanticscholar.org/paper/af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"title\":\"Related Work 2 . 1 Visual Saliency Prediction Saliency maps\",\"url\":\"https://www.semanticscholar.org/paper/504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35271622\",\"name\":\"D. Michaud\"},{\"authorId\":\"1678624\",\"name\":\"Thierry Urruty\"},{\"authorId\":\"98318969\",\"name\":\"P. Carr\\u00e9\"},{\"authorId\":\"3000307\",\"name\":\"F. Lecellier\"}],\"doi\":\"10.1016/j.image.2018.06.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af2429e0f796cab405d90e57550c1f9f3f167b25\",\"title\":\"Adaptive features selection for expert datasets: A cultural heritage application\",\"url\":\"https://www.semanticscholar.org/paper/af2429e0f796cab405d90e57550c1f9f3f167b25\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":\"1801.05787\",\"authors\":[{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"46400982\",\"name\":\"I. Korshunova\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"title\":\"Faster gaze prediction with dense networks and Fisher pruning\",\"url\":\"https://www.semanticscholar.org/paper/d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.24963/ijcai.2017/543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aca8c4a62ed6e590889f1e859d7bc79311fa6f4d\",\"title\":\"Beyond Universal Saliency: Personalized Saliency Prediction with Multi-task CNN\",\"url\":\"https://www.semanticscholar.org/paper/aca8c4a62ed6e590889f1e859d7bc79311fa6f4d\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663936\",\"name\":\"Zhengchao Lei\"},{\"authorId\":\"2805822\",\"name\":\"Weiyan Chai\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"9284635\",\"name\":\"Hongmei Song\"},{\"authorId\":\"2255689\",\"name\":\"F. Li\"}],\"doi\":\"10.1109/ICCSE.2017.8085532\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67872e68188985b4bcbcd43ff1617eed34b200ec\",\"title\":\"Saliency detection for RGBD image using optimization\",\"url\":\"https://www.semanticscholar.org/paper/67872e68188985b4bcbcd43ff1617eed34b200ec\",\"venue\":\"2017 12th International Conference on Computer Science and Education (ICCSE)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145171786\",\"name\":\"T. Bradley\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c367d0b0d59f1ba057c176ced93f94ce9cc62af\",\"title\":\"Visual attention for high-fidelity imaging\",\"url\":\"https://www.semanticscholar.org/paper/8c367d0b0d59f1ba057c176ced93f94ce9cc62af\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shree Nath Dutt Sharma\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"35217367\",\"name\":\"Niranjan Balasubramanian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"385c9cb10e5f46af0057c8103edccd9062bc721a\",\"title\":\"Ordering Salient Objects in Images\",\"url\":\"https://www.semanticscholar.org/paper/385c9cb10e5f46af0057c8103edccd9062bc721a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.05268\",\"authors\":[{\"authorId\":\"3296335\",\"name\":\"D. Mascharka\"},{\"authorId\":\"46450184\",\"name\":\"Philip Tran\"},{\"authorId\":\"49902902\",\"name\":\"Ryan Soklaski\"},{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"}],\"doi\":\"10.1109/CVPR.2018.00519\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd0a7c58964905ccfddbad1614165320ccc56393\",\"title\":\"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cd0a7c58964905ccfddbad1614165320ccc56393\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.05719\",\"authors\":[{\"authorId\":\"27343041\",\"name\":\"Ayesha Gurnani\"},{\"authorId\":\"145230420\",\"name\":\"Kenil Shah\"},{\"authorId\":\"23922616\",\"name\":\"Vandit Gajjar\"},{\"authorId\":\"22239413\",\"name\":\"Viraj Mavani\"},{\"authorId\":\"26425477\",\"name\":\"Yash Khandhediya\"}],\"doi\":\"10.1109/WACV.2019.00094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86effa47676edd477a906f0063e55b752ec32d9a\",\"title\":\"SAF-BAGE: Salient Approach for Facial Soft-Biometric Classification - Age, Gender, and Facial Expression\",\"url\":\"https://www.semanticscholar.org/paper/86effa47676edd477a906f0063e55b752ec32d9a\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1705.03854\",\"authors\":[{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TPAMI.2018.2845370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"914e98db74f29fc608106ff438edde58965037c5\",\"title\":\"Predicting the Driver's Focus of Attention: The DR(eye)VE Project\",\"url\":\"https://www.semanticscholar.org/paper/914e98db74f29fc608106ff438edde58965037c5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"venue\":\"EMNLP 2016\",\"year\":2016},{\"arxivId\":\"2007.09943\",\"authors\":[{\"authorId\":\"1823941979\",\"name\":\"Sucheng Ren\"},{\"authorId\":\"1641959671\",\"name\":\"Chu Han\"},{\"authorId\":\"6131290\",\"name\":\"X. Yang\"},{\"authorId\":\"2823769\",\"name\":\"G. Han\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1007/978-3-030-58558-7_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1caaf771cf0b8bd0105b01bf7f2b73a58904b5b0\",\"title\":\"TENet: Triple Excitation Network for Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1caaf771cf0b8bd0105b01bf7f2b73a58904b5b0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1805.01047\",\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":\"10.1016/j.imavis.2020.103887\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"title\":\"EML-NET: An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/cvpr42600.2020.00305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"title\":\"Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1810.04456\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be0d5d28fafe262e509a04b7fc7673d63f563747\",\"title\":\"Invariance Analysis of Saliency Models versus Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/be0d5d28fafe262e509a04b7fc7673d63f563747\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"47291418\",\"name\":\"Yi Fang\"},{\"authorId\":\"144509573\",\"name\":\"Lei Fan\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"}],\"doi\":\"10.1145/3337066\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e01f0475ac9a96da307b2b10778ab6c9283381fb\",\"title\":\"Visual Attention Analysis and Prediction on Human Faces for Children with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/e01f0475ac9a96da307b2b10778ab6c9283381fb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1507.01422\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b37efd3987c1e625b063a6998bd6b282c844915\",\"title\":\"End-to-end Convolutional Network for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4b37efd3987c1e625b063a6998bd6b282c844915\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"Lorenzo Baraldi\"},{\"authorId\":\"145518528\",\"name\":\"G. Serra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"title\":\"1 Paying More A ention to Saliency : Image Captioning with Saliency and Context A ention\",\"url\":\"https://www.semanticscholar.org/paper/96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388070721\",\"name\":\"Alexander Makrigiorgos\"},{\"authorId\":\"144793784\",\"name\":\"Aldo Faisal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"867c8a5b96962d674e2f2978ad016e2fc86a468f\",\"title\":\"Improving Autonomous Driving Agents using Bio-Inspired Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/867c8a5b96962d674e2f2978ad016e2fc86a468f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da951412f75aac6cffb310656770552548a11798\",\"title\":\"SalGAN : Visual Saliency Prediction with Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/da951412f75aac6cffb310656770552548a11798\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1806.03960\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"2619658\",\"name\":\"Zhuode Liu\"},{\"authorId\":\"13800723\",\"name\":\"L. Zhang\"},{\"authorId\":\"51002225\",\"name\":\"Jake A. Whritner\"},{\"authorId\":\"47136793\",\"name\":\"K. Muller\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1007/978-3-030-01252-6_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"170643ea1794c4285a491bcea7dede2d35806726\",\"title\":\"AGIL: Learning Attention from Human for Visuomotor Tasks\",\"url\":\"https://www.semanticscholar.org/paper/170643ea1794c4285a491bcea7dede2d35806726\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2008.11151\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"205d3644e73c1e5cbce9ce08ea94bbfbc6c13a91\",\"title\":\"FastSal: a Computationally Efficient Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/205d3644e73c1e5cbce9ce08ea94bbfbc6c13a91\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICCV.2019.00862\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48631489\",\"name\":\"X. Wang\"},{\"authorId\":\"48594748\",\"name\":\"S. Koch\"},{\"authorId\":\"3165327\",\"name\":\"K. Holmqvist\"},{\"authorId\":\"1751554\",\"name\":\"M. Alexa\"}],\"doi\":\"10.1145/3272127.3275094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d36af28a3a6e2b5b2dab34238a30f950e7598461\",\"title\":\"Tracking the gaze on objects in 3D\",\"url\":\"https://www.semanticscholar.org/paper/d36af28a3a6e2b5b2dab34238a30f950e7598461\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1809.00567\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1007/978-3-030-11021-5_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"title\":\"PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"144889891\",\"name\":\"M. Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/CVPRW.2019.00110\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ca3a708d0b2e2b8cb1010c364e89de3c85adfe2\",\"title\":\"Visual Attention in Multi-Label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/3ca3a708d0b2e2b8cb1010c364e89de3c85adfe2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1506.02059\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1d775083122bb3efa4ea9d235a34276644bfee7\",\"title\":\"Sentence Directed Video Object Codetection\",\"url\":\"https://www.semanticscholar.org/paper/f1d775083122bb3efa4ea9d235a34276644bfee7\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"47177940\",\"name\":\"F. Hahn\"},{\"authorId\":\"2467595\",\"name\":\"I. Zingman\"},{\"authorId\":\"1775428\",\"name\":\"D. Saupe\"}],\"doi\":\"10.21437/PQS.2016-25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19d4cdf0a664c5b7ad11b394bdf66f5d37476941\",\"title\":\"Reported Attention as a Promising Alternative to Gaze in IQA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/19d4cdf0a664c5b7ad11b394bdf66f5d37476941\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2115104\",\"name\":\"Wenjia Niu\"},{\"authorId\":\"100613971\",\"name\":\"Gang Li\"},{\"authorId\":\"8190315\",\"name\":\"Jiqiang Liu\"},{\"authorId\":\"40062477\",\"name\":\"J. Tan\"},{\"authorId\":\"72055377\",\"name\":\"L. Guo\"},{\"authorId\":\"114687731\",\"name\":\"Zhen Han\"},{\"authorId\":\"1731028\",\"name\":\"L. Batten\"}],\"doi\":\"10.1007/978-3-662-48683-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"title\":\"Applications and Techniques in Information Security\",\"url\":\"https://www.semanticscholar.org/paper/58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"venue\":\"Communications in Computer and Information Science\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47786249\",\"name\":\"J. Li\"},{\"authorId\":\"9083492\",\"name\":\"Yangjie Zhao\"},{\"authorId\":\"50236144\",\"name\":\"W. Ye\"},{\"authorId\":\"46330829\",\"name\":\"Kai-Wen Yu\"},{\"authorId\":\"102999346\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/JSTSP.2019.2953950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"641f0a8280c28de5251f8e0f28dec90a40918793\",\"title\":\"Attentive Deep Stitching and Quality Assessment for 360$^{\\\\circ }$ Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/641f0a8280c28de5251f8e0f28dec90a40918793\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020}],\"corpusId\":5864146,\"doi\":\"10.1109/CVPR.2015.7298710\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":107,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"}],\"doi\":\"10.1167/7.14.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"title\":\"The central fixation bias in scene viewing: selecting an optimal viewing position independently of motor biases and image feature distributions.\",\"url\":\"https://www.semanticscholar.org/paper/caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"venue\":\"Journal of vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-319-10584-0_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ef53fe5a5cfeb4cde46efe31378b93ae0cba328\",\"title\":\"Webpage Saliency\",\"url\":\"https://www.semanticscholar.org/paper/0ef53fe5a5cfeb4cde46efe31378b93ae0cba328\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16656212\",\"name\":\"J. S. Perry\"},{\"authorId\":\"2966196\",\"name\":\"W. Geisler\"}],\"doi\":\"10.1117/12.469554\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"474cf62f98c40157b0c23d9def81cfc0d5c8ccb7\",\"title\":\"Gaze-contingent real-time simulation of arbitrary visual fields\",\"url\":\"https://www.semanticscholar.org/paper/474cf62f98c40157b0c23d9def81cfc0d5c8ccb7\",\"venue\":\"IS&T/SPIE Electronic Imaging\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"38163342\",\"name\":\"Merrielle Spain\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1167/8.14.18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"title\":\"Objects predict fixations better than early saliency.\",\"url\":\"https://www.semanticscholar.org/paper/c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Judd\"},{\"authorId\":null,\"name\":\"F. Durand\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fixations on lowresolution images\",\"url\":\"\",\"venue\":\"J. Vis., 11(4):14.1\\u201320\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5469799\",\"name\":\"D. Pelli\"}],\"doi\":\"10.1163/156856897X00366\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff0810bad9e051454837b3632220149c47325973\",\"title\":\"The VideoToolbox software for visual psychophysics: transforming numbers into movies.\",\"url\":\"https://www.semanticscholar.org/paper/ff0810bad9e051454837b3632220149c47325973\",\"venue\":\"Spatial vision\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948968\",\"name\":\"D. Brainard\"}],\"doi\":\"10.1163/156856897X00357\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e7e1543be54a354dece522077a4bf339c97c722\",\"title\":\"The Psychophysics Toolbox.\",\"url\":\"https://www.semanticscholar.org/paper/7e7e1543be54a354dece522077a4bf339c97c722\",\"venue\":\"Spatial vision\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1802088\",\"name\":\"E. Peli\"},{\"authorId\":\"31412988\",\"name\":\"J. Yang\"},{\"authorId\":\"50115342\",\"name\":\"R. Goldstein\"}],\"doi\":\"10.1364/JOSAA.8.001762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9d6ec89d0bf302505e0275130dbaa5e83eac984\",\"title\":\"Image invariance with changes in size: the role of peripheral contrast thresholds.\",\"url\":\"https://www.semanticscholar.org/paper/f9d6ec89d0bf302505e0275130dbaa5e83eac984\",\"venue\":\"Journal of the Optical Society of America. A, Optics and image science\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-319-10584-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"title\":\"Saliency in Crowd\",\"url\":\"https://www.semanticscholar.org/paper/2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32644704\",\"name\":\"L. Sibert\"},{\"authorId\":\"1723792\",\"name\":\"R. Jacob\"}],\"doi\":\"10.1145/332040.332445\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091a811b9e426dbebed704b62d57c98fb8b7b747\",\"title\":\"Evaluation of eye gaze interaction\",\"url\":\"https://www.semanticscholar.org/paper/091a811b9e426dbebed704b62d57c98fb8b7b747\",\"venue\":\"CHI\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33182815\",\"name\":\"D. Hansen\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TPAMI.2009.30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79ced39c474df5d944323a394dc0d5923c14b410\",\"title\":\"In the Eye of the Beholder: A Survey of Models for Eyes and Gaze\",\"url\":\"https://www.semanticscholar.org/paper/79ced39c474df5d944323a394dc0d5923c14b410\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739588\",\"name\":\"M. Pomplun\"},{\"authorId\":\"2040325\",\"name\":\"E. Reingold\"},{\"authorId\":\"3209489\",\"name\":\"J. Shen\"}],\"doi\":\"10.1016/S0010-0277(01)00123-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bdb43d4f8b8b64f499ddbbb18c5a0090e45a3fb\",\"title\":\"Investigating the visual span in comparative search: the effects of task difficulty and divided attention\",\"url\":\"https://www.semanticscholar.org/paper/8bdb43d4f8b8b64f499ddbbb18c5a0090e45a3fb\",\"venue\":\"Cognition\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1016/j.imavis.2011.11.007\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b089afcf58bfdc73a956e015c82a8005ec313dac\",\"title\":\"Saliency from hierarchical adaptation through decorrelation and variance normalization\",\"url\":\"https://www.semanticscholar.org/paper/b089afcf58bfdc73a956e015c82a8005ec313dac\",\"venue\":\"Image Vis. Comput.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N.D.B. Bruce\"},{\"authorId\":null,\"name\":\"J. K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliency\",\"url\":\"\",\"venue\":\"attention, and visual search: an information theoretic approach. J. Vis., 9(3):5.1\\u201324\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2013.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"526eff11d1f545d0dafe025f9c0d5d558456f624\",\"title\":\"Fine-Grained Crowdsourcing for Fine-Grained Recognition\",\"url\":\"https://www.semanticscholar.org/paper/526eff11d1f545d0dafe025f9c0d5d558456f624\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38497468\",\"name\":\"M. Cerf\"},{\"authorId\":\"2356306\",\"name\":\"E. P. Frady\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/9.12.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14d146b099b12af9b6d7c13342d9ca9db9984275\",\"title\":\"Faces and text attract gaze independent of the task: Experimental data and computer model.\",\"url\":\"https://www.semanticscholar.org/paper/14d146b099b12af9b6d7c13342d9ca9db9984275\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1167/11.4.14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66bb08b37ac9d4398b59e89570c0602d69ab3cc3\",\"title\":\"Fixations on low-resolution images.\",\"url\":\"https://www.semanticscholar.org/paper/66bb08b37ac9d4398b59e89570c0602d69ab3cc3\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24492532\",\"name\":\"Jian-xiong Xiao\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2010.5539970\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"title\":\"SUN database: Large-scale scene recognition from abbey to zoo\",\"url\":\"https://www.semanticscholar.org/paper/908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2575582\",\"name\":\"Vidhya Navalpakkam\"},{\"authorId\":\"2845696\",\"name\":\"LaDawn Jentzsch\"},{\"authorId\":\"144042306\",\"name\":\"Rory Sayres\"},{\"authorId\":\"35014893\",\"name\":\"Sujith Ravi\"},{\"authorId\":\"143629707\",\"name\":\"A. Ahmed\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1145/2488388.2488471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83210e25dd00c7277d04650251d21b87fe04c09b\",\"title\":\"Measurement and modeling of eye-mouse behavior in the presence of nonlinear page layouts\",\"url\":\"https://www.semanticscholar.org/paper/83210e25dd00c7277d04650251d21b87fe04c09b\",\"venue\":\"WWW '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749373\",\"name\":\"Dim P. Papadopoulos\"},{\"authorId\":\"47849651\",\"name\":\"A. Clarke\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-319-10602-1_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e75e7030837b9b83eb085f26b1ca45a7b2587a19\",\"title\":\"Training Object Class Detectors from Eye Tracking Data\",\"url\":\"https://www.semanticscholar.org/paper/e75e7030837b9b83eb085f26b1ca45a7b2587a19\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7982460\",\"name\":\"J. S. Pointer\"},{\"authorId\":\"32477129\",\"name\":\"R. Hess\"}],\"doi\":\"10.1016/0042-6989(89)90061-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca34b28960db135d033fb5bb71d292274fc21e19\",\"title\":\"The contrast sensitivity gradient across the human visual field: With emphasis on the low spatial frequency range\",\"url\":\"https://www.semanticscholar.org/paper/ca34b28960db135d033fb5bb71d292274fc21e19\",\"venue\":\"Vision Research\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-642-15561-1_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"title\":\"An Eye Fixation Database for Saliency Detection in Images\",\"url\":\"https://www.semanticscholar.org/paper/ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6828503\",\"name\":\"L. Thibos\"}],\"doi\":\"10.1097/00006324-199806000-00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ee465bdba5759882a6b988ec3c300b0aadb5962\",\"title\":\"Acuity perimetry and the sampling theory of visual resolution.\",\"url\":\"https://www.semanticscholar.org/paper/2ee465bdba5759882a6b988ec3c300b0aadb5962\",\"venue\":\"Optometry and vision science : official publication of the American Academy of Optometry\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/TPAMI.2008.128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d2b5c64a67f65c5dd812b89e07973f97699552\",\"title\":\"80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/54d2b5c64a67f65c5dd812b89e07973f97699552\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2148762\",\"name\":\"K. Rayner\"},{\"authorId\":\"2994100\",\"name\":\"G. McConkie\"}],\"doi\":\"10.1016/0042-6989(76)90143-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be8c7748171565ace53470ac341e85b70be95615\",\"title\":\"What guides a reader's eye movements?\",\"url\":\"https://www.semanticscholar.org/paper/be8c7748171565ace53470ac341e85b70be95615\",\"venue\":\"Vision Research\",\"year\":1976},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2930640\",\"name\":\"P. Welinder\"},{\"authorId\":\"3251767\",\"name\":\"S. Branson\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2e250b4b49a9aa04b68dfd40dc69b022b1f8b3d\",\"title\":\"The Multidimensional Wisdom of Crowds\",\"url\":\"https://www.semanticscholar.org/paper/c2e250b4b49a9aa04b68dfd40dc69b022b1f8b3d\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145522949\",\"name\":\"Jeff Huang\"},{\"authorId\":\"34286525\",\"name\":\"Ryen W. White\"},{\"authorId\":\"1693190\",\"name\":\"G. Buscher\"},{\"authorId\":\"1748169\",\"name\":\"Kuansan Wang\"}],\"doi\":\"10.1145/2348283.2348313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3674b7610d922fee4a5ef4b9aabeb342ee0c38f8\",\"title\":\"Improving searcher models using mouse cursor activity\",\"url\":\"https://www.semanticscholar.org/paper/3674b7610d922fee4a5ef4b9aabeb342ee0c38f8\",\"venue\":\"SIGIR '12\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H.-W. Hunziker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Im Auge des Lesers: foveale und periphere Wahrnehmung - vom Buchstabieren zur Lesefreude\",\"url\":\"\",\"venue\":\"Transmedia Verlag\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1167/9.3.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25e67f4ca6f45533cbe5cec4c6d169b7daf3af2b\",\"title\":\"Saliency, attention, and visual search: an information theoretic approach.\",\"url\":\"https://www.semanticscholar.org/paper/25e67f4ca6f45533cbe5cec4c6d169b7daf3af2b\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103579533\",\"name\":\"Q. V. Soranus\"},{\"authorId\":\"46288330\",\"name\":\"E. Courtney\"}],\"doi\":\"10.1093/OSEO/INSTANCE.00076674\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1000dfbfef78c593c401c1f15974a409885f2b86\",\"title\":\"2 = 4 M\",\"url\":\"https://www.semanticscholar.org/paper/1000dfbfef78c593c401c1f15974a409885f2b86\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/11.3.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b380725466e69717ab4c2520c80cff4bba2cc05c\",\"title\":\"Learning a saliency map using fixated locations in natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/b380725466e69717ab4c2520c80cff4bba2cc05c\",\"venue\":\"Journal of vision\",\"year\":2011}],\"title\":\"SALICON: Saliency in Context\",\"topics\":[{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Eye tracking\",\"topicId\":\"7621\",\"url\":\"https://www.semanticscholar.org/topic/7621\"},{\"topic\":\"Peripheral vision\",\"topicId\":\"283606\",\"url\":\"https://www.semanticscholar.org/topic/283606\"},{\"topic\":\"Mouse tracking\",\"topicId\":\"465948\",\"url\":\"https://www.semanticscholar.org/topic/465948\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Contingency (philosophy)\",\"topicId\":\"202768\",\"url\":\"https://www.semanticscholar.org/topic/202768\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"General-purpose modeling\",\"topicId\":\"1218769\",\"url\":\"https://www.semanticscholar.org/topic/1218769\"},{\"topic\":\"Spatial variability\",\"topicId\":\"155512\",\"url\":\"https://www.semanticscholar.org/topic/155512\"},{\"topic\":\"Tier 1 network\",\"topicId\":\"622670\",\"url\":\"https://www.semanticscholar.org/topic/622670\"}],\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"