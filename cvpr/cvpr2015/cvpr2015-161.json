"{\"abstract\":\"This paper presents a novel approach for automatically generating image descriptions: visual detectors, language models, and multimodal similarity models learnt directly from a dataset of image captions. We use multiple instance learning to train visual detectors for words that commonly occur in captions, including many different parts of speech such as nouns, verbs, and adjectives. The word detector outputs serve as conditional inputs to a maximum-entropy language model. The language model learns from a set of over 400,000 image descriptions to capture the statistics of word usage. We capture global semantics by re-ranking caption candidates using sentence-level features and a deep multimodal similarity model. Our system is state-of-the-art on the official Microsoft COCO benchmark, producing a BLEU-4 score of 29.1%. When human judges compare the system captions to ones written by other people on our held-out test set, the system captions have equal or better quality 34% of the time.\",\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\",\"url\":\"https://www.semanticscholar.org/author/47395669\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\",\"url\":\"https://www.semanticscholar.org/author/144157872\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\",\"url\":\"https://www.semanticscholar.org/author/3346186\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\",\"url\":\"https://www.semanticscholar.org/author/2100612\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\",\"url\":\"https://www.semanticscholar.org/author/144718788\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\",\"url\":\"https://www.semanticscholar.org/author/3127283\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\",\"url\":\"https://www.semanticscholar.org/author/1800422\"},{\"authorId\":\"144137069\",\"name\":\"X. He\",\"url\":\"https://www.semanticscholar.org/author/144137069\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\",\"url\":\"https://www.semanticscholar.org/author/49501003\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\",\"url\":\"https://www.semanticscholar.org/author/144189092\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\",\"url\":\"https://www.semanticscholar.org/author/1699161\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\",\"url\":\"https://www.semanticscholar.org/author/1681543\"}],\"citationVelocity\":185,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429472\",\"name\":\"Philipp Blandfort\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d207010d9147485901057a9d380ad589a294005\",\"title\":\"Computational Approaches to Subjective Interpretation of Multimedia Messages\",\"url\":\"https://www.semanticscholar.org/paper/8d207010d9147485901057a9d380ad589a294005\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.13682\",\"authors\":[{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f147279c9d1edddda57f1f21f23b3b58998bad74\",\"title\":\"VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/f147279c9d1edddda57f1f21f23b3b58998bad74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1503.00064\",\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c80c4ba8226ec556e1775e647f91bb8c126b5e57\",\"title\":\"Generating Multi-Sentence Lingual Descriptions of Indoor Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c80c4ba8226ec556e1775e647f91bb8c126b5e57\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2716932\",\"name\":\"Muhammad Attamimi\"},{\"authorId\":\"47597848\",\"name\":\"Yuji Ando\"},{\"authorId\":\"1693821\",\"name\":\"T. Nakamura\"},{\"authorId\":\"47734618\",\"name\":\"T. Nagai\"},{\"authorId\":\"2619938\",\"name\":\"D. Mochihashi\"},{\"authorId\":\"3236658\",\"name\":\"I. Kobayashi\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"}],\"doi\":\"10.18653/v1/D15-1269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f816fe9e26915d4ec734f27118c2ef07022b0794\",\"title\":\"Learning Word Meanings and Grammar for Describing Everyday Activities in Smart Environments\",\"url\":\"https://www.semanticscholar.org/paper/f816fe9e26915d4ec734f27118c2ef07022b0794\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1604.06838\",\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca366bc08a738a92e2c7e2c142ec853dbea3b82b\",\"title\":\"Word2VisualVec: Cross-Media Retrieval by Visual Feature Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ca366bc08a738a92e2c7e2c142ec853dbea3b82b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1612.00385\",\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"2743835\",\"name\":\"D. Tax\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2017.94\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04556d5f283d7f90e24d43371d3f51faff8c0423\",\"title\":\"Temporal Attention-Gated Model for Robust Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/04556d5f283d7f90e24d43371d3f51faff8c0423\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774112\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"Changyin Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"789c76749a15614d97ac8f4ec18b3ce7d80a2d28\",\"title\":\"Explorer Multiplicative LSTM for sequence modelling\",\"url\":\"https://www.semanticscholar.org/paper/789c76749a15614d97ac8f4ec18b3ce7d80a2d28\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1702.07191\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da5075fa79da6cd7b81e5d3dc24161217ef86368\",\"title\":\"ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/da5075fa79da6cd7b81e5d3dc24161217ef86368\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073332\",\"name\":\"J. Li\"},{\"authorId\":\"1923156\",\"name\":\"P. Yao\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"49039585\",\"name\":\"Wei-Cun Zhang\"}],\"doi\":\"10.3390/APP9163260\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"title\":\"Boosted Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ACCESS.2019.2942000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"801827592d18c4e6170d88f8345465de4a8db7ca\",\"title\":\"Video Captioning With Adaptive Attention and Mixed Loss Optimization\",\"url\":\"https://www.semanticscholar.org/paper/801827592d18c4e6170d88f8345465de4a8db7ca\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"1812.08126\",\"authors\":[{\"authorId\":\"32236286\",\"name\":\"Annika Lindh\"},{\"authorId\":\"144394786\",\"name\":\"R. Ross\"},{\"authorId\":\"31179447\",\"name\":\"Abhijit Mahalunkar\"},{\"authorId\":\"31071031\",\"name\":\"Giancarlo Salton\"},{\"authorId\":\"34967075\",\"name\":\"John D. Kelleher\"}],\"doi\":\"10.1007/978-3-030-01418-6_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93a10137a41f9e1c8f939517bfc75379b47cb1a1\",\"title\":\"Generating Diverse and Meaningful Captions - Unsupervised Specificity Optimization for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93a10137a41f9e1c8f939517bfc75379b47cb1a1\",\"venue\":\"ICANN\",\"year\":2018},{\"arxivId\":\"1906.12188\",\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"title\":\"A Deep Decoder Structure Based on WordEmbedding Regression for An Encoder-Decoder Based Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"},{\"authorId\":\"144538257\",\"name\":\"Y. Weiss\"}],\"doi\":\"10.1007/978-3-030-01258-8\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ecf589ab160976d283d751a8dc407b6cdaff67b0\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/ecf589ab160976d283d751a8dc407b6cdaff67b0\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144792753\",\"name\":\"Y. Qin\"},{\"authorId\":\"151046769\",\"name\":\"Jiajun Du\"},{\"authorId\":\"48379418\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0c0ac3bb66203c32be81193fabeee44c3585582\",\"title\":\"Look Back and Predict Forward in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0c0ac3bb66203c32be81193fabeee44c3585582\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.11310\",\"authors\":[{\"authorId\":\"19444389\",\"name\":\"Koustav Ghosal\"},{\"authorId\":\"36809068\",\"name\":\"Aakanksha Rana\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d204156022f65e34706d4211e05bcb578940939\",\"title\":\"Aesthetic Image Captioning From Weakly-Labelled Photographs\",\"url\":\"https://www.semanticscholar.org/paper/5d204156022f65e34706d4211e05bcb578940939\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703980\",\"name\":\"Nick Craswell\"},{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1777025\",\"name\":\"J. Guo\"},{\"authorId\":\"116506812\",\"name\":\"Bhaskar Mitra\"},{\"authorId\":\"1696030\",\"name\":\"M. Rijke\"}],\"doi\":\"10.1145/2911451.2917762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84aff5163f4db175a94c8c565990c6733c887c6f\",\"title\":\"Neu-IR: The SIGIR 2016 Workshop on Neural Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/84aff5163f4db175a94c8c565990c6733c887c6f\",\"venue\":\"SIGIR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461583\",\"name\":\"Kun Zhang\"},{\"authorId\":\"2767360\",\"name\":\"Guangyi Lv\"},{\"authorId\":\"47767796\",\"name\":\"L. Wu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"50383774\",\"name\":\"Q. Liu\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"153710346\",\"name\":\"Xing Xie\"},{\"authorId\":\"2397264\",\"name\":\"Fangzhao Wu\"}],\"doi\":\"10.1109/tsmc.2019.2932410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da0c294c84ef6d48822eeb383d36015a5bbc96eb\",\"title\":\"Multilevel Image-Enhanced Sentence Representation Net for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/da0c294c84ef6d48822eeb383d36015a5bbc96eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.00460\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2018.00930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09efde3bd0a380e8cbcd55a13694648276c2c166\",\"title\":\"Customized Image Narrative Generation via Interactive Visual Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/09efde3bd0a380e8cbcd55a13694648276c2c166\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.02308\",\"authors\":[{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1721328\",\"name\":\"S. Antani\"},{\"authorId\":\"145949571\",\"name\":\"D. Bulterman\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"},{\"authorId\":\"144049352\",\"name\":\"Julia Hirschberg\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"},{\"authorId\":\"1398227667\",\"name\":\"K. Mayer-Patel\"},{\"authorId\":\"2337428\",\"name\":\"R. Meth\"},{\"authorId\":\"144447740\",\"name\":\"R. Mooney\"},{\"authorId\":\"1688353\",\"name\":\"K. Nahrstedt\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"},{\"authorId\":\"2807460\",\"name\":\"S. Oviatt\"},{\"authorId\":\"70295214\",\"name\":\"B. Prabhakaran\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"},{\"authorId\":\"145372008\",\"name\":\"H. Sundaram\"},{\"authorId\":\"51064498\",\"name\":\"Zhengyou Zhang\"},{\"authorId\":\"1705742\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"539a7061d4289b1aa72f319c680ea87ff695289c\",\"title\":\"Report of 2017 NSF Workshop on Multimedia Challenges, Opportunities and Research Roadmaps\",\"url\":\"https://www.semanticscholar.org/paper/539a7061d4289b1aa72f319c680ea87ff695289c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca5d57ded15b19748c897cb1e96cb51a71f86308\",\"title\":\"Shallow and deep learning for audio and natural language processing\",\"url\":\"https://www.semanticscholar.org/paper/ca5d57ded15b19748c897cb1e96cb51a71f86308\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7644453\",\"name\":\"Hanqi Wang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"46867455\",\"name\":\"Yin Sheng Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3126686.3126715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70f7bcfe2ce3789e62846c73e98feeaa319135e5\",\"title\":\"Learning Deep Contextual Attention Network for Narrative Photo Stream Captioning\",\"url\":\"https://www.semanticscholar.org/paper/70f7bcfe2ce3789e62846c73e98feeaa319135e5\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4078c37c39dc5c7c65a5494651ba6dd443cf9269\",\"title\":\"Empirical performance upper bounds for image and video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4078c37c39dc5c7c65a5494651ba6dd443cf9269\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"Li Yao\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"117aae1dc5b3aee679a690f7dab84e9a23add930\",\"title\":\"AGE AND VIDEO CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/117aae1dc5b3aee679a690f7dab84e9a23add930\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97c881c89166cd4ae5c16050140edbbee417582c\",\"title\":\"Natural Language as a Scaffold for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/97c881c89166cd4ae5c16050140edbbee417582c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30043205\",\"name\":\"Ho\\u00e0\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"95daf004cb89e0d9e4056b08825867329927f9f9\",\"title\":\"Vu Grounding Natural Language Inference on Images\",\"url\":\"https://www.semanticscholar.org/paper/95daf004cb89e0d9e4056b08825867329927f9f9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.08759\",\"authors\":[{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.763\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cee733ee31e245dac4655a870fd9226163a52b5\",\"title\":\"Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-in-the-Blank Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1cee733ee31e245dac4655a870fd9226163a52b5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-030-01174-1_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"title\":\"Multimodal Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738202556\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"50045602\",\"name\":\"Xiaodong He\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1738701211\",\"name\":\"C. Lawrence Zitnick\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"}],\"doi\":\"10.18653/v1/N16-1147\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba7694798333d4670722bb703b7922a0df9a7e7b\",\"title\":\"Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/ba7694798333d4670722bb703b7922a0df9a7e7b\",\"venue\":\"NAACL 2016\",\"year\":2016},{\"arxivId\":\"1510.01027\",\"authors\":[{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"1834450\",\"name\":\"Zhuotun Zhu\"},{\"authorId\":\"2146721\",\"name\":\"Cong Yao\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1109/ICCV.2015.145\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f55bd553deeb0d24df92079dcec8f7e8bdd8a3a\",\"title\":\"Relaxed Multiple-Instance SVM with Application to Object Discovery\",\"url\":\"https://www.semanticscholar.org/paper/5f55bd553deeb0d24df92079dcec8f7e8bdd8a3a\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7415284\",\"name\":\"Y. Jia\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"49830854\",\"name\":\"P. Wang\"},{\"authorId\":\"1805712\",\"name\":\"Jinlin Guo\"},{\"authorId\":\"2248082\",\"name\":\"Yuxiang Xie\"}],\"doi\":\"10.1007/978-3-319-73603-7_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64caa670a1286cfe73012b1a94111419c72a36bf\",\"title\":\"Deep Convolutional Neural Network for Correlating Images and Sentences\",\"url\":\"https://www.semanticscholar.org/paper/64caa670a1286cfe73012b1a94111419c72a36bf\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5364446\",\"name\":\"K. Sherren\"},{\"authorId\":\"2348818\",\"name\":\"J. Parkins\"},{\"authorId\":\"143902272\",\"name\":\"M. Smit\"},{\"authorId\":\"89173793\",\"name\":\"Mona Holmlund\"},{\"authorId\":\"35400608\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1016/J.EIAR.2017.08.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4147b38c294417ead38e0d804207ce8ce63b443\",\"title\":\"Digital archives, big data and image-based culturomics for social impact assessment: Opportunities and challenges\",\"url\":\"https://www.semanticscholar.org/paper/c4147b38c294417ead38e0d804207ce8ce63b443\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804399\",\"name\":\"Guang Li\"},{\"authorId\":\"22771932\",\"name\":\"Shubo Ma\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/2733373.2806314\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39cc55356215fef3f975c74fd024441dcdc20b65\",\"title\":\"Summarization-based Video Caption via Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/39cc55356215fef3f975c74fd024441dcdc20b65\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693307\",\"name\":\"Antti Ukkonen\"},{\"authorId\":\"1830481893\",\"name\":\"Pyry Joona\"},{\"authorId\":\"2084101\",\"name\":\"Tuukka Ruotsalo\"}],\"doi\":\"10.1145/3397271.3401129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2b3ec797b6be1320d84d8e71536f46d22151caa\",\"title\":\"Generating Images Instead of Retrieving Them: Relevance Feedback on Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/b2b3ec797b6be1320d84d8e71536f46d22151caa\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"1811.11683\",\"authors\":[{\"authorId\":\"145559125\",\"name\":\"H. Akbari\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"1754397\",\"name\":\"Surabhi Bhargava\"},{\"authorId\":\"143852868\",\"name\":\"B. Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.01276\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"title\":\"Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48692957\",\"name\":\"B. Jin\"}],\"doi\":\"10.5075/EPFL-THESIS-8420\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68f71644d02a2a0198ba20f411bfcb1cfe655f88\",\"title\":\"Computational Aesthetics and Image Enhancements using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68f71644d02a2a0198ba20f411bfcb1cfe655f88\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11377726\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Zheng Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-3-030-39431-8_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba1b0d693d63837423cd87a5cbcf1b55656db241\",\"title\":\"Semantical Knowledge Guided Salient Object Detection with Multiple Proposals\",\"url\":\"https://www.semanticscholar.org/paper/ba1b0d693d63837423cd87a5cbcf1b55656db241\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":\"1812.08352\",\"authors\":[{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"40609859\",\"name\":\"Yitong Li\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1145/3394171.3413551\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4630a4dc4015c68b5f802b62c963496a024e4843\",\"title\":\"Sequential Attention GAN for Interactive Image Editing\",\"url\":\"https://www.semanticscholar.org/paper/4630a4dc4015c68b5f802b62c963496a024e4843\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1901.00326\",\"authors\":[{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"51289564\",\"name\":\"Tomasz K. Konopczynski\"},{\"authorId\":\"3406625\",\"name\":\"Piotr Semberecki\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"}],\"doi\":\"10.1109/WACV45572.2020.9093644\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d854665be4ebe84355bfe090b7577cd320531a6a\",\"title\":\"Plugin Networks for Inference under Partial Evidence\",\"url\":\"https://www.semanticscholar.org/paper/d854665be4ebe84355bfe090b7577cd320531a6a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20632291\",\"name\":\"Shiliang Sun\"},{\"authorId\":\"145307050\",\"name\":\"Liang Mao\"},{\"authorId\":\"66550933\",\"name\":\"Ziang Dong\"},{\"authorId\":\"4382815\",\"name\":\"Lidan Wu\"}],\"doi\":\"10.1007/978-981-13-3029-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"173a286cfb01a605641c8a7c1c110d648b404459\",\"title\":\"Multiview Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/173a286cfb01a605641c8a7c1c110d648b404459\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1706.09789\",\"authors\":[{\"authorId\":\"145798491\",\"name\":\"D. Golub\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.18653/v1/D17-1087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be60cdc4f3202f44afdfb90bff005e3005dacf9a\",\"title\":\"Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/be60cdc4f3202f44afdfb90bff005e3005dacf9a\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51125006\",\"name\":\"A. Nengroo\"},{\"authorId\":\"32795089\",\"name\":\"K. Kuppusamy\"}],\"doi\":\"10.1007/s10209-017-0607-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"883a2034aabb02ff21de0c947f306abdd7c88568\",\"title\":\"Accessible images (AIMS): a model to build self-describing images for assisting screen reader users\",\"url\":\"https://www.semanticscholar.org/paper/883a2034aabb02ff21de0c947f306abdd7c88568\",\"venue\":\"Universal Access in the Information Society\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47240387\",\"name\":\"Y. Zhong\"},{\"authorId\":\"35268094\",\"name\":\"Masaki Matsubara\"},{\"authorId\":\"34573158\",\"name\":\"A. Morishima\"}],\"doi\":\"10.1109/BigData.2018.8621911\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"048e4fa6dc6a2ce0092b638de62ed58ec0a265a4\",\"title\":\"Identification of Important Images for Understanding Web Pages\",\"url\":\"https://www.semanticscholar.org/paper/048e4fa6dc6a2ce0092b638de62ed58ec0a265a4\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"205e895e03969c96f3c482b0bd26308b16a12bd0\",\"title\":\"Image Captioning with an Intermediate Attributes Layer\",\"url\":\"https://www.semanticscholar.org/paper/205e895e03969c96f3c482b0bd26308b16a12bd0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491174998\",\"name\":\"Prajakta Ganesh Pawar\"},{\"authorId\":\"2605911\",\"name\":\"V. Devendran\"}],\"doi\":\"10.1109/ICCT46177.2019.8969051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b26bcaf33df23b50639b2aa58f5c8f0aa6ae690\",\"title\":\"Scene Understanding: A Survey to See the World at a Single Glance\",\"url\":\"https://www.semanticscholar.org/paper/0b26bcaf33df23b50639b2aa58f5c8f0aa6ae690\",\"venue\":\"2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25184078\",\"name\":\"M. Chevalier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b23981c8466e9a3b98f43b503d0dec0ac464bfa\",\"title\":\"R\\u00e9solution variable et information privil\\u00e9gi\\u00e9e pour la reconnaissance d'images. (Varying resolution and privileged information for image recognition)\",\"url\":\"https://www.semanticscholar.org/paper/1b23981c8466e9a3b98f43b503d0dec0ac464bfa\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145201042\",\"name\":\"L. Han\"},{\"authorId\":\"15132338\",\"name\":\"X. Jing\"},{\"authorId\":\"144894851\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1016/j.neucom.2017.09.045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dfb8153dd61496e96617fb8958b6cd5399c4464\",\"title\":\"Multi-view local discrimination and canonical correlation analysis for image classification\",\"url\":\"https://www.semanticscholar.org/paper/7dfb8153dd61496e96617fb8958b6cd5399c4464\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40143631\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TCSVT.2019.2916167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"title\":\"Matching Image and Sentence With Multi-Faceted Representations\",\"url\":\"https://www.semanticscholar.org/paper/4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643775\",\"name\":\"Zhongyu Liu\"},{\"authorId\":\"153489843\",\"name\":\"T. Chen\"},{\"authorId\":\"3091544\",\"name\":\"Enjie Ding\"},{\"authorId\":\"46398350\",\"name\":\"Y. Liu\"},{\"authorId\":\"145909567\",\"name\":\"Wanli Yu\"}],\"doi\":\"10.1109/ACCESS.2020.3010872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6d66e02be2972957c2579cdc4dd46b5b0a5369d\",\"title\":\"Attention-Based Convolutional LSTM for Describing Video\",\"url\":\"https://www.semanticscholar.org/paper/d6d66e02be2972957c2579cdc4dd46b5b0a5369d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/ISM.2018.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"title\":\"Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":\"1904.01475\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/CVPR.2019.01275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"908c6b1577a1f5309ae183daf2e24363039f22a8\",\"title\":\"Good News, Everyone! Context Driven Entity-Aware Captioning for News Images\",\"url\":\"https://www.semanticscholar.org/paper/908c6b1577a1f5309ae183daf2e24363039f22a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"2987316\",\"name\":\"W. Zhang\"},{\"authorId\":\"2600667\",\"name\":\"W. Diao\"},{\"authorId\":\"1972876\",\"name\":\"Menglong Yan\"},{\"authorId\":\"143703146\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1109/ACCESS.2019.2942154\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d706abc18828390fa0b809a2eb62e1e7688f159\",\"title\":\"VAA: Visual Aligning Attention Model for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d706abc18828390fa0b809a2eb62e1e7688f159\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1712.02051\",\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"49490596\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d190282ed59639b16e726a3237938b53976077\",\"title\":\"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d190282ed59639b16e726a3237938b53976077\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.06622\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb859d4184476bd80d5f2090b3401c702f66135\",\"title\":\"Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions\",\"url\":\"https://www.semanticscholar.org/paper/0eb859d4184476bd80d5f2090b3401c702f66135\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35413543\",\"name\":\"Humberto S. Garcia Caballero\"},{\"authorId\":\"1768706\",\"name\":\"M. A. Westenberg\"},{\"authorId\":\"3153393\",\"name\":\"B. Gebre\"},{\"authorId\":\"143693813\",\"name\":\"J. V. Wijk\"}],\"doi\":\"10.1111/cgf.13667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b8a01e224443eccdac36768fb8ad63e1c6a4ae2\",\"title\":\"V\\u2010Awake: A Visual Analytics Approach for Correcting Sleep Predictions from Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/5b8a01e224443eccdac36768fb8ad63e1c6a4ae2\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"1802.02568\",\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"49652360\",\"name\":\"P. Garrigues\"}],\"doi\":\"10.1109/CVPRW50498.2020.00479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"697f0e24f24b016cef9474db485fe61a667f07b8\",\"title\":\"ViSeR: Visual Self-Regularization\",\"url\":\"https://www.semanticscholar.org/paper/697f0e24f24b016cef9474db485fe61a667f07b8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34672380\",\"name\":\"Madhuri A. Bhalekar\"},{\"authorId\":\"1572146174\",\"name\":\"Shubham Sureka\"},{\"authorId\":\"2427975\",\"name\":\"S. Joshi\"},{\"authorId\":\"50727097\",\"name\":\"M. Bedekar\"}],\"doi\":\"10.1007/978-981-15-1366-4_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d49579b7c727e6b8caca54edbcf81d7fcaee33f\",\"title\":\"Generation of Image Captions Using VGG and ResNet CNN Models Cascaded with RNN Approach\",\"url\":\"https://www.semanticscholar.org/paper/7d49579b7c727e6b8caca54edbcf81d7fcaee33f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1511.06233\",\"authors\":[{\"authorId\":\"3274223\",\"name\":\"Abhijit Bendale\"},{\"authorId\":\"32163276\",\"name\":\"T. Boult\"}],\"doi\":\"10.1109/CVPR.2016.173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c\",\"title\":\"Towards Open Set Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/d094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934466\",\"name\":\"Junwei Zhou\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2710247\",\"name\":\"Jizhong Han\"},{\"authorId\":\"144553025\",\"name\":\"S. Hu\"},{\"authorId\":\"2755326\",\"name\":\"Hongchao Gao\"}],\"doi\":\"10.1109/BigMM.2018.8499060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"title\":\"Spatial- Temporal Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4efc523df04fe19b600e372b9cfc9acf2e0b21d8\",\"title\":\"LSTM stack-based Neural Multi-sequence Alignment TeCHnique (NeuMATCH)\",\"url\":\"https://www.semanticscholar.org/paper/4efc523df04fe19b600e372b9cfc9acf2e0b21d8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1007/978-3-030-14657-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a9bae357bc63540cfbd630f4aaab4088edf2e0\",\"title\":\"Video Captioning Using Hierarchical LSTM and Text-Based Sliding Window\",\"url\":\"https://www.semanticscholar.org/paper/08a9bae357bc63540cfbd630f4aaab4088edf2e0\",\"venue\":\"IoTaaS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8160667\",\"name\":\"Julia El Zini\"},{\"authorId\":\"2587541\",\"name\":\"Yara Rizk\"},{\"authorId\":\"97477222\",\"name\":\"M. Awad\"}],\"doi\":\"10.1109/TGRS.2019.2950888\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2fa002b0154d902fa543cb666eb818739fc6775\",\"title\":\"A Deep Transfer Learning Framework for Seismic Data Analysis: A Case Study on Bright Spot Detection\",\"url\":\"https://www.semanticscholar.org/paper/a2fa002b0154d902fa543cb666eb818739fc6775\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1906.01542\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf8d0386cabafee915e579b54902d2418e0716ad\",\"title\":\"Natural Vocabulary Emerges from Free-Form Annotations\",\"url\":\"https://www.semanticscholar.org/paper/cf8d0386cabafee915e579b54902d2418e0716ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.00579\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P19-1648\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"title\":\"Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huan Yang\"},{\"authorId\":\"145144398\",\"name\":\"Dandan Song\"},{\"authorId\":\"3000498\",\"name\":\"Lejian Liao\"}],\"doi\":\"10.1007/978-3-319-97310-4_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1473ca131d8a6030def18ca196b8d39e0665613\",\"title\":\"Image Captioning with Relational Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c1473ca131d8a6030def18ca196b8d39e0665613\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":\"1801.10300\",\"authors\":[{\"authorId\":\"48149965\",\"name\":\"W. Lin\"},{\"authorId\":\"143672077\",\"name\":\"K. Chen\"},{\"authorId\":\"29837150\",\"name\":\"HungYueh Chiang\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1145/3184558.3186354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e1b3cf334aead8d2c29747f6ee7d1291dd83708\",\"title\":\"Netizen-Style Commenting on Fashion Photos: Dataset and Diversity Measures\",\"url\":\"https://www.semanticscholar.org/paper/9e1b3cf334aead8d2c29747f6ee7d1291dd83708\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2169614\",\"name\":\"Yashaswi Verma\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.cviu.2016.10.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3805cd9f0db2a71bd33cb72ad6ca7bd23fe95e35\",\"title\":\"A support vector approach for cross-modal search of images and texts\",\"url\":\"https://www.semanticscholar.org/paper/3805cd9f0db2a71bd33cb72ad6ca7bd23fe95e35\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90813197\",\"name\":\"M. Ayyavaraiah\"},{\"authorId\":\"47902507\",\"name\":\"B. Venkateswarlu\"}],\"doi\":\"10.1007/978-3-030-37218-7_118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35f4102e7234fa2096b839ac70e2eab549d8e501\",\"title\":\"Cross Media Feature Retrieval and Optimization: A Contemporary Review of Research Scope, Challenges and Objectives\",\"url\":\"https://www.semanticscholar.org/paper/35f4102e7234fa2096b839ac70e2eab549d8e501\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1909.05316\",\"authors\":[{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.1609/AAAI.V34I05.6305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"title\":\"What Makes A Good Story? Designing Composite Rewards for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718795\",\"name\":\"L. Deng\"}],\"doi\":\"10.1017/ATSIP.2015.22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b11f3cb6d5f56771146d54022d28fc4711f0f49\",\"title\":\"From Speech Recognition to Language and Multimodal Processing\",\"url\":\"https://www.semanticscholar.org/paper/4b11f3cb6d5f56771146d54022d28fc4711f0f49\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41f105ba407e9800c7c113a93ee53e20b46d52e6\",\"title\":\"Multimodal Retrieval With Asymmetrically Weighted Truncated-SVD Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/41f105ba407e9800c7c113a93ee53e20b46d52e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1602.08581\",\"authors\":[{\"authorId\":\"21681977\",\"name\":\"Rahul Radhakrishnan Iyer\"},{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"3373875\",\"name\":\"Vikas Mohandoss\"},{\"authorId\":\"3364946\",\"name\":\"Anush Ramsurat\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"1798727\",\"name\":\"R. Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cee02cffb8d123f94c05f6ee3e49c7d94b9aeed\",\"title\":\"Content-based Video Indexing and Retrieval Using Corr-LDA\",\"url\":\"https://www.semanticscholar.org/paper/6cee02cffb8d123f94c05f6ee3e49c7d94b9aeed\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1612.04949\",\"authors\":[{\"authorId\":\"38314901\",\"name\":\"H. Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b5793958cd1654b4817ebb57f5484dfd8861f916\",\"title\":\"Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering\",\"url\":\"https://www.semanticscholar.org/paper/b5793958cd1654b4817ebb57f5484dfd8861f916\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"Andrea Apicella\"},{\"authorId\":\"13851143\",\"name\":\"Anna Corazza\"},{\"authorId\":\"34675913\",\"name\":\"Francesco Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.1109/WETICE.2017.47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a6f970f6801b07d0dd12d836a49bde5b0433d69\",\"title\":\"Integrating a Priori Probabilistic Knowledge into Classification for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/5a6f970f6801b07d0dd12d836a49bde5b0433d69\",\"venue\":\"2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)\",\"year\":2017},{\"arxivId\":\"1804.08274\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00782\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"title\":\"Jointly Localizing and Describing Events for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff8eb9448c3d764e631f54e2936251f5ef5defcb\",\"title\":\"Generative Grammar Semantic Trees Parse Graphs Training Descriptions New Image Scene Graph Semantic Trees Generated Description Vision Models Training Images\",\"url\":\"https://www.semanticscholar.org/paper/ff8eb9448c3d764e631f54e2936251f5ef5defcb\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1710.11475\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96692a8fc740eee99e3ad5e48e73eae8de2578db\",\"title\":\"A Neural-Symbolic Approach to Design of CAPTCHA.\",\"url\":\"https://www.semanticscholar.org/paper/96692a8fc740eee99e3ad5e48e73eae8de2578db\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51151974\",\"name\":\"Prakruthi Prabhakar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b56b001dff2e13f8b6488a9473163fff31f2953f\",\"title\":\"Question Relevance in VisualQuestion Answering\",\"url\":\"https://www.semanticscholar.org/paper/b56b001dff2e13f8b6488a9473163fff31f2953f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9db873fb85ad9e3f19d2462a724e6f169a79328a\",\"title\":\"Optimization for Networks and Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9db873fb85ad9e3f19d2462a724e6f169a79328a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2800977\",\"name\":\"Roman Visotsky\"},{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1007/978-3-030-27005-6_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3b820eba90b18b331ce4db48147e7c6f7d8c48a\",\"title\":\"Learning with Per-Sample Side Information\",\"url\":\"https://www.semanticscholar.org/paper/b3b820eba90b18b331ce4db48147e7c6f7d8c48a\",\"venue\":\"AGI\",\"year\":2019},{\"arxivId\":\"1912.12655\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/WACV45572.2020.9093330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0155df608af9c0024c6d557b16bdc15af78c5133\",\"title\":\"Personalizing Fast-Forward Videos Based on Visual and Textual Features from Social Network\",\"url\":\"https://www.semanticscholar.org/paper/0155df608af9c0024c6d557b16bdc15af78c5133\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380508\",\"name\":\"Sasa Arsovski\"},{\"authorId\":\"143699999\",\"name\":\"A. Cheok\"},{\"authorId\":\"1507030228\",\"name\":\"Kirthana Govindarajoo\"},{\"authorId\":\"1507091318\",\"name\":\"Nurizzaty Salehuddin\"},{\"authorId\":\"1507088977\",\"name\":\"Somaiyeh Vedadi\"}],\"doi\":\"10.1007/s10489-019-01621-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c0311428e7aed5abce69adbfba3e8ee85409dc9\",\"title\":\"Artificial intelligence snapchat: Visual conversation agent\",\"url\":\"https://www.semanticscholar.org/paper/1c0311428e7aed5abce69adbfba3e8ee85409dc9\",\"venue\":\"Applied Intelligence\",\"year\":2020},{\"arxivId\":\"1711.02578\",\"authors\":[{\"authorId\":\"143652809\",\"name\":\"Octavio Arriaga\"},{\"authorId\":\"79429761\",\"name\":\"P. Pl\\u00f6ger\"},{\"authorId\":\"1399503242\",\"name\":\"Matias Valdenegro-Toro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a77b0e52e07edc501473410a4bdcf32ab11a00b\",\"title\":\"Image Captioning and Classification of Dangerous Situations\",\"url\":\"https://www.semanticscholar.org/paper/8a77b0e52e07edc501473410a4bdcf32ab11a00b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.05321\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cc23e554d98522b377d227dc78e9382a0ed35e5\",\"title\":\"Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8cc23e554d98522b377d227dc78e9382a0ed35e5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"}],\"doi\":\"10.21437/Interspeech.2016-380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2abae43b4a7fd85473bd6c906a0fcfc403968e87\",\"title\":\"Generating Natural Video Descriptions via Multimodal Processing\",\"url\":\"https://www.semanticscholar.org/paper/2abae43b4a7fd85473bd6c906a0fcfc403968e87\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336997\",\"name\":\"W. Wang\"},{\"authorId\":\"12287885\",\"name\":\"R. Liu\"},{\"authorId\":\"4820214\",\"name\":\"Mingle Wang\"},{\"authorId\":\"49184528\",\"name\":\"Sen Wang\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1145/3394171.3413507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00075d654178c2641b779d28235c85877f475858\",\"title\":\"Memory-Based Network for Scene Graph with Unbalanced Relations\",\"url\":\"https://www.semanticscholar.org/paper/00075d654178c2641b779d28235c85877f475858\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145552742\",\"name\":\"Feng Yan\"},{\"authorId\":\"1772774\",\"name\":\"Yuxiong He\"},{\"authorId\":\"2537545\",\"name\":\"Olatunji Ruwase\"},{\"authorId\":\"1730525\",\"name\":\"E. Smirni\"}],\"doi\":\"10.1109/SC.2016.25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d338ca44be5c771a29b954a8eb8e916e4a8507a\",\"title\":\"SERF: Efficient Scheduling for Fast Deep Neural Network Serving via Judicious Parallelism\",\"url\":\"https://www.semanticscholar.org/paper/4d338ca44be5c771a29b954a8eb8e916e4a8507a\",\"venue\":\"SC16: International Conference for High Performance Computing, Networking, Storage and Analysis\",\"year\":2016},{\"arxivId\":\"1705.00581\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1145/3123266.3123297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48031e454325487b5fa7972280d1a2400bdef1d4\",\"title\":\"Query-adaptive Video Summarization via Quality-aware Relevance Estimation\",\"url\":\"https://www.semanticscholar.org/paper/48031e454325487b5fa7972280d1a2400bdef1d4\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1803.06506\",\"authors\":[{\"authorId\":\"40604609\",\"name\":\"Syed Ashar Javed\"},{\"authorId\":\"2143851\",\"name\":\"Shreyas Saxena\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":\"10.24963/ijcai.2019/112\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e6538b709d111b9fb3437fe6ccea81577dde24d\",\"title\":\"Learning Unsupervised Visual Grounding Through Semantic Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6e6538b709d111b9fb3437fe6ccea81577dde24d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1710.08049\",\"authors\":[{\"authorId\":\"3456473\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":\"10.1109/CVPR.2018.00100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8613d16ae3ec7263a56a58b9ffdd7dc7fe4e18d\",\"title\":\"Feedback-Prop: Convolutional Neural Network Inference Under Partial Evidence\",\"url\":\"https://www.semanticscholar.org/paper/e8613d16ae3ec7263a56a58b9ffdd7dc7fe4e18d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3123266.3123317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"title\":\"Multi-Networks Joint Learning for Large-Scale Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60af58a2435fe758fe9a172f2009efbb89584f58\",\"title\":\"Temporal-Difference Learning With Sampling Baseline for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/60af58a2435fe758fe9a172f2009efbb89584f58\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958420\",\"name\":\"Tianyi Wang\"},{\"authorId\":\"47539594\",\"name\":\"Jiang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1007/978-3-030-00776-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c50c91875767ec7c6391d99d30838d90275a0f1b\",\"title\":\"Collaborative Detection and Caption Network\",\"url\":\"https://www.semanticscholar.org/paper/c50c91875767ec7c6391d99d30838d90275a0f1b\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3041b13dc0b862e71a67b7d7841ad01e01f7f0a\",\"title\":\"Deep Semantic Indexing Using Convolutional Localization Network with Region-Based Visual Attention for Image Database\",\"url\":\"https://www.semanticscholar.org/paper/b3041b13dc0b862e71a67b7d7841ad01e01f7f0a\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2164516\",\"name\":\"A. Chang\"},{\"authorId\":\"2889774\",\"name\":\"E. Culurciello\"}],\"doi\":\"10.1109/ISCAS.2017.8050816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a32fcc73b6f03dc793e510823d9dd2c22cf617b\",\"title\":\"Hardware accelerators for recurrent neural networks on FPGA\",\"url\":\"https://www.semanticscholar.org/paper/3a32fcc73b6f03dc793e510823d9dd2c22cf617b\",\"venue\":\"2017 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"2318023\",\"name\":\"Matthew W. Moskewicz\"},{\"authorId\":\"2059241\",\"name\":\"K. Ashraf\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"592d2e65489f23ebd993dbdc0c84eda9ac8aadbe\",\"title\":\"- LEVEL ACCURACY WITH 50 X FEWER PARAMETERS AND < 0 . 5 MB MODEL SIZE\",\"url\":\"https://www.semanticscholar.org/paper/592d2e65489f23ebd993dbdc0c84eda9ac8aadbe\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/ICCV.2017.433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"898d3f2560d3568eea53b5781af58811145f4cf6\",\"title\":\"A Stagewise Refinement Model for Detecting Salient Objects in Images\",\"url\":\"https://www.semanticscholar.org/paper/898d3f2560d3568eea53b5781af58811145f4cf6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238568\",\"name\":\"M. Liu\"},{\"authorId\":\"1485768948\",\"name\":\"Lingjun Li\"},{\"authorId\":\"146896370\",\"name\":\"H. Hu\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"153307124\",\"name\":\"J. Tian\"}],\"doi\":\"10.1016/j.ipm.2019.102178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4ba3a265763677dfb68567aa6b62cd5fe4a633b\",\"title\":\"Image caption generation with dual attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e4ba3a265763677dfb68567aa6b62cd5fe4a633b\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288954\",\"name\":\"Jiarong Dong\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"144089410\",\"name\":\"J. Cao\"}],\"doi\":\"10.1007/s11063-019-10030-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed3215857d14557d0afe517b4d28b0e98b384f4b\",\"title\":\"Refocused Attention: Long Short-Term Rewards Guided Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ed3215857d14557d0afe517b4d28b0e98b384f4b\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"}],\"doi\":\"10.1016/j.patcog.2016.08.029\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c95cd791ad0cb0a08cb39e987f725eabe3a08648\",\"title\":\"Are all objects equal? Deep spatio-temporal importance prediction in driving videos\",\"url\":\"https://www.semanticscholar.org/paper/c95cd791ad0cb0a08cb39e987f725eabe3a08648\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81431475\",\"name\":\"Amin Sleimi\"},{\"authorId\":\"1794075\",\"name\":\"Claire Gardent\"}],\"doi\":\"10.18653/V1/W16-3511\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f2aaf34cf4ba627ab39a80b4a8d8b484aa1dc687\",\"title\":\"Generating Paraphrases from DBPedia using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/f2aaf34cf4ba627ab39a80b4a8d8b484aa1dc687\",\"venue\":\"WebNLG\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":\"1607.03240\",\"authors\":[{\"authorId\":\"144208571\",\"name\":\"Sohil Shah\"},{\"authorId\":\"40222634\",\"name\":\"K. Kulkarni\"},{\"authorId\":\"47606073\",\"name\":\"A. Biswas\"},{\"authorId\":\"144883800\",\"name\":\"A. Gandhi\"},{\"authorId\":\"2116262\",\"name\":\"O. Deshmukh\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46466-4_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b7180854e2f2911ac4878c91b451ad07f989725\",\"title\":\"Weakly Supervised Learning of Heterogeneous Concepts in Videos\",\"url\":\"https://www.semanticscholar.org/paper/7b7180854e2f2911ac4878c91b451ad07f989725\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1608.00525\",\"authors\":[{\"authorId\":\"3081378\",\"name\":\"Varun K. Nagaraja\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46493-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"title\":\"Modeling Context Between Objects for Referring Expression Understanding\",\"url\":\"https://www.semanticscholar.org/paper/86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3123266.3127901\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3609c92bbcad4eaa6e239112fc2cadbf87bb3c33\",\"title\":\"Knowing Yourself: Improving Video Caption via In-depth Recap\",\"url\":\"https://www.semanticscholar.org/paper/3609c92bbcad4eaa6e239112fc2cadbf87bb3c33\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e267498c92272820e495f491a52d5ab2c16a2b\",\"title\":\"Supplemental material : Temporal Residual Networks for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72e267498c92272820e495f491a52d5ab2c16a2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9305072\",\"name\":\"Jifei Song\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"},{\"authorId\":\"1965319\",\"name\":\"Tony Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.5244/C.31.45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c52f30ef7fbef659994dc195bcce16fa85bd6f41\",\"title\":\"Fine-Grained Image Retrieval: the Text/Sketch Input Dilemma\",\"url\":\"https://www.semanticscholar.org/paper/c52f30ef7fbef659994dc195bcce16fa85bd6f41\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1910.05728\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"title\":\"Granular Multimodal Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"2600667\",\"name\":\"W. Diao\"},{\"authorId\":\"2987316\",\"name\":\"W. Zhang\"},{\"authorId\":\"1972876\",\"name\":\"Menglong Yan\"},{\"authorId\":\"97941663\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.3390/rs11202349\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c9a104c7b9a76ba03b8f8cf14f7b6b9066d62f0\",\"title\":\"LAM: Remote Sensing Image Captioning with Label-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/4c9a104c7b9a76ba03b8f8cf14f7b6b9066d62f0\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"1505.05914\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08b4577100d63d9e9fd8e35045e220e5cf640ce2\",\"title\":\"A Multi-scale Multiple Instance Video Description Network\",\"url\":\"https://www.semanticscholar.org/paper/08b4577100d63d9e9fd8e35045e220e5cf640ce2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2716932\",\"name\":\"Muhammad Attamimi\"},{\"authorId\":\"47597848\",\"name\":\"Yuji Ando\"},{\"authorId\":\"1693821\",\"name\":\"T. Nakamura\"},{\"authorId\":\"47734618\",\"name\":\"T. Nagai\"},{\"authorId\":\"2619938\",\"name\":\"D. Mochihashi\"},{\"authorId\":\"3236658\",\"name\":\"I. Kobayashi\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"}],\"doi\":\"10.1080/01691864.2016.1172507\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1eeb31e4615b1665b87d5b0ac25739b597924c88\",\"title\":\"Learning word meanings and grammar for verbalization of daily life activities using multilayered multimodal latent Dirichlet allocation and Bayesian hidden Markov models\",\"url\":\"https://www.semanticscholar.org/paper/1eeb31e4615b1665b87d5b0ac25739b597924c88\",\"venue\":\"Adv. Robotics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3407447\",\"name\":\"Rama Kovvuri\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1145/3078971.3078976\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1504eae5487e1e062fef96e1e424de5d3a5a3858\",\"title\":\"MSRC: Multimodal Spatial Regression with Semantic Context for Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/1504eae5487e1e062fef96e1e424de5d3a5a3858\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1909.00301\",\"authors\":[{\"authorId\":\"46700226\",\"name\":\"Jiacheng Liu\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/D19-1515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9abeabd42883b55a1b01e812aa8856280abe0bad\",\"title\":\"Phrase Grounding by Soft-Label Chain Conditional Random Field\",\"url\":\"https://www.semanticscholar.org/paper/9abeabd42883b55a1b01e812aa8856280abe0bad\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7675774\",\"name\":\"C. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"627107c02c2df1366965f11678dd3c4fb14ac9b3\",\"title\":\"CONNECTING IMAGES AND NATURAL LANGUAGE A DISSERTATION SUBMITTED TO THE DEPARTMENT OF COMPUTER SCIENCE AND THE COMMITTEE ON GRADUATE STUDIES OF STANFORD UNIVERSITY IN PARTIAL FULFILLMENT OF THE REQUIREMENTS FOR THE DEGREE OF DOCTOR OF PHILOSOPHY\",\"url\":\"https://www.semanticscholar.org/paper/627107c02c2df1366965f11678dd3c4fb14ac9b3\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1612.03365\",\"authors\":[{\"authorId\":\"36858580\",\"name\":\"Marc-Andr\\u00e9 Carbonneau\"},{\"authorId\":\"2225413\",\"name\":\"V. Cheplygina\"},{\"authorId\":\"145611842\",\"name\":\"Eric Granger\"},{\"authorId\":\"36931204\",\"name\":\"G. Gagnon\"}],\"doi\":\"10.1016/j.patcog.2017.10.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba54fdb71e4f77447460616908f1b931e61c251\",\"title\":\"Multiple instance learning: A survey of problem characteristics and applications\",\"url\":\"https://www.semanticscholar.org/paper/1ba54fdb71e4f77447460616908f1b931e61c251\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.02339\",\"authors\":[{\"authorId\":\"2031911881\",\"name\":\"Edwin G. Ng\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"title\":\"Understanding Guided Image Captioning Performance across Domains\",\"url\":\"https://www.semanticscholar.org/paper/0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1610.01206\",\"authors\":[{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"}],\"doi\":\"10.1109/TKDE.2018.2872063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa53bb7432cad104622f45f5ede17a2cb4642b0e\",\"title\":\"Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods\",\"url\":\"https://www.semanticscholar.org/paper/fa53bb7432cad104622f45f5ede17a2cb4642b0e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395925001\",\"name\":\"Bj\\u00f6rn Wahle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"title\":\"Grounding semantics in robots for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97667801\",\"name\":\"Matthew John Marter\"}],\"doi\":\"10.15126/THESIS.00850052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0f45a806a38bf38511a9f2fd774d7a18d0fc3b3\",\"title\":\"Learning to recognise visual content from textual annotation\",\"url\":\"https://www.semanticscholar.org/paper/a0f45a806a38bf38511a9f2fd774d7a18d0fc3b3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1902.10178\",\"authors\":[{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"15252080\",\"name\":\"S. W\\u00e4ldchen\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"},{\"authorId\":\"144535526\",\"name\":\"Gr\\u00e9goire Montavon\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"}],\"doi\":\"10.1038/s41467-019-08987-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f51a64793d3b2a60e9e5846c31dae023cf5c69a\",\"title\":\"Unmasking Clever Hans predictors and assessing what machines really learn\",\"url\":\"https://www.semanticscholar.org/paper/4f51a64793d3b2a60e9e5846c31dae023cf5c69a\",\"venue\":\"Nature Communications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39054424\",\"name\":\"Min Gao\"},{\"authorId\":\"121685794\",\"name\":\"Xian-Hua Han\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"144562060\",\"name\":\"Hui Ji\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"},{\"authorId\":\"51299154\",\"name\":\"Jiande Sun\"}],\"doi\":\"10.1007/s11042-018-6751-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b737a81ff05e64e29596415c65dbc156e3481f95\",\"title\":\"Image super-resolution based on two-level residual learning CNN\",\"url\":\"https://www.semanticscholar.org/paper/b737a81ff05e64e29596415c65dbc156e3481f95\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3077136.3084144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cdf9b822b07199415f0e25aa0517c82b1bd499a\",\"title\":\"Seeing Bot\",\"url\":\"https://www.semanticscholar.org/paper/7cdf9b822b07199415f0e25aa0517c82b1bd499a\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":\"1612.01033\",\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.1109/ICCV.2017.140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"title\":\"Areas of Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1145/3103535.3103541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0bacb6246e40a3595a90a6c55ccf9573322312\",\"title\":\"An Elevator Pitch on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/5a0bacb6246e40a3595a90a6c55ccf9573322312\",\"venue\":\"GETMBL\",\"year\":2017},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"2007.06811\",\"authors\":[{\"authorId\":\"1978641\",\"name\":\"Xiao-Qi Zhao\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"152551539\",\"name\":\"Y. Pang\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"},{\"authorId\":\"1429345566\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1007/978-3-030-58542-6_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9eac3f2931432ba6d3fa829eafbd3b9198193eaf\",\"title\":\"A Single Stream Network for Robust and Real-time RGB-D Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/9eac3f2931432ba6d3fa829eafbd3b9198193eaf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1804.08473\",\"authors\":[{\"authorId\":\"143672100\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"32878737\",\"name\":\"M. Kato\"},{\"authorId\":\"1740865\",\"name\":\"M. Yoshikawa\"}],\"doi\":\"10.1145/3240508.3240587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e56f1fd88d967aab6be2a51f3633697e2df667\",\"title\":\"Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/99e56f1fd88d967aab6be2a51f3633697e2df667\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122032919\",\"name\":\"Ivan Rafael Ram\\u00edrez D\\u00edaz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c7aec3a906248a46f0a5ff7df599ac465ecf593\",\"title\":\"Variational and Deep Learning Methods in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/0c7aec3a906248a46f0a5ff7df599ac465ecf593\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71582095\",\"name\":\"S. V. Waveren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"620850f8f43a357a49068bb9f06b609568294a26\",\"title\":\"Automatic image caption generation for digital cultural emages collections\",\"url\":\"https://www.semanticscholar.org/paper/620850f8f43a357a49068bb9f06b609568294a26\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1109/CVPR.2018.00521\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"title\":\"Categorizing Concepts with Basic Level for Vision-to-Language\",\"url\":\"https://www.semanticscholar.org/paper/7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51001584\",\"name\":\"Hyung-min Lee\"},{\"authorId\":\"153481384\",\"name\":\"Il-Koo Kim\"}],\"doi\":\"10.1109/IJCNN.2019.8851892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"title\":\"Generating Natural Video Descriptions using Semantic Gate\",\"url\":\"https://www.semanticscholar.org/paper/b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1109/TPAMI.2017.2786699\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b74208db3a241d3e7567e29bae3b81b1ad75cb91\",\"title\":\"Disambiguating Visual Verbs\",\"url\":\"https://www.semanticscholar.org/paper/b74208db3a241d3e7567e29bae3b81b1ad75cb91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.neucom.2018.02.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a24f013cbae0f349c54aaf958dca944d561a6efd\",\"title\":\"VD-SAN: Visual-Densely Semantic Attention Network for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a24f013cbae0f349c54aaf958dca944d561a6efd\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959354\",\"name\":\"Renato Preigschadt de Azevedo\"},{\"authorId\":\"2548454\",\"name\":\"M. J. V. Pereira\"},{\"authorId\":\"1717634\",\"name\":\"P. Henriques\"}],\"doi\":\"10.1007/978-3-030-16181-1_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afe4d56d3a39c901a29606b0bf522bbfb6abd2cf\",\"title\":\"DSL Based Automatic Generation of Q&A Systems\",\"url\":\"https://www.semanticscholar.org/paper/afe4d56d3a39c901a29606b0bf522bbfb6abd2cf\",\"venue\":\"WorldCIST\",\"year\":2019},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1701.08251\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"3130583\",\"name\":\"Georgios P. Spithourakis\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880fca26169023a900c0f7d65d9b85abc5240a0\",\"title\":\"Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/c880fca26169023a900c0f7d65d9b85abc5240a0\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8657946\",\"name\":\"A. Kumar\"},{\"authorId\":\"4054731\",\"name\":\"Shivali Goel\"}],\"doi\":\"10.3233/HIS-170246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd8a3f44f806afa2a609185dfe615fb65724bc2b\",\"title\":\"A survey of evolution of image captioning techniques\",\"url\":\"https://www.semanticscholar.org/paper/cd8a3f44f806afa2a609185dfe615fb65724bc2b\",\"venue\":\"Int. J. Hybrid Intell. Syst.\",\"year\":2017},{\"arxivId\":\"1612.00576\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/D17-1098\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"title\":\"Guided Open Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"1792458\",\"name\":\"A. Belz\"}],\"doi\":\"10.1109/MCI.2017.2708559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9da7a7b44022be3888ce9aaa82c8e6018e4b87f2\",\"title\":\"Learning to Generate Descriptions of Visual Data Anchored in Spatial Relations\",\"url\":\"https://www.semanticscholar.org/paper/9da7a7b44022be3888ce9aaa82c8e6018e4b87f2\",\"venue\":\"IEEE Computational Intelligence Magazine\",\"year\":2017},{\"arxivId\":\"1909.02050\",\"authors\":[{\"authorId\":\"144889895\",\"name\":\"Ming Jiang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"50141029\",\"name\":\"Xin Wang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"3207378\",\"name\":\"J. Diesner\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/D19-1220\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce01073130ff984eb43cbf43f6bdcbe4d5a09df9\",\"title\":\"TIGEr: Text-to-Image Grounding for Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/ce01073130ff984eb43cbf43f6bdcbe4d5a09df9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398421283\",\"name\":\"U. Markowska-Kaczmar\"},{\"authorId\":\"153318273\",\"name\":\"H. Kwasnicka\"}],\"doi\":\"10.1007/978-3-319-73891-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"title\":\"Deep Learning\\u2014A New Era in Bridging the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"144547972\",\"name\":\"Kun Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7953d06375e1e18bfdb0d95b570f1367757b9d0b\",\"title\":\"Scene Graph Generation from Objects, Phrases and Caption Regions\",\"url\":\"https://www.semanticscholar.org/paper/7953d06375e1e18bfdb0d95b570f1367757b9d0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47557007\",\"name\":\"Himanshu Sharma\"},{\"authorId\":\"2704856\",\"name\":\"A. S. Jalal\"}],\"doi\":\"10.1142/s0217984920503157\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b16e790764d0169e06501125ce946123d67f7c30\",\"title\":\"Incorporating external knowledge for image captioning using CNN and LSTM\",\"url\":\"https://www.semanticscholar.org/paper/b16e790764d0169e06501125ce946123d67f7c30\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27139174\",\"name\":\"Elliot Salisbury\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12a15dfbdc2ed8ff943c8867daeb64c46142e421\",\"title\":\"Toward Scalable Social Alt Text: Conversational Crowdsourcing as a Tool for Refining Vision-to-Language Technology for the Blind\",\"url\":\"https://www.semanticscholar.org/paper/12a15dfbdc2ed8ff943c8867daeb64c46142e421\",\"venue\":\"HCOMP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47329912\",\"name\":\"F. Enache\"},{\"authorId\":\"31331770\",\"name\":\"V. Greu\"},{\"authorId\":\"51174175\",\"name\":\"Petric\\u0103 Ciot\\u00eernae\"},{\"authorId\":\"49349813\",\"name\":\"F. Popescu\"}],\"doi\":\"10.1109/COMM48946.2020.9141972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5643e2e1ad72f4f0b020b712b968adf2c11fe7ac\",\"title\":\"Model and Algorithms for Optimizing a Human Computing System Oriented to Knowledge Extraction by Use of Crowdsourcing\",\"url\":\"https://www.semanticscholar.org/paper/5643e2e1ad72f4f0b020b712b968adf2c11fe7ac\",\"venue\":\"2020 13th International Conference on Communications (COMM)\",\"year\":2020},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1706.00932\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"title\":\"See, Hear, and Read: Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.07889\",\"authors\":[{\"authorId\":\"144690460\",\"name\":\"Di Lu\"},{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"34170717\",\"name\":\"Lifu Huang\"},{\"authorId\":\"144016781\",\"name\":\"Heng Ji\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.18653/v1/D18-1435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e8feffa2280e41ceb864b940869c5408db89285\",\"title\":\"Entity-aware Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/1e8feffa2280e41ceb864b940869c5408db89285\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1703.06492\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"title\":\"VQABQ: Visual Question Answering by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144977003\",\"name\":\"H. Peng\"},{\"authorId\":null,\"name\":\"Nianheng Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7523ead2a91191f0ecfb88fba5c0f2deeddaa256\",\"title\":\"Generating Chinese Captions for Flickr 30 K Images\",\"url\":\"https://www.semanticscholar.org/paper/7523ead2a91191f0ecfb88fba5c0f2deeddaa256\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"title\":\"Image Input OR Video Hierarchical LSTMs with Adaptive Attention ( hLSTMat ) Feature Extraction Generated Captions Losses\",\"url\":\"https://www.semanticscholar.org/paper/e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.06306\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/ICCV.2019.00754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"title\":\"U-CAM: Visual Explanation Using Uncertainty Based Class Activation Maps\",\"url\":\"https://www.semanticscholar.org/paper/5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2002.12585\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"145558281\",\"name\":\"Kai Lei\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.24963/ijcai.2019/708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"title\":\"Exploring and Distilling Cross-Modal Information for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"135273ea1521236e96bd79a319bf9386969bae5f\",\"title\":\"Exploiting independent visual and textual data sources to improve multi-modal methods for description and querying of visual data\",\"url\":\"https://www.semanticscholar.org/paper/135273ea1521236e96bd79a319bf9386969bae5f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9bbc952adb3e3c6091d45d800e806d3373a52bac\",\"title\":\"Learning Visual Classifiers using Human-centric Annotations\",\"url\":\"https://www.semanticscholar.org/paper/9bbc952adb3e3c6091d45d800e806d3373a52bac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1512.02479\",\"authors\":[{\"authorId\":\"144535526\",\"name\":\"Gr\\u00e9goire Montavon\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"145838768\",\"name\":\"K. M\\u00fcller\"}],\"doi\":\"10.1016/j.patcog.2016.11.008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc00e2c47411d6d257c979963e4dd2f7d97d5d03\",\"title\":\"Explaining nonlinear classification decisions with deep Taylor decomposition\",\"url\":\"https://www.semanticscholar.org/paper/dc00e2c47411d6d257c979963e4dd2f7d97d5d03\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"020ef0ff20efd4f873ade6ddd718c1624b5963ca\",\"title\":\"Learning spoken language through vision\",\"url\":\"https://www.semanticscholar.org/paper/020ef0ff20efd4f873ade6ddd718c1624b5963ca\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1829790\",\"name\":\"L. Zhou\"},{\"authorId\":\"2094999\",\"name\":\"L. Piras\"},{\"authorId\":\"10395256\",\"name\":\"M. Riegler\"},{\"authorId\":\"49450956\",\"name\":\"M. Lux\"},{\"authorId\":\"1381816609\",\"name\":\"Duc-Tien Dang-Nguyen\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4df31ea4ab2c26970217bc4160850ef110b8e3ac\",\"title\":\"An Interactive Lifelog Retrieval System for Activities of Daily Living Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4df31ea4ab2c26970217bc4160850ef110b8e3ac\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":\"1711.08389\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"8440041\",\"name\":\"Paige Kordas\"},{\"authorId\":\"1772294\",\"name\":\"M. Kiapour\"},{\"authorId\":\"144147900\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"3221010\",\"name\":\"Robinson Piramuthu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-030-01258-8_16\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5bfebd3774c44580463cda8e611487ae3639cd7\",\"title\":\"Conditional Image-Text Embedding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e5bfebd3774c44580463cda8e611487ae3639cd7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92716077\",\"name\":\"Shaokang Yang\"},{\"authorId\":\"122218340\",\"name\":\"J. Niu\"},{\"authorId\":\"1809483\",\"name\":\"Jiyan Wu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"}],\"doi\":\"10.1007/978-3-030-60248-2_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"title\":\"Automatic Medical Image Report Generation with Multi-view and Multi-modal Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"venue\":\"ICA3PP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48773674\",\"name\":\"Lydia Weiland\"},{\"authorId\":\"2680937\",\"name\":\"Ioana Hulpus\"},{\"authorId\":\"1801255\",\"name\":\"Simone Paolo Ponzetto\"},{\"authorId\":\"145798497\",\"name\":\"Laura Dietz\"}],\"doi\":\"10.1007/978-3-319-51814-5_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffa8e426856b312e38bd1de223ed9fad0be77630\",\"title\":\"Using Object Detection, NLP, and Knowledge Bases to Understand the Message of Images\",\"url\":\"https://www.semanticscholar.org/paper/ffa8e426856b312e38bd1de223ed9fad0be77630\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780690\",\"name\":\"Baolin Peng\"},{\"authorId\":\"1727524\",\"name\":\"Michael L. Seltzer\"},{\"authorId\":\"144900671\",\"name\":\"Y. C. Ju\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/V1/E17-1043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49a223852c163662cddc1f0beded8a919afc19a9\",\"title\":\"May I take your order? A Neural Model for Extracting Structured Information from Conversations\",\"url\":\"https://www.semanticscholar.org/paper/49a223852c163662cddc1f0beded8a919afc19a9\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":\"1701.02870\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/CVPR.2017.120\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e782437503f2a24fd1a836a434da395bf15c88c2\",\"title\":\"Context-Aware Captions from Context-Agnostic Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e782437503f2a24fd1a836a434da395bf15c88c2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.03895\",\"authors\":[{\"authorId\":\"10730666\",\"name\":\"Siddha Ganju\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"title\":\"What's in a Question: Using Visual Questions as a Form of Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.08298\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2a2818ec251d947acd9c74c2040337e656946bc\",\"title\":\"Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/e2a2818ec251d947acd9c74c2040337e656946bc\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2426718\",\"name\":\"J. Masci\"},{\"authorId\":\"1804261\",\"name\":\"D. Boscaini\"},{\"authorId\":\"1732570\",\"name\":\"M. Bronstein\"},{\"authorId\":\"1697397\",\"name\":\"P. Vandergheynst\"}],\"doi\":\"10.1109/ICCVW.2015.112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a743115795375666593919cbd48590213c229ae9\",\"title\":\"Geodesic Convolutional Neural Networks on Riemannian Manifolds\",\"url\":\"https://www.semanticscholar.org/paper/a743115795375666593919cbd48590213c229ae9\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"35528948\",\"name\":\"M. A. Khan\"}],\"doi\":\"10.1109/ACCESS.2019.2902507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fe47bbcd536bb9ce80661b17dae92f41328e91f\",\"title\":\"ASoVS: Abstractive Summarization of Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/1fe47bbcd536bb9ce80661b17dae92f41328e91f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71787436\",\"name\":\"F. Xiao\"},{\"authorId\":\"144838968\",\"name\":\"Xue Gong\"},{\"authorId\":\"49890762\",\"name\":\"Yiming Zhang\"},{\"authorId\":\"2879323\",\"name\":\"Yanqing Shen\"},{\"authorId\":\"46276957\",\"name\":\"J. Li\"},{\"authorId\":\"1705421\",\"name\":\"Xieping Gao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f5ec7bdce1acf0415e3c3370b4f634ca3d474cb\",\"title\":\"DAA: Dual LSTMs with adaptive attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f5ec7bdce1acf0415e3c3370b4f634ca3d474cb\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3004780\",\"name\":\"A. Ghosh\"},{\"authorId\":\"19773349\",\"name\":\"D. Dutta\"},{\"authorId\":\"151403876\",\"name\":\"Tiyasa Moitra\"}],\"doi\":\"10.1007/978-981-13-7403-6_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09075c1cbba632243727e9c4d964d836a38ddfda\",\"title\":\"A Neural Network Framework to Generate Caption from Images\",\"url\":\"https://www.semanticscholar.org/paper/09075c1cbba632243727e9c4d964d836a38ddfda\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"49725227\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.04.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"title\":\"Stimulus-driven and concept-driven analysis for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1608.02367\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"},{\"authorId\":\"1771769\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1007/978-3-319-46604-0_46\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa76f655c2ad655080593a191c4b479ab9f18117\",\"title\":\"Learning Joint Representations of Videos and Sentences with Web Image Search\",\"url\":\"https://www.semanticscholar.org/paper/aa76f655c2ad655080593a191c4b479ab9f18117\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145542828\",\"name\":\"I. Ram\\u00edrez\"},{\"authorId\":\"1402348047\",\"name\":\"Alfredo Cuesta-Infante\"},{\"authorId\":\"2097662\",\"name\":\"J. Pantrigo\"},{\"authorId\":\"3147668\",\"name\":\"A. S. Montemayor\"},{\"authorId\":\"144369993\",\"name\":\"J. L. Moreno\"},{\"authorId\":\"103412310\",\"name\":\"Valvanera Alonso\"},{\"authorId\":\"87029583\",\"name\":\"G. Anguita\"},{\"authorId\":\"104361825\",\"name\":\"Luciano Palombarani\"}],\"doi\":\"10.1007/s00521-018-3390-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"184809418946dc5cca8e67604b502eeac23bfabb\",\"title\":\"Convolutional neural networks for computer vision-based detection and recognition of dumpsters\",\"url\":\"https://www.semanticscholar.org/paper/184809418946dc5cca8e67604b502eeac23bfabb\",\"venue\":\"Neural Computing and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120800460\",\"name\":\"L. Zhou\"},{\"authorId\":\"98110081\",\"name\":\"J. Gao\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"},{\"authorId\":\"70362337\",\"name\":\"Heung-Yeung Shum\"}],\"doi\":\"10.1162/coli_a_00368\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3737b57e8b739b595cd5b877769cbc719c42f2c7\",\"title\":\"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot\",\"url\":\"https://www.semanticscholar.org/paper/3737b57e8b739b595cd5b877769cbc719c42f2c7\",\"venue\":\"Computational Linguistics\",\"year\":2020},{\"arxivId\":\"1708.02478\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2018.2851077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d78c47093fbf3d85225fd502674aba4a29b3987\",\"title\":\"From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d78c47093fbf3d85225fd502674aba4a29b3987\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"Andrea Apicella\"},{\"authorId\":\"13851143\",\"name\":\"Anna Corazza\"},{\"authorId\":\"34675913\",\"name\":\"Francesco Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.1007/978-3-319-68560-1_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ee6951d8cdb9c2ee5d56d2b3f40296256164d3\",\"title\":\"Exploiting Context Information for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/e7ee6951d8cdb9c2ee5d56d2b3f40296256164d3\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":\"1810.12097\",\"authors\":[{\"authorId\":\"51464770\",\"name\":\"Sonam Damani\"},{\"authorId\":\"38731539\",\"name\":\"N. Raviprakash\"},{\"authorId\":\"1952900\",\"name\":\"U. Gupta\"},{\"authorId\":\"2463157\",\"name\":\"A. Chatterjee\"},{\"authorId\":\"47309386\",\"name\":\"Meghana Joshi\"},{\"authorId\":\"51496146\",\"name\":\"Khyatti Gupta\"},{\"authorId\":\"34749306\",\"name\":\"Kedhar Nath Narahari\"},{\"authorId\":\"40039923\",\"name\":\"P. Agrawal\"},{\"authorId\":\"2031480\",\"name\":\"Manoj Kumar Chinnakotla\"},{\"authorId\":\"25129379\",\"name\":\"S. Magapu\"},{\"authorId\":\"72192115\",\"name\":\"A. Mathur\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3e670b020c106d2d43b8d47b75482533223cae3\",\"title\":\"Ruuh: A Deep Learning Based Conversational Social Agent\",\"url\":\"https://www.semanticscholar.org/paper/e3e670b020c106d2d43b8d47b75482533223cae3\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19268185\",\"name\":\"Niange Yu\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"38524079\",\"name\":\"Binheng Song\"},{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"39665190\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2018.2889922\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"title\":\"Topic-Oriented Image Captioning Based on Order-Embedding\",\"url\":\"https://www.semanticscholar.org/paper/d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1908.07274\",\"authors\":[{\"authorId\":\"48723079\",\"name\":\"Y. Zeng\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"145527704\",\"name\":\"Zhe Lin\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/ICCV.2019.00733\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d08c7e556071e87eea263abe9393405501457ea4\",\"title\":\"Towards High-Resolution Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d08c7e556071e87eea263abe9393405501457ea4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97636424\",\"name\":\"G. Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144303230\",\"name\":\"Ping Liu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICCV.2019.00902\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"title\":\"Entangled Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"}],\"doi\":\"10.1145/3313831.3376404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4501c700e6aefb261efa50a46e1b9091e175cad2\",\"title\":\"\\\"Person, Shoes, Tree. Is the Person Naked?\\\" What People with Vision Impairments Want in Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4501c700e6aefb261efa50a46e1b9091e175cad2\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":\"1805.08969\",\"authors\":[{\"authorId\":\"47871644\",\"name\":\"Pei Guo\"},{\"authorId\":\"24884535\",\"name\":\"C. Anderson\"},{\"authorId\":\"46199465\",\"name\":\"Kolten Pearson\"},{\"authorId\":\"49791682\",\"name\":\"Ryan Farrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a223fc8cd3e7ca19255ff31a3494fedb09c7bfd\",\"title\":\"Neural Network Interpretation via Fine Grained Textual Summarization\",\"url\":\"https://www.semanticscholar.org/paper/4a223fc8cd3e7ca19255ff31a3494fedb09c7bfd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.11701\",\"authors\":[{\"authorId\":\"84039136\",\"name\":\"P. Sadler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60d6e35891baa34282433546df0449d7422ce98\",\"title\":\"Spatial Attention as an Interface for Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b60d6e35891baa34282433546df0449d7422ce98\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"1890615\",\"name\":\"Y. Huo\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1145/2964284.2984064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f28cd3ad13fe0b3e94d7c49886648fb164601f20\",\"title\":\"Early Embedding and Late Reranking for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f28cd3ad13fe0b3e94d7c49886648fb164601f20\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362315\",\"name\":\"J. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"},{\"authorId\":\"47789939\",\"name\":\"J. Lu\"}],\"doi\":\"10.1109/ICC40277.2020.9149264\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a5a6c759925570ab178c45340d34174fc8760f3\",\"title\":\"Local-to-Global Semantic Supervised Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3a5a6c759925570ab178c45340d34174fc8760f3\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31196120\",\"name\":\"Lizhao Gao\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"}],\"doi\":\"10.1145/3195106.3195114\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3adf719a5f451a61e98823783b5f2e049bbffa2d\",\"title\":\"Image Captioning with Scene-graph Based Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/3adf719a5f451a61e98823783b5f2e049bbffa2d\",\"venue\":\"ICMLC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"title\":\"Unsupervised Learning of Spoken Language with Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2993077\",\"name\":\"Sebastien Delecraz\"},{\"authorId\":\"1403823070\",\"name\":\"L. Becerra-Bonache\"},{\"authorId\":\"1840417318\",\"name\":\"Beno\\u00eet Favre\"},{\"authorId\":\"1842327445\",\"name\":\"Alexis Nasr\"},{\"authorId\":\"1842339203\",\"name\":\"Frederic Bechet\"}],\"doi\":\"10.1007/s11063-020-10314-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fb0979f8dda369220bc6772fa16068e64a9b82c\",\"title\":\"Multimodal Machine Learning for Natural Language Processing: Disambiguating Prepositional Phrase Attachments with Images\",\"url\":\"https://www.semanticscholar.org/paper/8fb0979f8dda369220bc6772fa16068e64a9b82c\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2301765\",\"name\":\"Tsung-Wei Ke\"},{\"authorId\":\"3172276\",\"name\":\"Che-Wei Lin\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"14489533\",\"name\":\"D. Geiger\"}],\"doi\":\"10.1007/978-3-319-54190-7_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1df74a5047e953766fa07dec356bba285c605a1\",\"title\":\"Variational Convolutional Networks for Human-Centric Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d1df74a5047e953766fa07dec356bba285c605a1\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1608.00507\",\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"145527700\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/s11263-017-1059-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7361e42c5eb0d5438c4294cc7ea3f9a53d326309\",\"title\":\"Top-Down Neural Attention by Excitation Backprop\",\"url\":\"https://www.semanticscholar.org/paper/7361e42c5eb0d5438c4294cc7ea3f9a53d326309\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1704.01502\",\"authors\":[{\"authorId\":\"145314568\",\"name\":\"Zhiqiang Shen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"},{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"3700393\",\"name\":\"Minjun Li\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2017.548\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"title\":\"Weakly Supervised Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1704.03114\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2017.352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fcd93997b7dde90594dc1caa27ba9d560bbe63d\",\"title\":\"Detecting Visual Relationships with Deep Relational Networks\",\"url\":\"https://www.semanticscholar.org/paper/5fcd93997b7dde90594dc1caa27ba9d560bbe63d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543226\",\"name\":\"Xiaoxiao Liu\"},{\"authorId\":\"40096492\",\"name\":\"Q. Xu\"},{\"authorId\":null,\"name\":\"Ning Wang\"}],\"doi\":\"10.1007/s00371-018-1566-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f79c03f977d1c9acb71d87301272682422b0b14f\",\"title\":\"A survey on deep neural network-based image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79c03f977d1c9acb71d87301272682422b0b14f\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":\"1512.06974\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2016.320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a0a00380c13002b330c70be2802904c4f31064f\",\"title\":\"Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels\",\"url\":\"https://www.semanticscholar.org/paper/7a0a00380c13002b330c70be2802904c4f31064f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1707.06320\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"2480903\",\"name\":\"Alexis Conneau\"},{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"1729762\",\"name\":\"M. Nickel\"}],\"doi\":\"10.18653/v1/N18-1038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f269968ee8192f3cf663efd6d1dcdff22aabdefe\",\"title\":\"Learning Visually Grounded Sentence Representations\",\"url\":\"https://www.semanticscholar.org/paper/f269968ee8192f3cf663efd6d1dcdff22aabdefe\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46413437\",\"name\":\"Xiangfang Zeng\"},{\"authorId\":\"35661244\",\"name\":\"Xiaodong Wang\"}],\"doi\":\"10.1109/ICCCBDA.2017.7951934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69c36275ddf2ea95ea4ac39b4d41079c13827281\",\"title\":\"Add English to image Chinese captioning\",\"url\":\"https://www.semanticscholar.org/paper/69c36275ddf2ea95ea4ac39b4d41079c13827281\",\"venue\":\"2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3274223\",\"name\":\"Abhijit Bendale\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56caae37ed0cf1b7384c17141212bc3cf8845b6a\",\"title\":\"Open World Recognition\",\"url\":\"https://www.semanticscholar.org/paper/56caae37ed0cf1b7384c17141212bc3cf8845b6a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143901333\",\"name\":\"Lin Shao\"},{\"authorId\":\"2178889\",\"name\":\"Toki Migimatsu\"},{\"authorId\":\"153441749\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1990958\",\"name\":\"Karen Yang\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.15607/rss.2020.xvi.082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c328a1ea31eaa4b357e584285ffb6ff2671b5bd4\",\"title\":\"Concept2Robot: Learning Manipulation Concepts from Instructions and Human Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/c328a1ea31eaa4b357e584285ffb6ff2671b5bd4\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a645bcd029cc5ce21b973146f21a9655047cc96\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Linguistic Cues\",\"url\":\"https://www.semanticscholar.org/paper/1a645bcd029cc5ce21b973146f21a9655047cc96\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34153289\",\"name\":\"Anqi Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3226037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f164313e63d5c6d0a5f4b55fd0ffcc25c436bc14\",\"title\":\"Image Captioning with Affective Guiding and Selective Attention\",\"url\":\"https://www.semanticscholar.org/paper/f164313e63d5c6d0a5f4b55fd0ffcc25c436bc14\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/CVPR.2015.7298966\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"title\":\"Deep correlation for matching images and text\",\"url\":\"https://www.semanticscholar.org/paper/efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1807.03514\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1109/ICIP.2018.8451083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdab688a49bb873d36ae638c647d6ca9e3d75d18\",\"title\":\"Topic-Guided Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fdab688a49bb873d36ae638c647d6ca9e3d75d18\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1809.08267\",\"authors\":[{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/3209978.3210183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83e567c2822aeda91006096a5d7ac0b34721d2a5\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/83e567c2822aeda91006096a5d7ac0b34721d2a5\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3321318\",\"name\":\"W. Liu\"},{\"authorId\":\"2263674\",\"name\":\"Yidong Li\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/ACCESS.2018.2886597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40c97ba0f8c50cae18151901c0ea2504bba4e79b\",\"title\":\"An Attribute-Based High-Level Image Representation for Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/40c97ba0f8c50cae18151901c0ea2504bba4e79b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31465302\",\"name\":\"E. Wang\"},{\"authorId\":\"46182609\",\"name\":\"X. Zhang\"},{\"authorId\":\"39907479\",\"name\":\"F. Wang\"},{\"authorId\":\"1682589\",\"name\":\"T. Wu\"},{\"authorId\":\"144404748\",\"name\":\"Chien-Ming Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2917771\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"title\":\"Multilayer Dense Attention Model for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df40d057b584de2cf74123a2ef4274de582d6b03\",\"title\":\"Detailed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df40d057b584de2cf74123a2ef4274de582d6b03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.03169\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"67001969\",\"name\":\"Mahmoud Elsayed\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7af5c94fedc32f3104a08301a46c62f51b044a81\",\"title\":\"Look and Modify: Modification Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7af5c94fedc32f3104a08301a46c62f51b044a81\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31041364\",\"name\":\"Thanh-Trung Phan\"},{\"authorId\":\"145504160\",\"name\":\"S. Muralidhar\"},{\"authorId\":\"1403029865\",\"name\":\"D. Gatica-Perez\"}],\"doi\":\"10.1145/3329189.3329193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cab83f9b7ca0e5dccacc952522b92786b5b3d5b\",\"title\":\"#Drink Or #Drunk: Multimodal Signals and Drinking Practices on Instagram\",\"url\":\"https://www.semanticscholar.org/paper/7cab83f9b7ca0e5dccacc952522b92786b5b3d5b\",\"venue\":\"PervasiveHealth\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1419474253\",\"name\":\"Md Asifuzzaman Jishan\"},{\"authorId\":\"102857185\",\"name\":\"K. R. Mahmud\"},{\"authorId\":\"48058214\",\"name\":\"A. K. Azad\"}],\"doi\":\"10.11591/ijece.v9i4.pp2932-2940\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f51c42bc6d52e7d46c348c67f1f7b2cc1534f63\",\"title\":\"Natural language description of images using hybrid recurrent neural network\",\"url\":\"https://www.semanticscholar.org/paper/1f51c42bc6d52e7d46c348c67f1f7b2cc1534f63\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12271314\",\"name\":\"Chenwei Tang\"},{\"authorId\":\"2053666\",\"name\":\"J. Lv\"},{\"authorId\":\"47558162\",\"name\":\"Y. Chen\"},{\"authorId\":\"34809813\",\"name\":\"J. Guo\"}],\"doi\":\"10.1007/S00500-018-3051-Y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4d99da5e3523ac174cc554441bf293b8c39bba3\",\"title\":\"An angle-based method for measuring the semantic similarity between visual and textual features\",\"url\":\"https://www.semanticscholar.org/paper/e4d99da5e3523ac174cc554441bf293b8c39bba3\",\"venue\":\"Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014498\",\"name\":\"Q. Liu\"},{\"authorId\":\"50580380\",\"name\":\"Yingying Chen\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"27356041\",\"name\":\"Sijiong Zhang\"}],\"doi\":\"10.1007/978-981-10-8530-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b31a49cfbc04f0b5ee174db72f1dc001c42b156f\",\"title\":\"Joint Visual Context for Pedestrian Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b31a49cfbc04f0b5ee174db72f1dc001c42b156f\",\"venue\":\"ICIMCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52270988\",\"name\":\"C. Chaudhari\"},{\"authorId\":\"34265148\",\"name\":\"S. Devane\"}],\"doi\":\"10.1007/978-981-13-1513-8_100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd78eecdc7249ebab6585f928f70fe75a1079b0c\",\"title\":\"Captioning the Images: A Deep Analysis\",\"url\":\"https://www.semanticscholar.org/paper/cd78eecdc7249ebab6585f928f70fe75a1079b0c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.10616\",\"authors\":[{\"authorId\":\"3057169\",\"name\":\"Chakaveh Saedi\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e12fcb1ae4905cb8d263fb07f74bbdfa68ca22a\",\"title\":\"Siamese Networks for Large-Scale Author Identification\",\"url\":\"https://www.semanticscholar.org/paper/5e12fcb1ae4905cb8d263fb07f74bbdfa68ca22a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/W18-6547\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"657ae9ecb59cb2a27e57784577a9efb60de81126\",\"title\":\"The Task Matters: Comparing Image Captioning and Task-Based Dialogical Image Description\",\"url\":\"https://www.semanticscholar.org/paper/657ae9ecb59cb2a27e57784577a9efb60de81126\",\"venue\":\"INLG\",\"year\":2018},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471727570\",\"name\":\"Oh Weon Geun\"},{\"authorId\":\"1410552374\",\"name\":\"Ko Jong-Gook\"}],\"doi\":\"10.1109/ictc46691.2019.8939893\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fe26f3564673fa5709a5bb0648b23e86fed682d\",\"title\":\"Visual Narrative Technology of Paintings Based on Image Objects\",\"url\":\"https://www.semanticscholar.org/paper/4fe26f3564673fa5709a5bb0648b23e86fed682d\",\"venue\":\"2019 International Conference on Information and Communication Technology Convergence (ICTC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1706.01231\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"153757316\",\"name\":\"Zhao Guo\"},{\"authorId\":\"144973314\",\"name\":\"Wu Liu\"},{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.24963/ijcai.2017/381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"title\":\"Hierarchical LSTM with Adjusted Temporal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900967\",\"name\":\"U. Zia\"},{\"authorId\":\"145759322\",\"name\":\"M. M. Riaz\"},{\"authorId\":\"144683577\",\"name\":\"A. Ghafoor\"},{\"authorId\":\"145602758\",\"name\":\"Seyyed Salehi Seyyed Ali\"}],\"doi\":\"10.1007/s00521-019-04587-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"title\":\"Topic sensitive image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"2005.00596\",\"authors\":[{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"3330139\",\"name\":\"J. Silovsk\\u00fd\"},{\"authorId\":\"143882614\",\"name\":\"M. Siu\"},{\"authorId\":\"144339076\",\"name\":\"W. Hartmann\"},{\"authorId\":\"1793645\",\"name\":\"H. Gish\"},{\"authorId\":\"32484187\",\"name\":\"S. Adali\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d4ead18fc29e22a5f8b4d42e2f6041861b65b58\",\"title\":\"Learning from Noisy Labels with Noise Modeling Network\",\"url\":\"https://www.semanticscholar.org/paper/0d4ead18fc29e22a5f8b4d42e2f6041861b65b58\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.03409\",\"authors\":[{\"authorId\":\"79953458\",\"name\":\"Haoshuo Huang\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"18138802\",\"name\":\"Harsh Mehta\"},{\"authorId\":\"31702389\",\"name\":\"Alexander Ku\"},{\"authorId\":\"145181836\",\"name\":\"Gabriel Magalh\\u00e3es\"},{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"}],\"doi\":\"10.1109/ICCV.2019.00750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c351e405660f09ded4ba2bd05a2362be292a3da3\",\"title\":\"Transferable Representation Learning in Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c351e405660f09ded4ba2bd05a2362be292a3da3\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"}],\"doi\":\"10.15781/T2QR4P68H\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"title\":\"Natural Language Video Description using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1510.01431\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"title\":\"SentiCap: Generating Image Descriptions with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2175808\",\"name\":\"Ramesh R. Manuvinakurike\"},{\"authorId\":\"2061232\",\"name\":\"C. Kennington\"},{\"authorId\":\"144662324\",\"name\":\"D. DeVault\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/W16-3630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4898430211fe7895f98436d56162cefacf0c4326\",\"title\":\"Real-Time Understanding of Complex Discriminative Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4898430211fe7895f98436d56162cefacf0c4326\",\"venue\":\"SIGDIAL Conference\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2762725\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b74d80faa4e4c95e44523d49f238dc40514d8b7c\",\"title\":\"Artificial Intelligence in the Rising Wave of Deep Learning: The Historical Path and Future Outlook [Perspectives]\",\"url\":\"https://www.semanticscholar.org/paper/b74d80faa4e4c95e44523d49f238dc40514d8b7c\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2784591\",\"name\":\"Zetao Chen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1867220\",\"name\":\"I. Sa\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"},{\"authorId\":\"1885768\",\"name\":\"M. Chli\"}],\"doi\":\"10.1109/LRA.2018.2859916\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c452daa8766e1438835d4f664e4feef7fd8e5e01\",\"title\":\"Learning Context Flexible Attention Model for Long-Term Visual Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c452daa8766e1438835d4f664e4feef7fd8e5e01\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49035023\",\"name\":\"T. Nguyen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"title\":\"Automatic Video Captioning using Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2993077\",\"name\":\"Sebastien Delecraz\"},{\"authorId\":\"2017150\",\"name\":\"Leonor Becerra-Bonache\"},{\"authorId\":\"144155256\",\"name\":\"B. Favre\"},{\"authorId\":\"144551937\",\"name\":\"A. Nasr\"},{\"authorId\":\"1725420\",\"name\":\"Fr\\u00e9d\\u00e9ric B\\u00e9chet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07fcc9b66aeda6f84f8a1595ab50f6ad6906c40e\",\"title\":\"Correction automatique d'attachements pr\\u00e9positionnels par utilisation de traits visuels (PP-attachement resolution using visual features)\",\"url\":\"https://www.semanticscholar.org/paper/07fcc9b66aeda6f84f8a1595ab50f6ad6906c40e\",\"venue\":\"CORIA-TALN-RJC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/ICCV.2015.277\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c3640aae13e344ad70a926510221dada626a44de\",\"title\":\"Guiding the Long-Short Term Memory Model for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/c3640aae13e344ad70a926510221dada626a44de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1509.08075\",\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/ICCV.2015.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a2945a2bcdd2f712aa58e6907cd985191ed672b\",\"title\":\"Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing\",\"url\":\"https://www.semanticscholar.org/paper/6a2945a2bcdd2f712aa58e6907cd985191ed672b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"}],\"doi\":\"10.14288/1.0343522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"580d8b18269ffda8ac08b9a31299e5bb4cec329d\",\"title\":\"Deep learning for sequence modelling : applications in natural languages and distributed compressive sensing\",\"url\":\"https://www.semanticscholar.org/paper/580d8b18269ffda8ac08b9a31299e5bb4cec329d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8153177\",\"name\":\"J. Lee\"},{\"authorId\":\"2772676\",\"name\":\"Sanghoon Jun\"},{\"authorId\":\"19305738\",\"name\":\"Young-Won Cho\"},{\"authorId\":\"46900979\",\"name\":\"H. Lee\"},{\"authorId\":\"38628528\",\"name\":\"G. Kim\"},{\"authorId\":\"46844846\",\"name\":\"J. Seo\"},{\"authorId\":\"145979410\",\"name\":\"N. Kim\"}],\"doi\":\"10.3348/kjr.2017.18.4.570\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"265644f1b6740ca34bfbe9762b90b33021adde62\",\"title\":\"Deep Learning in Medical Imaging: General Overview\",\"url\":\"https://www.semanticscholar.org/paper/265644f1b6740ca34bfbe9762b90b33021adde62\",\"venue\":\"Korean journal of radiology\",\"year\":2017},{\"arxivId\":\"1912.01447\",\"authors\":[{\"authorId\":\"145908975\",\"name\":\"X. Shen\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"3493947\",\"name\":\"Anfeng He\"},{\"authorId\":\"3141359\",\"name\":\"Shaoyan Sun\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1145/2964284.2964316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"346e044735c9c862bf9687e36bab466d290f91ab\",\"title\":\"Transform-Invariant Convolutional Neural Networks for Image Classification and Search\",\"url\":\"https://www.semanticscholar.org/paper/346e044735c9c862bf9687e36bab466d290f91ab\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACVW.2019.00011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1904.06861\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/CVPR.2019.00646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"title\":\"Self-Critical N-Step Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.01976\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"}],\"doi\":\"10.1109/ICCVW.2019.00551\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"title\":\"Do Cross Modal Systems Leverage Semantic Relationships?\",\"url\":\"https://www.semanticscholar.org/paper/5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09a63dacd10be7d43087cb697d4f46fd8afc2e2b\",\"title\":\"The Art of Deep Connection - Towards Natural and Pragmatic Conversational Agent Interactions\",\"url\":\"https://www.semanticscholar.org/paper/09a63dacd10be7d43087cb697d4f46fd8afc2e2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020137\",\"name\":\"Farnaz Abtahi\"},{\"authorId\":\"3094813\",\"name\":\"T. Ro\"},{\"authorId\":\"48625314\",\"name\":\"Wei Li\"},{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"}],\"doi\":\"10.1109/WACV.2018.00008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7ff9b22715ee5f19303b028b245a35fc13cba07\",\"title\":\"Emotion Analysis Using Audio/Video, EMG and EEG: A Dataset and Comparison Study\",\"url\":\"https://www.semanticscholar.org/paper/d7ff9b22715ee5f19303b028b245a35fc13cba07\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2002.09536\",\"authors\":[{\"authorId\":\"38672865\",\"name\":\"M. Seshadri\"},{\"authorId\":\"145311801\",\"name\":\"M. Srikanth\"},{\"authorId\":\"1901449\",\"name\":\"M. Belov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4aaa61d7e56f42833aaae788544704c46dcb9e\",\"title\":\"Image to Language Understanding: Captioning approach\",\"url\":\"https://www.semanticscholar.org/paper/ad4aaa61d7e56f42833aaae788544704c46dcb9e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"145414746\",\"name\":\"Kun Fu\"},{\"authorId\":\"143900006\",\"name\":\"Lei Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851721\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"title\":\"Image Captioning with Partially Rewarded Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1804.00887\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3dc2c3be0796f65154d2106ed4442889c84546df\",\"title\":\"Learning to Guide Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3dc2c3be0796f65154d2106ed4442889c84546df\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461583\",\"name\":\"Kun Zhang\"},{\"authorId\":\"2767360\",\"name\":\"Guangyi Lv\"},{\"authorId\":\"2688093\",\"name\":\"Le Wu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"50384171\",\"name\":\"Qi Liu\"},{\"authorId\":\"46476917\",\"name\":\"H. Wu\"},{\"authorId\":\"2397264\",\"name\":\"Fangzhao Wu\"}],\"doi\":\"10.1109/ICDM.2018.00090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebc2038a264574055ad6b5aa9beec903eba81130\",\"title\":\"Image-Enhanced Multi-level Sentence Representation Net for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/ebc2038a264574055ad6b5aa9beec903eba81130\",\"venue\":\"2018 IEEE International Conference on Data Mining (ICDM)\",\"year\":2018},{\"arxivId\":\"1811.10092\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"title\":\"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"title\":\"Visual context for verb sense disambiguation and multilingual representation learning\",\"url\":\"https://www.semanticscholar.org/paper/49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34532042\",\"name\":\"Federico Maria Cau\"},{\"authorId\":\"2598389\",\"name\":\"L. D. Spano\"},{\"authorId\":\"1803171\",\"name\":\"N. Tintarev\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37e4ab1e776954df073c8178069e1ca914d95b95\",\"title\":\"Considerations for Applying Logical Reasoning to Explain Neural Network Outputs\",\"url\":\"https://www.semanticscholar.org/paper/37e4ab1e776954df073c8178069e1ca914d95b95\",\"venue\":\"XAI.it@AI*IA\",\"year\":2020},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"2012.13095\",\"authors\":[{\"authorId\":\"48607882\",\"name\":\"Yuhuan Wu\"},{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"3459992\",\"name\":\"Jiawang Bian\"},{\"authorId\":\"15420514\",\"name\":\"Yu-chao Gu\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"901bff8a8aca0b1772bc4352c2939f98d21e1b8b\",\"title\":\"MobileSal: Extremely Efficient RGB-D Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/901bff8a8aca0b1772bc4352c2939f98d21e1b8b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97596665\",\"name\":\"Y. Liu\"},{\"authorId\":\"1893018986\",\"name\":\"Jianbing Shen\"},{\"authorId\":\"2198278\",\"name\":\"Haibo He\"}],\"doi\":\"10.1016/j.neucom.2020.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f618c59afc050e03c18a060da466d052e828607b\",\"title\":\"Multi-attention deep reinforcement learning and re-ranking for vehicle re-identification\",\"url\":\"https://www.semanticscholar.org/paper/f618c59afc050e03c18a060da466d052e828607b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"48885685\",\"name\":\"Shihui Duan\"},{\"authorId\":\"50394327\",\"name\":\"F. Long\"},{\"authorId\":null,\"name\":\"Yongxing Wang\"},{\"authorId\":\"47673446\",\"name\":\"S. Wang\"},{\"authorId\":\"40177644\",\"name\":\"Q. Ling\"}],\"doi\":\"10.23919/CCC50068.2020.9188494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6b9ec747a1ce104810b89ee0947dcbf6b0a244a\",\"title\":\"Two-Stream Convolutional Neural Networks for Emergency Recognition in Images\",\"url\":\"https://www.semanticscholar.org/paper/f6b9ec747a1ce104810b89ee0947dcbf6b0a244a\",\"venue\":\"2020 39th Chinese Control Conference (CCC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691021\",\"name\":\"Antoine Bosselut\"},{\"authorId\":\"7557441\",\"name\":\"J. Chen\"},{\"authorId\":\"145873830\",\"name\":\"D. Warren\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/P16-1167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6a5f61942da1653725315dc23b1bd399b056d97\",\"title\":\"Learning Prototypical Event Structure from Photo Albums\",\"url\":\"https://www.semanticscholar.org/paper/f6a5f61942da1653725315dc23b1bd399b056d97\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1806.06004\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceabd7ff28ce2d501511da998252aeb938adc98b\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ceabd7ff28ce2d501511da998252aeb938adc98b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"78507285\",\"name\":\"Zhiping Zhou\"},{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/s11042-019-08165-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"title\":\"An image retrieval method based on semantic matching with multiple positional representations\",\"url\":\"https://www.semanticscholar.org/paper/0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116506812\",\"name\":\"Bhaskar Mitra\"},{\"authorId\":\"1703980\",\"name\":\"Nick Craswell\"}],\"doi\":\"10.1145/3018661.3022755\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e700355bce4d8637c5dd6656a77c8c67bcd0770\",\"title\":\"Neural Text Embeddings for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2e700355bce4d8637c5dd6656a77c8c67bcd0770\",\"venue\":\"WSDM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10798523\",\"name\":\"C. C. Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/TPAMI.2018.2824816\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"title\":\"Towards Personalized Image Captioning via Multimodal Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"1848462\",\"name\":\"Yarong Han\"},{\"authorId\":\"144530696\",\"name\":\"Li Wan\"},{\"authorId\":\"144025048\",\"name\":\"Xing Zhou\"},{\"authorId\":\"144975798\",\"name\":\"Min Deng\"}],\"doi\":\"10.1080/01431161.2019.1594439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"title\":\"Geospatial relation captioning for high-spatial-resolution images by using an attention-based neural network\",\"url\":\"https://www.semanticscholar.org/paper/baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1705.11001\",\"authors\":[{\"authorId\":\"143786724\",\"name\":\"Kevin Lin\"},{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"50045602\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144463556\",\"name\":\"M. Sun\"},{\"authorId\":\"51064498\",\"name\":\"Zhengyou Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a88f86093e6f2d14761d4b8cbdcadfeff496c948\",\"title\":\"Adversarial Ranking for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/a88f86093e6f2d14761d4b8cbdcadfeff496c948\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1709.08624\",\"authors\":[{\"authorId\":\"15563286\",\"name\":\"Jiaxian Guo\"},{\"authorId\":\"26386237\",\"name\":\"S. Lu\"},{\"authorId\":\"145834074\",\"name\":\"Han Cai\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"},{\"authorId\":\"39811558\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"485552d2711868b54d5fcddc92c746b09afeab07\",\"title\":\"Long Text Generation via Adversarial Training with Leaked Information\",\"url\":\"https://www.semanticscholar.org/paper/485552d2711868b54d5fcddc92c746b09afeab07\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1601.06823\",\"authors\":[{\"authorId\":\"47939010\",\"name\":\"Feng Wang\"},{\"authorId\":\"2743835\",\"name\":\"D. Tax\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f660ea723b62f69b9f4c439724a6b73357e1d3c3\",\"title\":\"Survey on the attention based RNN model and its applications in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/f660ea723b62f69b9f4c439724a6b73357e1d3c3\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.01393\",\"authors\":[{\"authorId\":\"145399579\",\"name\":\"Karan Sharma\"},{\"authorId\":\"30512587\",\"name\":\"Arun C. S. Kumar\"},{\"authorId\":\"3422895\",\"name\":\"Suchendra M. Bhandarkar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad9b3dc6c0e54070cec79df86458ed38566da1ff\",\"title\":\"Automated Image Captioning for Rapid Prototyping and Resource Constrained Environments\",\"url\":\"https://www.semanticscholar.org/paper/ad9b3dc6c0e54070cec79df86458ed38566da1ff\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703980\",\"name\":\"Nick Craswell\"},{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1777025\",\"name\":\"J. Guo\"},{\"authorId\":\"116506812\",\"name\":\"Bhaskar Mitra\"},{\"authorId\":\"1696030\",\"name\":\"M. Rijke\"}],\"doi\":\"10.1145/3053408.3053425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5f781a2050fa513f7e6de2d6aa99ab079be540b\",\"title\":\"Report on the SIGIR 2016 Workshop on Neural Information Retrieval (Neu-IR)\",\"url\":\"https://www.semanticscholar.org/paper/b5f781a2050fa513f7e6de2d6aa99ab079be540b\",\"venue\":\"SIGIR Forum\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"J. Laaksonen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"title\":\"Can Saliency Information Benefit Image Captioning Models?\",\"url\":\"https://www.semanticscholar.org/paper/204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tarfah Alrashid\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70327c8228b508388f96bd70d7dbdf3943c8437e\",\"title\":\"Annotating and Recognising Visually Descriptive Language\",\"url\":\"https://www.semanticscholar.org/paper/70327c8228b508388f96bd70d7dbdf3943c8437e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1707.09472\",\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2017.554\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"title\":\"Weakly-Supervised Learning of Visual Relations\",\"url\":\"https://www.semanticscholar.org/paper/5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27139174\",\"name\":\"Elliot Salisbury\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.24963/ijcai.2018/751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98e69c8786cc6cb44e4b6751f2ab8f6d089db85f\",\"title\":\"Evaluating and Complementing Vision-to-Language Technology for People who are Blind with Conversational Crowdsourcing\",\"url\":\"https://www.semanticscholar.org/paper/98e69c8786cc6cb44e4b6751f2ab8f6d089db85f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1109/CVPRW.2018.00260\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bd5fceb1f885f690f63a58c289607c85069be3d\",\"title\":\"Image Caption Generation with Hierarchical Contextual Visual Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bd5fceb1f885f690f63a58c289607c85069be3d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34682444\",\"name\":\"Anshu Rajendra\"},{\"authorId\":\"3025014\",\"name\":\"R. Rajendra\"},{\"authorId\":\"144486305\",\"name\":\"O. Mengshoel\"},{\"authorId\":\"143629822\",\"name\":\"M. Zeng\"},{\"authorId\":\"48173075\",\"name\":\"Momina Haider\"}],\"doi\":\"10.1109/DSAA.2018.00054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de7b1f601de3c3205d3a640934ad4ce81a595397\",\"title\":\"Captioning with Language-Based Attention\",\"url\":\"https://www.semanticscholar.org/paper/de7b1f601de3c3205d3a640934ad4ce81a595397\",\"venue\":\"2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc8df4ad35282ccf19261e02de87d8e35c956537\",\"title\":\"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fc8df4ad35282ccf19261e02de87d8e35c956537\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317148\",\"name\":\"Z. Zhang\"},{\"authorId\":null,\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213537\",\"name\":\"X. Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7937ad963f18675d2dc802d94f672180c037fde\",\"title\":\"Color dark Taxonomy nightdress Length short Material cotton Type casual Color beige Taxonomy nightdress Length mini Material silk Type patchwork Color dark Taxonomy nightdress Length\",\"url\":\"https://www.semanticscholar.org/paper/a7937ad963f18675d2dc802d94f672180c037fde\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Huang\"},{\"authorId\":\"51231229\",\"name\":\"Fengqi Yan\"},{\"authorId\":\"40515617\",\"name\":\"W. Xu\"},{\"authorId\":\"1716059\",\"name\":\"M. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2947134\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12e9fb63e5b46b241fed3ab2e9d95219db80e056\",\"title\":\"Multi-Attention and Incorporating Background Information Model for Chest X-Ray Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/12e9fb63e5b46b241fed3ab2e9d95219db80e056\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DM Blei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4571196dc5da7a3288c1ac8cc771da0d62cbb99a\",\"title\":\"Bimodal Modelling of Source Code and Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/4571196dc5da7a3288c1ac8cc771da0d62cbb99a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144168152\",\"name\":\"Q. Cai\"},{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"40569887\",\"name\":\"X. Zhang\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"145259074\",\"name\":\"W. Shao\"},{\"authorId\":null,\"name\":\"Lei Wang\"}],\"doi\":\"10.1007/978-981-10-7299-4_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd8c8dfc6ab8ba3c96834b04cd55ce83972de4a4\",\"title\":\"A Novel Framework for Image Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/dd8c8dfc6ab8ba3c96834b04cd55ce83972de4a4\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1711.06032\",\"authors\":[{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"2355388\",\"name\":\"S. Lin\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"}],\"doi\":\"10.1109/CVPRW.2019.00058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92650fcd4c288934e7b08c18a86c5cb63f5ce1ae\",\"title\":\"Natural Language Guided Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/92650fcd4c288934e7b08c18a86c5cb63f5ce1ae\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1702.05658\",\"authors\":[{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"39369840\",\"name\":\"Feng Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.24963/ijcai.2017/563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2498124e6466ccde28c95477c923e7cd5843f4c0\",\"title\":\"MAT: A Multimodal Attentive Translator for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2498124e6466ccde28c95477c923e7cd5843f4c0\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1501.02741\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"49712326\",\"name\":\"M. Cheng\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"97483166\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TIP.2015.2487833\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1260c42b86dcbe123ccc038857cd3b14e146032\",\"title\":\"Salient Object Detection: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/a1260c42b86dcbe123ccc038857cd3b14e146032\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3176559\",\"name\":\"Pepi Stavropoulou\"},{\"authorId\":\"1908600\",\"name\":\"D. Spiliotopoulos\"},{\"authorId\":\"1730511\",\"name\":\"G. Kouroupetroglou\"}],\"doi\":\"10.1007/978-3-030-49282-3_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cfd3ed3cbcebecefda6d231aef79476ea11a3ea\",\"title\":\"Voice User Interfaces for Service Robots: Design Principles and Methodology\",\"url\":\"https://www.semanticscholar.org/paper/2cfd3ed3cbcebecefda6d231aef79476ea11a3ea\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1910.01279\",\"authors\":[{\"authorId\":\"153469844\",\"name\":\"H. Wang\"},{\"authorId\":\"50219096\",\"name\":\"Zifan Wang\"},{\"authorId\":\"3432460\",\"name\":\"Mengnan Du\"},{\"authorId\":null,\"name\":\"Fan Yang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"153112833\",\"name\":\"Sirui Ding\"},{\"authorId\":\"3251561\",\"name\":\"Piotr Mardziel\"},{\"authorId\":\"48539382\",\"name\":\"Xia Hu\"}],\"doi\":\"10.1109/CVPRW50498.2020.00020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e56d11bb7b0171a2634c8674ca6981c672c98ef\",\"title\":\"Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5e56d11bb7b0171a2634c8674ca6981c672c98ef\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"153173208\",\"name\":\"J. Xu\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1016/j.patrec.2019.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eaffb8e5f6f8d11d0c5c012980b25829667f6d1\",\"title\":\"Exploring diverse and fine-grained caption for video by incorporating convolutional architecture into LSTM-based model\",\"url\":\"https://www.semanticscholar.org/paper/2eaffb8e5f6f8d11d0c5c012980b25829667f6d1\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.09544\",\"authors\":[{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1016/j.neucom.2018.10.059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dfb603674cc927ba65f056a54738734cbb348b2\",\"title\":\"3G structure for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/7dfb603674cc927ba65f056a54738734cbb348b2\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1805.08191\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1609/aaai.v33i01.33018465\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2b02822cfbc50d17ec5220a19556be9d601c132\",\"title\":\"Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/c2b02822cfbc50d17ec5220a19556be9d601c132\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1702.05729\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1380096226\",\"name\":\"Dayu Yue\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2017.551\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28870e4de79d5086864a9f2c6df632b606ac3347\",\"title\":\"Person Search with Natural Language Description\",\"url\":\"https://www.semanticscholar.org/paper/28870e4de79d5086864a9f2c6df632b606ac3347\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1711.06640\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"38094552\",\"name\":\"Sam Thomson\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2018.00611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"title\":\"Neural Motifs: Scene Graph Parsing with Global Context\",\"url\":\"https://www.semanticscholar.org/paper/0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414742\",\"name\":\"Kun Fu\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TPAMI.2016.2642953\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"title\":\"Aligning Where to See and What to Tell: Image Captioning with Region-Based Attention and Scene-Specific Contexts\",\"url\":\"https://www.semanticscholar.org/paper/afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3132847.3132922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"title\":\"Movie Fill in the Blank with Adaptive Temporal Attention and Description Update\",\"url\":\"https://www.semanticscholar.org/paper/3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145960537\",\"name\":\"W. Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1007/978-981-10-7299-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"title\":\"Relevance and Coherence Based Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1809.06297\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"8774293\",\"name\":\"Shuyang Dai\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"13390301\",\"name\":\"H. Zhang\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"314cb3091043a47d8d10ec08313a2131d3ef3238\",\"title\":\"Adversarial Text Generation via Feature-Mover's Distance\",\"url\":\"https://www.semanticscholar.org/paper/314cb3091043a47d8d10ec08313a2131d3ef3238\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2001.10857\",\"authors\":[{\"authorId\":\"2897459\",\"name\":\"Sebastian Stabinger\"},{\"authorId\":\"38185901\",\"name\":\"Justus Piater\"},{\"authorId\":\"1410954364\",\"name\":\"A. Rodr\\u00edguez-S\\u00e1nchez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c36304005e6c6864111a3e803f34683808ebb8e\",\"title\":\"Evaluating the Progress of Deep Learning for Visual Relational Concepts\",\"url\":\"https://www.semanticscholar.org/paper/5c36304005e6c6864111a3e803f34683808ebb8e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.00901\",\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2017.671\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bbf2a343eda14e6cbf36ba2ae42663c95de37c7\",\"title\":\"Commonly Uncommon: Semantic Sparsity in Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3bbf2a343eda14e6cbf36ba2ae42663c95de37c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51496146\",\"name\":\"Khyatti Gupta\"},{\"authorId\":\"48820833\",\"name\":\"M. Joshi\"},{\"authorId\":\"2463157\",\"name\":\"A. Chatterjee\"},{\"authorId\":\"51464770\",\"name\":\"Sonam Damani\"},{\"authorId\":\"34749306\",\"name\":\"Kedhar Nath Narahari\"},{\"authorId\":\"40039923\",\"name\":\"P. Agrawal\"}],\"doi\":\"10.18653/v1/W19-4112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45efb14c59fd478f5c6e3173632a379273131846\",\"title\":\"Insights from Building an Open-Ended Conversational Agent\",\"url\":\"https://www.semanticscholar.org/paper/45efb14c59fd478f5c6e3173632a379273131846\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.06475\",\"authors\":[{\"authorId\":\"3165417\",\"name\":\"J. Wu\"},{\"authorId\":\"145565491\",\"name\":\"He Zheng\"},{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"47003565\",\"name\":\"Yixin Li\"},{\"authorId\":\"50736086\",\"name\":\"Baoming Yan\"},{\"authorId\":\"143978866\",\"name\":\"R. Liang\"},{\"authorId\":\"46314609\",\"name\":\"Wenjia Wang\"},{\"authorId\":\"14547213\",\"name\":\"Shipei Zhou\"},{\"authorId\":\"33344887\",\"name\":\"Guosen Lin\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"36637369\",\"name\":\"Y. Wang\"},{\"authorId\":\"47904050\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ff40f0760bd8d3c46d72147b0f5b0d4aee2a24f\",\"title\":\"AI Challenger : A Large-scale Dataset for Going Deeper in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3ff40f0760bd8d3c46d72147b0f5b0d4aee2a24f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christopher Elamri\"},{\"authorId\":null,\"name\":\"Teun de Planque\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc61cd90529fede6e1bfb14042d021bc2a076e99\",\"title\":\"Automated Neural Image Caption Generator for Visually Impaired People\",\"url\":\"https://www.semanticscholar.org/paper/cc61cd90529fede6e1bfb14042d021bc2a076e99\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1808.03986\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"49596229\",\"name\":\"S. Kumar\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.18653/v1/D18-1434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"title\":\"Multimodal Differential Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1804.03052\",\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2018.8462396\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f54d9dbad1f60de83485232707c945f209af867e\",\"title\":\"Vision as an Interlingua: Learning Multilingual Semantic Embeddings of Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/f54d9dbad1f60de83485232707c945f209af867e\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1809.09314\",\"authors\":[{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"145810388\",\"name\":\"Zheng Zhou\"},{\"authorId\":\"145149511\",\"name\":\"J. Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/BigData.2018.8622461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5138f2cb6de716880cea11df04a2037c5dac6711\",\"title\":\"How to Become Instagram Famous: Post Popularity Prediction with Dual-Attention\",\"url\":\"https://www.semanticscholar.org/paper/5138f2cb6de716880cea11df04a2037c5dac6711\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"title\":\"Story Understanding through Semantic Analysis and Automatic Alignment of Text and Video\",\"url\":\"https://www.semanticscholar.org/paper/39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181816\",\"name\":\"Jianming Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3676c29babe1563ee64a1149d2ae2f9f1369fe25\",\"title\":\"Visual saliency computation for image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3676c29babe1563ee64a1149d2ae2f9f1369fe25\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145850271\",\"name\":\"Cong Hu\"},{\"authorId\":\"37020604\",\"name\":\"X. Wu\"},{\"authorId\":\"145801638\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/TCDS.2018.2875462\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"410079df0cfde7828d3955cd303a9706f9491d5f\",\"title\":\"Semi-Supervised Learning Based on GAN With Mean and Variance Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/410079df0cfde7828d3955cd303a9706f9491d5f\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1016/j.neucom.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"title\":\"Phrase-based image caption generator with hierarchical LSTM network\",\"url\":\"https://www.semanticscholar.org/paper/760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TIP.2020.3034494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"title\":\"Learning Dual Encoding Model for Adaptive Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3336495\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"715fe60a8615d283c70d12db13857d8948baebca\",\"title\":\"Pseudo-3D Attention Transfer Network with Content-aware Strategy for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/715fe60a8615d283c70d12db13857d8948baebca\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"},{\"authorId\":\"49269449\",\"name\":\"Clint Malcolm\"}],\"doi\":\"10.18653/v1/D15-1171\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c87dccf7c21e67679389f23f86f039cd96720c3f\",\"title\":\"Solving Geometry Problems: Combining Text and Diagram Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/c87dccf7c21e67679389f23f86f039cd96720c3f\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"1790251284\",\"name\":\"Lin Li\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"9594118\",\"name\":\"C. Gu\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/s11063-020-10352-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"title\":\"Adaptively Converting Auxiliary Attributes and Textual Embedding for Video Captioning Based on BiLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"venue\":\"Neural Process. Lett.\",\"year\":2020},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898103\",\"name\":\"J. Glass\"}],\"doi\":\"10.1007/s11263-019-01205-0\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1911.12682\",\"authors\":[{\"authorId\":\"47435551\",\"name\":\"Xu Shen\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"3141359\",\"name\":\"Shaoyan Sun\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04583eacb6b18d297f680a3a5cda5cbf653efeda\",\"title\":\"Patch Reordering: a Novel Way to Achieve Rotation and Translation Invariance in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/04583eacb6b18d297f680a3a5cda5cbf653efeda\",\"venue\":\"AAAI 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"2440772\",\"name\":\"Ankit P Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1942176\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.09.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2dbca69f6e50c058a44243abfaf669097a02c879\",\"title\":\"Resolving vision and language ambiguities together: Joint segmentation & prepositional attachment resolution in captioned scenes\",\"url\":\"https://www.semanticscholar.org/paper/2dbca69f6e50c058a44243abfaf669097a02c879\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"2550719\",\"name\":\"X. Zeng\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2015.220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b55da293699ddea02fc4a6c8bb197375e4cfa195\",\"title\":\"Learning Deep Representation with Large-Scale Attributes\",\"url\":\"https://www.semanticscholar.org/paper/b55da293699ddea02fc4a6c8bb197375e4cfa195\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1609.01859\",\"authors\":[{\"authorId\":\"143819050\",\"name\":\"Ke Sun\"},{\"authorId\":\"3468964\",\"name\":\"Xianxu Hou\"},{\"authorId\":\"1737486\",\"name\":\"Q. Zhang\"},{\"authorId\":\"143740671\",\"name\":\"G. Qiu\"}],\"doi\":\"10.1109/ICMIP.2017.3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dafd73e9f326f4a1b9a71c17714765926074183a\",\"title\":\"Automatic Visual Theme Discovery from Joint Image and Text Corpora\",\"url\":\"https://www.semanticscholar.org/paper/dafd73e9f326f4a1b9a71c17714765926074183a\",\"venue\":\"2017 2nd International Conference on Multimedia and Image Processing (ICMIP)\",\"year\":2017},{\"arxivId\":\"1805.09461\",\"authors\":[{\"authorId\":\"2180949\",\"name\":\"Yaser Keneshloo\"},{\"authorId\":\"145531789\",\"name\":\"Tian Shi\"},{\"authorId\":\"1755938\",\"name\":\"Naren Ramakrishnan\"},{\"authorId\":\"144417522\",\"name\":\"C. Reddy\"}],\"doi\":\"10.1109/TNNLS.2019.2929141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15a06d8601539b5eb6df5baf6bc4c3bdefb34855\",\"title\":\"Deep Reinforcement Learning for Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/15a06d8601539b5eb6df5baf6bc4c3bdefb34855\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1706.02430\",\"authors\":[{\"authorId\":\"143932857\",\"name\":\"Zhongliang Yang\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"},{\"authorId\":\"19283055\",\"name\":\"S. Rehman\"},{\"authorId\":\"1731776\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1007/978-3-319-71589-6_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8fa2e242369dcf50ab5cd1745b29bfc51aadf2a\",\"title\":\"Image Captioning with Object Detection and Localization\",\"url\":\"https://www.semanticscholar.org/paper/e8fa2e242369dcf50ab5cd1745b29bfc51aadf2a\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51906984\",\"name\":\"Ayushi Dutta\"},{\"authorId\":\"2169614\",\"name\":\"Yashaswi Verma\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1007/978-3-030-58526-6_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92a4dd57bb66231c6769b8d0693fb61814db13a7\",\"title\":\"Recurrent Image Annotation with Explicit Inter-label Dependencies\",\"url\":\"https://www.semanticscholar.org/paper/92a4dd57bb66231c6769b8d0693fb61814db13a7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718794\",\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Yang Liu\"}],\"doi\":\"10.1007/978-981-10-5209-5_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"874cff125dc723eb86a9520247231d30f1432e17\",\"title\":\"A Joint Introduction to Natural Language Processing and to Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/874cff125dc723eb86a9520247231d30f1432e17\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.09996\",\"authors\":[{\"authorId\":\"15035398\",\"name\":\"V. O. Yazici\"},{\"authorId\":\"1403268002\",\"name\":\"Abel Gonzalez-Garcia\"},{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"},{\"authorId\":\"2470703\",\"name\":\"Bartlomiej Twardowski\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"}],\"doi\":\"10.1109/cvpr42600.2020.01345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6b118f0fc679bcb8a670f5d31cb241cf1da7536\",\"title\":\"Orderless Recurrent Models for Multi-Label Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6b118f0fc679bcb8a670f5d31cb241cf1da7536\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216345\",\"name\":\"Miltiadis Allamanis\"},{\"authorId\":\"1725299\",\"name\":\"Daniel Tarlow\"},{\"authorId\":\"144376271\",\"name\":\"A. Gordon\"},{\"authorId\":\"145861592\",\"name\":\"Y. Wei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5defb8729294614d40e0247eabfdc483bf1a992\",\"title\":\"Bimodal Modelling of Source Code and Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/b5defb8729294614d40e0247eabfdc483bf1a992\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1504.06692\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"144287022\",\"name\":\"Xu Wei\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"152924551\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb847564774394c484e701437dbcffbf040ff3cc\",\"title\":\"Learning Like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images\",\"url\":\"https://www.semanticscholar.org/paper/eb847564774394c484e701437dbcffbf040ff3cc\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1609.08976\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145153424\",\"name\":\"Ricardo Henao\"},{\"authorId\":\"50242822\",\"name\":\"X. Yuan\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9074631\",\"name\":\"A. Stevens\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"title\":\"Variational Autoencoder for Deep Learning of Images, Labels and Captions\",\"url\":\"https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1704.06485\",\"authors\":[{\"authorId\":\"47465525\",\"name\":\"Cesc Chunseong Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.681\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"title\":\"Attend to You: Personalized Image Captioning with Context Sequence Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30771413\",\"name\":\"Brandon Birmingham\"},{\"authorId\":\"35347012\",\"name\":\"Adrian Muscat\"}],\"doi\":\"10.18653/v1/W17-2002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dab64439ffb72da80175ba98a47b6f1e0ddd21b\",\"title\":\"The Use of Object Labels and Spatial Prepositions as Keywords in a Web-Retrieval-Based Image Caption Generation System\",\"url\":\"https://www.semanticscholar.org/paper/1dab64439ffb72da80175ba98a47b6f1e0ddd21b\",\"venue\":\"VL@EACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47495908\",\"name\":\"R. Gupta\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"}],\"doi\":\"10.1007/978-3-319-73603-7_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68ea3f3aae4294821c7f6fb77f0adba0cdd622e1\",\"title\":\"Approaches for Event Segmentation of Visual Lifelog Data\",\"url\":\"https://www.semanticscholar.org/paper/68ea3f3aae4294821c7f6fb77f0adba0cdd622e1\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"30076791\",\"name\":\"Zhilong Zhou\"},{\"authorId\":\"35153304\",\"name\":\"Lijiang Chen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11280-018-0531-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7eb3ac4ccb30a2ce759094f3972a018575f74b6\",\"title\":\"Residual attention-based LSTM for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/f7eb3ac4ccb30a2ce759094f3972a018575f74b6\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1906.02850\",\"authors\":[{\"authorId\":\"48240607\",\"name\":\"C. Chen\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"145381969\",\"name\":\"T. Yu\"},{\"authorId\":\"3139133\",\"name\":\"Razvan C. Bunescu\"},{\"authorId\":\"47131074\",\"name\":\"Razvan Bunescu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"755dd3628b04adad423d2418f98c156123ebac2a\",\"title\":\"Figure Captioning with Reasoning and Sequence-Level Training\",\"url\":\"https://www.semanticscholar.org/paper/755dd3628b04adad423d2418f98c156123ebac2a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.05084\",\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e854ee8a8eda42858e8b1fc050f6cae98f54be6\",\"title\":\"MeetUp! A Corpus of Joint Activity Dialogues in a Visual Environment\",\"url\":\"https://www.semanticscholar.org/paper/3e854ee8a8eda42858e8b1fc050f6cae98f54be6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150213872\",\"name\":\"M. Hemalatha.\"},{\"authorId\":\"143783787\",\"name\":\"C. C. Sekhar\"}],\"doi\":\"10.1109/WACV45572.2020.9093344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"509b25d45c6f5e3cafa48395c941611364e22efc\",\"title\":\"Domain-Specific Semantics Guided Approach to Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/509b25d45c6f5e3cafa48395c941611364e22efc\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1591412916\",\"name\":\"Jiajie Su\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1007/s11042-020-08832-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"title\":\"Tell and guess: cooperative learning for natural image caption generation with hierarchical refined attention\",\"url\":\"https://www.semanticscholar.org/paper/814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1707.08364\",\"authors\":[{\"authorId\":\"40028657\",\"name\":\"Ali Sharifi Boroujerdi\"},{\"authorId\":\"152839172\",\"name\":\"M. Khanian\"},{\"authorId\":\"8778956\",\"name\":\"M. Breu\\u00df\"}],\"doi\":\"10.1109/SITIS.2017.27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cafa1f108063ea6ab11c587ba74f91f13d2ba50\",\"title\":\"Deep Interactive Region Segmentation and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8cafa1f108063ea6ab11c587ba74f91f13d2ba50\",\"venue\":\"2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783507\",\"name\":\"Anni Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1016/j.neucom.2020.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"title\":\"Multi-attention guided feature fusion network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632281\",\"name\":\"X. Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/tpami.2020.2972281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"title\":\"Vision-Language Navigation Policy Learning and Adaptation.\",\"url\":\"https://www.semanticscholar.org/paper/2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"75148679\",\"name\":\"J. Burstein\"},{\"authorId\":\"19528889\",\"name\":\"C. Doran\"},{\"authorId\":\"148242829\",\"name\":\"T. Solorio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"786d9428e80758ebaa50aa133603d8f7c49f87a0\",\"title\":\"Cross-lingual Visual Verb Sense Disambiguation\",\"url\":\"https://www.semanticscholar.org/paper/786d9428e80758ebaa50aa133603d8f7c49f87a0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32324177\",\"name\":\"C. Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.neucom.2018.07.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fc4a590d1859ba43c1303927c86c64b34e43287\",\"title\":\"Hierarchical attention-based multimodal fusion for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fc4a590d1859ba43c1303927c86c64b34e43287\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1803.00057\",\"authors\":[{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":\"10.1109/CVPR.2018.00912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8027791ca64f4270cd86e2deb830a3a7383dcff\",\"title\":\"A Neural Multi-sequence Alignment TeCHnique (NeuMATCH)\",\"url\":\"https://www.semanticscholar.org/paper/f8027791ca64f4270cd86e2deb830a3a7383dcff\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1506.03694\",\"authors\":[{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"}],\"doi\":\"10.3115/v1/P15-2019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36da622533db1b55e6e918b81d47b96975d729d7\",\"title\":\"Learning language through pictures\",\"url\":\"https://www.semanticscholar.org/paper/36da622533db1b55e6e918b81d47b96975d729d7\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32987878\",\"name\":\"Nigel G. Ward\"},{\"authorId\":\"144662324\",\"name\":\"D. DeVault\"}],\"doi\":\"10.1609/aimag.v37i4.2687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05f5bf296805c2df401666b892827a2ecb49fde1\",\"title\":\"Challenges in Building Highly-Interactive Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/05f5bf296805c2df401666b892827a2ecb49fde1\",\"venue\":\"AI Mag.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1007/978-3-030-37731-1_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"title\":\"Image Captioning Based on Visual and Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151497541\",\"name\":\"X. Meng\"},{\"authorId\":\"151474857\",\"name\":\"Hao Kong\"},{\"authorId\":\"151486196\",\"name\":\"D. Tang\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"}],\"doi\":\"10.1109/ICME.2019.00229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95ddec4b0ab0024da1e80b66b0a29e0102c0b8fe\",\"title\":\"Multimodal Image Captioning Through Combining Reinforced Cross Entropy Loss and Stochastic Deprecation\",\"url\":\"https://www.semanticscholar.org/paper/95ddec4b0ab0024da1e80b66b0a29e0102c0b8fe\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"46867445\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9305704\",\"name\":\"Xiaosheng Yu\"}],\"doi\":\"10.1155/2020/3062706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"title\":\"An Overview of Image Caption Generation Methods\",\"url\":\"https://www.semanticscholar.org/paper/4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"38218192\",\"name\":\"X. Wang\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02844808a10aa27fad397d1941ec24f5e546ca0b\",\"title\":\"Bidirectional image-sentence retrieval by local and global deep matching\",\"url\":\"https://www.semanticscholar.org/paper/02844808a10aa27fad397d1941ec24f5e546ca0b\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"2008.01663\",\"authors\":[{\"authorId\":\"1490886782\",\"name\":\"Inaam Ilahi\"},{\"authorId\":\"1854367666\",\"name\":\"Hafiz Muhammad Abdullah Zia\"},{\"authorId\":\"1854367588\",\"name\":\"Ahtazaz Ehsan\"},{\"authorId\":\"1854281866\",\"name\":\"Rauf Tabassam\"},{\"authorId\":\"1854198530\",\"name\":\"Armaghan Ahmed\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fe045f4c1c689718a851ee4ac11ff20c529bc29\",\"title\":\"Efficient Urdu Caption Generation using Attention based LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/0fe045f4c1c689718a851ee4ac11ff20c529bc29\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.01462\",\"authors\":[{\"authorId\":\"1491380573\",\"name\":\"Jes\\u00fas P\\u00e9rez-Mart\\u00edn\"},{\"authorId\":\"145899264\",\"name\":\"B. Bustos\"},{\"authorId\":\"145727300\",\"name\":\"M. Salda\\u00f1a\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e3335dd9b1894ab43c7f366634de60b2fa2449f\",\"title\":\"Semantic Search of Memes on Twitter\",\"url\":\"https://www.semanticscholar.org/paper/1e3335dd9b1894ab43c7f366634de60b2fa2449f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48032469\",\"name\":\"X. Liu\"},{\"authorId\":\"1795699\",\"name\":\"M. Milanova\"}],\"doi\":\"10.1007/978-3-030-20984-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df2f287d6e774917c3528be8dece5f221b0a4328\",\"title\":\"An Image Captioning Method for Infant Sleeping Environment Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/df2f287d6e774917c3528be8dece5f221b0a4328\",\"venue\":\"MPRSS\",\"year\":2018},{\"arxivId\":\"1510.02125\",\"authors\":[{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"2061232\",\"name\":\"C. Kennington\"}],\"doi\":\"10.18653/v1/P16-1115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13a721dc8a7c774ca3feec3710212c809a28dd1d\",\"title\":\"Resolving References to Objects in Photographs using the Words-As-Classifiers Model\",\"url\":\"https://www.semanticscholar.org/paper/13a721dc8a7c774ca3feec3710212c809a28dd1d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"47666390\",\"name\":\"H. Chen\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/s12559-018-9581-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"title\":\"Neural Image Caption Generation with Weighted Training and Reference\",\"url\":\"https://www.semanticscholar.org/paper/848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"venue\":\"Cognitive Computation\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"}],\"doi\":\"10.1109/CCDC.2017.7979342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7926df884c677ecbd2f44402f33024ccd942a6b\",\"title\":\"Visual attention based on long-short term memory model for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/f7926df884c677ecbd2f44402f33024ccd942a6b\",\"venue\":\"2017 29th Chinese Control And Decision Conference (CCDC)\",\"year\":2017},{\"arxivId\":\"1904.09146\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0167e98f6d2e4c44b505c0f74f91425f62dfc62c\",\"title\":\"Salient Object Detection in the Deep Learning Era: An In-Depth Survey\",\"url\":\"https://www.semanticscholar.org/paper/0167e98f6d2e4c44b505c0f74f91425f62dfc62c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381902419\",\"name\":\"Mihir Prabhudesai\"},{\"authorId\":\"1693704\",\"name\":\"H. F. Tung\"},{\"authorId\":\"40604609\",\"name\":\"Syed Ashar Javed\"},{\"authorId\":\"51039185\",\"name\":\"Maximilian Sieb\"},{\"authorId\":\"34939798\",\"name\":\"Adam W. Harley\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"}],\"doi\":\"10.1109/CVPR42600.2020.00229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77e98ae704a70478fb1eea7625f54d103e427a58\",\"title\":\"Embodied Language Grounding With 3D Visual Feature Representations\",\"url\":\"https://www.semanticscholar.org/paper/77e98ae704a70478fb1eea7625f54d103e427a58\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48036166\",\"name\":\"Ruka Funaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf17c86d5df875ffada0065ed26762a8b8cd4949\",\"title\":\"Zero-Shot Cross-Lingual Document Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bf17c86d5df875ffada0065ed26762a8b8cd4949\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e97f10c2a4d7edac33597692e6dc243bd86adf10\",\"title\":\"Trainable performance upper bounds for image and video captioning\",\"url\":\"https://www.semanticscholar.org/paper/e97f10c2a4d7edac33597692e6dc243bd86adf10\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1603.09046\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a12540c85c6835eb6fd36131107d82c50d2b8d0\",\"title\":\"Dense Image Representation with Spatial Pyramid VLAD Coding of CNN for Locally Robust Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8a12540c85c6835eb6fd36131107d82c50d2b8d0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1612.07833\",\"authors\":[{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"title\":\"Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task\",\"url\":\"https://www.semanticscholar.org/paper/6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1811.05253\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"Fangyu Wu\"},{\"authorId\":\"33830793\",\"name\":\"Jeremy S. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"Bailing Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"title\":\"Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9382626\",\"name\":\"M. Amaresh\"},{\"authorId\":\"144902122\",\"name\":\"S. Chitrakala\"}],\"doi\":\"10.1109/ICCSP.2019.8698097\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aad4525b28b18fde9c793ab387ac327802ef71d2\",\"title\":\"Video Captioning using Deep Learning: An Overview of Methods, Datasets and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/aad4525b28b18fde9c793ab387ac327802ef71d2\",\"venue\":\"2019 International Conference on Communication and Signal Processing (ICCSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"48651559\",\"name\":\"Ku\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a311848acc2deacc2c03a6fa97fbb81f17223ad6\",\"title\":\"C V ] 16 S ep 2 01 5 Guiding Long-Short Term Memory for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a311848acc2deacc2c03a6fa97fbb81f17223ad6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153804074\",\"name\":\"Heng Quan Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"}],\"doi\":\"10.1117/12.2524235\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"title\":\"When visual object-context features meet generic and specific semantic priors in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2019},{\"arxivId\":\"1911.08618\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1609/AAAI.V34I07.6858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"title\":\"Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA\",\"url\":\"https://www.semanticscholar.org/paper/dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1906.05963\",\"authors\":[{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"40441990\",\"name\":\"Armin Kappeler\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"},{\"authorId\":\"145730823\",\"name\":\"J. Soares\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b499228aa74b59be32711c3926e44de208d6b636\",\"title\":\"Image Captioning: Transforming Objects into Words\",\"url\":\"https://www.semanticscholar.org/paper/b499228aa74b59be32711c3926e44de208d6b636\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405709193\",\"name\":\"Gonzalo Vaca-Castano\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/J.CVIU.2019.02.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0efecabff90401ea60cc5bca791d00f5113fa73\",\"title\":\"Holistic object detection and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0efecabff90401ea60cc5bca791d00f5113fa73\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"2012.05545\",\"authors\":[{\"authorId\":\"67333377\",\"name\":\"Zeliang Song\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"title\":\"Image Captioning with Context-Aware Auxiliary Guidance\",\"url\":\"https://www.semanticscholar.org/paper/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.03240\",\"authors\":[{\"authorId\":\"38921864\",\"name\":\"J. Li\"},{\"authorId\":\"21184593\",\"name\":\"Haizhou Shi\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3343031.3350918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b2bb2ce93f2a48f998b6ca1e4364e8f2707e3e6\",\"title\":\"Informative Visual Storytelling with Cross-modal Rules\",\"url\":\"https://www.semanticscholar.org/paper/1b2bb2ce93f2a48f998b6ca1e4364e8f2707e3e6\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97713340\",\"name\":\"X. Liu\"},{\"authorId\":\"1943870\",\"name\":\"Weibin Liu\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00152\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f55a588eef043cbb72ee548714d623b573c21e9b\",\"title\":\"Image Caption Generation with Local Semantic Information and Global Information\",\"url\":\"https://www.semanticscholar.org/paper/f55a588eef043cbb72ee548714d623b573c21e9b\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":\"1909.09060\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"312799645adfafb886f156708a7a36f2db459c62\",\"title\":\"Adaptively Aligned Image Captioning via Adaptive Attention Time\",\"url\":\"https://www.semanticscholar.org/paper/312799645adfafb886f156708a7a36f2db459c62\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48490580\",\"name\":\"J. Park\"},{\"authorId\":\"35409051\",\"name\":\"Chibon Song\"},{\"authorId\":\"47180565\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/ICIIBMS.2017.8279760\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e8d9299af393da5e7534f0a8cce5a270c0b7775\",\"title\":\"A study of evaluation metrics and datasets for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/2e8d9299af393da5e7534f0a8cce5a270c0b7775\",\"venue\":\"2017 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152349861\",\"name\":\"Cong Hu\"},{\"authorId\":\"47684404\",\"name\":\"Xiao-Ning Song\"}],\"doi\":\"10.1109/ACCESS.2020.3038276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14c3133950acc4e971535ebc657ae795a9418100\",\"title\":\"Graph Regularized Variational Ladder Networks for Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/14c3133950acc4e971535ebc657ae795a9418100\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.01881\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03158341c61b8bfedc9ccd503610ab150678a7c1\",\"title\":\"Better Understanding Hierarchical Visual Relationship for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/03158341c61b8bfedc9ccd503610ab150678a7c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.04919\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"58a77455b1c38afe1eab4bec664bd866eba1573d\",\"title\":\"Towards Diverse and Accurate Image Captions via Reinforcing Determinantal Point Process\",\"url\":\"https://www.semanticscholar.org/paper/58a77455b1c38afe1eab4bec664bd866eba1573d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921534\",\"name\":\"Philip Kinghorn\"},{\"authorId\":\"41204462\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/J.PATREC.2017.09.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac23ecff8ad11ba6de4ce09b058d05e1d41d01c\",\"title\":\"A hierarchical and regional deep learning architecture for image description generation\",\"url\":\"https://www.semanticscholar.org/paper/5ac23ecff8ad11ba6de4ce09b058d05e1d41d01c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34692779\",\"name\":\"K. Chang\"},{\"authorId\":\"10421443\",\"name\":\"Kung-Hung Lu\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"}],\"doi\":\"10.1109/ICCV.2017.380\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"title\":\"Aesthetic Critiques Generation for Photos\",\"url\":\"https://www.semanticscholar.org/paper/c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339506\",\"name\":\"Mari Ostendorf\"}],\"doi\":\"10.1007/978-3-319-45925-7_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f671de27822abc46287a60e93a85c4536dc8fde\",\"title\":\"Continuous-Space Language Processing: Beyond Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/8f671de27822abc46287a60e93a85c4536dc8fde\",\"venue\":\"SLSP\",\"year\":2016},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1811.07662\",\"authors\":[{\"authorId\":\"47833739\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2112160\",\"name\":\"Y. Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00859\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"23e943809c131c50dc90c1d308373febc60b9029\",\"title\":\"Intention Oriented Image Captions With Guiding Objects\",\"url\":\"https://www.semanticscholar.org/paper/23e943809c131c50dc90c1d308373febc60b9029\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1809.09294\",\"authors\":[{\"authorId\":\"145314568\",\"name\":\"Zhiqiang Shen\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TPAMI.2019.2922181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1c98035c32e783b7450f1779af572a65e6fc23f\",\"title\":\"Object Detection from Scratch with Deep Supervision\",\"url\":\"https://www.semanticscholar.org/paper/f1c98035c32e783b7450f1779af572a65e6fc23f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150123423\",\"name\":\"Haiyun Jiang\"},{\"authorId\":\"3011950\",\"name\":\"Y. Xiao\"},{\"authorId\":\"49336726\",\"name\":\"Wei Wang\"}],\"doi\":\"10.1007/s11280-019-00752-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a2aa94bf701861909eece022027ec948cc4548d\",\"title\":\"Explaining a bag of words with hierarchical conceptual labels\",\"url\":\"https://www.semanticscholar.org/paper/1a2aa94bf701861909eece022027ec948cc4548d\",\"venue\":\"World Wide Web\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1503.02351\",\"authors\":[{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"416a242f24246f8ee2c00f4d3d1561443dc65b59\",\"title\":\"Fully Connected Deep Structured Networks\",\"url\":\"https://www.semanticscholar.org/paper/416a242f24246f8ee2c00f4d3d1561443dc65b59\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de228875bc33e9db85123469ef80fc0071a92386\",\"title\":\"Word2VisualVec: Image and Video to Sentence Matching by Visual Feature Prediction\",\"url\":\"https://www.semanticscholar.org/paper/de228875bc33e9db85123469ef80fc0071a92386\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"144509504\",\"name\":\"A. D. Vries\"}],\"doi\":\"10.3115/v1/P15-1005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bfa75238e15e869b902ceb62b31ffddbe8ccb0d\",\"title\":\"Describing Images using Inferred Visual Dependency Representations\",\"url\":\"https://www.semanticscholar.org/paper/3bfa75238e15e869b902ceb62b31ffddbe8ccb0d\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1603.08507\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46493-0_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"title\":\"Generating Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbd429d1a5582ef4347abc7cd99eb6d5b740e70a\",\"title\":\"Explorer Image Pivoting for Learning Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/fbd429d1a5582ef4347abc7cd99eb6d5b740e70a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.5244/C.29.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63de6bb482d07f9e81ecbe9acfb62433b4ce6fe6\",\"title\":\"Generating Multi-sentence Natural Language Descriptions of Indoor Scenes\",\"url\":\"https://www.semanticscholar.org/paper/63de6bb482d07f9e81ecbe9acfb62433b4ce6fe6\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868350\",\"name\":\"Yiman Zhang\"},{\"authorId\":\"48551615\",\"name\":\"Xiaolin Zhao\"},{\"authorId\":\"144453844\",\"name\":\"Yin Zhou\"},{\"authorId\":\"46395663\",\"name\":\"Yong Wang\"},{\"authorId\":\"48625308\",\"name\":\"Xinyu Hou\"}],\"doi\":\"10.12783/DTCSE/CSAE2017/17484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac65b64e3401118b239b3f9a750b5210ea60df75\",\"title\":\"The Improvement of GK-tail Algorithm of Software Behavior Modeling\",\"url\":\"https://www.semanticscholar.org/paper/ac65b64e3401118b239b3f9a750b5210ea60df75\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/ICCV.2019.00434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"title\":\"Generating Diverse and Descriptive Image Captions Using Visual Paraphrases\",\"url\":\"https://www.semanticscholar.org/paper/b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1901.08362\",\"authors\":[{\"authorId\":\"13676653\",\"name\":\"Z. Li\"},{\"authorId\":\"3350185\",\"name\":\"C. Lang\"},{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"40320335\",\"name\":\"JunHao Liew\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d4c8427e3bdc307e8da6cf53110aafb78f47a8a\",\"title\":\"Deep Reasoning with Multi-scale Context for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/7d4c8427e3bdc307e8da6cf53110aafb78f47a8a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66320916\",\"name\":\"Ruturaj Nene\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7813cdf27e637118a7f3e804a745854dca78ceae\",\"title\":\"Caption Generation for Images Using Deep Multimodal Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/7813cdf27e637118a7f3e804a745854dca78ceae\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50994378\",\"name\":\"Chen Chen\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"35365476\",\"name\":\"R. Rossi\"}],\"doi\":\"10.1109/WACV45572.2020.9093592\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40e09c8e31bc859d90ba8ceeb70ef7534bf6b7a5\",\"title\":\"Figure Captioning with Relation Maps for Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/40e09c8e31bc859d90ba8ceeb70ef7534bf6b7a5\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952857\",\"name\":\"K. Zheng\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"2478555\",\"name\":\"Shaopeng Lu\"},{\"authorId\":\"40457369\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-00776-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"title\":\"Multiple-Level Feature-Based Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1606.01550\",\"authors\":[{\"authorId\":\"143743802\",\"name\":\"A. Babenko\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e8dbdc2dc36705bb54aad58813b73a947db7329\",\"title\":\"Pairwise Quantization\",\"url\":\"https://www.semanticscholar.org/paper/2e8dbdc2dc36705bb54aad58813b73a947db7329\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/978-3-030-00776-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee34a697bc114a5284025648fb9b49f9cdf5e343\",\"title\":\"Video Captioning Based on the Spatial-Temporal Saliency Tracing\",\"url\":\"https://www.semanticscholar.org/paper/ee34a697bc114a5284025648fb9b49f9cdf5e343\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.18653/v1/D15-1021\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a98a8b3b28250cb77d99748bff15ddbd9351433\",\"title\":\"A Survey of Current Datasets for Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/4a98a8b3b28250cb77d99748bff15ddbd9351433\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7974293\",\"name\":\"L. Wang\"},{\"authorId\":\"47153495\",\"name\":\"Guoguang Zhao\"},{\"authorId\":\"2028692\",\"name\":\"Donghong Sun\"}],\"doi\":\"10.3390/a8030562\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9eecd9043ae784679fa4f9d360a044a3022a0a2\",\"title\":\"Modeling Documents with Event Model\",\"url\":\"https://www.semanticscholar.org/paper/a9eecd9043ae784679fa4f9d360a044a3022a0a2\",\"venue\":\"Algorithms\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1906.08876\",\"authors\":[{\"authorId\":\"3038511\",\"name\":\"Sanqiang Zhao\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P19-1650\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"title\":\"Informative Image Captioning with External Sources of Information\",\"url\":\"https://www.semanticscholar.org/paper/68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1412.4729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.3115/v1/N15-1173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cef41606f1e1324b683441e694f0e1c96387abf\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cef41606f1e1324b683441e694f0e1c96387abf\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118079565\",\"name\":\"Mengjun Ni\"},{\"authorId\":\"145039750\",\"name\":\"J. Yang\"},{\"authorId\":\"144361839\",\"name\":\"X. Lin\"},{\"authorId\":\"145836225\",\"name\":\"Liang He\"}],\"doi\":\"10.1007/978-3-319-68612-7_62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89f523605f8d0a59f584053beb94cc52b7180f47\",\"title\":\"Reducing Unknown Unknowns with Guidance in Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/89f523605f8d0a59f584053beb94cc52b7180f47\",\"venue\":\"ICANN\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2374364\",\"name\":\"Yusuke Mukuta\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2015.306\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f6ed8a79b814893bbe4902634416096ac4e8ed6\",\"title\":\"Common Subspace for Model and Similarity: Phrase Learning for Caption Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/3f6ed8a79b814893bbe4902634416096ac4e8ed6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"}],\"doi\":\"10.1184/R1/11898378.V1\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8acc12ccc3487093314ee1d20c51ce73210ba8eb\",\"title\":\"Towards Literate Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/8acc12ccc3487093314ee1d20c51ce73210ba8eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1507.01053\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1109/TMM.2015.2477044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"654a3e53fb41d8168798ee0ee61dfab73739b1ed\",\"title\":\"Describing Multimedia Content Using Attention-Based Encoder-Decoder Networks\",\"url\":\"https://www.semanticscholar.org/paper/654a3e53fb41d8168798ee0ee61dfab73739b1ed\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121556212\",\"name\":\"R. Subash\"},{\"authorId\":\"145313336\",\"name\":\"R. Jebakumar\"},{\"authorId\":\"1453739025\",\"name\":\"Yash Kamdar\"},{\"authorId\":\"79366636\",\"name\":\"N. Bhatt\"}],\"doi\":\"10.1088/1742-6596/1362/1/012096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08640d76e5bff226a74a18c9d76ea2347e034473\",\"title\":\"Automatic Image Captioning Using Convolution Neural Networks and LSTM\",\"url\":\"https://www.semanticscholar.org/paper/08640d76e5bff226a74a18c9d76ea2347e034473\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.13846\",\"authors\":[{\"authorId\":\"1661218221\",\"name\":\"Kenya Sakka\"},{\"authorId\":\"1943224\",\"name\":\"K. Nakayama\"},{\"authorId\":\"1661219175\",\"name\":\"Nisei Kimura\"},{\"authorId\":\"6937940\",\"name\":\"T. Inoue\"},{\"authorId\":\"1715282\",\"name\":\"Yusuke Iwasawa\"},{\"authorId\":\"152962999\",\"name\":\"R. Yamaguchi\"},{\"authorId\":\"1661217362\",\"name\":\"Yosimasa Kawazoe\"},{\"authorId\":\"1765631\",\"name\":\"K. Ohe\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.1007/978-3-030-53352-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59dfb5b3c4ebd14e0e3128d421ec40cd99b3a2e7\",\"title\":\"Character-level Japanese Text Generation with Attention Mechanism for Chest Radiography Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/59dfb5b3c4ebd14e0e3128d421ec40cd99b3a2e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3185668\",\"name\":\"Haoran Liang\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1145/3200767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df36f11cddb2cfd01cd062b53f10d206db752e5\",\"title\":\"CapVis: Toward Better Understanding of Visual-Verbal Saliency Consistency\",\"url\":\"https://www.semanticscholar.org/paper/4df36f11cddb2cfd01cd062b53f10d206db752e5\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2019},{\"arxivId\":\"1908.02950\",\"authors\":[{\"authorId\":\"121490889\",\"name\":\"Deepan Das\"},{\"authorId\":\"151478044\",\"name\":\"Noor Mohammed Ghouse\"},{\"authorId\":\"66917427\",\"name\":\"S. Verma\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"dc2473ee27f76e8490d982f43973e7eb902de79d\",\"title\":\"Semi Supervised Phrase Localization in a Bidirectional Caption-Image Retrieval Framework\",\"url\":\"https://www.semanticscholar.org/paper/dc2473ee27f76e8490d982f43973e7eb902de79d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.10658\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICCV.2019.01042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"title\":\"Unpaired Image Captioning via Scene Graph Alignments\",\"url\":\"https://www.semanticscholar.org/paper/f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2734498\",\"name\":\"N. Laokulrat\"},{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"8058716\",\"name\":\"Noriki Nishida\"},{\"authorId\":\"7412686\",\"name\":\"Raphael Shu\"},{\"authorId\":\"35257737\",\"name\":\"Yo Ehara\"},{\"authorId\":\"1764004\",\"name\":\"N. Okazaki\"},{\"authorId\":\"1768065\",\"name\":\"Yusuke Miyao\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf05e710dae791f82cc639a09dbe5ec66fed2008\",\"title\":\"Generating Video Description using Sequence-to-sequence Model with Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf05e710dae791f82cc639a09dbe5ec66fed2008\",\"venue\":\"COLING\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1145/2983563.2983571\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d6d6edce271935feec96484d0e1f16dcc24973fd\",\"title\":\"Exploiting Scene Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d6d6edce271935feec96484d0e1f16dcc24973fd\",\"venue\":\"iV&L-MM@MM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7415284\",\"name\":\"Y. Jia\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"49830854\",\"name\":\"P. Wang\"},{\"authorId\":\"1805712\",\"name\":\"Jinlin Guo\"},{\"authorId\":\"2248082\",\"name\":\"Yuxiang Xie\"},{\"authorId\":\"145344058\",\"name\":\"Tianyuan Yu\"}],\"doi\":\"10.1007/s11042-018-5692-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa2a1866646e29ba6994adecef14757587dd5735\",\"title\":\"Irrelevance reduction with locality-sensitive hash learning for efficient cross-media retrieval\",\"url\":\"https://www.semanticscholar.org/paper/aa2a1866646e29ba6994adecef14757587dd5735\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672743\",\"name\":\"C. Li\"},{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"}],\"doi\":\"10.1007/978-3-319-71607-7_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"title\":\"Combining Object-Based Attention and Attributes for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31277115\",\"name\":\"K. Shivdikar\"},{\"authorId\":\"34814649\",\"name\":\"A. Kak\"},{\"authorId\":\"3337517\",\"name\":\"Kshitij Marwah\"}],\"doi\":\"10.1109/INDICON.2015.7443338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b81073dd2598885f8836cb603d44fa2500d7932a\",\"title\":\"Automatic image annotation using a hybrid engine\",\"url\":\"https://www.semanticscholar.org/paper/b81073dd2598885f8836cb603d44fa2500d7932a\",\"venue\":\"2015 Annual IEEE India Conference (INDICON)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1801.01957\",\"authors\":[{\"authorId\":\"144154486\",\"name\":\"H. Shum\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"}],\"doi\":\"10.1631/FITEE.1700826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60e6d991462d3995cdb6079e5e49ee40e5a583b4\",\"title\":\"From Eliza to XiaoIce: challenges and opportunities with social chatbots\",\"url\":\"https://www.semanticscholar.org/paper/60e6d991462d3995cdb6079e5e49ee40e5a583b4\",\"venue\":\"Frontiers of Information Technology & Electronic Engineering\",\"year\":2018},{\"arxivId\":\"2004.08070\",\"authors\":[{\"authorId\":\"51163002\",\"name\":\"Alasdair Tran\"},{\"authorId\":\"46953477\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"}],\"doi\":\"10.1109/CVPR42600.2020.01305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"title\":\"Transform and Tell: Entity-Aware News Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48036166\",\"name\":\"Ruka Funaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.18653/v1/D15-1070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24a36b5153ce9338d06204bca45098997e79295b\",\"title\":\"Image-Mediated Learning for Zero-Shot Cross-Lingual Document Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/24a36b5153ce9338d06204bca45098997e79295b\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1808.03090\",\"authors\":[{\"authorId\":\"1932329\",\"name\":\"Wen-Feng Cheng\"},{\"authorId\":\"3363972\",\"name\":\"Chao-Chung Wu\"},{\"authorId\":\"35119829\",\"name\":\"R. Song\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144076239\",\"name\":\"X. Xie\"},{\"authorId\":\"143619007\",\"name\":\"Jian-Yun Nie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"469d249a40639d4ffb62abfb2c25f5aab0812fa4\",\"title\":\"Image Inspired Poetry Generation in XiaoIce\",\"url\":\"https://www.semanticscholar.org/paper/469d249a40639d4ffb62abfb2c25f5aab0812fa4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177145\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dadb7ddfde3478238d23a8bacf5eddecc59e84c9\",\"title\":\"Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/dadb7ddfde3478238d23a8bacf5eddecc59e84c9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.05490\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2017.443\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"title\":\"Semantic Regularisation for Recurrent Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143715692\",\"name\":\"X. Hao\"},{\"authorId\":\"46468475\",\"name\":\"F. Zhou\"},{\"authorId\":\"33899331\",\"name\":\"Xiaoyong Li\"}],\"doi\":\"10.1109/ITNEC48623.2020.9084781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"653de101370307afc2eba27d4e4c574441eb06da\",\"title\":\"Scene-Edge GRU for Video Caption\",\"url\":\"https://www.semanticscholar.org/paper/653de101370307afc2eba27d4e4c574441eb06da\",\"venue\":\"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711712\",\"name\":\"Y. Mrabet\"},{\"authorId\":\"7631872\",\"name\":\"P. Vougiouklis\"},{\"authorId\":\"3358452\",\"name\":\"Halil Kilicoglu\"},{\"authorId\":\"1794075\",\"name\":\"Claire Gardent\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"2927032\",\"name\":\"E. Simperl\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e080760d73a15a1c305d4f3ec4da480942b054bc\",\"title\":\"WebNLG 2016 Proceedings of the 2nd International Workshop on Natural Language Generation and the Semantic Web\",\"url\":\"https://www.semanticscholar.org/paper/e080760d73a15a1c305d4f3ec4da480942b054bc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1710.07300\",\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"title\":\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"},{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2124897a3f82ef855d94d15766ce49320ede3fc1\",\"title\":\"Learning word meanings from images of natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/2124897a3f82ef855d94d15766ce49320ede3fc1\",\"venue\":\"Trait. Autom. des Langues\",\"year\":2014},{\"arxivId\":\"1710.02584\",\"authors\":[{\"authorId\":\"36858580\",\"name\":\"Marc-Andr\\u00e9 Carbonneau\"},{\"authorId\":\"145611842\",\"name\":\"Eric Granger\"},{\"authorId\":\"36931204\",\"name\":\"G. Gagnon\"}],\"doi\":\"10.1109/TNNLS.2018.2869164\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2f28a358e1cd5dd9c113e76f51533019421fca9\",\"title\":\"Bag-Level Aggregation for Multiple-Instance Active Learning in Instance Classification Problems\",\"url\":\"https://www.semanticscholar.org/paper/f2f28a358e1cd5dd9c113e76f51533019421fca9\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1606.04646\",\"authors\":[{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3109befb74bcd5f6cdbe7f2136e745484db0491\",\"title\":\"Unsupervised Learning of Predictors from Unpaired Input-Output Samples\",\"url\":\"https://www.semanticscholar.org/paper/b3109befb74bcd5f6cdbe7f2136e745484db0491\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146940789\",\"name\":\"Ha Nguyen Tien\"},{\"authorId\":\"2269079\",\"name\":\"Thanh-Ha Do\"}],\"doi\":\"10.1109/MAPR49794.2020.9237773\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c46bd6de48214a1e81ebef369070713febaeced\",\"title\":\"Generating Vietnamese Language Caption Automatically for Scene Images\",\"url\":\"https://www.semanticscholar.org/paper/6c46bd6de48214a1e81ebef369070713febaeced\",\"venue\":\"2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1511.07916\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5bfec86bb67a1c49359e8a171917311d48688068\",\"title\":\"Natural Language Understanding with Distributed Representation\",\"url\":\"https://www.semanticscholar.org/paper/5bfec86bb67a1c49359e8a171917311d48688068\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1829790\",\"name\":\"L. Zhou\"},{\"authorId\":\"2538385\",\"name\":\"Zaher Hinbarji\"},{\"authorId\":\"1381816609\",\"name\":\"Duc-Tien Dang-Nguyen\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"}],\"doi\":\"10.1145/3210539.3210542\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"77e8750a4c5222597ba31d7b541ee4eab237b75a\",\"title\":\"LIFER: An Interactive Lifelog Retrieval System\",\"url\":\"https://www.semanticscholar.org/paper/77e8750a4c5222597ba31d7b541ee4eab237b75a\",\"venue\":\"LSC@ICMR\",\"year\":2018},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28909797\",\"name\":\"Xiyao Fu\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":null,\"name\":\"Zheng Wang\"},{\"authorId\":\"143760554\",\"name\":\"Q. Wei\"},{\"authorId\":\"47336231\",\"name\":\"S. Chen\"}],\"doi\":\"10.1007/978-3-030-26075-0_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42c6c030ea35449ee824cbab20031add67d1f999\",\"title\":\"Supervised Hashing with Recurrent Scaling\",\"url\":\"https://www.semanticscholar.org/paper/42c6c030ea35449ee824cbab20031add67d1f999\",\"venue\":\"APWeb/WAIM\",\"year\":2019},{\"arxivId\":\"1812.08658\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"46395829\",\"name\":\"Yufei Wang\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607624548\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.1109/ICCV.2019.00904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"title\":\"nocaps: novel object captioning at scale\",\"url\":\"https://www.semanticscholar.org/paper/8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1704.00260\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2017.452\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"title\":\"Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.08486\",\"authors\":[{\"authorId\":\"1797022\",\"name\":\"Hoo-Chang Shin\"},{\"authorId\":\"1742509\",\"name\":\"Kirk Roberts\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"},{\"authorId\":\"150167064\",\"name\":\"Jianhua Yao\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2016.274\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"0460d3497490fa8332c5ff2ecdab88fb7dff4755\",\"title\":\"Learning to Read Chest X-Rays: Recurrent Neural Cascade Model for Automated Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/0460d3497490fa8332c5ff2ecdab88fb7dff4755\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.08716\",\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1609/aimag.v37i1.2647\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"title\":\"Measuring Machine Intelligence Through Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"venue\":\"AI Mag.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893996\",\"name\":\"S. Kane\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.1145/3064663.3064762\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a7a169382aab1b39d339474728afd67c784cb39\",\"title\":\"Let's Talk About X: Combining Image Recognition and Eye Gaze to Support Conversation for People with ALS\",\"url\":\"https://www.semanticscholar.org/paper/0a7a169382aab1b39d339474728afd67c784cb39\",\"venue\":\"Conference on Designing Interactive Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805894\",\"name\":\"Dafna Shahaf\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"2122569\",\"name\":\"Robert Mankoff\"}],\"doi\":\"10.1145/2783258.2783388\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17527d8d2c0f6235a1ad232dd7f1c0cf01196622\",\"title\":\"Inside Jokes: Identifying Humorous Cartoon Captions\",\"url\":\"https://www.semanticscholar.org/paper/17527d8d2c0f6235a1ad232dd7f1c0cf01196622\",\"venue\":\"KDD\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1017/S1351324918000116\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"title\":\"The role of image representations in vision to language tasks\",\"url\":\"https://www.semanticscholar.org/paper/2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"2004.04696\",\"authors\":[{\"authorId\":\"145450400\",\"name\":\"Thibault Sellam\"},{\"authorId\":\"143790066\",\"name\":\"Dipanjan Das\"},{\"authorId\":\"144729897\",\"name\":\"Ankur P. Parikh\"}],\"doi\":\"10.18653/v1/2020.acl-main.704\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5814778561d6a6a6e72e96447ddff3d26ed95c04\",\"title\":\"BLEURT: Learning Robust Metrics for Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/5814778561d6a6a6e72e96447ddff3d26ed95c04\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"1698822\",\"name\":\"Miaomiao Wen\"}],\"doi\":\"10.3115/v1/N15-1039\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4f9e9a59d0ae975a01a7fc6d3ca9645f7c633319\",\"title\":\"I Can Has Cheezburger? A Nonparanormal Approach to Combining Textual and Visual Information for Predicting and Generating Popular Meme Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4f9e9a59d0ae975a01a7fc6d3ca9645f7c633319\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/ICCV.2017.272\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32482521\",\"name\":\"P. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"title\":\"Towards Interpretable Vision Systems\",\"url\":\"https://www.semanticscholar.org/paper/00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144018558\",\"name\":\"M. Antona\"},{\"authorId\":\"152894018\",\"name\":\"C. Stephanidis\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-49282-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97d57acdea55c8aedb103a9ca7b136b7ad9ed113\",\"title\":\"Universal Access in Human-Computer Interaction. Design Approaches and Supporting Technologies: 14th International Conference, UAHCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19\\u201324, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/97d57acdea55c8aedb103a9ca7b136b7ad9ed113\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8071088\",\"name\":\"R. Oruganti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"00e19d93780ecf8f807c510a1105749d5bb1a2f3\",\"title\":\"Image Description using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/00e19d93780ecf8f807c510a1105749d5bb1a2f3\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46999304\",\"name\":\"T. Liu\"},{\"authorId\":\"15763974\",\"name\":\"Bingzhen Wei\"},{\"authorId\":\"39488576\",\"name\":\"Baobao Chang\"},{\"authorId\":\"3335836\",\"name\":\"Z. Sui\"}],\"doi\":\"10.1007/978-3-319-73618-1_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10f885b9e6bedd5517fdff47c382ec066b9625d7\",\"title\":\"Large-Scale Simple Question Generation by Template-Based Seq2seq Learning\",\"url\":\"https://www.semanticscholar.org/paper/10f885b9e6bedd5517fdff47c382ec066b9625d7\",\"venue\":\"NLPCC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.5244/C.31.131\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d814981606fe5954148e45c737f1debe7b5b36c4\",\"title\":\"Visual Textbook Network: Watch Carefully before Answering Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/d814981606fe5954148e45c737f1debe7b5b36c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47075011\",\"name\":\"Cheng Wang\"},{\"authorId\":\"1688587\",\"name\":\"Haojin Yang\"},{\"authorId\":\"1708312\",\"name\":\"C. Meinel\"}],\"doi\":\"10.1145/3115432\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fe69c9ebf4ede1eb8e2ec233b632031173dd8cb\",\"title\":\"Image Captioning with Deep Bidirectional LSTMs and Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/0fe69c9ebf4ede1eb8e2ec233b632031173dd8cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1711.05557\",\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e70af721dbf04ab8aacc138d75c808588612289b\",\"title\":\"Phrase-based Image Captioning with Hierarchical LSTM Model\",\"url\":\"https://www.semanticscholar.org/paper/e70af721dbf04ab8aacc138d75c808588612289b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Teun de Planque\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5983b0c92f2a619157e2bedf15abb97ed1b0b98f\",\"title\":\"Computer Vision and Deep Learning for Automated Surveillance Technology\",\"url\":\"https://www.semanticscholar.org/paper/5983b0c92f2a619157e2bedf15abb97ed1b0b98f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46576324\",\"name\":\"Kevin P. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbbbd89435dbd21458dda069d00717125f757204\",\"title\":\"C L ] 1 6 A pr 2 01 8 Adversarial Ranking for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/cbbbd89435dbd21458dda069d00717125f757204\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.07010\",\"authors\":[{\"authorId\":\"1804100\",\"name\":\"Mark Kozdoba\"},{\"authorId\":\"2859062\",\"name\":\"Edward Moroshko\"},{\"authorId\":\"38274824\",\"name\":\"Lior Shani\"},{\"authorId\":\"2134977\",\"name\":\"Takuya Takagi\"},{\"authorId\":\"2137115\",\"name\":\"Takashi Katoh\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"},{\"authorId\":\"1693407\",\"name\":\"Koby Crammer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d56ad8e78328b84a5e0b4c94dfec721e459bf7d5\",\"title\":\"Multi Instance Learning For Unbalanced Data\",\"url\":\"https://www.semanticscholar.org/paper/d56ad8e78328b84a5e0b4c94dfec721e459bf7d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65767906\",\"name\":\"Silvio Olivastri\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20f3d85b99b4b595b1c92f60a9b9a126f7384e15\",\"title\":\"An End-to-End Baseline for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/20f3d85b99b4b595b1c92f60a9b9a126f7384e15\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731827\",\"name\":\"Shuo Wang\"},{\"authorId\":\"144713153\",\"name\":\"Dan Guo\"},{\"authorId\":\"7925966\",\"name\":\"X. Xu\"},{\"authorId\":\"145210913\",\"name\":\"L. Zhuo\"},{\"authorId\":\"73160450\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3314577\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b83d310ab8626d93c175371e480c41978889c2d7\",\"title\":\"Cross-Modality Retrieval by Joint Correlation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b83d310ab8626d93c175371e480c41978889c2d7\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145560798\",\"name\":\"R. Wu\"},{\"authorId\":\"40117581\",\"name\":\"Mengyang Feng\"},{\"authorId\":\"12431607\",\"name\":\"Wenlong Guan\"},{\"authorId\":\"143987332\",\"name\":\"D. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":\"10.1109/CVPR.2019.00834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"117ac7c5d42bfdbe83432672db05a2de08dae113\",\"title\":\"A Mutual Learning Method for Salient Object Detection With Intertwined Multi-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/117ac7c5d42bfdbe83432672db05a2de08dae113\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105817\",\"name\":\"Shaosheng Cao\"},{\"authorId\":\"143844110\",\"name\":\"Wei Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"227da7ccdc5c5bc722fd2f38a67d74f38498985c\",\"title\":\"Improving Word Embeddings with Convolutional Feature Learning and Subword Information\",\"url\":\"https://www.semanticscholar.org/paper/227da7ccdc5c5bc722fd2f38a67d74f38498985c\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1912.06365\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"title\":\"Fast Image Caption Generation with Position Alignment\",\"url\":\"https://www.semanticscholar.org/paper/38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1807810\",\"name\":\"Gemma Boleda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0434b16a363d88e27a1b36fc68e04451cc3725b9\",\"title\":\"Object Naming in Language and Vision: A Survey and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0434b16a363d88e27a1b36fc68e04451cc3725b9\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1502.04569\",\"authors\":[{\"authorId\":\"2428539\",\"name\":\"M. Jas\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b3250650c06ecb286badc876d43452941ad20b\",\"title\":\"Image specificity\",\"url\":\"https://www.semanticscholar.org/paper/34b3250650c06ecb286badc876d43452941ad20b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48377888\",\"name\":\"M. Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"056d4807881791a7bcff2e0e4ecdee1b79ac83d9\",\"title\":\"Merging chrominance and luminance in early, medium, and late fusion using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/056d4807881791a7bcff2e0e4ecdee1b79ac83d9\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2011.14901\",\"authors\":[{\"authorId\":\"32236286\",\"name\":\"Annika Lindh\"},{\"authorId\":\"144394786\",\"name\":\"R. Ross\"},{\"authorId\":\"34967075\",\"name\":\"John D. Kelleher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"027aba2214f6a199d7be75150e94075f3752e27f\",\"title\":\"Language-Driven Region Pointer Advancement for Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/027aba2214f6a199d7be75150e94075f3752e27f\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1906.03859\",\"authors\":[{\"authorId\":\"2800977\",\"name\":\"Roman Visotsky\"},{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a49623ec2dcfe71b0800fb0eb99897ae196a7d17\",\"title\":\"Few-Shot Learning with Per-Sample Rich Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a49623ec2dcfe71b0800fb0eb99897ae196a7d17\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48694109\",\"name\":\"J. Nie\"},{\"authorId\":\"1390466881\",\"name\":\"Chunlei Zhang\"},{\"authorId\":\"143644534\",\"name\":\"F. Xia\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"}],\"doi\":\"10.1109/ICIST.2019.8836845\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de0db1c862ea24e447352b83586884a13ed49017\",\"title\":\"Saliency Detection via Recurrently Aggregating and Refining Cross-layer Residual Features\",\"url\":\"https://www.semanticscholar.org/paper/de0db1c862ea24e447352b83586884a13ed49017\",\"venue\":\"2019 9th International Conference on Information Science and Technology (ICIST)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9741677\",\"name\":\"Senmao Ye\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"}],\"doi\":\"10.1109/TIP.2018.2855406\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"title\":\"Attentive Linear Transformation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1801.01582\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"title\":\"Object Referring in Videos with Language and Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2008.00299\",\"authors\":[{\"authorId\":\"1504364089\",\"name\":\"Mohammed Bany Muhammad\"},{\"authorId\":\"1828610\",\"name\":\"M. Yeasin\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206626\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8541d37973ec4c8a63b9b7b62dd6c1ec2d069d5\",\"title\":\"Eigen-CAM: Class Activation Map using Principal Components\",\"url\":\"https://www.semanticscholar.org/paper/d8541d37973ec4c8a63b9b7b62dd6c1ec2d069d5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2996667\",\"name\":\"Darren Guinness\"},{\"authorId\":\"1722375\",\"name\":\"E. Cutrell\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.1145/3173574.3174092\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"737a372a48357a249270afbe6f382eceaa90f9b9\",\"title\":\"Caption Crawler: Enabling Reusable Alternative Text Descriptions using Reverse Image Search\",\"url\":\"https://www.semanticscholar.org/paper/737a372a48357a249270afbe6f382eceaa90f9b9\",\"venue\":\"CHI\",\"year\":2018},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3123266.3123391\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39836fbbcd2a664edb31119e88870c38b83df352\",\"title\":\"Adaptively Attending to Visual Attributes and Linguistic Knowledge for Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39836fbbcd2a664edb31119e88870c38b83df352\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1511.00175\",\"authors\":[{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2318023\",\"name\":\"Matthew W. Moskewicz\"},{\"authorId\":\"152380706\",\"name\":\"K. Ashraf\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1109/CVPR.2016.284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b97ac54f4fd80ee34fa6d249a69793e03dd22d87\",\"title\":\"FireCaffe: Near-Linear Acceleration of Deep Neural Network Training on Compute Clusters\",\"url\":\"https://www.semanticscholar.org/paper/b97ac54f4fd80ee34fa6d249a69793e03dd22d87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1802.10250\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cdb10443a0543be3466c9231ff922bcc996843\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/99cdb10443a0543be3466c9231ff922bcc996843\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5482750\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240538\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72f9116a04e584081635500e9f0789fa26e4d15f\",\"title\":\"Hierarchical Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72f9116a04e584081635500e9f0789fa26e4d15f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1145/3239576.3239580\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"title\":\"Video Captioning using Hierarchical Multi-Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"venue\":\"ICAIP '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ICASSP.2018.8461507\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"54969341ec539ddaaf7537b7353e3cea84790eac\",\"title\":\"A Novel Semantic Attribute-Based Feature for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/54969341ec539ddaaf7537b7353e3cea84790eac\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11499112\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1016/j.cviu.2019.102819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a417da4fd1b49d5f33feb7d4c4846260950d94b3\",\"title\":\"Visual Skeleton and Reparative Attention for Part-of-Speech image captioning system\",\"url\":\"https://www.semanticscholar.org/paper/a417da4fd1b49d5f33feb7d4c4846260950d94b3\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"}],\"doi\":\"10.1016/J.NEUCOM.2018.06.096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"title\":\"Fused GRU with semantic-temporal attention for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2010.07074\",\"authors\":[{\"authorId\":\"48304805\",\"name\":\"Xiaofei Sun\"},{\"authorId\":\"32637368\",\"name\":\"C. Fan\"},{\"authorId\":\"1879521408\",\"name\":\"Zijun Sun\"},{\"authorId\":\"65844131\",\"name\":\"Yuxian Meng\"},{\"authorId\":\"93192602\",\"name\":\"Fei Wu\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd3761ac4795b3840dabb325b6171e6368542576\",\"title\":\"Summarize, Outline, and Elaborate: Long-Text Generation via Hierarchical Supervision from Extractive Summaries\",\"url\":\"https://www.semanticscholar.org/paper/cd3761ac4795b3840dabb325b6171e6368542576\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1605.05440\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICIP.2016.7532983\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41aa209e9d294d370357434f310d49b2b0baebeb\",\"title\":\"Beyond caption to narrative: Video captioning with multiple sentences\",\"url\":\"https://www.semanticscholar.org/paper/41aa209e9d294d370357434f310d49b2b0baebeb\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1612.03557\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"afbff808f4a4c6eafcce3858451b9b1a508ecba3\",\"title\":\"Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/afbff808f4a4c6eafcce3858451b9b1a508ecba3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1611.02261\",\"authors\":[{\"authorId\":\"2915023\",\"name\":\"Rasool Fakoor\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"143967473\",\"name\":\"Pushmeet Kohli\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"249c2e960edb6b3b1f2922a3ea70fad4bae057ec\",\"title\":\"Memory-augmented Attention Modelling for Videos\",\"url\":\"https://www.semanticscholar.org/paper/249c2e960edb6b3b1f2922a3ea70fad4bae057ec\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1867415\",\"name\":\"K. Mokhtari\"},{\"authorId\":\"1886387\",\"name\":\"John N. Maidens\"},{\"authorId\":\"1730000\",\"name\":\"A. Bener\"}],\"doi\":\"10.1007/978-3-030-18305-9_56\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd33c7ec0c213e5be263927ef54bb31d9b60c2e3\",\"title\":\"Predicting Commentaries on a Financial Report with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fd33c7ec0c213e5be263927ef54bb31d9b60c2e3\",\"venue\":\"Canadian Conference on AI\",\"year\":2019},{\"arxivId\":\"1707.09700\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"48884894\",\"name\":\"K. Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf2de559e5a6235783e0762862f6e42192f142a8\",\"title\":\"Scene Graph Generation from Objects, Phrases and Region Captions\",\"url\":\"https://www.semanticscholar.org/paper/cf2de559e5a6235783e0762862f6e42192f142a8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.05345\",\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.18653/v1/N18-1143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb567cf793a6c4df1a652489c5ce866fe044f0e5\",\"title\":\"Supervised and Unsupervised Transfer Learning for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bb567cf793a6c4df1a652489c5ce866fe044f0e5\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2964284.2964288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f05908d2fad82129395ab81d4337fb454748667\",\"title\":\"Robust Visual-Textual Sentiment Analysis: When Attention meets Tree-structured Recursive Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0f05908d2fad82129395ab81d4337fb454748667\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"456983805a8781d6429bed1ed66dc9f3902767af\",\"title\":\"Seeing with Humans : Gaze-Assisted Neural Image\",\"url\":\"https://www.semanticscholar.org/paper/456983805a8781d6429bed1ed66dc9f3902767af\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"3348635\",\"name\":\"Haoran Wang\"}],\"doi\":\"10.1109/BigMM.2018.8499098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaf2eaf8ffd056799ae6bbe44f5939eb562fd8d9\",\"title\":\"Reference Based on Adaptive Attention Mechanism for Image Captioning*\",\"url\":\"https://www.semanticscholar.org/paper/eaf2eaf8ffd056799ae6bbe44f5939eb562fd8d9\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"}],\"doi\":\"10.1109/BigMM.2018.8499357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"title\":\"Video Captioning with Semantic Guiding\",\"url\":\"https://www.semanticscholar.org/paper/ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1811.00228\",\"authors\":[{\"authorId\":\"143827145\",\"name\":\"Daouda Sow\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"51910760\",\"name\":\"Mouhamed Niasse\"},{\"authorId\":\"46579572\",\"name\":\"T. Wan\"}],\"doi\":\"10.1109/ICASSP.2019.8682505\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"title\":\"A Sequential Guiding Network with Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"8425523\",\"name\":\"J. Hirayama\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"686b14ce7f02516730de03f459cadb223a03765f\",\"title\":\"Generating an Event Timeline About Daily Activities From a Semantic Concept Stream\",\"url\":\"https://www.semanticscholar.org/paper/686b14ce7f02516730de03f459cadb223a03765f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"269546925f0fd457b31c13c2870343b0aed761dc\",\"title\":\"Visual Question Answering with Question Representation Update (QRU)\",\"url\":\"https://www.semanticscholar.org/paper/269546925f0fd457b31c13c2870343b0aed761dc\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121260236\",\"name\":\"Vicente Dominguez\"},{\"authorId\":\"19324186\",\"name\":\"Pablo Messina\"},{\"authorId\":\"1410284615\",\"name\":\"Ivania Donoso-Guzm\\u00e1n\"},{\"authorId\":\"145831266\",\"name\":\"D. Parra\"}],\"doi\":\"10.1145/3301275.3302274\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb4f4a7ce55840712adf790efe5f0b2ee9770e09\",\"title\":\"The effect of explanations and algorithmic accuracy on visual recommender systems of artistic images\",\"url\":\"https://www.semanticscholar.org/paper/cb4f4a7ce55840712adf790efe5f0b2ee9770e09\",\"venue\":\"IUI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/MMUL.2018.112135923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da8f9211ea60755bb40811bb92de76be389566c6\",\"title\":\"Image and Video Captioning with Augmented Neural Architectures\",\"url\":\"https://www.semanticscholar.org/paper/da8f9211ea60755bb40811bb92de76be389566c6\",\"venue\":\"IEEE MultiMedia\",\"year\":2018},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f5a58e715afad8499d90c4855824c6967dbf39\",\"title\":\"Learning Visually Grounded and Multilingual Representations\",\"url\":\"https://www.semanticscholar.org/paper/58f5a58e715afad8499d90c4855824c6967dbf39\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.10692\",\"authors\":[{\"authorId\":\"1693704\",\"name\":\"H. F. Tung\"},{\"authorId\":\"34939798\",\"name\":\"Adam W. Harley\"},{\"authorId\":\"9930869\",\"name\":\"Liang-Kang Huang\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"}],\"doi\":\"10.1109/CVPR.2018.00732\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2558c26915e834b60b06be7da1d9db5d0897343\",\"title\":\"Reward Learning from Narrated Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/d2558c26915e834b60b06be7da1d9db5d0897343\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375391\",\"name\":\"Aparna Nurani Venkitasubramanian\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1007/s11042-017-4732-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79d8e93bf937772227790f3d000afe1c4440303d\",\"title\":\"Entity linking across vision and language\",\"url\":\"https://www.semanticscholar.org/paper/79d8e93bf937772227790f3d000afe1c4440303d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895813\",\"name\":\"Yibing Zhan\"},{\"authorId\":\"143923524\",\"name\":\"J. Yu\"},{\"authorId\":\"144478228\",\"name\":\"T. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1007/s11263-020-01353-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c40d14f9af8888dbc3713d790c161c7ef007fa52\",\"title\":\"Multi-task Compositional Network for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/c40d14f9af8888dbc3713d790c161c7ef007fa52\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40061480\",\"name\":\"Z. Dong\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"2000237078\",\"name\":\"Qi Cui\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/978-3-030-55187-2_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78a1094e0968cf4e2b61c83100d971031597ae4b\",\"title\":\"Adaptive Attention Mechanism Based Semantic Compositional Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/78a1094e0968cf4e2b61c83100d971031597ae4b\",\"venue\":\"IntelliSys\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144844426\",\"name\":\"M. Morris\"},{\"authorId\":\"47400663\",\"name\":\"Jazette Johnson\"},{\"authorId\":\"2803724\",\"name\":\"C. Bennett\"},{\"authorId\":\"1722375\",\"name\":\"E. Cutrell\"}],\"doi\":\"10.1145/3173574.3173633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c84e4275202f74a3f46059daad531da203c38dca\",\"title\":\"Rich Representations of Visual Content for Screen Reader Users\",\"url\":\"https://www.semanticscholar.org/paper/c84e4275202f74a3f46059daad531da203c38dca\",\"venue\":\"CHI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"3079146\",\"name\":\"Y. He\"},{\"authorId\":\"22567297\",\"name\":\"L. Fan\"}],\"doi\":\"10.1016/j.patrec.2017.09.007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bbd9a6cb28d1bda29844e77c3e5d80896324bc5\",\"title\":\"Let the robot tell: Describe car image with natural language via LSTM\",\"url\":\"https://www.semanticscholar.org/paper/4bbd9a6cb28d1bda29844e77c3e5d80896324bc5\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145344058\",\"name\":\"Tianyuan Yu\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"1805712\",\"name\":\"Jinlin Guo\"},{\"authorId\":\"40176711\",\"name\":\"Z. Yang\"},{\"authorId\":\"2248082\",\"name\":\"Yuxiang Xie\"}],\"doi\":\"10.1007/978-3-319-48890-5_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"871751d1cbee03875bc5d8789a5b9cfbe3e522f9\",\"title\":\"A Deep Two-Stream Network for Bidirectional Cross-Media Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/871751d1cbee03875bc5d8789a5b9cfbe3e522f9\",\"venue\":\"PCM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/2964284.2967242\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90c4a6c6f790dbcef9a29c9a755458be09e319b6\",\"title\":\"Attention-based LSTM with Semantic Consistency for Videos Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90c4a6c6f790dbcef9a29c9a755458be09e319b6\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.cviu.2017.04.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"title\":\"Hierarchical & multimodal video captioning: Discovering and transferring multimodal knowledge for vision to language\",\"url\":\"https://www.semanticscholar.org/paper/96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1704.06972\",\"authors\":[{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1109/CVPR.2017.780\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1de837d76d6513aa664f2d032d49ef12c938bbbb\",\"title\":\"Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/1de837d76d6513aa664f2d032d49ef12c938bbbb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2007.08074\",\"authors\":[{\"authorId\":\"1978641\",\"name\":\"Xiao-Qi Zhao\"},{\"authorId\":\"152551539\",\"name\":\"Y. Pang\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"},{\"authorId\":\"1452981772\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1007/978-3-030-58536-5_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0f9736c164afe7f57e232fe6c3e626ffee333f8\",\"title\":\"Suppress and Balance: A Simple Gated Network for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/a0f9736c164afe7f57e232fe6c3e626ffee333f8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2734498\",\"name\":\"N. Laokulrat\"},{\"authorId\":\"1764004\",\"name\":\"N. Okazaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8972dc1f5e59042c6ce111dc7591e8b5eed9737d\",\"title\":\"Incorporating Semantic Attention in Video Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/8972dc1f5e59042c6ce111dc7591e8b5eed9737d\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f22058a3003cee6b17c6c25c8a635a653e78614c\",\"title\":\"Multimodal Attention in Recurrent Neural Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f22058a3003cee6b17c6c25c8a635a653e78614c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-36718-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"title\":\"SACIC: A Semantics-Aware Convolutional Image Captioner Using Multi-level Pervasive Attention\",\"url\":\"https://www.semanticscholar.org/paper/9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27730319\",\"name\":\"Virginia Pinto Campos\"},{\"authorId\":\"34475830\",\"name\":\"L. M. G. Goncalves\"},{\"authorId\":\"34572692\",\"name\":\"Tiago Maritan Ugulino de Ara\\u00fajo\"}],\"doi\":\"10.1109/AVSS.2017.8078530\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b8ff42141d2625fb67f031d3c5f4e55ff7c310a\",\"title\":\"Applying audio description for context understanding of surveillance videos by people with visual impairments\",\"url\":\"https://www.semanticscholar.org/paper/8b8ff42141d2625fb67f031d3c5f4e55ff7c310a\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":\"1611.08309\",\"authors\":[{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"1691108\",\"name\":\"D. Kossmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76fa3008f02ffabfaedc46abf192ee1feec4651a\",\"title\":\"On Human Intellect and Machine Failures: Troubleshooting Integrative Machine Learning Systems\",\"url\":\"https://www.semanticscholar.org/paper/76fa3008f02ffabfaedc46abf192ee1feec4651a\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1905.01595\",\"authors\":[{\"authorId\":\"1895813\",\"name\":\"Yibing Zhan\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478228\",\"name\":\"T. Yu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.00527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56325ed57ae76d591a98d05cf94a9e891e389c40\",\"title\":\"On Exploring Undetermined Relationships for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/56325ed57ae76d591a98d05cf94a9e891e389c40\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.03694\",\"authors\":[{\"authorId\":\"1702290\",\"name\":\"Weiran Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"07f9e25dc0ee735480b9b4a0377ff4dfa9c0c165\",\"title\":\"Everything old is new again: A multi-view learning approach to learning using privileged information and distillation\",\"url\":\"https://www.semanticscholar.org/paper/07f9e25dc0ee735480b9b4a0377ff4dfa9c0c165\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2017.766\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"401cb8e62b915a7af0bd18776548896559566ce0\",\"title\":\"ViP-CNN: Visual Phrase Guided Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/401cb8e62b915a7af0bd18776548896559566ce0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1903.11649\",\"authors\":[{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/ICCV.2019.00269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a89cd9056c0fb037d659215b121686ff3b454fd5\",\"title\":\"Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment\",\"url\":\"https://www.semanticscholar.org/paper/a89cd9056c0fb037d659215b121686ff3b454fd5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1708.00634\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/ICCV.2017.289\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2cbdd5f24c2d6a4f33734636cc220f0825042f0\",\"title\":\"Dual-Glance Model for Deciphering Social Relationships\",\"url\":\"https://www.semanticscholar.org/paper/f2cbdd5f24c2d6a4f33734636cc220f0825042f0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92187979\",\"name\":\"C. Xu\"},{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"16003095\",\"name\":\"Meng-long Zhang\"},{\"authorId\":\"49470161\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ICUSAI47366.2019.9124779\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72364b3cd61221a99fb6be65e34a10c53db531cd\",\"title\":\"Attention-gated LSTM for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72364b3cd61221a99fb6be65e34a10c53db531cd\",\"venue\":\"2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40378636\",\"name\":\"Panqu Wang\"},{\"authorId\":\"2307211\",\"name\":\"Vicente L. Malave\"},{\"authorId\":\"2327561\",\"name\":\"Ben Cipollini\"}],\"doi\":\"10.1523/JNEUROSCI.3454-15.2015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6003e87932a403774307267b8526508f5288586\",\"title\":\"Encoding Voxels with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6003e87932a403774307267b8526508f5288586\",\"venue\":\"The Journal of Neuroscience\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.04474\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c5f9f5083b9fca4dcdbc4b122099ac1f630728b\",\"title\":\"Visual Semantic Role Labeling\",\"url\":\"https://www.semanticscholar.org/paper/0c5f9f5083b9fca4dcdbc4b122099ac1f630728b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1602.07360\",\"authors\":[{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2318023\",\"name\":\"Matthew W. Moskewicz\"},{\"authorId\":\"2059241\",\"name\":\"K. Ashraf\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"969fbdcd0717bec06228053788c2ff78bbb4daac\",\"title\":\"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size\",\"url\":\"https://www.semanticscholar.org/paper/969fbdcd0717bec06228053788c2ff78bbb4daac\",\"venue\":\"CVPR 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921534\",\"name\":\"Philip Kinghorn\"},{\"authorId\":\"41204462\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.neucom.2017.07.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"title\":\"A region-based image caption generator with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1809.07424\",\"authors\":[{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c280c95c17194de83e5234cca3586cd567ecd47c\",\"title\":\"Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing System Failure\",\"url\":\"https://www.semanticscholar.org/paper/c280c95c17194de83e5234cca3586cd567ecd47c\",\"venue\":\"HCOMP\",\"year\":2018},{\"arxivId\":\"1609.08124\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"title\":\"Learning Language-Visual Embedding for Movie Understanding with Natural-Language\",\"url\":\"https://www.semanticscholar.org/paper/2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1611.07212\",\"authors\":[{\"authorId\":\"39398377\",\"name\":\"A. Haque\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"868ae15b05c015fd9fdd93a2ca00c26ca4108699\",\"title\":\"Recurrent Attention Models for Depth-Based Person Identification\",\"url\":\"https://www.semanticscholar.org/paper/868ae15b05c015fd9fdd93a2ca00c26ca4108699\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.00790\",\"authors\":[{\"authorId\":\"47075011\",\"name\":\"Cheng Wang\"},{\"authorId\":\"1688587\",\"name\":\"Haojin Yang\"},{\"authorId\":\"28918194\",\"name\":\"C. Bartz\"},{\"authorId\":\"1708312\",\"name\":\"C. Meinel\"}],\"doi\":\"10.1145/2964284.2964299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26e425781e4090abfae65b5d68eac72282dd2e31\",\"title\":\"Image Captioning with Deep Bidirectional LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/26e425781e4090abfae65b5d68eac72282dd2e31\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2016.538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"50695255\",\"name\":\"S. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"145789906\",\"name\":\"G. Yang\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"239f8b0262622e90eb9353b101419027e69c6a50\",\"title\":\"Detect Globally, Refine Locally: A Novel Approach to Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/239f8b0262622e90eb9353b101419027e69c6a50\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bc9e06c6deaa8526b2aef5f96c2159b4cc232db\",\"title\":\"Learning from Collective Intelligence : Weakly-Supervised Feature Learning Using Largely Social Images and Tags\",\"url\":\"https://www.semanticscholar.org/paper/3bc9e06c6deaa8526b2aef5f96c2159b4cc232db\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"title\":\"Generalization to new compositions of known entities in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22771932\",\"name\":\"Shubo Ma\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ICME.2016.7552883\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb0e921fb3fe5e938f5fd9652c34ba2f44152997\",\"title\":\"Describing images by feeding LSTM with structural words\",\"url\":\"https://www.semanticscholar.org/paper/eb0e921fb3fe5e938f5fd9652c34ba2f44152997\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1906.02365\",\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144864336\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2909864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"title\":\"Context-Aware Visual Policy Network for Fine-Grained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df9a08016fa553a169d893ce2d3fca375bab4781\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df9a08016fa553a169d893ce2d3fca375bab4781\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"3374688\",\"name\":\"M. Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":null,\"name\":\"Heng Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"}],\"doi\":\"10.1016/J.PATREC.2019.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749f376d0addb83569fcc7536e46308abbb232d4\",\"title\":\"How much do cross-modal related semantics benefit image captioning by weighting attributes and re-ranking sentences?\",\"url\":\"https://www.semanticscholar.org/paper/749f376d0addb83569fcc7536e46308abbb232d4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1807.09434\",\"authors\":[{\"authorId\":\"2183432\",\"name\":\"Boeun Kim\"},{\"authorId\":\"49380412\",\"name\":\"Y. Lee\"},{\"authorId\":\"3011724\",\"name\":\"Hyedong Jung\"},{\"authorId\":\"2529532\",\"name\":\"C. S. Cho\"}],\"doi\":\"10.1007/978-3-030-11018-5_12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"239a38663967140e026385f6625a913a3e7b1cd7\",\"title\":\"Distinctive-attribute Extraction for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/239a38663967140e026385f6625a913a3e7b1cd7\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1804.06786\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"1705700\",\"name\":\"David Mimno\"},{\"authorId\":\"145810617\",\"name\":\"Lillian Lee\"}],\"doi\":\"10.18653/v1/N18-1199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d02bf4082850a667bf0b7b6205df1cf9c1899233\",\"title\":\"Quantifying the visual concreteness of words and topics in multimodal datasets\",\"url\":\"https://www.semanticscholar.org/paper/d02bf4082850a667bf0b7b6205df1cf9c1899233\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba67de7e822a94091b9e57cc9be3069822a4f5c8\",\"title\":\"A Neural-Symbolic Approach to Natural Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ba67de7e822a94091b9e57cc9be3069822a4f5c8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.07141\",\"authors\":[{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"},{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/TPAMI.2017.2721945\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82d9b588eabeb6bf4baa945d5c71b3bf89dd1e69\",\"title\":\"BreakingNews: Article Annotation by Image and Text Processing\",\"url\":\"https://www.semanticscholar.org/paper/82d9b588eabeb6bf4baa945d5c71b3bf89dd1e69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1603.06059\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.18653/v1/P16-1170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"title\":\"Generating Natural Questions About an Image\",\"url\":\"https://www.semanticscholar.org/paper/8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1745000\",\"name\":\"H. Wang\"}],\"doi\":\"10.1145/2733373.2807418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b17b9c40ea8bb8904b782e91627c1f022a5574f\",\"title\":\"Learning Knowledge Bases for Multimedia in 2015\",\"url\":\"https://www.semanticscholar.org/paper/9b17b9c40ea8bb8904b782e91627c1f022a5574f\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"074eb7a6940d8629c6f26594a1f485d42aba8821\",\"title\":\"Simple Image Description Generator via a Linear Phrase-based Model\",\"url\":\"https://www.semanticscholar.org/paper/074eb7a6940d8629c6f26594a1f485d42aba8821\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3390891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb9fb10f604a196515e48ad90f217d33794f5991\",\"title\":\"Recurrent Attention Network with Reinforced Generator for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cb9fb10f604a196515e48ad90f217d33794f5991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2008.12416\",\"authors\":[{\"authorId\":\"48607882\",\"name\":\"Yuhuan Wu\"},{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"1500381094\",\"name\":\"Wang Gao\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"886699cc3e58dcdfae5173543f7d0d850a6ebec4\",\"title\":\"Regularized Densely-connected Pyramid Network for Salient Instance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/886699cc3e58dcdfae5173543f7d0d850a6ebec4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.07449\",\"authors\":[{\"authorId\":\"8118056\",\"name\":\"Tristan Sylvain\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"198333f1f426224de2f36a3ee2aa48e54cf4ba3e\",\"title\":\"Object-Centric Image Generation from Layouts\",\"url\":\"https://www.semanticscholar.org/paper/198333f1f426224de2f36a3ee2aa48e54cf4ba3e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2badc4c87a7751dd5ae1797bc4091d10d1acf442\",\"title\":\"Multimodal Retrieval With Asymmetrically Weighted Regularized Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/2badc4c87a7751dd5ae1797bc4091d10d1acf442\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8682392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dee549ba6f09e59c6d6d13434a2b023d868467a\",\"title\":\"Image Captioning with Two Cascaded Agents\",\"url\":\"https://www.semanticscholar.org/paper/4dee549ba6f09e59c6d6d13434a2b023d868467a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47309386\",\"name\":\"Meghana Joshi\"},{\"authorId\":\"51464770\",\"name\":\"Sonam Damani\"},{\"authorId\":\"51496146\",\"name\":\"Khyatti Gupta\"},{\"authorId\":\"38731539\",\"name\":\"N. Raviprakash\"}],\"doi\":\"10.1145/3308560.3316472\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c7ac38ca638629707ba494c7c426fb5cbfd86af\",\"title\":\"Lightning Talk - Ruuh: A Conversational Social Agent\",\"url\":\"https://www.semanticscholar.org/paper/0c7ac38ca638629707ba494c7c426fb5cbfd86af\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":\"1601.03916\",\"authors\":[{\"authorId\":\"1828499\",\"name\":\"Julian Hitschler\"},{\"authorId\":\"2026457\",\"name\":\"Shigehiko Schamoni\"},{\"authorId\":\"3289329\",\"name\":\"S. Riezler\"}],\"doi\":\"10.18653/v1/P16-1227\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcf6ea33ab5f9af8019fab4bbbabba3b2231f03b\",\"title\":\"Multimodal Pivots for Image Caption Translation\",\"url\":\"https://www.semanticscholar.org/paper/dcf6ea33ab5f9af8019fab4bbbabba3b2231f03b\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1608.00272\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"3451188\",\"name\":\"Patrick Poirson\"},{\"authorId\":\"144947353\",\"name\":\"S. Yang\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46475-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"title\":\"Modeling Context in Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"}],\"doi\":\"10.18653/v1/D16-1128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"604764133befe7a0aaa692919545846197e6e065\",\"title\":\"Neural Text Generation from Structured Data with Application to the Biography Domain\",\"url\":\"https://www.semanticscholar.org/paper/604764133befe7a0aaa692919545846197e6e065\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df4f851e3c37017822a683b1356c6c390b5b5487\",\"title\":\"Image Question Answering: A Visual Semantic Embedding Model and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/df4f851e3c37017822a683b1356c6c390b5b5487\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2031480\",\"name\":\"Manoj Kumar Chinnakotla\"},{\"authorId\":\"40039923\",\"name\":\"P. Agrawal\"}],\"doi\":\"10.1145/3209978.3210209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2569cb658b681bc969f1229c87a2f20e2f51e92\",\"title\":\"Lessons from Building a Large-scale Commercial IR-based Chatbot for an Emerging Market\",\"url\":\"https://www.semanticscholar.org/paper/d2569cb658b681bc969f1229c87a2f20e2f51e92\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7221695df4de3f34d5e4a877b71c14bc88760d2\",\"title\":\"Proposal Incorporating Structural Bias into Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d7221695df4de3f34d5e4a877b71c14bc88760d2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.02250\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"119899233\",\"name\":\"Len Hamey\"}],\"doi\":\"10.1007/978-3-030-10925-7_14\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"036c29c2c2a2494faae205c0f270ce4d076cc3f2\",\"title\":\"Face-Cap: Image Captioning using Facial Expression Analysis\",\"url\":\"https://www.semanticscholar.org/paper/036c29c2c2a2494faae205c0f270ce4d076cc3f2\",\"venue\":\"ECML/PKDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c192cd39f90eb8ff2969f8916ef8967607c5298\",\"title\":\"Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/8c192cd39f90eb8ff2969f8916ef8967607c5298\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1903.01072\",\"authors\":[{\"authorId\":\"47060391\",\"name\":\"J. Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"38900275\",\"name\":\"Joon Huang Chuah\"}],\"doi\":\"10.1109/TMM.2019.2904878\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"title\":\"COMIC: Toward A Compact Image Captioning Model With Attention\",\"url\":\"https://www.semanticscholar.org/paper/9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1809.04144\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"title\":\"End-to-end Image Captioning Exploits Multimodal Distributional Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134473603\",\"name\":\"Mohammedsayeemuddin K Shaikh\"},{\"authorId\":\"3226334\",\"name\":\"M. V. Joshi\"}],\"doi\":\"10.1109/SPCOM.2018.8724400\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c85da5f3b2de5a681d0d97a27f0db47b89c84d0\",\"title\":\"Recursive Network with Explicit Neighbor Connection for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c85da5f3b2de5a681d0d97a27f0db47b89c84d0\",\"venue\":\"2018 International Conference on Signal Processing and Communications (SPCOM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13760868\",\"name\":\"Katharina Schwarz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1809190\",\"name\":\"H. Lensch\"}],\"doi\":\"10.1007/978-3-319-54190-7_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2347d47ba35e19a55d15deae5c2613adb22e55da\",\"title\":\"Auto-Illustrating Poems and Songs with Style\",\"url\":\"https://www.semanticscholar.org/paper/2347d47ba35e19a55d15deae5c2613adb22e55da\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.06315\",\"authors\":[{\"authorId\":\"153636852\",\"name\":\"Soumik Ranjan Dasgupta\"},{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"title\":\"Dynamic Attention Networks for Task Oriented Grounding\",\"url\":\"https://www.semanticscholar.org/paper/361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"31126576\",\"name\":\"Zheng Xiong\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"9245443\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.3390/app10010391\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"945ffeb90e538214e3063407db8e094469ec877a\",\"title\":\"Panoptic Segmentation-Based Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/945ffeb90e538214e3063407db8e094469ec877a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1812.08352\",\"authors\":[{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yitong Li\"},{\"authorId\":\"31617773\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8f2ba261756ca551ba68940e08a9466c2602f79\",\"title\":\"Sequential Attention GAN for Interactive Image Editing via Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/b8f2ba261756ca551ba68940e08a9466c2602f79\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1510.04709\",\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"37922370\",\"name\":\"S. Frank\"},{\"authorId\":\"2955842\",\"name\":\"E. Hasler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5af227e3e3158158163fb0715ae3971be2e1df4\",\"title\":\"Multilingual Image Description with Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/a5af227e3e3158158163fb0715ae3971be2e1df4\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144844426\",\"name\":\"M. Morris\"},{\"authorId\":\"3396892\",\"name\":\"Annuska Zolyomi\"},{\"authorId\":\"3396850\",\"name\":\"Catherine Yao\"},{\"authorId\":\"3196867\",\"name\":\"Sina Bahram\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"2893996\",\"name\":\"S. Kane\"}],\"doi\":\"10.1145/2858036.2858116\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4acbc3656424766e39a6fbb0ae758d90554111e\",\"title\":\"\\\"With most of it being pictures now, I rarely use it\\\": Understanding Twitter's Evolving Accessibility to Blind Users\",\"url\":\"https://www.semanticscholar.org/paper/e4acbc3656424766e39a6fbb0ae758d90554111e\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741174\",\"name\":\"Z. Shi\"},{\"authorId\":\"2430445\",\"name\":\"Zhengxia Zou\"}],\"doi\":\"10.1109/TGRS.2017.2677464\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8956305288444e6ed1bcaaf3e6d4a5eb6e479eb2\",\"title\":\"Can a Machine Generate Humanlike Language Descriptions for a Remote Sensing Image?\",\"url\":\"https://www.semanticscholar.org/paper/8956305288444e6ed1bcaaf3e6d4a5eb6e479eb2\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2017},{\"arxivId\":\"1606.07770\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.130\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"title\":\"Captioning Images with Diverse Objects\",\"url\":\"https://www.semanticscholar.org/paper/b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1821267\",\"name\":\"A. Gordo\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"}],\"doi\":\"10.1109/CVPR.2017.560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb3e81b912f24e66d91509e8ab41d09b522a397a\",\"title\":\"Beyond Instance-Level Image Retrieval: Leveraging Captions to Learn a Global Visual Representation for Semantic Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/cb3e81b912f24e66d91509e8ab41d09b522a397a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.5244/C.30.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02d6fb270c82c390476faffc6015b3116ddbb60c\",\"title\":\"Image Captioning with Sentiment Terms via Weakly-Supervised Sentiment Dataset\",\"url\":\"https://www.semanticscholar.org/paper/02d6fb270c82c390476faffc6015b3116ddbb60c\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1912135\",\"name\":\"V. Jindal\"}],\"doi\":\"10.18653/v1/N18-4020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49ed7d18d67c20c4152ba26cc235b2a8e4aec0d5\",\"title\":\"Generating Image Captions in Arabic Using Root-Word Based Recurrent Neural Networks and Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/49ed7d18d67c20c4152ba26cc235b2a8e4aec0d5\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3407447\",\"name\":\"Rama Kovvuri\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/s13735-017-0139-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0047121fdb983e8189dd69006ddce89fe3bc3a\",\"title\":\"MSRC: multimodal spatial regression with semantic context for phrase grounding\",\"url\":\"https://www.semanticscholar.org/paper/cb0047121fdb983e8189dd69006ddce89fe3bc3a\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145129037\",\"name\":\"Kun Huang\"},{\"authorId\":\"1782912\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/CISP-BMEI.2016.7852756\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b03b9463ed01ee6131743372c72810c90e129597\",\"title\":\"Fine-grained vehicle recognition by deep Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b03b9463ed01ee6131743372c72810c90e129597\",\"venue\":\"2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2016},{\"arxivId\":\"1904.12004\",\"authors\":[{\"authorId\":\"98243944\",\"name\":\"Chenglong Wang\"},{\"authorId\":\"3407947\",\"name\":\"R. Bunel\"},{\"authorId\":\"1729912\",\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":\"10.1109/CVPR.2019.01254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59b439bde73d80dccf367d414e209d08d312c059\",\"title\":\"Knowing When to Stop: Evaluation and Verification of Conformity to Output-Size Specifications\",\"url\":\"https://www.semanticscholar.org/paper/59b439bde73d80dccf367d414e209d08d312c059\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39491387\",\"name\":\"J. Zhou\"},{\"authorId\":\"21576252\",\"name\":\"Jiangbo Ai\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"}],\"doi\":\"10.1109/TIP.2018.2855422\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd3d94fac6a282414406716040b10c1746634ecd\",\"title\":\"Video Captioning by Adversarial LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fd3d94fac6a282414406716040b10c1746634ecd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICPR.2018.8545049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c6272a095d6601acf683d9f94c8683009cd1e5c\",\"title\":\"Image Captioning using Adversarial Networks and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3c6272a095d6601acf683d9f94c8683009cd1e5c\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"A. Apicella\"},{\"authorId\":\"13851143\",\"name\":\"A. Corazza\"},{\"authorId\":\"34675913\",\"name\":\"F. Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.3390/info9100252\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e08dcf5e8fb1e5a59408c267af64145ce2e9daeb\",\"title\":\"Integration of Context Information through Probabilistic Ontological Knowledge into Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/e08dcf5e8fb1e5a59408c267af64145ce2e9daeb\",\"venue\":\"Inf.\",\"year\":2018},{\"arxivId\":\"1909.03493\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1609/AAAI.V34I07.6785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77802591c3f5b3f654bb5b68ad62ed056769320f\",\"title\":\"MULE: Multimodal Universal Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/77802591c3f5b3f654bb5b68ad62ed056769320f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1705.08844\",\"authors\":[{\"authorId\":\"15316342\",\"name\":\"Rodrigo Toro Icarte\"},{\"authorId\":\"2170801\",\"name\":\"Jorge A. Baier\"},{\"authorId\":\"2095964\",\"name\":\"C. Ruz\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.24963/ijcai.2017/178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4e69a06833706d7ab174072ddcff35a3a22516c\",\"title\":\"How a General-Purpose Commonsense Ontology can Improve Performance of Learning-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/e4e69a06833706d7ab174072ddcff35a3a22516c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146940789\",\"name\":\"Ha Nguyen Tien\"},{\"authorId\":\"2269079\",\"name\":\"Thanh-Ha Do\"},{\"authorId\":\"122777102\",\"name\":\"Van-Anh Nguyen\"}],\"doi\":\"10.1007/978-3-030-63119-2_64\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f000dce82acc480626de90c6a8549cf53e4aed84\",\"title\":\"Image Captioning in Vietnamese Language Based on Deep Learning Network\",\"url\":\"https://www.semanticscholar.org/paper/f000dce82acc480626de90c6a8549cf53e4aed84\",\"venue\":\"ICCCI\",\"year\":2020},{\"arxivId\":\"1412.8419\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"015d25f66514ce0a966300944201d45968a104ba\",\"title\":\"Simple Image Description Generator via a Linear Phrase-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/015d25f66514ce0a966300944201d45968a104ba\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"}],\"doi\":\"10.1145/2911996.2912043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f4dba1875eb7fb32d21bea88df7c4a9412eccb\",\"title\":\"Video Description Generation using Audio and Visual Cues\",\"url\":\"https://www.semanticscholar.org/paper/54f4dba1875eb7fb32d21bea88df7c4a9412eccb\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.08315\",\"authors\":[{\"authorId\":\"151195783\",\"name\":\"Ruixiang Tang\"},{\"authorId\":\"3432460\",\"name\":\"Mengnan Du\"},{\"authorId\":\"48513905\",\"name\":\"Yuening Li\"},{\"authorId\":\"47781070\",\"name\":\"Zirui Liu\"},{\"authorId\":\"1490483806\",\"name\":\"X. Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b239fe63de5de0a1e0c08af97a30f79b5a2bdbc\",\"title\":\"Mitigating Gender Bias in Captioning Systems\",\"url\":\"https://www.semanticscholar.org/paper/0b239fe63de5de0a1e0c08af97a30f79b5a2bdbc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c151789dd630798a77eba0e400de55603a72cb19\",\"title\":\"Spatial-Semantic Image Search by Visual Feature Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c151789dd630798a77eba0e400de55603a72cb19\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.09902\",\"authors\":[{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":\"10.1613/jair.5477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d13bb317e87f3f6da10da11059ebf4350b754814\",\"title\":\"Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d13bb317e87f3f6da10da11059ebf4350b754814\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375391\",\"name\":\"Aparna Nurani Venkitasubramanian\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.18653/v1/W17-2003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a2da477ea5eeabc043166c6fe1d85a3b586100c\",\"title\":\"Learning to Recognize Animals by Watching Documentaries: Using Subtitles as Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6a2da477ea5eeabc043166c6fe1d85a3b586100c\",\"venue\":\"VL@EACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3241910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"title\":\"Images2Poem: Generating Chinese Poetry from Image Streams\",\"url\":\"https://www.semanticscholar.org/paper/c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404464386\",\"name\":\"Carlos de la Torre-Ortiz\"},{\"authorId\":\"2353675\",\"name\":\"M. Spap\\u00e9\"},{\"authorId\":\"151091693\",\"name\":\"Lauri Kangassalo\"},{\"authorId\":\"2084101\",\"name\":\"Tuukka Ruotsalo\"}],\"doi\":\"10.1145/3379337.3415821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8419e1ec78f4d2961e3e72e6fa4c0b420e556f54\",\"title\":\"Brain Relevance Feedback for Interactive Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/8419e1ec78f4d2961e3e72e6fa4c0b420e556f54\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":\"1605.07912\",\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"title\":\"Encode, Review, and Decode: Reviewer Module for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"title\":\"Situation Recognition: Visual Semantic Role Labeling for Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/978-3-319-51811-4_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"title\":\"What Convnets Make for Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292515\",\"name\":\"Z. Liu\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":null,\"name\":\"Chen Shen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"}],\"doi\":\"10.1007/978-3-319-97304-3_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe3af3e0e06c1d0adf5173adea06c268692be10d\",\"title\":\"Topic-Guided Automatical Human-Simulated Tweeting System\",\"url\":\"https://www.semanticscholar.org/paper/fe3af3e0e06c1d0adf5173adea06c268692be10d\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":\"1611.06949\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.214\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"title\":\"Dense Captioning with Joint Inference and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73195876\",\"name\":\"M. Najman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eea248baa16162da661fbb9255e2cfcd5b9f0c05\",\"title\":\"Bachelor Project Image Captioning with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/eea248baa16162da661fbb9255e2cfcd5b9f0c05\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/WACV.2018.00205\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"03c820f35afdc38dd05e4c663d2877e2602bcde0\",\"title\":\"Semantically Guided Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/03c820f35afdc38dd05e4c663d2877e2602bcde0\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3418540\",\"name\":\"Athanasios Psaltis\"},{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":\"10.1109/CBMI.2018.8516470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12c12b4c86cf5254a4f0869e2ff6fc1b810601da\",\"title\":\"Deep 3D Flow Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12c12b4c86cf5254a4f0869e2ff6fc1b810601da\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67091864\",\"name\":\"D. Chechelnytskyy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c1875e73c7709a89c923e6c0f634cefdfeb18ba\",\"title\":\"Deep neural models to represent news events\",\"url\":\"https://www.semanticscholar.org/paper/1c1875e73c7709a89c923e6c0f634cefdfeb18ba\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25b78b68f8c9b50b7f9290d88134fc377fd43433\",\"title\":\"CloudCV: Deep Learning and Computer Vision on the Cloud\",\"url\":\"https://www.semanticscholar.org/paper/25b78b68f8c9b50b7f9290d88134fc377fd43433\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2980330\",\"name\":\"Xiaqing Li\"},{\"authorId\":\"8274453\",\"name\":\"Guangyan Zhang\"},{\"authorId\":\"2660680\",\"name\":\"Zhufan Wang\"},{\"authorId\":\"2225511\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/TPDS.2018.2864299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd75cb9d947f2fce9a1c34d76ab3f90c86aeefeb\",\"title\":\"HyConv: Accelerating Multi-Phase CNN Computation by Fine-Grained Policy Selection\",\"url\":\"https://www.semanticscholar.org/paper/dd75cb9d947f2fce9a1c34d76ab3f90c86aeefeb\",\"venue\":\"IEEE Transactions on Parallel and Distributed Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":\"1909.09953\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b488019592d8e0c08e6cd011ae0543a6ac451357\",\"title\":\"Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators\",\"url\":\"https://www.semanticscholar.org/paper/b488019592d8e0c08e6cd011ae0543a6ac451357\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39819744\",\"name\":\"J. Liu\"},{\"authorId\":\"49605237\",\"name\":\"J. Wang\"},{\"authorId\":\"1749731\",\"name\":\"Y. Zhou\"},{\"authorId\":\"47185625\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2938234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39d8e67001f1ad370626d53152a383871ba6fab7\",\"title\":\"A Cloud Server Oriented FPGA Accelerator for LSTM Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/39d8e67001f1ad370626d53152a383871ba6fab7\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758254\",\"name\":\"Virg\\u00ednia P. Campos\"},{\"authorId\":\"152123212\",\"name\":\"Tiago M. U. de Ara\\u00fajo\"},{\"authorId\":\"1521983402\",\"name\":\"Guido L. de Souza Filho\"},{\"authorId\":\"1703957\",\"name\":\"L. Gon\\u00e7alves\"}],\"doi\":\"10.1007/s10209-018-0634-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97b0e43ae18f32378d41c2730268aa7f0f6ba462\",\"title\":\"CineAD: a system for automated audio description script generation for the visually impaired\",\"url\":\"https://www.semanticscholar.org/paper/97b0e43ae18f32378d41c2730268aa7f0f6ba462\",\"venue\":\"Universal Access in the Information Society\",\"year\":2018},{\"arxivId\":\"1805.00314\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-1198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"title\":\"Object Counts! Bringing Explicit Detections Back into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46458416\",\"name\":\"L. Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"48263872\",\"name\":\"Ruiguo Zhang\"},{\"authorId\":\"1490736109\",\"name\":\"Yuxuan Ding\"}],\"doi\":\"10.1117/12.2557584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d11973ef9567133ae8035dfbd4e96c87ca36505\",\"title\":\"Generating description with multi-feature and saliency maps of image\",\"url\":\"https://www.semanticscholar.org/paper/0d11973ef9567133ae8035dfbd4e96c87ca36505\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72350529\",\"name\":\"Abdelhafid Dakhia\"},{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa7c21dd045f248cac67e6298f32804b5e79548\",\"title\":\"A hybrid-backward refinement model for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/4aa7c21dd045f248cac67e6298f32804b5e79548\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144343897\",\"name\":\"R. Guo\"},{\"authorId\":\"22771932\",\"name\":\"Shubo Ma\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/s11042-018-7118-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"title\":\"Image captioning: from structural tetrad to translated sentences\",\"url\":\"https://www.semanticscholar.org/paper/ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1606.07287\",\"authors\":[{\"authorId\":\"1996072\",\"name\":\"Fabio Carrara\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"2811629\",\"name\":\"T. Fagni\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"38218211\",\"name\":\"Alejandro Moreo\"}],\"doi\":\"10.1007/s10791-017-9318-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"303da9a87f1bdc9057eb19b19860a2e83f5375d0\",\"title\":\"Picture it in your mind: generating high level visual representations from textual descriptions\",\"url\":\"https://www.semanticscholar.org/paper/303da9a87f1bdc9057eb19b19860a2e83f5375d0\",\"venue\":\"Information Retrieval Journal\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13310524\",\"name\":\"Bingbing Han\"},{\"authorId\":\"47295137\",\"name\":\"Z. Zhang\"},{\"authorId\":\"3303862\",\"name\":\"Chuanyu Xu\"},{\"authorId\":\"2931985\",\"name\":\"B. Wang\"},{\"authorId\":\"38819702\",\"name\":\"Guosheng Hu\"},{\"authorId\":\"145515614\",\"name\":\"Lu Bai\"},{\"authorId\":\"40300673\",\"name\":\"Qingqi Hong\"},{\"authorId\":\"1679753\",\"name\":\"E. Hancock\"}],\"doi\":\"10.1007/978-3-319-68548-9_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"036262f3a2eb00494bc152af751d9180caa4f7ca\",\"title\":\"Deep Face Model Compression Using Entropy-Based Filter Selection\",\"url\":\"https://www.semanticscholar.org/paper/036262f3a2eb00494bc152af751d9180caa4f7ca\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.08709\",\"authors\":[{\"authorId\":\"48773674\",\"name\":\"Lydia Weiland\"},{\"authorId\":\"2680937\",\"name\":\"Ioana Hulpus\"},{\"authorId\":\"1801255\",\"name\":\"Simone Paolo Ponzetto\"},{\"authorId\":\"1750165\",\"name\":\"W. Effelsberg\"},{\"authorId\":\"145798497\",\"name\":\"Laura Dietz\"}],\"doi\":\"10.1016/j.datak.2018.07.006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3293346fa3ae58fa1a93cad668da16827eb7620\",\"title\":\"Knowledge-rich image gist understanding beyond literal meaning\",\"url\":\"https://www.semanticscholar.org/paper/d3293346fa3ae58fa1a93cad668da16827eb7620\",\"venue\":\"Data Knowl. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"}],\"doi\":\"10.1007/978-3-030-29516-5_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"422910cd883a39a42e40d6630997c95cb1864d44\",\"title\":\"Anticipating Next Goal for Robot Plan Prediction\",\"url\":\"https://www.semanticscholar.org/paper/422910cd883a39a42e40d6630997c95cb1864d44\",\"venue\":\"IntelliSys\",\"year\":2019},{\"arxivId\":\"1505.06798\",\"authors\":[{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"47114430\",\"name\":\"Jianhua Zou\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/TPAMI.2015.2502579\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b89d7f7439cab841934a1ede06bf6b1f593c754f\",\"title\":\"Accelerating Very Deep Convolutional Networks for Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/b89d7f7439cab841934a1ede06bf6b1f593c754f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.07639\",\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"3451674\",\"name\":\"Vahid Kezami\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"936227f7483938097cc1cdd3032016df54dbd5b6\",\"title\":\"Learning to generalize to new compositions in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/936227f7483938097cc1cdd3032016df54dbd5b6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375391\",\"name\":\"Aparna Nurani Venkitasubramanian\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1016/j.patrec.2016.01.025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ec05713a1eed6fa9b57fef718f369f68bbbe09f\",\"title\":\"Wildlife recognition in nature documentaries with weak supervision from subtitles and external data\",\"url\":\"https://www.semanticscholar.org/paper/3ec05713a1eed6fa9b57fef718f369f68bbbe09f\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2016},{\"arxivId\":\"1502.03671\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"123b9de009865472c660192f8072493a48352dc2\",\"title\":\"Phrase-based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123b9de009865472c660192f8072493a48352dc2\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"2009.05175\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"87784755\",\"name\":\"A. Thapliyal\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"title\":\"Weakly Supervised Content Selection for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1603.09188\",\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.18653/v1/N16-1022\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e3cf09d619cff79b8379b639cddfcd09451995b\",\"title\":\"Unsupervised Visual Sense Disambiguation for Verbs using Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/3e3cf09d619cff79b8379b639cddfcd09451995b\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144540018\",\"name\":\"Wei Ji\"},{\"authorId\":\"92384987\",\"name\":\"X. Li\"},{\"authorId\":\"50589478\",\"name\":\"Lina Wei\"},{\"authorId\":\"1521935491\",\"name\":\"Fei Wu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/tip.2020.3002083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab286c3e07366cd734223ddda4fea94b06a72af0\",\"title\":\"Context-Aware Graph Label Propagation Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/ab286c3e07366cd734223ddda4fea94b06a72af0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2006.09920\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"47008546\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1007/978-3-030-58580-8_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14e6c84fd88badeaa969c27d4cdada764877afff\",\"title\":\"Contrastive Learning for Weakly Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/14e6c84fd88badeaa969c27d4cdada764877afff\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153006313\",\"name\":\"Z. Wu\"},{\"authorId\":\"1750922204\",\"name\":\"Shuai Li\"},{\"authorId\":\"3289090\",\"name\":\"Chenglizhao Chen\"},{\"authorId\":\"143811959\",\"name\":\"Aimin Hao\"},{\"authorId\":\"1830614308\",\"name\":\"Hong Qin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"863b798de6245a542c116fe4fb0db3b4783de0e5\",\"title\":\"Recursive Multi-model Complementary Deep Fusion forRobust Salient Object Detection via Parallel Sub Networks\",\"url\":\"https://www.semanticscholar.org/paper/863b798de6245a542c116fe4fb0db3b4783de0e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1604.02125\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"48222562\",\"name\":\"A. Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"98391857\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eb2c900814707ae962184ad4173e754247a80a\",\"title\":\"Resolving Language and Vision Ambiguities Together: Joint Segmentation & Prepositional Attachment Resolution in Captioned Scenes\",\"url\":\"https://www.semanticscholar.org/paper/26eb2c900814707ae962184ad4173e754247a80a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"39943835\",\"name\":\"Gui-Song Xia\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"2872774\",\"name\":\"W. Dong\"}],\"doi\":\"10.1016/J.PATREC.2017.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390d0bb977b7473b8b76d045875c767d743de943\",\"title\":\"Image Caption Generation with Part of Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/390d0bb977b7473b8b76d045875c767d743de943\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1710.02534\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83d66c1f808962536a68418587b691f30221c5a1\",\"title\":\"Contrastive Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/83d66c1f808962536a68418587b691f30221c5a1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/TASLP.2018.2872106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e56c99e8a94d3e585166fcd66f2ab6da60932f09\",\"title\":\"Semantic Speech Retrieval With a Visually Grounded Model of Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/e56c99e8a94d3e585166fcd66f2ab6da60932f09\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.04590\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.5244/C.30.141\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"16aac81ae033f7295d82e5b679400d105170a3e1\",\"title\":\"Oracle Performance for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/16aac81ae033f7295d82e5b679400d105170a3e1\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145471480\",\"name\":\"Yunmeng Feng\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46446912\",\"name\":\"X. Zhang\"},{\"authorId\":\"7521170\",\"name\":\"Chuanfu Xu\"},{\"authorId\":\"2243533\",\"name\":\"Zhenghua Wang\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1145/3302425.3302464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"title\":\"AttResNet: Attention-based ResNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1604.04842\",\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-016-0958-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d0584075807741798055af1b6711475babc4315\",\"title\":\"Subjects and Their Objects: Localizing Interactees for a Person-Centric View of Importance\",\"url\":\"https://www.semanticscholar.org/paper/5d0584075807741798055af1b6711475babc4315\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"2012.13122\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5318abd4f12a5b25c2847e9c66713951341af504\",\"title\":\"SubICap: Towards Subword-informed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5318abd4f12a5b25c2847e9c66713951341af504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.00749\",\"authors\":[{\"authorId\":\"36904159\",\"name\":\"J. Zhu\"},{\"authorId\":\"47912692\",\"name\":\"Hua Yang\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"2918263\",\"name\":\"Minyoung Kim\"},{\"authorId\":\"144913615\",\"name\":\"W. Zhang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01228-1_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fefa8f07d998f8f4a6c85a7da781b19bf6b78d7d\",\"title\":\"Online Multi-Object Tracking with Dual Matching Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/fefa8f07d998f8f4a6c85a7da781b19bf6b78d7d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.07482\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37f371fe04f3dc38df7f27f43277ba15d3637890\",\"title\":\"Imperial College London Submission to VATEX Video Captioning Task\",\"url\":\"https://www.semanticscholar.org/paper/37f371fe04f3dc38df7f27f43277ba15d3637890\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014498\",\"name\":\"Q. Liu\"},{\"authorId\":\"50580380\",\"name\":\"Yingying Chen\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"27356041\",\"name\":\"Sijiong Zhang\"}],\"doi\":\"10.1016/j.compind.2018.01.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ed73cea8227a9a4733146053c2d1baa52de9572\",\"title\":\"Multi-view pedestrian captioning with an attention topic CNN model\",\"url\":\"https://www.semanticscholar.org/paper/1ed73cea8227a9a4733146053c2d1baa52de9572\",\"venue\":\"Comput. Ind.\",\"year\":2018},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"title\":\"VisualNews : Benchmark and Challenges in Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"title\":\"What value high level concepts in vision to language problems\",\"url\":\"https://www.semanticscholar.org/paper/bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1605.09553\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"title\":\"Attention Correctness in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49645155\",\"name\":\"Yan-shuo Chang\"}],\"doi\":\"10.1007/s11042-017-4593-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2617da2d4a0466784809981babcdb7f697b5f24\",\"title\":\"Fine-grained attention for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/f2617da2d4a0466784809981babcdb7f697b5f24\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1605.00855\",\"authors\":[{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1007/978-3-319-48896-7_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45c0d4ea93566d366ec14d39fae8cf12309cdbc8\",\"title\":\"Improving Image Captioning by Concept-Based Sentence Reranking\",\"url\":\"https://www.semanticscholar.org/paper/45c0d4ea93566d366ec14d39fae8cf12309cdbc8\",\"venue\":\"PCM\",\"year\":2016},{\"arxivId\":\"1608.00187\",\"authors\":[{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46448-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d9506257186023b78cf19ed4f9e77a4ae4fa0f0\",\"title\":\"Visual Relationship Detection with Language Priors\",\"url\":\"https://www.semanticscholar.org/paper/4d9506257186023b78cf19ed4f9e77a4ae4fa0f0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1612.06519\",\"authors\":[{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f614de5a406beec7e3de85bcc6dfac222390266c\",\"title\":\"Exploring the Design Space of Deep Convolutional Neural Networks at Large Scale\",\"url\":\"https://www.semanticscholar.org/paper/f614de5a406beec7e3de85bcc6dfac222390266c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1807.08435\",\"authors\":[{\"authorId\":\"51151974\",\"name\":\"Prakruthi Prabhakar\"},{\"authorId\":\"51115915\",\"name\":\"Nitish Kulkarni\"},{\"authorId\":\"2145765\",\"name\":\"Linghao Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a838a1184cb9ca86ae910509bb318266101ae656\",\"title\":\"Question Relevance in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a838a1184cb9ca86ae910509bb318266101ae656\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"35528948\",\"name\":\"M. A. Khan\"},{\"authorId\":\"32824146\",\"name\":\"Ammarah Farooq\"},{\"authorId\":\"46198155\",\"name\":\"Z. Rehman\"},{\"authorId\":\"143929828\",\"name\":\"S. Rho\"},{\"authorId\":\"3330588\",\"name\":\"I. Mehmood\"}],\"doi\":\"10.1109/ACCESS.2018.2814075\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7544aead4c1c68e21a775fc8c62c19fb5bc8171c\",\"title\":\"Natural Language Description of Video Streams Using Task-Specific Feature Encoding\",\"url\":\"https://www.semanticscholar.org/paper/7544aead4c1c68e21a775fc8c62c19fb5bc8171c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"},{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aa1045859089567dd65f69499d01aaaf701da70\",\"title\":\"Visual Dialogue Needs Symmetry , Goals , and Dynamics : The Example of the MeetUp Task\",\"url\":\"https://www.semanticscholar.org/paper/2aa1045859089567dd65f69499d01aaaf701da70\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15316342\",\"name\":\"Rodrigo Toro Icarte\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea2772e03af15b8387f2789a45a4e1d197b13f88\",\"title\":\"COMMONSENSE ONTOLOGY IMPROVE PERFORMANCE OF LEARNING-BASED IMAGE RETRIEVAL ?\",\"url\":\"https://www.semanticscholar.org/paper/ea2772e03af15b8387f2789a45a4e1d197b13f88\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31732712\",\"name\":\"H. MacLeod\"},{\"authorId\":\"2803724\",\"name\":\"C. Bennett\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"},{\"authorId\":\"1722375\",\"name\":\"E. Cutrell\"}],\"doi\":\"10.1145/3025453.3025814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4d7780cff87334906ede9036ed6aafc837997e2\",\"title\":\"Understanding Blind People's Experiences with Computer-Generated Captions of Social Media Images\",\"url\":\"https://www.semanticscholar.org/paper/e4d7780cff87334906ede9036ed6aafc837997e2\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47752775\",\"name\":\"Gengshi Huang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-018-9836-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1571f6a35809ee111b14ebf43859e787c782f79\",\"title\":\"c-RNN: A Fine-Grained Language Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c1571f6a35809ee111b14ebf43859e787c782f79\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-019-10045-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f15f92647a02e526c02c1b61bf8bcc5d6b206e99\",\"title\":\"Adaptive Syncretic Attention for Constrained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f15f92647a02e526c02c1b61bf8bcc5d6b206e99\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1910.01210\",\"authors\":[{\"authorId\":\"1381902419\",\"name\":\"Mihir Prabhudesai\"},{\"authorId\":\"1693704\",\"name\":\"H. F. Tung\"},{\"authorId\":\"40604609\",\"name\":\"Syed Ashar Javed\"},{\"authorId\":\"51039185\",\"name\":\"Maximilian Sieb\"},{\"authorId\":\"34939798\",\"name\":\"Adam W. Harley\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3245f7b672b382d9a122fe1730ae22113d61dbc4\",\"title\":\"Embodied Language Grounding with Implicit 3D Visual Feature Representations\",\"url\":\"https://www.semanticscholar.org/paper/3245f7b672b382d9a122fe1730ae22113d61dbc4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.00766\",\"authors\":[{\"authorId\":\"90639891\",\"name\":\"Hassan Maleki Galandouz\"},{\"authorId\":\"2734293\",\"name\":\"Mohsen Ebrahimi Moghaddam\"},{\"authorId\":\"2567327\",\"name\":\"Mehrnoush Shamsfard\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1717cd0899bda3166687281e6ed8b99ca285a311\",\"title\":\"A Weighted Multi-Criteria Decision Making Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1717cd0899bda3166687281e6ed8b99ca285a311\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.12633\",\"authors\":[{\"authorId\":\"24339915\",\"name\":\"Davis Gilton\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"145952380\",\"name\":\"R. Willett\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"title\":\"Detection and Description of Change in Visual Streams\",\"url\":\"https://www.semanticscholar.org/paper/dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1604.03968\",\"authors\":[{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"143967473\",\"name\":\"Pushmeet Kohli\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3139/9783446448100.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927987a48c2a519bbc097d8b6c925b64a85b7d8e\",\"title\":\"Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/927987a48c2a519bbc097d8b6c925b64a85b7d8e\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08242\",\"authors\":[{\"authorId\":\"116144731\",\"name\":\"Thomas M. Sutter\"},{\"authorId\":\"116604389\",\"name\":\"Imant Daunhawer\"},{\"authorId\":\"8258126\",\"name\":\"J. Vogt\"}],\"doi\":\"10.3929/ETHZ-B-000392472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40abbd5078b0796c1f70c887a8fa6386b7171dcf\",\"title\":\"Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence\",\"url\":\"https://www.semanticscholar.org/paper/40abbd5078b0796c1f70c887a8fa6386b7171dcf\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1905.02963\",\"authors\":[{\"authorId\":\"145114776\",\"name\":\"L. Sun\"},{\"authorId\":\"143721383\",\"name\":\"Bing Li\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICME.2019.00226\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"title\":\"Multimodal Semantic Attention Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702778\",\"name\":\"H. Zhang\"},{\"authorId\":\"2913523\",\"name\":\"Diedie Qiu\"},{\"authorId\":\"50477983\",\"name\":\"R. Wu\"},{\"authorId\":\"103624776\",\"name\":\"Dong-Hong Ji\"},{\"authorId\":\"49461429\",\"name\":\"Guangli Li\"},{\"authorId\":\"9201022\",\"name\":\"Zhenyu Niu\"},{\"authorId\":\"50289773\",\"name\":\"Tao Li\"}],\"doi\":\"10.1007/S00500-019-03973-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f7104056642c03263508957f20505a1dbba03ce\",\"title\":\"Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images\",\"url\":\"https://www.semanticscholar.org/paper/7f7104056642c03263508957f20505a1dbba03ce\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":\"2001.08730\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1490642986\",\"name\":\"Shivansh Pate\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a487065408c44d387aa1cf7836cd58405f945983\",\"title\":\"Robust Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a487065408c44d387aa1cf7836cd58405f945983\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/3292058\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"title\":\"Image Captioning With Visual-Semantic Double Attention\",\"url\":\"https://www.semanticscholar.org/paper/1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1908.05407\",\"authors\":[{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3343031.3350996\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1056e6e84d52cf45017aad544fa0406441abda0\",\"title\":\"Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards\",\"url\":\"https://www.semanticscholar.org/paper/c1056e6e84d52cf45017aad544fa0406441abda0\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/W16-3203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbaa92c289f4f5ff9a57b19a2725036a92311f5\",\"title\":\"Focused Evaluation for Image Description with Binary Forced-Choice Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ecbaa92c289f4f5ff9a57b19a2725036a92311f5\",\"venue\":\"VL@ACL\",\"year\":2016},{\"arxivId\":\"1611.06492\",\"authors\":[{\"authorId\":\"7284555\",\"name\":\"A. Jain\"},{\"authorId\":\"34762956\",\"name\":\"Abhinav Agarwalla\"},{\"authorId\":\"6565766\",\"name\":\"Kumar Krishna Agrawal\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1109/CVPRW.2017.273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53a41c711b40e7fe3dc2b12e0790933d9c99a6e0\",\"title\":\"Recurrent Memory Addressing for Describing Videos\",\"url\":\"https://www.semanticscholar.org/paper/53a41c711b40e7fe3dc2b12e0790933d9c99a6e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/CVPR.2017.658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab6480a63ac304eef220dad024106e07f21a3a35\",\"title\":\"Multi-attention Network for One Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/ab6480a63ac304eef220dad024106e07f21a3a35\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3126686.3126714\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"title\":\"Image Caption with Synchronous Cross-Attention\",\"url\":\"https://www.semanticscholar.org/paper/b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805970305\",\"name\":\"Georgios Barlas\"},{\"authorId\":\"1859319\",\"name\":\"Christos Veinidis\"},{\"authorId\":\"35575984\",\"name\":\"A. Arampatzis\"}],\"doi\":\"10.1007/s00371-020-01867-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a31c2b3a88719419cf679778846edbe3be9e81b3\",\"title\":\"What we see in a photograph: content selection for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a31c2b3a88719419cf679778846edbe3be9e81b3\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959354\",\"name\":\"Renato Preigschadt de Azevedo\"},{\"authorId\":\"2548454\",\"name\":\"M. J. V. Pereira\"},{\"authorId\":\"1717634\",\"name\":\"P. Henriques\"}],\"doi\":\"10.4230/OASIcs.SLATE.2020.8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fae553611983a692edeaf2c76e683148ae8abcbb\",\"title\":\"Development of Q&A Systems Using AcQA\",\"url\":\"https://www.semanticscholar.org/paper/fae553611983a692edeaf2c76e683148ae8abcbb\",\"venue\":\"SLATE\",\"year\":2020},{\"arxivId\":\"1707.07601\",\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.18653/v1/D17-1303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8eee0c0a566c9d59e264dd4119225840caa307dc\",\"title\":\"Image Pivoting for Learning Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/8eee0c0a566c9d59e264dd4119225840caa307dc\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1501.06297\",\"authors\":[{\"authorId\":\"2426718\",\"name\":\"J. Masci\"},{\"authorId\":\"1804261\",\"name\":\"D. Boscaini\"},{\"authorId\":\"1732570\",\"name\":\"M. Bronstein\"},{\"authorId\":\"1697397\",\"name\":\"P. Vandergheynst\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fcb266c334b0e649426a0b92c0199d3a0c726b0\",\"title\":\"ShapeNet: Convolutional Neural Networks on Non-Euclidean Manifolds\",\"url\":\"https://www.semanticscholar.org/paper/4fcb266c334b0e649426a0b92c0199d3a0c726b0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1509.04942\",\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"title\":\"Guiding Long-Short Term Memory for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1710.01949\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/TASLP.2018.2872106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561f69917d109a20d630408718676b299c7de191\",\"title\":\"Semantic keyword spotting by learning from images and speech\",\"url\":\"https://www.semanticscholar.org/paper/561f69917d109a20d630408718676b299c7de191\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46174228\",\"name\":\"Sidra Shabir\"},{\"authorId\":\"49854677\",\"name\":\"Syed Yasser Arafat\"}],\"doi\":\"10.1109/ICPESG.2018.8384519\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"title\":\"An image conveys a message: A brief survey on image description generation\",\"url\":\"https://www.semanticscholar.org/paper/4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"venue\":\"2018 1st International Conference on Power, Energy and Smart Grid (ICPESG)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583569\",\"name\":\"Adrian Benton\"},{\"authorId\":\"1782853\",\"name\":\"Mark Dredze\"}],\"doi\":\"10.18653/v1/N18-1034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"445386d94bdacb1ef6c125151bca7547da76b1f8\",\"title\":\"Deep Dirichlet Multinomial Regression\",\"url\":\"https://www.semanticscholar.org/paper/445386d94bdacb1ef6c125151bca7547da76b1f8\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35641549\",\"name\":\"Rucai Zhou\"},{\"authorId\":\"49245946\",\"name\":\"Kuojian Lu\"},{\"authorId\":\"47341671\",\"name\":\"Yi Long\"},{\"authorId\":\"2674321\",\"name\":\"Jiaying Lu\"},{\"authorId\":\"144925373\",\"name\":\"Xinghua Cheng\"},{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"2168143\",\"name\":\"Y. Gu\"}],\"doi\":\"10.1109/BESC.2017.8256394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9146b314812231d09587e3a9f622dda65d3cc40\",\"title\":\"A survey on social image understanding\",\"url\":\"https://www.semanticscholar.org/paper/b9146b314812231d09587e3a9f622dda65d3cc40\",\"venue\":\"2017 International Conference on Behavioral, Economic, Socio-cultural Computing (BESC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"37922370\",\"name\":\"S. Frank\"},{\"authorId\":\"2955842\",\"name\":\"E. Hasler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d0a348510cb2fbefbb3225ee18fafc1479eaeef\",\"title\":\"Multi-Language Image Description with Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/0d0a348510cb2fbefbb3225ee18fafc1479eaeef\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1709.01148\",\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":null,\"name\":\"Yizhe Zhu\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":\"10.1109/CVPR.2017.666\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5447f2addbd8b7ccda2cb9e3084cb3fa1d876ff\",\"title\":\"Link the Head to the \\\"Beak\\\": Zero Shot Learning from Noisy Text Description at Part Precision\",\"url\":\"https://www.semanticscholar.org/paper/b5447f2addbd8b7ccda2cb9e3084cb3fa1d876ff\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.07853\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"48032659\",\"name\":\"Xiaoyi Liu\"},{\"authorId\":\"49330599\",\"name\":\"Liangjian Chen\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/WACV.2018.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"title\":\"Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3418540\",\"name\":\"Athanasios Psaltis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd1d77d66f1ed0179affe4b36e6d72b2c82bfa35\",\"title\":\"Deep 3 D Flow Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd1d77d66f1ed0179affe4b36e6d72b2c82bfa35\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2993077\",\"name\":\"Sebastien Delecraz\"},{\"authorId\":\"1403823070\",\"name\":\"L. Becerra-Bonache\"},{\"authorId\":\"123173138\",\"name\":\"Alexis Nasr\"},{\"authorId\":\"1725420\",\"name\":\"Fr\\u00e9d\\u00e9ric B\\u00e9chet\"},{\"authorId\":\"92454011\",\"name\":\"B. Favre\"}],\"doi\":\"10.1007/978-3-030-20521-8_52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5fde3b580b9733e56b7ad4dbb119864ffed905e\",\"title\":\"Visual Disambiguation of Prepositional Phrase Attachments: Multimodal Machine Learning for Syntactic Analysis Correction\",\"url\":\"https://www.semanticscholar.org/paper/f5fde3b580b9733e56b7ad4dbb119864ffed905e\",\"venue\":\"IWANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"153028537\",\"name\":\"X. Wu\"},{\"authorId\":\"36263371\",\"name\":\"Shen Ge\"},{\"authorId\":\"93249636\",\"name\":\"W. Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1609/AAAI.V34I07.6824\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"title\":\"Federated Learning for Vision-and-Language Grounding Problems\",\"url\":\"https://www.semanticscholar.org/paper/d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1145/3293353.3293391\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"title\":\"A Bottom-Up and Top-Down Approach for Image Captioning using Transformer\",\"url\":\"https://www.semanticscholar.org/paper/acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1502.02761\",\"authors\":[{\"authorId\":\"1980990\",\"name\":\"Y. Li\"},{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8b509be29721ee6b12c880b4d97ed6b60bad217\",\"title\":\"Generative Moment Matching Networks\",\"url\":\"https://www.semanticscholar.org/paper/c8b509be29721ee6b12c880b4d97ed6b60bad217\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"}],\"doi\":\"10.4233/UUID:FFF15717-71EC-402D-96E6-773884659F2C\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c90362daffb92ca848450ca33fe2c2d3f3665e2a\",\"title\":\"Models for supervised learning in sequence data\",\"url\":\"https://www.semanticscholar.org/paper/c90362daffb92ca848450ca33fe2c2d3f3665e2a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49908183\",\"name\":\"R. Wang\"},{\"authorId\":\"3069541\",\"name\":\"Toru Wakahara\"}],\"doi\":\"10.1145/3342999.3343004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7a57277acde8c881403be006f7c0b1462c571dc\",\"title\":\"Practice in Caption Generation with Keras: The Design and Evaluation for Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/d7a57277acde8c881403be006f7c0b1462c571dc\",\"venue\":\"ICDLT 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"title\":\"Learning to Caption Images with Two-Stream Attention and Sentence Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.09530\",\"authors\":[{\"authorId\":\"153769937\",\"name\":\"H. Akbari\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"120157163\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"37409035\",\"name\":\"R. Fernandez\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"title\":\"Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30209846\",\"name\":\"Lifei Han\"},{\"authorId\":\"2258415\",\"name\":\"G. Gu\"}],\"doi\":\"10.1007/978-981-10-7305-2_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c972c53eff61dc2b5a006a24cf13004a42c9c64\",\"title\":\"Key Words Extraction and Semantic-Based Image Retrieval on RNNs\",\"url\":\"https://www.semanticscholar.org/paper/0c972c53eff61dc2b5a006a24cf13004a42c9c64\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"title\":\"A Semi-supervised Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1905.12255\",\"authors\":[{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"145181836\",\"name\":\"Gabriel Magalh\\u00e3es\"},{\"authorId\":\"31702389\",\"name\":\"Alexander Ku\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"}],\"doi\":\"10.18653/v1/P19-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68ccecb380ecfc0a4b294b84e3d0b6ff6884c4df\",\"title\":\"Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/68ccecb380ecfc0a4b294b84e3d0b6ff6884c4df\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.04938\",\"authors\":[{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":\"145500855\",\"name\":\"Lei Cui\"},{\"authorId\":\"10780897\",\"name\":\"Damai Dai\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.1609/AAAI.V33I01.33016810\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09e39f4334417f92bddc20072f43efade9bd5b60\",\"title\":\"LiveBot: Generating Live Video Comments Based on Visual and Textual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/09e39f4334417f92bddc20072f43efade9bd5b60\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152628978\",\"name\":\"Zhiwang Luo\"},{\"authorId\":\"49268539\",\"name\":\"Jiwei Hu\"},{\"authorId\":\"24825378\",\"name\":\"Q. Liu\"},{\"authorId\":\"50060682\",\"name\":\"J. Deng\"}],\"doi\":\"10.1117/12.2540579\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fba6e52ac4855a71037a648d199b8e3afd6268cb\",\"title\":\"An image caption model incorporating high-level semantic features\",\"url\":\"https://www.semanticscholar.org/paper/fba6e52ac4855a71037a648d199b8e3afd6268cb\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"48873711\",\"name\":\"Q. Liu\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"910eb7a8c3f175a9b71680f70303751726bebd30\",\"title\":\"Reference Based LSTM for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/910eb7a8c3f175a9b71680f70303751726bebd30\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351058\",\"name\":\"Marc-Andre Carbonneau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79e3b7a59311638e0968f6b3935043376ee8e2fd\",\"title\":\"Multiple instance learning under real-world conditions\",\"url\":\"https://www.semanticscholar.org/paper/79e3b7a59311638e0968f6b3935043376ee8e2fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1702.07817\",\"authors\":[{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6f6e959f7c20fbc6d8dcf2453c1a84605c39dcb\",\"title\":\"An Unsupervised Learning Method Exploiting Sequential Output Statistics\",\"url\":\"https://www.semanticscholar.org/paper/d6f6e959f7c20fbc6d8dcf2453c1a84605c39dcb\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50394960\",\"name\":\"Ke Wang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8549e6c596ac21990d54ddafa7beee4b067816e9\",\"title\":\"Adversarial Text Generation via Sequence Contrast Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/8549e6c596ac21990d54ddafa7beee4b067816e9\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48441202\",\"name\":\"J. Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1561/1500000074\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"venue\":\"Found. Trends Inf. Retr.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/ICCVW.2017.46\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"73598ca47948fa18e051ce5173d7556e0f485489\",\"title\":\"Adaptive Pooling in Multi-instance Learning for Web Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/73598ca47948fa18e051ce5173d7556e0f485489\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1706.00038\",\"authors\":[{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f6610f23af1bf193ca55b4af119b9be733bce99\",\"title\":\"Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f6610f23af1bf193ca55b4af119b9be733bce99\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582309\",\"name\":\"Kongming Liang\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.24963/ijcai.2017/313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02428c771564125ed1e38d87b6c6dfa9fe6ca65d\",\"title\":\"Incomplete Attribute Learning with auxiliary labels\",\"url\":\"https://www.semanticscholar.org/paper/02428c771564125ed1e38d87b6c6dfa9fe6ca65d\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2215952\",\"name\":\"Saeid Balaneshin Kordan\"},{\"authorId\":\"145084003\",\"name\":\"Alexander Kotov\"}],\"doi\":\"10.1145/3159652.3159735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b24792298d47409cdf23012f593d49e2be0d4f3\",\"title\":\"Deep Neural Architecture for Multi-Modal Retrieval based on Joint Embedding Space for Text and Images\",\"url\":\"https://www.semanticscholar.org/paper/6b24792298d47409cdf23012f593d49e2be0d4f3\",\"venue\":\"WSDM\",\"year\":2018},{\"arxivId\":\"1506.00196\",\"authors\":[{\"authorId\":\"39922478\",\"name\":\"K. Yao\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc96e329dc7b9d29aa8b2f1a44e8928b6977456a\",\"title\":\"Sequence-to-sequence neural net models for grapheme-to-phoneme conversion\",\"url\":\"https://www.semanticscholar.org/paper/dc96e329dc7b9d29aa8b2f1a44e8928b6977456a\",\"venue\":\"INTERSPEECH\",\"year\":2015},{\"arxivId\":\"1811.07212\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"121704643\",\"name\":\"Yichen Li\"},{\"authorId\":\"145031845\",\"name\":\"Ke Xu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2020.3029008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"title\":\"Revisiting Image-Language Networks for Open-ended Phrase Detection.\",\"url\":\"https://www.semanticscholar.org/paper/0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2009.13862\",\"authors\":[{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3287827\",\"name\":\"Guangluan Xu\"},{\"authorId\":\"7413451\",\"name\":\"Daoyu Lin\"},{\"authorId\":\"1379498558\",\"name\":\"Wei Dai\"},{\"authorId\":\"48607717\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/JSTSP.2020.2987729\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"title\":\"Where is the Model Looking At? \\u2013 Concentrate and Explain the Network Attention\",\"url\":\"https://www.semanticscholar.org/paper/7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"2007.08883\",\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"72095125\",\"name\":\"Y. Zhang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"}],\"doi\":\"10.1007/978-3-030-58586-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe573437cbd4069556348ad28dfeae2df46e22a0\",\"title\":\"Consensus-Aware Visual-Semantic Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/fe573437cbd4069556348ad28dfeae2df46e22a0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.10309\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"title\":\"Uncertainty based Class Activation Maps for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40526720\",\"name\":\"Pengtao Xie\"}],\"doi\":\"10.1184/R1/7553468.V1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04f11687c7b918501c1a24195d8336936adf194d\",\"title\":\"Diversity-Promoting and Large-Scale Machine Learning for Healthcare\",\"url\":\"https://www.semanticscholar.org/paper/04f11687c7b918501c1a24195d8336936adf194d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7504183\",\"name\":\"B. Zhang\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1994580036\",\"name\":\"Jincan Deng\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b0209f6fa41030e7e590f2cb5568f47563a759a\",\"title\":\"Structural Semantic Adversarial Active Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4b0209f6fa41030e7e590f2cb5568f47563a759a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453279481\",\"name\":\"Gonzalo Vaca Castano\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a851ad57feec3140b574c85851c436dacad8e70\",\"title\":\"Understanding images and videos using context\",\"url\":\"https://www.semanticscholar.org/paper/4a851ad57feec3140b574c85851c436dacad8e70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34740554\",\"name\":\"I. Goodfellow\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1038/nature14539\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4cec122a08216fe8a3bc19b22e78fbaea096256\",\"title\":\"Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4cec122a08216fe8a3bc19b22e78fbaea096256\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1904.05092\",\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.18653/v1/N19-1200\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b84063ec9b37d416a6331c14dee600868daf44c1\",\"title\":\"Cross-lingual Visual Verb Sense Disambiguation\",\"url\":\"https://www.semanticscholar.org/paper/b84063ec9b37d416a6331c14dee600868daf44c1\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3090304\",\"name\":\"Zhuhao Wang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"1776903\",\"name\":\"Weiming Lu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"38979129\",\"name\":\"Xi Li\"},{\"authorId\":\"3431212\",\"name\":\"Zitong Zhang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e55283e6eb3f0f9db07cf1b20e0de8d5aac10e\",\"title\":\"Diverse Image Captioning via GroupTalk\",\"url\":\"https://www.semanticscholar.org/paper/39e55283e6eb3f0f9db07cf1b20e0de8d5aac10e\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749071\",\"name\":\"L. Hollink\"},{\"authorId\":\"3449769\",\"name\":\"A. Bedjeti\"},{\"authorId\":\"3448672\",\"name\":\"Martin van Harmelen\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffbf1422e9b1defa03814c9f068d792bde8fd1ff\",\"title\":\"A Corpus of Images and Text in Online News\",\"url\":\"https://www.semanticscholar.org/paper/ffbf1422e9b1defa03814c9f068d792bde8fd1ff\",\"venue\":\"LREC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153382059\",\"name\":\"Rashmi Gupta\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"}],\"doi\":\"10.1109/CBMI.2019.8877444\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"699fc506eb3ff03b2e4cbd91b66285ebadff102c\",\"title\":\"Activity Recognition and Segmentation Approaches to Multimodal Lifelog Data\",\"url\":\"https://www.semanticscholar.org/paper/699fc506eb3ff03b2e4cbd91b66285ebadff102c\",\"venue\":\"2019 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471463062\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1522102572\",\"name\":\"Zhen Lei\"},{\"authorId\":\"1415720379\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"title\":\"Context-Aware Attention Network for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.01197\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"title\":\"Contextual Action Recognition with R*CNN\",\"url\":\"https://www.semanticscholar.org/paper/1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1703.08136\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"40059964\",\"name\":\"Shane Settle\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.21437/INTERSPEECH.2017-502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93f46618df0a6cd81d9e42361082e7a80fc9adf7\",\"title\":\"Visually Grounded Learning of Keyword Prediction from Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/93f46618df0a6cd81d9e42361082e7a80fc9adf7\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1706.09601\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"title\":\"Actor-Critic Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22066021\",\"name\":\"Xishan Zhang\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"2069818\",\"name\":\"D. Zhang\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2017.662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b0b706fc94b35a1eddd830685e07870315b9565\",\"title\":\"Task-Driven Dynamic Fusion: Reducing Ambiguity in Video Description\",\"url\":\"https://www.semanticscholar.org/paper/3b0b706fc94b35a1eddd830685e07870315b9565\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144439462\",\"name\":\"Shuang Liu\"},{\"authorId\":\"48499525\",\"name\":\"Liang Richard Bai\"},{\"authorId\":\"46972536\",\"name\":\"Yan-Li Hu\"},{\"authorId\":\"49528408\",\"name\":\"Haoran Wang\"}],\"doi\":\"10.1051/MATECCONF/201823201052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"730083506b1f6064ae12cc7ced6b3b2093d59bfd\",\"title\":\"Image Captioning Based on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/730083506b1f6064ae12cc7ced6b3b2093d59bfd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134881509\",\"name\":\"Xiucong Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e75b28c77c83b3281541b6b9a0222de615ab78b\",\"title\":\"Image Description Generation in Chinese Based on Keywords Guidance\",\"url\":\"https://www.semanticscholar.org/paper/7e75b28c77c83b3281541b6b9a0222de615ab78b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12431607\",\"name\":\"Wenlong Guan\"},{\"authorId\":\"48469896\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/LSP.2018.2881835\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72e4aa7412631eff16808fdd2cbac887b1bd6350\",\"title\":\"Edge-Aware Convolution Neural Network Based Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/72e4aa7412631eff16808fdd2cbac887b1bd6350\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145399579\",\"name\":\"Karan Sharma\"},{\"authorId\":\"5864325\",\"name\":\"Arun\"},{\"authorId\":\"1483929243\",\"name\":\"Kumar\"},{\"authorId\":\"3422895\",\"name\":\"S. Bhandarkar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf881e53510b230879aa0d3b02576043b8f881e7\",\"title\":\"Automated Image Captioning Using Nearest-Neighbors Approach Driven by Top-Object Detections\",\"url\":\"https://www.semanticscholar.org/paper/bf881e53510b230879aa0d3b02576043b8f881e7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20632291\",\"name\":\"Shiliang Sun\"},{\"authorId\":\"145307050\",\"name\":\"Liang Mao\"},{\"authorId\":\"66550933\",\"name\":\"Ziang Dong\"},{\"authorId\":\"4382815\",\"name\":\"Lidan Wu\"}],\"doi\":\"10.1007/978-981-13-3029-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b74af2609e83796ad07069ff76d34fd2223efc0\",\"title\":\"Multiview Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/0b74af2609e83796ad07069ff76d34fd2223efc0\",\"venue\":\"Springer Singapore\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2934386\",\"name\":\"Tongxin Hu\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"}],\"doi\":\"10.1007/978-3-030-33676-9_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1591d983571bb37c909f36b09d4051e83147450f\",\"title\":\"Exploiting Attention for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/1591d983571bb37c909f36b09d4051e83147450f\",\"venue\":\"GCPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3057169\",\"name\":\"Chakaveh Saedi\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32586f0f58009e58f430bb75b84f1c7da004c7f4\",\"title\":\"Siamese Networks for Large-Scale Author Identification Siamese Networks for Large-Scale Author Identification\",\"url\":\"https://www.semanticscholar.org/paper/32586f0f58009e58f430bb75b84f1c7da004c7f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"144067957\",\"name\":\"K. Mao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"title\":\"Semantic-filtered Soft-Split-Aware video captioning with audio-augmented feature\",\"url\":\"https://www.semanticscholar.org/paper/fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"2630752\",\"name\":\"L. Manikonda\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c3d8cf726f17bbb326551253c810429d332d3f3\",\"title\":\"Complementing the Execution of AI Systems with Human Computation\",\"url\":\"https://www.semanticscholar.org/paper/5c3d8cf726f17bbb326551253c810429d332d3f3\",\"venue\":\"AAAI Workshops\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P18-1238\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"title\":\"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1803.01457\",\"authors\":[{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"47527850\",\"name\":\"W. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1007/978-3-030-01261-8_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"title\":\"Less Is More: Picking Informative Frames for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.02628\",\"authors\":[{\"authorId\":\"65767906\",\"name\":\"Silvio Olivastri\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00185\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c1ebaa635f68bb4a09fc59191642f30cfa894c9\",\"title\":\"End-to-End Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0c1ebaa635f68bb4a09fc59191642f30cfa894c9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144642941\",\"name\":\"K. Kumari\"},{\"authorId\":\"1644340629\",\"name\":\"C. Mouneeshwari\"},{\"authorId\":\"70494695\",\"name\":\"R. Udhaya\"},{\"authorId\":\"1644333373\",\"name\":\"R. Jasmitha\"}],\"doi\":\"10.1007/978-3-030-24051-6_62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a4cf01162054cdafdcf0db6d121e682471d0478\",\"title\":\"Automated Image Captioning for Flickr8K Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8a4cf01162054cdafdcf0db6d121e682471d0478\",\"venue\":\"AISGSC 2019\",\"year\":2019},{\"arxivId\":\"1801.10121\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"title\":\"Image Captioning at Will: A Versatile Scheme for Effectively Injecting Sentiments into Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.05379\",\"authors\":[{\"authorId\":\"27866536\",\"name\":\"Q. Wang\"},{\"authorId\":\"1725438390\",\"name\":\"H. Tan\"},{\"authorId\":\"2191455\",\"name\":\"Sheng Shen\"},{\"authorId\":\"1717098\",\"name\":\"M. W. Mahoney\"},{\"authorId\":\"9088433\",\"name\":\"Zhewei Yao\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f68429e4cb119d3ac6cfbc9be7476609878fd2fa\",\"title\":\"MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/f68429e4cb119d3ac6cfbc9be7476609878fd2fa\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1705.01359\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"13597291\",\"name\":\"Yauhen Klimovich\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/P17-1024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"title\":\"FOIL it! Find One mismatch between Image and Language caption\",\"url\":\"https://www.semanticscholar.org/paper/c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1604.04053\",\"authors\":[{\"authorId\":\"144813536\",\"name\":\"Kai Kang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.95\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"title\":\"Object Detection from Video Tubelets with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429472\",\"name\":\"Philipp Blandfort\"},{\"authorId\":\"2675822\",\"name\":\"Tushar Karayil\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1145/3132515.3132522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8bcc9cb6dda08678351cc294319650d7bb31fb0\",\"title\":\"Image Captioning in the Wild: How People Caption Images on Flickr\",\"url\":\"https://www.semanticscholar.org/paper/c8bcc9cb6dda08678351cc294319650d7bb31fb0\",\"venue\":\"MUSA2@MM\",\"year\":2017},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.06641\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues\",\"url\":\"https://www.semanticscholar.org/paper/d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9037003\",\"name\":\"Duc-Cuong Dao\"},{\"authorId\":\"40429856\",\"name\":\"Thi-Oanh Nguyen\"},{\"authorId\":\"1735321\",\"name\":\"S. Bressan\"}],\"doi\":\"10.1145/3007120.3007136\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e559630c5710afb0d5eb8f95141e451393bbcbd9\",\"title\":\"Factors Influencing The Performance of Image Captioning Model: An Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/e559630c5710afb0d5eb8f95141e451393bbcbd9\",\"venue\":\"MoMM\",\"year\":2016},{\"arxivId\":\"1508.02091\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"2761119\",\"name\":\"N. Savva\"},{\"authorId\":\"3035230\",\"name\":\"Michael J. Wilber\"}],\"doi\":\"10.18653/v1/W15-2807\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b40f47c522093d4fc674b1247953e7475426fb6\",\"title\":\"Image Representations and New Domains in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9b40f47c522093d4fc674b1247953e7475426fb6\",\"venue\":\"VL@EMNLP\",\"year\":2015},{\"arxivId\":\"1506.01698\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-24947-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"title\":\"The Long-Short Story of Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"venue\":\"GCPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"46182785\",\"name\":\"Chang-Jun Nan\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6448e25b8767febcd2933eadb3ffc70eb0dffb64\",\"title\":\"Pororobot: A Deep Learning Robot That Plays Video Q&A Games\",\"url\":\"https://www.semanticscholar.org/paper/6448e25b8767febcd2933eadb3ffc70eb0dffb64\",\"venue\":\"AAAI Fall Symposia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145283199\",\"name\":\"M. Baroni\"}],\"doi\":\"10.1111/lnc3.12170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5473f9b4bafb63782049725bf7f3f8ee92f6e85\",\"title\":\"Grounding Distributional Semantics in the Visual World\",\"url\":\"https://www.semanticscholar.org/paper/f5473f9b4bafb63782049725bf7f3f8ee92f6e85\",\"venue\":\"Lang. Linguistics Compass\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3303969\",\"name\":\"Max Kemman\"},{\"authorId\":\"143711097\",\"name\":\"Mark Hill\"},{\"authorId\":\"82170926\",\"name\":\"John Nulty\"},{\"authorId\":\"34987460\",\"name\":\"P. D. Bolla\"},{\"authorId\":\"2179044\",\"name\":\"P. Huijnen\"},{\"authorId\":\"1922461\",\"name\":\"Tom Kenter\"},{\"authorId\":\"103220674\",\"name\":\"D. Guido\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1b3dbf647058e3219ecd4a6a94c1af69fa07622\",\"title\":\"Reflections on reading history from a distance\",\"url\":\"https://www.semanticscholar.org/paper/d1b3dbf647058e3219ecd4a6a94c1af69fa07622\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9127cbb1180c228475eefa8ca28be9eab1db2e9\",\"title\":\"A Survey of MultiView Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9127cbb1180c228475eefa8ca28be9eab1db2e9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICIP.2019.8803785\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"title\":\"A Novel Attribute Selection Mechanism for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-319-46493-0_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26d43ae0e7a8d523d48d2fe8a9e1b6e308913cf5\",\"title\":\"Top-Down Neural Attention by Excitation Backprop\",\"url\":\"https://www.semanticscholar.org/paper/26d43ae0e7a8d523d48d2fe8a9e1b6e308913cf5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1707.07102\",\"authors\":[{\"authorId\":\"8135633\",\"name\":\"Xuwang Yin\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":\"10.18653/v1/D17-1017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cc6ba3dfd6bf1f6257b2e4651f4cae355284286\",\"title\":\"Obj2Text: Generating Visually Descriptive Language from Object Layouts\",\"url\":\"https://www.semanticscholar.org/paper/2cc6ba3dfd6bf1f6257b2e4651f4cae355284286\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302246\",\"name\":\"Shuaijing Xu\"},{\"authorId\":\"2421895\",\"name\":\"Guangzhi Zhang\"},{\"authorId\":\"145149132\",\"name\":\"R. Bie\"},{\"authorId\":\"47580688\",\"name\":\"Anton Kos\"}],\"doi\":\"10.1007/978-3-030-23597-0_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47c006c56ea260d3f2d2f2dac39ecbe09f5f7cf8\",\"title\":\"CXNet-m2: A Deep Model with Visual and Clinical Contexts for Image-Based Detection of Multiple Lesions\",\"url\":\"https://www.semanticscholar.org/paper/47c006c56ea260d3f2d2f2dac39ecbe09f5f7cf8\",\"venue\":\"WASA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.09442\",\"authors\":[{\"authorId\":\"145341207\",\"name\":\"Chenhan Yuan\"},{\"authorId\":\"1743690\",\"name\":\"Yi-Chin Huang\"}],\"doi\":\"10.13053/CYS-1-1-3350\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c0cb8bcbaf7e614cc9c7a66a1b8a625dc02689c\",\"title\":\"Personalized sentence generation using generative adversarial networks with author-specific word usage\",\"url\":\"https://www.semanticscholar.org/paper/1c0cb8bcbaf7e614cc9c7a66a1b8a625dc02689c\",\"venue\":\"Computaci\\u00f3n y Sistemas\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"1696019\",\"name\":\"H. Luan\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/2978656\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f3417e73528025a5429547814e5a2fd91deb818\",\"title\":\"Learning from Collective Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/4f3417e73528025a5429547814e5a2fd91deb818\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414749\",\"name\":\"Kun Fu\"},{\"authorId\":\"3068555\",\"name\":\"Jin Li\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/TNNLS.2018.2813306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"title\":\"Image-Text Surgery: Efficient Concept Learning in Image Captioning by Generating Pseudopairs\",\"url\":\"https://www.semanticscholar.org/paper/f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1604.03249\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-319-50077-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"title\":\"Attributes as Semantic Units between Natural Language and Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37231867\",\"name\":\"N. Savage\"}],\"doi\":\"10.1145/2843532\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5231108789ecb4af8e8d9c5886804acc923d34c\",\"title\":\"Seeing more clearly\",\"url\":\"https://www.semanticscholar.org/paper/f5231108789ecb4af8e8d9c5886804acc923d34c\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":\"1701.07481\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.18653/v1/P17-1047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9140be329cd4ebbea8113087d65e68569b2f1269\",\"title\":\"Learning Word-Like Units from Joint Audio-Visual Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9140be329cd4ebbea8113087d65e68569b2f1269\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/s11263-017-0993-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7730d2a16d6b85edfacdfa37124abda79a667702\",\"title\":\"Guest Editorial: Image and Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/7730d2a16d6b85edfacdfa37124abda79a667702\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1708.01676\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3407447\",\"name\":\"Rama Kovvuri\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.95\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"title\":\"Query-Guided Regression Network with Context Policy for Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8071088\",\"name\":\"R. Oruganti\"},{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"8262287\",\"name\":\"Suhas Pillai\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/ICIP.2016.7533033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fe220d668a694cddf005958e2e58f568570276b\",\"title\":\"Image description through fusion based recurrent multi-modal learning\",\"url\":\"https://www.semanticscholar.org/paper/5fe220d668a694cddf005958e2e58f568570276b\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"title\":\"IGURE QA : A N A NNOTATED F IGURE D ATASET FOR V ISUAL R EASONING\",\"url\":\"https://www.semanticscholar.org/paper/cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49ac61eed8301f41da85e0053be3be790293faac\",\"title\":\"Recurrent Highway Networks with Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49ac61eed8301f41da85e0053be3be790293faac\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1807.07364\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"title\":\"Revisiting Cross Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101574342\",\"name\":\"Laokulrat Natsuda\"},{\"authorId\":\"72456985\",\"name\":\"Okazaki Naoaki\"},{\"authorId\":\"72028078\",\"name\":\"Nakayama Hideki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dc7c33475b545271d1de726fd88bb68dfb7e11b\",\"title\":\"Generating Video Description using RNN with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/5dc7c33475b545271d1de726fd88bb68dfb7e11b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"330c5eaca3bcc4a431cbd57c610f2096055782a1\",\"title\":\"Neural Approaches to Conversational AI Question Answering , Task-Oriented Dialogue and Chatbots : A Unified View\",\"url\":\"https://www.semanticscholar.org/paper/330c5eaca3bcc4a431cbd57c610f2096055782a1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"}],\"doi\":\"10.5075/EPFL-THESIS-7148\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de2899d6c850e9d57b80c471f8a06f669afa1812\",\"title\":\"Word Embeddings for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/de2899d6c850e9d57b80c471f8a06f669afa1812\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144126831\",\"name\":\"C. Henning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59709420b1105f0ac02fb3d8e58353ae164148ce\",\"title\":\"Estimating the Information Gap between Textual and Graphical Representations\",\"url\":\"https://www.semanticscholar.org/paper/59709420b1105f0ac02fb3d8e58353ae164148ce\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145551908\",\"name\":\"R. M. Winters\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"1722375\",\"name\":\"E. Cutrell\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.1177/1064804618788098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bb54dbcb2a8f69c12d1d327c420c6dcd16a9e19\",\"title\":\"Strategies for Auditory Display of Social Media\",\"url\":\"https://www.semanticscholar.org/paper/6bb54dbcb2a8f69c12d1d327c420c6dcd16a9e19\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153382059\",\"name\":\"Rashmi Gupta\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"}],\"doi\":\"10.1109/PERCOMW.2019.8730649\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66c8517bd39667a251a5050cfb50d3e99ae36c68\",\"title\":\"Considering Manual Annotations in Dynamic Segmentation of Multimodal Lifelog Data\",\"url\":\"https://www.semanticscholar.org/paper/66c8517bd39667a251a5050cfb50d3e99ae36c68\",\"venue\":\"2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)\",\"year\":2019},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1506.06833\",\"authors\":[{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30193451e552286645baa00db7dcd05780d9e1da\",\"title\":\"On Available Corpora for Empirical Methods in Vision & Language\",\"url\":\"https://www.semanticscholar.org/paper/30193451e552286645baa00db7dcd05780d9e1da\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1145/3231740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"544eac9bfda56052d3a996546f464618b34c2a0d\",\"title\":\"Cross-Modality Feature Learning via Convolutional Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/544eac9bfda56052d3a996546f464618b34c2a0d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1812.08989\",\"authors\":[{\"authorId\":\"49718206\",\"name\":\"L. Zhou\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1162/coli_a_00368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66b7d31527f980bb2eecc23629f08ba6037facc4\",\"title\":\"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot\",\"url\":\"https://www.semanticscholar.org/paper/66b7d31527f980bb2eecc23629f08ba6037facc4\",\"venue\":\"Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1911.10082\",\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"title\":\"Injecting Prior Knowledge into Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"40894329\",\"name\":\"Stephan Alaniz\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-98131-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86de19e783d717c5db77f96f707613c27bde2915\",\"title\":\"Generating Post-Hoc Rationales of Deep Visual Classification Decisions\",\"url\":\"https://www.semanticscholar.org/paper/86de19e783d717c5db77f96f707613c27bde2915\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1612.09161\",\"authors\":[{\"authorId\":\"145476835\",\"name\":\"Ang Li\"},{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCV.2017.449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8938988d82c6eb18e47deb5e69220652446c60bd\",\"title\":\"Learning Visual N-Grams from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/8938988d82c6eb18e47deb5e69220652446c60bd\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1610.02947\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.347\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3dc37dab102a0465098111b7ccf6f95b736397f2\",\"title\":\"End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3dc37dab102a0465098111b7ccf6f95b736397f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.74\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24120b948f39834e7860271992464eb4a575501b\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/24120b948f39834e7860271992464eb4a575501b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2010.02949\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.60\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73068d13d6e53876c374ebd4c862ec01351c9f39\",\"title\":\"Learning to Represent Image and Text with Denotation Graph\",\"url\":\"https://www.semanticscholar.org/paper/73068d13d6e53876c374ebd4c862ec01351c9f39\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"48447075\",\"name\":\"H. Liu\"}],\"doi\":\"10.1145/2911996.2912049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7e553b68f595f809bacead28fefb9e5efec090b\",\"title\":\"Adding Chinese Captions to Images\",\"url\":\"https://www.semanticscholar.org/paper/d7e553b68f595f809bacead28fefb9e5efec090b\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"1908.02127\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"145851264\",\"name\":\"Wei Luo\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350943\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"133921bb5e559de464c0078f5fa67409aca27917\",\"title\":\"Aligning Linguistic Words and Visual Semantic Units for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/133921bb5e559de464c0078f5fa67409aca27917\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1511.06267\",\"authors\":[{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ce9944108bfda7f081529fd61d0a50e64b97650\",\"title\":\"Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding For Image & Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2ce9944108bfda7f081529fd61d0a50e64b97650\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144724524\",\"name\":\"Lis Pereira\"},{\"authorId\":\"1729368\",\"name\":\"X. Liu\"},{\"authorId\":\"1703375\",\"name\":\"J. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23bf86abf9433b05150cf7b85f49d98f3b6027b5\",\"title\":\"Lexical Simplification with the Deep Structured Similarity Model\",\"url\":\"https://www.semanticscholar.org/paper/23bf86abf9433b05150cf7b85f49d98f3b6027b5\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145308148\",\"name\":\"L. Bai\"},{\"authorId\":\"2626803\",\"name\":\"Q. Chen\"}],\"doi\":\"10.1016/j.neucom.2017.01.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb16c5ab94c89c14969775e6ffcc66d59470c8e5\",\"title\":\"Visual phrase recognition by modeling 3D spatial context of multiple objects\",\"url\":\"https://www.semanticscholar.org/paper/eb16c5ab94c89c14969775e6ffcc66d59470c8e5\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2017.767\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.10819\",\"authors\":[{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"39083167\",\"name\":\"A. Dutta\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"143826881\",\"name\":\"J. Llad\\u00f3s\"},{\"authorId\":\"144167309\",\"name\":\"U. Pal\"}],\"doi\":\"10.1109/ICPR.2018.8545452\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9ac7adc8db3030707102efa07c06bd38aea233e\",\"title\":\"Learning Cross-Modal Deep Embeddings for Multi-Object Image Retrieval using Text and Sketch\",\"url\":\"https://www.semanticscholar.org/paper/e9ac7adc8db3030707102efa07c06bd38aea233e\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145552742\",\"name\":\"Feng Yan\"},{\"authorId\":\"1772774\",\"name\":\"Yuxiong He\"},{\"authorId\":\"2537545\",\"name\":\"Olatunji Ruwase\"},{\"authorId\":\"1730525\",\"name\":\"E. Smirni\"}],\"doi\":\"10.1109/TNSM.2018.2808352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"968c1a89472a32e00d617a478c561b9cd2187c5b\",\"title\":\"Efficient Deep Neural Network Serving: Fast and Furious\",\"url\":\"https://www.semanticscholar.org/paper/968c1a89472a32e00d617a478c561b9cd2187c5b\",\"venue\":\"IEEE Transactions on Network and Service Management\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2388012\",\"name\":\"S. Dash\"},{\"authorId\":\"102265808\",\"name\":\"S. Saha\"},{\"authorId\":\"1882574\",\"name\":\"Partha Pakray\"},{\"authorId\":\"1747784\",\"name\":\"Alexander Gelbukh\"}],\"doi\":\"10.3233/JIFS-179027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"200fb3952463d0051a613e14710b7f2ad5ffc173\",\"title\":\"Generating image captions through multimodal embedding\",\"url\":\"https://www.semanticscholar.org/paper/200fb3952463d0051a613e14710b7f2ad5ffc173\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2305522\",\"name\":\"Abid M. Malik\"},{\"authorId\":\"123554524\",\"name\":\"Micheal Lu\"},{\"authorId\":\"153247633\",\"name\":\"N. Wang\"},{\"authorId\":\"119916543\",\"name\":\"Yeiwei Lin\"},{\"authorId\":\"2282774\",\"name\":\"S. Yoo\"}],\"doi\":\"10.1109/NYSDS.2018.8538946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36b6c27bebcb75b9d55afa47f2f24b04792d4b29\",\"title\":\"Detailed Performance Analysis of Distributed Tensorflow on a GPU Cluster using Deep Learning Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/36b6c27bebcb75b9d55afa47f2f24b04792d4b29\",\"venue\":\"2018 New York Scientific Data Summit (NYSDS)\",\"year\":2018},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.04390\",\"authors\":[{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"}],\"doi\":\"10.1145/3123266.3123366\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"title\":\"Fluency-Guided Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152347102\",\"name\":\"F. Yu\"},{\"authorId\":\"30490097\",\"name\":\"Haonan Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3343031.3350931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47e8c51d8293eb59416456179c606cb3ae08692\",\"title\":\"Instance of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/c47e8c51d8293eb59416456179c606cb3ae08692\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520780\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38bbace118817cd18677f169a8c8e6c8b005df18\",\"title\":\"Auto-Encoding Graphical Inductive Bias for Descriptive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/38bbace118817cd18677f169a8c8e6c8b005df18\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.05113\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1609/AAAI.V33I01.33019062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"title\":\"Multilevel Language and Vision Integration for Text-to-Clip Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1908.02726\",\"authors\":[{\"authorId\":\"94845899\",\"name\":\"Qianyu Feng\"},{\"authorId\":\"98264517\",\"name\":\"Y. Wu\"},{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"3863922\",\"name\":\"C. Yan\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1109/TCSVT.2020.2965966\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daa87e86b469d975a9ad84bfb5eee230efa8af3e\",\"title\":\"Cascaded Revision Network for Novel Object Captioning\",\"url\":\"https://www.semanticscholar.org/paper/daa87e86b469d975a9ad84bfb5eee230efa8af3e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6806161\",\"name\":\"A. Khamparia\"},{\"authorId\":\"48413825\",\"name\":\"B. Pandey\"},{\"authorId\":\"74600005\",\"name\":\"Shrasti Tiwari\"},{\"authorId\":\"144786228\",\"name\":\"D. Gupta\"},{\"authorId\":\"103319292\",\"name\":\"A. Khanna\"},{\"authorId\":\"144091143\",\"name\":\"J. Rodrigues\"}],\"doi\":\"10.1007/s00034-019-01306-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8e5e775da93348382f198fa22f3cda7f04c71f\",\"title\":\"An Integrated Hybrid CNN\\u2013RNN Model for Visual Description and Generation of Captions\",\"url\":\"https://www.semanticscholar.org/paper/dc8e5e775da93348382f198fa22f3cda7f04c71f\",\"venue\":\"Circuits Syst. Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"title\":\"VisualNews : A Large Multi-source News Image Dataset\",\"url\":\"https://www.semanticscholar.org/paper/7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1511.05552\",\"authors\":[{\"authorId\":\"2164516\",\"name\":\"A. Chang\"},{\"authorId\":\"1940285\",\"name\":\"B. Martini\"},{\"authorId\":\"2889774\",\"name\":\"E. Culurciello\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b1136a2135eaccb8c980fb61113f083ceca95e3\",\"title\":\"Recurrent Neural Networks Hardware Implementation on FPGA\",\"url\":\"https://www.semanticscholar.org/paper/5b1136a2135eaccb8c980fb61113f083ceca95e3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1603.07771\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc6ef7cebf340606cb9c2f374474f567880fab38\",\"title\":\"Generating Text from Structured Data with Application to the Biography Domain\",\"url\":\"https://www.semanticscholar.org/paper/cc6ef7cebf340606cb9c2f374474f567880fab38\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.1007/978-3-030-01237-3_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"title\":\"NNEval: Neural Network Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33970300\",\"name\":\"Bor-Chun Chen\"},{\"authorId\":\"35081710\",\"name\":\"Yan-Ying Chen\"},{\"authorId\":\"27375808\",\"name\":\"Francine Chen\"}],\"doi\":\"10.5244/C.31.118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb3bce3a6221eb65451584efa898ecbe211bdab6\",\"title\":\"Video to Text Summary: Joint Video Summarization and Captioning with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fb3bce3a6221eb65451584efa898ecbe211bdab6\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"}],\"doi\":\"10.15781/T20G3GZ9Q\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccd2152c77ae65e4d3d0988990f6e243133a5efc\",\"title\":\"Learning human activities and poses with interconnected data sources\",\"url\":\"https://www.semanticscholar.org/paper/ccd2152c77ae65e4d3d0988990f6e243133a5efc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350881\",\"name\":\"Y. Tian\"},{\"authorId\":\"47120369\",\"name\":\"X. Wang\"},{\"authorId\":\"13013695\",\"name\":\"Jiachen Wu\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"7324474\",\"name\":\"Bailin Yang\"}],\"doi\":\"10.1613/jair.1.11338\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfeda236987b04250a218b688e32b6b35c617ba4\",\"title\":\"Multi-scale Hierarchical Residual Network for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cfeda236987b04250a218b688e32b6b35c617ba4\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39214752\",\"name\":\"Z. Zhang\"},{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213540\",\"name\":\"Xiaoyan Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3308558.3313598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"title\":\"Neural Multimodal Belief Tracker with Adaptive Attention for Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47362926\",\"name\":\"M. Ebner\"}],\"doi\":\"10.1515/bams-2017-0005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5621e278cf093139f8dfc7831924acbdb43921b8\",\"title\":\"Distributed storage and recall of sentences\",\"url\":\"https://www.semanticscholar.org/paper/5621e278cf093139f8dfc7831924acbdb43921b8\",\"venue\":\"Bio Algorithms Med Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153469844\",\"name\":\"H. Wang\"},{\"authorId\":\"3432460\",\"name\":\"Mengnan Du\"},{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bbe29c2c1c5a8a8d21f47459e5c4a898fc28fc2\",\"title\":\"Score-CAM: Improved Visual Explanations Via Score-Weighted Class Activation Mapping\",\"url\":\"https://www.semanticscholar.org/paper/2bbe29c2c1c5a8a8d21f47459e5c4a898fc28fc2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144546798\",\"name\":\"Y. Han\"},{\"authorId\":\"144400646\",\"name\":\"J. He\"},{\"authorId\":\"35137026\",\"name\":\"Qiwen Dong\"}],\"doi\":\"10.1145/3292448.3292455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03c2948ed2591c35b92325485a79120e5ec1d9ac\",\"title\":\"CSSSketch2Code: An Automatic Method to Generate Web Pages with CSS Style\",\"url\":\"https://www.semanticscholar.org/paper/03c2948ed2591c35b92325485a79120e5ec1d9ac\",\"venue\":\"ICAAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"46651452\",\"name\":\"Cong Li\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8803108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff24050374748529fa2a1fee6941af08296449f8\",\"title\":\"Image Captioning with Attribute Refinement\",\"url\":\"https://www.semanticscholar.org/paper/ff24050374748529fa2a1fee6941af08296449f8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1624658620\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"1429199889\",\"name\":\"Shaozu Yuan\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981513\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"711be95a04da16c93b6bc880169532b68cdca37a\",\"title\":\"Hierarchical Attention-Based Fusion for Image Caption With Multi-Grained Rewards\",\"url\":\"https://www.semanticscholar.org/paper/711be95a04da16c93b6bc880169532b68cdca37a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92104112\",\"name\":\"Tangming Chen\"},{\"authorId\":\"9398015\",\"name\":\"Qike Zhao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1007/978-3-030-33982-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf546bfb933bddbd9e7017525d9621405e549b9\",\"title\":\"Boundary Detector Encoder and Decoder with Soft Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1cf546bfb933bddbd9e7017525d9621405e549b9\",\"venue\":\"APWeb/WAIM Workshops\",\"year\":2019},{\"arxivId\":\"1710.08321\",\"authors\":[{\"authorId\":\"143856269\",\"name\":\"N. Nikhil\"},{\"authorId\":\"27088137\",\"name\":\"M. M. Srivastava\"}],\"doi\":\"10.1109/ICICI.2017.8365399\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edee94d667b1974c2ed55e43428631e6ca242738\",\"title\":\"Content based document recommender using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/edee94d667b1974c2ed55e43428631e6ca242738\",\"venue\":\"2017 International Conference on Inventive Computing and Informatics (ICICI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72350529\",\"name\":\"Abdelhafid Dakhia\"},{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/j.neucom.2018.12.045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95291afde3b890ff39ba635e1b8b7cf4dc0a30af\",\"title\":\"Multi-scale Pyramid Pooling Network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/95291afde3b890ff39ba635e1b8b7cf4dc0a30af\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"152333274\",\"name\":\"Seunghyun Yoon\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"2007775508\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":\"10.18653/v1/2020.eval4nlp-1.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2be4e374800a0db69695eb4c558a6653dd258fcd\",\"title\":\"ViLBERTScore: Evaluating Image Caption Using Vision-and-Language BERT\",\"url\":\"https://www.semanticscholar.org/paper/2be4e374800a0db69695eb4c558a6653dd258fcd\",\"venue\":\"EVAL4NLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"},{\"authorId\":\"48805287\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1109/TKDE.2018.2872063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63787b1fcf5add4b5e25376f7bee155a39e958c3\",\"title\":\"A Survey of Multi-View Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/63787b1fcf5add4b5e25376f7bee155a39e958c3\",\"venue\":\"IEEE Transactions on Knowledge and Data Engineering\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1711.08195\",\"authors\":[{\"authorId\":\"29860450\",\"name\":\"Baoyu Jing\"},{\"authorId\":\"40526720\",\"name\":\"Pengtao Xie\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/P18-1240\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d45cc9a3a2fc064eccc0c915dbdf73cce559ce7\",\"title\":\"On the Automatic Generation of Medical Imaging Reports\",\"url\":\"https://www.semanticscholar.org/paper/5d45cc9a3a2fc064eccc0c915dbdf73cce559ce7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1809.04835\",\"authors\":[{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"144326612\",\"name\":\"P. Li\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"2960930\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1145/3240876.3240900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dec04588b73efb1192d1778b2b818842ccd242e7\",\"title\":\"Image captioning based on deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/dec04588b73efb1192d1778b2b818842ccd242e7\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":\"2006.03122\",\"authors\":[{\"authorId\":\"3186020\",\"name\":\"Satya M. Muddamsetty\"},{\"authorId\":\"2044277\",\"name\":\"M. S. Jahromi\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/ICIP40778.2020.9190952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"301e237a2f384a139d51e18953a49746b7c17e9b\",\"title\":\"SIDU: Similarity Difference And Uniqueness Method for Explainable AI\",\"url\":\"https://www.semanticscholar.org/paper/301e237a2f384a139d51e18953a49746b7c17e9b\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2011.00569\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"46962482\",\"name\":\"C. H. Yang\"},{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"1935549028\",\"name\":\"Meng Tian\"},{\"authorId\":\"51224607\",\"name\":\"Yi-Chieh Liu\"},{\"authorId\":\"48865440\",\"name\":\"Tingwei Wu\"},{\"authorId\":\"2607585\",\"name\":\"I. Lin\"},{\"authorId\":\"1771700\",\"name\":\"K. Wang\"},{\"authorId\":\"7505210\",\"name\":\"H. Morikawa\"},{\"authorId\":\"34452443\",\"name\":\"Herng-Hua Chang\"},{\"authorId\":\"1402915033\",\"name\":\"Jesper Tegn\\u00e9r\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e77b77dacb36bae9264efb93685efcab126171e\",\"title\":\"DeepOpht: Medical Report Generation for Retinal Images via Deep Models and Visual Explanation\",\"url\":\"https://www.semanticscholar.org/paper/3e77b77dacb36bae9264efb93685efcab126171e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146925983\",\"name\":\"H. Rao\"},{\"authorId\":\"50251617\",\"name\":\"Z. Zhou\"},{\"authorId\":\"40371253\",\"name\":\"Bo Li\"},{\"authorId\":\"38188011\",\"name\":\"X. Shu\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81c8e663a4564ff4cca9fb00a3dcf29d2c6a9c91\",\"title\":\"DAGNet: Exploring the Structure of Objects for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/81c8e663a4564ff4cca9fb00a3dcf29d2c6a9c91\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2007.05608\",\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":\"10.24963/ijcai.2019/496\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"18403a06a67b7060645e137a36ad15122ee2c2f9\",\"title\":\"Image Captioning with Compositional Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/18403a06a67b7060645e137a36ad15122ee2c2f9\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2001.08779\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":null,\"name\":\"Sandeep Kumar\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e4720942ff8b02d2822aea5d024628139551723\",\"title\":\"Deep Bayesian Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/8e4720942ff8b02d2822aea5d024628139551723\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020}],\"corpusId\":9254582,\"doi\":\"10.1109/CVPR.2015.7298754\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":82,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"143818235\",\"name\":\"A. Carlson\"},{\"authorId\":\"31779043\",\"name\":\"J. Betteridge\"},{\"authorId\":\"16411658\",\"name\":\"Bryan Kisiel\"},{\"authorId\":\"1717452\",\"name\":\"B. Settles\"},{\"authorId\":\"1842532\",\"name\":\"Estevam R. Hruschka\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7312b8568d63bbbb239583ed282f46cdc40978d\",\"title\":\"Toward an Architecture for Never-Ending Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/f7312b8568d63bbbb239583ed282f46cdc40978d\",\"venue\":\"AAAI\",\"year\":2010},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143742935\",\"name\":\"R. Lau\"},{\"authorId\":\"145903504\",\"name\":\"R. Rosenfeld\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"}],\"doi\":\"10.1109/ICASSP.1993.319225\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e58b5f825df9fb0b00465a66598f302c30b080a\",\"title\":\"Trigger-based language models: a maximum entropy approach\",\"url\":\"https://www.semanticscholar.org/paper/6e58b5f825df9fb0b00465a66598f302c30b080a\",\"venue\":\"1993 IEEE International Conference on Acoustics, Speech, and Signal Processing\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3331580\",\"name\":\"O. Maron\"},{\"authorId\":\"1388700951\",\"name\":\"Tomas Lozano-Perez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8340eae2c98ab5e0a3b1a7e071a7ddb9106cff\",\"title\":\"A Framework for Multiple-Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/4d8340eae2c98ab5e0a3b1a7e071a7ddb9106cff\",\"venue\":\"NIPS\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5726c7b40fcc454b77d989656c085520bf6c15fa\",\"title\":\"Multimodal learning with deep Boltzmann machines\",\"url\":\"https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793475\",\"name\":\"A. Ratnaparkhi\"}],\"doi\":\"10.1016/S0885-2308(02)00025-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f4c9f5877fbd287785466d59877ef870c5e53c4\",\"title\":\"Trainable approaches to surface natural language generation and their application to conversational dialog systems\",\"url\":\"https://www.semanticscholar.org/paper/8f4c9f5877fbd287785466d59877ef870c5e53c4\",\"venue\":\"Comput. Speech Lang.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1713801\",\"name\":\"A. Deoras\"},{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"1899242\",\"name\":\"J. \\u010cernock\\u00fd\"}],\"doi\":\"10.1109/ASRU.2011.6163930\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb45e9217fe323fbc199d820e7735488fca2a9b3\",\"title\":\"Strategies for training large scale neural network language models\",\"url\":\"https://www.semanticscholar.org/paper/cb45e9217fe323fbc199d820e7735488fca2a9b3\",\"venue\":\"2011 IEEE Workshop on Automatic Speech Recognition & Understanding\",\"year\":2011},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"41207043\",\"name\":\"L. Deng\"},{\"authorId\":\"1935910\",\"name\":\"G. Mesnil\"}],\"doi\":\"10.1145/2661829.2661935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e8d5a108c28cdfb92f419ce919fbf7993dfebfc\",\"title\":\"A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7e8d5a108c28cdfb92f419ce919fbf7993dfebfc\",\"venue\":\"CIKM\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1756979\",\"name\":\"K. V. D. Sande\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1007/s11263-013-0620-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38b6540ddd5beebffd05047c78183f7575559fb2\",\"title\":\"Selective Search for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/38b6540ddd5beebffd05047c78183f7575559fb2\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.1109/CVPR.2014.412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0ab8aa7a5b684532b4ff30f8d34b35a99759a46\",\"title\":\"Learning Everything about Anything: Webly-Supervised Visual Concept Learning\",\"url\":\"https://www.semanticscholar.org/paper/b0ab8aa7a5b684532b4ff30f8d34b35a99759a46\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1206.6426\",\"authors\":[{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b0d644f5c4b9880cbaf79932c0a4fa98996f068\",\"title\":\"A fast and simple algorithm for training neural probabilistic language models\",\"url\":\"https://www.semanticscholar.org/paper/5b0d644f5c4b9880cbaf79932c0a4fa98996f068\",\"venue\":\"ICML\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2013.178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53e4ab9730e983242a3409c7bf1af945041a6563\",\"title\":\"NEIL: Extracting Visual Knowledge from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/53e4ab9730e983242a3409c7bf1af945041a6563\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710580\",\"name\":\"Adam L. Berger\"},{\"authorId\":\"2714577\",\"name\":\"S. D. Pietra\"},{\"authorId\":\"39944066\",\"name\":\"V. D. Pietra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb486e03369a64de2d5b0df86ec0a7b55d3907db\",\"title\":\"A Maximum Entropy Approach to Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/fb486e03369a64de2d5b0df86ec0a7b55d3907db\",\"venue\":\"Comput. Linguistics\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47713710\",\"name\":\"Benjamin Z. Yao\"},{\"authorId\":\"47008378\",\"name\":\"Xiong Yang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/JPROC.2010.2050411\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"05e074abddd3fe987b9bebd46f6cf4bf8465c37e\",\"title\":\"I2T: Image Parsing to Text Description\",\"url\":\"https://www.semanticscholar.org/paper/05e074abddd3fe987b9bebd46f6cf4bf8465c37e\",\"venue\":\"Proceedings of the IEEE\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2013.387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"051830b0ea58d1568f19ec3297e301d9789c9a76\",\"title\":\"Bringing Semantics into Focus Using Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/051830b0ea58d1568f19ec3297e301d9789c9a76\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"cs/0006028\",\"authors\":[{\"authorId\":\"1793475\",\"name\":\"A. Ratnaparkhi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2540b651519f631ab62b609b1acbfdb6d774fd3a\",\"title\":\"Trainable Methods for Surface Natural Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/2540b651519f631ab62b609b1acbfdb6d774fd3a\",\"venue\":\"ANLP\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Bottou M. Oquab\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"J. Sivic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A fast and simple algorithm for training neural probabilistic language models Minimum error rate training in statistical machine translation\",\"url\":\"\",\"venue\":\"In ACL\",\"year\":2003},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A L Berger\"},{\"authorId\":null,\"name\":\"S A D Pietra\"},{\"authorId\":null,\"name\":\"V J D Pietra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A maximum entropy approach to natural language processing. Computational Linguistics\",\"url\":\"\",\"venue\":\"A maximum entropy approach to natural language processing. Computational Linguistics\",\"year\":1996},{\"arxivId\":\"1502.03671\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"123b9de009865472c660192f8072493a48352dc2\",\"title\":\"Phrase-based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123b9de009865472c660192f8072493a48352dc2\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.3115/v1/P14-2074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52f86811b57034ba5c0478b37cab101d9a84024a\",\"title\":\"Comparing Automatic Evaluation Measures for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/52f86811b57034ba5c0478b37cab101d9a84024a\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1403.1024\",\"authors\":[{\"authorId\":\"2133680\",\"name\":\"Hyun Oh Song\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"2594093\",\"name\":\"S. Jegelka\"},{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"680e3de379ca4613fbe5a5d0e09d3028ffaad573\",\"title\":\"On learning to localize objects with minimal supervision\",\"url\":\"https://www.semanticscholar.org/paper/680e3de379ca4613fbe5a5d0e09d3028ffaad573\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731948\",\"name\":\"P. Viola\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"521768f7772163bc7c57ae2c9855889abb747fbb\",\"title\":\"Multiple Instance Boosting for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/521768f7772163bc7c57ae2c9855889abb747fbb\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"1723644\",\"name\":\"A. Acero\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"}],\"doi\":\"10.1145/2505515.2505665\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdb813d8b927bdd21ae1858cafa6c34b66a36268\",\"title\":\"Learning deep structured semantic models for web search using clickthrough data\",\"url\":\"https://www.semanticscholar.org/paper/fdb813d8b927bdd21ae1858cafa6c34b66a36268\",\"venue\":\"CIKM\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"1790580\",\"name\":\"Bharath Hariharan\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2014.458\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89e1ec16073ccf0c1356b243d0dfd4a3aee73df6\",\"title\":\"Using k-Poselets for Detecting People and Localizing Their Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/89e1ec16073ccf0c1356b243d0dfd4a3aee73df6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1310.1531\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8de958fead0d8a9619b55c7299df3257c624a96\",\"title\":\"DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8de958fead0d8a9619b55c7299df3257c624a96\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1007/978-3-319-10602-1_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b183947ee15718b45546eda6b01e179b9a95421f\",\"title\":\"Edge Boxes: Locating Object Proposals from Edges\",\"url\":\"https://www.semanticscholar.org/paper/b183947ee15718b45546eda6b01e179b9a95421f\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf60322f83714523e2d7c1d39983151fe9db7146\",\"title\":\"Collecting Image Annotations Using Amazon's Mechanical Turk\",\"url\":\"https://www.semanticscholar.org/paper/bf60322f83714523e2d7c1d39983151fe9db7146\",\"venue\":\"Mturk@HLT-NAACL\",\"year\":2010},{\"arxivId\":\"1404.2188\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"}],\"doi\":\"10.3115/v1/P14-1062\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"27725a2d2a8cee9bf9fffc6c2167017103aba0fa\",\"title\":\"A Convolutional Neural Network for Modelling Sentences\",\"url\":\"https://www.semanticscholar.org/paper/27725a2d2a8cee9bf9fffc6c2167017103aba0fa\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/1273496.1273577\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7d93193aad6c4b71cc8942e808753019e87706\",\"title\":\"Three new graphical models for statistical language modelling\",\"url\":\"https://www.semanticscholar.org/paper/bd7d93193aad6c4b71cc8942e808753019e87706\",\"venue\":\"ICML '07\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":\"1403.6382\",\"authors\":[{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"},{\"authorId\":\"2622491\",\"name\":\"H. Azizpour\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPRW.2014.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6270baedeba28001cd1b563a199335720d6e0fe0\",\"title\":\"CNN Features Off-the-Shelf: An Astounding Baseline for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6270baedeba28001cd1b563a199335720d6e0fe0\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2093491\",\"name\":\"M. Oquab\"},{\"authorId\":\"119267979\",\"name\":\"L. Bottou\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2014.222\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c08f5fa876181fc040d76c75fe2433eee3c9b001\",\"title\":\"Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c08f5fa876181fc040d76c75fe2433eee3c9b001\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O. Maron\"},{\"authorId\":null,\"name\":\"T. Lozano-P\\u00e9rez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"A framework for multipleinstance learning\",\"url\":\"\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2002316\",\"name\":\"F. Och\"}],\"doi\":\"10.3115/1075096.1075117\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f12451245667a85d0ee225a80880fc93c71cc8b\",\"title\":\"Minimum Error Rate Training in Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/1f12451245667a85d0ee225a80880fc93c71cc8b\",\"venue\":\"ACL\",\"year\":2003},{\"arxivId\":\"1406.3830\",\"authors\":[{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"1687966\",\"name\":\"Alban Demiraj\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9791399e87bba3f911fd8f570443cf721cf7b1e\",\"title\":\"Modelling, Visualising and Summarising Documents with a Single Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/f9791399e87bba3f911fd8f570443cf721cf7b1e\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"},{\"authorId\":\"2002316\",\"name\":\"F. Och\"}],\"doi\":\"10.3115/1218955.1219032\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ca86842aad16797d0fe0323358f3beb1ac6a5c6\",\"title\":\"Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip-Bigram Statistics\",\"url\":\"https://www.semanticscholar.org/paper/9ca86842aad16797d0fe0323358f3beb1ac6a5c6\",\"venue\":\"ACL\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"From captions to visual concepts and back\",\"topics\":[{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"BLEU\",\"topicId\":\"250421\",\"url\":\"https://www.semanticscholar.org/topic/250421\"},{\"topic\":\"Amazon Mechanical Turk\",\"topicId\":\"84\",\"url\":\"https://www.semanticscholar.org/topic/84\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Meteor\",\"topicId\":\"131649\",\"url\":\"https://www.semanticscholar.org/topic/131649\"},{\"topic\":\"Multiple instance learning\",\"topicId\":\"97196\",\"url\":\"https://www.semanticscholar.org/topic/97196\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Test set\",\"topicId\":\"24168\",\"url\":\"https://www.semanticscholar.org/topic/24168\"},{\"topic\":\"The Turk\",\"topicId\":\"788117\",\"url\":\"https://www.semanticscholar.org/topic/788117\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"