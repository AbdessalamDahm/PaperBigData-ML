"{\"abstract\":\"In this paper we explore the bi-directional mapping between images and their sentence-based descriptions. Critical to our approach is a recurrent neural network that attempts to dynamically build a visual representation of the scene as a caption is being generated or read. The representation automatically learns to remember long-term visual concepts. Our model is capable of both generating novel captions given an image, and reconstructing visual features given an image description. We evaluate our approach on several tasks. These include sentence generation, sentence retrieval and image retrieval. State-of-the-art results are shown for the task of generating novel image descriptions. When compared to human generated captions, our automatically generated captions are equal to or preferred by humans 21.0% of the time. Results are better than or comparable to state-of-the-art results on the image and sentence retrieval tasks for methods using similar visual features.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\",\"url\":\"https://www.semanticscholar.org/author/39717886\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\",\"url\":\"https://www.semanticscholar.org/author/1699161\"}],\"citationVelocity\":73,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/2964284.2984068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cea60c30d404abfd4044a6367d436fa6f67bb89\",\"title\":\"ConTagNet: Exploiting User Context for Image Tag Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/4cea60c30d404abfd4044a6367d436fa6f67bb89\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/ICCV.2015.277\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c3640aae13e344ad70a926510221dada626a44de\",\"title\":\"Guiding the Long-Short Term Memory Model for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/c3640aae13e344ad70a926510221dada626a44de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50218964\",\"name\":\"Zhaohui Wang\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2147e0ef8507e1a4880a916e46c27e15c11d65f4\",\"title\":\"Text to Region: Visual-Word Guided Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/2147e0ef8507e1a4880a916e46c27e15c11d65f4\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2924101\",\"name\":\"Laura K. Allen\"},{\"authorId\":\"2379945\",\"name\":\"Matthew E. Jacovina\"},{\"authorId\":\"2912495\",\"name\":\"M. Dascalu\"},{\"authorId\":\"2122997\",\"name\":\"Rod D. Roscoe\"},{\"authorId\":\"145819845\",\"name\":\"Kevin Kent\"},{\"authorId\":\"3303728\",\"name\":\"Aaron D. Likens\"},{\"authorId\":\"1801516\",\"name\":\"D. McNamara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0569d399ec23876b834777a0ace15c8eb82e29d6\",\"title\":\"{ENTER}ing the Time Series {SPACE}: Uncovering the Writing Process through Keystroke Analyses\",\"url\":\"https://www.semanticscholar.org/paper/0569d399ec23876b834777a0ace15c8eb82e29d6\",\"venue\":\"EDM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31196120\",\"name\":\"Lizhao Gao\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"}],\"doi\":\"10.1145/3195106.3195114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3adf719a5f451a61e98823783b5f2e049bbffa2d\",\"title\":\"Image Captioning with Scene-graph Based Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/3adf719a5f451a61e98823783b5f2e049bbffa2d\",\"venue\":\"ICMLC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"205e895e03969c96f3c482b0bd26308b16a12bd0\",\"title\":\"Image Captioning with an Intermediate Attributes Layer\",\"url\":\"https://www.semanticscholar.org/paper/205e895e03969c96f3c482b0bd26308b16a12bd0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30979431\",\"name\":\"Fuji Ren\"},{\"authorId\":\"3060463\",\"name\":\"Yanwei Bao\"}],\"doi\":\"10.1142/s0219622019300052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41a126896b916299cd6b58e66d89caa7d09eccaf\",\"title\":\"A Review on Human-Computer Interaction and Intelligent Robots\",\"url\":\"https://www.semanticscholar.org/paper/41a126896b916299cd6b58e66d89caa7d09eccaf\",\"venue\":\"Int. J. Inf. Technol. Decis. Mak.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8153177\",\"name\":\"J. Lee\"},{\"authorId\":\"2772676\",\"name\":\"Sanghoon Jun\"},{\"authorId\":\"19305738\",\"name\":\"Young-Won Cho\"},{\"authorId\":\"46900979\",\"name\":\"H. Lee\"},{\"authorId\":\"38628528\",\"name\":\"G. Kim\"},{\"authorId\":\"46844846\",\"name\":\"J. Seo\"},{\"authorId\":\"145979410\",\"name\":\"N. Kim\"}],\"doi\":\"10.3348/kjr.2017.18.4.570\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"265644f1b6740ca34bfbe9762b90b33021adde62\",\"title\":\"Deep Learning in Medical Imaging: General Overview\",\"url\":\"https://www.semanticscholar.org/paper/265644f1b6740ca34bfbe9762b90b33021adde62\",\"venue\":\"Korean journal of radiology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34672380\",\"name\":\"Madhuri A. Bhalekar\"},{\"authorId\":\"143738453\",\"name\":\"M. V. Bedekar\"}],\"doi\":\"10.14445/23488387/ijcse-v4i6p108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1ade6a8c3a4c929efb70810a171c62a39e6f195\",\"title\":\"Review on latest approaches used in Natural Language Processing for generation of Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d1ade6a8c3a4c929efb70810a171c62a39e6f195\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"48651559\",\"name\":\"Ku\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a311848acc2deacc2c03a6fa97fbb81f17223ad6\",\"title\":\"C V ] 16 S ep 2 01 5 Guiding Long-Short Term Memory for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a311848acc2deacc2c03a6fa97fbb81f17223ad6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.02980\",\"authors\":[{\"authorId\":\"2896521\",\"name\":\"Ajoy Mondal\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/ICDAR.2019.00210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed0fdc574d304ea7cb890de445e3537569a5e1dc\",\"title\":\"Textual Description for Mathematical Equations\",\"url\":\"https://www.semanticscholar.org/paper/ed0fdc574d304ea7cb890de445e3537569a5e1dc\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26994223\",\"name\":\"Yunbin Tu\"},{\"authorId\":\"22066021\",\"name\":\"Xishan Zhang\"},{\"authorId\":\"50678151\",\"name\":\"Bingtao Liu\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"}],\"doi\":\"10.1145/3123266.3123354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2cf74ba6f107aa9508e7ef1bad93916d944cb4c\",\"title\":\"Video Description with Spatial-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/c2cf74ba6f107aa9508e7ef1bad93916d944cb4c\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726066\",\"name\":\"Ashesh Jain\"}],\"doi\":\"10.7298/X4MW2F2V\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4f95cae3e35ba70e4a6f7b899de514d18aa0c71\",\"title\":\"Learning from natural human interactions for assistive robots\",\"url\":\"https://www.semanticscholar.org/paper/b4f95cae3e35ba70e4a6f7b899de514d18aa0c71\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145960537\",\"name\":\"W. Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1007/978-981-10-7299-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"title\":\"Relevance and Coherence Based Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398421283\",\"name\":\"U. Markowska-Kaczmar\"},{\"authorId\":\"153318273\",\"name\":\"H. Kwasnicka\"}],\"doi\":\"10.1007/978-3-319-73891-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"title\":\"Deep Learning\\u2014A New Era in Bridging the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8218640e95bb2d925a617b1c3012eed7d209351\",\"title\":\"Show, Reward and Tell: Automatic Generation of Narrative Paragraph From Photo Stream by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/b8218640e95bb2d925a617b1c3012eed7d209351\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783874\",\"name\":\"T. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144751998\",\"name\":\"C. He\"}],\"doi\":\"10.1007/s11063-019-09979-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a54a18073b4b4a788e106d540d26817c8c898a63\",\"title\":\"Image Caption with Endogenous\\u2013Exogenous Attention\",\"url\":\"https://www.semanticscholar.org/paper/a54a18073b4b4a788e106d540d26817c8c898a63\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1804.00861\",\"authors\":[{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"title\":\"Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1604.04279\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46454-1_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"title\":\"Learning Visual Storylines with Skipping Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8020f05b18ed434009b5d56398c57456c7dcde\",\"title\":\"Disentangling neural network representations for improved generalization\",\"url\":\"https://www.semanticscholar.org/paper/dc8020f05b18ed434009b5d56398c57456c7dcde\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49827131\",\"name\":\"Peggy Chi\"},{\"authorId\":null,\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04f83b15c3d40851dd6cc9d5b3f8b0b714780437\",\"title\":\"Interactive Visual Description of a Web Page for Smart Speakers\",\"url\":\"https://www.semanticscholar.org/paper/04f83b15c3d40851dd6cc9d5b3f8b0b714780437\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743434\",\"name\":\"W. Cheng\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fa1076a98a15cec083fb474f238237f1b3a341a\",\"title\":\"Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-based Method\",\"url\":\"https://www.semanticscholar.org/paper/6fa1076a98a15cec083fb474f238237f1b3a341a\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2002.09536\",\"authors\":[{\"authorId\":\"38672865\",\"name\":\"M. Seshadri\"},{\"authorId\":\"145311801\",\"name\":\"M. Srikanth\"},{\"authorId\":\"1901449\",\"name\":\"M. Belov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4aaa61d7e56f42833aaae788544704c46dcb9e\",\"title\":\"Image to Language Understanding: Captioning approach\",\"url\":\"https://www.semanticscholar.org/paper/ad4aaa61d7e56f42833aaae788544704c46dcb9e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40143631\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TCSVT.2019.2916167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"title\":\"Matching Image and Sentence With Multi-Faceted Representations\",\"url\":\"https://www.semanticscholar.org/paper/4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591146157\",\"name\":\"Yixiao Zhang\"},{\"authorId\":\"40406046\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"150084152\",\"name\":\"Dingsu Wang\"},{\"authorId\":\"38746431\",\"name\":\"G. Xia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2022ea7ad4b00a307559ae0be1d0ae2237ad7466\",\"title\":\"BUTTER: A Representation Learning Framework for Bi-directional Music-Sentence Retrieval and Generation\",\"url\":\"https://www.semanticscholar.org/paper/2022ea7ad4b00a307559ae0be1d0ae2237ad7466\",\"venue\":\"NLP4MUSA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39232438\",\"name\":\"C. Liu\"},{\"authorId\":\"40203750\",\"name\":\"F. Sun\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"49451531\",\"name\":\"F. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e5ae83f9f44b606898b1795906de5464ac3482e\",\"title\":\"WEOTAWEO 2 LSTM WEO 1 Encoding WSS 1 WSS 2 WSSTB Decoding Attention Cell\",\"url\":\"https://www.semanticscholar.org/paper/2e5ae83f9f44b606898b1795906de5464ac3482e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144168152\",\"name\":\"Q. Cai\"},{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"40569887\",\"name\":\"X. Zhang\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"145259074\",\"name\":\"W. Shao\"},{\"authorId\":null,\"name\":\"Lei Wang\"}],\"doi\":\"10.1007/978-981-10-7299-4_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd8c8dfc6ab8ba3c96834b04cd55ce83972de4a4\",\"title\":\"A Novel Framework for Image Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/dd8c8dfc6ab8ba3c96834b04cd55ce83972de4a4\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1612.04949\",\"authors\":[{\"authorId\":\"38314901\",\"name\":\"H. Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5793958cd1654b4817ebb57f5484dfd8861f916\",\"title\":\"Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering\",\"url\":\"https://www.semanticscholar.org/paper/b5793958cd1654b4817ebb57f5484dfd8861f916\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1805.02763\",\"authors\":[{\"authorId\":\"40027070\",\"name\":\"Junjie Wang\"},{\"authorId\":\"144634407\",\"name\":\"Mingyang Li\"},{\"authorId\":\"47673404\",\"name\":\"Song Wang\"},{\"authorId\":\"1703872\",\"name\":\"Tim Menzies\"},{\"authorId\":\"40326638\",\"name\":\"Qing Wang\"}],\"doi\":\"10.1016/j.infsof.2019.03.003\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a85fbfd545116c7e85846ce8d5903bebfd5ab4d7\",\"title\":\"Cutting Away the Confusion From Crowdtesting\",\"url\":\"https://www.semanticscholar.org/paper/a85fbfd545116c7e85846ce8d5903bebfd5ab4d7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.cviu.2017.04.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"title\":\"Hierarchical & multimodal video captioning: Discovering and transferring multimodal knowledge for vision to language\",\"url\":\"https://www.semanticscholar.org/paper/96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1704.04224\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.440\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"title\":\"Spatial Memory for Context Reasoning in Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1702.05658\",\"authors\":[{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"39369840\",\"name\":\"Feng Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.24963/ijcai.2017/563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2498124e6466ccde28c95477c923e7cd5843f4c0\",\"title\":\"MAT: A Multimodal Attentive Translator for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2498124e6466ccde28c95477c923e7cd5843f4c0\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1007/978-981-10-7299-4_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42618b4eddda34ebaf4501e9b54203d38b52534b\",\"title\":\"FFGS: Feature Fusion with Gating Structure for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/42618b4eddda34ebaf4501e9b54203d38b52534b\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc8df4ad35282ccf19261e02de87d8e35c956537\",\"title\":\"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fc8df4ad35282ccf19261e02de87d8e35c956537\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49110486\",\"name\":\"Qianwen Wang\"},{\"authorId\":\"143625301\",\"name\":\"J. Yuan\"},{\"authorId\":\"50358016\",\"name\":\"Shuxin Chen\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145506027\",\"name\":\"H. Qu\"},{\"authorId\":\"71520199\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TVCG.2019.2921323\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a56942ee5ab6ebdc3d8c06092ea148e7fc80f73\",\"title\":\"Visual Genealogy of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6a56942ee5ab6ebdc3d8c06092ea148e7fc80f73\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":\"2010.11701\",\"authors\":[{\"authorId\":\"84039136\",\"name\":\"P. Sadler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b60d6e35891baa34282433546df0449d7422ce98\",\"title\":\"Spatial Attention as an Interface for Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b60d6e35891baa34282433546df0449d7422ce98\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2532864\",\"name\":\"Sotetsu Koyamada\"},{\"authorId\":null,\"name\":\"Yuta Kikuchi\"},{\"authorId\":null,\"name\":\"Atsunori Kanemura\"},{\"authorId\":null,\"name\":\"Shin-ichi Maeda\"},{\"authorId\":\"145516720\",\"name\":\"S. Ishii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e1e7d41b35544a3a44c3e25b579a28e61bd827c\",\"title\":\"Alpha-divergence bridges maximum likelihood and reinforcement learning in neural sequence generation\",\"url\":\"https://www.semanticscholar.org/paper/7e1e7d41b35544a3a44c3e25b579a28e61bd827c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1703.04706\",\"authors\":[{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"35646366\",\"name\":\"A. Mcfadyen\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.neucom.2018.03.040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5820ce33563f44f0c3127d46654a2b48aac12cc\",\"title\":\"Tree Memory Networks for Modelling Long-term Temporal Dependencies\",\"url\":\"https://www.semanticscholar.org/paper/d5820ce33563f44f0c3127d46654a2b48aac12cc\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3291925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a437bb550d1df02188e4b145e01675551da36336\",\"title\":\"Show, Reward, and Tell\",\"url\":\"https://www.semanticscholar.org/paper/a437bb550d1df02188e4b145e01675551da36336\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1810.04101\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"2120874\",\"name\":\"Tobias Domhan\"},{\"authorId\":\"2521764\",\"name\":\"F. Hieber\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"title\":\"Image Captioning as Neural Machine Translation Task in SOCKEYE\",\"url\":\"https://www.semanticscholar.org/paper/d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"}],\"doi\":\"10.1145/2964284.2971475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15bf3cffe453cc5d29fc16e1032163e234d52e9d\",\"title\":\"Sentiment and Emotion Analysis for Social Multimedia: Methodologies and Applications\",\"url\":\"https://www.semanticscholar.org/paper/15bf3cffe453cc5d29fc16e1032163e234d52e9d\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144711477\",\"name\":\"B. Qu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/CITS.2016.7546397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80e65772132b356358f192470ae1e36d2ed6a965\",\"title\":\"Deep semantic understanding of high resolution remote sensing image\",\"url\":\"https://www.semanticscholar.org/paper/80e65772132b356358f192470ae1e36d2ed6a965\",\"venue\":\"2016 International Conference on Computer, Information and Telecommunication Systems (CITS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49ac61eed8301f41da85e0053be3be790293faac\",\"title\":\"Recurrent Highway Networks with Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49ac61eed8301f41da85e0053be3be790293faac\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/TASLP.2018.2872106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e56c99e8a94d3e585166fcd66f2ab6da60932f09\",\"title\":\"Semantic Speech Retrieval With a Visually Grounded Model of Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/e56c99e8a94d3e585166fcd66f2ab6da60932f09\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.08779\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":null,\"name\":\"Sandeep Kumar\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093293\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e4720942ff8b02d2822aea5d024628139551723\",\"title\":\"Deep Bayesian Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/8e4720942ff8b02d2822aea5d024628139551723\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1710.01949\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/TASLP.2018.2872106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"561f69917d109a20d630408718676b299c7de191\",\"title\":\"Semantic keyword spotting by learning from images and speech\",\"url\":\"https://www.semanticscholar.org/paper/561f69917d109a20d630408718676b299c7de191\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba67de7e822a94091b9e57cc9be3069822a4f5c8\",\"title\":\"A Neural-Symbolic Approach to Natural Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ba67de7e822a94091b9e57cc9be3069822a4f5c8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"title\":\"Story Understanding through Semantic Analysis and Automatic Alignment of Text and Video\",\"url\":\"https://www.semanticscholar.org/paper/39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25184078\",\"name\":\"M. Chevalier\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"2386962\",\"name\":\"Gilles H\\u00e9naff\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1016/j.patrec.2018.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2a2ddc4701076919d814e84172823ebd3faf09c\",\"title\":\"Classifying low-resolution images by integrating privileged information in deep CNNs\",\"url\":\"https://www.semanticscholar.org/paper/d2a2ddc4701076919d814e84172823ebd3faf09c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47668580\",\"name\":\"Akeem Olowolayemo\"},{\"authorId\":\"52230792\",\"name\":\"Pearly Oh Bei Qing\"}],\"doi\":\"10.1109/ICT4M.2018.00039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1db5407f7f11c72994456402037dea3fce31303a\",\"title\":\"Automated Real-Time At-Scene Reporting System\",\"url\":\"https://www.semanticscholar.org/paper/1db5407f7f11c72994456402037dea3fce31303a\",\"venue\":\"2018 International Conference on Information and Communication Technology for the Muslim World (ICT4M)\",\"year\":2018},{\"arxivId\":\"1805.09461\",\"authors\":[{\"authorId\":\"2180949\",\"name\":\"Yaser Keneshloo\"},{\"authorId\":\"145531789\",\"name\":\"Tian Shi\"},{\"authorId\":\"1755938\",\"name\":\"Naren Ramakrishnan\"},{\"authorId\":\"144417522\",\"name\":\"C. Reddy\"}],\"doi\":\"10.1109/TNNLS.2019.2929141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15a06d8601539b5eb6df5baf6bc4c3bdefb34855\",\"title\":\"Deep Reinforcement Learning for Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/15a06d8601539b5eb6df5baf6bc4c3bdefb34855\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33265017\",\"name\":\"Akihito Seki\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/CVPR.2017.703\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60f2f1de7ac2976285b477ebe74884f5c641a7a0\",\"title\":\"SGM-Nets: Semi-Global Matching with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/60f2f1de7ac2976285b477ebe74884f5c641a7a0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1912.00501\",\"authors\":[{\"authorId\":\"34816469\",\"name\":\"Himangi Mittal\"},{\"authorId\":\"1744000\",\"name\":\"A. Abraham\"},{\"authorId\":\"1836246\",\"name\":\"A. Arora\"}],\"doi\":\"10.1007/978-3-030-37188-3_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"702ba69061222f5178824a51008bf33e118e4b7d\",\"title\":\"Interpreting Context of Images Using Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/702ba69061222f5178824a51008bf33e118e4b7d\",\"venue\":\"BDA\",\"year\":2019},{\"arxivId\":\"1710.11475\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"96692a8fc740eee99e3ad5e48e73eae8de2578db\",\"title\":\"A Neural-Symbolic Approach to Design of CAPTCHA.\",\"url\":\"https://www.semanticscholar.org/paper/96692a8fc740eee99e3ad5e48e73eae8de2578db\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9260404\",\"name\":\"Xiaotong Du\"},{\"authorId\":\"46685438\",\"name\":\"J. Yuan\"},{\"authorId\":\"47652550\",\"name\":\"L. Hu\"},{\"authorId\":\"122907636\",\"name\":\"Yuke Dai\"}],\"doi\":\"10.1007/s00371-018-1591-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4170882122b559fc39ab3eafd66babe2429ba858\",\"title\":\"Description generation of open-domain videos incorporating multimodal features and bidirectional encoder\",\"url\":\"https://www.semanticscholar.org/paper/4170882122b559fc39ab3eafd66babe2429ba858\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40027070\",\"name\":\"J. Wang\"},{\"authorId\":\"50651506\",\"name\":\"Mingyang Li\"},{\"authorId\":\"50694781\",\"name\":\"S. Wang\"},{\"authorId\":\"1703872\",\"name\":\"T. Menzies\"},{\"authorId\":\"40326638\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/J.INFSOF.2019.03.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f4a6c38731e3bda1522e81b48948707856f2a68\",\"title\":\"Images don't lie: Duplicate crowdtesting reports detection with screenshot information\",\"url\":\"https://www.semanticscholar.org/paper/7f4a6c38731e3bda1522e81b48948707856f2a68\",\"venue\":\"Inf. Softw. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758254\",\"name\":\"Virg\\u00ednia P. Campos\"},{\"authorId\":\"152123212\",\"name\":\"Tiago M. U. de Ara\\u00fajo\"},{\"authorId\":\"1521983402\",\"name\":\"Guido L. de Souza Filho\"},{\"authorId\":\"1703957\",\"name\":\"L. Gon\\u00e7alves\"}],\"doi\":\"10.1007/s10209-018-0634-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97b0e43ae18f32378d41c2730268aa7f0f6ba462\",\"title\":\"CineAD: a system for automated audio description script generation for the visually impaired\",\"url\":\"https://www.semanticscholar.org/paper/97b0e43ae18f32378d41c2730268aa7f0f6ba462\",\"venue\":\"Universal Access in the Information Society\",\"year\":2018},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"title\":\"What value high level concepts in vision to language problems\",\"url\":\"https://www.semanticscholar.org/paper/bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9db873fb85ad9e3f19d2462a724e6f169a79328a\",\"title\":\"Optimization for Networks and Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9db873fb85ad9e3f19d2462a724e6f169a79328a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49268056\",\"name\":\"J. Hu\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1145/3339363.3339389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"title\":\"Semantic BI-Embedded GRU for Fill-in-the-Blank Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"venue\":\"CSSE 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"145819866\",\"name\":\"J. Liang\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1016/j.neucom.2018.03.078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"title\":\"Image captioning by incorporating affective concepts learned from both visual and textual components\",\"url\":\"https://www.semanticscholar.org/paper/adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40930501\",\"name\":\"Jinning Guan\"},{\"authorId\":\"145567111\",\"name\":\"E. Wang\"}],\"doi\":\"10.1016/j.image.2018.02.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9a5786025bae3de7d631daa8460ed9dc32a8fab\",\"title\":\"Repeated review based image captioning for image evidence review\",\"url\":\"https://www.semanticscholar.org/paper/e9a5786025bae3de7d631daa8460ed9dc32a8fab\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51444178\",\"name\":\"K. P. Korshunova\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c22aa66b2fad7ed31252b5e6276a0df371c57b4c\",\"title\":\"The neural network image captioning model based on adversarial training\",\"url\":\"https://www.semanticscholar.org/paper/c22aa66b2fad7ed31252b5e6276a0df371c57b4c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2374364\",\"name\":\"Yusuke Mukuta\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2015.306\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f6ed8a79b814893bbe4902634416096ac4e8ed6\",\"title\":\"Common Subspace for Model and Similarity: Phrase Learning for Caption Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/3f6ed8a79b814893bbe4902634416096ac4e8ed6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1711.06640\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"38094552\",\"name\":\"Sam Thomson\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2018.00611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"title\":\"Neural Motifs: Scene Graph Parsing with Global Context\",\"url\":\"https://www.semanticscholar.org/paper/0da8af8d81e84381ffe656a0bbf2f3937ffac618\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1745000\",\"name\":\"H. Wang\"}],\"doi\":\"10.1145/2733373.2807418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b17b9c40ea8bb8904b782e91627c1f022a5574f\",\"title\":\"Learning Knowledge Bases for Multimedia in 2015\",\"url\":\"https://www.semanticscholar.org/paper/9b17b9c40ea8bb8904b782e91627c1f022a5574f\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"2012.02339\",\"authors\":[{\"authorId\":\"2031911881\",\"name\":\"Edwin G. Ng\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"title\":\"Understanding Guided Image Captioning Performance across Domains\",\"url\":\"https://www.semanticscholar.org/paper/0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143974276\",\"name\":\"Marco Idiart\"},{\"authorId\":\"2038285\",\"name\":\"A. Lenci\"},{\"authorId\":\"1736763\",\"name\":\"T. Poibeau\"},{\"authorId\":\"145585242\",\"name\":\"Aline Villavicencio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca4d78f2995f51a43fe86abf67c1664f4e8b6d73\",\"title\":\"ACL 2018 Cognitive Aspects of Computational Language Learning and Processing Proceedings of the Eighth Workshop\",\"url\":\"https://www.semanticscholar.org/paper/ca4d78f2995f51a43fe86abf67c1664f4e8b6d73\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134518946\",\"name\":\"Nanxing Li\"},{\"authorId\":\"50678073\",\"name\":\"Bei Liu\"},{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1145/3323873.3325050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"title\":\"Emotion Reinforced Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.35940/ijrte.b1472.0982s1119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d23256c631bde5d1c88a5f6ed139a458c45c6b54\",\"title\":\"Prediction of Caption and Emoji of an Image using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d23256c631bde5d1c88a5f6ed139a458c45c6b54\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"49713266\",\"name\":\"Fan Jia\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2017.656\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca738cb87bb49495e20be72adffce37bb8990368\",\"title\":\"Diverse Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/ca738cb87bb49495e20be72adffce37bb8990368\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121104319\",\"name\":\"Rehab Alahmadi\"},{\"authorId\":\"1695172\",\"name\":\"C. H. Park\"},{\"authorId\":\"36266636\",\"name\":\"J. Hahn\"}],\"doi\":\"10.1117/12.2523174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"title\":\"Sequence-to-sequence image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"venue\":\"International Conference on Machine Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2124180\",\"name\":\"Jiayan Qiu\"},{\"authorId\":\"48632224\",\"name\":\"Xinchao Wang\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.00869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dde47480f7efd36903d3e554256f6f1d185d6415\",\"title\":\"World From Blur\",\"url\":\"https://www.semanticscholar.org/paper/dde47480f7efd36903d3e554256f6f1d185d6415\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2785110\",\"name\":\"Alexy Bhowmick\"},{\"authorId\":\"2350548\",\"name\":\"S. M. Hazarika\"}],\"doi\":\"10.1007/s12193-016-0235-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ac481b9f85ca498fb770fca7d460a96eb0debdb\",\"title\":\"An insight into assistive technology for the visually impaired and blind people: state-of-the-art and future trends\",\"url\":\"https://www.semanticscholar.org/paper/1ac481b9f85ca498fb770fca7d460a96eb0debdb\",\"venue\":\"Journal on Multimodal User Interfaces\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"}],\"doi\":\"10.1016/j.cviu.2017.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1e2e32f29cf7d23881e98dfe018d9049bdb070d\",\"title\":\"Image Understanding using vision and reasoning through Scene Description Graph\",\"url\":\"https://www.semanticscholar.org/paper/e1e2e32f29cf7d23881e98dfe018d9049bdb070d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1612.07360\",\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f83380fe193ae8475e660c1c6b12b60521a29f\",\"title\":\"Top-Down Visual Saliency Guided by Captions\",\"url\":\"https://www.semanticscholar.org/paper/76f83380fe193ae8475e660c1c6b12b60521a29f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1907.05084\",\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e854ee8a8eda42858e8b1fc050f6cae98f54be6\",\"title\":\"MeetUp! A Corpus of Joint Activity Dialogues in a Visual Environment\",\"url\":\"https://www.semanticscholar.org/paper/3e854ee8a8eda42858e8b1fc050f6cae98f54be6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1709.09118\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6a645ea49b0723c88286cbf416c7956b1e2ea7c\",\"title\":\"Tensor Product Generation Networks\",\"url\":\"https://www.semanticscholar.org/paper/d6a645ea49b0723c88286cbf416c7956b1e2ea7c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":\"10.18653/v1/N18-1114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2df65bc38690ec56c4fe24380f9993ba2904e9c\",\"title\":\"Tensor Product Generation Networks for Deep NLP Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f2df65bc38690ec56c4fe24380f9993ba2904e9c\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35181104\",\"name\":\"T. N. Tran\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"dd9bd7e08139510228303f678d289a9bb7027a55\",\"title\":\"Aggregating Image and Text Quantized Correlated Components Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/dd9bd7e08139510228303f678d289a9bb7027a55\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1605.05440\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICIP.2016.7532983\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41aa209e9d294d370357434f310d49b2b0baebeb\",\"title\":\"Beyond caption to narrative: Video captioning with multiple sentences\",\"url\":\"https://www.semanticscholar.org/paper/41aa209e9d294d370357434f310d49b2b0baebeb\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632281\",\"name\":\"X. Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/tpami.2020.2972281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"title\":\"Vision-Language Navigation Policy Learning and Adaptation.\",\"url\":\"https://www.semanticscholar.org/paper/2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"Andrea Apicella\"},{\"authorId\":\"13851143\",\"name\":\"Anna Corazza\"},{\"authorId\":\"34675913\",\"name\":\"Francesco Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.1007/978-3-319-68560-1_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ee6951d8cdb9c2ee5d56d2b3f40296256164d3\",\"title\":\"Exploiting Context Information for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/e7ee6951d8cdb9c2ee5d56d2b3f40296256164d3\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900013\",\"name\":\"Zhengyang Wu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"177c48590469c62d430cf74fee7b5bd28bfbbc1d\",\"title\":\"Articulated Motion Learning via Visual and Lingual Signals\",\"url\":\"https://www.semanticscholar.org/paper/177c48590469c62d430cf74fee7b5bd28bfbbc1d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"36158244\",\"name\":\"Maaike H. T. de Boer\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1109/ICME.2018.8486491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d27272027cd84341070fd4b7eb7e03dcb514d93f\",\"title\":\"A Dual Prediction Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d27272027cd84341070fd4b7eb7e03dcb514d93f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10798523\",\"name\":\"C. C. Park\"},{\"authorId\":\"47659605\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/TPAMI.2017.2700381\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17d4fee6b21c9277375d6cf0c9087828595009b6\",\"title\":\"Retrieval of Sentence Sequences for an Image Stream via Coherence Recurrent Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/17d4fee6b21c9277375d6cf0c9087828595009b6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1712.02051\",\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"49490596\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d190282ed59639b16e726a3237938b53976077\",\"title\":\"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d190282ed59639b16e726a3237938b53976077\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2532864\",\"name\":\"Sotetsu Koyamada\"},{\"authorId\":\"144142812\",\"name\":\"Yuta Kikuchi\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"},{\"authorId\":\"35647224\",\"name\":\"S. Maeda\"},{\"authorId\":\"145516720\",\"name\":\"S. Ishii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21895b5cf7a4a1a97d628d97cdb59c7f606d973b\",\"title\":\"Neural Sequence Model Training via $\\u03b1$-divergence Minimization\",\"url\":\"https://www.semanticscholar.org/paper/21895b5cf7a4a1a97d628d97cdb59c7f606d973b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2343931\",\"name\":\"Miao Ma\"},{\"authorId\":\"49292300\",\"name\":\"Bolong Wang\"}],\"doi\":\"10.1109/GSIS.2017.8077673\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d466c9ceeecb326c5f2c834b8f424d5384a200a\",\"title\":\"A grey relational analysis based evaluation metric for image captioning and video captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d466c9ceeecb326c5f2c834b8f424d5384a200a\",\"venue\":\"2017 International Conference on Grey Systems and Intelligent Services (GSIS)\",\"year\":2017},{\"arxivId\":\"1705.00581\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1145/3123266.3123297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48031e454325487b5fa7972280d1a2400bdef1d4\",\"title\":\"Query-adaptive Video Summarization via Quality-aware Relevance Estimation\",\"url\":\"https://www.semanticscholar.org/paper/48031e454325487b5fa7972280d1a2400bdef1d4\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1704.03944\",\"authors\":[{\"authorId\":\"145489055\",\"name\":\"Y. Zhang\"},{\"authorId\":\"27257564\",\"name\":\"Luyao Yuan\"},{\"authorId\":\"1857914\",\"name\":\"Yijie Guo\"},{\"authorId\":\"1755497\",\"name\":\"Zhiyuan He\"},{\"authorId\":\"38648777\",\"name\":\"Ian Huang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/CVPR.2017.122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"title\":\"Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.08759\",\"authors\":[{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.763\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cee733ee31e245dac4655a870fd9226163a52b5\",\"title\":\"Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-in-the-Blank Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1cee733ee31e245dac4655a870fd9226163a52b5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8657946\",\"name\":\"A. Kumar\"},{\"authorId\":\"4054731\",\"name\":\"Shivali Goel\"}],\"doi\":\"10.3233/HIS-170246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd8a3f44f806afa2a609185dfe615fb65724bc2b\",\"title\":\"A survey of evolution of image captioning techniques\",\"url\":\"https://www.semanticscholar.org/paper/cd8a3f44f806afa2a609185dfe615fb65724bc2b\",\"venue\":\"Int. J. Hybrid Intell. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805970305\",\"name\":\"Georgios Barlas\"},{\"authorId\":\"1859319\",\"name\":\"Christos Veinidis\"},{\"authorId\":\"35575984\",\"name\":\"A. Arampatzis\"}],\"doi\":\"10.1007/s00371-020-01867-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a31c2b3a88719419cf679778846edbe3be9e81b3\",\"title\":\"What we see in a photograph: content selection for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a31c2b3a88719419cf679778846edbe3be9e81b3\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1611.06949\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"title\":\"Dense Captioning with Joint Inference and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49645155\",\"name\":\"Yan-shuo Chang\"}],\"doi\":\"10.1007/s11042-017-4593-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2617da2d4a0466784809981babcdb7f697b5f24\",\"title\":\"Fine-grained attention for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/f2617da2d4a0466784809981babcdb7f697b5f24\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1803.08326\",\"authors\":[{\"authorId\":\"35347896\",\"name\":\"Y. Qian\"},{\"authorId\":\"1911387\",\"name\":\"S. Pertuz\"},{\"authorId\":\"2596488\",\"name\":\"Jarno Nikkanen\"},{\"authorId\":\"145196370\",\"name\":\"J. K\\u00e4m\\u00e4r\\u00e4inen\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"}],\"doi\":\"10.5220/0007406900360046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721306ec8c7b49b33c286e3244fceb0abeaf8914\",\"title\":\"Revisiting Gray Pixel for Statistical Illumination Estimation\",\"url\":\"https://www.semanticscholar.org/paper/721306ec8c7b49b33c286e3244fceb0abeaf8914\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"3436918\",\"name\":\"S. Surya\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TPAMI.2018.2877996\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71807a11819431cce1b29b9c64dbd876f1da39c7\",\"title\":\"Pictionary-Style Word Guessing on Hand-Drawn Object Sketches: Dataset, Analysis and Deep Network Models\",\"url\":\"https://www.semanticscholar.org/paper/71807a11819431cce1b29b9c64dbd876f1da39c7\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47075011\",\"name\":\"Cheng Wang\"},{\"authorId\":\"1688587\",\"name\":\"Haojin Yang\"},{\"authorId\":\"1708312\",\"name\":\"C. Meinel\"}],\"doi\":\"10.1145/3115432\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fe69c9ebf4ede1eb8e2ec233b632031173dd8cb\",\"title\":\"Image Captioning with Deep Bidirectional LSTMs and Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/0fe69c9ebf4ede1eb8e2ec233b632031173dd8cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48496963\",\"name\":\"F. Ahmed\"},{\"authorId\":null,\"name\":\"Md Sultan Mahmud\"},{\"authorId\":\"1828610\",\"name\":\"M. Yeasin\"}],\"doi\":\"10.1109/ICECE.2018.8636726\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db30478abbb3875ba474994d0cb1fb10e3ffb099\",\"title\":\"Words to Meaningful Sentence: Analytics through Game Interface\",\"url\":\"https://www.semanticscholar.org/paper/db30478abbb3875ba474994d0cb1fb10e3ffb099\",\"venue\":\"2018 10th International Conference on Electrical and Computer Engineering (ICECE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144479376\",\"name\":\"Renchu Guan\"},{\"authorId\":\"26832002\",\"name\":\"X. Wang\"},{\"authorId\":\"1400229417\",\"name\":\"Mary Qu Yang\"},{\"authorId\":\"49889909\",\"name\":\"Y. Zhang\"},{\"authorId\":\"40242610\",\"name\":\"F. Zhou\"},{\"authorId\":\"48473466\",\"name\":\"Chen Yang\"},{\"authorId\":\"1694025\",\"name\":\"Yanchun Liang\"}],\"doi\":\"10.1038/s41598-017-17842-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8767c51c110d708496fcc84ed0517ad380348048\",\"title\":\"Multi-label Deep Learning for Gene Function Annotation in Cancer Pathways\",\"url\":\"https://www.semanticscholar.org/paper/8767c51c110d708496fcc84ed0517ad380348048\",\"venue\":\"Scientific Reports\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46348862\",\"name\":\"D. Wang\"},{\"authorId\":\"144067957\",\"name\":\"K. Mao\"}],\"doi\":\"10.1109/TMM.2019.2920620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"200484b9e25486c32f84c229426b30f58b89e16e\",\"title\":\"Learning Semantic Text Features for Web Text-Aided Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/200484b9e25486c32f84c229426b30f58b89e16e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"2001.08730\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1490642986\",\"name\":\"Shivansh Pate\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a487065408c44d387aa1cf7836cd58405f945983\",\"title\":\"Robust Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a487065408c44d387aa1cf7836cd58405f945983\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1904.09421\",\"authors\":[{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1007/s11042-018-5856-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c03b9770f8cfa7b1420af68cd4d2236c182df967\",\"title\":\"Multi-modal gated recurrent units for image description\",\"url\":\"https://www.semanticscholar.org/paper/c03b9770f8cfa7b1420af68cd4d2236c182df967\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1607.06215\",\"authors\":[{\"authorId\":\"2500189\",\"name\":\"K. Wang\"},{\"authorId\":\"2397961\",\"name\":\"Qiyue Yin\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":\"50425438\",\"name\":\"S. Wu\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6721e26e65c6b72dafae74fd1e7a6f2e6023a312\",\"title\":\"A Comprehensive Survey on Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6721e26e65c6b72dafae74fd1e7a6f2e6023a312\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1703.03567\",\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b7c6ef333c6e64f2dfa97a1a3614d0775d81a8a\",\"title\":\"A New Evaluation Protocol and Benchmarking Results for Extendable Cross-media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9b7c6ef333c6e64f2dfa97a1a3614d0775d81a8a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25b78b68f8c9b50b7f9290d88134fc377fd43433\",\"title\":\"CloudCV: Deep Learning and Computer Vision on the Cloud\",\"url\":\"https://www.semanticscholar.org/paper/25b78b68f8c9b50b7f9290d88134fc377fd43433\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1511.05526\",\"authors\":[{\"authorId\":\"1900013\",\"name\":\"Zhengyang Wu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9453721f35f364e176a5aaa7bdb622f72fbcaec\",\"title\":\"Learning Articulated Motion Models from Visual and Lingual Signals\",\"url\":\"https://www.semanticscholar.org/paper/a9453721f35f364e176a5aaa7bdb622f72fbcaec\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1903.10842\",\"authors\":[{\"authorId\":\"46868295\",\"name\":\"Yuchi Zhang\"},{\"authorId\":\"47906605\",\"name\":\"Yongliang Wang\"},{\"authorId\":\"50821035\",\"name\":\"Liping Zhang\"},{\"authorId\":\"90272871\",\"name\":\"Zhiqiang Zhang\"},{\"authorId\":\"20029557\",\"name\":\"K. Gai\"}],\"doi\":\"10.1109/ICASSP.2019.8683090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bddac3af58429b442f195a642bc338421ab512a7\",\"title\":\"Improve Diverse Text Generation by Self Labeling Conditional Variational Auto Encoder\",\"url\":\"https://www.semanticscholar.org/paper/bddac3af58429b442f195a642bc338421ab512a7\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900967\",\"name\":\"U. Zia\"},{\"authorId\":\"145759322\",\"name\":\"M. M. Riaz\"},{\"authorId\":\"144683577\",\"name\":\"A. Ghafoor\"},{\"authorId\":\"145602758\",\"name\":\"Seyyed Salehi Seyyed Ali\"}],\"doi\":\"10.1007/s00521-019-04587-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"title\":\"Topic sensitive image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"3141085\",\"name\":\"V. K\\u0131l\\u0131\\u00e7\"}],\"doi\":\"10.23919/ELECO47770.2019.8990630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94b442f133b1c11ccb6fb22affb797818745c4b7\",\"title\":\"A New Image Captioning Approach for Visually Impaired People\",\"url\":\"https://www.semanticscholar.org/paper/94b442f133b1c11ccb6fb22affb797818745c4b7\",\"venue\":\"2019 11th International Conference on Electrical and Electronics Engineering (ELECO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13827135\",\"name\":\"Wenjian Hu\"},{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"2304380\",\"name\":\"Jinyoung Han\"},{\"authorId\":\"143880500\",\"name\":\"C. Chuah\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1145/3159652.3159705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d82ee124118ac065dd25f7c5e45ec5455e9c8d6\",\"title\":\"Who Will Share My Image?: Predicting the Content Diffusion Path in Online Social Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d82ee124118ac065dd25f7c5e45ec5455e9c8d6\",\"venue\":\"WSDM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144655341\",\"name\":\"S. L. Frank\"},{\"authorId\":\"50276886\",\"name\":\"P. Monaghan\"},{\"authorId\":\"40563913\",\"name\":\"C. Tsoukala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ce7e53d00c717ba30e7fafe2883ee276eddd196e\",\"title\":\"Neural network models of language acquisition and processing\",\"url\":\"https://www.semanticscholar.org/paper/ce7e53d00c717ba30e7fafe2883ee276eddd196e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/2962719\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99a34646fc41586e82d0712a6ea3c04deb15cad9\",\"title\":\"Semantic Feature Mining for Video Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/99a34646fc41586e82d0712a6ea3c04deb15cad9\",\"venue\":\"TOMM\",\"year\":2016},{\"arxivId\":\"1608.08716\",\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1609/aimag.v37i1.2647\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"title\":\"Measuring Machine Intelligence Through Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"venue\":\"AI Mag.\",\"year\":2016},{\"arxivId\":\"1911.08618\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1609/AAAI.V34I07.6858\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"title\":\"Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA\",\"url\":\"https://www.semanticscholar.org/paper/dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108124522\",\"name\":\"T. Fujii\"},{\"authorId\":\"1768926\",\"name\":\"Yuichi Sei\"},{\"authorId\":\"1749328\",\"name\":\"Y. Tahara\"},{\"authorId\":\"1394541524\",\"name\":\"Ryohei Orihara\"},{\"authorId\":\"1740433\",\"name\":\"A. Ohsuga\"}],\"doi\":\"10.2991/IJNDC.K.190710.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d85b1543ab836881d3f0992395e8f210b8fc07f4\",\"title\":\"\\\"Never fry carrots without chopping\\\" Generating Cooking Recipes from Cooking Videos Using Deep Learning Considering Previous Process\",\"url\":\"https://www.semanticscholar.org/paper/d85b1543ab836881d3f0992395e8f210b8fc07f4\",\"venue\":\"Int. J. Networked Distributed Comput.\",\"year\":2019},{\"arxivId\":\"1707.05720\",\"authors\":[{\"authorId\":\"33516562\",\"name\":\"Mohit Shridhar\"},{\"authorId\":\"145463096\",\"name\":\"D. Hsu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff84ec1dab06135b2d8a99b441d04e15259090a1\",\"title\":\"Grounding Spatio-Semantic Referring Expressions for Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ff84ec1dab06135b2d8a99b441d04e15259090a1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1611.06607\",\"authors\":[{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.356\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a7011346ce939e3251915e92ae2f252e4c7f777\",\"title\":\"A Hierarchical Approach for Generating Descriptive Image Paragraphs\",\"url\":\"https://www.semanticscholar.org/paper/3a7011346ce939e3251915e92ae2f252e4c7f777\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICCVW.2017.34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48cfb97dbbc324d9f98effa5a7e07665f62080c3\",\"title\":\"Going Deeper: Autonomous Steering with Neural Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/48cfb97dbbc324d9f98effa5a7e07665f62080c3\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50141014\",\"name\":\"Xinzhi Wang\"},{\"authorId\":\"2727339\",\"name\":\"Shengcheng Yuan\"},{\"authorId\":\"49461512\",\"name\":\"Hui Zhang\"},{\"authorId\":\"48575708\",\"name\":\"M. Lewis\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":\"10.1109/RO-MAN46459.2019.8956301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50b6f97ea0e913a4906d9f154916b76191ac6585\",\"title\":\"Verbal Explanations for Deep Reinforcement Learning Neural Networks with Attention on Extracted Features\",\"url\":\"https://www.semanticscholar.org/paper/50b6f97ea0e913a4906d9f154916b76191ac6585\",\"venue\":\"2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2019},{\"arxivId\":\"1603.07141\",\"authors\":[{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"},{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/TPAMI.2017.2721945\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"82d9b588eabeb6bf4baa945d5c71b3bf89dd1e69\",\"title\":\"BreakingNews: Article Annotation by Image and Text Processing\",\"url\":\"https://www.semanticscholar.org/paper/82d9b588eabeb6bf4baa945d5c71b3bf89dd1e69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1904.09544\",\"authors\":[{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1016/j.neucom.2018.10.059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7dfb603674cc927ba65f056a54738734cbb348b2\",\"title\":\"3G structure for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/7dfb603674cc927ba65f056a54738734cbb348b2\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1803.07729\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"22253126\",\"name\":\"Wenhan Xiong\"},{\"authorId\":\"46506498\",\"name\":\"Hongmin Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1007/978-3-030-01270-0_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"368131eaf906d7b29517066e1b2759a44c8105d4\",\"title\":\"Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/368131eaf906d7b29517066e1b2759a44c8105d4\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41048842\",\"name\":\"Tonmoay Deb\"},{\"authorId\":\"152359104\",\"name\":\"M. Ali\"},{\"authorId\":\"152398205\",\"name\":\"S. Bhowmik\"},{\"authorId\":\"1972671\",\"name\":\"A. Firoze\"},{\"authorId\":\"152242250\",\"name\":\"Syed Shahir Ahmed\"},{\"authorId\":\"1395633906\",\"name\":\"Muhammad Abeer Tahmeed\"},{\"authorId\":\"145057622\",\"name\":\"N. Rahman\"},{\"authorId\":\"1732925\",\"name\":\"Rashedur M. Rahman\"}],\"doi\":\"10.3233/JIFS-179351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40ba4d6ebb66673bea62b1889f6fcde139f4b816\",\"title\":\"Oboyob: A sequential-semantic Bengali image captioning engine\",\"url\":\"https://www.semanticscholar.org/paper/40ba4d6ebb66673bea62b1889f6fcde139f4b816\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1703.07022\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"1682058\",\"name\":\"H. Zhang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428818a9edfb547431be6d7ec165c6af576c83d5\",\"title\":\"Recurrent Topic-Transition GAN for Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/428818a9edfb547431be6d7ec165c6af576c83d5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492994\",\"name\":\"Mert Kilickaya\"},{\"authorId\":\"2376985\",\"name\":\"Burak Kerim Akkus\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"2011587\",\"name\":\"Nazli Ikizler-Cinbis\"}],\"doi\":\"10.1049/iet-cvi.2016.0286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c8cf97f00cd8b4303eccc4134fa79b15cc3d564\",\"title\":\"Data-driven image captioning via salient region discovery\",\"url\":\"https://www.semanticscholar.org/paper/3c8cf97f00cd8b4303eccc4134fa79b15cc3d564\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053897\",\"name\":\"Jes\\u00fas Calvillo\"},{\"authorId\":\"1823416\",\"name\":\"M. Crocker\"}],\"doi\":\"10.18653/v1/W18-2803\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5de2d97203a41782351d7561a0d66c0e38a0768c\",\"title\":\"Language Production Dynamics with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5de2d97203a41782351d7561a0d66c0e38a0768c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.00228\",\"authors\":[{\"authorId\":\"143827145\",\"name\":\"Daouda Sow\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"51910760\",\"name\":\"Mouhamed Niasse\"},{\"authorId\":\"46579572\",\"name\":\"T. Wan\"}],\"doi\":\"10.1109/ICASSP.2019.8682505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"title\":\"A Sequential Guiding Network with Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144128023\",\"name\":\"Youcai Zhang\"},{\"authorId\":\"47470404\",\"name\":\"Jiayan Cao\"},{\"authorId\":null,\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1109/ACCESS.2018.2881997\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"152bb56b4d7f78fefd4e20c50c5aedc48a5fc78b\",\"title\":\"Learning Cross-Modal Aligned Representation With Graph Embedding\",\"url\":\"https://www.semanticscholar.org/paper/152bb56b4d7f78fefd4e20c50c5aedc48a5fc78b\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"159d16cdc48135632c2d5790e5baaf8d0631f510\",\"title\":\"StructCap: Structured Semantic Embedding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/159d16cdc48135632c2d5790e5baaf8d0631f510\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"}],\"doi\":\"10.24963/ijcai.2017/737\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27f1fd71538ba420c63aa4c74704718a0633b22a\",\"title\":\"Multimodal News Article Analysis\",\"url\":\"https://www.semanticscholar.org/paper/27f1fd71538ba420c63aa4c74704718a0633b22a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2561937\",\"name\":\"S. Wang\"},{\"authorId\":\"1684800\",\"name\":\"J. Chen\"},{\"authorId\":\"47227012\",\"name\":\"Guangyao Wang\"}],\"doi\":\"10.1007/978-3-030-02698-1_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebcaf8fbe0c51e2ce16055210b736fd8ec7e5512\",\"title\":\"Intensive Positioning Network for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ebcaf8fbe0c51e2ce16055210b736fd8ec7e5512\",\"venue\":\"IScIDE\",\"year\":2018},{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49605790\",\"name\":\"Junyi Wang\"},{\"authorId\":\"145513489\",\"name\":\"Xinyu Su\"}],\"doi\":\"10.1109/ICCIS49662.2019.00022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f60d6c43ebe1d45ff4a30224811adf56072a9116\",\"title\":\"Human Motion Modeling Based on Single Action Context\",\"url\":\"https://www.semanticscholar.org/paper/f60d6c43ebe1d45ff4a30224811adf56072a9116\",\"venue\":\"2019 4th International Conference on Communication and Information Systems (ICCIS)\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04349\",\"authors\":[{\"authorId\":\"2007739187\",\"name\":\"Hieu Trong Phung\"},{\"authorId\":\"39722350\",\"name\":\"A. Vu\"},{\"authorId\":\"49035142\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2007743298\",\"name\":\"Lam Thanh Do\"},{\"authorId\":\"2007740386\",\"name\":\"Giang Nam Ngo\"},{\"authorId\":\"34505180\",\"name\":\"T. T. Tran\"},{\"authorId\":\"2007738281\",\"name\":\"N. C. L. P. Vietnam\"},{\"authorId\":\"89934810\",\"name\":\"Hanoi\"},{\"authorId\":\"2007739185\",\"name\":\"Vietnam. Hanoi University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"67001972\",\"name\":\"H\\u00e0 N\\u1ed9i\"},{\"authorId\":\"4601368\",\"name\":\"V. Nam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7fa8e15dcab4be4fecdaa6669186162037c8f87\",\"title\":\"MAGNeto: An Efficient Deep Learning Method for the Extractive Tags Summarization Problem\",\"url\":\"https://www.semanticscholar.org/paper/c7fa8e15dcab4be4fecdaa6669186162037c8f87\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1607.08584\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-319-46493-0_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18994755100686833b92c34af8ec1b35934e23d6\",\"title\":\"Connectionist Temporal Modeling for Weakly Supervised Action Labeling\",\"url\":\"https://www.semanticscholar.org/paper/18994755100686833b92c34af8ec1b35934e23d6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543226\",\"name\":\"Xiaoxiao Liu\"},{\"authorId\":\"40096492\",\"name\":\"Q. Xu\"},{\"authorId\":null,\"name\":\"Ning Wang\"}],\"doi\":\"10.1007/s00371-018-1566-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f79c03f977d1c9acb71d87301272682422b0b14f\",\"title\":\"A survey on deep neural network-based image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79c03f977d1c9acb71d87301272682422b0b14f\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37824829\",\"name\":\"M. Cogswell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d8eef8f8d6cd8436c55018e6ca5c5907b31ac19\",\"title\":\"Understanding Representations and Reducing their Redundancy in Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d8eef8f8d6cd8436c55018e6ca5c5907b31ac19\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1808.01571\",\"authors\":[{\"authorId\":\"1679279\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"2371221\",\"name\":\"Y. Shen\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01270-0_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a808a17f5c86413bd552a324ee6ba180a12f46d\",\"title\":\"Improving Deep Visual Representation for Person Re-identification by Global and Local Image-language Association\",\"url\":\"https://www.semanticscholar.org/paper/0a808a17f5c86413bd552a324ee6ba180a12f46d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.00490\",\"authors\":[{\"authorId\":\"2588567\",\"name\":\"X. Lyu\"},{\"authorId\":\"50988033\",\"name\":\"M. H\\u00fcser\"},{\"authorId\":\"34918424\",\"name\":\"Stephanie L. Hyland\"},{\"authorId\":\"30647302\",\"name\":\"G. Zerveas\"},{\"authorId\":\"2414086\",\"name\":\"G. R\\u00e4tsch\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34e97ee9d13f6ba74ff3d50377e029c0e56af63e\",\"title\":\"Improving Clinical Predictions through Unsupervised Time Series Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/34e97ee9d13f6ba74ff3d50377e029c0e56af63e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.05298\",\"authors\":[{\"authorId\":\"1726066\",\"name\":\"Ashesh Jain\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/CVPR.2016.573\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44e1ee7a63a01a76371d7070c132361a5ddd54a0\",\"title\":\"Structural-RNN: Deep Learning on Spatio-Temporal Graphs\",\"url\":\"https://www.semanticscholar.org/paper/44e1ee7a63a01a76371d7070c132361a5ddd54a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.05813\",\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1007/978-3-319-54193-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e07183a8d585a9c5860ea712095fbff6ab893103\",\"title\":\"phi-LSTM: A Phrase-Based Hierarchical LSTM Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e07183a8d585a9c5860ea712095fbff6ab893103\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47752775\",\"name\":\"Gengshi Huang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-018-9836-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1571f6a35809ee111b14ebf43859e787c782f79\",\"title\":\"c-RNN: A Fine-Grained Language Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c1571f6a35809ee111b14ebf43859e787c782f79\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":\"1904.00766\",\"authors\":[{\"authorId\":\"90639891\",\"name\":\"Hassan Maleki Galandouz\"},{\"authorId\":\"2734293\",\"name\":\"Mohsen Ebrahimi Moghaddam\"},{\"authorId\":\"2567327\",\"name\":\"Mehrnoush Shamsfard\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1717cd0899bda3166687281e6ed8b99ca285a311\",\"title\":\"A Weighted Multi-Criteria Decision Making Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1717cd0899bda3166687281e6ed8b99ca285a311\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1506.04089\",\"authors\":[{\"authorId\":\"33344744\",\"name\":\"Hongyuan Mei\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80f15048f9774191c3ae2ab8950b6d49f2d05295\",\"title\":\"Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/80f15048f9774191c3ae2ab8950b6d49f2d05295\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1707.08364\",\"authors\":[{\"authorId\":\"40028657\",\"name\":\"Ali Sharifi Boroujerdi\"},{\"authorId\":\"152839172\",\"name\":\"M. Khanian\"},{\"authorId\":\"8778956\",\"name\":\"M. Breu\\u00df\"}],\"doi\":\"10.1109/SITIS.2017.27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cafa1f108063ea6ab11c587ba74f91f13d2ba50\",\"title\":\"Deep Interactive Region Segmentation and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8cafa1f108063ea6ab11c587ba74f91f13d2ba50\",\"venue\":\"2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)\",\"year\":2017},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/2964284.2967242\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90c4a6c6f790dbcef9a29c9a755458be09e319b6\",\"title\":\"Attention-based LSTM with Semantic Consistency for Videos Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90c4a6c6f790dbcef9a29c9a755458be09e319b6\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38547813\",\"name\":\"A. Yilmaz\"}],\"doi\":\"10.38016/jista.674910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"715a19f21cd11fca61c6a1617d8ef4f397670688\",\"title\":\"Assessment of Mutation Susceptibility in DNA Sequences with Word Vectors\",\"url\":\"https://www.semanticscholar.org/paper/715a19f21cd11fca61c6a1617d8ef4f397670688\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"145081300\",\"name\":\"L. Zhu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e7696554d6881cd12ad2d0063b9663d566e13b6\",\"title\":\"Web-Based Semantic Fragment Discovery for On-Line Lingual-Visual Similarity\",\"url\":\"https://www.semanticscholar.org/paper/3e7696554d6881cd12ad2d0063b9663d566e13b6\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1109/CVPRW.2018.00260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bd5fceb1f885f690f63a58c289607c85069be3d\",\"title\":\"Image Caption Generation with Hierarchical Contextual Visual Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bd5fceb1f885f690f63a58c289607c85069be3d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1808.09648\",\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"title\":\"From VQA to Multimodal CQA: Adapting Visual QA Models for Community QA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1776014\",\"name\":\"Ce Zhang\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"131125a5aadb48ec3eceb404cedbff713c401feb\",\"title\":\"Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries\",\"url\":\"https://www.semanticscholar.org/paper/131125a5aadb48ec3eceb404cedbff713c401feb\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738471\",\"name\":\"Chenyang Zhang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1007/978-3-319-48881-3_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2cda0dbb8b2e83ce3e70d818f78d2add803c661\",\"title\":\"Automatic Video Captioning via Multi-channel Sequential Encoding\",\"url\":\"https://www.semanticscholar.org/paper/d2cda0dbb8b2e83ce3e70d818f78d2add803c661\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34751361\",\"name\":\"Arjun Sharma\"},{\"authorId\":\"47606073\",\"name\":\"A. Biswas\"},{\"authorId\":\"144883800\",\"name\":\"A. Gandhi\"},{\"authorId\":\"145844088\",\"name\":\"Sonal Patil\"},{\"authorId\":\"2116262\",\"name\":\"O. Deshmukh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dac50ff2168c1c5228be9ad0d854bfaf13a5388\",\"title\":\"LIVELINET: A Multimodal Deep Recurrent Neural Network to Predict Liveliness in Educational Videos\",\"url\":\"https://www.semanticscholar.org/paper/3dac50ff2168c1c5228be9ad0d854bfaf13a5388\",\"venue\":\"EDM\",\"year\":2016},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66230036\",\"name\":\"L. Sun\"},{\"authorId\":\"49337262\",\"name\":\"Weipeng Wang\"},{\"authorId\":\"39682947\",\"name\":\"Jiyun Li\"},{\"authorId\":\"13387006\",\"name\":\"Jingsheng Lin\"}],\"doi\":\"10.1007/978-3-030-26763-6_66\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a7983742d4e9bb354217c42b7aa27f45518916b\",\"title\":\"Study on Medical Image Report Generation Based on Improved Encoding-Decoding Method\",\"url\":\"https://www.semanticscholar.org/paper/4a7983742d4e9bb354217c42b7aa27f45518916b\",\"venue\":\"ICIC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9260404\",\"name\":\"Xiaotong Du\"},{\"authorId\":\"46685438\",\"name\":\"J. Yuan\"},{\"authorId\":\"1840183\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-00021-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"544ccc01b63be4a68fb3f2c318ee14b5fc036c37\",\"title\":\"Attention-Based Bidirectional Recurrent Neural Networks for Description Generation of Videos\",\"url\":\"https://www.semanticscholar.org/paper/544ccc01b63be4a68fb3f2c318ee14b5fc036c37\",\"venue\":\"ICCCS\",\"year\":2018},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/CVPR.2017.658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab6480a63ac304eef220dad024106e07f21a3a35\",\"title\":\"Multi-attention Network for One Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/ab6480a63ac304eef220dad024106e07f21a3a35\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.04631\",\"authors\":[{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"83672162\",\"name\":\"Zi Huang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/2964284.2967258\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b193b01b4d15959ac85c3bd9d98af1f82159bd1f\",\"title\":\"Bidirectional Long-Short Term Memory for Video Description\",\"url\":\"https://www.semanticscholar.org/paper/b193b01b4d15959ac85c3bd9d98af1f82159bd1f\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1706.00999\",\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"19204942\",\"name\":\"Anderson Mattjie\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1016/j.patrec.2017.11.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3053db1016d039757d072f1ae85735d8a21478f\",\"title\":\"Order embeddings and character-level convolutions for multimodal alignment\",\"url\":\"https://www.semanticscholar.org/paper/a3053db1016d039757d072f1ae85735d8a21478f\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1708.01988\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47718789\",\"name\":\"Wei Yang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f222282574666658dc0408176805cbe21348477d\",\"title\":\"Identity-Aware Textual-Visual Matching with Latent Co-attention\",\"url\":\"https://www.semanticscholar.org/paper/f222282574666658dc0408176805cbe21348477d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.08486\",\"authors\":[{\"authorId\":\"1797022\",\"name\":\"Hoo-Chang Shin\"},{\"authorId\":\"1742509\",\"name\":\"Kirk Roberts\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"},{\"authorId\":\"150167064\",\"name\":\"Jianhua Yao\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2016.274\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"0460d3497490fa8332c5ff2ecdab88fb7dff4755\",\"title\":\"Learning to Read Chest X-Rays: Recurrent Neural Cascade Model for Automated Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/0460d3497490fa8332c5ff2ecdab88fb7dff4755\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"}],\"doi\":\"10.4233/UUID:FFF15717-71EC-402D-96E6-773884659F2C\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c90362daffb92ca848450ca33fe2c2d3f3665e2a\",\"title\":\"Models for supervised learning in sequence data\",\"url\":\"https://www.semanticscholar.org/paper/c90362daffb92ca848450ca33fe2c2d3f3665e2a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145037543\",\"name\":\"Q. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"974cadd15684c96618d04f845794cec5568a86a6\",\"title\":\"Greedy Inference Algorithms for Structured and Neural Models\",\"url\":\"https://www.semanticscholar.org/paper/974cadd15684c96618d04f845794cec5568a86a6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.02648\",\"authors\":[{\"authorId\":\"8442412\",\"name\":\"Xueya Zhang\"},{\"authorId\":\"50728655\",\"name\":\"Tong Zhang\"},{\"authorId\":\"49783660\",\"name\":\"X. Hong\"},{\"authorId\":\"1830568950\",\"name\":\"Zhen Cui\"},{\"authorId\":\"72086292\",\"name\":\"Jian Yang\"}],\"doi\":\"10.1007/978-3-030-58595-2_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc97c0e2e2645a9f633aaf6b93232c1ad605498a\",\"title\":\"Graph Wasserstein Correlation Analysis for Movie Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/cc97c0e2e2645a9f633aaf6b93232c1ad605498a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30209846\",\"name\":\"Lifei Han\"},{\"authorId\":\"2258415\",\"name\":\"G. Gu\"}],\"doi\":\"10.1007/978-981-10-7305-2_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c972c53eff61dc2b5a006a24cf13004a42c9c64\",\"title\":\"Key Words Extraction and Semantic-Based Image Retrieval on RNNs\",\"url\":\"https://www.semanticscholar.org/paper/0c972c53eff61dc2b5a006a24cf13004a42c9c64\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1911.09345\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62fadf3cd3ba64cd148600f2582e2cfa6859fad7\",\"title\":\"Empirical Autopsy of Deep Video Captioning Frameworks\",\"url\":\"https://www.semanticscholar.org/paper/62fadf3cd3ba64cd148600f2582e2cfa6859fad7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74437294\",\"name\":\"Sk. Arif Ahmed\"},{\"authorId\":\"3320759\",\"name\":\"D. P. Dogra\"},{\"authorId\":\"32614479\",\"name\":\"S. Kar\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1007/978-981-10-7590-2_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"522b13ea02d6d62e54180bd13595eb0e40333d48\",\"title\":\"Natural Language Description of Surveillance Events\",\"url\":\"https://www.semanticscholar.org/paper/522b13ea02d6d62e54180bd13595eb0e40333d48\",\"venue\":\"ICITAM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41134094\",\"name\":\"V. Batra\"},{\"authorId\":\"1704133\",\"name\":\"Yulan He\"},{\"authorId\":\"1737941\",\"name\":\"George Vogiatzis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7395112e0b27733ed4fe2bcdb04252efc8d5dfdf\",\"title\":\"Neural Caption Generation for News Images\",\"url\":\"https://www.semanticscholar.org/paper/7395112e0b27733ed4fe2bcdb04252efc8d5dfdf\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48754879\",\"name\":\"F. Zeng\"},{\"authorId\":null,\"name\":\"Chen Wang\"},{\"authorId\":\"5136757\",\"name\":\"S. Ge\"}],\"doi\":\"10.1109/ACCESS.2020.3011438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d17362c79ff42760c70235fb377923f0caad1f3a\",\"title\":\"A Survey on Visual Navigation for Artificial Agents With Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d17362c79ff42760c70235fb377923f0caad1f3a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3071906\",\"name\":\"Anna Fariha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"001dc49f7f3348841b4086f966bfe4e9dfadf03e\",\"title\":\"Automatic image captioning using multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/001dc49f7f3348841b4086f966bfe4e9dfadf03e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":\"10.1145/3357384.3358000\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"title\":\"Adapting Visual Question Answering Models for Enhancing Multimodal Community Q&A Platforms\",\"url\":\"https://www.semanticscholar.org/paper/6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.10092\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"title\":\"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1512.00570\",\"authors\":[{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1007/978-3-319-46493-0_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0363a3ebda56d91d704d5ff5458a527775b609\",\"title\":\"Attribute2Image: Conditional Image Generation from Visual Attributes\",\"url\":\"https://www.semanticscholar.org/paper/2d0363a3ebda56d91d704d5ff5458a527775b609\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"39943835\",\"name\":\"Gui-Song Xia\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"2872774\",\"name\":\"W. Dong\"}],\"doi\":\"10.1016/J.PATREC.2017.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390d0bb977b7473b8b76d045875c767d743de943\",\"title\":\"Image Caption Generation with Part of Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/390d0bb977b7473b8b76d045875c767d743de943\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393199\",\"name\":\"Jiren Jin\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a7f383053ef04e8262d5c03388109d1c7ae9f9c\",\"title\":\"Annotation Length Matters : Recurrent Image Annotator for Arbitrary Length Image Tagging\",\"url\":\"https://www.semanticscholar.org/paper/6a7f383053ef04e8262d5c03388109d1c7ae9f9c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35347896\",\"name\":\"Y. Qian\"},{\"authorId\":\"32811782\",\"name\":\"Ke Chen\"},{\"authorId\":\"2596488\",\"name\":\"Jarno Nikkanen\"},{\"authorId\":\"145196370\",\"name\":\"J. K\\u00e4m\\u00e4r\\u00e4inen\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47407c089b1c8af315b0fd6e565c4fdbc045474c\",\"title\":\"Dichromatic Gray Pixel for Camera-agnostic Color Constancy\",\"url\":\"https://www.semanticscholar.org/paper/47407c089b1c8af315b0fd6e565c4fdbc045474c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1016/j.neucom.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"title\":\"Phrase-based image caption generator with hierarchical LSTM network\",\"url\":\"https://www.semanticscholar.org/paper/760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1906.00283\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"122175026\",\"name\":\"P\\u00e9ter Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"title\":\"Learning to Generate Grounded Image Captions without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35181104\",\"name\":\"T. N. Tran\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3ff0b428fa2671b6359e9797819b98cf55076cc\",\"title\":\"Robust and comprehensive joint image-text representations\",\"url\":\"https://www.semanticscholar.org/paper/b3ff0b428fa2671b6359e9797819b98cf55076cc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1510.01431\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"title\":\"SentiCap: Generating Image Descriptions with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":\"10.1007/978-3-030-58523-5_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f692df9ca116884860d580902fa642370bd1be5d\",\"title\":\"Learning to Generate Grounded Visual Captions Without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/f692df9ca116884860d580902fa642370bd1be5d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843683\",\"name\":\"Davide Conigliaro\"},{\"authorId\":\"3218233\",\"name\":\"R. Ferrario\"},{\"authorId\":\"1931593\",\"name\":\"C. Hudelot\"},{\"authorId\":\"3240526\",\"name\":\"Daniele Porello\"}],\"doi\":\"10.1016/B978-0-12-809276-7.00016-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5836d2d38e6fed4dff4fd6998feb936fe805291\",\"title\":\"Integrating Computer Vision Algorithms and Ontologies for Spectator Crowd Behavior Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c5836d2d38e6fed4dff4fd6998feb936fe805291\",\"venue\":\"Group and Crowd Behavior for Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.11536\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1007/978-3-030-20876-9_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"695420559bd694f0fe084b64556e8241c3d02868\",\"title\":\"Automatic Graphics Program Generation using Attention-Based Hierarchical Decoder\",\"url\":\"https://www.semanticscholar.org/paper/695420559bd694f0fe084b64556e8241c3d02868\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1708.02043\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.18653/v1/W17-3506\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"title\":\"What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?\",\"url\":\"https://www.semanticscholar.org/paper/3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1415134980\",\"name\":\"Genc Hoxha\"},{\"authorId\":\"1774633\",\"name\":\"F. Melgani\"},{\"authorId\":\"144375744\",\"name\":\"B. Demir\"}],\"doi\":\"10.1109/JSTARS.2020.3013818\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47f78f6d4d60f45b471fa625416b634f9e501efd\",\"title\":\"Toward Remote Sensing Image Retrieval Under a Deep Image Captioning Perspective\",\"url\":\"https://www.semanticscholar.org/paper/47f78f6d4d60f45b471fa625416b634f9e501efd\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32482521\",\"name\":\"P. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"title\":\"Towards Interpretable Vision Systems\",\"url\":\"https://www.semanticscholar.org/paper/00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958420\",\"name\":\"Tianyi Wang\"},{\"authorId\":\"47539594\",\"name\":\"Jiang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1007/978-3-030-00776-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c50c91875767ec7c6391d99d30838d90275a0f1b\",\"title\":\"Collaborative Detection and Caption Network\",\"url\":\"https://www.semanticscholar.org/paper/c50c91875767ec7c6391d99d30838d90275a0f1b\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40313071\",\"name\":\"Nermin Samet\"},{\"authorId\":\"2060717\",\"name\":\"Samet Hicsonmez\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"2132749\",\"name\":\"Emre Akbas\"}],\"doi\":\"10.1109/SIU.2017.7960638\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0d70587340adc412c6e2afd71012d563c1e724\",\"title\":\"Could we create a training set for image captioning using automatic translation?\",\"url\":\"https://www.semanticscholar.org/paper/1c0d70587340adc412c6e2afd71012d563c1e724\",\"venue\":\"2017 25th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2017},{\"arxivId\":\"1810.05786\",\"authors\":[{\"authorId\":\"30572523\",\"name\":\"H. Wang\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"},{\"authorId\":\"80158488\",\"name\":\"SingBing Kang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56bb6fbf51905151f3147d674fea45219e6a6f35\",\"title\":\"Learning to Globally Edit Images with Textual Description\",\"url\":\"https://www.semanticscholar.org/paper/56bb6fbf51905151f3147d674fea45219e6a6f35\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33265017\",\"name\":\"Akihito Seki\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.5244/C.30.23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ecc65267d765e4b3a089a27f5ebb65de672164c\",\"title\":\"Patch Based Confidence Prediction for Dense Disparity Map\",\"url\":\"https://www.semanticscholar.org/paper/4ecc65267d765e4b3a089a27f5ebb65de672164c\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1706.10031\",\"authors\":[{\"authorId\":\"2532864\",\"name\":\"Sotetsu Koyamada\"},{\"authorId\":\"144142812\",\"name\":\"Yuta Kikuchi\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"},{\"authorId\":\"35647224\",\"name\":\"Shin-ichi Maeda\"},{\"authorId\":\"145516720\",\"name\":\"Shin Ishii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"24e050ec48499e76f649e1d40c1bb09c9493d0d8\",\"title\":\"Neural Sequence Model Training via $\\\\alpha$-divergence Minimization\",\"url\":\"https://www.semanticscholar.org/paper/24e050ec48499e76f649e1d40c1bb09c9493d0d8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1612.05203\",\"authors\":[{\"authorId\":\"144150628\",\"name\":\"Kai Xu\"},{\"authorId\":\"40615963\",\"name\":\"Fengbo Ren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1384a83e557b96883a6bffdb8433517ec52d0bea\",\"title\":\"CSVideoNet: A Recurrent Convolutional Neural Network for Compressive Sensing Video Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/1384a83e557b96883a6bffdb8433517ec52d0bea\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98482977\",\"name\":\"\\u0411\\u043e\\u0440\\u0438\\u0441\\u043e\\u0432 \\u0413\\u0435\\u043e\\u0440\\u0433\\u0438\\u0439 \\u0410\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u043e\\u0432\\u0438\\u0447\"},{\"authorId\":\"97625681\",\"name\":\"\\u0422\\u0438\\u0445\\u043e\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430 \\u0422\\u0430\\u043c\\u0430\\u0440\\u0430 \\u041f\\u0435\\u0442\\u0440\\u043e\\u0432\\u043d\\u0430\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de0cec214cf34d089a9fce9015256b63534cd08\",\"title\":\"\\u0417\\u0430\\u0434\\u0430\\u0447\\u0438 \\u0438 \\u043c\\u0435\\u0442\\u043e\\u0434\\u044b \\u0440\\u0435\\u0441\\u0443\\u0440\\u0441\\u043e\\u0441\\u0431\\u0435\\u0440\\u0435\\u0433\\u0430\\u044e\\u0449\\u0435\\u0439 \\u043e\\u043f\\u0442\\u0438\\u043c\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u0432 \\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u044d\\u043d\\u0435\\u0440\\u0433\\u0435\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0435\",\"url\":\"https://www.semanticscholar.org/paper/0de0cec214cf34d089a9fce9015256b63534cd08\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.07212\",\"authors\":[{\"authorId\":\"39398377\",\"name\":\"A. Haque\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"868ae15b05c015fd9fdd93a2ca00c26ca4108699\",\"title\":\"Recurrent Attention Models for Depth-Based Person Identification\",\"url\":\"https://www.semanticscholar.org/paper/868ae15b05c015fd9fdd93a2ca00c26ca4108699\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9037003\",\"name\":\"Duc-Cuong Dao\"},{\"authorId\":\"40429856\",\"name\":\"Thi-Oanh Nguyen\"},{\"authorId\":\"1735321\",\"name\":\"S. Bressan\"}],\"doi\":\"10.1145/3007120.3007136\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e559630c5710afb0d5eb8f95141e451393bbcbd9\",\"title\":\"Factors Influencing The Performance of Image Captioning Model: An Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/e559630c5710afb0d5eb8f95141e451393bbcbd9\",\"venue\":\"MoMM\",\"year\":2016},{\"arxivId\":\"1605.01379\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-319-46475-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94217efec8773ef947df2772f92df8c5726f855\",\"title\":\"Leveraging Visual Question Answering for Image-Caption Ranking\",\"url\":\"https://www.semanticscholar.org/paper/c94217efec8773ef947df2772f92df8c5726f855\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37441231\",\"name\":\"N. Siegel\"},{\"authorId\":\"2803574\",\"name\":\"Zachary Horvitz\"},{\"authorId\":\"145872888\",\"name\":\"Roie Levin\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1007/978-3-319-46478-7_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d0a05fa74dd5ed8aed59bd7a92420e034d64cf1\",\"title\":\"FigureSeer: Parsing Result-Figures in Research Papers\",\"url\":\"https://www.semanticscholar.org/paper/0d0a05fa74dd5ed8aed59bd7a92420e034d64cf1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3132847.3132922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"title\":\"Movie Fill in the Blank with Adaptive Temporal Attention and Description Update\",\"url\":\"https://www.semanticscholar.org/paper/3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1904.12004\",\"authors\":[{\"authorId\":\"98243944\",\"name\":\"Chenglong Wang\"},{\"authorId\":\"3407947\",\"name\":\"R. Bunel\"},{\"authorId\":\"1729912\",\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":\"10.1109/CVPR.2019.01254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59b439bde73d80dccf367d414e209d08d312c059\",\"title\":\"Knowing When to Stop: Evaluation and Verification of Conformity to Output-Size Specifications\",\"url\":\"https://www.semanticscholar.org/paper/59b439bde73d80dccf367d414e209d08d312c059\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492115154\",\"name\":\"Jinquan Li\"},{\"authorId\":\"1490746211\",\"name\":\"Haiming Dong\"}],\"doi\":\"10.1117/12.2557941\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bccbae78a996dec639b873d35e77ce0017c4f81\",\"title\":\"A generative-predictive framework used for video conversion\",\"url\":\"https://www.semanticscholar.org/paper/6bccbae78a996dec639b873d35e77ce0017c4f81\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"}],\"doi\":\"10.5075/EPFL-THESIS-7148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2899d6c850e9d57b80c471f8a06f669afa1812\",\"title\":\"Word Embeddings for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/de2899d6c850e9d57b80c471f8a06f669afa1812\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"}],\"doi\":\"10.1007/978-981-10-7299-4_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"title\":\"Automatic Image Description Generation with Emotional Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458333\",\"name\":\"Adel Saleh\"},{\"authorId\":\"46717559\",\"name\":\"Mohamed Abdel-Nasser\"},{\"authorId\":\"2372326\",\"name\":\"Md. Mostafa Kamal Sarker\"},{\"authorId\":\"144687691\",\"name\":\"V. K. Singh\"},{\"authorId\":\"48067440\",\"name\":\"S. Abdulwahab\"},{\"authorId\":\"34379031\",\"name\":\"N. Saffari\"},{\"authorId\":\"145356986\",\"name\":\"M. A. Garcia\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1109/ITCE.2018.8316596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfbfdcf64b6b8b91460c5567efbffa9f68592bea\",\"title\":\"Deep visual embedding for image classification\",\"url\":\"https://www.semanticscholar.org/paper/cfbfdcf64b6b8b91460c5567efbffa9f68592bea\",\"venue\":\"2018 International Conference on Innovative Trends in Computer Engineering (ITCE)\",\"year\":2018},{\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2017.767\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1901.03198\",\"authors\":[{\"authorId\":\"35347896\",\"name\":\"Y. Qian\"},{\"authorId\":\"2596488\",\"name\":\"Jarno Nikkanen\"},{\"authorId\":\"145196370\",\"name\":\"J. K\\u00e4m\\u00e4r\\u00e4inen\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"}],\"doi\":\"10.1109/CVPR.2019.00825\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6aabad83dff79b05e267659948f8e8d1695c0e2\",\"title\":\"On Finding Gray Pixels\",\"url\":\"https://www.semanticscholar.org/paper/b6aabad83dff79b05e267659948f8e8d1695c0e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10798523\",\"name\":\"C. C. Park\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c72ab3484bea5aa8abbd041d31f6b17c17513de\",\"title\":\"Expressing an Image Stream with a Sequence of Natural Sentences\",\"url\":\"https://www.semanticscholar.org/paper/1c72ab3484bea5aa8abbd041d31f6b17c17513de\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1908.02923\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":\"10.1613/jair.1.12025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"title\":\"Image Captioning using Facial Expression and Attention\",\"url\":\"https://www.semanticscholar.org/paper/29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1007/978-3-030-11479-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"title\":\"Deep Learning for Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"venue\":\"Handbook of Deep Learning Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"38218192\",\"name\":\"X. Wang\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02844808a10aa27fad397d1941ec24f5e546ca0b\",\"title\":\"Bidirectional image-sentence retrieval by local and global deep matching\",\"url\":\"https://www.semanticscholar.org/paper/02844808a10aa27fad397d1941ec24f5e546ca0b\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1804.08473\",\"authors\":[{\"authorId\":\"143672100\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"32878737\",\"name\":\"M. Kato\"},{\"authorId\":\"1740865\",\"name\":\"M. Yoshikawa\"}],\"doi\":\"10.1145/3240508.3240587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99e56f1fd88d967aab6be2a51f3633697e2df667\",\"title\":\"Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/99e56f1fd88d967aab6be2a51f3633697e2df667\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":\"1705.01371\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/CVPR.2017.558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9405a9180139f23f4dd9d90aa4e86944b35b8c88\",\"title\":\"Weakly-Supervised Visual Grounding of Phrases with Linguistic Structures\",\"url\":\"https://www.semanticscholar.org/paper/9405a9180139f23f4dd9d90aa4e86944b35b8c88\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394741222\",\"name\":\"Yuling Gui\"},{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"97522088\",\"name\":\"Ye Zhao\"}],\"doi\":\"10.1145/3347319.3356839\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fc5e1793d9836d6c19cbd933d8b1fcc01dcc22f\",\"title\":\"Semantic Enhanced Encoder-Decoder Network (SEN) for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fc5e1793d9836d6c19cbd933d8b1fcc01dcc22f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461528\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"46458102\",\"name\":\"L. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"title\":\"CycleMatch: A cycle-consistent embedding network for image-text matching\",\"url\":\"https://www.semanticscholar.org/paper/d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"456983805a8781d6429bed1ed66dc9f3902767af\",\"title\":\"Seeing with Humans : Gaze-Assisted Neural Image\",\"url\":\"https://www.semanticscholar.org/paper/456983805a8781d6429bed1ed66dc9f3902767af\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1612.00385\",\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"2743835\",\"name\":\"D. Tax\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2017.94\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04556d5f283d7f90e24d43371d3f51faff8c0423\",\"title\":\"Temporal Attention-Gated Model for Robust Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/04556d5f283d7f90e24d43371d3f51faff8c0423\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508437\",\"name\":\"J. Moon\"},{\"authorId\":\"152840733\",\"name\":\"B. Lee\"}],\"doi\":\"10.1007/s11370-018-0257-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f41837099ab10f8490c27d278a0ee299c426e3c\",\"title\":\"Scene understanding using natural language description based on 3D semantic graph map\",\"url\":\"https://www.semanticscholar.org/paper/7f41837099ab10f8490c27d278a0ee299c426e3c\",\"venue\":\"Intell. Serv. Robotics\",\"year\":2018},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411500195\",\"name\":\"D. K. Guevara-Flores\"},{\"authorId\":\"1397808828\",\"name\":\"Fernando Perez-Tellez\"},{\"authorId\":\"3469668\",\"name\":\"D. Avenda\\u00f1o\"}],\"doi\":\"10.13053/cys-24-2-3393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2c6ba89a8bb820055319df10fcc861840a9a36b\",\"title\":\"Analysis of Automatic Annotations of Real Video Surveillance Images\",\"url\":\"https://www.semanticscholar.org/paper/b2c6ba89a8bb820055319df10fcc861840a9a36b\",\"venue\":\"Computaci\\u00f3n y Sistemas\",\"year\":2020},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"3141085\",\"name\":\"V. K\\u0131l\\u0131\\u00e7\"}],\"doi\":\"10.23919/ELECO47770.2019.8990395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c04709cafc945deaa13b6a92c092416188d8bf9\",\"title\":\"Smartphone-based Image Captioning for Visually and Hearing Impaired\",\"url\":\"https://www.semanticscholar.org/paper/2c04709cafc945deaa13b6a92c092416188d8bf9\",\"venue\":\"2019 11th International Conference on Electrical and Electronics Engineering (ELECO)\",\"year\":2019},{\"arxivId\":\"1511.06068\",\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"48496963\",\"name\":\"F. Ahmed\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a61992160c1075035f184f28c1a01414971b2b58\",\"title\":\"Reducing Overfitting in Deep Networks by Decorrelating Representations\",\"url\":\"https://www.semanticscholar.org/paper/a61992160c1075035f184f28c1a01414971b2b58\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1812.02872\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2149345\",\"name\":\"Chenxiao Guan\"},{\"authorId\":\"48616329\",\"name\":\"J. Goodman\"},{\"authorId\":\"50583301\",\"name\":\"Marc Moore\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5328a7024f820fafdab4165777807c2ecb855fe4\",\"title\":\"An Attempt towards Interpretable Audio-Visual Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5328a7024f820fafdab4165777807c2ecb855fe4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"144474380\",\"name\":\"X. Tang\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"},{\"authorId\":\"33161908\",\"name\":\"C. Li\"}],\"doi\":\"10.3390/rs11060612\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"944e93e74379afedced307ca30fc6d31365dc96e\",\"title\":\"Description Generation for Remote Sensing Images Using Attribute Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/944e93e74379afedced307ca30fc6d31365dc96e\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108449655\",\"name\":\"Chetan Amritkar\"},{\"authorId\":\"9431671\",\"name\":\"Vaishali S. Jabade\"}],\"doi\":\"10.1109/ICCUBEA.2018.8697360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01698c61fa4786c6c514fe252d5049b01cd010d\",\"title\":\"Image Caption Generation Using Deep Learning Technique\",\"url\":\"https://www.semanticscholar.org/paper/f01698c61fa4786c6c514fe252d5049b01cd010d\",\"venue\":\"2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33344744\",\"name\":\"Hongyuan Mei\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"487e32a081fd40ea93b28f2acfdaa18b163c0cf7\",\"title\":\"LSTM-RNN MULTI-LEVEL ALIGNER DECODERENCODER Aligner LSTM-RNN LSTM-RNN LSTM-RNN go forward two segments to the end of the hall E World State Action Sequence Instruction\",\"url\":\"https://www.semanticscholar.org/paper/487e32a081fd40ea93b28f2acfdaa18b163c0cf7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.5244/C.30.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02d6fb270c82c390476faffc6015b3116ddbb60c\",\"title\":\"Image Captioning with Sentiment Terms via Weakly-Supervised Sentiment Dataset\",\"url\":\"https://www.semanticscholar.org/paper/02d6fb270c82c390476faffc6015b3116ddbb60c\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651496\",\"name\":\"Chengxi Li\"},{\"authorId\":\"153194886\",\"name\":\"Sagar Gandhi\"},{\"authorId\":\"35066258\",\"name\":\"B. Harrison\"}],\"doi\":\"10.1145/3337722.3341870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79b31c51375fdfe87d854d238d2bfb4696fd71cf\",\"title\":\"End-to-end let's play commentary generation using multi-modal video representations\",\"url\":\"https://www.semanticscholar.org/paper/79b31c51375fdfe87d854d238d2bfb4696fd71cf\",\"venue\":\"FDG\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1808.03986\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"49596229\",\"name\":\"S. Kumar\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.18653/v1/D18-1434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"title\":\"Multimodal Differential Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1707.06320\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"2480903\",\"name\":\"Alexis Conneau\"},{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"1729762\",\"name\":\"M. Nickel\"}],\"doi\":\"10.18653/v1/N18-1038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f269968ee8192f3cf663efd6d1dcdff22aabdefe\",\"title\":\"Learning Visually Grounded Sentence Representations\",\"url\":\"https://www.semanticscholar.org/paper/f269968ee8192f3cf663efd6d1dcdff22aabdefe\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.09038\",\"authors\":[{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"title\":\"Professor Forcing: A New Algorithm for Training Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03671\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"123b9de009865472c660192f8072493a48352dc2\",\"title\":\"Phrase-based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123b9de009865472c660192f8072493a48352dc2\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.00790\",\"authors\":[{\"authorId\":\"47075011\",\"name\":\"Cheng Wang\"},{\"authorId\":\"1688587\",\"name\":\"Haojin Yang\"},{\"authorId\":\"28918194\",\"name\":\"C. Bartz\"},{\"authorId\":\"1708312\",\"name\":\"C. Meinel\"}],\"doi\":\"10.1145/2964284.2964299\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"26e425781e4090abfae65b5d68eac72282dd2e31\",\"title\":\"Image Captioning with Deep Bidirectional LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/26e425781e4090abfae65b5d68eac72282dd2e31\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"A. Apicella\"},{\"authorId\":\"13851143\",\"name\":\"A. Corazza\"},{\"authorId\":\"34675913\",\"name\":\"F. Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.3390/info9100252\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e08dcf5e8fb1e5a59408c267af64145ce2e9daeb\",\"title\":\"Integration of Context Information through Probabilistic Ontological Knowledge into Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/e08dcf5e8fb1e5a59408c267af64145ce2e9daeb\",\"venue\":\"Inf.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"145093507\",\"name\":\"Yao Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3300939\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"70e80065c4db089c3792245535ecacdca3770577\",\"title\":\"Modality-Invariant Image-Text Embedding for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/70e80065c4db089c3792245535ecacdca3770577\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3336495\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"715fe60a8615d283c70d12db13857d8948baebca\",\"title\":\"Pseudo-3D Attention Transfer Network with Content-aware Strategy for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/715fe60a8615d283c70d12db13857d8948baebca\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121569773\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"48586318\",\"name\":\"Chengrong Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"151495118\",\"name\":\"Cong Bai\"},{\"authorId\":\"48002027\",\"name\":\"X. Xue\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d54af916d7b813e798fa27327bfb0a909d816fd7\",\"title\":\"Embodied One-Shot Video Recognition: Learning from Actions of a Virtual Embodied Agent\",\"url\":\"https://www.semanticscholar.org/paper/d54af916d7b813e798fa27327bfb0a909d816fd7\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.03622\",\"authors\":[{\"authorId\":\"36538344\",\"name\":\"James O'Neill\"},{\"authorId\":\"2720656\",\"name\":\"Danushka Bollegala\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e382d10993daae43659a06c99b7ae8f3b00ad75\",\"title\":\"Transfer Reward Learning for Policy Gradient-Based Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/8e382d10993daae43659a06c99b7ae8f3b00ad75\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47653951\",\"name\":\"Gayatri Nair\"},{\"authorId\":\"1642218980\",\"name\":\"Karishma Elsa Johns\"},{\"authorId\":\"147995455\",\"name\":\"S. A\"},{\"authorId\":\"1945946\",\"name\":\"A. John\"}],\"doi\":\"10.1109/ICCS45141.2019.9065654\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d99c5a0fc2c24b2911c44a17a03a3a9f9f99cf0\",\"title\":\"An overview of machine learning techniques applicable for summarisation of characters in videos\",\"url\":\"https://www.semanticscholar.org/paper/1d99c5a0fc2c24b2911c44a17a03a3a9f9f99cf0\",\"venue\":\"2019 International Conference on Intelligent Computing and Control Systems (ICCS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367790\",\"name\":\"Seong Jae Hwang\"},{\"authorId\":\"3023295\",\"name\":\"S. Ravi\"},{\"authorId\":\"46641029\",\"name\":\"Zirui Tao\"},{\"authorId\":\"40147719\",\"name\":\"H. Kim\"},{\"authorId\":\"31604982\",\"name\":\"Maxwell D. Collins\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2018.00112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b6d41795de1fd9a0da4227c83dc4dd038a229ec\",\"title\":\"Tensorize, Factorize and Regularize: Robust Visual Relationship Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b6d41795de1fd9a0da4227c83dc4dd038a229ec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30771413\",\"name\":\"Brandon Birmingham\"},{\"authorId\":\"35347012\",\"name\":\"Adrian Muscat\"}],\"doi\":\"10.18653/v1/W17-2002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dab64439ffb72da80175ba98a47b6f1e0ddd21b\",\"title\":\"The Use of Object Labels and Spatial Prepositions as Keywords in a Web-Retrieval-Based Image Caption Generation System\",\"url\":\"https://www.semanticscholar.org/paper/1dab64439ffb72da80175ba98a47b6f1e0ddd21b\",\"venue\":\"VL@EACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"},{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aa1045859089567dd65f69499d01aaaf701da70\",\"title\":\"Visual Dialogue Needs Symmetry , Goals , and Dynamics : The Example of the MeetUp Task\",\"url\":\"https://www.semanticscholar.org/paper/2aa1045859089567dd65f69499d01aaaf701da70\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.09996\",\"authors\":[{\"authorId\":\"15035398\",\"name\":\"V. O. Yazici\"},{\"authorId\":\"1403268002\",\"name\":\"Abel Gonzalez-Garcia\"},{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"},{\"authorId\":\"2470703\",\"name\":\"Bartlomiej Twardowski\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"}],\"doi\":\"10.1109/cvpr42600.2020.01345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6b118f0fc679bcb8a670f5d31cb241cf1da7536\",\"title\":\"Orderless Recurrent Models for Multi-Label Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6b118f0fc679bcb8a670f5d31cb241cf1da7536\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1809.04835\",\"authors\":[{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"144326612\",\"name\":\"P. Li\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"2960930\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1145/3240876.3240900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dec04588b73efb1192d1778b2b818842ccd242e7\",\"title\":\"Image captioning based on deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/dec04588b73efb1192d1778b2b818842ccd242e7\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":\"1705.01359\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"13597291\",\"name\":\"Yauhen Klimovich\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/P17-1024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"title\":\"FOIL it! Find One mismatch between Image and Language caption\",\"url\":\"https://www.semanticscholar.org/paper/c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P16-1058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06d7968ced2bdeba0d7dc58fb8e12406a3ccb3c8\",\"title\":\"Easy Things First: Installments Improve Referring Expression Generation for Objects in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/06d7968ced2bdeba0d7dc58fb8e12406a3ccb3c8\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"656a59954de3c9fcf82ffcef926af6ade2f3fdb5\",\"title\":\"Convolutional Network Representation for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656a59954de3c9fcf82ffcef926af6ade2f3fdb5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1609.05281\",\"authors\":[{\"authorId\":\"144883800\",\"name\":\"A. Gandhi\"},{\"authorId\":\"34751361\",\"name\":\"Arjun Sharma\"},{\"authorId\":\"47606073\",\"name\":\"A. Biswas\"},{\"authorId\":\"2116262\",\"name\":\"O. Deshmukh\"}],\"doi\":\"10.1007/978-3-319-48881-3_58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"551fa37e8d6d03b89d195a5c00c74cc52ff1c67a\",\"title\":\"GeThR-Net: A Generalized Temporally Hybrid Recurrent Neural Network for Multimodal Information Fusion\",\"url\":\"https://www.semanticscholar.org/paper/551fa37e8d6d03b89d195a5c00c74cc52ff1c67a\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"Andrea Apicella\"},{\"authorId\":\"13851143\",\"name\":\"Anna Corazza\"},{\"authorId\":\"34675913\",\"name\":\"Francesco Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.1109/WETICE.2017.47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a6f970f6801b07d0dd12d836a49bde5b0433d69\",\"title\":\"Integrating a Priori Probabilistic Knowledge into Classification for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/5a6f970f6801b07d0dd12d836a49bde5b0433d69\",\"venue\":\"2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1712.01329\",\"authors\":[{\"authorId\":\"32652024\",\"name\":\"Mircea Mironenco\"},{\"authorId\":\"1867140\",\"name\":\"D. Kianfar\"},{\"authorId\":\"145560715\",\"name\":\"Ke Tran\"},{\"authorId\":\"1713134\",\"name\":\"E. Kanoulas\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03f98bfb129028b80ce98686c573830671ee1e3d\",\"title\":\"Examining Cooperation in Visual Dialog Models\",\"url\":\"https://www.semanticscholar.org/paper/03f98bfb129028b80ce98686c573830671ee1e3d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1910.06315\",\"authors\":[{\"authorId\":\"153636852\",\"name\":\"Soumik Ranjan Dasgupta\"},{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"title\":\"Dynamic Attention Networks for Task Oriented Grounding\",\"url\":\"https://www.semanticscholar.org/paper/361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47098628\",\"name\":\"S. Pillai\"},{\"authorId\":\"50351300\",\"name\":\"Jeremy Brown\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57c5c512bd8ad09f9eb0b5630b72746d5ffbb6e5\",\"title\":\"Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/57c5c512bd8ad09f9eb0b5630b72746d5ffbb6e5\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143966993\",\"name\":\"X. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bdbf483de5db6645106bb5a1b39b10381ccc74c\",\"title\":\"Frames in places: visual common sense knowledge in context\",\"url\":\"https://www.semanticscholar.org/paper/7bdbf483de5db6645106bb5a1b39b10381ccc74c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1609.08124\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"title\":\"Learning Language-Visual Embedding for Movie Understanding with Natural-Language\",\"url\":\"https://www.semanticscholar.org/paper/2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9377628\",\"name\":\"S. Sehgal\"},{\"authorId\":\"47231598\",\"name\":\"J. Sharma\"},{\"authorId\":\"1961030572\",\"name\":\"Natasha Chaudhary\"}],\"doi\":\"10.1109/ICRITO48877.2020.9197977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"787415b2e7d11dfc895e78221cb044085620d830\",\"title\":\"Generating Image Captions based on Deep Learning and Natural language Processing\",\"url\":\"https://www.semanticscholar.org/paper/787415b2e7d11dfc895e78221cb044085620d830\",\"venue\":\"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\"year\":2020},{\"arxivId\":\"2012.12139\",\"authors\":[{\"authorId\":\"143865282\",\"name\":\"Al Faruk\"},{\"authorId\":\"9158386\",\"name\":\"H. Faraby\"},{\"authorId\":\"2040271206\",\"name\":\"Md. Muzahidul Azad\"},{\"authorId\":\"2040242557\",\"name\":\"Md. Riduyan Fedous\"},{\"authorId\":\"1575405660\",\"name\":\"Md. Kishor Morol\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92cb0ecfb52f981e86b95d0c88c7bf49edb2cbd6\",\"title\":\"Image to Bengali Caption Generation Using Deep CNN and Bidirectional Gated Recurrent Unit\",\"url\":\"https://www.semanticscholar.org/paper/92cb0ecfb52f981e86b95d0c88c7bf49edb2cbd6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3123266.3123317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"title\":\"Multi-Networks Joint Learning for Large-Scale Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":\"1705.10762\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"33091759\",\"name\":\"Ian S. Fischer\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"226f08bb8fd049fdca2f6a8a41ffe485a0ee6ebc\",\"title\":\"Generative Models of Visually Grounded Imagination\",\"url\":\"https://www.semanticscholar.org/paper/226f08bb8fd049fdca2f6a8a41ffe485a0ee6ebc\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35181104\",\"name\":\"T. N. Tran\"},{\"authorId\":\"2138418\",\"name\":\"H. Borgne\"},{\"authorId\":\"1719698\",\"name\":\"M. Crucianu\"}],\"doi\":\"10.1109/CVPR.2016.225\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"999cd12e1347c18ea00545e9f52a287b81c8548b\",\"title\":\"Aggregating Image and Text Quantized Correlated Components\",\"url\":\"https://www.semanticscholar.org/paper/999cd12e1347c18ea00545e9f52a287b81c8548b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1016/j.jvcir.2018.12.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58323b889d916403c6674eb3112370a13bd63fe9\",\"title\":\"Scene graph captioner: Image captioning based on structural visual representation\",\"url\":\"https://www.semanticscholar.org/paper/58323b889d916403c6674eb3112370a13bd63fe9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2784591\",\"name\":\"Zetao Chen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1867220\",\"name\":\"I. Sa\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"},{\"authorId\":\"1885768\",\"name\":\"M. Chli\"}],\"doi\":\"10.1109/LRA.2018.2859916\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c452daa8766e1438835d4f664e4feef7fd8e5e01\",\"title\":\"Learning Context Flexible Attention Model for Long-Term Visual Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c452daa8766e1438835d4f664e4feef7fd8e5e01\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152347102\",\"name\":\"F. Yu\"},{\"authorId\":\"30490097\",\"name\":\"Haonan Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3343031.3350931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47e8c51d8293eb59416456179c606cb3ae08692\",\"title\":\"Instance of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/c47e8c51d8293eb59416456179c606cb3ae08692\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152969844\",\"name\":\"N. Zakharov\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"39197903\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2151203\",\"name\":\"J. Gl\\u00e4scher\"}],\"doi\":\"10.1016/J.JVCIR.2019.102574\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e0d5efef6e620050435280f8a3e2df982dce8ea\",\"title\":\"Towards controllable image descriptions with semi-supervised VAE\",\"url\":\"https://www.semanticscholar.org/paper/1e0d5efef6e620050435280f8a3e2df982dce8ea\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2010.02949\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73068d13d6e53876c374ebd4c862ec01351c9f39\",\"title\":\"Learning to Represent Image and Text with Denotation Graph\",\"url\":\"https://www.semanticscholar.org/paper/73068d13d6e53876c374ebd4c862ec01351c9f39\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1908.06306\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/ICCV.2019.00754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"title\":\"U-CAM: Visual Explanation Using Uncertainty Based Class Activation Maps\",\"url\":\"https://www.semanticscholar.org/paper/5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279549\",\"name\":\"Xiao Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"title\":\"Leveraging Multimodal Perspectives to Learn Common Sense for Vision and Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2964284.2964288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f05908d2fad82129395ab81d4337fb454748667\",\"title\":\"Robust Visual-Textual Sentiment Analysis: When Attention meets Tree-structured Recursive Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0f05908d2fad82129395ab81d4337fb454748667\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27730319\",\"name\":\"Virginia Pinto Campos\"},{\"authorId\":\"34475830\",\"name\":\"L. M. G. Goncalves\"},{\"authorId\":\"34572692\",\"name\":\"Tiago Maritan Ugulino de Ara\\u00fajo\"}],\"doi\":\"10.1109/AVSS.2017.8078530\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b8ff42141d2625fb67f031d3c5f4e55ff7c310a\",\"title\":\"Applying audio description for context understanding of surveillance videos by people with visual impairments\",\"url\":\"https://www.semanticscholar.org/paper/8b8ff42141d2625fb67f031d3c5f4e55ff7c310a\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1509.04942\",\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"title\":\"Guiding Long-Short Term Memory for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"}],\"doi\":\"10.15781/T2QR4P68H\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"title\":\"Natural Language Video Description using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35413543\",\"name\":\"Humberto S. Garcia Caballero\"},{\"authorId\":\"1768706\",\"name\":\"M. A. Westenberg\"},{\"authorId\":\"3153393\",\"name\":\"B. Gebre\"},{\"authorId\":\"143693813\",\"name\":\"J. V. Wijk\"}],\"doi\":\"10.1111/cgf.13667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b8a01e224443eccdac36768fb8ad63e1c6a4ae2\",\"title\":\"V\\u2010Awake: A Visual Analytics Approach for Correcting Sleep Predictions from Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/5b8a01e224443eccdac36768fb8ad63e1c6a4ae2\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"1902.00749\",\"authors\":[{\"authorId\":\"36904159\",\"name\":\"J. Zhu\"},{\"authorId\":\"47912692\",\"name\":\"Hua Yang\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"2918263\",\"name\":\"Minyoung Kim\"},{\"authorId\":\"144913615\",\"name\":\"W. Zhang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01228-1_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fefa8f07d998f8f4a6c85a7da781b19bf6b78d7d\",\"title\":\"Online Multi-Object Tracking with Dual Matching Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/fefa8f07d998f8f4a6c85a7da781b19bf6b78d7d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47196697\",\"name\":\"Zeyu Wang\"},{\"authorId\":\"2036152\",\"name\":\"Y. Wu\"},{\"authorId\":\"8016808\",\"name\":\"Shuhui Bu\"},{\"authorId\":\"46452797\",\"name\":\"Pengcheng Han\"},{\"authorId\":\"1724610\",\"name\":\"Guoyin Zhang\"}],\"doi\":\"10.1371/journal.pone.0195114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"479eb6579194d4d944671dfe5e90b122ca4b58fd\",\"title\":\"Structural inference embedded adversarial networks for scene parsing\",\"url\":\"https://www.semanticscholar.org/paper/479eb6579194d4d944671dfe5e90b122ca4b58fd\",\"venue\":\"PloS one\",\"year\":2018},{\"arxivId\":\"1805.08191\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1609/aaai.v33i01.33018465\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2b02822cfbc50d17ec5220a19556be9d601c132\",\"title\":\"Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/c2b02822cfbc50d17ec5220a19556be9d601c132\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"}],\"doi\":\"10.3115/v1/P15-2018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12aee52ad6c2b15d4006611651400baa9d01dee9\",\"title\":\"A Distributed Representation Based Query Expansion Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/12aee52ad6c2b15d4006611651400baa9d01dee9\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.05253\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"Fangyu Wu\"},{\"authorId\":\"33830793\",\"name\":\"Jeremy S. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"Bailing Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"title\":\"Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49605790\",\"name\":\"Junyi Wang\"},{\"authorId\":\"145513489\",\"name\":\"Xinyu Su\"}],\"doi\":\"10.1145/3379247.3379295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d088d893301b15c64f195d111ab3953b09d0a06\",\"title\":\"Enriching Intention of Human Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3d088d893301b15c64f195d111ab3953b09d0a06\",\"venue\":\"ICCDE\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89981182\",\"name\":\"Reema K. Sans\"},{\"authorId\":\"89292267\",\"name\":\"Reenu Sara Joseph\"},{\"authorId\":\"9002511\",\"name\":\"Rekha Narayanan\"},{\"authorId\":\"66711706\",\"name\":\"V. G. Mohan Prasad\"},{\"authorId\":\"22985130\",\"name\":\"Jisha James\"}],\"doi\":\"10.1007/978-3-030-00665-5_124\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3072672826ac1c8748d9cedc5e0ea0c54235bedf\",\"title\":\"AUGEN: An Ocular Support for Visually Impaired Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3072672826ac1c8748d9cedc5e0ea0c54235bedf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Fan\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":\"10.1109/ICTAI.2018.00047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdea9a5054f3b5f4dd4c3e75f9278e9548c2de7a\",\"title\":\"Long-Term Recurrent Merge Network Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cdea9a5054f3b5f4dd4c3e75f9278e9548c2de7a\",\"venue\":\"2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2018},{\"arxivId\":\"1801.09356\",\"authors\":[{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"3436918\",\"name\":\"S. Surya\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"7757884\",\"name\":\"V. Radhakrishnan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b081d11a8d19048c65b34c520357a82efcc91856\",\"title\":\"Game of Sketches: Deep Recurrent Models of Pictionary-style Word Guessing\",\"url\":\"https://www.semanticscholar.org/paper/b081d11a8d19048c65b34c520357a82efcc91856\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9430995\",\"name\":\"Vahid Chahkandi\"},{\"authorId\":\"1840177\",\"name\":\"Mohammad Javad Fadaeieslam\"},{\"authorId\":\"1914793\",\"name\":\"F. Yaghmaee\"}],\"doi\":\"10.1007/s13735-018-0158-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b61c59188b830b9bbeb346d86f950585204af1\",\"title\":\"Improvement of image description using bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/d4b61c59188b830b9bbeb346d86f950585204af1\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144187895\",\"name\":\"Zhihong Zeng\"},{\"authorId\":\"39738087\",\"name\":\"X. Li\"}],\"doi\":\"10.1007/S00542-019-04473-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"638e4d81bc43a22add5f3cca181f468c5ac40b8c\",\"title\":\"Application of human computing in image captioning under deep learning\",\"url\":\"https://www.semanticscholar.org/paper/638e4d81bc43a22add5f3cca181f468c5ac40b8c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339038\",\"name\":\"Nisha Pillai\"},{\"authorId\":\"2674440\",\"name\":\"Cynthia Matuszek\"}],\"doi\":\"10.13016/M2WD3Q48B\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6b8a1c74f1c7b317188c8309b8c2e72591b4a83\",\"title\":\"Unsupervised Selection of Negative Examples for Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6b8a1c74f1c7b317188c8309b8c2e72591b4a83\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1809.00339\",\"authors\":[{\"authorId\":\"144483305\",\"name\":\"M. Rahman\"},{\"authorId\":\"145972524\",\"name\":\"Nabeel Mohammed\"},{\"authorId\":\"1786649\",\"name\":\"N. Mansoor\"},{\"authorId\":\"2599479\",\"name\":\"S. Momen\"}],\"doi\":\"10.1016/J.PROCS.2019.06.100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1c4520309fcb3108cf83ac6630222e7956ebe9f\",\"title\":\"Chittron: An Automatic Bangla Image Captioning System\",\"url\":\"https://www.semanticscholar.org/paper/e1c4520309fcb3108cf83ac6630222e7956ebe9f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"1626610869\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1692580\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/TMM.2020.2976552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"title\":\"Integrating Part of Speech Guidance for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1511.04510\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/CVPR.2016.347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7304c3155ee9ac37348ced0d71f3cb03434b252d\",\"title\":\"Semantic Object Parsing with Local-Global Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/7304c3155ee9ac37348ced0d71f3cb03434b252d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2001.11701\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df50b896c58770bf494f983e5ee1a4383f8357b7\",\"title\":\"Teaching Machines to Converse\",\"url\":\"https://www.semanticscholar.org/paper/df50b896c58770bf494f983e5ee1a4383f8357b7\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":6785090,\"doi\":\"10.1109/CVPR.2015.7298856\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":19,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1713801\",\"name\":\"A. Deoras\"},{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"1899242\",\"name\":\"J. \\u010cernock\\u00fd\"}],\"doi\":\"10.1109/ASRU.2011.6163930\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb45e9217fe323fbc199d820e7735488fca2a9b3\",\"title\":\"Strategies for training large scale neural network language models\",\"url\":\"https://www.semanticscholar.org/paper/cb45e9217fe323fbc199d820e7735488fca2a9b3\",\"venue\":\"2011 IEEE Workshop on Automatic Speech Recognition & Understanding\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf60322f83714523e2d7c1d39983151fe9db7146\",\"title\":\"Collecting Image Annotations Using Amazon's Mechanical Turk\",\"url\":\"https://www.semanticscholar.org/paper/bf60322f83714523e2d7c1d39983151fe9db7146\",\"venue\":\"Mturk@HLT-NAACL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"2245567\",\"name\":\"M. Karafi\\u00e1t\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"1899242\",\"name\":\"J. \\u010cernock\\u00fd\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9819b600a828a57e1cde047bbe710d3446b30da5\",\"title\":\"Recurrent neural network based language model\",\"url\":\"https://www.semanticscholar.org/paper/9819b600a828a57e1cde047bbe710d3446b30da5\",\"venue\":\"INTERSPEECH\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Figure 1: Several examples of generated captions (red) and human generated captions (black) Last row shows failure cases. Comparison of free verbal recall\",\"url\":\"\",\"venue\":\"Psychological Reports\",\"year\":1965},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"30345804\",\"name\":\"Jean-S\\u00e9bastien Senecal\"},{\"authorId\":\"1949088\",\"name\":\"F. Morin\"},{\"authorId\":\"1685010\",\"name\":\"J. Gauvain\"}],\"doi\":\"10.1007/3-540-33486-6_6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5eb1a272f9933a11d113cf63fe659e073942bce5\",\"title\":\"Neural Probabilistic Language Models\",\"url\":\"https://www.semanticscholar.org/paper/5eb1a272f9933a11d113cf63fe659e073942bce5\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/SLT.2012.6424228\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1275b2a2ab53013310e759e5c6878b96df643d4\",\"title\":\"Context dependent recurrent neural network language model\",\"url\":\"https://www.semanticscholar.org/paper/d1275b2a2ab53013310e759e5c6878b96df643d4\",\"venue\":\"2012 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Lewis\"},{\"authorId\":null,\"name\":\"James T Lieberman\"},{\"authorId\":null,\"name\":\"Culpepper\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Words versus objects: This is an extended abstract. The full paper is available at the Computer Vision Foundation webpage\",\"url\":\"\",\"venue\":\"Words versus objects: This is an extended abstract. The full paper is available at the Computer Vision Foundation webpage\",\"year\":null},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47713710\",\"name\":\"Benjamin Z. Yao\"},{\"authorId\":\"47008378\",\"name\":\"Xiong Yang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/JPROC.2010.2050411\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05e074abddd3fe987b9bebd46f6cf4bf8465c37e\",\"title\":\"I2T: Image Parsing to Text Description\",\"url\":\"https://www.semanticscholar.org/paper/05e074abddd3fe987b9bebd46f6cf4bf8465c37e\",\"venue\":\"Proceedings of the IEEE\",\"year\":2010},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"}],\"doi\":\"10.1109/72.279181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0be39ee052d246ae99c082a565aba25b811be2d\",\"title\":\"Learning long-term dependencies with gradient descent is difficult\",\"url\":\"https://www.semanticscholar.org/paper/d0be39ee052d246ae99c082a565aba25b811be2d\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"},{\"authorId\":\"1895771\",\"name\":\"D. Zipser\"}],\"doi\":\"10.1080/09540098908915631\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424710825d726e10b016204ed2bc979e2a342d10\",\"title\":\"Experimental Analysis of the Real-time Recurrent Learning Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/424710825d726e10b016204ed2bc979e2a342d10\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-10593-2_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"title\":\"Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections\",\"url\":\"https://www.semanticscholar.org/paper/fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145704247\",\"name\":\"J. Martens\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"title\":\"Generating Text with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6729734\",\"name\":\"L. Lieberman\"},{\"authorId\":\"38133932\",\"name\":\"J. T. Culpepper\"}],\"doi\":\"10.2466/pr0.1965.17.3.983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b27639bd026e6492a51d538a1b3374353a327cda\",\"title\":\"Words versus Objects: Comparison of Free Verbal Recall\",\"url\":\"https://www.semanticscholar.org/paper/b27639bd026e6492a51d538a1b3374353a327cda\",\"venue\":\"Psychological reports\",\"year\":1965},{\"arxivId\":\"1411.5654\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"title\":\"Learning a Recurrent Visual Representation for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. A. Just\"},{\"authorId\":null,\"name\":\"S. D. Newman\"},{\"authorId\":null,\"name\":\"T. A. Keller\"},{\"authorId\":null,\"name\":\"A. McEleney\"},{\"authorId\":null,\"name\":\"P. A. Carpenter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Convolu - tional architecture for fast feature embedding\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv : 1408 .\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1798462\",\"name\":\"Pierre-Antoine Manzagol\"}],\"doi\":\"10.1145/1390156.1390294\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"843959ffdccf31c6694d135fad07425924f785b1\",\"title\":\"Extracting and composing robust features with denoising autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1\",\"venue\":\"ICML '08\",\"year\":2008},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2473524\",\"name\":\"A. Paivio\"},{\"authorId\":\"116552190\",\"name\":\"T. B. Rogers\"},{\"authorId\":\"115021533\",\"name\":\"P. R. Smythe\"}],\"doi\":\"10.3758/BF03331011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b89506c0d81fa9da28cfc8e3cfdf12012ca3320a\",\"title\":\"Why are pictures easier to recall than words?\",\"url\":\"https://www.semanticscholar.org/paper/b89506c0d81fa9da28cfc8e3cfdf12012ca3320a\",\"venue\":\"\",\"year\":1968},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.3115/v1/P14-2074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52f86811b57034ba5c0478b37cab101d9a84024a\",\"title\":\"Comparing Automatic Evaluation Measures for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/52f86811b57034ba5c0478b37cab101d9a84024a\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2884373\",\"name\":\"J. Elman\"}],\"doi\":\"10.1207/s15516709cog1402_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"668087f0ae7ce1de6e0bd0965dbb480c08103260\",\"title\":\"Finding Structure in Time\",\"url\":\"https://www.semanticscholar.org/paper/668087f0ae7ce1de6e0bd0965dbb480c08103260\",\"venue\":\"Cogn. Sci.\",\"year\":1990},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2013.387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"051830b0ea58d1568f19ec3297e301d9789c9a76\",\"title\":\"Bringing Semantics into Focus Using Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/051830b0ea58d1568f19ec3297e301d9789c9a76\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065109\",\"name\":\"M. Just\"},{\"authorId\":\"6809972\",\"name\":\"S. Newman\"},{\"authorId\":\"28431545\",\"name\":\"T. Keller\"},{\"authorId\":\"3912397\",\"name\":\"A. McEleney\"},{\"authorId\":\"145761969\",\"name\":\"P. Carpenter\"}],\"doi\":\"10.1016/j.neuroimage.2003.08.042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bae60fcf0bc1521f69963e4309e170c2acdcaca3\",\"title\":\"Imagery in sentence comprehension: an fMRI study\",\"url\":\"https://www.semanticscholar.org/paper/bae60fcf0bc1521f69963e4309e170c2acdcaca3\",\"venue\":\"NeuroImage\",\"year\":2004},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013}],\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"topics\":[{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Content-based image retrieval\",\"topicId\":\"44433\",\"url\":\"https://www.semanticscholar.org/topic/44433\"},{\"topic\":\"Bi-directional text\",\"topicId\":\"325093\",\"url\":\"https://www.semanticscholar.org/topic/325093\"}],\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"