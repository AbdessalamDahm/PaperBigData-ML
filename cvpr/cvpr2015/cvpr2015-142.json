"{\"abstract\":\"In this paper we target at generating generic action proposals in unconstrained videos. Each action proposal corresponds to a temporal series of spatial bounding boxes, i.e., a spatio-temporal video tube, which has a good potential to locate one human action. Assuming each action is performed by a human with meaningful motion, both appearance and motion cues are utilized to measure the actionness of the video tubes. After picking those spatiotemporal paths of high actionness scores, our action proposal generation is formulated as a maximum set coverage problem, where greedy search is performed to select a set of action proposals that can maximize the overall actionness score. Compared with existing action proposal approaches, our action proposals do not rely on video segmentation and can be generated in nearly real-time. Experimental results on two challenging datasets, MSRII and UCF 101, validate the superior performance of our action proposals as well as competitive results on action detection and search.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\",\"url\":\"https://www.semanticscholar.org/author/145015817\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\",\"url\":\"https://www.semanticscholar.org/author/34316743\"}],\"citationVelocity\":34,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123524055\",\"name\":\"Yan\"},{\"authorId\":\"39436288\",\"name\":\"Min Jia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8405492c97fff8e374e2752aa78c31dfa884c93\",\"title\":\"VIDEO ANOMALY DETECTION USING UNSUPERVISED DEEP LEARNING METHODS\",\"url\":\"https://www.semanticscholar.org/paper/e8405492c97fff8e374e2752aa78c31dfa884c93\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72046972\",\"name\":\"Kataoka Hirokatsu\"},{\"authorId\":\"1393888854\",\"name\":\"Miyashita Yudai\"},{\"authorId\":\"1392031925\",\"name\":\"Yamabe Tomoaki\"},{\"authorId\":\"100877779\",\"name\":\"Shirakabe Soma\"},{\"authorId\":\"52601768\",\"name\":\"Sato Shinichi\"},{\"authorId\":\"1392572194\",\"name\":\"Hoshino Hironori\"},{\"authorId\":\"1392011341\",\"name\":\"Kato Ryo\"},{\"authorId\":\"101524854\",\"name\":\"Abe Kaori\"},{\"authorId\":\"1390054231\",\"name\":\"Imanari Takaaki\"},{\"authorId\":\"1394469677\",\"name\":\"Kobayashi Naomichi\"},{\"authorId\":\"100667175\",\"name\":\"Morita Shinichiro\"},{\"authorId\":\"66767948\",\"name\":\"Nakamura Akio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"title\":\"cvpaper.challenge in CVPR2015 -- A review of CVPR2015\",\"url\":\"https://www.semanticscholar.org/paper/b35a6e738aadd4a974db2d0815879e37e5d7d66f\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2006.04489\",\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"title\":\"Action Recognition with Deep Multiple Aggregation Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34596687\",\"name\":\"Mengjia Yan\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/ICPR.2018.8546039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5425dd075193bc7814578c410dbf7d1e2793425\",\"title\":\"3D Convolutional Generative Adversarial Networks for Detecting Temporal Irregularities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e5425dd075193bc7814578c410dbf7d1e2793425\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134835107\",\"name\":\"Van Gemert\"},{\"authorId\":\"48038845\",\"name\":\"Elena Gati\"},{\"authorId\":\"49418951\",\"name\":\"Xueliang Xie\"},{\"authorId\":\"145063584\",\"name\":\"Mark W. Jones\"},{\"authorId\":\"1888880\",\"name\":\"Gary K. L. Tam\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"76e0dac1af110cf11f31ff08e205e4ee082af285\",\"title\":\"UvA-DARE ( Digital Academic Repository ) APT : Action localization Proposals from dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/76e0dac1af110cf11f31ff08e205e4ee082af285\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.5244/C.31.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"title\":\"End-to-End, Single-Stream Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/90b0d4fff784f12c2819bdf07fe7c62b7e2e7daf\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1016/j.neucom.2018.05.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2cda38655d3f216430969b5b864b96c1b011c1\",\"title\":\"Detecting action tubes via spatial action estimation and temporal path inference\",\"url\":\"https://www.semanticscholar.org/paper/de2cda38655d3f216430969b5b864b96c1b011c1\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/CVPR.2018.00871\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e2f163e8a94d7a8597cabe73e7503d6b3bd7bec\",\"title\":\"SSNet: Scale Selection Network for Online 3D Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5e2f163e8a94d7a8597cabe73e7503d6b3bd7bec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734295227\",\"name\":\"Albert Haque\"},{\"authorId\":\"3472674\",\"name\":\"A. Milstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1038/s41586-020-2669-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38783aba80a96c13d3f1ca71320dfda3b65827d3\",\"title\":\"Illuminating the dark spaces of healthcare with ambient intelligence\",\"url\":\"https://www.semanticscholar.org/paper/38783aba80a96c13d3f1ca71320dfda3b65827d3\",\"venue\":\"Nat.\",\"year\":2020},{\"arxivId\":\"1808.00297\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-20876-9_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"563fcc87934a4e6c8843c81b58273cb366918bfb\",\"title\":\"TraMNet - Transition Matrix Network for Efficient Action Tube Proposals\",\"url\":\"https://www.semanticscholar.org/paper/563fcc87934a4e6c8843c81b58273cb366918bfb\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812342\",\"name\":\"Yeongtaek Song\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3390/s19051085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"title\":\"Spatio-Temporal Action Detection in Untrimmed Videos by Using Multimodal Features and Region Proposals\",\"url\":\"https://www.semanticscholar.org/paper/be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d83ae5926b05894fcda0bc89bdc621e4f21272da\",\"title\":\"Frugal Forests : Learning a Dynamic and Cost Sensitive Feature Extraction Policy for Anytime Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/d83ae5926b05894fcda0bc89bdc621e4f21272da\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143622778\",\"name\":\"K. Xu\"},{\"authorId\":\"1888867\",\"name\":\"X. Jiang\"},{\"authorId\":\"3307728\",\"name\":\"T. Sun\"}],\"doi\":\"10.1109/TCSVT.2017.2665359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8b0fb855e2ddbf490d3160c408a0cbe16c5ee9f\",\"title\":\"Two-Stream Dictionary Learning Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8b0fb855e2ddbf490d3160c408a0cbe16c5ee9f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/ICCV.2017.619\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44a3e466743add34a34567b4566ebe6c98bd2abf\",\"title\":\"TORNADO: A Spatio-Temporal Convolutional Regression Network for Video Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/44a3e466743add34a34567b4566ebe6c98bd2abf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1109/CVPR.2016.216\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"title\":\"A Multi-stream Bi-directional Recurrent Neural Network for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39453466\",\"name\":\"T. Zhang\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/VCIP.2017.8305139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5fd22f59041a0fd405805b46a7fb9b32fce9a90\",\"title\":\"Action proposals using hierarchical clustering of super-trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d5fd22f59041a0fd405805b46a7fb9b32fce9a90\",\"venue\":\"2017 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2017},{\"arxivId\":\"1607.02003\",\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-017-1023-9\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9dd21511fc70f9b7ed1d095a51f09c60f9f1efe1\",\"title\":\"Tubelets: Unsupervised Action Proposals from Spatiotemporal Super-Voxels\",\"url\":\"https://www.semanticscholar.org/paper/9dd21511fc70f9b7ed1d095a51f09c60f9f1efe1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2674558\",\"name\":\"Zahra Kamranian\"},{\"authorId\":\"30758533\",\"name\":\"Ahmad Reza Naghsh Nilchi\"},{\"authorId\":\"153246742\",\"name\":\"Hamid Sadeghian\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"145587210\",\"name\":\"Nassir Navab\"}],\"doi\":\"10.1007/s00521-019-04448-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"834020bf39704ead11c26116b6e61ac2f81e69b8\",\"title\":\"Joint motion boundary detection and CNN-based feature visualization for video object segmentation\",\"url\":\"https://www.semanticscholar.org/paper/834020bf39704ead11c26116b6e61ac2f81e69b8\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1605.05197\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"144173710\",\"name\":\"X. Martin\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08d40ee6e1c0060d3b706b6b627e03d4b123377a\",\"title\":\"Towards Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/08d40ee6e1c0060d3b706b6b627e03d4b123377a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-M\\u00e1adeed\"}],\"doi\":\"10.1007/s00138-019-01039-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"title\":\"Action recognition in poor-quality spectator crowd videos using head distribution-based person segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"venue\":\"Machine Vision and Applications\",\"year\":2019},{\"arxivId\":\"2004.00180\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2683916\",\"name\":\"Lizhi Yang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"title\":\"Spatio-Temporal Action Detection with Multi-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014138\",\"name\":\"L. Qi\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"}],\"doi\":\"10.1145/3271553.3271563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08410196627dfd16371d781a64e98573c54d07a4\",\"title\":\"Action Recognition by Jointly Using Video Proposal and Trajectory\",\"url\":\"https://www.semanticscholar.org/paper/08410196627dfd16371d781a64e98573c54d07a4\",\"venue\":\"ICVISP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438978\",\"name\":\"Geoffrey Vaquette\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"},{\"authorId\":\"1885717\",\"name\":\"L. Lucat\"}],\"doi\":\"10.1007/s11554-016-0660-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f738ff26fdc2bce00862c8256641ba1b945281a3\",\"title\":\"Robust information fusion in the DOHT paradigm for real-time action detection\",\"url\":\"https://www.semanticscholar.org/paper/f738ff26fdc2bce00862c8256641ba1b945281a3\",\"venue\":\"Journal of Real-Time Image Processing\",\"year\":2016},{\"arxivId\":\"1901.09403\",\"authors\":[{\"authorId\":\"41049768\",\"name\":\"Amlaan Bhoi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"title\":\"Spatio-temporal Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.00758\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2017.06.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"079ca5438664c8fc529bfbf2749747515c098e8a\",\"title\":\"Unsupervised action proposal ranking through proposal recombination\",\"url\":\"https://www.semanticscholar.org/paper/079ca5438664c8fc529bfbf2749747515c098e8a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"144173710\",\"name\":\"X. Martin\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3daafe6389d877fe15d8823cdf5ac15fd919676f\",\"title\":\"Human Action Localization with Sparse Spatial Supervision\",\"url\":\"https://www.semanticscholar.org/paper/3daafe6389d877fe15d8823cdf5ac15fd919676f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2407432\",\"name\":\"Claudio Baecchi\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1801509\",\"name\":\"M. Bertini\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3078971.3079027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc4f29647db7b7d4fc30a66d63a341c20adc8840\",\"title\":\"Deep Sentiment Features of Context and Faces for Affective Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/cc4f29647db7b7d4fc30a66d63a341c20adc8840\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1511.04067\",\"authors\":[{\"authorId\":\"39963722\",\"name\":\"Raviteja Vemulapalli\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"}],\"doi\":\"10.1109/CVPR.2016.519\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f71bb02fe5fb2719e588f7cb275e6effd1bf4858\",\"title\":\"Deep Gaussian Conditional Random Field Network: A Model-Based Deep Network for Discriminative Denoising\",\"url\":\"https://www.semanticscholar.org/paper/f71bb02fe5fb2719e588f7cb275e6effd1bf4858\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1607.01115\",\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d9a04a3c4dd293576665154721579ef5ed7f7d0\",\"title\":\"Click Carving: Segmenting Objects in Video with Point Clicks\",\"url\":\"https://www.semanticscholar.org/paper/3d9a04a3c4dd293576665154721579ef5ed7f7d0\",\"venue\":\"HCOMP\",\"year\":2016},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09926ed62511c340f4540b5bc53cf2480e8063f8\",\"title\":\"Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/09926ed62511c340f4540b5bc53cf2480e8063f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-019-01184-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06a3a31eb79f9589fdfcd1aca5b41d1bf47956fa\",\"title\":\"Click Carving: Interactive Object Segmentation in Images and Videos with Point Clicks\",\"url\":\"https://www.semanticscholar.org/paper/06a3a31eb79f9589fdfcd1aca5b41d1bf47956fa\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.07403\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/WACV.2017.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e12226cf0da453dc4b9879d7af6b43af3c31d2b\",\"title\":\"Efficient Action Detection in Untrimmed Videos via Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/6e12226cf0da453dc4b9879d7af6b43af3c31d2b\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1604.07602\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/978-3-319-46454-1_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ea1e828256feee129eae3497f41e21bce36a34\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/b1ea1e828256feee129eae3497f41e21bce36a34\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1609.00221\",\"authors\":[{\"authorId\":\"35058266\",\"name\":\"G. Cuffaro\"},{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"2407432\",\"name\":\"Claudio Baecchi\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1007/978-3-319-49409-8_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5a0e119ce4925a55910dcf0b5667ab551f8cdf1\",\"title\":\"Segmentation Free Object Discovery in Video\",\"url\":\"https://www.semanticscholar.org/paper/e5a0e119ce4925a55910dcf0b5667ab551f8cdf1\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICIP40778.2020.9191360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a15dbfca55605bd3a5769ada375433c216822e0e\",\"title\":\"Coarse-to-Fine Aggregation for Cross-Granularity Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a15dbfca55605bd3a5769ada375433c216822e0e\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46332770\",\"name\":\"M. Jiang\"},{\"authorId\":\"1752849\",\"name\":\"T. Aoyama\"},{\"authorId\":\"145091856\",\"name\":\"T. Takaki\"},{\"authorId\":\"1766560\",\"name\":\"I. Ishii\"}],\"doi\":\"10.3390/s16111842\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b72091b0398467bbe4280d78fea3d60c16d5331\",\"title\":\"Pixel-Level and Robust Vibration Source Sensing in High-Frame-Rate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7b72091b0398467bbe4280d78fea3d60c16d5331\",\"venue\":\"Sensors\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":null,\"name\":\"Yi Zhou\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2813530\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"0329d9be8ab1e3a1d5e4b9e7db5af5bbcc64e36f\",\"title\":\"Deep Action Parsing in Videos With Large-Scale Synthesized Data\",\"url\":\"https://www.semanticscholar.org/paper/0329d9be8ab1e3a1d5e4b9e7db5af5bbcc64e36f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123524055\",\"name\":\"Yan\"},{\"authorId\":\"39436288\",\"name\":\"Min Jia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a15fda2ee7cc6ffbc4eec37eee00d4e7cc04e31\",\"title\":\"VIDEO ANOMALY DETECTION USING UNSUPERVISED DEEP LEARNING METHODS\",\"url\":\"https://www.semanticscholar.org/paper/5a15fda2ee7cc6ffbc4eec37eee00d4e7cc04e31\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9385562\",\"name\":\"Minwen Zhang\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"48934185\",\"name\":\"Q. Li\"},{\"authorId\":\"48169955\",\"name\":\"L. Wang\"},{\"authorId\":\"49050577\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11042-017-5116-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"954ce390c9e762b2c34b0c6cc8d8829bc6932d4c\",\"title\":\"Action detection based on tracklets with the two-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/954ce390c9e762b2c34b0c6cc8d8829bc6932d4c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2799968\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"title\":\"Multi-Modality Multi-Task Recurrent Neural Network for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490866837\",\"name\":\"Chan Zheng\"},{\"authorId\":\"50030933\",\"name\":\"X. Yang\"},{\"authorId\":\"46875450\",\"name\":\"Xunmu Zhu\"},{\"authorId\":\"2023742062\",\"name\":\"Chen Changxin\"},{\"authorId\":\"49681427\",\"name\":\"L. Wang\"},{\"authorId\":\"41157630\",\"name\":\"Shuqin Tu\"},{\"authorId\":\"46889237\",\"name\":\"Aqing Yang\"},{\"authorId\":\"3104125\",\"name\":\"Yueju Xue\"}],\"doi\":\"10.1016/j.biosystemseng.2020.04.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"title\":\"Automatic posture change analysis of lactating sows by action localisation and tube optimisation from untrimmed depth videos\",\"url\":\"https://www.semanticscholar.org/paper/c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145272426\",\"name\":\"H. Song\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"46511084\",\"name\":\"B. Zhu\"},{\"authorId\":\"32161932\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"50133140\",\"name\":\"Mei Chen\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/TMM.2018.2866370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00d0ade3b49533b87714fa12da4fb3f89500fabb\",\"title\":\"Temporal Action Localization in Untrimmed Videos Using Action Pattern Trees\",\"url\":\"https://www.semanticscholar.org/paper/00d0ade3b49533b87714fa12da4fb3f89500fabb\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145602046\",\"name\":\"R. Zeng\"},{\"authorId\":\"2228021\",\"name\":\"R. Lakemond\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"31548192\",\"name\":\"S. Morgan\"}],\"doi\":\"10.1109/DICTA.2016.7797093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8b7decaedbf41dd3e7e71e50f551b4463d702fe\",\"title\":\"Vertical Axis Detection for Sport Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/d8b7decaedbf41dd3e7e71e50f551b4463d702fe\",\"venue\":\"2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2016},{\"arxivId\":\"1810.04511\",\"authors\":[{\"authorId\":\"48153708\",\"name\":\"L. Meng\"},{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"2123865\",\"name\":\"F. Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b613ea6c4fb5efdf17af090d64e9bdce41e28711\",\"title\":\"Where and When to Look? Spatio-temporal Attention for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b613ea6c4fb5efdf17af090d64e9bdce41e28711\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"},{\"authorId\":\"50656755\",\"name\":\"Qing Yuan Zhou\"},{\"authorId\":\"50424096\",\"name\":\"Nicolas Christou\"},{\"authorId\":\"145081360\",\"name\":\"Alan Loddon Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"title\":\"Electronic Theses and Dissertations Title Mining Spatial and Spatio-Temporal ROIs for Action Recognition Permalink\",\"url\":\"https://www.semanticscholar.org/paper/4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1811.12248\",\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.12.019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac360c948a81738b892869fafe950e05cf477618\",\"title\":\"Discovering Spatio-Temporal Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/ac360c948a81738b892869fafe950e05cf477618\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2071053\",\"name\":\"J. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/ICME.2017.8019495\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2525f336af31178b836e27f8c60056e18f1455d2\",\"title\":\"Temporally enhanced image object proposals for videos\",\"url\":\"https://www.semanticscholar.org/paper/2525f336af31178b836e27f8c60056e18f1455d2\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"title\":\"Enhancing human action recognition with region proposals\",\"url\":\"https://www.semanticscholar.org/paper/30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"venue\":\"ICRA 2015\",\"year\":2015},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.02349\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"144091320\",\"name\":\"Guyue Zhang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"10727378\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCV.2017.610\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f0167299d73b19d800953dd2859a0af2244a0c5\",\"title\":\"Temporal Context Network for Activity Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5f0167299d73b19d800953dd2859a0af2244a0c5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39872583\",\"name\":\"M. Wang\"},{\"authorId\":\"2206888\",\"name\":\"Changzhi Luo\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"49606802\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TCSVT.2017.2716819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b300b85e10aa312dfe31d8064d86f764d0aaa68\",\"title\":\"First-Person Daily Activity Recognition With Manipulated Object Proposals and Non-Linear Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5b300b85e10aa312dfe31d8064d86f764d0aaa68\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"49982480\",\"name\":\"Yuanyuan Ge\"},{\"authorId\":\"47909272\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s11042-018-5868-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"title\":\"Remember and forget: video and text fusion for video question answering\",\"url\":\"https://www.semanticscholar.org/paper/ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12649937\",\"name\":\"Y. Chen\"},{\"authorId\":\"2069934\",\"name\":\"Shyi-Chyi Cheng\"},{\"authorId\":\"35493143\",\"name\":\"Chen-Kuai Yang\"}],\"doi\":\"10.1109/ISCIT.2017.8261171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f92224e019ee35ceeaa8fbd5eaf9fc1a0361bef9\",\"title\":\"Unsupervised learning of space-time symmetric patterns in RGB-D videos for 4D human activity detection\",\"url\":\"https://www.semanticscholar.org/paper/f92224e019ee35ceeaa8fbd5eaf9fc1a0361bef9\",\"venue\":\"2017 17th International Symposium on Communications and Information Technologies (ISCIT)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"896b764cff4d71f917c485593ef78d2f1ed7124d\",\"title\":\"Online, Supervised and Unsupervised Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/896b764cff4d71f917c485593ef78d2f1ed7124d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/ICIP.2017.8297080\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e5690cdb4dfa30d98dff653be459e1c270cde7f\",\"title\":\"Multiple path search for action tube detection in videos\",\"url\":\"https://www.semanticscholar.org/paper/9e5690cdb4dfa30d98dff653be459e1c270cde7f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1812.10000\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1995717\",\"name\":\"Bingyi Kang\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12479dcd4808b96d6a149919183ef15afcf6a89e\",\"title\":\"Similarity R-C3D for Few-shot Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/12479dcd4808b96d6a149919183ef15afcf6a89e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"144466591\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2018.2887061\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"c372c9892fa0e3b36675bbf63b221696cd8a8b1f\",\"title\":\"Fast and Accurate Action Detection in Videos With Motion-Centric Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/c372c9892fa0e3b36675bbf63b221696cd8a8b1f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1505.05836\",\"authors\":[{\"authorId\":\"1942727\",\"name\":\"Neelima Chavali\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2016.97\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf0f4f4dfda2473601d60de36333c4ebe1df8f1a\",\"title\":\"Object-Proposal Evaluation Protocol is \\u2018Gameable\\u2019\",\"url\":\"https://www.semanticscholar.org/paper/cf0f4f4dfda2473601d60de36333c4ebe1df8f1a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.07945\",\"authors\":[{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2017.162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06184106c9a5dc602cac98f162b991707aaa4a80\",\"title\":\"Spatio-Temporal Person Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/06184106c9a5dc602cac98f162b991707aaa4a80\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29326440\",\"name\":\"A. Roy\"}],\"doi\":\"10.15167/ROY-ABHINABA_PHD2019-02-21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0c43e113d7ae99e763ea09dac97ba115d9e54bb\",\"title\":\"Data Driven Approaches for Image & Video Understanding: from Traditional to Zero-shot Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/c0c43e113d7ae99e763ea09dac97ba115d9e54bb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845267\",\"name\":\"Da Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"daf161f0f763bf19246ad51338764c9f732d11f0\",\"title\":\"METAL: Minimum Effort Temporal Activity Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/daf161f0f763bf19246ad51338764c9f732d11f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1805.11333\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-018-1120-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90f457c30a678ea879827b6d576ec4b97e404c28\",\"title\":\"Pointly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/90f457c30a678ea879827b6d576ec4b97e404c28\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1605.08247\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"3108668\",\"name\":\"Tomoaki K. Yamabe\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"47937389\",\"name\":\"Shin-ichi Sato\"},{\"authorId\":\"29998543\",\"name\":\"H. Hoshino\"},{\"authorId\":\"144802310\",\"name\":\"Ryo Kato\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"3407486\",\"name\":\"Takaaki Imanari\"},{\"authorId\":\"26851746\",\"name\":\"Naomichi Kobayashi\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"2462801\",\"name\":\"A. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"title\":\"cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey\",\"url\":\"https://www.semanticscholar.org/paper/74012279e94f13d44c62f5d5b20dc983b7f5cf84\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.82\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c535d4d61aa0f1d8aadb4082bdcc19f4cbdf0eaf\",\"title\":\"Unsupervised Action Discovery and Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c535d4d61aa0f1d8aadb4082bdcc19f4cbdf0eaf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144925873\",\"name\":\"N. Kumaran\"},{\"authorId\":\"3846423\",\"name\":\"U. S. Reddy\"},{\"authorId\":\"46574794\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"title\":\"Multiple Action Recognition for Human Object with Motion Video Sequence using the Properties of HSV Color Space Applying with Region of Interest\",\"url\":\"https://www.semanticscholar.org/paper/80032a37b56d3cec48e9250a5518f6949de3ce1d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1604.00427\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8926471921ff608f70c6c81777782974a91086ae\",\"title\":\"Leaving Some Stones Unturned: Dynamic Feature Prioritization for Activity Detection in Streaming Video\",\"url\":\"https://www.semanticscholar.org/paper/8926471921ff608f70c6c81777782974a91086ae\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"49292395\",\"name\":\"B. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"}],\"doi\":\"10.1109/TPAMI.2019.2940225\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"810bfc2786292757185ed53b29e98c56ee1c95d5\",\"title\":\"Sequence-to-Segments Networks for Detecting Segments in Videos.\",\"url\":\"https://www.semanticscholar.org/paper/810bfc2786292757185ed53b29e98c56ee1c95d5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46401013\",\"name\":\"Jian-wen Jiang\"},{\"authorId\":\"153843000\",\"name\":\"Y. Cao\"},{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"51487081\",\"name\":\"Yunkai Li\"},{\"authorId\":\"70397730\",\"name\":\"Ziyao Xu\"},{\"authorId\":\"47506758\",\"name\":\"Q. Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f968688dcdd8980399265de1996a00a62034913\",\"title\":\"Human Centric Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4f968688dcdd8980399265de1996a00a62034913\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3117712\",\"name\":\"C. V. Gemeren\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/FG.2017.72\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4347097c6d1587ec21c24a64f1bde677a851ed6c\",\"title\":\"Lend Me a Hand: Auxiliary Image Data Helps Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/4347097c6d1587ec21c24a64f1bde677a851ed6c\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"title\":\"Learning to Recognize Actions with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1710.06236\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1145/3123266.3123343\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"title\":\"Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"143676076\",\"name\":\"Boyu Wang\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"},{\"authorId\":\"50562082\",\"name\":\"J. Zhang\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6c5ed5021ea817ee6c6b9f4df922e3a1bf977349\",\"title\":\"Sequence-to-Segment Networks for Segment Detection\",\"url\":\"https://www.semanticscholar.org/paper/6c5ed5021ea817ee6c6b9f4df922e3a1bf977349\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65863515\",\"name\":\"X. Xie\"},{\"authorId\":\"145063584\",\"name\":\"M. W. Jones\"},{\"authorId\":\"1888880\",\"name\":\"G. Tam\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"603e20e189aaf2324318e4168e615d317142d26a\",\"title\":\"APT: Action localization Proposals from dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/603e20e189aaf2324318e4168e615d317142d26a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.5244/C.31.91\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e899061f8ac891f39f197fbbb5cc64ab57bebd6a\",\"title\":\"Real-Time Temporal Action Localization in Untrimmed Videos by Sub-Action Discovery\",\"url\":\"https://www.semanticscholar.org/paper/e899061f8ac891f39f197fbbb5cc64ab57bebd6a\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/TIP.2017.2772904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a955ee69174fb97c7017f2e227a5fa26b900537\",\"title\":\"Egocentric Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/7a955ee69174fb97c7017f2e227a5fa26b900537\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.07702\",\"authors\":[{\"authorId\":\"1685519\",\"name\":\"Ahmed Taha\"},{\"authorId\":\"27018486\",\"name\":\"Y. Chen\"},{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"32639375\",\"name\":\"Teruhisa Misu\"},{\"authorId\":\"145879186\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe3f8826f615cc5ada33b01777b9f9dc93e0023c\",\"title\":\"Exploring Uncertainty in Conditional Multi-Modal Retrieval Systems\",\"url\":\"https://www.semanticscholar.org/paper/fe3f8826f615cc5ada33b01777b9f9dc93e0023c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.03280\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"title\":\"Exploring Temporal Preservation Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1601.02129\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a82860d11fcbf12628724333f1e7ada8f3cd255\",\"title\":\"Action Temporal Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/0a82860d11fcbf12628724333f1e7ada8f3cd255\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/ICIP.2017.8296639\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d933b789e4822b4d77976936ca6c82026b7e280c\",\"title\":\"Search video action proposal with recurrent and static YOLO\",\"url\":\"https://www.semanticscholar.org/paper/d933b789e4822b4d77976936ca6c82026b7e280c\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1707.09143\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.5244/C.31.22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/0b6fe7284d7f23ea841d47a5f16f95d8820e53c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143781496\",\"name\":\"Ke Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Yong Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"title\":\"TPC: Temporal Preservation Convolutional Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"},{\"authorId\":\"1701928\",\"name\":\"Jixiang Du\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"47416429\",\"name\":\"Shuang Ye\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19194129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"title\":\"A Survey of Vision-Based Human Action Evaluation Methods\",\"url\":\"https://www.semanticscholar.org/paper/fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40085868\",\"name\":\"Kai Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c6e067098fa86ee3f96365f28669b06f9ce0c7a\",\"title\":\"generate action proposals by calculating actionness scores and solving a maximum set coverage problem\",\"url\":\"https://www.semanticscholar.org/paper/1c6e067098fa86ee3f96365f28669b06f9ce0c7a\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1806.11269\",\"authors\":[{\"authorId\":\"144209663\",\"name\":\"Y. Xiao\"},{\"authorId\":\"98894244\",\"name\":\"Jun Chen\"},{\"authorId\":\"144762660\",\"name\":\"Zhiguo Cao\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.ins.2018.12.050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4508789311f47bf6f6bb348d001b9ab370b71de\",\"title\":\"Action Recognition for Depth Video using Multi-view Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/e4508789311f47bf6f6bb348d001b9ab370b71de\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9271111\",\"name\":\"Nasrin Sadeghzadehyazdi\"},{\"authorId\":\"2870447\",\"name\":\"T. Batabyal\"},{\"authorId\":\"1771388\",\"name\":\"L. Barnes\"},{\"authorId\":\"1737005\",\"name\":\"S. Acton\"}],\"doi\":\"10.1109/ACSSC.2016.7869577\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9cf8d3b1609f8df248f4ba51bbf6800e6613bc6f\",\"title\":\"Graph-based classification of healthcare provider activity\",\"url\":\"https://www.semanticscholar.org/paper/9cf8d3b1609f8df248f4ba51bbf6800e6613bc6f\",\"venue\":\"2016 50th Asilomar Conference on Signals, Systems and Computers\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49402429\",\"name\":\"J. Yu\"},{\"authorId\":\"46533851\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"40322073\",\"name\":\"L. Wan\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TCSVT.2019.2919064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10129da014606c70b6fab077319491c772b01c04\",\"title\":\"Spatio-Temporal Deep Q-Networks for Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/10129da014606c70b6fab077319491c772b01c04\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.3389/frobt.2015.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90a754f597958a2717862fbaa313f67b25083bf9\",\"title\":\"A Review of Human Activity Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/90a754f597958a2717862fbaa313f67b25083bf9\",\"venue\":\"Front. Robot. AI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"143629371\",\"name\":\"L. Song\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2019.2959425\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8006397de84196e07ee4b520100940f2fd46483\",\"title\":\"GLNet: Global Local Network for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b8006397de84196e07ee4b520100940f2fd46483\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"33379011\",\"name\":\"E. Gati\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.5244/C.29.177\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"21ef7e01de0e1feb4b21c89ccb0423e4213bb9e0\",\"title\":\"APT: Action localization proposals from dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/21ef7e01de0e1feb4b21c89ccb0423e4213bb9e0\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"38748749\",\"name\":\"Wayner Barrios\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2017.338\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"551cddb9a5e20861b491ec39f3ced933f6364a17\",\"title\":\"SCC: Semantic Context Cascade for Efficient Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/551cddb9a5e20861b491ec39f3ced933f6364a17\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708998\",\"name\":\"Nguyen Anh Tu\"},{\"authorId\":\"1402997421\",\"name\":\"Thien Huynh-The\"},{\"authorId\":\"46581230\",\"name\":\"K. Khan\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/TCSVT.2018.2816960\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c0d23485c0ece214000ff8c0dcb3042bc114048\",\"title\":\"ML-HDP: A Hierarchical Bayesian Nonparametric Model for Recognizing Human Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/5c0d23485c0ece214000ff8c0dcb3042bc114048\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1109/TIP.2019.2942814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"title\":\"Deep Reinforcement Learning for Weak Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1805.06749\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89d7aa10ad97251089d0204916f784f137f3a1ec\",\"title\":\"Action Completion: A Temporal Model for Moment Detection\",\"url\":\"https://www.semanticscholar.org/paper/89d7aa10ad97251089d0204916f784f137f3a1ec\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39691613\",\"name\":\"H. Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2018.00175\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"title\":\"Instance-Aware Detailed Action Labeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1710.08011\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"35163655\",\"name\":\"K. Hata\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba11083602568bbc2514c0905e0d831a65c2af6e\",\"title\":\"ActivityNet Challenge 2017 Summary\",\"url\":\"https://www.semanticscholar.org/paper/ba11083602568bbc2514c0905e0d831a65c2af6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/LSP.2017.2778190\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35b84c0b3e20cf27e08a200e9c17dcf215263ed7\",\"title\":\"PMHI: Proposals From Motion History Images for Temporal Segmentation of Long Uncut Videos\",\"url\":\"https://www.semanticscholar.org/paper/35b84c0b3e20cf27e08a200e9c17dcf215263ed7\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":\"1802.10250\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cdb10443a0543be3466c9231ff922bcc996843\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/99cdb10443a0543be3466c9231ff922bcc996843\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38932510\",\"name\":\"J. Matas\"},{\"authorId\":\"34788950\",\"name\":\"N. Sebe\"},{\"authorId\":\"144026434\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eef65ed4a246a15fb1dd0a3816fef9c9988ee22\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5eef65ed4a246a15fb1dd0a3816fef9c9988ee22\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"49308184\",\"name\":\"Y. Yang\"},{\"authorId\":\"143822920\",\"name\":\"He Jiang\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"2585506\",\"name\":\"G. Wang\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/RCAR.2018.8621829\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"title\":\"Action Recognition and Localization with Instance FCNN\",\"url\":\"https://www.semanticscholar.org/paper/ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"venue\":\"2018 IEEE International Conference on Real-time Computing and Robotics (RCAR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96668091\",\"name\":\"Tan Yu\"},{\"authorId\":\"49201849\",\"name\":\"Z. Ren\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"104219153\",\"name\":\"Enxu Yan\"},{\"authorId\":\"145857596\",\"name\":\"N. Xu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/ICCV.2019.00562\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c\",\"title\":\"Temporal Structure Mining for Weakly Supervised Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549298\",\"name\":\"J. Li\"},{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"}],\"doi\":\"10.1109/ICME.2017.8019535\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2606d7b1351af521aa43a99e3765e648f32233ed\",\"title\":\"Learning to generate video object segment proposals\",\"url\":\"https://www.semanticscholar.org/paper/2606d7b1351af521aa43a99e3765e648f32233ed\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691251\",\"name\":\"J. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.jvcir.2018.03.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3780f56d2563dcdea4a3ce178acd265456f05dd\",\"title\":\"Temporally enhanced image object proposals for online video object and action detections\",\"url\":\"https://www.semanticscholar.org/paper/e3780f56d2563dcdea4a3ce178acd265456f05dd\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1804.01824\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2019.102886\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a427fc1fde8206136075785eda3d757278adfb44\",\"title\":\"Guess Where? Actor-Supervision for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a427fc1fde8206136075785eda3d757278adfb44\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1604.05633\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1007/978-3-319-46478-7_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"576aeac727c76abadbf678d39215c33941e712f4\",\"title\":\"Online Human Action Detection using Joint Classification-Regression Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/576aeac727c76abadbf678d39215c33941e712f4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"title\":\"Role of Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25b78b68f8c9b50b7f9290d88134fc377fd43433\",\"title\":\"CloudCV: Deep Learning and Computer Vision on the Cloud\",\"url\":\"https://www.semanticscholar.org/paper/25b78b68f8c9b50b7f9290d88134fc377fd43433\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379882732\",\"name\":\"L. Tani\"},{\"authorId\":\"2512422\",\"name\":\"Abdelghani Ghomari\"},{\"authorId\":\"2782248\",\"name\":\"M. Y. K. Tani\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-135-2019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4823216083b8fbab8e246dc0867f2aac4718bc32\",\"title\":\"EVENTS RECOGNITION FOR A SEMI-AUTOMATIC ANNOTATION OF SOCCER VIDEOS: A STUDY BASED DEEP LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/4823216083b8fbab8e246dc0867f2aac4718bc32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"1740321\",\"name\":\"Jian Yu\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1016/j.neucom.2019.01.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f38d00417e5e6655caf8eeea224aaceffbe20606\",\"title\":\"Action recognition and localization with spatial and temporal contexts\",\"url\":\"https://www.semanticscholar.org/paper/f38d00417e5e6655caf8eeea224aaceffbe20606\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sonia Mittal\"},{\"authorId\":null,\"name\":\"Kanika Sharma\"},{\"authorId\":null,\"name\":\"Sheena Nanda\"},{\"authorId\":\"4332590\",\"name\":\"Aditi Thakur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf50d1731e9dc6c0e85f5a05138ae2c1de6b5cdb\",\"title\":\"OBJECT DETECTION IN VIDEO BASED ON TRANSFER LEARNING USING CONVOLUTION NEURAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/bf50d1731e9dc6c0e85f5a05138ae2c1de6b5cdb\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2016.290\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68bd9fa880a368b82782f617deefbde9552cac28\",\"title\":\"Predicting the Where and What of Actors and Actions through Online Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/68bd9fa880a368b82782f617deefbde9552cac28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"title\":\"Mining Spatial and Spatio-Temporal ROIs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":null,\"name\":\"Nannan Li\"}],\"doi\":\"10.1109/ACCESS.2018.2842088\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1312b0b0fd660de87fa42de39316b28f9336e70\",\"title\":\"Action Extraction in Continuous Unconstrained Video for Cloud-Based Intelligent Service Robot\",\"url\":\"https://www.semanticscholar.org/paper/e1312b0b0fd660de87fa42de39316b28f9336e70\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1810.03964\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"},{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"}],\"doi\":\"10.1109/ICIP.2018.8451666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143676076\",\"name\":\"Boyu Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1016/j.cviu.2018.10.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c6b64312fd6adc8b563852ad59483dc1aea3693\",\"title\":\"Back to the beginning: Starting point detection for early recognition of ongoing human actions\",\"url\":\"https://www.semanticscholar.org/paper/2c6b64312fd6adc8b563852ad59483dc1aea3693\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7675e7d657b3dfe25022ad918a09b588ea0d2e30\",\"title\":\"Motion in action : optical flow estimation and action localization in videos. (Le mouvement en action : estimation du flot optique et localisation d'actions dans les vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/7675e7d657b3dfe25022ad918a09b588ea0d2e30\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691251\",\"name\":\"J. Yang\"}],\"doi\":\"10.32657/10356/75713\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"191d0e995ac07b2301691b55d528ecc4a26944ec\",\"title\":\"Discovering thematic visual objects in unconstrained videos\",\"url\":\"https://www.semanticscholar.org/paper/191d0e995ac07b2301691b55d528ecc4a26944ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1145/3264706.3264716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"title\":\"PhD thesis: objects for spatio-temporal activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"venue\":\"ACMMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2015.375\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a4a601279458c9359a900b01bf259097571b739\",\"title\":\"Action Localization in Videos through Context Walk\",\"url\":\"https://www.semanticscholar.org/paper/6a4a601279458c9359a900b01bf259097571b739\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1145/2964284.2971479\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e04069bd66dfa7b3f2ba75ace4133cc4c154116\",\"title\":\"Weakly-Supervised Recognition, Localization, and Explanation of Visual Entities\",\"url\":\"https://www.semanticscholar.org/paper/3e04069bd66dfa7b3f2ba75ace4133cc4c154116\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674907\",\"name\":\"Lili Meng\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"115284322\",\"name\":\"W. Sun\"},{\"authorId\":\"1402348340\",\"name\":\"Frederich Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCVW.2019.00189\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"title\":\"Interpretable Spatio-Temporal Attention for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACVW.2019.00011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138115\",\"name\":\"F. Negin\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.3390/s19194237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"title\":\"An Unsupervised Framework for Online Spatiotemporal Detection of Activities of Daily Living by Hierarchical Activity Models\",\"url\":\"https://www.semanticscholar.org/paper/4a43026d85dd4f377cd9e62ed2bdaa7bcbb3ccba\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1604.04053\",\"authors\":[{\"authorId\":\"144813536\",\"name\":\"Kai Kang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.95\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"title\":\"Object Detection from Video Tubelets with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.04702\",\"authors\":[{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-017-1006-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f168d6933ba90c241ad0295b01e43538883d524\",\"title\":\"DeepProposals: Hunting Objects and Actions by Cascading Deep Convolutional Layers\",\"url\":\"https://www.semanticscholar.org/paper/5f168d6933ba90c241ad0295b01e43538883d524\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"title\":\"Learning to Recognize Actions with Weak Supervision. (Reconnaissance d'actions de mani\\u00e8re faiblement supervis\\u00e9e)\",\"url\":\"https://www.semanticscholar.org/paper/d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1707.09145\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/ICCV.2017.476\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af2896e36cec58c2acca03001d7f19db48e9e5c3\",\"title\":\"Spatial-Aware Object Embeddings for Zero-Shot Localization and Classification of Actions\",\"url\":\"https://www.semanticscholar.org/paper/af2896e36cec58c2acca03001d7f19db48e9e5c3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1602.03346\",\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":null,\"name\":\"Yi Zhou\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICRA.2017.7989018\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e251595e6ef8396d5b3e423bc03a22ec75ff5038\",\"title\":\"DAP3D-Net: Where, what and how actions occur in videos?\",\"url\":\"https://www.semanticscholar.org/paper/e251595e6ef8396d5b3e423bc03a22ec75ff5038\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2016.211\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"bac994dda1385cd709e08e24170c711d8c573676\",\"title\":\"Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bac994dda1385cd709e08e24170c711d8c573676\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46521926\",\"name\":\"Xinran Liu\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":\"10.1007/978-3-319-73600-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95ea887b1692ae21e2fafae960ccca89fc55f82b\",\"title\":\"Effective Action Detection Using Temporal Context and Posterior Probability of Length\",\"url\":\"https://www.semanticscholar.org/paper/95ea887b1692ae21e2fafae960ccca89fc55f82b\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77c95c3648cea1a9bc38384f0ae7a37a7c4004a7\",\"title\":\"Human Action Detection Using Joint Classification-Regression Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/77c95c3648cea1a9bc38384f0ae7a37a7c4004a7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1608.06495\",\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"34692827\",\"name\":\"Zhenqiang Ying\"},{\"authorId\":\"143846985\",\"name\":\"Z. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1007/978-3-319-54184-6_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fa832841daef04ec2865577d9e73b2d8d47ae1d\",\"title\":\"Searching Action Proposals via Spatial Actionness Estimation and Temporal Path Inference and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/6fa832841daef04ec2865577d9e73b2d8d47ae1d\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1691251\",\"name\":\"J. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/ICCV.2017.237\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ed2d7ecb34a13e12474f75d803547ad2ad811b2\",\"title\":\"Common Action Discovery and Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/4ed2d7ecb34a13e12474f75d803547ad2ad811b2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1706.04122\",\"authors\":[{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76798bddd0f12ae03de26b7c7743c008d505215\",\"title\":\"Joint Max Margin and Semantic Features for Continuous Event Detection in Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/e76798bddd0f12ae03de26b7c7743c008d505215\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48998638\",\"name\":\"P. Ni\"},{\"authorId\":\"1902517\",\"name\":\"Shilei Lv\"},{\"authorId\":\"1945398\",\"name\":\"XiaoXiao Zhu\"},{\"authorId\":\"48142797\",\"name\":\"Qixin Cao\"},{\"authorId\":\"49039567\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1016/j.dcan.2020.05.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6282bd563f5283260056f3edeef4c3b2deecefce\",\"title\":\"A light-weight on-line action detection with hand trajectories for industrial surveillance\",\"url\":\"https://www.semanticscholar.org/paper/6282bd563f5283260056f3edeef4c3b2deecefce\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26940993\",\"name\":\"Djamila Romaissa Beddiar\"},{\"authorId\":\"2079007\",\"name\":\"B. Nini\"},{\"authorId\":\"1887141250\",\"name\":\"Mohammad Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/s11042-020-09004-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46995f6b266a40c10bc05b046654a4be8bf2220c\",\"title\":\"Vision-based human activity recognition: a survey\",\"url\":\"https://www.semanticscholar.org/paper/46995f6b266a40c10bc05b046654a4be8bf2220c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2006.04473\",\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efcd92bd79eab5d4eeabcf5da8710b04b5bf2d50\",\"title\":\"Deep hierarchical pooling design for cross-granularity action recognition\",\"url\":\"https://www.semanticscholar.org/paper/efcd92bd79eab5d4eeabcf5da8710b04b5bf2d50\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02182\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2019.2921539\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95138f276b34cc84695b64ee5fc00c1e27091497\",\"title\":\"Two-Stream Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/95138f276b34cc84695b64ee5fc00c1e27091497\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"Bharat Singh\"}],\"doi\":\"10.13016/M2FX7423N\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4391b692d6b7a242f719e4d219b4b7db155bccea\",\"title\":\"Detecting Objects and Actions with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4391b692d6b7a242f719e4d219b4b7db155bccea\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TCSVT.2018.2887283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"title\":\"CNN-Based Multiple Path Search for Action Tube Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47930257\",\"name\":\"R. S. C. Oliveira\"}],\"doi\":\"10.25911/5dfc956bbd86c\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"title\":\"Visual Recognition From Structured Supervision\",\"url\":\"https://www.semanticscholar.org/paper/388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877834352\",\"name\":\"Sukrit Bhattacharya\"},{\"authorId\":\"1877778893\",\"name\":\"Vaibhav Shaw\"},{\"authorId\":\"143730686\",\"name\":\"P. Singh\"},{\"authorId\":\"70680168\",\"name\":\"R. Sarkar\"},{\"authorId\":\"89542097\",\"name\":\"D. Bhattacharjee\"}],\"doi\":\"10.1007/978-3-030-49345-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae92267620dcebcc38ffb1258344ab8dd21fa635\",\"title\":\"SV-NET: A Deep Learning Approach to Video Based Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae92267620dcebcc38ffb1258344ab8dd21fa635\",\"venue\":\"SoCPaR\",\"year\":2019},{\"arxivId\":\"1706.08218\",\"authors\":[{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"39859402\",\"name\":\"Romain Vial\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"39514690\",\"name\":\"Xi Peng\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"}],\"doi\":\"10.1109/TIP.2018.2806279\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baac20337b7fcdb54547abf2984be8ee753f4c3b\",\"title\":\"YoTube: Searching Action Proposal Via Recurrent and Static Regression Networks\",\"url\":\"https://www.semanticscholar.org/paper/baac20337b7fcdb54547abf2984be8ee753f4c3b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"}],\"doi\":\"10.15781/T2R20SC9C\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5a14671f53b010acefc0ed9ea8ce7dca65fb413\",\"title\":\"Human machine collaboration for foreground segmentation in images and videos\",\"url\":\"https://www.semanticscholar.org/paper/e5a14671f53b010acefc0ed9ea8ce7dca65fb413\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1512.09041\",\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2016.336\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bac3ed8deec94196170ad89931c419ce3ff14b5\",\"title\":\"Actor-Action Semantic Segmentation with Grouping Process Models\",\"url\":\"https://www.semanticscholar.org/paper/1bac3ed8deec94196170ad89931c419ce3ff14b5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3318552\",\"name\":\"Francesco Turchini\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1016/j.cviu.2016.11.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2851efe83633a1c80272ba2c9302a1333dd32523\",\"title\":\"Understanding and localizing activities from correspondences of clustered trajectories\",\"url\":\"https://www.semanticscholar.org/paper/2851efe83633a1c80272ba2c9302a1333dd32523\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15841516\",\"name\":\"Shuo Chen\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144436744\",\"name\":\"Tao Hu\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1145/3372278.3390680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed38ab8511cd7f6a202730bfd3de566c3622562f\",\"title\":\"Interactivity Proposals for Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/ed38ab8511cd7f6a202730bfd3de566c3622562f\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"}],\"doi\":\"10.1016/J.CVIU.2019.04.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3917d925dac0abf6e7b452fa2916c25f9e72fc2c\",\"title\":\"TAB: Temporally aggregated bag-of-discriminant-words for temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/3917d925dac0abf6e7b452fa2916c25f9e72fc2c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"3309893\",\"name\":\"G. Brostow\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7e7ff6237110e3d78be3bde42196b02935f207f\",\"title\":\"Localizing Actions from Video Labels and Pseudo-Annotations\",\"url\":\"https://www.semanticscholar.org/paper/f7e7ff6237110e3d78be3bde42196b02935f207f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1612.01194\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2018.2797266\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"title\":\"Online Localization and Prediction of Actions and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"3421228\",\"name\":\"Bilal Mirza\"}],\"doi\":\"10.1016/j.neucom.2017.04.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bf29868e856621a59dad8adb2c66e21348612ef\",\"title\":\"Dual-layer kernel extreme learning machine for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2bf29868e856621a59dad8adb2c66e21348612ef\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1905.13417\",\"authors\":[{\"authorId\":\"143629372\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"144254616\",\"name\":\"Hongbin Sun\"}],\"doi\":\"10.1109/CVPR.2019.01226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"518512621412fd76d47ef9225a45fcc99d0247d2\",\"title\":\"TACNet: Transition-Aware Context Network for Spatio-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/518512621412fd76d47ef9225a45fcc99d0247d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"118098028\",\"name\":\"Linchao He\"},{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47180213\",\"name\":\"Shifu Zhang\"},{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"153671183\",\"name\":\"Boxiong Yang\"}],\"doi\":\"10.1016/j.patcog.2020.107312\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79921dc4596e36efb431077208a73a46995d8a2c\",\"title\":\"Learning motion representation for real-time spatio-temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/79921dc4596e36efb431077208a73a46995d8a2c\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1701.05384\",\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2017.228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a76dc85d8c458eebdffa87c64233d1345163478\",\"title\":\"FusionSeg: Learning to Combine Motion and Appearance for Fully Automatic Segmentation of Generic Objects in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a76dc85d8c458eebdffa87c64233d1345163478\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.01358\",\"authors\":[{\"authorId\":\"145560551\",\"name\":\"Harkirat Singh Behl\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"961fd8da3102e9c8696f70375507eee89d37ef61\",\"title\":\"Incremental Tube Construction for Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/961fd8da3102e9c8696f70375507eee89d37ef61\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1708.00042\",\"authors\":[{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.95\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae6fc9fa6dba7a20567671b9f1b0815b343bc152\",\"title\":\"Spatio-Temporal Action Detection with Cascade Proposal and Location Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/ae6fc9fa6dba7a20567671b9f1b0815b343bc152\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"081a05d88f0442915c1402548fc82e48ee8133a2\",\"title\":\"Weakly Labeled Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/081a05d88f0442915c1402548fc82e48ee8133a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.08069\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"207a1766a942be3f22534980f47916f6dc683095\",\"title\":\"S3D: Single Shot multi-Span Detector via Fully 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/207a1766a942be3f22534980f47916f6dc683095\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3031655\",\"name\":\"Stavros Tachos\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1713991\",\"name\":\"Alexia Briassouli\"},{\"authorId\":\"1715604\",\"name\":\"Yiannis Kompatsiaris\"}],\"doi\":\"10.1016/j.cviu.2017.04.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b2812cf37440cc09a7e2734b927986b4027539b\",\"title\":\"Mining discriminative descriptors for goal-based activity detection\",\"url\":\"https://www.semanticscholar.org/paper/5b2812cf37440cc09a7e2734b927986b4027539b\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2018.2844101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ef6b55a23aab0ec6b02fdb01d5e30181ef42e04\",\"title\":\"Hierarchical Concept Score Postprocessing and Concept-Wise Normalization in CNN-Based Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ef6b55a23aab0ec6b02fdb01d5e30181ef42e04\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46332770\",\"name\":\"M. Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"766691a5537bdc8d6dbba2f84f17593acd85849c\",\"title\":\"A Study on Vibration Source Localization Using High-speed Vision\",\"url\":\"https://www.semanticscholar.org/paper/766691a5537bdc8d6dbba2f84f17593acd85849c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"134883142\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2018.2887408\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification With Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1707.06005\",\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.31.51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89597f719e7fc8022016da6b5cabb3e1fa1c775e\",\"title\":\"Detecting Parts for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/89597f719e7fc8022016da6b5cabb3e1fa1c775e\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47598805\",\"name\":\"Qing Wang\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"145235303\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1007/978-3-319-77380-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5107d9fa904543b7080b384435a59a6f8def60c4\",\"title\":\"Temporal Interval Regression Network for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/5107d9fa904543b7080b384435a59a6f8def60c4\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1904.00696\",\"authors\":[{\"authorId\":\"4712803\",\"name\":\"Jiaojiao Zhao\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2019.01017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"title\":\"Dance With Flow: Two-In-One Stream Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019}],\"corpusId\":2758467,\"doi\":\"10.1109/CVPR.2015.7298735\",\"fieldsOfStudy\":[\"Mathematics\",\"Computer Science\"],\"influentialCitationCount\":34,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TPAMI.2011.38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b97a5850d257e068f5c0b5f6eb303920a81d1cd\",\"title\":\"Discriminative Video Pattern Search for Efficient Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/7b97a5850d257e068f5c0b5f6eb303920a81d1cd\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8193421\",\"name\":\"Yicong Tian\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2013.341\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eea7842025dad6b4cf53445c161538536020b412\",\"title\":\"Spatiotemporal Deformable Part Models for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eea7842025dad6b4cf53445c161538536020b412\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.341\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf2e2804b0601c88dd843a0e494e41b4a7959d81\",\"title\":\"Action Recognition and Localization by Hierarchical Space-Time Segments\",\"url\":\"https://www.semanticscholar.org/paper/cf2e2804b0601c88dd843a0e494e41b4a7959d81\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"144016261\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"53970934246dc6536e9d99de6d9718db58377a37\",\"title\":\"Video Event Detection: From Subvolume Localization To Spatio-Temporal Path Search.\",\"url\":\"https://www.semanticscholar.org/paper/53970934246dc6536e9d99de6d9718db58377a37\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34405061\",\"name\":\"Dan Banica\"},{\"authorId\":\"9122572\",\"name\":\"Alexandru Agape\"},{\"authorId\":\"144135837\",\"name\":\"A. Ion\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/ICCVW.2013.45\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2011d6ff9540f9b8cb63f1f6e36cd9489b46971\",\"title\":\"Video Object Segmentation by Salient Segment Chain Composition\",\"url\":\"https://www.semanticscholar.org/paper/a2011d6ff9540f9b8cb63f1f6e36cd9489b46971\",\"venue\":\"2013 IEEE International Conference on Computer Vision Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2014.101\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"title\":\"Actionness Ranking with Lattice Conditional Ordinal Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787725\",\"name\":\"Fabio Galasso\"},{\"authorId\":\"40031905\",\"name\":\"N. S. Nagaraja\"},{\"authorId\":\"2704621\",\"name\":\"Tatiana Jimenez Cardenas\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4194159e8cb641b2df7e995794e3af2a8a03ab23\",\"title\":\"A Unified Video Segmentation Benchmark: Annotation, Metrics and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4194159e8cb641b2df7e995794e3af2a8a03ab23\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48527910\",\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":\"2990689\",\"name\":\"R. Appel\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1109/TPAMI.2014.2300479\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"84e0d68e41788644c78cfdc3f4ac3cbea7854a5c\",\"title\":\"Fast Feature Pyramids for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/84e0d68e41788644c78cfdc3f4ac3cbea7854a5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2014.100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"title\":\"Action Localization with Tubelets from Motion\",\"url\":\"https://www.semanticscholar.org/paper/377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2009.5459303\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55b29a2505149d06d8c1d616cd30edca40cb029c\",\"title\":\"Poselets: Body part detectors trained using 3D human pose annotations\",\"url\":\"https://www.semanticscholar.org/paper/55b29a2505149d06d8c1d616cd30edca40cb029c\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c0f44d60b485da34112161536f294ef9d12dac5\",\"title\":\"Evaluation of super-voxel methods for early video processing\",\"url\":\"https://www.semanticscholar.org/paper/6c0f44d60b485da34112161536f294ef9d12dac5\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34702203\",\"name\":\"M. Bergh\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"2414059\",\"name\":\"S. Manen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICCV.2013.54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4404a99e2f6db3e703609168a3595e0fbdeabc38\",\"title\":\"Online Video SEEDS for Temporal Window Objectness\",\"url\":\"https://www.semanticscholar.org/paper/4404a99e2f6db3e703609168a3595e0fbdeabc38\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1406.6962\",\"authors\":[{\"authorId\":\"2536361\",\"name\":\"J. Hosang\"},{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.5244/C.28.24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b1e6ed85dae91843f3d986a001fb59439adbc39\",\"title\":\"How good are detection proposals, really?\",\"url\":\"https://www.semanticscholar.org/paper/7b1e6ed85dae91843f3d986a001fb59439adbc39\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5da64a24a3a0a07b1b21db2fb2a64ded1340fc57\",\"title\":\"Max-Margin Structured Output Regression for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/5da64a24a3a0a07b1b21db2fb2a64ded1340fc57\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144477854\",\"name\":\"N. Shapovalova\"},{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b541127473598a121e7f1d565e27d21a15c66fad\",\"title\":\"Action is in the Eye of the Beholder: Eye-gaze Driven Model for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b541127473598a121e7f1d565e27d21a15c66fad\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10578-9_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"title\":\"Spatio-temporal Object Detection Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"7969330\",\"name\":\"Ziming Zhang\"},{\"authorId\":\"1730822\",\"name\":\"Wen-Yan Lin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/CVPR.2014.414\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"636cea485f77373ae18e32ac8e1c4e37555db5bd\",\"title\":\"BING: Binarized Normed Gradients for Objectness Estimation at 300fps\",\"url\":\"https://www.semanticscholar.org/paper/636cea485f77373ae18e32ac8e1c4e37555db5bd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10602-1_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"title\":\"Video Action Detection with Relational Dynamic-Poselets\",\"url\":\"https://www.semanticscholar.org/paper/d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1145/1099396.1099397\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed635bad612bc6292e3d219e8fb3599e54e1ce11\",\"title\":\"Recognizing human actions\",\"url\":\"https://www.semanticscholar.org/paper/ed635bad612bc6292e3d219e8fb3599e54e1ce11\",\"venue\":\"VSSN '05\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/TPAMI.2013.137\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"41ed93fd97aa76b4abfda7a09168ad1799f34664\",\"title\":\"Video Event Detection: From Subvolume Localization to Spatiotemporal Path Search\",\"url\":\"https://www.semanticscholar.org/paper/41ed93fd97aa76b4abfda7a09168ad1799f34664\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2010.5539875\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"071c86ee1e28008f06a43da962174bd702d9f408\",\"title\":\"Cross-dataset action detection\",\"url\":\"https://www.semanticscholar.org/paper/071c86ee1e28008f06a43da962174bd702d9f408\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48858384\",\"name\":\"William Brendel\"},{\"authorId\":\"4599641\",\"name\":\"M. Amer\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2011.5995395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38079a7f127ee9279ac99c4e18f87e80777cc895\",\"title\":\"Multiobject tracking as maximum weight independent set\",\"url\":\"https://www.semanticscholar.org/paper/38079a7f127ee9279ac99c4e18f87e80777cc895\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995488\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b65e9f26a1528d09466df85d50127246b272fc2\",\"title\":\"Unsupervised random forest indexing for fast action search\",\"url\":\"https://www.semanticscholar.org/paper/0b65e9f26a1528d09466df85d50127246b272fc2\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-642-15549-9_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7de6028a3b6c07a5544b48e132862923d9c01bd\",\"title\":\"Object, Scene and Actions: Combining Multiple Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c7de6028a3b6c07a5544b48e132862923d9c01bd\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39336289\",\"name\":\"Wen-Sheng Chu\"},{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1007/978-3-642-33765-9_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c58f6a7e882fd4f79bbea5cdf22f36553ac3030\",\"title\":\"Unsupervised Temporal Commonality Discovery\",\"url\":\"https://www.semanticscholar.org/paper/7c58f6a7e882fd4f79bbea5cdf22f36553ac3030\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1145/2072298.2071961\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63127d8e547e0cec7f45dce7462d05d3e44e3188\",\"title\":\"Real-time human action search using random forest based hough voting\",\"url\":\"https://www.semanticscholar.org/paper/63127d8e547e0cec7f45dce7462d05d3e44e3188\",\"venue\":\"MM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2787367\",\"name\":\"P. Siva\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"}],\"doi\":\"10.5244/C.25.65\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16fd1875104614d499402b660bc0a8e19d07963c\",\"title\":\"Weakly Supervised Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/16fd1875104614d499402b660bc0a8e19d07963c\",\"venue\":\"BMVC\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1007/978-3-642-33712-3_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"516afd835d5b0ec7c4727f4635d8de7a35dff0a4\",\"title\":\"Propagative Hough Voting for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/516afd835d5b0ec7c4727f4635d8de7a35dff0a4\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1705564\",\"name\":\"G. Nemhauser\"},{\"authorId\":\"1736128\",\"name\":\"L. Wolsey\"},{\"authorId\":\"143904924\",\"name\":\"M. L. Fisher\"}],\"doi\":\"10.1007/BF01588971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b9e43395663f74c581982e9ca97a0d7057a0008c\",\"title\":\"An analysis of approximations for maximizing submodular set functions\\u2014I\",\"url\":\"https://www.semanticscholar.org/paper/b9e43395663f74c581982e9ca97a0d7057a0008c\",\"venue\":\"Math. Program.\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2980212\",\"name\":\"Y. Xie\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"49969887\",\"name\":\"Zhe Li\"},{\"authorId\":\"1751319\",\"name\":\"L. Liang\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"},{\"authorId\":\"1725937\",\"name\":\"D. Zhao\"}],\"doi\":\"10.1109/CVPR.2011.5995648\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"524b5c2c5b7485a4e3933b4e56af36c0034aab0b\",\"title\":\"A unified framework for locating and recognizing human actions\",\"url\":\"https://www.semanticscholar.org/paper/524b5c2c5b7485a4e3933b4e56af36c0034aab0b\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/CVPR.2011.5995604\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"417a1990a0b2017fe0b932673776a970295afa00\",\"title\":\"Globally-optimal greedy algorithms for tracking a variable number of objects\",\"url\":\"https://www.semanticscholar.org/paper/417a1990a0b2017fe0b932673776a970295afa00\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39971338\",\"name\":\"T. Dean\"},{\"authorId\":\"3154722\",\"name\":\"Mark A. Ruzon\"},{\"authorId\":\"145993832\",\"name\":\"M. Segal\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"1842163\",\"name\":\"J. Yagnik\"}],\"doi\":\"10.1109/CVPR.2013.237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"774f67303ea4a3a94874f08cf9a9dacc69b40782\",\"title\":\"Fast, Accurate Detection of 100,000 Object Classes on a Single Machine\",\"url\":\"https://www.semanticscholar.org/paper/774f67303ea4a3a94874f08cf9a9dacc69b40782\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"},{\"authorId\":\"1760861\",\"name\":\"N. Razavi\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":\"10.1109/TPAMI.2011.70\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8e82ae774e08eeebefc0cda1a64b66bf6884130\",\"title\":\"Hough Forests for Object Detection, Tracking, and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8e82ae774e08eeebefc0cda1a64b66bf6884130\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2787367\",\"name\":\"P. Siva\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"}],\"doi\":\"10.5244/C.24.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"998e027318e51cd388160c556a92f68c9a61bced\",\"title\":\"Action Detection in Crowd\",\"url\":\"https://www.semanticscholar.org/paper/998e027318e51cd388160c556a92f68c9a61bced\",\"venue\":\"BMVC\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1719780\",\"name\":\"Yan Ke\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2007.4409011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53964e0ccc0412e2fbb2cdf3483e1f383208febe\",\"title\":\"Event Detection in Crowded Videos\",\"url\":\"https://www.semanticscholar.org/paper/53964e0ccc0412e2fbb2cdf3483e1f383208febe\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCV.2011.6126472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"title\":\"Discriminative figure-centric models for joint action localization and recognition\",\"url\":\"https://www.semanticscholar.org/paper/40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"11983029\",\"name\":\"Markus Mathias\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2012.6248017\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78cea77517dcc8e0f3a4c28ec4d4606ca5b20af5\",\"title\":\"Pedestrian detection at 100 frames per second\",\"url\":\"https://www.semanticscholar.org/paper/78cea77517dcc8e0f3a4c28ec4d4606ca5b20af5\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2365442\",\"name\":\"B. Alexe\"},{\"authorId\":\"1879646\",\"name\":\"Thomas Deselaers\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/CVPR.2010.5540226\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2dd55b3bcaf50c1228569d0efe5620a910c1cd07\",\"title\":\"What is an object?\",\"url\":\"https://www.semanticscholar.org/paper/2dd55b3bcaf50c1228569d0efe5620a910c1cd07\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1756979\",\"name\":\"K. V. D. Sande\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1007/s11263-013-0620-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38b6540ddd5beebffd05047c78183f7575559fb2\",\"title\":\"Selective Search for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/38b6540ddd5beebffd05047c78183f7575559fb2\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013}],\"title\":\"Fast action proposals for human action detection and search\",\"topics\":[{\"topic\":\"Greedy algorithm\",\"topicId\":\"4173\",\"url\":\"https://www.semanticscholar.org/topic/4173\"},{\"topic\":\"Real-time clock\",\"topicId\":\"121831\",\"url\":\"https://www.semanticscholar.org/topic/121831\"}],\"url\":\"https://www.semanticscholar.org/paper/22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}\n"