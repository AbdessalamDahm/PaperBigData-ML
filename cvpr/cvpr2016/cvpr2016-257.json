"{\"abstract\":\"Objects make distinctive sounds when they are hit or scratched. These sounds reveal aspects of an object's material properties, as well as the actions that produced them. In this paper, we propose the task of predicting what sound an object makes when struck as a way of studying physical interactions within a visual scene. We present an algorithm that synthesizes sound from silent videos of people hitting and scratching objects with a drumstick. This algorithm uses a recurrent neural network to predict sound features from videos and then produces a waveform from these features with an example-based synthesis procedure. We show that the sounds predicted by our model are realistic enough to fool participants in a \\\"real or fake\\\" psychophysical experiment, and that they convey significant information about material properties and physical interactions.\",\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\",\"url\":\"https://www.semanticscholar.org/author/144956994\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\",\"url\":\"https://www.semanticscholar.org/author/2094770\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\",\"url\":\"https://www.semanticscholar.org/author/2324658\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805211\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\",\"url\":\"https://www.semanticscholar.org/author/145358192\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\",\"url\":\"https://www.semanticscholar.org/author/1768236\"}],\"citationVelocity\":51,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3460423\",\"name\":\"Yichao Yan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1780882\",\"name\":\"W. Zhang\"},{\"authorId\":\"49763212\",\"name\":\"J. Tang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1016/J.CVIU.2019.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23633493bc7bd73116adfe922991aef3f0201b4a\",\"title\":\"Cross-modality motion parameterization for fine-grained video prediction\",\"url\":\"https://www.semanticscholar.org/paper/23633493bc7bd73116adfe922991aef3f0201b4a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1809.02587\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"029490920cd736e91d6c57f3cfb850adddcf2725\",\"title\":\"Self-Supervised Generation of Spatial Audio for 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/029490920cd736e91d6c57f3cfb850adddcf2725\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40069761\",\"name\":\"Auston Sterling\"},{\"authorId\":\"46939093\",\"name\":\"J. Wilson\"},{\"authorId\":\"40623145\",\"name\":\"S. Lowe\"},{\"authorId\":\"144247566\",\"name\":\"M. Lin\"}],\"doi\":\"10.1007/978-3-030-01267-0_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d95d29db6778c6a2c6c6415f22814864348708e\",\"title\":\"ISNN: Impact Sound Neural Network for Audio-Visual Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/4d95d29db6778c6a2c6c6415f22814864348708e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1704.08292\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4037274\",\"name\":\"Sudhanshu Srivastava\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1145/3126686.3126723\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27e8965cc9c166e9afee46e611039f0ce8263e51\",\"title\":\"Deep Cross-Modal Audio-Visual Generation\",\"url\":\"https://www.semanticscholar.org/paper/27e8965cc9c166e9afee46e611039f0ce8263e51\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1712.07271\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/s11263-018-1083-5\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"046111bd2dfc057182e0b995110a5705b572c819\",\"title\":\"Learning Sight from Sound: Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/046111bd2dfc057182e0b995110a5705b572c819\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39502882\",\"name\":\"Rodrigo Mart\\u00edn\"},{\"authorId\":\"144562356\",\"name\":\"Michael Weinmann\"},{\"authorId\":\"1899671\",\"name\":\"Matthias B. Hullin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1024c5c3d26a4da848d76ef4335d268c6431a69\",\"title\":\"Evaluating the Effects of Material Sonification in Tactile Devices\",\"url\":\"https://www.semanticscholar.org/paper/c1024c5c3d26a4da848d76ef4335d268c6431a69\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990548\",\"name\":\"Go Irie\"},{\"authorId\":\"9211474\",\"name\":\"M. O\\u0161trek\"},{\"authorId\":\"48017277\",\"name\":\"Haochen Wang\"},{\"authorId\":\"1787190\",\"name\":\"H. Kameoka\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"}],\"doi\":\"10.1109/ICASSP.2019.8683142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"title\":\"Seeing through Sounds: Predicting Visual Semantic Segmentation Results from Multichannel Audio Signals\",\"url\":\"https://www.semanticscholar.org/paper/36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.13132\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bf4168f696923ea5566d3a1ced37772897e24bd\",\"title\":\"A critical analysis of self-supervision, or what we can learn from a single image\",\"url\":\"https://www.semanticscholar.org/paper/7bf4168f696923ea5566d3a1ced37772897e24bd\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":\"10.1007/978-981-15-4095-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"079021d93a88c6a4721af75397d14c2125af1f26\",\"title\":\"DEEP REINFORCEMENT LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/079021d93a88c6a4721af75397d14c2125af1f26\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31431896\",\"name\":\"Hua Zhang\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"39077217\",\"name\":\"Rui Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a88abb2221818877df9e36e22291cf756764fcb\",\"title\":\"Audio Visual Attribute Discovery for Fine-Grained Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a88abb2221818877df9e36e22291cf756764fcb\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40122680\",\"name\":\"M. Weger\"},{\"authorId\":\"144853116\",\"name\":\"T. Hermann\"},{\"authorId\":\"1779788\",\"name\":\"R. H\\u00f6ldrich\"}],\"doi\":\"10.21785/ICAD2019.026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67e326e10ea4881e991554bdb2627b9db450bb1e\",\"title\":\"Real-time Auditory Contrast Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/67e326e10ea4881e991554bdb2627b9db450bb1e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01150-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"title\":\"You Said That?: Synthesising Talking Faces from Audio\",\"url\":\"https://www.semanticscholar.org/paper/0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71614861\",\"name\":\"Sebastian S\\u00e4ger\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"144719835\",\"name\":\"C. Schulze\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.1186/s13636-018-0137-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fc8f46ed3e679fa50ecddd7e394235d6b983b4e\",\"title\":\"AudioPairBank: towards a large-scale tag-pair-based audio content analysis\",\"url\":\"https://www.semanticscholar.org/paper/2fc8f46ed3e679fa50ecddd7e394235d6b983b4e\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2018},{\"arxivId\":\"1603.08511\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46487-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"title\":\"Colorful Image Colorization\",\"url\":\"https://www.semanticscholar.org/paper/8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1902.07473\",\"authors\":[{\"authorId\":\"2564871\",\"name\":\"Yan-Bo Lin\"},{\"authorId\":\"3312576\",\"name\":\"Yu-Jhe Li\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"title\":\"Dual-modality Seq2Seq Network for Audio-visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1600703039\",\"name\":\"Janani Ramaswamy\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"380e7cc65c7be734f2179953bd921630afdee6ec\",\"title\":\"What Makes the Sound?: A Dual-Modality Interacting Network for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/380e7cc65c7be734f2179953bd921630afdee6ec\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"title\":\"2.5D Visual Sound\",\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.10997\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"title\":\"Vision-Infused Deep Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1704.03822\",\"authors\":[{\"authorId\":\"3333169\",\"name\":\"Wenzhen Yuan\"},{\"authorId\":\"7488549\",\"name\":\"Shaoxiong Wang\"},{\"authorId\":\"3308345\",\"name\":\"Siyuan Dong\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"}],\"doi\":\"10.1109/CVPR.2017.478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"011eafc2d845ede162a96801c3e42525cb7ebeec\",\"title\":\"Connecting Look and Feel: Associating the Visual and Tactile Properties of Physical Materials\",\"url\":\"https://www.semanticscholar.org/paper/011eafc2d845ede162a96801c3e42525cb7ebeec\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4947266e0caa3d8be726b98f5be08217748a6e20\",\"title\":\"Input Mask Encoder z Decoder Reconstructed Mask a ) VAE Input Mask Action CNN b ) Action CNN Predicted Action Probability Fixed Action\",\"url\":\"https://www.semanticscholar.org/paper/4947266e0caa3d8be726b98f5be08217748a6e20\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144816684\",\"name\":\"K. Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"title\":\"Learning Video Representations using Contrastive Bidirectional Transformer\",\"url\":\"https://www.semanticscholar.org/paper/025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10755743\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2eea407f5ec91186ddedb0ae314facd86c917fc\",\"title\":\"Simulating the friction sounds using a friction-based adhesion theory model\",\"url\":\"https://www.semanticscholar.org/paper/b2eea407f5ec91186ddedb0ae314facd86c917fc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145236670\",\"name\":\"R. Lu\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/LSP.2018.2853566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2176fe5d53f69c26ae88c4ffe6607f7466ef33bc\",\"title\":\"Listen and Look: Audio\\u2013Visual Matching Assisted Speech Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/2176fe5d53f69c26ae88c4ffe6607f7466ef33bc\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101687783\",\"name\":\"O. Friberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba018189673d883920111184040d307153346267\",\"title\":\"Recognizing Semantics in Human Actions with Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/ba018189673d883920111184040d307153346267\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48842639\",\"name\":\"Dotan Kaufman\"},{\"authorId\":\"36813724\",\"name\":\"Gil Levi\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"48519520\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1109/ICCV.2017.20\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62e6b749ed5825739aa906021c5e613803d5cbe2\",\"title\":\"Temporal Tessellation: A Unified Approach for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/62e6b749ed5825739aa906021c5e613803d5cbe2\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22248942\",\"name\":\"J. Patman\"},{\"authorId\":\"51061517\",\"name\":\"Meshal Alfarhood\"},{\"authorId\":\"144590711\",\"name\":\"S. Islam\"},{\"authorId\":\"51067689\",\"name\":\"Mauro Lemus\"},{\"authorId\":\"3174714\",\"name\":\"Prasad Calyam\"},{\"authorId\":\"1921638\",\"name\":\"K. Palaniappan\"}],\"doi\":\"10.1109/INFCOMW.2018.8407027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf753e8b1ba34bce7e1492b87e7a1eb5573b8ca2\",\"title\":\"Predictive analytics for fog computing using machine learning and GENI\",\"url\":\"https://www.semanticscholar.org/paper/cf753e8b1ba34bce7e1492b87e7a1eb5573b8ca2\",\"venue\":\"IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1996072\",\"name\":\"Fabio Carrara\"},{\"authorId\":\"1692167\",\"name\":\"Rudy Becarelli\"},{\"authorId\":\"1704038\",\"name\":\"R. Caldelli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"144514871\",\"name\":\"Giuseppe Amato\"}],\"doi\":\"10.1007/978-3-030-11012-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"294525731a1cbee5552e0f42f207532388d17f4a\",\"title\":\"Adversarial Examples Detection in Features Distance Spaces\",\"url\":\"https://www.semanticscholar.org/paper/294525731a1cbee5552e0f42f207532388d17f4a\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arnau Bar\\u00f3-Mas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c68730960b641e4f1309f3ee2498de4e91386a2\",\"title\":\"Optical Music Recognition by Long Short-Term Memory Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c68730960b641e4f1309f3ee2498de4e91386a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717546\",\"name\":\"Zhoutong Zhang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"12493779\",\"name\":\"Q. Li\"},{\"authorId\":\"25699206\",\"name\":\"Zhengjia Huang\"},{\"authorId\":\"50690309\",\"name\":\"James Traer\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/ICCV.2017.141\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0472a1e41e9ef5b8c619443328d360f88ca34362\",\"title\":\"Generative Modeling of Audible Shapes for Object Perception\",\"url\":\"https://www.semanticscholar.org/paper/0472a1e41e9ef5b8c619443328d360f88ca34362\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe81492df7e5426b30d455868815ed4853aa9d04\",\"title\":\"Visual Pitch Estimation\",\"url\":\"https://www.semanticscholar.org/paper/fe81492df7e5426b30d455868815ed4853aa9d04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1708.06767\",\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ebc58bb5d517db0111f3565c4eb378d93dad908\",\"title\":\"Seeing Through Noise: Speaker Separation and Enhancement using Visually-derived Speech\",\"url\":\"https://www.semanticscholar.org/paper/0ebc58bb5d517db0111f3565c4eb378d93dad908\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116195\",\"name\":\"Arturo Marb\\u00e1n\"},{\"authorId\":\"4365900\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"122748666\",\"name\":\"J. Fern\\u00e1ndez\"},{\"authorId\":\"144921705\",\"name\":\"A. Casals\"}],\"doi\":\"10.1109/IROS.2018.8593701\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"952c32af671c23c51c5c2eb9dee3c66be92ad204\",\"title\":\"Estimation of Interaction Forces in Robotic Surgery using a Semi-Supervised Deep Neural Network Model\",\"url\":\"https://www.semanticscholar.org/paper/952c32af671c23c51c5c2eb9dee3c66be92ad204\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1807.00619\",\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"46469663\",\"name\":\"Mayank Aggarwal\"},{\"authorId\":\"51118910\",\"name\":\"Pratham Nawal\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.1145/3240508.3241911\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b978e6034842395b3e9202cec26a257594da8f76\",\"title\":\"Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed\",\"url\":\"https://www.semanticscholar.org/paper/b978e6034842395b3e9202cec26a257594da8f76\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"title\":\"Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6806161\",\"name\":\"A. Khamparia\"},{\"authorId\":\"144319831\",\"name\":\"K. Singh\"}],\"doi\":\"10.1111/EXSY.12400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23e2d8579eddc9a3f406367a95bf5a168e4dacf0\",\"title\":\"A systematic review on deep learning architectures and applications\",\"url\":\"https://www.semanticscholar.org/paper/23e2d8579eddc9a3f406367a95bf5a168e4dacf0\",\"venue\":\"Expert Syst. J. Knowl. Eng.\",\"year\":2019},{\"arxivId\":\"2001.10692\",\"authors\":[{\"authorId\":\"1898455\",\"name\":\"Charles R. Qi\"},{\"authorId\":null,\"name\":\"Xinlei Chen\"},{\"authorId\":\"2528439\",\"name\":\"O. Litany\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1109/CVPR42600.2020.00446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddb42aace56362ea9725a33815a64bb213d0329a\",\"title\":\"ImVoteNet: Boosting 3D Object Detection in Point Clouds With Image Votes\",\"url\":\"https://www.semanticscholar.org/paper/ddb42aace56362ea9725a33815a64bb213d0329a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2499552\",\"name\":\"M. Sprogar\"}],\"doi\":\"10.1080/0952813X.2018.1509897\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0600fbb6cd69192babd7dc06b31fb0f83b184712\",\"title\":\"A ladder to human-comparable intelligence: an empirical metric\",\"url\":\"https://www.semanticscholar.org/paper/0600fbb6cd69192babd7dc06b31fb0f83b184712\",\"venue\":\"J. Exp. Theor. Artif. Intell.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46228775\",\"name\":\"Yoonjae Cho\"},{\"authorId\":\"33085949\",\"name\":\"Dohyeong Kim\"},{\"authorId\":\"116406543\",\"name\":\"Edwin M. Truman\"},{\"authorId\":\"153427058\",\"name\":\"Jean-Charles Bazin\"}],\"doi\":\"10.1109/ICCVW.2019.00458\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"337825eef0731eea6bc67544f6d30cf3f383c78f\",\"title\":\"FaceSyncNet: A Deep Learning-Based Approach for Non-Linear Synchronization of Facial Performance Videos\",\"url\":\"https://www.semanticscholar.org/paper/337825eef0731eea6bc67544f6d30cf3f383c78f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35061099\",\"name\":\"Purnendu Banerjee\"},{\"authorId\":\"46634310\",\"name\":\"S. Das\"},{\"authorId\":\"9527673\",\"name\":\"B. Seraogi\"},{\"authorId\":\"51321819\",\"name\":\"H. Majumder\"},{\"authorId\":\"1718382\",\"name\":\"S. Mukkamala\"},{\"authorId\":\"145062098\",\"name\":\"R. Roy\"},{\"authorId\":\"1759420\",\"name\":\"B. Chaudhuri\"}],\"doi\":\"10.1007/978-3-030-02284-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d867acb2d1f127a7ee1896663ab4a6ec67c909c1\",\"title\":\"Graphics Recognition. Current Trends and Evolutions\",\"url\":\"https://www.semanticscholar.org/paper/d867acb2d1f127a7ee1896663ab4a6ec67c909c1\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2017},{\"arxivId\":\"1804.07345\",\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae2114763744cc403df2e3b9da2cae9c9768ae78\",\"title\":\"Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events\",\"url\":\"https://www.semanticscholar.org/paper/ae2114763744cc403df2e3b9da2cae9c9768ae78\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1708.01204\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/ICCVW.2017.61\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b598c73e9335277106fcb8acdad6cda227c6cdf\",\"title\":\"Improved Speech Reconstruction from Silent Video\",\"url\":\"https://www.semanticscholar.org/paper/2b598c73e9335277106fcb8acdad6cda227c6cdf\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c192cd39f90eb8ff2969f8916ef8967607c5298\",\"title\":\"Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/8c192cd39f90eb8ff2969f8916ef8967607c5298\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1905.04418\",\"authors\":[{\"authorId\":\"48293266\",\"name\":\"Michael J. Bianco\"},{\"authorId\":\"117106206\",\"name\":\"P. Gerstoft\"},{\"authorId\":\"50690309\",\"name\":\"James Traer\"},{\"authorId\":\"15018343\",\"name\":\"Emma Ozanich\"},{\"authorId\":\"35154087\",\"name\":\"M. A. Roch\"},{\"authorId\":\"1774548\",\"name\":\"S. Gannot\"},{\"authorId\":\"2262533\",\"name\":\"Charles-Alban Deledalle\"}],\"doi\":\"10.1121/1.5133944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e6c570d277b0b4edd48e2054d5cede4c6bbb50f\",\"title\":\"Machine learning in acoustics: Theory and applications.\",\"url\":\"https://www.semanticscholar.org/paper/2e6c570d277b0b4edd48e2054d5cede4c6bbb50f\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2019},{\"arxivId\":\"1803.10404\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"48458657\",\"name\":\"Zhiheng Li\"},{\"authorId\":\"4053196\",\"name\":\"Ross K. Maddox\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01234-2_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7e12f93339dc9a97cc325a4a3e9a13bdffb4988\",\"title\":\"Lip Movements Generation at a Glance\",\"url\":\"https://www.semanticscholar.org/paper/d7e12f93339dc9a97cc325a4a3e9a13bdffb4988\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.06888\",\"authors\":[{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"2527420\",\"name\":\"Yevgen Chebotar\"},{\"authorId\":\"2726592\",\"name\":\"Jasmine Hsu\"},{\"authorId\":\"145116380\",\"name\":\"Eric Jang\"},{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/ICRA.2018.8462891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2adae2da173b9dd720c8bcac0250a90a7f1ec697\",\"title\":\"Time-Contrastive Networks: Self-Supervised Learning from Video\",\"url\":\"https://www.semanticscholar.org/paper/2adae2da173b9dd720c8bcac0250a90a7f1ec697\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yoshida Isami\"},{\"authorId\":\"65954771\",\"name\":\"Nisimura Ryuichi\"},{\"authorId\":\"67289655\",\"name\":\"Irino Toshio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"889f9eacc9b4744f9c66c3283b8d0b4516851668\",\"title\":\"Acoustic Signal Synthesis Method of Footsteps Based on Sensing Data of Walking Motion\",\"url\":\"https://www.semanticscholar.org/paper/889f9eacc9b4744f9c66c3283b8d0b4516851668\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565372\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":\"10.1109/TASLP.2019.2957889\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"300b6751b7ba68908afdd695f6ca5dfb2ff19d07\",\"title\":\"Weakly Supervised Representation Learning for Audio-Visual Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/300b6751b7ba68908afdd695f6ca5dfb2ff19d07\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.21437/Interspeech.2018-1955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f997d69d78af086dec4462e4319c6d241f42c0c1\",\"title\":\"Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/f997d69d78af086dec4462e4319c6d241f42c0c1\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1608.08614\",\"authors\":[{\"authorId\":\"145294140\",\"name\":\"Mi-Young Huh\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"540b5b4919d345e4da3cc4f3e8a7862329bf41a2\",\"title\":\"What makes ImageNet good for transfer learning?\",\"url\":\"https://www.semanticscholar.org/paper/540b5b4919d345e4da3cc4f3e8a7862329bf41a2\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1610.09003\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2753232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4162e328aacba376ea95a7654378423e504ca3d\",\"title\":\"Cross-Modal Scene Networks\",\"url\":\"https://www.semanticscholar.org/paper/a4162e328aacba376ea95a7654378423e504ca3d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1904.07750\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00398\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"title\":\"Co-Separating Sounds of Visual Objects\",\"url\":\"https://www.semanticscholar.org/paper/7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1710.09798\",\"authors\":[{\"authorId\":\"145559125\",\"name\":\"H. Akbari\"},{\"authorId\":\"49583376\",\"name\":\"Himani Arora\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1686269\",\"name\":\"Nima Mesgarani\"}],\"doi\":\"10.1109/ICASSP.2018.8461856\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"edf0d924b740e436ca4641ccdc8ec3983132fa18\",\"title\":\"Lip2Audspec: Speech Reconstruction from Silent Lip Movements Video\",\"url\":\"https://www.semanticscholar.org/paper/edf0d924b740e436ca4641ccdc8ec3983132fa18\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"2002.04076\",\"authors\":[{\"authorId\":\"50469466\",\"name\":\"P. Verma\"},{\"authorId\":\"1772984\",\"name\":\"J. Salisbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ef729fc8bd7c99255ca05af9d9af4a2dc64be75\",\"title\":\"Unsupervised Learning of Audio Perception for Robotics Applications: Learning to Project Data to T-SNE/UMAP space\",\"url\":\"https://www.semanticscholar.org/paper/9ef729fc8bd7c99255ca05af9d9af4a2dc64be75\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.06322\",\"authors\":[{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1726802\",\"name\":\"Russ Tedrake\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2019.01086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"818ab75722aea9b76a8032c13b8eea9600aa1453\",\"title\":\"Connecting Touch and Vision via Cross-Modal Prediction\",\"url\":\"https://www.semanticscholar.org/paper/818ab75722aea9b76a8032c13b8eea9600aa1453\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.03186\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"title\":\"Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32524586\",\"name\":\"Elias Lundeqvist\"},{\"authorId\":\"144082496\",\"name\":\"M. Svensson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"203464f5f6343d9874519899947c2b6426484a80\",\"title\":\"profiling : A machine learning approach towards detecting gender , age and native language of users in social media\",\"url\":\"https://www.semanticscholar.org/paper/203464f5f6343d9874519899947c2b6426484a80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717546\",\"name\":\"Zhoutong Zhang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"12493779\",\"name\":\"Q. Li\"},{\"authorId\":\"25699206\",\"name\":\"Zhengjia Huang\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c3ea92a4a458b7aacc2fe9e1eb185aede7c1724\",\"title\":\"Inverting Audio-Visual Simulation for Shape and Material Perception\",\"url\":\"https://www.semanticscholar.org/paper/3c3ea92a4a458b7aacc2fe9e1eb185aede7c1724\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1603.05631\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46493-0_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c763df6843aba88d7fb3ab3c55a5937a5f39276\",\"title\":\"Generative Image Modeling Using Style and Structure Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c763df6843aba88d7fb3ab3c55a5937a5f39276\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"2726592\",\"name\":\"Jasmine Hsu\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/CVPRW.2017.69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77712d113a62caa83d6330360ce99d6a5f47bd6a\",\"title\":\"Time-Contrastive Networks: Self-Supervised Learning from Multi-view Observation\",\"url\":\"https://www.semanticscholar.org/paper/77712d113a62caa83d6330360ce99d6a5f47bd6a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1906.00634\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"144036236\",\"name\":\"Carlos Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2599ba93b13c7b08fc0309d0678cc2d74fe8c52a\",\"title\":\"How Much Does Audio Matter to Recognize Egocentric Object Interactions?\",\"url\":\"https://www.semanticscholar.org/paper/2599ba93b13c7b08fc0309d0678cc2d74fe8c52a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717546\",\"name\":\"Zhoutong Zhang\"},{\"authorId\":\"12493779\",\"name\":\"Q. Li\"},{\"authorId\":\"25699206\",\"name\":\"Zhengjia Huang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"34356e364b988e9a1c5c1152df653183b79625a4\",\"title\":\"Shape and Material from Sound\",\"url\":\"https://www.semanticscholar.org/paper/34356e364b988e9a1c5c1152df653183b79625a4\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66227056\",\"name\":\"M. Guo\"},{\"authorId\":\"2035796\",\"name\":\"C. Zhou\"},{\"authorId\":\"49721726\",\"name\":\"Jiahang Liu\"}],\"doi\":\"10.1109/JSTARS.2019.2949220\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db38673271d01e83d915053f64eb058b94141c9f\",\"title\":\"Jointly Learning of Visual and Auditory: A New Approach for RS Image and Audio Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/db38673271d01e83d915053f64eb058b94141c9f\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2019},{\"arxivId\":\"1906.05849\",\"authors\":[{\"authorId\":\"2476765\",\"name\":\"Yonglong Tian\"},{\"authorId\":\"1707347\",\"name\":\"Dilip Krishnan\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":\"10.1007/978-3-030-58621-8_45\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97f4d09175705be4677d675fa27e55defac44800\",\"title\":\"Contrastive Multiview Coding\",\"url\":\"https://www.semanticscholar.org/paper/97f4d09175705be4677d675fa27e55defac44800\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2012.04124\",\"authors\":[{\"authorId\":\"40176903\",\"name\":\"Sangho Lee\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"6555176\",\"name\":\"Thomas Breuel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"title\":\"Parameter Efficient Multimodal Transformers for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"245a50c0f6f6b0c1ea3ab77b2df116b83ba667d8\",\"title\":\"Surprising Effectiveness of Few-Image Unsupervised Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/245a50c0f6f6b0c1ea3ab77b2df116b83ba667d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.07933\",\"authors\":[{\"authorId\":\"145343013\",\"name\":\"Andr\\u00e9s F. P\\u00e9rez\"},{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/WACV45572.2020.9093307\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"title\":\"Audio-Visual Model Distillation Using Acoustic Images\",\"url\":\"https://www.semanticscholar.org/paper/f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486440762\",\"name\":\"K. Ramachandruni\"},{\"authorId\":\"30779954\",\"name\":\"M. Vankadari\"},{\"authorId\":\"1380965321\",\"name\":\"Anima Majumder\"},{\"authorId\":\"1486144212\",\"name\":\"Samrat Dutta\"},{\"authorId\":\"48084237\",\"name\":\"S. Kumar\"}],\"doi\":\"10.1109/RO-MAN46459.2019.8956303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0412679ec2d01a90e57009353bed7cb0726fa2eb\",\"title\":\"SMAK-Net: Self-Supervised Multi-level Spatial Attention Network for Knowledge Representation towards Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/0412679ec2d01a90e57009353bed7cb0726fa2eb\",\"venue\":\"2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.2200/S00819ED1V01Y201712COV014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86ce04c2da6515df45070f5fcd2456b30a571ebe\",\"title\":\"Computational Texture and Patterns: From Textons to Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/86ce04c2da6515df45070f5fcd2456b30a571ebe\",\"venue\":\"Computational Texture and Patterns\",\"year\":2018},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50469466\",\"name\":\"Prateek Verma\"},{\"authorId\":\"2000083\",\"name\":\"Kenneth J. Salisbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2bec95c1c879c2ada2f7a399dd3d331bb391ebdb\",\"title\":\"Unsupervised Learning of Audio Perception: Learning to Project Data to UMAP space\",\"url\":\"https://www.semanticscholar.org/paper/2bec95c1c879c2ada2f7a399dd3d331bb391ebdb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.04312\",\"authors\":[{\"authorId\":\"148115980\",\"name\":\"Soren Pirk\"},{\"authorId\":\"30559411\",\"name\":\"Mohi Khansari\"},{\"authorId\":\"46931507\",\"name\":\"Yunfei Bai\"},{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e874d31af82de73f8dd2d55461c2f4ec838a07c\",\"title\":\"Online Object Representations with Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/3e874d31af82de73f8dd2d55461c2f4ec838a07c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.02541\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.21437/interspeech.2020-1026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a0d2dc8123277cf3c894a10121272207dc39413\",\"title\":\"Vocoder-Based Speech Synthesis from Silent Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a0d2dc8123277cf3c894a10121272207dc39413\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2008.06581\",\"authors\":[{\"authorId\":\"1826395\",\"name\":\"Bin Duan\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"91913011\",\"name\":\"Wei Wang\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":null,\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"title\":\"Audio-Visual Event Localization via Recursive Fusion by Joint Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04758\",\"authors\":[{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"100602595\",\"name\":\"Mandi Luo\"},{\"authorId\":\"77886607\",\"name\":\"Rui Wang\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"title\":\"Deep Audio-Visual Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.07490\",\"authors\":[{\"authorId\":\"145524953\",\"name\":\"S. Luo\"},{\"authorId\":\"3333169\",\"name\":\"Wenzhen Yuan\"},{\"authorId\":\"49006060\",\"name\":\"Edward Adelson\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"},{\"authorId\":\"145856960\",\"name\":\"R. Fuentes\"}],\"doi\":\"10.1109/ICRA.2018.8460494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a99b54a24ba87f3b4c2eb074ee67c307dfb31bb\",\"title\":\"ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a99b54a24ba87f3b4c2eb074ee67c307dfb31bb\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":\"1808.07507\",\"authors\":[{\"authorId\":\"2308598\",\"name\":\"U. Ahsan\"},{\"authorId\":\"37714701\",\"name\":\"R. Madhok\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1109/WACV.2019.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecbfdcbc09146c87fca594b9dcdf55f9c3504ce3\",\"title\":\"Video Jigsaw: Unsupervised Learning of Spatiotemporal Context for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbfdcbc09146c87fca594b9dcdf55f9c3504ce3\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1807.01106\",\"authors\":[{\"authorId\":\"39502882\",\"name\":\"Rodrigo Mart\\u00edn\"},{\"authorId\":\"144562356\",\"name\":\"Michael Weinmann\"},{\"authorId\":\"1899671\",\"name\":\"M. Hullin\"}],\"doi\":\"10.1145/3279778.3281455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec473a8278b4db096cb5da54284be581281b8e97\",\"title\":\"A Study of Material Sonification in Touchscreen Devices\",\"url\":\"https://www.semanticscholar.org/paper/ec473a8278b4db096cb5da54284be581281b8e97\",\"venue\":\"ISS\",\"year\":2018},{\"arxivId\":\"1906.05743\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"title\":\"Contrastive Bidirectional Transformer for Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1607.07295\",\"authors\":[{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e64992091458256f438fbe1bd44fffcc197b76c\",\"title\":\"Learning Aligned Cross-Modal Representations from Weakly Aligned Data\",\"url\":\"https://www.semanticscholar.org/paper/7e64992091458256f438fbe1bd44fffcc197b76c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46885959\",\"name\":\"R. Wang\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"1391221164\",\"name\":\"Xufeng Zhang\"},{\"authorId\":\"35043641\",\"name\":\"Jixin Ma\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"}],\"doi\":\"10.1109/ICMEW.2019.00-70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2a8ca7fbb86dc0b8f4d9c4c44e7bffb186c585a\",\"title\":\"A Novel Distance Learning for Elastic Cross-Modal Audio-Visual Matching\",\"url\":\"https://www.semanticscholar.org/paper/a2a8ca7fbb86dc0b8f4d9c4c44e7bffb186c585a\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2019145\",\"name\":\"Vinayak Abrol\"},{\"authorId\":\"2390321\",\"name\":\"P. Sharma\"}],\"doi\":\"10.1109/TASLP.2020.3001969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9ba712e07122c9bf8cdd39d5d5f97f594ad481d\",\"title\":\"Learning Hierarchy Aware Embedding From Raw Audio for Acoustic Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9ba712e07122c9bf8cdd39d5d5f97f594ad481d\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"GRAU DE MATEM\\u00c0TIQUES\"},{\"authorId\":\"1392651751\",\"name\":\"Carlos Vich\\u00e9 Montahud\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55ac97902384dba08c019b992d1774f464866858\",\"title\":\"Treball final de grau\",\"url\":\"https://www.semanticscholar.org/paper/55ac97902384dba08c019b992d1774f464866858\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"2026650249\",\"name\":\"Niccol\\u00f2 Pozzetti\"},{\"authorId\":\"103150889\",\"name\":\"D. Greco\"},{\"authorId\":\"1723008\",\"name\":\"Marco Cristani\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-58542-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8728049700f949a4731ca9d6de73dee8940592bc\",\"title\":\"Leveraging Acoustic Images for Effective Self-supervised Audio Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8728049700f949a4731ca9d6de73dee8940592bc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1805.08545\",\"authors\":[{\"authorId\":\"3116195\",\"name\":\"Arturo Marb\\u00e1n\"},{\"authorId\":\"4365900\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"122748666\",\"name\":\"J. Fern\\u00e1ndez\"},{\"authorId\":\"144921705\",\"name\":\"A. Casals\"}],\"doi\":\"10.1016/j.bspc.2019.01.011\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf27b16f28496d66df75edafc0fb3fa6da87742b\",\"title\":\"A Recurrent Convolutional Neural Network Approach for Sensorless Force Estimation in Robotic Surgery\",\"url\":\"https://www.semanticscholar.org/paper/bf27b16f28496d66df75edafc0fb3fa6da87742b\",\"venue\":\"Biomed. Signal Process. Control.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72500859\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yan Yan\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/ICCV.2019.00639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c2b97b0e02d0b7e02fe4303a6c1894e13b27335\",\"title\":\"Dual Attention Matching for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6c2b97b0e02d0b7e02fe4303a6c1894e13b27335\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2003.04210\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58548-8_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.03478\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866ba646300961747ddc29ce57153858e2be588a\",\"title\":\"Multi-Instrumentalist Net: Unsupervised Generation of Music from Body Movements\",\"url\":\"https://www.semanticscholar.org/paper/866ba646300961747ddc29ce57153858e2be588a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2046898\",\"name\":\"Trevor Scott Standley\"},{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"1924999\",\"name\":\"Dawn Chen\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09c1c3a7693d5790a2be0cab506debf26069bc95\",\"title\":\"image2mass: Estimating the Mass of an Object from Its Image\",\"url\":\"https://www.semanticscholar.org/paper/09c1c3a7693d5790a2be0cab506debf26069bc95\",\"venue\":\"CoRL\",\"year\":2017},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.01851\",\"authors\":[{\"authorId\":\"3393217\",\"name\":\"Dhiraj Gandhi\"},{\"authorId\":\"50179097\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34026610\",\"name\":\"Lerrel Pinto\"}],\"doi\":\"10.15607/RSS.2020.XVI.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f9ee3659c2a855b33ae256e98b05c51b2e30b7\",\"title\":\"Swoosh! Rattle! Thump! - Actions that Sound\",\"url\":\"https://www.semanticscholar.org/paper/c9f9ee3659c2a855b33ae256e98b05c51b2e30b7\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3460423\",\"name\":\"Yichao Yan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1780882\",\"name\":\"W. Zhang\"},{\"authorId\":\"47883221\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/TMM.2018.2885235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7d96828d37c47543fbe9a2a6ce49ea3b44d0178\",\"title\":\"Structure-Constrained Motion Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/e7d96828d37c47543fbe9a2a6ce49ea3b44d0178\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2202838\",\"name\":\"David B. Lindell\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/CVPR.2019.00694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c5b1bbc49e4be0efd98e0b513e0b41659a32413\",\"title\":\"Acoustic Non-Line-Of-Sight Imaging\",\"url\":\"https://www.semanticscholar.org/paper/7c5b1bbc49e4be0efd98e0b513e0b41659a32413\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/ICASSP.2018.8462527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e246fd8721f5718981d735c328d74e50afc0e9d0\",\"title\":\"Seeing Through Noise: Visually Driven Speaker Separation And Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/e246fd8721f5718981d735c328d74e50afc0e9d0\",\"venue\":\"ICASSP\",\"year\":2018},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1911.05371\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55c451f6cf2e96f45678d2dce6075a93129004c8\",\"title\":\"Self-labelling via simultaneous clustering and representation learning\",\"url\":\"https://www.semanticscholar.org/paper/55c451f6cf2e96f45678d2dce6075a93129004c8\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39711148\",\"name\":\"P. Gloor\"},{\"authorId\":\"1389575231\",\"name\":\"Keith April G Arano\"},{\"authorId\":\"151380520\",\"name\":\"Emanuele Guerrazzi\"}],\"doi\":\"10.1007/978-3-030-48993-9_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdd9bdc58a7cf4f50e24d8e3d431c7a54c2056c8\",\"title\":\"Measuring Audience and Actor Emotions at a Theater Play Through Automatic Emotion Recognition from Face, Speech, and Body Sensors\",\"url\":\"https://www.semanticscholar.org/paper/bdd9bdc58a7cf4f50e24d8e3d431c7a54c2056c8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145801638\",\"name\":\"J. Kittler\"},{\"authorId\":\"2745028\",\"name\":\"Ioannis Kaloskampis\"},{\"authorId\":\"1779413\",\"name\":\"Cemre Zor\"},{\"authorId\":\"39418120\",\"name\":\"Yang Xu\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"145879265\",\"name\":\"W. Wang\"}],\"doi\":\"10.1109/ICASSP.2018.8461595\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a4852f9466c1323f5d9ab79610beae45c9958c8\",\"title\":\"Intelligent Signal Processing Mechanisms for Nuanced Anomaly Detection in Action Audio-Visual Data Streams\",\"url\":\"https://www.semanticscholar.org/paper/0a4852f9466c1323f5d9ab79610beae45c9958c8\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1811.00201\",\"authors\":[{\"authorId\":\"16324428\",\"name\":\"Pranay Mukherjee\"},{\"authorId\":\"50317196\",\"name\":\"A. Das\"},{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1109/ICIP.2019.8803717\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4d6bb9700de0ac61f7b3cb284cf269c9a57f283\",\"title\":\"Cogni-Net: Cognitive Feature Learning Through Deep Visual Perception\",\"url\":\"https://www.semanticscholar.org/paper/b4d6bb9700de0ac61f7b3cb284cf269c9a57f283\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"48380309\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"36217631\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67e733b987eb508fdaa60746bf0f5ed4ad192dbe\",\"title\":\"Grounding Spoken Words in Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/67e733b987eb508fdaa60746bf0f5ed4ad192dbe\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152823345\",\"name\":\"M. Sol\\u00e8r\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"153243248\",\"name\":\"A. Krause\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1007/978-3-319-48881-3_59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"title\":\"Suggesting Sounds for Images from Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116195\",\"name\":\"Arturo Marb\\u00e1n\"},{\"authorId\":\"4365900\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"122748666\",\"name\":\"J. Fern\\u00e1ndez\"},{\"authorId\":\"144921705\",\"name\":\"A. Casals\"}],\"doi\":\"10.1109/ICCVW.2017.173\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5beb27e04345b80924a45326243f8ef87f392812\",\"title\":\"Estimating Position & Velocity in 3D Space from Monocular Video Sequences Using a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/5beb27e04345b80924a45326243f8ef87f392812\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1712.09382\",\"authors\":[{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1411184751\",\"name\":\"Hayden Schoen\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"}],\"doi\":\"10.1109/CVPR.2018.00790\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6d60aaad68fa78c914ee34c26bceab033a88622\",\"title\":\"Audio to Body Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/c6d60aaad68fa78c914ee34c26bceab033a88622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.09680\",\"authors\":[{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"46393778\",\"name\":\"Y. Wang\"},{\"authorId\":\"2452082\",\"name\":\"Joseph Szurley\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"46634400\",\"name\":\"S. Das\"}],\"doi\":\"10.1109/ICASSP.2018.8462479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f684cad739a33ff25c817c102d62532c003f21e\",\"title\":\"A Light-Weight Multimodal Framework for Improved Environmental Audio Tagging\",\"url\":\"https://www.semanticscholar.org/paper/1f684cad739a33ff25c817c102d62532c003f21e\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11307648\",\"name\":\"Fernando Moreu\"},{\"authorId\":\"145794243\",\"name\":\"E. Ayorinde\"},{\"authorId\":\"152616176\",\"name\":\"J. Mason\"},{\"authorId\":\"78418118\",\"name\":\"C. Farrar\"},{\"authorId\":\"49699576\",\"name\":\"D. Mascarenas\"}],\"doi\":\"10.1007/s41315-017-0041-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f30a0fe3dac5ea60090d95addfacbd239bd1bd39\",\"title\":\"Remote railroad bridge structural tap testing using aerial robots\",\"url\":\"https://www.semanticscholar.org/paper/f30a0fe3dac5ea60090d95addfacbd239bd1bd39\",\"venue\":\"International Journal of Intelligent Robotics and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898103\",\"name\":\"J. Glass\"}],\"doi\":\"10.1007/s11263-019-01205-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"51346163\",\"name\":\"M. Csail\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48b5289aa08beb10fca58c6a542a597afc359e5d\",\"title\":\"Shared ' Cross + Modal ' Representation religious , * church , * plants\",\"url\":\"https://www.semanticscholar.org/paper/48b5289aa08beb10fca58c6a542a597afc359e5d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145499893\",\"name\":\"Z. Guan\"},{\"authorId\":\"9473013\",\"name\":\"Gangyi Ding\"}],\"doi\":\"10.1016/j.micpro.2020.103048\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85b8d2f080f9bfbcbfcc0ab476c780cdf19c7854\",\"title\":\"Editable video creation based on embedded simulation engine and GAN\",\"url\":\"https://www.semanticscholar.org/paper/85b8d2f080f9bfbcbfcc0ab476c780cdf19c7854\",\"venue\":\"Microprocess. Microsystems\",\"year\":2020},{\"arxivId\":\"2008.00820\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"4506893\",\"name\":\"Hongdong Xiao\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2020.3009820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"title\":\"Generating Visually Aligned Sound From Videos\",\"url\":\"https://www.semanticscholar.org/paper/d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390761515\",\"name\":\"Shashwat Uttam\"},{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"66016321\",\"name\":\"Dhruva Sahrawat\"},{\"authorId\":\"145451222\",\"name\":\"Mansi Aggarwal\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"2712224\",\"name\":\"Debanjan Mahata\"},{\"authorId\":\"1690152\",\"name\":\"Amanda Stent\"}],\"doi\":\"10.21437/interspeech.2019-3269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec9fda5db1ced6058824ce0c8fe9cb6e1d20c24e\",\"title\":\"Hush-Hush Speak: Speech Reconstruction Using Silent Videos\",\"url\":\"https://www.semanticscholar.org/paper/ec9fda5db1ced6058824ce0c8fe9cb6e1d20c24e\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"2004.02205\",\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e908719ae2a09e3726300df65bcd31dfddea5a86\",\"title\":\"Deep Multimodal Feature Encoding for Video Ordering\",\"url\":\"https://www.semanticscholar.org/paper/e908719ae2a09e3726300df65bcd31dfddea5a86\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.06217\",\"authors\":[{\"authorId\":\"8806222\",\"name\":\"Carlo Innamorati\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"145794288\",\"name\":\"D. Kaufman\"},{\"authorId\":\"1710455\",\"name\":\"N. Mitra\"}],\"doi\":\"10.1109/ICCV.2019.00881\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ea024b69849e80cb0e3de35ba1d5725fa41595c\",\"title\":\"Neural Re-Simulation for Generating Bounces in Single Images\",\"url\":\"https://www.semanticscholar.org/paper/4ea024b69849e80cb0e3de35ba1d5725fa41595c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2006.14613\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78b00f2abbf7523a860e717f767b0bb8f860143\",\"title\":\"Space-Time Correspondence as a Contrastive Random Walk\",\"url\":\"https://www.semanticscholar.org/paper/c78b00f2abbf7523a860e717f767b0bb8f860143\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1904.09115\",\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00816\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6ccd4369781ccc31bd6e08a837d4ab0d9ddda4c\",\"title\":\"Listen to the Image\",\"url\":\"https://www.semanticscholar.org/paper/e6ccd4369781ccc31bd6e08a837d4ab0d9ddda4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1706.00932\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"title\":\"See, Hear, and Read: Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40579588\",\"name\":\"H. Komatsu\"},{\"authorId\":\"40345648\",\"name\":\"N. Goda\"}],\"doi\":\"10.1016/j.neuroscience.2018.09.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e87cb08a0e9006207e6fd8a66b0a7692127fa9\",\"title\":\"Neural mechanisms of material perception: quest on Shitsukan\",\"url\":\"https://www.semanticscholar.org/paper/a6e87cb08a0e9006207e6fd8a66b0a7692127fa9\",\"venue\":\"Neuroscience\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144882773\",\"name\":\"Arnau Bar\\u00f3\"},{\"authorId\":\"40420775\",\"name\":\"Pau Riba\"},{\"authorId\":\"1388521984\",\"name\":\"Jorge Calvo-Zaragoza\"},{\"authorId\":\"1686569\",\"name\":\"A. Forn\\u00e9s\"}],\"doi\":\"10.1007/978-3-030-02284-6_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3c337a1b48086ea8df89edecf58592527fdf40e\",\"title\":\"Optical Music Recognition by Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/d3c337a1b48086ea8df89edecf58592527fdf40e\",\"venue\":\"GREC\",\"year\":2017},{\"arxivId\":\"1911.02001\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"47008546\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"153699069\",\"name\":\"Mingyu Liu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"8646392\",\"name\":\"Yu-Ding Lu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"title\":\"Dancing to Music\",\"url\":\"https://www.semanticscholar.org/paper/12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35256518\",\"name\":\"A. L. Ngo\"},{\"authorId\":\"145016295\",\"name\":\"R. Phan\"}],\"doi\":\"10.1145/3355389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c8fb20f3c38c0386594e481ca71836d6bfd9393\",\"title\":\"Seeing the Invisible\",\"url\":\"https://www.semanticscholar.org/paper/8c8fb20f3c38c0386594e481ca71836d6bfd9393\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.11474\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58539-6_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47ef056ac57e83405f9ee63c32c6a185011d187\",\"title\":\"SoundSpaces: Audio-Visual Navigation in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/c47ef056ac57e83405f9ee63c32c6a185011d187\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51301205\",\"name\":\"Shir Goldstein\"},{\"authorId\":\"2957934\",\"name\":\"Y. Moses\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6956e43cf061d55b8db83989dff7f447287fad9\",\"title\":\"Guitar Music Transcription from Silent Video\",\"url\":\"https://www.semanticscholar.org/paper/d6956e43cf061d55b8db83989dff7f447287fad9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"2173143\",\"name\":\"C. Zhang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"48707717\",\"name\":\"Z. Wang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-11024-6_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"title\":\"Visually Indicated Sound Generation by Perceptually Optimized Classification\",\"url\":\"https://www.semanticscholar.org/paper/d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152420788\",\"name\":\"Mohit Sewak\"}],\"doi\":\"10.1007/978-981-13-8285-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b457d0dcc7419fb6532dc444839773f983ac9109\",\"title\":\"Deep Reinforcement Learning: Frontiers of Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/b457d0dcc7419fb6532dc444839773f983ac9109\",\"venue\":\"Springer Singapore\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48359318\",\"name\":\"Sanchita Ghose\"},{\"authorId\":\"39409158\",\"name\":\"John J. Prevost\"}],\"doi\":\"10.1109/SoSE50414.2020.9130483\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"06525364255afaa0a159edd4204e6a561174579f\",\"title\":\"Enabling an IoT System of Systems through Auto Sound Synthesis in Silent Video with DNN\",\"url\":\"https://www.semanticscholar.org/paper/06525364255afaa0a159edd4204e6a561174579f\",\"venue\":\"2020 IEEE 15th International Conference of System of Systems Engineering (SoSE)\",\"year\":2020},{\"arxivId\":\"1904.01766\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"49588480\",\"name\":\"A. Myers\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2019.00756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c41a11c0e9b8b92b4faaf97749841170b760760a\",\"title\":\"VideoBERT: A Joint Model for Video and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/c41a11c0e9b8b92b4faaf97749841170b760760a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"}],\"doi\":\"10.1109/TGRS.2019.2951636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a86714cb7ac711054244aeea51a55715e679ebb\",\"title\":\"Sound Active Attention Framework for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2a86714cb7ac711054244aeea51a55715e679ebb\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1415029348\",\"name\":\"Norberto Torres-Reyes\"},{\"authorId\":\"143935167\",\"name\":\"S. Latifi\"}],\"doi\":\"10.5120/IJCA2019918334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54dd66fbc59fbdfbd4cb29b966287e0b6982b703\",\"title\":\"Audio Enhancement and Synthesis using Generative Adversarial Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/54dd66fbc59fbdfbd4cb29b966287e0b6982b703\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3260490\",\"name\":\"S. Wang\"},{\"authorId\":\"38244340\",\"name\":\"Pangfeng Liu\"},{\"authorId\":\"1726584\",\"name\":\"Jan-Jan Wu\"}],\"doi\":\"10.1145/3301326.3301347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2cc4ae8f4c7578239e7c626b658fd3dac58819\",\"title\":\"Communication Usage Optimization of Gradient Sparsification with Aggregation in Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/aa2cc4ae8f4c7578239e7c626b658fd3dac58819\",\"venue\":\"ICNCC 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"1705.02966\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.31.109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8632cf6c1ef4319966564328d187876d3bef363\",\"title\":\"You said that?\",\"url\":\"https://www.semanticscholar.org/paper/a8632cf6c1ef4319966564328d187876d3bef363\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1904.06827\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145794288\",\"name\":\"D. Kaufman\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b39399b1b7c8d2950109b645552439a712913bf1\",\"title\":\"Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces\",\"url\":\"https://www.semanticscholar.org/paper/b39399b1b7c8d2950109b645552439a712913bf1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1907.13098\",\"authors\":[{\"authorId\":\"14656092\",\"name\":\"M. Lee\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1389620826\",\"name\":\"Peter Zachares\"},{\"authorId\":\"144323731\",\"name\":\"Matthew Tan\"},{\"authorId\":\"1391084712\",\"name\":\"K. Srinivasan\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"3245752\",\"name\":\"Feifei Li\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/TRO.2019.2959445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1be579f4c120a8bf15c4df78d622549913b4d8f7\",\"title\":\"Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks\",\"url\":\"https://www.semanticscholar.org/paper/1be579f4c120a8bf15c4df78d622549913b4d8f7\",\"venue\":\"IEEE Transactions on Robotics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98727476\",\"name\":\"Tsan-Hwei Huang\"},{\"authorId\":\"2024357948\",\"name\":\"Hunter Hsieh\"},{\"authorId\":\"2025282857\",\"name\":\"Jiaqi Qin\"},{\"authorId\":\"2024727250\",\"name\":\"Hsien-Fung Liu\"},{\"authorId\":\"2377003\",\"name\":\"M. Eirinaki\"}],\"doi\":\"10.1109/TransAI49837.2020.00008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"title\":\"Play it again IMuCo! Music Composition to Match your Mood\",\"url\":\"https://www.semanticscholar.org/paper/30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"venue\":\"2020 Second International Conference on Transdisciplinary AI (TransAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50394552\",\"name\":\"Rui Lu\"},{\"authorId\":\"72028302\",\"name\":\"Zhiyao Duan\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TASLP.2019.2928140\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90f8b5d87c41230c691e6a243aef9d62063522b0\",\"title\":\"Audio\\u2013Visual Deep Clustering for Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/90f8b5d87c41230c691e6a243aef9d62063522b0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2019.00213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"title\":\"Learning Words by Drawing Images\",\"url\":\"https://www.semanticscholar.org/paper/bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1701.00495\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/ICASSP.2017.7953127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c87c275ddde2e0b75264fe9dad7b130db410601\",\"title\":\"Vid2speech: Speech reconstruction from silent video\",\"url\":\"https://www.semanticscholar.org/paper/5c87c275ddde2e0b75264fe9dad7b130db410601\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993656259\",\"name\":\"Xutong Jin\"},{\"authorId\":\"66841398\",\"name\":\"S. Li\"},{\"authorId\":\"48821625\",\"name\":\"T. Qu\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"},{\"authorId\":\"50248637\",\"name\":\"Guoping Wang\"}],\"doi\":\"10.1145/3394171.3413572\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc316c6c3f2f55f03e486536a5850752df49bb84\",\"title\":\"Deep-Modal: Real-Time Impact Sound Synthesis for Arbitrary Shapes\",\"url\":\"https://www.semanticscholar.org/paper/dc316c6c3f2f55f03e486536a5850752df49bb84\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1805.05553\",\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-20873-8_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"title\":\"On Learning Associations of Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211940\",\"name\":\"H. Guan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ROBIO.2016.7866570\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d7bc3d6d3e965e153f705664c58160fe1c6ef22\",\"title\":\"Multi-sensory based novel household object categorization system by using interactive behaviours\",\"url\":\"https://www.semanticscholar.org/paper/3d7bc3d6d3e965e153f705664c58160fe1c6ef22\",\"venue\":\"2016 IEEE International Conference on Robotics and Biomimetics (ROBIO)\",\"year\":2016},{\"arxivId\":\"1801.03924\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c468bbde6a22d961829e1970e6ad5795e05418d1\",\"title\":\"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\",\"url\":\"https://www.semanticscholar.org/paper/c468bbde6a22d961829e1970e6ad5795e05418d1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.00971\",\"authors\":[{\"authorId\":\"52193502\",\"name\":\"Mitchell Wortsman\"},{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00691\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d21334ea3564c89586e1ba176e11382bdd3d394\",\"title\":\"Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/4d21334ea3564c89586e1ba176e11382bdd3d394\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.05538\",\"authors\":[{\"authorId\":\"153318498\",\"name\":\"Shiguang Liu\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"770a44ea4c18d2a62c24b1f2758743d04d357e45\",\"title\":\"Sound Synthesis, Propagation, and Rendering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/770a44ea4c18d2a62c24b1f2758743d04d357e45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":null,\"name\":\"joon Amir Jamaludin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b24ef13fc9a51a9892f164bc142ffefc0b7a8ee\",\"title\":\"CHUNG , JAMALUDIN , ZISSERMAN : YOU SAID THAT ? 1 You said that ?\",\"url\":\"https://www.semanticscholar.org/paper/5b24ef13fc9a51a9892f164bc142ffefc0b7a8ee\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3270255\",\"name\":\"Arindam Jati\"},{\"authorId\":\"145743058\",\"name\":\"N. Kumar\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"1765829\",\"name\":\"P. Georgiou\"}],\"doi\":\"10.1109/ICASSP.2019.8682341\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09f8343d00866cf1280700b9c45832f6a1f96a27\",\"title\":\"Hierarchy-aware Loss Function on a Tree Structured Label Space for Audio Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/09f8343d00866cf1280700b9c45832f6a1f96a27\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2604835\",\"name\":\"S. Pirk\"},{\"authorId\":\"30559411\",\"name\":\"Mohi Khansari\"},{\"authorId\":\"46931507\",\"name\":\"Yunfei Bai\"},{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"}],\"doi\":\"10.1109/ICRA40945.2020.9196567\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7dd066222e537c34ea5b9b4ddcd3f9c58dd80d1c\",\"title\":\"Online Learning of Object Representations by Appearance Space Feature Alignment\",\"url\":\"https://www.semanticscholar.org/paper/7dd066222e537c34ea5b9b4ddcd3f9c58dd80d1c\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134734745\",\"name\":\"Sandra Malpica\"},{\"authorId\":\"116241751\",\"name\":\"A. Serrano\"},{\"authorId\":\"25638028\",\"name\":\"M. Allu\\u00e9\"},{\"authorId\":\"120772133\",\"name\":\"M. Bedia\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"}],\"doi\":\"10.1007/s11042-019-7331-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdd169d3b96086716c7eb445f74b2475e16f06cc\",\"title\":\"Crossmodal perception in virtual reality\",\"url\":\"https://www.semanticscholar.org/paper/fdd169d3b96086716c7eb445f74b2475e16f06cc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2020.2969791\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"title\":\"Multimedia Intelligence: When Multimedia Meets Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"3493789\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1007/978-3-030-31726-3_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fd9462b383033ac1e32964d9219a8636d98be18\",\"title\":\"Deep Voice-Visual Cross-Modal Retrieval with Deep Feature Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/6fd9462b383033ac1e32964d9219a8636d98be18\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50131290\",\"name\":\"M. Yasuda\"},{\"authorId\":\"2991962\",\"name\":\"Y. Ohishi\"},{\"authorId\":\"67318326\",\"name\":\"Y. Koizumi\"},{\"authorId\":\"145752315\",\"name\":\"N. Harada\"}],\"doi\":\"10.21437/interspeech.2020-2445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81da4385a561b48763d140be8bbb30212bbd467d\",\"title\":\"Crossmodal Sound Retrieval Based on Specific Target Co-Occurrence Denoted with Weak Labels\",\"url\":\"https://www.semanticscholar.org/paper/81da4385a561b48763d140be8bbb30212bbd467d\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2008.04237\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58523-5_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0eb79a085e014f129b063199a38fe9945355c137\",\"title\":\"Self-Supervised Learning of Audio-Visual Objects from Video\",\"url\":\"https://www.semanticscholar.org/paper/0eb79a085e014f129b063199a38fe9945355c137\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.15470\",\"authors\":[{\"authorId\":null,\"name\":\"Senthil Purushwalkam\"},{\"authorId\":null,\"name\":\"Sebastian Vicenc Amengual Gari\"},{\"authorId\":null,\"name\":\"Vamsi Krishna Ithapu\"},{\"authorId\":null,\"name\":\"Carl Schissler\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Kristen Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6f3c6927b15b035e501727fe5c4e6459f09f9a8\",\"title\":\"Audio-Visual Floorplan Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/f6f3c6927b15b035e501727fe5c4e6459f09f9a8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50841319\",\"name\":\"Jyoti Shokeen\"},{\"authorId\":\"2960442\",\"name\":\"C. Rana\"}],\"doi\":\"10.5815/ijisa.2019.05.06\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4acb6c83f2d10faaf89e999d6be330742e3dd8da\",\"title\":\"An Application-oriented Review of Deep Learning in Recommender Systems\",\"url\":\"https://www.semanticscholar.org/paper/4acb6c83f2d10faaf89e999d6be330742e3dd8da\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.14487\",\"authors\":[{\"authorId\":\"94314731\",\"name\":\"Matthew Purri\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-58583-9_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"title\":\"Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images\",\"url\":\"https://www.semanticscholar.org/paper/dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1808.04572\",\"authors\":[{\"authorId\":\"38741604\",\"name\":\"Jun Shu\"},{\"authorId\":\"7814629\",\"name\":\"Zongben Xu\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d510bca00b625f86606cb0096299b993090534a\",\"title\":\"Small Sample Learning in Big Data Era\",\"url\":\"https://www.semanticscholar.org/paper/4d510bca00b625f86606cb0096299b993090534a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.10827\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"2456400\",\"name\":\"Hessam Bagherinezhad\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00426\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a63b8429ebeef316a65a94b021ef9a214c705f83\",\"title\":\"Who Let the Dogs Out? Modeling Dog Behavior from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/a63b8429ebeef316a65a94b021ef9a214c705f83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2010.12013\",\"authors\":[{\"authorId\":\"3209509\",\"name\":\"Rui-Lin Xu\"},{\"authorId\":\"1406236938\",\"name\":\"Rundi Wu\"},{\"authorId\":\"1443787627\",\"name\":\"Yuko Ishiwaka\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"46882430\",\"name\":\"C. Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1d16d4a122e3a6d6db5e959dad03055e3955444\",\"title\":\"Listening to Sounds of Silence for Speech Denoising\",\"url\":\"https://www.semanticscholar.org/paper/f1d16d4a122e3a6d6db5e959dad03055e3955444\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50477900\",\"name\":\"Takuya Koumura\"},{\"authorId\":\"2254764\",\"name\":\"S. Furukawa\"}],\"doi\":\"10.1038/s41598-017-16651-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"733f747946b63ae114228d122e04ee2528fca599\",\"title\":\"Context-Dependent Effect of Reverberation on Material Perception from Impact Sound\",\"url\":\"https://www.semanticscholar.org/paper/733f747946b63ae114228d122e04ee2528fca599\",\"venue\":\"Scientific Reports\",\"year\":2017},{\"arxivId\":\"1611.01843\",\"authors\":[{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f3a8cf93c1e006616c38d6c34fbedf8eb0a50cc\",\"title\":\"Learning to Perform Physics Experiments via Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3a8cf93c1e006616c38d6c34fbedf8eb0a50cc\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1808.04108\",\"authors\":[{\"authorId\":\"35508795\",\"name\":\"Chia-Hung Wan\"},{\"authorId\":\"7146976\",\"name\":\"Shun-Po Chuang\"},{\"authorId\":\"144300094\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.1109/ICASSP.2019.8682383\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"908c342d66137f5e70544e8204951f28cb02deb0\",\"title\":\"Towards Audio to Scene Image Synthesis Using Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/908c342d66137f5e70544e8204951f28cb02deb0\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2024547613\",\"name\":\"George Guan\"},{\"authorId\":\"1596816919\",\"name\":\"Fuquan Zhang\"},{\"authorId\":\"1596816919\",\"name\":\"Fuquan Zhang\"},{\"authorId\":\"9473013\",\"name\":\"Gangyi Ding\"},{\"authorId\":\"2024268002\",\"name\":\"Meng Niu\"},{\"authorId\":\"91882598\",\"name\":\"Liguo Xu\"}],\"doi\":\"10.1007/978-3-319-70730-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ae8ec195f58ca877b5b74d2fc1d41e647a9710b\",\"title\":\"A Video Coloring Method Based on CNN and Feature Point Tracking\",\"url\":\"https://www.semanticscholar.org/paper/5ae8ec195f58ca877b5b74d2fc1d41e647a9710b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144248892\",\"name\":\"C. Spence\"}],\"doi\":\"10.1163/22134808-bja10003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"139cbaa1027f5b43a31936b1d4cf6fe152a603e8\",\"title\":\"Shitsukan\\u00a0- the Multisensory Perception of Quality.\",\"url\":\"https://www.semanticscholar.org/paper/139cbaa1027f5b43a31936b1d4cf6fe152a603e8\",\"venue\":\"Multisensory research\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40122680\",\"name\":\"M. Weger\"},{\"authorId\":\"1779788\",\"name\":\"R. H\\u00f6ldrich\"}],\"doi\":\"10.1145/3356590.3356593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"097d27da0f5de6096ecd065442b46a3d39ce9b06\",\"title\":\"A hear-through system for plausible auditory contrast enhancement\",\"url\":\"https://www.semanticscholar.org/paper/097d27da0f5de6096ecd065442b46a3d39ce9b06\",\"venue\":\"Audio Mostly Conference\",\"year\":2019},{\"arxivId\":\"2002.10981\",\"authors\":[{\"authorId\":\"48359318\",\"name\":\"Sanchita Ghose\"},{\"authorId\":\"2845029\",\"name\":\"John J. Prevost\"}],\"doi\":\"10.1109/TMM.2020.3005033\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1337db4d3283e77e959a683ef5cb15949f1d5400\",\"title\":\"AutoFoley: Artificial Synthesis of Synchronized Sound Tracks for Silent Videos with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1337db4d3283e77e959a683ef5cb15949f1d5400\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9f86d087e84eaf0e6a09575982aa7b41fa62451\",\"title\":\"Image Synthesis for Self-Supervised Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f9f86d087e84eaf0e6a09575982aa7b41fa62451\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.04104\",\"authors\":[{\"authorId\":\"49019816\",\"name\":\"Zengming Shen\"},{\"authorId\":\"1774449\",\"name\":\"Y. Chen\"},{\"authorId\":\"152856676\",\"name\":\"S. Zhou\"},{\"authorId\":\"1388066189\",\"name\":\"B. Georgescu\"},{\"authorId\":\"97713285\",\"name\":\"X. Liu\"},{\"authorId\":\"3371621\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"809703f7ae5aa77171a1d8079041d574f897b1db\",\"title\":\"Towards Learning a Self-inverse Network for Bidirectional Image-to-image Translation\",\"url\":\"https://www.semanticscholar.org/paper/809703f7ae5aa77171a1d8079041d574f897b1db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145816931\",\"name\":\"Gaurav Verma\"},{\"authorId\":\"1519982037\",\"name\":\"Suryateja Bv\"},{\"authorId\":\"1519989202\",\"name\":\"Samagra Sharma\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"}],\"doi\":\"10.1145/3377325.3377487\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"893154dbcd6c6c6d1c4913002de37d6e739cf5f2\",\"title\":\"Generating need-adapted multimodal fragments\",\"url\":\"https://www.semanticscholar.org/paper/893154dbcd6c6c6d1c4913002de37d6e739cf5f2\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":\"2004.14368\",\"authors\":[{\"authorId\":\"1390823178\",\"name\":\"Honglie Chen\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66831f683141c11ed7e20b0f2e8b40700740c164\",\"title\":\"Vggsound: A Large-Scale Audio-Visual Dataset\",\"url\":\"https://www.semanticscholar.org/paper/66831f683141c11ed7e20b0f2e8b40700740c164\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1711.08789\",\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f04d8a78cd33ac944353c55d3d40230ef504f449\",\"title\":\"Visual Speech Enhancement using Noise-Invariant Training\",\"url\":\"https://www.semanticscholar.org/paper/f04d8a78cd33ac944353c55d3d40230ef504f449\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1905.09773\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1109/CVPR.2019.00772\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"title\":\"Speech2Face: Learning the Face Behind a Voice\",\"url\":\"https://www.semanticscholar.org/paper/e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40069761\",\"name\":\"Auston Sterling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9e404eb374035b8a79b45ef4fcb6f728f4372ef2\",\"title\":\"AUDIO-MATERIAL MODELING AND RECONSTRUCTION FOR MULTIMODAL INTERACTION\",\"url\":\"https://www.semanticscholar.org/paper/9e404eb374035b8a79b45ef4fcb6f728f4372ef2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.00305\",\"authors\":[{\"authorId\":\"1973062\",\"name\":\"Omid Poursaeed\"},{\"authorId\":\"31531866\",\"name\":\"Tianxing Jiang\"},{\"authorId\":\"1850349772\",\"name\":\"Quintessa Qiao\"},{\"authorId\":\"35718053\",\"name\":\"N. Xu\"},{\"authorId\":\"3082383\",\"name\":\"Vladimir G. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97da14337c54a6d055e2947b500af94bc5537a12\",\"title\":\"Self-supervised Learning of Point Clouds via Orientation Estimation\",\"url\":\"https://www.semanticscholar.org/paper/97da14337c54a6d055e2947b500af94bc5537a12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502450\",\"name\":\"C. Hsu\"},{\"authorId\":\"1583964783\",\"name\":\"Abbas Zeitoun\"},{\"authorId\":\"2141495\",\"name\":\"Guang-He Lee\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"},{\"authorId\":\"35132120\",\"name\":\"T. Jaakkola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab699bc0208256d01f7cf5cb1290e2632279534\",\"title\":\"Self-Supervised Learning of Appliance Usage\",\"url\":\"https://www.semanticscholar.org/paper/3ab699bc0208256d01f7cf5cb1290e2632279534\",\"venue\":\"ICLR\",\"year\":2020}],\"corpusId\":1697911,\"doi\":\"10.1109/CVPR.2016.264\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":9,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"6903801\",\"name\":\"B. Glasberg\"},{\"authorId\":\"145167842\",\"name\":\"B. Moore\"}],\"doi\":\"10.1016/0378-5955(90)90170-T\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b33c93114e079ea7a93f42dc516ade92aade5390\",\"title\":\"Derivation of auditory filter shapes from notched-noise data\",\"url\":\"https://www.semanticscholar.org/paper/b33c93114e079ea7a93f42dc516ade92aade5390\",\"venue\":\"Hearing Research\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Davis\"},{\"authorId\":null,\"name\":\"K L Bouman\"},{\"authorId\":null,\"name\":\"M Rubinstein\"},{\"authorId\":null,\"name\":\"F Durand\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Freeman. Visual vibrometry: Estimating material properties from small motion in video\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3935cabb73d75939ade5fc8839cfd946fbdc8057\",\"title\":\"Learning image representations equivariant to ego-motion\",\"url\":\"https://www.semanticscholar.org/paper/3935cabb73d75939ade5fc8839cfd946fbdc8057\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1505.05192\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2015.167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"title\":\"Unsupervised Visual Representation Learning by Context Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670479\",\"name\":\"L. Schulz\"}],\"doi\":\"10.1016/j.tics.2012.06.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5c602afb195c2203b1fe1138c5c6f6184f61da6\",\"title\":\"The origins of inquiry: inductive inference and exploration in early childhood\",\"url\":\"https://www.semanticscholar.org/paper/a5c602afb195c2203b1fe1138c5c6f6184f61da6\",\"venue\":\"Trends in Cognitive Sciences\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3742713\",\"name\":\"R. Lutfi\"}],\"doi\":\"10.1007/978-0-387-71305-2_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c092d7173a86c8c04e5ccee393e542b817d9569\",\"title\":\"Human Sound Source Identification\",\"url\":\"https://www.semanticscholar.org/paper/6c092d7173a86c8c04e5ccee393e542b817d9569\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"title\":\"Unsupervised Learning of Visual Representations using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2730646\",\"name\":\"Mevlana Gemici\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/IROS.2014.6942626\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0dcca4fa447a14496f0143c211fd40a54039b98\",\"title\":\"Learning haptic representation for manipulating deformable food objects\",\"url\":\"https://www.semanticscholar.org/paper/e0dcca4fa447a14496f0143c211fd40a54039b98\",\"venue\":\"2014 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2014},{\"arxivId\":\"1511.06811\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2944502\",\"name\":\"Daniel Zoran\"},{\"authorId\":\"1707347\",\"name\":\"Dilip Krishnan\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5253cf4f3b1eeb63a07982b0e9e42e7d267d767e\",\"title\":\"Learning visual groups from co-occurrences in space and time\",\"url\":\"https://www.semanticscholar.org/paper/5253cf4f3b1eeb63a07982b0e9e42e7d267d767e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Rubinstein A. Davis\"},{\"authorId\":null,\"name\":\"N. Wadhwa\"},{\"authorId\":null,\"name\":\"G. J. Mysore\"},{\"authorId\":null,\"name\":\"F. Durand\"},{\"authorId\":null,\"name\":\"W. T. Freeman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Free - man . Visual vibrometry : Estimating material properties from small motion in video\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1492fdd62030ccd0fd219888d8530b7e842847dc\",\"title\":\"Pattern Playback in the 90s\",\"url\":\"https://www.semanticscholar.org/paper/1492fdd62030ccd0fd219888d8530b7e842847dc\",\"venue\":\"NIPS\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. A. Shabana\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Theory of vibration: an introduction, volume 1\",\"url\":\"\",\"venue\":\"Springer Science & Business Media,\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1601.02220\",\"authors\":[{\"authorId\":\"31638576\",\"name\":\"A. Arnab\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143777501\",\"name\":\"Stuart Golodetz\"},{\"authorId\":\"39596866\",\"name\":\"Julien P. C. Valentin\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"},{\"authorId\":\"79406746\",\"name\":\"S. Izadi\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.5244/C.29.40\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e3e6c68a2106129c66a05522b58af3d0c2600f\",\"title\":\"Joint Object-Material Category Segmentation from Audio-Visual Cues\",\"url\":\"https://www.semanticscholar.org/paper/54e3e6c68a2106129c66a05522b58af3d0c2600f\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49041437\",\"name\":\"M. Kac\"}],\"doi\":\"10.1080/00029890.1966.11970915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a26bb6f1a849f185019dce64529b453e1f3996ff\",\"title\":\"Can One Hear the Shape of a Drum\",\"url\":\"https://www.semanticscholar.org/paper/a26bb6f1a849f185019dce64529b453e1f3996ff\",\"venue\":\"\",\"year\":1966},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145336510\",\"name\":\"A. Shabana\"}],\"doi\":\"10.1007/978-3-319-94271-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13015346447dd7b8b846c5916dfe703d2fe9c87c\",\"title\":\"Theory of Vibration: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/13015346447dd7b8b846c5916dfe703d2fe9c87c\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1505.02206\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2015.166\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c426ba865e9158a0f7962a86a50575aa943051b1\",\"title\":\"Learning Image Representations Tied to Ego-Motion\",\"url\":\"https://www.semanticscholar.org/paper/c426ba865e9158a0f7962a86a50575aa943051b1\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6226925\",\"name\":\"R. Baillargeon\"}],\"doi\":\"10.1002/9780470996652.CH3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"062eb9ba6ad869599e6c7b6bca9cd3518096a232\",\"title\":\"The Acquisition of Physical Knowledge in Infancy: A Summary in Eight Lessons\",\"url\":\"https://www.semanticscholar.org/paper/062eb9ba6ad869599e6c7b6bca9cd3518096a232\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"S. Karayev\"},{\"authorId\":null,\"name\":\"J. Long\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"S. Guadarrama\"},{\"authorId\":null,\"name\":\"T. Darrell.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ioffe and C . Szegedy . Batch normalization : Accelerating deep network training by reducing internal covariate shift 3 d convolutional neural networks for human action recognition\",\"url\":\"\",\"venue\":\"Pattern Analysis and Machine Intelligence , IEEE Transactions on\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3232655\",\"name\":\"H. Mobahi\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553469\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2c477de72bb7718f5304c6f38457fda9c8334b1\",\"title\":\"Deep learning from temporal coherence in video\",\"url\":\"https://www.semanticscholar.org/paper/e2c477de72bb7718f5304c6f38457fda9c8334b1\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2780072\",\"name\":\"Terri L. Bonebright\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66c7585be7ff16589203517f96c45db7218b6f7a\",\"title\":\"COCONUTS OR HORSE HOOFS ? VISUAL CONTEXT EFFECTS ON IDENTIFICATION AND PERCEIVED VERACITY OF EVERYDAY SOUNDS\",\"url\":\"https://www.semanticscholar.org/paper/66c7585be7ff16589203517f96c45db7218b6f7a\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1505.01596\",\"authors\":[{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfbfaaec46d38392f61d683c340ee92a0a66e5d9\",\"title\":\"Learning to See by Moving\",\"url\":\"https://www.semanticscholar.org/paper/dfbfaaec46d38392f61d683c340ee92a0a66e5d9\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2240195\",\"name\":\"L. Sharan\"},{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"1680975\",\"name\":\"R. Rosenholtz\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"}],\"doi\":\"10.1007/s11263-013-0609-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"392e3f9ab733264f938cdf7c4ebbfb4dc94ff919\",\"title\":\"Recognizing Materials Using Perceptually Inspired Features\",\"url\":\"https://www.semanticscholar.org/paper/392e3f9ab733264f938cdf7c4ebbfb4dc94ff919\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"000 ms coco images in 5 minutes\",\"url\":\"\",\"venue\":\"000 ms coco images in 5 minutes\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34894065\",\"name\":\"J. Bello\"},{\"authorId\":\"1742040\",\"name\":\"L. Daudet\"},{\"authorId\":\"34212067\",\"name\":\"Samer A. Abdallah\"},{\"authorId\":\"2848576\",\"name\":\"C. Duxbury\"},{\"authorId\":\"144113976\",\"name\":\"M. Davies\"},{\"authorId\":\"40764812\",\"name\":\"M. Sandler\"}],\"doi\":\"10.1109/TSA.2005.851998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe8d91583cf2638f9ff066c99ec75afb407da87f\",\"title\":\"A tutorial on onset detection in music signals\",\"url\":\"https://www.semanticscholar.org/paper/fe8d91583cf2638f9ff066c99ec75afb407da87f\",\"venue\":\"IEEE Transactions on Speech and Audio Processing\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749989\",\"name\":\"Z. Ling\"},{\"authorId\":\"2193534\",\"name\":\"Shiyin Kang\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"7565008\",\"name\":\"Xiaojun Qian\"},{\"authorId\":\"145199941\",\"name\":\"H. Meng\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2014.2359987\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"849c9a0b3c76c7e65e3e5f0bdfd56921731ea043\",\"title\":\"Deep Learning for Acoustic Modeling in Parametric Speech Generation: A systematic review of existing techniques and future trends\",\"url\":\"https://www.semanticscholar.org/paper/849c9a0b3c76c7e65e3e5f0bdfd56921731ea043\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2015},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30364688\",\"name\":\"M. Siegel\"},{\"authorId\":\"2572818\",\"name\":\"Rachel Magid\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144877155\",\"name\":\"L. Schulz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e00b4b9b534aa25c10a3478e07418d56fe9053af\",\"title\":\"Black boxes: Hypothesis testing via indirect perceptual evidence\",\"url\":\"https://www.semanticscholar.org/paper/e00b4b9b534aa25c10a3478e07418d56fe9053af\",\"venue\":\"CogSci\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Hu\"},{\"authorId\":null,\"name\":\"P C Loizou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Speech enhancement based on wavelet thresholding the multitaper spectrum. Speech and Audio Processing\",\"url\":\"\",\"venue\":\"IEEE Transactions on\",\"year\":2004},{\"arxivId\":\"1504.08023\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fb3b63090f95af97723efe565893eb25ea9188c\",\"title\":\"Anticipating the future by watching unlabeled video\",\"url\":\"https://www.semanticscholar.org/paper/0fb3b63090f95af97723efe565893eb25ea9188c\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1504.02518\",\"authors\":[{\"authorId\":\"2558463\",\"name\":\"R. Goroshin\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"2060028\",\"name\":\"D. Eigen\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"394cbf2d589eadcfbdbdaaed65c77532b9c856af\",\"title\":\"Unsupervised Feature Learning from Temporal Data\",\"url\":\"https://www.semanticscholar.org/paper/394cbf2d589eadcfbdbdaaed65c77532b9c856af\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153669825\",\"name\":\"P-J Hsieh\"},{\"authorId\":\"4462940\",\"name\":\"J. Colas\"},{\"authorId\":\"1931482\",\"name\":\"N. Kanwisher\"}],\"doi\":\"10.1152/jn.01094.2010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edb7bc689e68d119c9afa7c9275cb97bfab10ecc\",\"title\":\"Spatial pattern of BOLD fMRI activation reveals cross-modal information in auditory cortex.\",\"url\":\"https://www.semanticscholar.org/paper/edb7bc689e68d119c9afa7c9275cb97bfab10ecc\",\"venue\":\"Journal of neurophysiology\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46972251\",\"name\":\"Y. Hu\"},{\"authorId\":\"1759800\",\"name\":\"P. Loizou\"}],\"doi\":\"10.1109/TSA.2003.819949\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93ff7a1929d1d029e61495c434a73fc715eb44e4\",\"title\":\"Speech enhancement based on wavelet thresholding the multitaper spectrum\",\"url\":\"https://www.semanticscholar.org/paper/93ff7a1929d1d029e61495c434a73fc715eb44e4\",\"venue\":\"IEEE Transactions on Speech and Audio Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103797937\",\"name\":\"Luuk Verhoeven\"},{\"authorId\":\"69365456\",\"name\":\"W. D. Suijlekom\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"757fb29bd1a6958f6593e708bc4a5ecabcebfba1\",\"title\":\"Can one Hear the Shape of a Drum?\",\"url\":\"https://www.semanticscholar.org/paper/757fb29bd1a6958f6593e708bc4a5ecabcebfba1\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715858\",\"name\":\"J. Sinapov\"},{\"authorId\":\"32011288\",\"name\":\"Mark Wiemer\"},{\"authorId\":\"3245286\",\"name\":\"A. Stoytchev\"}],\"doi\":\"10.1109/ROBOT.2009.5152802\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"29361be99bcb16256b510d512d62aff60246a1b3\",\"title\":\"Interactive learning of the acoustic properties of household objects\",\"url\":\"https://www.semanticscholar.org/paper/29361be99bcb16256b510d512d62aff60246a1b3\",\"venue\":\"2009 IEEE International Conference on Robotics and Automation\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295441\",\"name\":\"K. Fukunaga\"},{\"authorId\":\"2322936\",\"name\":\"L. Hostetler\"}],\"doi\":\"10.1109/TIT.1975.1055330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98431da7222ee3fe12d277facf5ca1561c56d4f3\",\"title\":\"The estimation of the gradient of a density function, with applications in pattern recognition\",\"url\":\"https://www.semanticscholar.org/paper/98431da7222ee3fe12d277facf5ca1561c56d4f3\",\"venue\":\"IEEE Trans. Inf. Theory\",\"year\":1975},{\"arxivId\":\"1505.00687\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2015.320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"title\":\"Unsupervised Learning of Visual Representations Using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2780072\",\"name\":\"Terri L. Bonebright\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f75b3e88be498ce45856d474f9ed907ff9ffab21\",\"title\":\"Were those coconuts or horse hoofs? Visual context effects on identification and veracity of everyday sounds\",\"url\":\"https://www.semanticscholar.org/paper/f75b3e88be498ce45856d474f9ed907ff9ffab21\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46662383\",\"name\":\"Sofia Cavaco\"},{\"authorId\":\"3069792\",\"name\":\"M. S. Lewicki\"}],\"doi\":\"10.1121/1.2729368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15aaf247d6d45e93f4a453ac0b20ae671947138c\",\"title\":\"Statistical modeling of intrinsic structures in impacts sounds.\",\"url\":\"https://www.semanticscholar.org/paper/15aaf247d6d45e93f4a453ac0b20ae671947138c\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Shelhamer Y. Jia\"},{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"S. Karayev\"},{\"authorId\":null,\"name\":\"J. Long\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"S. Guadarrama\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ioffe and C . Szegedy . Batch normalization : Accelerating deep network training by reducing internal covariate shift Learning image representations tied to ego - motion\",\"url\":\"\",\"venue\":\"IEEE TPAMI\",\"year\":null},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2487205\",\"name\":\"William W. Gaver\"}],\"doi\":\"10.1207/S15326969ECO0501_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a36667de28f912ba999fe92ae718284012a67be\",\"title\":\"What in the World Do We Hear? An Ecological Approach to Auditory Event Perception\",\"url\":\"https://www.semanticscholar.org/paper/0a36667de28f912ba999fe92ae718284012a67be\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1412.0623\",\"authors\":[{\"authorId\":\"3119803\",\"name\":\"S. Bell\"},{\"authorId\":\"3222840\",\"name\":\"P. Upchurch\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"144374926\",\"name\":\"K. Bala\"}],\"doi\":\"10.1109/CVPR.2015.7298970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0959ef8fefe9e7041f508c2448fc026bc9e08393\",\"title\":\"Material recognition in the wild with the Materials in Context Database\",\"url\":\"https://www.semanticscholar.org/paper/0959ef8fefe9e7041f508c2448fc026bc9e08393\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"}],\"doi\":\"10.1016/j.neuron.2011.06.032\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9921e7412a49ced5cdede8797e32476c737d4ec0\",\"title\":\"Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9921e7412a49ced5cdede8797e32476c737d4ec0\",\"venue\":\"Neuron\",\"year\":2011},{\"arxivId\":\"1509.06825\",\"authors\":[{\"authorId\":\"34026610\",\"name\":\"Lerrel Pinto\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICRA.2016.7487517\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f03b4ff1b4943691cec703b508c0a91f2d97a881\",\"title\":\"Supersizing self-supervision: Learning to grasp from 50K tries and 700 robot hours\",\"url\":\"https://www.semanticscholar.org/paper/f03b4ff1b4943691cec703b508c0a91f2d97a881\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49935357\",\"name\":\"Abe Davis\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"34004812\",\"name\":\"N. Wadhwa\"},{\"authorId\":\"1781063\",\"name\":\"Gautham J. Mysore\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/2601097.2601119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3c0cab96b85b469da9c1084aad85702136eca1d\",\"title\":\"The visual microphone\",\"url\":\"https://www.semanticscholar.org/paper/e3c0cab96b85b469da9c1084aad85702136eca1d\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737088\",\"name\":\"E. Krotkov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6248cd56230d003b4a380265d28b660deb70808c\",\"title\":\"Robotic Perception of Material\",\"url\":\"https://www.semanticscholar.org/paper/6248cd56230d003b4a380265d28b660deb70808c\",\"venue\":\"IJCAI\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2836466\",\"name\":\"L. Smith\"},{\"authorId\":\"2740806\",\"name\":\"M. Gasser\"}],\"doi\":\"10.1162/1064546053278973\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25f8e9e35cafd7fb686d939f274111bcffeafd6b\",\"title\":\"The Development of Embodied Cognition: Six Lessons from Babies\",\"url\":\"https://www.semanticscholar.org/paper/25f8e9e35cafd7fb686d939f274111bcffeafd6b\",\"venue\":\"Artificial Life\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49935357\",\"name\":\"Abe Davis\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"2292318\",\"name\":\"J. Chen\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"3469877\",\"name\":\"O. B\\u00fcy\\u00fck\\u00f6zt\\u00fcrk\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/TPAMI.2016.2622271\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7505e94b421048b65a832125acf27fd63b2ecef\",\"title\":\"Visual Vibrometry: Estimating Material Properties from Small Motions in Video\",\"url\":\"https://www.semanticscholar.org/paper/e7505e94b421048b65a832125acf27fd63b2ecef\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8464172\",\"name\":\"K. V. D. Doel\"},{\"authorId\":\"1970147\",\"name\":\"P. Kry\"},{\"authorId\":\"1694975\",\"name\":\"D. Pai\"}],\"doi\":\"10.1145/383259.383322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1284a9db84cf8c1a086e11c5dd09ae7480b47272\",\"title\":\"FoleyAutomatic: physically-based sound effects for interactive simulation and animation\",\"url\":\"https://www.semanticscholar.org/paper/1284a9db84cf8c1a086e11c5dd09ae7480b47272\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49935357\",\"name\":\"Abe Davis\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"2292318\",\"name\":\"J. Chen\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2015.7299171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fe34cb3a504ed423dcac102c59892f5df6ced73\",\"title\":\"Visual vibrometry: Estimating material properties from small motions in video\",\"url\":\"https://www.semanticscholar.org/paper/5fe34cb3a504ed423dcac102c59892f5df6ced73\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"Visually Indicated Sounds\",\"topics\":[{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Fundamental interaction\",\"topicId\":\"362949\",\"url\":\"https://www.semanticscholar.org/topic/362949\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Waveform\",\"topicId\":\"1613\",\"url\":\"https://www.semanticscholar.org/topic/1613\"}],\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"