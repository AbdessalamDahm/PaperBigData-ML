"{\"abstract\":\"The depth image based rendering (DIBR) plays a key role in 3D video synthesis, by which other virtual views can be generated from a 2D video and its depth map. However, in the synthesis process, the background occluded by the foreground objects might be exposed in the new view, resulting in some holes in the synthetized video. In this paper, a hole filling approach based on background reconstruction is proposed, in which the temporal correlation information in both the 2D video and its corresponding depth map are exploited to construct a background video. To construct a clean background video, the foreground objects are detected and removed. Also motion compensation is applied to make the background reconstruction model suitable for moving camera scenario. Each frame is projected to the current plane where a modified Gaussian mixture model is performed. The constructed background video is used to eliminate the holes in the synthetized video. Our experimental results have indicated that the proposed approach has better quality of the synthetized 3D video compared with the other methods.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"34708617\",\"name\":\"Guibo Luo\",\"url\":\"https://www.semanticscholar.org/author/34708617\"},{\"authorId\":\"2073517\",\"name\":\"Yuesheng Zhu\",\"url\":\"https://www.semanticscholar.org/author/2073517\"},{\"authorId\":\"49970020\",\"name\":\"Zhaotian Li\",\"url\":\"https://www.semanticscholar.org/author/49970020\"},{\"authorId\":\"38867682\",\"name\":\"Liming Zhang\",\"url\":\"https://www.semanticscholar.org/author/38867682\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"134066747\",\"name\":\"H. Liang\"},{\"authorId\":\"32897332\",\"name\":\"X. Chen\"},{\"authorId\":\"150128938\",\"name\":\"Huaiyuan Xu\"},{\"authorId\":\"1642328639\",\"name\":\"Siyu Ren\"},{\"authorId\":\"1963957\",\"name\":\"H. Cai\"},{\"authorId\":null,\"name\":\"Yi Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3036053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb219e2f6ca7a5680610651dcf0b5de5ffeb4bb2\",\"title\":\"Local Foreground Removal Disocclusion Filling Method for View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/cb219e2f6ca7a5680610651dcf0b5de5ffeb4bb2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890383\",\"name\":\"Yu Zhang\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"144667540\",\"name\":\"Z. Jiang\"},{\"authorId\":\"10775732\",\"name\":\"Xiaohao Chen\"}],\"doi\":\"10.1109/CVPR.2019.00601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06e89127926108353b02fd64e60e80fc24412816\",\"title\":\"Structure-Preserving Stereoscopic View Synthesis With Multi-Scale Adversarial Correlation Matching\",\"url\":\"https://www.semanticscholar.org/paper/06e89127926108353b02fd64e60e80fc24412816\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51168535\",\"name\":\"Guangcheng Wang\"},{\"authorId\":\"50219008\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"144839077\",\"name\":\"K. Gu\"},{\"authorId\":\"2091623\",\"name\":\"L. Li\"},{\"authorId\":\"9530966\",\"name\":\"Zhifang Xia\"},{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"}],\"doi\":\"10.1109/TIP.2019.2945675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"023b2e6d0e37216589dddbdd5e97329871e3964f\",\"title\":\"Blind Quality Metric of DIBR-Synthesized Images in the Discrete Wavelet Transform Domain\",\"url\":\"https://www.semanticscholar.org/paper/023b2e6d0e37216589dddbdd5e97329871e3964f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145680601\",\"name\":\"Adriano Q. de Oliveira\"},{\"authorId\":\"143627191\",\"name\":\"T. D. Silveira\"},{\"authorId\":\"144970833\",\"name\":\"Marcelo Walter\"},{\"authorId\":\"2870402\",\"name\":\"C. R. Jung\"}],\"doi\":\"10.1109/ICASSP.2019.8683879\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9bb48f4783f7a34e01cf5056d46e291e6e946499\",\"title\":\"On the Performance of DIBR Methods When Using Depth Maps from State-of-the-art Stereo Matching Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/9bb48f4783f7a34e01cf5056d46e291e6e946499\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153522431\",\"name\":\"Chengtao Cai\"},{\"authorId\":\"144305048\",\"name\":\"B. Fan\"},{\"authorId\":\"120192831\",\"name\":\"Haiyang Meng\"},{\"authorId\":\"2436144\",\"name\":\"Qi-dan Zhu\"}],\"doi\":\"10.1117/1.JEI.29.1.013010\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"450f564a6a2255cfb5abf2e273d57145ec66ad25\",\"title\":\"Hole-filling approach based on convolutional neural network for depth image-based rendering view synthesis\",\"url\":\"https://www.semanticscholar.org/paper/450f564a6a2255cfb5abf2e273d57145ec66ad25\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3464854\",\"name\":\"D. Rahaman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0cd3848aff80a06bbc2a50cb693bfbfa18464cce\",\"title\":\"View Synthesis for Free Viewpoint Video Using Temporal Modelling\",\"url\":\"https://www.semanticscholar.org/paper/0cd3848aff80a06bbc2a50cb693bfbfa18464cce\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34708617\",\"name\":\"Guibo Luo\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"},{\"authorId\":\"3447941\",\"name\":\"Zhenyu Weng\"},{\"authorId\":\"49970020\",\"name\":\"Zhaotian Li\"}],\"doi\":\"10.1109/TPAMI.2019.2899837\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9f4e6fe03e48131a2b69ce93dc719f00e1303cda\",\"title\":\"A Disocclusion Inpainting Framework for Depth-Based View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9f4e6fe03e48131a2b69ce93dc719f00e1303cda\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2982639\",\"name\":\"Thomas Sch\\u00f6ps\"},{\"authorId\":\"1821761\",\"name\":\"M. Oswald\"},{\"authorId\":\"3344493\",\"name\":\"P. Speciale\"},{\"authorId\":\"26584661\",\"name\":\"Shuoran Yang\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/TVCG.2017.2734578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc9c78d8364cfa0bb529a1194f4990dc7105fa40\",\"title\":\"Real-Time View Correction for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/bc9c78d8364cfa0bb529a1194f4990dc7105fa40\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79500683\",\"name\":\"Adriano Q. de Oliveira\"},{\"authorId\":\"2129629\",\"name\":\"Marcelo Walter\"},{\"authorId\":\"2870402\",\"name\":\"C. R. Jung\"}],\"doi\":\"10.1109/LSP.2018.2870342\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3c53aca565af95b47558d8bb155f9c7682358385\",\"title\":\"An Artifact-Type Aware DIBR Method for View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/3c53aca565af95b47558d8bb155f9c7682358385\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93277052\",\"name\":\"L. Wang\"},{\"authorId\":\"47827145\",\"name\":\"Y. Zhao\"},{\"authorId\":\"152249496\",\"name\":\"Xu Ma\"},{\"authorId\":\"6288560\",\"name\":\"Sumin Qi\"},{\"authorId\":\"2528396\",\"name\":\"Weiqing Yan\"},{\"authorId\":\"49346661\",\"name\":\"H. Chen\"}],\"doi\":\"10.1109/ACCESS.2020.2971995\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7111003c9e33111edcc30d8b51c4ded529e6e09\",\"title\":\"Quality Assessment for DIBR-Synthesized Images With Local and Global Distortions\",\"url\":\"https://www.semanticscholar.org/paper/f7111003c9e33111edcc30d8b51c4ded529e6e09\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.07036\",\"authors\":[{\"authorId\":\"18126618\",\"name\":\"Shishun Tian\"},{\"authorId\":\"1429346658\",\"name\":\"Lu Zhang\"},{\"authorId\":\"47052618\",\"name\":\"Wenbin Zou\"},{\"authorId\":null,\"name\":\"Xia Li\"},{\"authorId\":\"93997918\",\"name\":\"Ting Su\"},{\"authorId\":\"100800163\",\"name\":\"Luce Morin\"},{\"authorId\":\"144598687\",\"name\":\"O. D\\u00e9forges\"}],\"doi\":\"10.1016/j.neucom.2020.09.062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8bc2215c86c44842599c20804b7099f50510261\",\"title\":\"Quality Assessment of DIBR-synthesized views: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/e8bc2215c86c44842599c20804b7099f50510261\",\"venue\":\"Neurocomputing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47029093\",\"name\":\"C. H. Cheung\"},{\"authorId\":\"1684869\",\"name\":\"K. N. Ngan\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"}],\"doi\":\"10.1109/TMM.2017.2772442\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"112dbeacbc2a337bcd06da317f309a163a5ee56d\",\"title\":\"Spatio-Temporal Disocclusion Filling Using Novel Sprite Cells\",\"url\":\"https://www.semanticscholar.org/paper/112dbeacbc2a337bcd06da317f309a163a5ee56d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144584653\",\"name\":\"A. Bokov\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"}],\"doi\":\"10.1109/IC3D.2018.8657873\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"097862b313588e42781dfa466398cb1fd6983810\",\"title\":\"Multilayer RGBD-Video Completion for Hole Filling in 3D-View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/097862b313588e42781dfa466398cb1fd6983810\",\"venue\":\"2018 International Conference on 3D Immersion (IC3D)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97709924\",\"name\":\"L. Yao\"},{\"authorId\":\"1456216474\",\"name\":\"Qiurui Lu\"},{\"authorId\":\"1502880173\",\"name\":\"Xiaomin Li\"}],\"doi\":\"10.1186/s13640-019-0485-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1b2c1d347aee7136cec9f433f587fee39bf57d6\",\"title\":\"View synthesis based on spatio-temporal continuity\",\"url\":\"https://www.semanticscholar.org/paper/f1b2c1d347aee7136cec9f433f587fee39bf57d6\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3464854\",\"name\":\"D. Rahaman\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1109/DICTA.2017.8227397\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0a7a830f490e7c9ebac3f6ae651855782cf016b\",\"title\":\"A Novel Virtual View Quality Enhancement Technique through a Learning of Synthesised Video\",\"url\":\"https://www.semanticscholar.org/paper/f0a7a830f490e7c9ebac3f6ae651855782cf016b\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3464854\",\"name\":\"D. Rahaman\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1109/TIP.2017.2772858\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22ae630710d2e46e24a77f40c5c1c799552b073\",\"title\":\"Virtual View Synthesis for Free Viewpoint Video and Multiview Video Compression using Gaussian Mixture Modelling\",\"url\":\"https://www.semanticscholar.org/paper/a22ae630710d2e46e24a77f40c5c1c799552b073\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"2983470\",\"name\":\"Xinzhu Sang\"},{\"authorId\":\"3357292\",\"name\":\"Xunbo Yu\"},{\"authorId\":\"143703146\",\"name\":\"X. Gao\"},{\"authorId\":\"152644837\",\"name\":\"Li Liu\"},{\"authorId\":\"7200549\",\"name\":\"K. Wang\"},{\"authorId\":\"9447568\",\"name\":\"Binbin Yan\"},{\"authorId\":\"145040482\",\"name\":\"C. Yu\"}],\"doi\":\"10.1117/12.2547853\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4de0b2cc9c255e9a9baf63580e8aee38e23e23e3\",\"title\":\"Efficient DIBR method based on depth offset mapping for 3D image rendering\",\"url\":\"https://www.semanticscholar.org/paper/4de0b2cc9c255e9a9baf63580e8aee38e23e23e3\",\"venue\":\"Applied Optics and Photonics China\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18126618\",\"name\":\"Shishun Tian\"},{\"authorId\":\"144679055\",\"name\":\"Lu Zhang\"},{\"authorId\":\"33236577\",\"name\":\"L. Morin\"},{\"authorId\":\"144598687\",\"name\":\"O. D\\u00e9forges\"}],\"doi\":\"10.1109/TMM.2018.2875307\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ccc62ef82ce1c33dde1b01adb96e93f11d6d6a2\",\"title\":\"A Benchmark of DIBR Synthesized View Quality Assessment Metrics on a New Database for Immersive Media Applications\",\"url\":\"https://www.semanticscholar.org/paper/6ccc62ef82ce1c33dde1b01adb96e93f11d6d6a2\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8543788\",\"name\":\"Sukla Satapathy\"},{\"authorId\":\"13208860\",\"name\":\"R. R. Sahay\"}],\"doi\":\"10.1109/NCC48643.2020.9056056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4cfaea3c0881a300b9bed4413caa5b73ed3d7af\",\"title\":\"Exploiting Low Rank Prior for Depth Map Completion\",\"url\":\"https://www.semanticscholar.org/paper/e4cfaea3c0881a300b9bed4413caa5b73ed3d7af\",\"venue\":\"2020 National Conference on Communications (NCC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48212549\",\"name\":\"Huiqing Zhang\"},{\"authorId\":\"1935058104\",\"name\":\"Donghao Li\"},{\"authorId\":\"9530966\",\"name\":\"Zhifang Xia\"},{\"authorId\":\"1765903\",\"name\":\"Zichen Wang\"},{\"authorId\":\"1934814264\",\"name\":\"Guangchen Wang\"}],\"doi\":\"10.23919/CCC50068.2020.9188414\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae08f78a23748f3ab66257b58d87df3b8f7e9688\",\"title\":\"Energy Loss Estimation Based Reference-Free Quality Assessment of DIBR-Synthesized Views\",\"url\":\"https://www.semanticscholar.org/paper/ae08f78a23748f3ab66257b58d87df3b8f7e9688\",\"venue\":\"2020 39th Chinese Control Conference (CCC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144584653\",\"name\":\"A. Bokov\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"}],\"doi\":\"10.1109/ICMEW.2017.8026297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d618e761432195c69cb8357be501dc3902ad5dbb\",\"title\":\"Toward efficient background reconstruction for 3D-view synthesis in dynamic scenes\",\"url\":\"https://www.semanticscholar.org/paper/d618e761432195c69cb8357be501dc3902ad5dbb\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"8361353\",\"name\":\"Yingdong Han\"},{\"authorId\":\"50080513\",\"name\":\"X. Li\"}],\"doi\":\"10.1007/s11042-019-7236-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5eae33778086ff3b481c9c6be8ea233042d6c01c\",\"title\":\"Fast and high-quality virtual view synthesis from multi-view plus depth videos\",\"url\":\"https://www.semanticscholar.org/paper/5eae33778086ff3b481c9c6be8ea233042d6c01c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144918349\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"40976947\",\"name\":\"Tai-Jiang Mu\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"}],\"doi\":\"10.1109/TST.2016.7787010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"183aab0b66d0f65256e06947ec4a0ae78f62cd52\",\"title\":\"A Survey on Multiview Video Synthesis and Editing\",\"url\":\"https://www.semanticscholar.org/paper/183aab0b66d0f65256e06947ec4a0ae78f62cd52\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34708617\",\"name\":\"Guibo Luo\"},{\"authorId\":\"2073517\",\"name\":\"Yuesheng Zhu\"}],\"doi\":\"10.1109/ACCESS.2018.2847312\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2a4483b54edc82bcf8c7fe0631ce490a50c2f352\",\"title\":\"Hole Filling for View Synthesis Using Depth Guided Global Optimization\",\"url\":\"https://www.semanticscholar.org/paper/2a4483b54edc82bcf8c7fe0631ce490a50c2f352\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596811874\",\"name\":\"Xuesong Gao\"},{\"authorId\":\"40553846\",\"name\":\"Keqiu Li\"},{\"authorId\":\"1795514\",\"name\":\"Weiqiang Chen\"},{\"authorId\":\"152747637\",\"name\":\"Z. Yang\"},{\"authorId\":\"34939083\",\"name\":\"W. Wei\"},{\"authorId\":\"2934688\",\"name\":\"Yangang Cai\"}],\"doi\":\"10.1109/MIPR49039.2020.00064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63b386f253d430654efb61522840f3cf6459be47\",\"title\":\"Free Viewpoint Video Synthesis Based on DIBR\",\"url\":\"https://www.semanticscholar.org/paper/63b386f253d430654efb61522840f3cf6459be47\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8415723\",\"name\":\"X. Wang\"},{\"authorId\":\"143749719\",\"name\":\"F. Shao\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"36814155\",\"name\":\"Randi Fu\"},{\"authorId\":\"143949085\",\"name\":\"Y. Ho\"}],\"doi\":\"10.1109/ACCESS.2019.2891070\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dacc5b4061cea446365749e4dada8816999a044a\",\"title\":\"Quality Assessment of 3D Synthesized Images via Measuring Local Feature Similarity and Global Sharpness\",\"url\":\"https://www.semanticscholar.org/paper/dacc5b4061cea446365749e4dada8816999a044a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2091623\",\"name\":\"L. Li\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"47876213\",\"name\":\"Jinjian Wu\"},{\"authorId\":\"145987552\",\"name\":\"F. Li\"},{\"authorId\":\"47234098\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1109/TMM.2020.2980185\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e64d0d98e72047cfb1cf16e42541a79bc5245141\",\"title\":\"Quality Index for View Synthesis by Measuring Instance Degradation and Global Appearance\",\"url\":\"https://www.semanticscholar.org/paper/e64d0d98e72047cfb1cf16e42541a79bc5245141\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3464854\",\"name\":\"D. Rahaman\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1109/ICMEW.2017.8026320\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d6a477efe508289c32d252eb3390cf49bbad803\",\"title\":\"Adaptive weighting between warped and learned foregrounds for view synthesize\",\"url\":\"https://www.semanticscholar.org/paper/3d6a477efe508289c32d252eb3390cf49bbad803\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123580502\",\"name\":\"Zengming Deng\"},{\"authorId\":\"2424958\",\"name\":\"Mingjiang Wang\"}],\"doi\":\"10.3390/APP8050823\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d14a88352f973b73d3a33b5e4f062dbee0ab2d28\",\"title\":\"Reliability-Based View Synthesis for Free Viewpoint Video\",\"url\":\"https://www.semanticscholar.org/paper/d14a88352f973b73d3a33b5e4f062dbee0ab2d28\",\"venue\":\"\",\"year\":2018}],\"corpusId\":5863537,\"doi\":\"10.1109/CVPR.2016.197\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"bcc31de891c5e47ee3cc4fd554a8b3860d76e408\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"122621370\",\"name\":\"Y. Mori\"},{\"authorId\":\"1730681\",\"name\":\"N. Fukushima\"},{\"authorId\":\"1732969\",\"name\":\"T. Fujii\"},{\"authorId\":\"1718833\",\"name\":\"M. Tanimoto\"}],\"doi\":\"10.1109/3DTV.2008.4547850\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ccab89d8bc8e26ee3c47461d1528b9367fe8923\",\"title\":\"View Generation with 3D Warping Using Depth Information for FTV\",\"url\":\"https://www.semanticscholar.org/paper/6ccab89d8bc8e26ee3c47461d1528b9367fe8923\",\"venue\":\"3DTV-CON 2008\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784334\",\"name\":\"S. Zinger\"},{\"authorId\":\"144937014\",\"name\":\"L. Do\"},{\"authorId\":\"8582219\",\"name\":\"P. H. With\"}],\"doi\":\"10.1016/j.jvcir.2010.01.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a4fdad2510c317b288d689a2a6a42bc80f76876\",\"title\":\"Free-viewpoint depth image based rendering\",\"url\":\"https://www.semanticscholar.org/paper/0a4fdad2510c317b288d689a2a6a42bc80f76876\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"143711233\",\"name\":\"Matthew Uyttendaele\"},{\"authorId\":\"2818882\",\"name\":\"S. Winder\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1145/1015706.1015766\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4aef53879770ce33e647264230b42ebaba1828\",\"title\":\"High-quality video view interpolation using a layered representation\",\"url\":\"https://www.semanticscholar.org/paper/5d4aef53879770ce33e647264230b42ebaba1828\",\"venue\":\"SIGGRAPH 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34712076\",\"name\":\"C. Stauffer\"},{\"authorId\":\"1719838\",\"name\":\"W. Grimson\"}],\"doi\":\"10.1109/CVPR.1999.784637\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eac7287d7ef69252358c1fbddedf123e11012370\",\"title\":\"Adaptive background mixture models for real-time tracking\",\"url\":\"https://www.semanticscholar.org/paper/eac7287d7ef69252358c1fbddedf123e11012370\",\"venue\":\"Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15166568\",\"name\":\"Ying-Rung Horng\"},{\"authorId\":\"2198054\",\"name\":\"Yu-Cheng Tseng\"},{\"authorId\":\"145328936\",\"name\":\"T. Chang\"}],\"doi\":\"10.1109/ISCAS.2010.5537052\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df9e69bd621cc3b83693f4fc60a5d7ba155dcc9a\",\"title\":\"Stereoscopic images generation with directional Gaussian filter\",\"url\":\"https://www.semanticscholar.org/paper/df9e69bd621cc3b83693f4fc60a5d7ba155dcc9a\",\"venue\":\"Proceedings of 2010 IEEE International Symposium on Circuits and Systems\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716777\",\"name\":\"A. Criminisi\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1769685\",\"name\":\"K. Toyama\"}],\"doi\":\"10.1109/TIP.2004.833105\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e763e059cead07d1c03646bfb8cb4a0a75ffc3ef\",\"title\":\"Region filling and object removal by exemplar-based image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/e763e059cead07d1c03646bfb8cb4a0a75ffc3ef\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Schwarz\"},{\"authorId\":null,\"name\":\"D. Marpe\"},{\"authorId\":null,\"name\":\"T. Wiegand\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Description of exploration experiments in 3d video coding\",\"url\":\"\",\"venue\":\"ISO/IEC JTC1/SC29/WG11 MPEG2010 N,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2311207\",\"name\":\"Isma\\u00ebl Daribo\"},{\"authorId\":\"51297261\",\"name\":\"H. Saito\"}],\"doi\":\"10.1109/TBC.2011.2125110\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"556e98b646a65535ae192b14800f624704ae09e5\",\"title\":\"A Novel Inpainting-Based Layered Depth Video for 3DTV\",\"url\":\"https://www.semanticscholar.org/paper/556e98b646a65535ae192b14800f624704ae09e5\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Chao Zhang\"}],\"doi\":\"10.1109/ICPR.2008.4761661\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06a0630a558f9e8b825ff960fad0ce1ee063c100\",\"title\":\"A layered method of visibility resolving in depth image-based rendering\",\"url\":\"https://www.semanticscholar.org/paper/06a0630a558f9e8b825ff960fad0ce1ee063c100\",\"venue\":\"2008 19th International Conference on Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48266000\",\"name\":\"M. K\\u00f6ppel\"},{\"authorId\":\"1403216318\",\"name\":\"P. Ndjiki-Nya\"},{\"authorId\":\"2969787\",\"name\":\"D. Doshkov\"},{\"authorId\":\"2052685\",\"name\":\"H. Lakshman\"},{\"authorId\":\"34771562\",\"name\":\"P. Merkle\"},{\"authorId\":\"153553624\",\"name\":\"K. M\\u00fcller\"},{\"authorId\":\"48531638\",\"name\":\"T. Wiegand\"}],\"doi\":\"10.1109/ICIP.2010.5652138\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"197a9c63e5f4d33f41c5cf1ead58a6145fdc8d4e\",\"title\":\"Temporally consistent handling of disocclusions with texture synthesis for depth-image-based rendering\",\"url\":\"https://www.semanticscholar.org/paper/197a9c63e5f4d33f41c5cf1ead58a6145fdc8d4e\",\"venue\":\"2010 IEEE International Conference on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Tanimoto\"},{\"authorId\":null,\"name\":\"T. Fujii\"},{\"authorId\":null,\"name\":\"K. Suzuki\"},{\"authorId\":null,\"name\":\"N. Fukushima\"},{\"authorId\":null,\"name\":\"Y. Mori\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Reference softwares for depth estimation and view synthesis\",\"url\":\"\",\"venue\":\"ISO/IEC JTC1/SC29/WG11 MPEG,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145055020\",\"name\":\"M. Haque\"},{\"authorId\":\"144854065\",\"name\":\"M. Murshed\"},{\"authorId\":\"145328424\",\"name\":\"M. Paul\"}],\"doi\":\"10.1109/ICPR.2008.4761496\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9d16b2730733144e4e7126d0a94544d66c8ee3d\",\"title\":\"Improved Gaussian mixtures for robust object detection by adaptive multi-background generation\",\"url\":\"https://www.semanticscholar.org/paper/d9d16b2730733144e4e7126d0a94544d66c8ee3d\",\"venue\":\"2008 19th International Conference on Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3694124\",\"name\":\"P. Lee\"},{\"authorId\":\"2778418\",\"name\":\"Effendi\"}],\"doi\":\"10.1109/TMM.2010.2100372\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2dae3bf5704d9ffe07a9ff4973b2fde7f46c515a\",\"title\":\"Nongeometric Distortion Smoothing Approach for Depth Map Preprocessing\",\"url\":\"https://www.semanticscholar.org/paper/2dae3bf5704d9ffe07a9ff4973b2fde7f46c515a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2696685\",\"name\":\"W. Chen\"},{\"authorId\":\"2842589\",\"name\":\"Yu-Lin Chang\"},{\"authorId\":\"2219929\",\"name\":\"Shyh-Feng Lin\"},{\"authorId\":\"1798485\",\"name\":\"Li-Fu Ding\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ICME.2005.1521671\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cfc14f6f4f2c53efe7b97dc53d6f42791e132c8\",\"title\":\"Efficient Depth Image Based Rendering with Edge Dependent Depth Filter and Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/3cfc14f6f4f2c53efe7b97dc53d6f42791e132c8\",\"venue\":\"2005 IEEE International Conference on Multimedia and Expo\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32213100\",\"name\":\"Ludovic J. Angot\"},{\"authorId\":\"8007884\",\"name\":\"Wei-Jia Huang\"},{\"authorId\":\"3231115\",\"name\":\"Kai-Che Liu\"}],\"doi\":\"10.1117/12.838571\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ef8fc0849349ae499a6e692f743fee6027a9c66\",\"title\":\"A 2D to 3D video and image conversion technique based on a bilateral filter\",\"url\":\"https://www.semanticscholar.org/paper/9ef8fc0849349ae499a6e692f743fee6027a9c66\",\"venue\":\"Electronic Imaging\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2770627\",\"name\":\"Ilkoo Ahn\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TBC.2013.2281658\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c90d6d4f05d31c711a5df94f2b6668491f29c60\",\"title\":\"A Novel Depth-Based Virtual View Synthesis Method for Free Viewpoint Video\",\"url\":\"https://www.semanticscholar.org/paper/6c90d6d4f05d31c711a5df94f2b6668491f29c60\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716777\",\"name\":\"A. Criminisi\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"143774737\",\"name\":\"J. Shotton\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1007/s11263-006-8525-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33cd925c1f1b83ef93edff5b5eb05111132b835b\",\"title\":\"Efficient Dense Stereo with Occlusions for New View-Synthesis by Four-State Dynamic Programming\",\"url\":\"https://www.semanticscholar.org/paper/33cd925c1f1b83ef93edff5b5eb05111132b835b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2885495\",\"name\":\"Mashhour Solh\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1109/JSTSP.2012.2204723\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31bf6eb2aa99ce045a9d23d9d1bf60f7090baf01\",\"title\":\"Hierarchical Hole-Filling For Depth-Based View Synthesis in FTV and 3D Video\",\"url\":\"https://www.semanticscholar.org/paper/31bf6eb2aa99ce045a9d23d9d1bf60f7090baf01\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25547810\",\"name\":\"J. Gautier\"},{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"},{\"authorId\":\"1780587\",\"name\":\"C. Guillemot\"}],\"doi\":\"10.1109/3DTV.2011.5877193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"257eccce31272f626967963a6dda0c085065c53f\",\"title\":\"Depth-based image completion for view synthesis\",\"url\":\"https://www.semanticscholar.org/paper/257eccce31272f626967963a6dda0c085065c53f\",\"venue\":\"2011 3DTV Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON)\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24344368\",\"name\":\"Dar-Shyang Lee\"}],\"doi\":\"10.1109/TPAMI.2005.102\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a53cc380d4356ef7c6b135284138ab5fb845a39e\",\"title\":\"Effective Gaussian mixture learning for video background subtraction\",\"url\":\"https://www.semanticscholar.org/paper/a53cc380d4356ef7c6b135284138ab5fb845a39e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145670268\",\"name\":\"C. Yao\"},{\"authorId\":\"1701659\",\"name\":\"T. Tillo\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2825865\",\"name\":\"J. Xiao\"},{\"authorId\":\"7465771\",\"name\":\"Huihui Bai\"},{\"authorId\":\"2212400\",\"name\":\"Chunyu Lin\"}],\"doi\":\"10.1109/TBC.2014.2321671\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1912208cff8c6815937370598a6c555bf573672b\",\"title\":\"Depth Map Driven Hole Filling Algorithm Exploiting Temporal Correlation Information\",\"url\":\"https://www.semanticscholar.org/paper/1912208cff8c6815937370598a6c555bf573672b\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2457976\",\"name\":\"P. KaewTrakulPong\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1007/978-1-4615-0913-4_11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"33aaa25346ba6796a0055a42cfa1932053878ba3\",\"title\":\"An Improved Adaptive Background Mixture Model for Real-time Tracking with Shadow Detection\",\"url\":\"https://www.semanticscholar.org/paper/33aaa25346ba6796a0055a42cfa1932053878ba3\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195306\",\"name\":\"H. Bay\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/11744023_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"490020c0d4fa1eb85fe353add5713e49f08c628d\",\"title\":\"SURF: Speeded Up Robust Features\",\"url\":\"https://www.semanticscholar.org/paper/490020c0d4fa1eb85fe353add5713e49f08c628d\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2236543\",\"name\":\"C. Fehn\"}],\"doi\":\"10.1117/12.524762\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b9b9496935cce3b643e7e5c519e056c998fb625\",\"title\":\"Depth-image-based rendering (DIBR), compression, and transmission for a new approach on 3D-TV\",\"url\":\"https://www.semanticscholar.org/paper/7b9b9496935cce3b643e7e5c519e056c998fb625\",\"venue\":\"IS&T/SPIE Electronic Imaging\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801656\",\"name\":\"P. Kauff\"},{\"authorId\":\"2463665\",\"name\":\"N. Atzpadin\"},{\"authorId\":\"2236543\",\"name\":\"C. Fehn\"},{\"authorId\":\"121905165\",\"name\":\"M. M\\u00fcller\"},{\"authorId\":\"1783136\",\"name\":\"O. Schreer\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"},{\"authorId\":\"3070493\",\"name\":\"R. Tanger\"}],\"doi\":\"10.1016/j.image.2006.11.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"261e39073725dd16d46aeaeb30b7b7dd3e8b78ee\",\"title\":\"Depth map creation and image-based rendering for advanced 3DTV services providing interoperability and scalability\",\"url\":\"https://www.semanticscholar.org/paper/261e39073725dd16d46aeaeb30b7b7dd3e8b78ee\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2333836\",\"name\":\"W. Tam\"},{\"authorId\":\"1815021\",\"name\":\"G. Alain\"},{\"authorId\":\"145967421\",\"name\":\"L. Zhang\"},{\"authorId\":\"31786161\",\"name\":\"Taali Martin\"},{\"authorId\":\"15996240\",\"name\":\"Ronald C. Renaud\"}],\"doi\":\"10.1117/12.583105\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3553d6c58b40d1e5a36d09fa95d0b0350050fb63\",\"title\":\"Smoothing depth maps for improved steroscopic image quality\",\"url\":\"https://www.semanticscholar.org/paper/3553d6c58b40d1e5a36d09fa95d0b0350050fb63\",\"venue\":\"SPIE Optics East\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2465976\",\"name\":\"M. Fischler\"},{\"authorId\":\"1764443\",\"name\":\"R. Bolles\"}],\"doi\":\"10.1016/B978-0-08-051581-6.50070-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f37468a95ccc62debb9e5a4cb0d73489ca61190\",\"title\":\"A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography\",\"url\":\"https://www.semanticscholar.org/paper/4f37468a95ccc62debb9e5a4cb0d73489ca61190\",\"venue\":\"\",\"year\":1987},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"144653005\",\"name\":\"V. Kolmogorov\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"}],\"doi\":\"10.1145/1186562.1015720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f26d35d2e32934150cd27b030d4d769942126184\",\"title\":\"\\\"GrabCut\\\": interactive foreground extraction using iterated graph cuts\",\"url\":\"https://www.semanticscholar.org/paper/f26d35d2e32934150cd27b030d4d769942126184\",\"venue\":\"ACM Trans. Graph.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145838767\",\"name\":\"K. M\\u00fcller\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"},{\"authorId\":\"39566263\",\"name\":\"K. Dix\"},{\"authorId\":\"34771562\",\"name\":\"P. Merkle\"},{\"authorId\":\"1801656\",\"name\":\"P. Kauff\"},{\"authorId\":\"1745395\",\"name\":\"T. Wiegand\"}],\"doi\":\"10.1155/2008/438148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5914853c8944eb66542feac412702d2416b2f5c\",\"title\":\"View Synthesis for Advanced 3D Video Systems\",\"url\":\"https://www.semanticscholar.org/paper/a5914853c8944eb66542feac412702d2416b2f5c\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2323644\",\"name\":\"Sunghwan Choi\"},{\"authorId\":\"38723538\",\"name\":\"Bumsub Ham\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/TIP.2013.2251646\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75c918261aa42e91a30fb93f140c28620b8d55f1\",\"title\":\"Space-Time Hole Filling With Random Walks in View Extrapolation for 3D Video\",\"url\":\"https://www.semanticscholar.org/paper/75c918261aa42e91a30fb93f140c28620b8d55f1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"144302962\",\"name\":\"O. Au\"},{\"authorId\":\"144104537\",\"name\":\"Lingfeng Xu\"},{\"authorId\":\"47003137\",\"name\":\"Yujun Li\"},{\"authorId\":\"144077687\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2012.6467461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a741eb15ee22f82c11e471b36860fd244fd36af\",\"title\":\"Novel temporal domain hole filling based on background modeling for view synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9a741eb15ee22f82c11e471b36860fd244fd36af\",\"venue\":\"2012 19th IEEE International Conference on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750819\",\"name\":\"L. Grady\"}],\"doi\":\"10.1109/TPAMI.2006.233\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"59d86a93c4ef54b5489bc375cd02e64205823f42\",\"title\":\"Random Walks for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/59d86a93c4ef54b5489bc375cd02e64205823f42\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2006}],\"title\":\"A Hole Filling Approach Based on Background Reconstruction for View Synthesis in 3D Video\",\"topics\":[{\"topic\":\"View synthesis\",\"topicId\":\"81953\",\"url\":\"https://www.semanticscholar.org/topic/81953\"},{\"topic\":\"Motion compensation\",\"topicId\":\"100764\",\"url\":\"https://www.semanticscholar.org/topic/100764\"},{\"topic\":\"Depth map\",\"topicId\":\"23196\",\"url\":\"https://www.semanticscholar.org/topic/23196\"},{\"topic\":\"Mixture model\",\"topicId\":\"3712\",\"url\":\"https://www.semanticscholar.org/topic/3712\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Google Map Maker\",\"topicId\":\"2833202\",\"url\":\"https://www.semanticscholar.org/topic/2833202\"}],\"url\":\"https://www.semanticscholar.org/paper/bcc31de891c5e47ee3cc4fd554a8b3860d76e408\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"