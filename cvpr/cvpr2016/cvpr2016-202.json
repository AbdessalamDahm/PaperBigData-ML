"{\"abstract\":\"We bring together ideas from recent work on feature design for egocentric action recognition under one framework by exploring the use of deep convolutional neural networks (CNN). Recent work has shown that features such as hand appearance, object attributes, local hand motion and camera ego-motion are important for characterizing first-person actions. To integrate these ideas under one framework, we propose a twin stream network architecture, where one stream analyzes appearance information and the other stream analyzes motion information. Our appearance stream encodes prior knowledge of the egocentric paradigm by explicitly training the network to segment hands and localize objects. By visualizing certain neuron activation of our network, we show that our proposed architecture naturally learns features that capture object attributes and hand-object configurations. Our extensive experiments on benchmark egocentric action datasets show that our deep architecture enables recognition rates that significantly outperform state-of-the-art techniques - an average 6:6% increase in accuracy over all datasets. Furthermore, by learning to recognize objects, actions and activities jointly, the performance of individual recognition tasks also increase by 30% (actions) and 14% (objects). We also include the results of extensive ablative analysis to highlight the importance of network design decisions.\",\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\",\"url\":\"https://www.semanticscholar.org/author/2238622\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\",\"url\":\"https://www.semanticscholar.org/author/2681569\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\",\"url\":\"https://www.semanticscholar.org/author/37991449\"}],\"citationVelocity\":51,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a671cb0d366ab895249349ca457673150ecc8ee2\",\"title\":\"A Long Short-Term Memory Convolutional Neural Network for First-Person Vision Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a671cb0d366ab895249349ca457673150ecc8ee2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1807.08254\",\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c1b526dc9adba029809e45693f758c2af913f60\",\"title\":\"Understanding hand-object manipulation by modeling the contextual relationship between actions, grasp types and object attributes\",\"url\":\"https://www.semanticscholar.org/paper/9c1b526dc9adba029809e45693f758c2af913f60\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867171\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/WACV.2017.21\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"67f49376d610b8e11505d455cdabb83811aaf431\",\"title\":\"First-Person Action Decomposition and Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/67f49376d610b8e11505d455cdabb83811aaf431\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32212960\",\"name\":\"E. Talavera\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1730388\",\"name\":\"N. Petkov\"}],\"doi\":\"10.1007/978-3-319-74727-9_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a248960e040778197276cf1c9e27c8c8116cfedb\",\"title\":\"Towards Egocentric Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a248960e040778197276cf1c9e27c8c8116cfedb\",\"venue\":\"EUROCAST\",\"year\":2017},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"145053996\",\"name\":\"Feng Lu\"},{\"authorId\":\"35350470\",\"name\":\"Yue Gao\"}],\"doi\":\"10.1109/TCYB.2018.2806381\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2565c9ea9edf4275cba0679c3ef6a8f3bea8aa52\",\"title\":\"Desktop Action Recognition From First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/2565c9ea9edf4275cba0679c3ef6a8f3bea8aa52\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"},{\"authorId\":\"143624101\",\"name\":\"R. Zhao\"},{\"authorId\":\"145974119\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144847940\",\"name\":\"K. Lam\"}],\"doi\":\"10.1109/LSP.2020.3011326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c232519f402375a404ac74f02451807c3fa3aa3c\",\"title\":\"Progressive Motion Representation Distillation With Two-Branch Networks for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c232519f402375a404ac74f02451807c3fa3aa3c\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23276966\",\"name\":\"A. Nakazawa\"},{\"authorId\":\"51285606\",\"name\":\"Yu Mitsuzumi\"},{\"authorId\":\"102305500\",\"name\":\"Y. Watanabe\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"},{\"authorId\":\"46330846\",\"name\":\"S. Yoshikawa\"},{\"authorId\":\"6101063\",\"name\":\"M. Honda\"}],\"doi\":\"10.1007/S10846-019-01052-8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a12e9ef876fb6f621fe9414bb7d17974fdbc00b0\",\"title\":\"First-person Video Analysis for Evaluating Skill Level in the Humanitude Tender-Care Technique\",\"url\":\"https://www.semanticscholar.org/paper/a12e9ef876fb6f621fe9414bb7d17974fdbc00b0\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":\"1603.04908\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.15607/RSS.2017.XIII.012\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6021af236342c11c44f681d2aa21b0b46756236a\",\"title\":\"First Person Action-Object Detection with EgoNet\",\"url\":\"https://www.semanticscholar.org/paper/6021af236342c11c44f681d2aa21b0b46756236a\",\"venue\":\"Robotics: Science and Systems\",\"year\":2017},{\"arxivId\":\"1701.00142\",\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"32776367\",\"name\":\"Mohammad Shafiei\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2980179.2980235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"title\":\"EgoCap: egocentric marker-less motion capture with two fisheye cameras\",\"url\":\"https://www.semanticscholar.org/paper/ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1801.06011\",\"authors\":[{\"authorId\":\"2920056\",\"name\":\"Julian Steil\"},{\"authorId\":\"49569816\",\"name\":\"P. M\\u00fcller\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/3229434.3229439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26dce5da1b49488c7a25a8841637c97b66d4cc00\",\"title\":\"Forecasting user attention during everyday mobile interactions using device-integrated and wearable sensors\",\"url\":\"https://www.semanticscholar.org/paper/26dce5da1b49488c7a25a8841637c97b66d4cc00\",\"venue\":\"MobileHCI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"}],\"doi\":\"10.22028/D291-26685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"title\":\"From motion capture to interactive virtual worlds: towards unconstrained motion-capture algorithms for real-time performance-driven character animation\",\"url\":\"https://www.semanticscholar.org/paper/62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2450903\",\"name\":\"Rawan Alharbi\"},{\"authorId\":\"153876788\",\"name\":\"Mariam Tolba\"},{\"authorId\":\"49489155\",\"name\":\"L. C. Petito\"},{\"authorId\":\"15918293\",\"name\":\"J. Hester\"},{\"authorId\":\"2959332\",\"name\":\"Nabil Alshurafa\"}],\"doi\":\"10.1145/3351230\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52ad405f439b1fc84956463bfe9346874c1e1164\",\"title\":\"To Mask or Not to Mask?\",\"url\":\"https://www.semanticscholar.org/paper/52ad405f439b1fc84956463bfe9346874c1e1164\",\"venue\":\"Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11485779\",\"name\":\"K. Lee\"}],\"doi\":\"10.1145/3386402.3386405\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d7fecd4357c79a6510b921a27283bdfa625a7e8\",\"title\":\"Teachable object recognizers for the blind\",\"url\":\"https://www.semanticscholar.org/paper/1d7fecd4357c79a6510b921a27283bdfa625a7e8\",\"venue\":\"ACM SIGACCESS Access. Comput.\",\"year\":2020},{\"arxivId\":\"2002.08219\",\"authors\":[{\"authorId\":\"1489467112\",\"name\":\"Yeji Kim\"},{\"authorId\":\"122808682\",\"name\":\"Dong-Gyu Lee\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107279\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"title\":\"Three-Stream Fusion Network for First-Person Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bff155ae5959ac48054594a4d2785684a90b278\",\"title\":\"Am I a Baller? Basketball Skill Assessment using First-Person Cameras\",\"url\":\"https://www.semanticscholar.org/paper/4bff155ae5959ac48054594a4d2785684a90b278\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1907.10045\",\"authors\":[{\"authorId\":\"3358340\",\"name\":\"Denis Tom\\u00e8\"},{\"authorId\":\"151353735\",\"name\":\"Patrick Peluse\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"},{\"authorId\":\"2863682\",\"name\":\"H. Badino\"}],\"doi\":\"10.1109/ICCV.2019.00782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f54f2db3e1c8e79f073840a7fd4f320fb3d0589c\",\"title\":\"xR-EgoPose: Egocentric 3D Human Pose From an HMD Camera\",\"url\":\"https://www.semanticscholar.org/paper/f54f2db3e1c8e79f073840a7fd4f320fb3d0589c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40327350\",\"name\":\"A. Mustafa\"},{\"authorId\":\"121339425\",\"name\":\"Dicle Cetinkaya\"},{\"authorId\":\"48683966\",\"name\":\"X. Cheng\"},{\"authorId\":\"89387506\",\"name\":\"Per-Ove Th\\u00f6rnqvist\"},{\"authorId\":\"1683008\",\"name\":\"S. Winberg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e61209959834e94ee972602d7f2c85d9fc9ded51\",\"title\":\"Spiegeldanio : A bold and aggressive fish but what if it loses a fight?\",\"url\":\"https://www.semanticscholar.org/paper/e61209959834e94ee972602d7f2c85d9fc9ded51\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145222076\",\"name\":\"Tianyu Zhang\"},{\"authorId\":\"2366119\",\"name\":\"Weiqing Min\"},{\"authorId\":\"27730334\",\"name\":\"Ying Zhu\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3394171.3413964\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10066d89b96b8baac518c994f23278b817994a12\",\"title\":\"An Egocentric Action Anticipation Framework via Fusing Intuition and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/10066d89b96b8baac518c994f23278b817994a12\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430672\",\"name\":\"Khalid El Ansaoui\"},{\"authorId\":\"102880570\",\"name\":\"Youness Chawki\"},{\"authorId\":\"151441479\",\"name\":\"Mohammed Ouhda\"}],\"doi\":\"10.1007/978-3-030-23672-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4ceaa1b392509591c384822cd789a263101107\",\"title\":\"Towards a Rich and Dynamic Human Digital Memory in Egocentric Dataset\",\"url\":\"https://www.semanticscholar.org/paper/3d4ceaa1b392509591c384822cd789a263101107\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1703.08338\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"Davide Moltisanti\"},{\"authorId\":\"1398236231\",\"name\":\"Walterio W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"Dima Damen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b408a3ca6fb39b0fda4d77e6a9679003b2dc9ab\",\"title\":\"Improving Classification by Improving Labelling: Introducing Probabilistic Multi-Label Object Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b408a3ca6fb39b0fda4d77e6a9679003b2dc9ab\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/ICCVW.2017.33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04964e2697778dc843671c7764f0f912e46991ca\",\"title\":\"Are They Going to Cross? A Benchmark Dataset and Baseline for Pedestrian Crosswalk Behavior\",\"url\":\"https://www.semanticscholar.org/paper/04964e2697778dc843671c7764f0f912e46991ca\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72801463\",\"name\":\"Y. Segawa\"},{\"authorId\":\"3063432\",\"name\":\"K. Kawamoto\"},{\"authorId\":\"23669216\",\"name\":\"K. Okamoto\"}],\"doi\":\"10.1186/S13640-018-0272-Z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23dbc7aed4af912dfb3a8ecc0b05fac0068699e3\",\"title\":\"First-person reading activity recognition by deep learning with synthetically generated images\",\"url\":\"https://www.semanticscholar.org/paper/23dbc7aed4af912dfb3a8ecc0b05fac0068699e3\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2018},{\"arxivId\":\"1811.07391\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"27018486\",\"name\":\"Y. Chen\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICCV.2019.00563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcaa81e2150dffcb5dc7bc785285444570443b80\",\"title\":\"Temporal Recurrent Networks for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/bcaa81e2150dffcb5dc7bc785285444570443b80\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48256136\",\"name\":\"Shoya Ishimaru\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1145/3123024.3123200\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"871cc1ef358eb45f1bb1f46693299aaf94026cbe\",\"title\":\"ARFLED: ability recognition framework for learning and education\",\"url\":\"https://www.semanticscholar.org/paper/871cc1ef358eb45f1bb1f46693299aaf94026cbe\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40611227\",\"name\":\"Rosario Scalise\"},{\"authorId\":null,\"name\":\"Jesse Thomason\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"82211564\",\"name\":\"Siddhartha Srinivasa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985eed4bf8a308b55eb83a02355d82b9e0c054e6\",\"title\":\"RGB Depth Spoon Tuna Clamp IN / ON \\u2714 / \\u2714 \\u2717 / \\u2717 \\u2717 / \\u2714 Grasp Pre-Manipulation Post-Manipulation SMALL RGB Depth GT\",\"url\":\"https://www.semanticscholar.org/paper/985eed4bf8a308b55eb83a02355d82b9e0c054e6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2008.06046\",\"authors\":[{\"authorId\":\"72802941\",\"name\":\"C. Rockwell\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"}],\"doi\":\"10.1007/978-3-030-58520-4_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77cc755f4d2a953a9c630f6900a2cfd696408d2d\",\"title\":\"Full-Body Awareness from Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/77cc755f4d2a953a9c630f6900a2cfd696408d2d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1703.09026\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/iccv.2017.314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"title\":\"Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73263377\",\"name\":\"Ozge Mercanoglu Sincan\"},{\"authorId\":\"1470736063\",\"name\":\"Sinan Gencoglu\"},{\"authorId\":\"114064343\",\"name\":\"M. Bacak\"},{\"authorId\":\"2987805\",\"name\":\"Hacer Yalim Keles\"}],\"doi\":\"10.1109/ISMSIT.2019.8932835\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f2cb2940bb3f2842ff37e2dfaefec38274f430\",\"title\":\"Hand and Face Segmentation with Deep Convolutional Networks using Limited Labelled Data\",\"url\":\"https://www.semanticscholar.org/paper/18f2cb2940bb3f2842ff37e2dfaefec38274f430\",\"venue\":\"2019 3rd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23400572\",\"name\":\"K. Hirota\"},{\"authorId\":\"145286719\",\"name\":\"T. Komuro\"}],\"doi\":\"10.1109/AIVR46125.2019.00035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e660d6984d2831a0e336b345c7843119123ff00\",\"title\":\"Situation-Adaptive Object Grasping Recognition in VR Environment\",\"url\":\"https://www.semanticscholar.org/paper/9e660d6984d2831a0e336b345c7843119123ff00\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":\"2009.14326\",\"authors\":[{\"authorId\":\"1711831424\",\"name\":\"B. Debnath\"},{\"authorId\":\"1934840264\",\"name\":\"M. O\\u2019Brien\"},{\"authorId\":\"1643138720\",\"name\":\"S. Kumar\"},{\"authorId\":\"69047479\",\"name\":\"A. Behera\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d7216754f292ecb8fd99aba6f384d9ab5502a53\",\"title\":\"Attention-Driven Body Pose Encoding for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d7216754f292ecb8fd99aba6f384d9ab5502a53\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"title\":\"Unified Egocentric Recognition of 3 D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.11217\",\"authors\":[{\"authorId\":\"31485927\",\"name\":\"T. Yagi\"},{\"authorId\":\"11379939\",\"name\":\"Karttikeya Mangalam\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2018.00792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d1b8ac91ca95f5234d58602078aa13753f3c73b\",\"title\":\"Future Person Localization in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d1b8ac91ca95f5234d58602078aa13753f3c73b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22225826\",\"name\":\"Jose Juan Dominguez Veiga\"},{\"authorId\":\"1399182383\",\"name\":\"M. O'Reilly\"},{\"authorId\":\"35270647\",\"name\":\"Darragh F Whelan\"},{\"authorId\":\"1680033\",\"name\":\"B. Caulfield\"},{\"authorId\":\"145950787\",\"name\":\"T. Ward\"}],\"doi\":\"10.2196/mhealth.7521\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"054f82bd76e2428e28b6131d7cedd8bc32a780e5\",\"title\":\"Feature-Free Activity Classification of Inertial Sensor Data With Machine Vision Techniques: Method, Development, and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/054f82bd76e2428e28b6131d7cedd8bc32a780e5\",\"venue\":\"JMIR mHealth and uHealth\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65804627\",\"name\":\"Khalid El Asnaoui\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1515/jisys-2017-0364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0363d6b6820070c475f6d8608e4594c7af9ca736\",\"title\":\"Automatically Assess Day Similarity Using Visual Lifelogs\",\"url\":\"https://www.semanticscholar.org/paper/0363d6b6820070c475f6d8608e4594c7af9ca736\",\"venue\":\"J. Intell. Syst.\",\"year\":2020},{\"arxivId\":\"1607.08414\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1007/978-3-319-46604-0_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995447f98766c17b414fd25b7f836c8bdda79225\",\"title\":\"SEMBED: Semantic Embedding of Egocentric Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/995447f98766c17b414fd25b7f836c8bdda79225\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4887445\",\"name\":\"Tomoya Nakatani\"},{\"authorId\":\"35421395\",\"name\":\"Ryohei Kuga\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"}],\"doi\":\"10.1109/PERCOMW.2019.8730673\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ab91c6e0623466f3b75c47c980bd5f8e88362b0\",\"title\":\"Object-based Activity Recognition Using Egocentric Video Based on Web Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/8ab91c6e0623466f3b75c47c980bd5f8e88362b0\",\"venue\":\"PerCom Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31790681\",\"name\":\"Shuya Ding\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"1750918854\",\"name\":\"Tianyue Zheng\"},{\"authorId\":\"34309103\",\"name\":\"Jun Luo\"}],\"doi\":\"10.1145/3384419.3430735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc75fb803a1c594935219dd5458f5f712d16bde3\",\"title\":\"RF-net: a unified meta-learning framework for RF-enabled one-shot human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc75fb803a1c594935219dd5458f5f712d16bde3\",\"venue\":\"SenSys\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"},{\"authorId\":\"40235962\",\"name\":\"Juarez Monteiro\"},{\"authorId\":\"10684139\",\"name\":\"Jo\\u00e3o Paulo Aires\"},{\"authorId\":\"3045512\",\"name\":\"Roger Granada\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab81f7686f118d9dda869c2020add70f6a0cd57c\",\"title\":\"Improving Activity Recognition using Temporal Regions\",\"url\":\"https://www.semanticscholar.org/paper/ab81f7686f118d9dda869c2020add70f6a0cd57c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3408086\",\"name\":\"M. Nouredanesh\"},{\"authorId\":\"29382256\",\"name\":\"Aaron W. Li\"},{\"authorId\":\"145113143\",\"name\":\"A. Godfrey\"},{\"authorId\":\"145803385\",\"name\":\"J. Hoey\"},{\"authorId\":\"145407517\",\"name\":\"J. Tung\"}],\"doi\":\"10.1007/978-3-030-11024-6_12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a472cc370eb59c347210ca5ba23dcef6af80ed1a\",\"title\":\"Chasing Feet in the Wild: A Proposed Egocentric Motion-Aware Gait Assessment Tool\",\"url\":\"https://www.semanticscholar.org/paper/a472cc370eb59c347210ca5ba23dcef6af80ed1a\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29001103\",\"name\":\"Rafael Possas\"},{\"authorId\":\"1405712007\",\"name\":\"Sheila M. Pinto-Caceres\"},{\"authorId\":\"145726167\",\"name\":\"F. Ramos\"}],\"doi\":\"10.1109/CVPR.2018.00625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcafefd074937caa6a56f3ffe0068075c6f631e8\",\"title\":\"Egocentric Activity Recognition on a Budget\",\"url\":\"https://www.semanticscholar.org/paper/bcafefd074937caa6a56f3ffe0068075c6f631e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.00104\",\"authors\":[{\"authorId\":\"46419391\",\"name\":\"M. Elfeki\"},{\"authorId\":\"50528026\",\"name\":\"Krishna Regmi\"},{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1c8fd832fe393034fad096f3296493ef6f807ad\",\"title\":\"From Third Person to First Person: Dataset and Baselines for Synthesis and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a1c8fd832fe393034fad096f3296493ef6f807ad\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.09062\",\"authors\":[{\"authorId\":\"50689299\",\"name\":\"Honglin Chen\"},{\"authorId\":\"144057957\",\"name\":\"H. Li\"},{\"authorId\":\"49077856\",\"name\":\"Alexander Song\"},{\"authorId\":\"33702926\",\"name\":\"M. Haberland\"},{\"authorId\":\"103541502\",\"name\":\"Osman Akar\"},{\"authorId\":\"144097866\",\"name\":\"Adam Dhillon\"},{\"authorId\":\"41033318\",\"name\":\"Tiankuang Zhou\"},{\"authorId\":\"144722242\",\"name\":\"A. Bertozzi\"},{\"authorId\":\"1970636\",\"name\":\"P. Brantingham\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0dbdf9665f1d810f3d6a8fa3092c7307920d874\",\"title\":\"Semi-Supervised First-Person Activity Recognition in Body-Worn Video\",\"url\":\"https://www.semanticscholar.org/paper/f0dbdf9665f1d810f3d6a8fa3092c7307920d874\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48183487\",\"name\":\"S. Samiei\"},{\"authorId\":\"134598664\",\"name\":\"Pejman Rasti\"},{\"authorId\":\"145631453\",\"name\":\"P. Richard\"},{\"authorId\":\"3395751\",\"name\":\"G. Galopin\"},{\"authorId\":\"153766356\",\"name\":\"D. Rousseau\"}],\"doi\":\"10.3390/s20154173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2195df91a37dc03f682ecb12ebaa5db7f77fc54\",\"title\":\"Toward Joint Acquisition-Annotation of Images with Egocentric Devices for a Lower-Cost Machine Learning Application to Apple Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2195df91a37dc03f682ecb12ebaa5db7f77fc54\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ACCESS.2020.2990333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b516f02c6fc6f923100f377b6aaa4ca3e515331d\",\"title\":\"Activities of Daily Living Monitoring via a Wearable Camera: Toward Real-World Applications\",\"url\":\"https://www.semanticscholar.org/paper/b516f02c6fc6f923100f377b6aaa4ca3e515331d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51243449\",\"name\":\"Atanas Poibrenski\"},{\"authorId\":\"1798357\",\"name\":\"M. Klusch\"},{\"authorId\":\"1596870919\",\"name\":\"Igor Vozniak\"},{\"authorId\":\"143851843\",\"name\":\"C. M\\u00fcller\"}],\"doi\":\"10.1145/3341105.3373877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a6af33e8117079372b60ba65dc15a4738105162\",\"title\":\"M2P3: multimodal multi-pedestrian path prediction by self-driving cars with egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/6a6af33e8117079372b60ba65dc15a4738105162\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"8425523\",\"name\":\"J. Hirayama\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"686b14ce7f02516730de03f459cadb223a03765f\",\"title\":\"Generating an Event Timeline About Daily Activities From a Semantic Concept Stream\",\"url\":\"https://www.semanticscholar.org/paper/686b14ce7f02516730de03f459cadb223a03765f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995028\",\"name\":\"K. Suma\"},{\"authorId\":\"71879392\",\"name\":\"G. Aditya\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1145/3293353.3293362\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc5e3095ce86de685418fb7ca2062eab21214801\",\"title\":\"Activity Recognition in Egocentric Videos Using Bag of Key Action Units\",\"url\":\"https://www.semanticscholar.org/paper/dc5e3095ce86de685418fb7ca2062eab21214801\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576151335\",\"name\":\"Trung Ky Nguyen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"36a8af51e773b19dead1ff121acb849532423c62\",\"title\":\"Story Generation from Smart Phone Data : A script approach. (G\\u00e9n\\u00e9ration d'histoires \\u00e0 partir de donn\\u00e9es de t\\u00e9l\\u00e9phone intelligentes : une approche de script)\",\"url\":\"https://www.semanticscholar.org/paper/36a8af51e773b19dead1ff121acb849532423c62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.07020\",\"authors\":[{\"authorId\":\"143732624\",\"name\":\"L. Xue\"},{\"authorId\":\"79977043\",\"name\":\"Si Xiandong\"},{\"authorId\":\"9391348\",\"name\":\"Nie Lan-shun\"},{\"authorId\":\"51426729\",\"name\":\"Li Jia-zhen\"},{\"authorId\":\"79352992\",\"name\":\"Ding Ren-jie\"},{\"authorId\":\"9203712\",\"name\":\"Zhan De-chen\"},{\"authorId\":\"9406694\",\"name\":\"Chu Dian-hui\"}],\"doi\":\"10.4108/EAI.21-6-2018.2276632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58c89c038ac14cb4b86fc37708f3f2fbaeea9886\",\"title\":\"Understanding and Improving Deep Neural Network for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58c89c038ac14cb4b86fc37708f3f2fbaeea9886\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.08381\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7c9b3eb8737d29a779a0e21e355543c22ccca49\",\"title\":\"Learning to Localize and Align Fine-Grained Actions to Sparse Instructions\",\"url\":\"https://www.semanticscholar.org/paper/a7c9b3eb8737d29a779a0e21e355543c22ccca49\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3072340\",\"name\":\"Zhongyang Zheng\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"46396212\",\"name\":\"Y. Wang\"},{\"authorId\":\"145071104\",\"name\":\"Shuang Yang\"},{\"authorId\":\"2194801\",\"name\":\"Zhongqian Dong\"},{\"authorId\":\"2517946\",\"name\":\"T. Yi\"},{\"authorId\":\"2007103\",\"name\":\"Cyrus Choi\"},{\"authorId\":\"2871091\",\"name\":\"Emily J. Chang\"},{\"authorId\":\"33794424\",\"name\":\"E. Chang\"}],\"doi\":\"10.1145/3123266.3123308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d8dbb50bdf046ab6cf8f265da8dba6a01a39067\",\"title\":\"Aristo: An Augmented Reality Platform for Immersion and Interactivity\",\"url\":\"https://www.semanticscholar.org/paper/5d8dbb50bdf046ab6cf8f265da8dba6a01a39067\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1903.00618\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"145489010\",\"name\":\"Yuchen Wang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"144729148\",\"name\":\"E. Atkins\"}],\"doi\":\"10.1109/IROS40897.2019.8967556\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7787488d4b1c0487b4393f44bc3d0148e15cf0c5\",\"title\":\"Unsupervised Traffic Accident Detection in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/7787488d4b1c0487b4393f44bc3d0148e15cf0c5\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"1809.07408\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"144729148\",\"name\":\"E. Atkins\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/ICRA.2019.8794474\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"497db84d084c34cf2db8883f95000953deeeddcc\",\"title\":\"Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems\",\"url\":\"https://www.semanticscholar.org/paper/497db84d084c34cf2db8883f95000953deeeddcc\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdb21633febd52b08a2059d03da083d191925413\",\"title\":\"Initial Round \\\\ FC 8 Unlabeled First-Person Training Images : MCG Projection Visual Pathway Predictions Spatial Pathway Predictions MCG Projection MCG Projection Backward Pass Forward Pass Backward Pass Backward\",\"url\":\"https://www.semanticscholar.org/paper/fdb21633febd52b08a2059d03da083d191925413\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1905.00742\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe9083f8d8a4d3c0a00b2c1caf3bf8a14d5c332e\",\"title\":\"Egocentric Hand Track and Object-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe9083f8d8a4d3c0a00b2c1caf3bf8a14d5c332e\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"3190022\",\"name\":\"Danping Liao\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICCVW.2019.00543\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"title\":\"Learning Spatiotemporal Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28911396\",\"name\":\"H. Jiang\"},{\"authorId\":\"48481808\",\"name\":\"Y. Song\"},{\"authorId\":\"49264448\",\"name\":\"Jiang He\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1007/978-3-030-37731-1_58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7451295f7d5fe96e2c350f04b40df80df2810cd\",\"title\":\"Cross Fusion for Egocentric Interactive Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a7451295f7d5fe96e2c350f04b40df80df2810cd\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1904.01650\",\"authors\":[{\"authorId\":\"40611227\",\"name\":\"Rosario Scalise\"},{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"1752197\",\"name\":\"S. Srinivasa\"}],\"doi\":\"10.1109/IROS40897.2019.8968142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b06fe6ca5f4404e68b066cdea1a74a36e3e0e13\",\"title\":\"Improving Robot Success Detection using Static Object Data\",\"url\":\"https://www.semanticscholar.org/paper/1b06fe6ca5f4404e68b066cdea1a74a36e3e0e13\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"1612.07796\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2017.399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"title\":\"First-Person Activity Forecasting with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1710.07477\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"16261770\",\"name\":\"Ting-An Chien\"},{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2017.15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"604575bf821ad655e195a78d53badb0a636ffa0f\",\"title\":\"Anticipating Daily Intention Using On-wrist Motion Triggered Sensing\",\"url\":\"https://www.semanticscholar.org/paper/604575bf821ad655e195a78d53badb0a636ffa0f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1809.00402\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"32212960\",\"name\":\"E. Talavera\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cbd2ea8f338bfb8c943a9b7a70a22657353ab4a\",\"title\":\"On the Role of Event Boundaries in Egocentric Activity Recognition from Photostreams\",\"url\":\"https://www.semanticscholar.org/paper/1cbd2ea8f338bfb8c943a9b7a70a22657353ab4a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"},{\"authorId\":\"2714949\",\"name\":\"C. Fuegen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e7912bc8af639b8612fa57abc7a3fa672eabf56\",\"title\":\"Facebook Acoustic Events Dataset\",\"url\":\"https://www.semanticscholar.org/paper/5e7912bc8af639b8612fa57abc7a3fa672eabf56\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1604.00427\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8926471921ff608f70c6c81777782974a91086ae\",\"title\":\"Leaving Some Stones Unturned: Dynamic Feature Prioritization for Activity Detection in Streaming Video\",\"url\":\"https://www.semanticscholar.org/paper/8926471921ff608f70c6c81777782974a91086ae\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCVW.2017.280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"title\":\"How Shall We Evaluate Egocentric Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"title\":\"Inertial-Vision: Cross-Domain Knowledge Transfer for Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1704.00098\",\"authors\":[{\"authorId\":\"145022261\",\"name\":\"Shan Su\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"603dee8661aa9bf0d7af6c61fe5fa2e85227f166\",\"title\":\"Customizing First Person Image Through Desired Actions\",\"url\":\"https://www.semanticscholar.org/paper/603dee8661aa9bf0d7af6c61fe5fa2e85227f166\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1701.00142\",\"authors\":[{\"authorId\":\"2933543\",\"name\":\"Helge Rhodin\"},{\"authorId\":\"1819028\",\"name\":\"Christian Richardt\"},{\"authorId\":\"1863006\",\"name\":\"Dan Casas\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"144784832\",\"name\":\"Mohammad Shafiei\"},{\"authorId\":\"145791333\",\"name\":\"Hans-Peter Seidel\"},{\"authorId\":\"1697100\",\"name\":\"Bernt Schiele\"},{\"authorId\":\"1680185\",\"name\":\"Christian Theobalt\"}],\"doi\":\"10.1145/2980179.2980235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f18ef0800e276617e458bc21502947f35a7f94\",\"title\":\"EgoCap: Egocentric Marker-less Motion Capture with Two Fisheye Cameras\",\"url\":\"https://www.semanticscholar.org/paper/44f18ef0800e276617e458bc21502947f35a7f94\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1905.04107\",\"authors\":[{\"authorId\":\"32212960\",\"name\":\"E. Talavera\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1730388\",\"name\":\"N. Petkov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"40b004a5d115d2c85648063d38ef5ef1fb8ea28a\",\"title\":\"Towards Emotion Retrieval in Egocentric PhotoStream\",\"url\":\"https://www.semanticscholar.org/paper/40b004a5d115d2c85648063d38ef5ef1fb8ea28a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.07470\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"46836072\",\"name\":\"S. Kundu\"},{\"authorId\":\"1945699686\",\"name\":\"Nikhil Gunti\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"051dc6c1821721151bea555307c5a6bc72965a55\",\"title\":\"Knowledge Guided Learning: Towards Open Domain Egocentric Action Recognition with Zero Supervision\",\"url\":\"https://www.semanticscholar.org/paper/051dc6c1821721151bea555307c5a6bc72965a55\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13586\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"50204657\",\"name\":\"Yijun Cai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"title\":\"Deep Dual Relation Modeling for Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.07889\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1109/ICCVW.2017.277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1e388269ea8ce7074f804f79e158038f629a0df\",\"title\":\"Batch-Based Activity Recognition from Egocentric Photo-Streams\",\"url\":\"https://www.semanticscholar.org/paper/d1e388269ea8ce7074f804f79e158038f629a0df\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1909.08150\",\"authors\":[{\"authorId\":\"51128743\",\"name\":\"Srikanth Malla\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ee3537572b04bd3b09c9cda832f89e41ddeaf35\",\"title\":\"NEMO: Future Object Localization Using Noisy Ego Priors\",\"url\":\"https://www.semanticscholar.org/paper/1ee3537572b04bd3b09c9cda832f89e41ddeaf35\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453887227\",\"name\":\"Pablo Laiz\"},{\"authorId\":\"1793079\",\"name\":\"Jordi Vitri\\u00e0\"},{\"authorId\":\"1557566239\",\"name\":\"Santi Segu\\u00ed\"}],\"doi\":\"10.1109/ICCVW.2019.00051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96d759493fef318cdb2c5d3043c5e2e32f4f8a02\",\"title\":\"Using the Triplet Loss for Domain Adaptation in WCE\",\"url\":\"https://www.semanticscholar.org/paper/96d759493fef318cdb2c5d3043c5e2e32f4f8a02\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789861350\",\"name\":\"Teerawat Kumrai\"},{\"authorId\":\"1789889055\",\"name\":\"Joseph Korpela\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"153020914\",\"name\":\"Y. Yu\"},{\"authorId\":\"1800112\",\"name\":\"R. Kanai\"}],\"doi\":\"10.1109/PerCom45495.2020.9127376\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75a7031603f16a51c9c1aa7998643bd8503a9ec6\",\"title\":\"Human Activity Recognition with Deep Reinforcement Learning using the Camera of a Mobile Robot\",\"url\":\"https://www.semanticscholar.org/paper/75a7031603f16a51c9c1aa7998643bd8503a9ec6\",\"venue\":\"2020 IEEE International Conference on Pervasive Computing and Communications (PerCom)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"}],\"doi\":\"10.1109/PERCOMW.2018.8480258\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"63552df3d8471207ff6e9e4b9933b41776e3ec8a\",\"title\":\"Where Am I? Comparing CNN and LSTM for Location Classification in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/63552df3d8471207ff6e9e4b9933b41776e3ec8a\",\"venue\":\"2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)\",\"year\":2018},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2513690\",\"name\":\"Tengqi Ye\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3067ed175499d7fcf214781b36302b76c65ed57\",\"title\":\"Visual object detection from lifelogs using visual non-lifelog data\",\"url\":\"https://www.semanticscholar.org/paper/f3067ed175499d7fcf214781b36302b76c65ed57\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1710.03755\",\"authors\":[{\"authorId\":\"1413956873\",\"name\":\"Nisha Vinayaga-Sureshkanth\"},{\"authorId\":\"34645101\",\"name\":\"A. Maiti\"},{\"authorId\":\"2235825\",\"name\":\"M. Jadliwala\"},{\"authorId\":\"3409217\",\"name\":\"K. Crager\"},{\"authorId\":\"1399925136\",\"name\":\"J. He\"},{\"authorId\":\"35472095\",\"name\":\"Heena Rathore\"}],\"doi\":\"10.1109/PERCOMW.2018.8480238\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43f69138e7fda4c6b59f3cb7026947abecb7223e\",\"title\":\"Towards a Practical Pedestrian Distraction Detection Framework using Wearables\",\"url\":\"https://www.semanticscholar.org/paper/43f69138e7fda4c6b59f3cb7026947abecb7223e\",\"venue\":\"2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2255226\",\"name\":\"H. Yu\"},{\"authorId\":\"1730644\",\"name\":\"W. Jia\"},{\"authorId\":\"1700892\",\"name\":\"Z. Li\"},{\"authorId\":\"2126283\",\"name\":\"Feixiang Gong\"},{\"authorId\":\"144437722\",\"name\":\"D. Yuan\"},{\"authorId\":\"46701928\",\"name\":\"H. Zhang\"},{\"authorId\":\"145070659\",\"name\":\"M. Sun\"}],\"doi\":\"10.1186/s13634-019-0612-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7212c39df46655a2b212e9a09d9a4ddec6f52959\",\"title\":\"A multisource fusion framework driven by user-defined knowledge for egocentric activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/7212c39df46655a2b212e9a09d9a4ddec6f52959\",\"venue\":\"EURASIP J. Adv. Signal Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.318\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"414c85e333a24456a3bb5b194d97e95e69175dea\",\"title\":\"Jointly Recognizing Object Fluents and Tasks in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/414c85e333a24456a3bb5b194d97e95e69175dea\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2005.05856\",\"authors\":[{\"authorId\":\"35756311\",\"name\":\"P. A. Dias\"},{\"authorId\":\"2767912\",\"name\":\"H. Medeiros\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bda77e052170cc15ff2672df6273849edf9d959\",\"title\":\"Probabilistic Semantic Segmentation Refinement by Monte Carlo Region Growing\",\"url\":\"https://www.semanticscholar.org/paper/6bda77e052170cc15ff2672df6273849edf9d959\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.05959\",\"authors\":[{\"authorId\":\"2470018\",\"name\":\"WeiPeng Xu\"},{\"authorId\":\"49926328\",\"name\":\"A. Chatterjee\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"153918727\",\"name\":\"P. Fua\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/TVCG.2019.2898650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3b4f711f415d5559e0626543c5413e4f6ec71c6\",\"title\":\"Mo2Cap2: Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye Camera\",\"url\":\"https://www.semanticscholar.org/paper/c3b4f711f415d5559e0626543c5413e4f6ec71c6\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"08825ffe4dc4f673eb86de43f9a708c85cdf9947\",\"title\":\"Contextually Driven First-person Action Recognition From Videos\",\"url\":\"https://www.semanticscholar.org/paper/08825ffe4dc4f673eb86de43f9a708c85cdf9947\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d572e5851306d7d420a619469c8f449943f5880\",\"title\":\"Modeling Long-Term Interactions to Enhance Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d572e5851306d7d420a619469c8f449943f5880\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1611.05365\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICCV.2017.239\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"61f8b4a736d5d7aebc64144112720edaef05610a\",\"title\":\"Am I a Baller? Basketball Performance Assessment from First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/61f8b4a736d5d7aebc64144112720edaef05610a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145311611\",\"name\":\"Artur Jordao\"},{\"authorId\":\"49084751\",\"name\":\"L. A. B. Torres\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1007/s11760-018-1293-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fa997b0f67b51ae5462b1ed40177616831ef4ed\",\"title\":\"Novel approaches to human activity recognition based on accelerometer data\",\"url\":\"https://www.semanticscholar.org/paper/5fa997b0f67b51ae5462b1ed40177616831ef4ed\",\"venue\":\"Signal Image Video Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491820\",\"name\":\"Nicholas Soures\"},{\"authorId\":\"3327477\",\"name\":\"D. Kudithipudi\"}],\"doi\":\"10.3389/fnins.2019.00686\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47077e47f18f4f63cb30ec90058eb0d59c69c8b5\",\"title\":\"Deep Liquid State Machines With Neural Plasticity for Video Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47077e47f18f4f63cb30ec90058eb0d59c69c8b5\",\"venue\":\"Front. Neurosci.\",\"year\":2019},{\"arxivId\":\"1904.05349\",\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/CVPR.2019.00464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"title\":\"H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1851536\",\"name\":\"C. Asakawa\"}],\"doi\":\"10.1145/3025453.3025899\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e00a6c6b0ff5575c304fefbdad7c88b16de171d\",\"title\":\"People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/8e00a6c6b0ff5575c304fefbdad7c88b16de171d\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":\"2002.12557\",\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1109/WACV45572.2020.9093353\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb634ac5f4d8166e7ba56bfd089cc0809ac6d71f\",\"title\":\"Hand-Priming in Object Localization for Assistive Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/fb634ac5f4d8166e7ba56bfd089cc0809ac6d71f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"41051809\",\"name\":\"Alireza Haji Fathaliyan\"},{\"authorId\":\"145577652\",\"name\":\"V. Santos\"}],\"doi\":\"10.3389/fnbot.2020.567571\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"467bc21ba8935685a98794fa15bc83638ec9626b\",\"title\":\"Toward Shared Autonomy Control Schemes for Human-Robot Systems: Action Primitive Recognition Using Eye Gaze Features\",\"url\":\"https://www.semanticscholar.org/paper/467bc21ba8935685a98794fa15bc83638ec9626b\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48607291\",\"name\":\"Yi Wu\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/ICCV.2017.406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"title\":\"Egocentric Gesture Recognition Using Recurrent 3D Convolutional Neural Networks with Spatiotemporal Transformer Modules\",\"url\":\"https://www.semanticscholar.org/paper/f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1912.10867\",\"authors\":[{\"authorId\":\"39612426\",\"name\":\"A. Bandini\"},{\"authorId\":\"1870273\",\"name\":\"J. Zariffa\"}],\"doi\":\"10.1109/TPAMI.2020.2986648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee84cebd99eca11eaf826a803feeb804634536dc\",\"title\":\"Analysis of the hands in egocentric vision: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ee84cebd99eca11eaf826a803feeb804634536dc\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3132818.3132831\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fdac02fd55308be6580ba289134a91376906b1f\",\"title\":\"Egoscanning: quickly scanning first-person videos with egocentric elastic timelines\",\"url\":\"https://www.semanticscholar.org/paper/1fdac02fd55308be6580ba289134a91376906b1f\",\"venue\":\"SIGGRAPH ASIA Emerging Technologies\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1007/978-3-030-25590-9_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2def8f26aabc1a5fd646aa4a9f17ab47e241e529\",\"title\":\"Object Detection-Based Location and Activity Classification from Egocentric Videos: A Systematic Analysis\",\"url\":\"https://www.semanticscholar.org/paper/2def8f26aabc1a5fd646aa4a9f17ab47e241e529\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145295896\",\"name\":\"Y. Shen\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"2492392\",\"name\":\"N. Zhuang\"}],\"doi\":\"10.1007/978-3-030-01216-8_13\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"title\":\"Egocentric Activity Prediction via Event Modulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1145/3242969.3242982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5415611fc9a55355d9dc7ff044bd9e2e3ca38c6b\",\"title\":\"Estimating Head Motion from Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/5415611fc9a55355d9dc7ff044bd9e2e3ca38c6b\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/TPAMI.2018.2873794\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"title\":\"First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153564324\",\"name\":\"Zeynep G\\u00f6k\\u00e7e\"},{\"authorId\":\"1390466817\",\"name\":\"Selen Pehlivan\"}],\"doi\":\"10.1109/SIU.2019.8806562\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"280bab045e794341af3e5e7514bd833a318ab473\",\"title\":\"Human Action Recognition in First Person Videos using Verb-Object Pairs\",\"url\":\"https://www.semanticscholar.org/paper/280bab045e794341af3e5e7514bd833a318ab473\",\"venue\":\"2019 27th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be35517555e01428ed04577f4e7e566041706aa9\",\"title\":\"Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be35517555e01428ed04577f4e7e566041706aa9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9115391\",\"name\":\"G. Li\"},{\"authorId\":\"143895325\",\"name\":\"L. Deng\"},{\"authorId\":\"3401913\",\"name\":\"Yansong Chua\"},{\"authorId\":null,\"name\":\"Peng Li\"},{\"authorId\":\"1404242270\",\"name\":\"Emre O. Neftci\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.3389/fnins.2020.00276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb6862574ecdecd482779a43d0d643560cebe947\",\"title\":\"Editorial: Spiking Neural Network Learning, Benchmarking, Programming and Executing\",\"url\":\"https://www.semanticscholar.org/paper/cb6862574ecdecd482779a43d0d643560cebe947\",\"venue\":\"Frontiers in Neuroscience\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/ICME.2017.8019520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00083b3b6c356aca3eccfa26988ce52a6682bd6b\",\"title\":\"Temporal aggregation for first-person action recognition using Hilbert-Huang transform\",\"url\":\"https://www.semanticscholar.org/paper/00083b3b6c356aca3eccfa26988ce52a6682bd6b\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1807.11794\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"title\":\"Attention is All We Need: Nailing Down Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4947266e0caa3d8be726b98f5be08217748a6e20\",\"title\":\"Input Mask Encoder z Decoder Reconstructed Mask a ) VAE Input Mask Action CNN b ) Action CNN Predicted Action Probability Fixed Action\",\"url\":\"https://www.semanticscholar.org/paper/4947266e0caa3d8be726b98f5be08217748a6e20\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1709.01630\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"46865173\",\"name\":\"Jianbo Shi\"}],\"doi\":\"10.1109/ICCVW.2017.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eb200cc606ec9290acdf4679fa4315c1bbe725d\",\"title\":\"Using Cross-Model EgoSupervision to Learn Cooperative Basketball Intention\",\"url\":\"https://www.semanticscholar.org/paper/5eb200cc606ec9290acdf4679fa4315c1bbe725d\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39109324\",\"name\":\"R. Luo\"},{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/3DV.2017.00073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58479c8c958584d501226712cba955dc98fc3f63\",\"title\":\"Scene Semantic Reconstruction from Egocentric RGB-D-Thermal Videos\",\"url\":\"https://www.semanticscholar.org/paper/58479c8c958584d501226712cba955dc98fc3f63\",\"venue\":\"2017 International Conference on 3D Vision (3DV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4887445\",\"name\":\"Tomoya Nakatani\"},{\"authorId\":\"35421395\",\"name\":\"Ryohei Kuga\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"}],\"doi\":\"10.1145/3282894.3289728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef372f6a5ead95b328e9b1608af942193cd63994\",\"title\":\"Object-based Activity Recognition Using Egocentric Video Based on Web Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/ef372f6a5ead95b328e9b1608af942193cd63994\",\"venue\":\"2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)\",\"year\":2019},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144444772\",\"name\":\"S. J. Berlin\"},{\"authorId\":\"34799829\",\"name\":\"M. John\"}],\"doi\":\"10.1007/s11042-020-08704-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a093bb0526c3e21469be8be537bbbf01198d0616\",\"title\":\"Particle swarm optimization with deep learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a093bb0526c3e21469be8be537bbbf01198d0616\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"10684139\",\"name\":\"J. Aires\"},{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"}],\"doi\":\"10.1109/IJCNN.2017.7966130\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20bda5e991a7c0774f2767b80de0ff54db1adf1b\",\"title\":\"Virtual guide dog: An application to support visually-impaired people through deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/20bda5e991a7c0774f2767b80de0ff54db1adf1b\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51207457\",\"name\":\"Chengzhang Zhong\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"},{\"authorId\":\"1423744921\",\"name\":\"Hansel Mina Cordoba\"},{\"authorId\":\"40268177\",\"name\":\"A. Deering\"}],\"doi\":\"10.1109/MMSP.2019.8901753\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eff8bfd489acbb0444a2b8def9632ae48029b7df\",\"title\":\"Hand-hygiene activity recognition in egocentric video\",\"url\":\"https://www.semanticscholar.org/paper/eff8bfd489acbb0444a2b8def9632ae48029b7df\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23276966\",\"name\":\"A. Nakazawa\"},{\"authorId\":\"6101063\",\"name\":\"M. Honda\"}],\"doi\":\"10.1109/ICCVW.2019.00544\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c388f71d209556c66415ff091a9c50864cf69ea9\",\"title\":\"First-Person Camera System to Evaluate Tender Dementia-Care Skill\",\"url\":\"https://www.semanticscholar.org/paper/c388f71d209556c66415ff091a9c50864cf69ea9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150296901\",\"name\":\"Shreyas Hampali\"},{\"authorId\":\"2650133\",\"name\":\"Markus Oberweger\"},{\"authorId\":\"144536317\",\"name\":\"M. Rad\"},{\"authorId\":\"144447227\",\"name\":\"Vincent Lepetit\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f649b8652703dd3053f798eae9e4b1fd44cd2f\",\"title\":\"HO-3D: A Multi-User, Multi-Object Dataset for Joint 3D Hand-Object Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/18f649b8652703dd3053f798eae9e4b1fd44cd2f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"1763134\",\"name\":\"Yeonho Kim\"},{\"authorId\":\"144499950\",\"name\":\"J. S. Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1016/j.patrec.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c81c88f74d466a65520ea9751970ff781352ec0a\",\"title\":\"First Person Action Recognition via Two-stream ConvNet with Long-term Fusion Pooling\",\"url\":\"https://www.semanticscholar.org/paper/c81c88f74d466a65520ea9751970ff781352ec0a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2018.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"title\":\"Personal-location-based temporal segmentation of egocentric videos for lifelogging applications\",\"url\":\"https://www.semanticscholar.org/paper/79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79993756\",\"name\":\"Haruya Ishikawa\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"48589121\",\"name\":\"Shuichi Akizuki\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.23919/MVA.2019.8757896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a019ef99567561824c50196f013eb73657b96232\",\"title\":\"Human-Object Maps for Daily Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a019ef99567561824c50196f013eb73657b96232\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/TIP.2017.2772904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a955ee69174fb97c7017f2e227a5fa26b900537\",\"title\":\"Egocentric Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/7a955ee69174fb97c7017f2e227a5fa26b900537\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2011.12102\",\"authors\":[{\"authorId\":\"1773047\",\"name\":\"Qing Gao\"},{\"authorId\":\"3356854\",\"name\":\"Ming-Tao Pei\"},{\"authorId\":\"2187859\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c195c6aa7269a7d4b64d24b079e3fd61d97f6e9c\",\"title\":\"Do You Live a Healthy Life? Analyzing Lifestyle by Visual Life Logging\",\"url\":\"https://www.semanticscholar.org/paper/c195c6aa7269a7d4b64d24b079e3fd61d97f6e9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122150713\",\"name\":\"Shuichi Urabe\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":\"10.1145/3230519.3230584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"title\":\"Cooking activities recognition in egocentric videos using combining 2DCNN and 3DCNN\",\"url\":\"https://www.semanticscholar.org/paper/43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"venue\":\"CEA@IJCAI\",\"year\":2018},{\"arxivId\":\"2011.01519\",\"authors\":[{\"authorId\":\"3358340\",\"name\":\"Denis Tom\\u00e8\"},{\"authorId\":\"1914886\",\"name\":\"Thiemo Alldieck\"},{\"authorId\":\"151353735\",\"name\":\"Patrick Peluse\"},{\"authorId\":\"1403428213\",\"name\":\"Gerard Pons-Moll\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"},{\"authorId\":\"2863682\",\"name\":\"H. Badino\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1109/TPAMI.2020.3029700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d77d035a5cdccbd96e2779cdcf69c05808559d2\",\"title\":\"SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/8d77d035a5cdccbd96e2779cdcf69c05808559d2\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dbe18855b85bc6f218c53993cf289e2607518b1\",\"title\":\"Learning Policies to Forecast Agent Behavior with Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/6dbe18855b85bc6f218c53993cf289e2607518b1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390872846\",\"name\":\"Mingdong Wang\"},{\"authorId\":\"49950733\",\"name\":\"Hai-Tao Fan\"},{\"authorId\":\"50844719\",\"name\":\"Jijun Tong\"},{\"authorId\":\"2419110\",\"name\":\"Lurong Jiang\"}],\"doi\":\"10.1007/978-981-15-5887-0_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d77c778c8dd971043eda8e25686af82583f514c\",\"title\":\"The Action Evaluation of Model Catwalk Based on Gait Segmentation and Template Comparison\",\"url\":\"https://www.semanticscholar.org/paper/8d77c778c8dd971043eda8e25686af82583f514c\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9362227\",\"name\":\"Sagar Verma\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72379808573cc333f63a3c774457d1770aca052d\",\"title\":\"Action recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/72379808573cc333f63a3c774457d1770aca052d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1710.04112\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/s10044-018-0708-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"726493da25879c1579941e9cbcd5e9a15c7665d1\",\"title\":\"Recognizing Daily Activities from Egocentric Photo-Streams\",\"url\":\"https://www.semanticscholar.org/paper/726493da25879c1579941e9cbcd5e9a15c7665d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3435194\",\"name\":\"El Asnaoui Khalid\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"15370656\",\"name\":\"Aksasse Brahim\"},{\"authorId\":\"15249320\",\"name\":\"Ouanan Mohammed\"}],\"doi\":\"10.1109/ISACV.2017.8054946\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f69a49d454c7da51d184992d776bed87ae0a0b3\",\"title\":\"Using content-based image retrieval to automatically assess day similarity in visual lifelogs\",\"url\":\"https://www.semanticscholar.org/paper/6f69a49d454c7da51d184992d776bed87ae0a0b3\",\"venue\":\"2017 Intelligent Systems and Computer Vision (ISCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743276\",\"name\":\"H. Ohashi\"},{\"authorId\":\"67338816\",\"name\":\"Mohammad Al-Naser\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1732106\",\"name\":\"Takayuki Akiyama\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"143995452\",\"name\":\"P. Nguyen\"},{\"authorId\":\"3062170\",\"name\":\"Katsuyuki Nakamura\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee9b0dde0debd74d4d48e16786c93430598d0d8f\",\"title\":\"Augmenting Wearable Sensor Data with Physical Constraint for DNN-Based Human-Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee9b0dde0debd74d4d48e16786c93430598d0d8f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1704.02463\",\"authors\":[{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"3325819\",\"name\":\"Shanxin Yuan\"},{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/CVPR.2018.00050\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"title\":\"First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations\",\"url\":\"https://www.semanticscholar.org/paper/e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"1764228\",\"name\":\"Chaoqun Weng\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1109/TCSVT.2018.2818151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e97ccbf38bb246b7fc44f03f0d164df0406e412d\",\"title\":\"Discriminative Spatio-Temporal Pattern Discovery for 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e97ccbf38bb246b7fc44f03f0d164df0406e412d\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2003.06045\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"1947383\",\"name\":\"Ashish Tawari\"},{\"authorId\":\"1841835\",\"name\":\"Sujitha Martin\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICRA40945.2020.9197104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"title\":\"Interaction Graphs for Object Importance Estimation in On-road Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1808.01725\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-030-01252-6_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"title\":\"Liquid Pouring Monitoring via Rich Sensory Inputs\",\"url\":\"https://www.semanticscholar.org/paper/e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12372393\",\"name\":\"Kunwar Yashraj Singh\"},{\"authorId\":\"49926372\",\"name\":\"N. Davis\"},{\"authorId\":\"38812851\",\"name\":\"Chih-Pin Hsiao\"},{\"authorId\":\"3108794\",\"name\":\"Mikhail Jacob\"},{\"authorId\":\"144000742\",\"name\":\"Krunal Patel\"},{\"authorId\":\"1691882\",\"name\":\"Brian Magerko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bdfc646b472cf93f1c2ef10602cc937f935d3c1\",\"title\":\"Recognizing Actions in Motion Trajectories Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8bdfc646b472cf93f1c2ef10602cc937f935d3c1\",\"venue\":\"AIIDE\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148404881\",\"name\":\"Yusei Oozono\"},{\"authorId\":\"2108938\",\"name\":\"H. Yamazoe\"},{\"authorId\":\"4165428\",\"name\":\"J. Lee\"}],\"doi\":\"10.1109/UR49135.2020.9144978\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3abd3e4a3198e5f0b642e0f9d5d634f74bb72d9f\",\"title\":\"Pointing Direction Estimation for Attention Target Extraction Using Body-mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/3abd3e4a3198e5f0b642e0f9d5d634f74bb72d9f\",\"venue\":\"2020 17th International Conference on Ubiquitous Robots (UR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22211769\",\"name\":\"Ikechukwu Ofodile\"},{\"authorId\":\"153787667\",\"name\":\"A. Helmi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"1950969\",\"name\":\"E. Avots\"},{\"authorId\":\"113565024\",\"name\":\"Kerttu Maria Peensoo\"},{\"authorId\":\"11373165\",\"name\":\"Sandhra-Mirella Valdma\"},{\"authorId\":\"14064057\",\"name\":\"A. Valdmann\"},{\"authorId\":\"1403959466\",\"name\":\"H. Valtna-Lukner\"},{\"authorId\":\"11322400\",\"name\":\"S. Omelkov\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"47731126\",\"name\":\"Cagri Ozcinar\"},{\"authorId\":\"3087532\",\"name\":\"G. Anbarjafari\"}],\"doi\":\"10.3390/e21040414\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dca0034b6148453a6426ca88fb7609c61274c6c5\",\"title\":\"Action Recognition Using Single-Pixel Time-of-Flight Detection\",\"url\":\"https://www.semanticscholar.org/paper/dca0034b6148453a6426ca88fb7609c61274c6c5\",\"venue\":\"Entropy\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3206025.3206041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"title\":\"Recognizing Actions in Wearable-Camera Videos by Training Classifiers on Fixed-Camera Videos\",\"url\":\"https://www.semanticscholar.org/paper/b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1901.03450\",\"authors\":[{\"authorId\":\"144601431\",\"name\":\"Chao Cai\"},{\"authorId\":\"143979115\",\"name\":\"Rong Zheng\"},{\"authorId\":\"2751352\",\"name\":\"M. Hu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d8b28ce136fb0faf4c26c27e6926ef678d14b11\",\"title\":\"A survey on acoustic sensing\",\"url\":\"https://www.semanticscholar.org/paper/8d8b28ce136fb0faf4c26c27e6926ef678d14b11\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.09627\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1145/3265987.3265995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.01413\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2018.00617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bfa0c14c2ae48c1ee6b145008137e4d69688416\",\"title\":\"Egocentric Basketball Motion Planning from a Single First-Person Image\",\"url\":\"https://www.semanticscholar.org/paper/8bfa0c14c2ae48c1ee6b145008137e4d69688416\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1704.04097\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/978-3-319-58838-4_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73a4b994c9f521153881e1c02e47086afa978566\",\"title\":\"Recognizing Activities of Daily Living from Egocentric Images\",\"url\":\"https://www.semanticscholar.org/paper/73a4b994c9f521153881e1c02e47086afa978566\",\"venue\":\"IbPRIA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alexandra Maha Abbas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0b8971c6a7f7d9fb73bc4414623a6dc7e8a183c\",\"title\":\"Object Detection on Large-Scale Egocentric Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e0b8971c6a7f7d9fb73bc4414623a6dc7e8a183c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50333150\",\"name\":\"Ning Zhuang\"},{\"authorId\":\"49347106\",\"name\":\"Q. Zhang\"},{\"authorId\":\"46724087\",\"name\":\"Y. Shen\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1016/J.PATREC.2019.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e2bcdd3632f7627ca00169cc3ca27be90d99154\",\"title\":\"Long term activity prediction in first person viewpoint\",\"url\":\"https://www.semanticscholar.org/paper/4e2bcdd3632f7627ca00169cc3ca27be90d99154\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16185102\",\"name\":\"Lingling Fa\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1007/978-3-319-73600-6_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e796f2e22d4598de4a80f6796df5ec2067e63a55\",\"title\":\"Global and Local C3D Ensemble System for First Person Interactive Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e796f2e22d4598de4a80f6796df5ec2067e63a55\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"121136457\",\"name\":\"E. V. Dam\"},{\"authorId\":\"46707400\",\"name\":\"R. Poppe\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"da73cc92995c3764e2ab49981bca2d5ba7b0be82\",\"title\":\"Action Detection from Egocentric Videos in Daily Living Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/da73cc92995c3764e2ab49981bca2d5ba7b0be82\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47528018\",\"name\":\"Weiming Zhang\"},{\"authorId\":\"11833179\",\"name\":\"Y. Huang\"},{\"authorId\":\"50239804\",\"name\":\"Wanting Yu\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"152958348\",\"name\":\"J. Sang\"}],\"doi\":\"10.1145/3338533.3366592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ffa55458f24787542860c8224cd97249836576c\",\"title\":\"Multimodal Attribute and Feature Embedding for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ffa55458f24787542860c8224cd97249836576c\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3090299\",\"name\":\"Sungmin Eum\"},{\"authorId\":\"2445131\",\"name\":\"Hyungtae Lee\"},{\"authorId\":\"1688527\",\"name\":\"H. Kwon\"}],\"doi\":\"10.1117/12.2306086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"153fe1f6cad586846a03ef1c7a178a582c1949e8\",\"title\":\"Going deeper with CNN in malicious crowd event classification\",\"url\":\"https://www.semanticscholar.org/paper/153fe1f6cad586846a03ef1c7a178a582c1949e8\",\"venue\":\"Defense + Security\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.721\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36e093e2c6142017e61c37200e915fd08d2456a1\",\"title\":\"Jointly Learning Energy Expenditures and Activities Using Egocentric Multimodal Signals\",\"url\":\"https://www.semanticscholar.org/paper/36e093e2c6142017e61c37200e915fd08d2456a1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2001.01083\",\"authors\":[{\"authorId\":\"51991145\",\"name\":\"Naina Dhingra\"},{\"authorId\":\"143717147\",\"name\":\"A. Kunz\"}],\"doi\":\"10.1109/3DV.2019.00061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"title\":\"Res3ATN - Deep 3D Residual Attention Network for Hand Gesture Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":\"2011.03920\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e61ed06f8778d03f0f32d7a94f01627b8557733e\",\"title\":\"Integrating Human Gaze into Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61ed06f8778d03f0f32d7a94f01627b8557733e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"101767253\",\"name\":\"J. Hong\"},{\"authorId\":\"1389222222\",\"name\":\"Simone Pimento\"},{\"authorId\":\"1389222220\",\"name\":\"Ebrima Jarjue\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1145/3308561.3353799\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"854f7ee708fdb78943c7b67dcf8f3b786d94b9b0\",\"title\":\"Revisiting Blind Photography in the Context of Teachable Object Recognizers\",\"url\":\"https://www.semanticscholar.org/paper/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0\",\"venue\":\"ASSETS\",\"year\":2019},{\"arxivId\":\"1612.05836\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"50528026\",\"name\":\"Krishna Regmi\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a74c9affc7209343026f8cd47d9b35fd818253c\",\"title\":\"EgoTransfer: Transferring Motion Across Egocentric and Exocentric Domains using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a74c9affc7209343026f8cd47d9b35fd818253c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67338816\",\"name\":\"Mohammad Al-Naser\"},{\"authorId\":\"1743276\",\"name\":\"H. Ohashi\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"1732106\",\"name\":\"Takayuki Akiyama\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"39483908\",\"name\":\"P. X. Nguyen\"},{\"authorId\":\"153402269\",\"name\":\"Andreas Dengel\"}],\"doi\":\"10.5220/0006595204780485\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d5c1d250bc505efadcc144eac7af220382fd3875\",\"title\":\"Hierarchical Model for Zero-shot Activity Recognition using Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/d5c1d250bc505efadcc144eac7af220382fd3875\",\"venue\":\"ICAART\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3025453.3025821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"835680aa3c770a2360e62e467d82760936e52431\",\"title\":\"EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines\",\"url\":\"https://www.semanticscholar.org/paper/835680aa3c770a2360e62e467d82760936e52431\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3293353.3293363\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"title\":\"Multimodal Egocentric Activity Recognition Using Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48046803\",\"name\":\"Bharat Lal Bhatnagar\"},{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.24963/ijcai.2017/200\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcf17cc3b4f8519a6789c1ea086689bcbc1d6f11\",\"title\":\"Unsupervised Learning of Deep Feature Representation for Clustering Egocentric Actions\",\"url\":\"https://www.semanticscholar.org/paper/dcf17cc3b4f8519a6789c1ea086689bcbc1d6f11\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/s10044-018-0708-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a625b55cf8914d6f275478773b84f58ad8ffdd85\",\"title\":\"Batch-based activity recognition from egocentric photo-streams revisited\",\"url\":\"https://www.semanticscholar.org/paper/a625b55cf8914d6f275478773b84f58ad8ffdd85\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"},{\"authorId\":\"7162505\",\"name\":\"A. Rugy\"}],\"doi\":\"10.1145/3206025.3206073\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"754876c90790b158aef5de8bbea297539dc81397\",\"title\":\"Perceptually-guided Understanding of Egocentric Video Content: Recognition of Objects to Grasp\",\"url\":\"https://www.semanticscholar.org/paper/754876c90790b158aef5de8bbea297539dc81397\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1807.00612\",\"authors\":[{\"authorId\":\"3172278\",\"name\":\"Mehmet Ali Arabaci\"},{\"authorId\":\"11255888\",\"name\":\"F. \\u00d6zkan\"},{\"authorId\":\"3299076\",\"name\":\"Elif Surer\"},{\"authorId\":\"1784515\",\"name\":\"P. Jancovic\"},{\"authorId\":\"1787799\",\"name\":\"Alptekin Temizel\"}],\"doi\":\"10.1007/s11042-020-08789-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"77181ce3e55e25da06d0ac584c3ceef313bdde3f\",\"title\":\"Multi-modal egocentric activity recognition using multi-kernel learning\",\"url\":\"https://www.semanticscholar.org/paper/77181ce3e55e25da06d0ac584c3ceef313bdde3f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918b67624d6f579567b7a191d01375339dd9298f\",\"title\":\"You 2 Me : Inferring Body Pose in Egocentric Video via First and Second Person Interactions by Evonne\",\"url\":\"https://www.semanticscholar.org/paper/918b67624d6f579567b7a191d01375339dd9298f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2568376\",\"name\":\"Abhimanyu Sahu\"},{\"authorId\":\"1384438931\",\"name\":\"Rajit Bhattacharya\"},{\"authorId\":\"1397164455\",\"name\":\"Pallabh Bhura\"},{\"authorId\":\"40272229\",\"name\":\"A. S. Chowdhury\"}],\"doi\":\"10.1007/978-981-32-9291-8_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3702830eeb1bc771a3a9b0133c407b1fe8afb4d3\",\"title\":\"Action Recognition from Egocentric Videos Using Random Walks\",\"url\":\"https://www.semanticscholar.org/paper/3702830eeb1bc771a3a9b0133c407b1fe8afb4d3\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d91632867822fc95a00348aeca3a3ea7844ab35a\",\"title\":\"Exploiting Visual-Spatial First-Person Co-Occurrence for Action-Object Detection without Labels\",\"url\":\"https://www.semanticscholar.org/paper/d91632867822fc95a00348aeca3a3ea7844ab35a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447347\",\"name\":\"H. Liu\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TPAMI.2017.2734779\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9dc41d3bc92e194c5a881ee9d741f898310ce9e\",\"title\":\"Two-Stream Transformer Networks for Video-Based Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/d9dc41d3bc92e194c5a881ee9d741f898310ce9e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1709.06495\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/ICCVW.2017.276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5155499812dafee92316bdbca5937f0e134514f3\",\"title\":\"Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5155499812dafee92316bdbca5937f0e134514f3\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51228744\",\"name\":\"Girmaw Abebe Tadesse\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1145/3211960.3211978\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d531875e928ae0e64df8a1618f47c111c9306b11\",\"title\":\"Visual features for ego-centric activity recognition: a survey\",\"url\":\"https://www.semanticscholar.org/paper/d531875e928ae0e64df8a1618f47c111c9306b11\",\"venue\":\"WearSys@MobiSys\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87116461\",\"name\":\"M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"80510807\",\"name\":\"E. Nascimento\"}],\"doi\":\"10.1109/SIBGRAPI-T.2019.00009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"title\":\"Fast-Forward Methods for Egocentric Videos: A Review\",\"url\":\"https://www.semanticscholar.org/paper/380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T)\",\"year\":2019},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yeping Wang\"},{\"authorId\":\"65770075\",\"name\":\"G. Ajaykumar\"},{\"authorId\":\"2805730\",\"name\":\"Chien-Ming Huang\"}],\"doi\":\"10.1145/3319502.3374820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9707757fd8bfb79def2853eaa4c7df0ac27330dc\",\"title\":\"See What I See: Enabling User-Centric Robotic Assistance Using First-Person Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/9707757fd8bfb79def2853eaa4c7df0ac27330dc\",\"venue\":\"HRI\",\"year\":2020},{\"arxivId\":\"1904.09882\",\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"},{\"authorId\":\"7996087\",\"name\":\"Hanbyul Joo\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/cvpr42600.2020.00991\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe87da6f364417d87ecaf525e563851718ffdb07\",\"title\":\"You2Me: Inferring Body Pose in Egocentric Video via First and Second Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/fe87da6f364417d87ecaf525e563851718ffdb07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35855259\",\"name\":\"R. Trabelsi\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"50081623\",\"name\":\"L. Zhang\"},{\"authorId\":\"1787085\",\"name\":\"I. Jabri\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"},{\"authorId\":\"2993100\",\"name\":\"F. Smach\"},{\"authorId\":\"144298084\",\"name\":\"A. Bouall\\u00e8gue\"},{\"authorId\":\"1742248\",\"name\":\"P. Moulin\"}],\"doi\":\"10.1145/3300937\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6204035ae26bc5601ae6866521ab9dff65803b4\",\"title\":\"Understanding the Dynamics of Social Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d6204035ae26bc5601ae6866521ab9dff65803b4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"1706028\",\"name\":\"L. Yang\"},{\"authorId\":\"2648838\",\"name\":\"Y. Peng\"},{\"authorId\":\"2864709\",\"name\":\"F. Chao\"},{\"authorId\":\"31851271\",\"name\":\"YanPeng Qu\"}],\"doi\":\"10.1109/ACCESS.2018.2808486\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6aa1b967b69897695b77a66dd36b5833581db49\",\"title\":\"Gaze-Informed Egocentric Action Recognition for Memory Aid Systems\",\"url\":\"https://www.semanticscholar.org/paper/d6aa1b967b69897695b77a66dd36b5833581db49\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1910.14260\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"46756438\",\"name\":\"Chen Yu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"title\":\"A Self Validation Network for Object-Level Human Attention Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50218246\",\"name\":\"Z. Wang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TCSVT.2018.2875441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a90a56267b66c060b235339a0080a00585fdeb41\",\"title\":\"Multi-Stream Deep Neural Networks for RGB-D Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a90a56267b66c060b235339a0080a00585fdeb41\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"},{\"authorId\":\"8258896\",\"name\":\"D. Cattaert\"},{\"authorId\":\"7162505\",\"name\":\"A. Rugy\"}],\"doi\":\"10.1016/j.patcog.2018.11.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81548cfb716a085ea6b2e56ee2dc8494fc6d19e4\",\"title\":\"Perceptually-guided deep neural networks for ego-action prediction: Object grasping\",\"url\":\"https://www.semanticscholar.org/paper/81548cfb716a085ea6b2e56ee2dc8494fc6d19e4\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1145/3290605.3300566\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de6562e7c3736b7e0c94f62f26ea1f77d44e4eff\",\"title\":\"Hands Holding Clues for Object Recognition in Teachable Machines\",\"url\":\"https://www.semanticscholar.org/paper/de6562e7c3736b7e0c94f62f26ea1f77d44e4eff\",\"venue\":\"CHI\",\"year\":2019},{\"arxivId\":\"1611.05335\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICCV.2017.216\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5ebfb763053d3a66e6a4f36ed443dc4ab5ac877\",\"title\":\"Unsupervised Learning of Important Objects from First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5ebfb763053d3a66e6a4f36ed443dc4ab5ac877\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2255226\",\"name\":\"H. Yu\"},{\"authorId\":\"65923466\",\"name\":\"Guoxiong Pan\"},{\"authorId\":\"144645724\",\"name\":\"M. Pan\"},{\"authorId\":\"49672995\",\"name\":\"Chong Li\"},{\"authorId\":\"1730644\",\"name\":\"W. Jia\"},{\"authorId\":\"39306621\",\"name\":\"L. Zhang\"},{\"authorId\":\"145070659\",\"name\":\"M. Sun\"}],\"doi\":\"10.3390/s19030546\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"288c1be23b143dd3e85f8b78e26b8516375b544e\",\"title\":\"A Hierarchical Deep Fusion Framework for Egocentric Activity Recognition using a Wearable Hybrid Sensor System\",\"url\":\"https://www.semanticscholar.org/paper/288c1be23b143dd3e85f8b78e26b8516375b544e\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1608.08139\",\"authors\":[{\"authorId\":\"144032116\",\"name\":\"C. Reyes\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":\"10.1145/2983576.2983582\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ee5e26d1b024d79f9d07068663244f1edbed7f\",\"title\":\"Where is my Phone?: Personal Object Retrieval from Egocentric Images\",\"url\":\"https://www.semanticscholar.org/paper/f8ee5e26d1b024d79f9d07068663244f1edbed7f\",\"venue\":\"LTA@MM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400685790\",\"name\":\"Jessica Beltr\\u00e1n-M\\u00e1rquez\"},{\"authorId\":\"1399106107\",\"name\":\"M. Garc\\u00eda-V\\u00e1zquez\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1384122700\",\"name\":\"L. Guti\\u00e9rrez-Robledo\"},{\"authorId\":\"80153973\",\"name\":\"J. Dartigues\"}],\"doi\":\"10.1155/2018/2676409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9a94545c781b455d962690c0d5b3e076bad233c\",\"title\":\"Computational Techniques for Eye Movements Analysis towards Supporting Early Diagnosis of Alzheimer's Disease: A Review\",\"url\":\"https://www.semanticscholar.org/paper/f9a94545c781b455d962690c0d5b3e076bad233c\",\"venue\":\"Comput. Math. Methods Medicine\",\"year\":2018},{\"arxivId\":\"2011.12263\",\"authors\":[{\"authorId\":\"29892729\",\"name\":\"Matteo Dunnhofer\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1708507\",\"name\":\"C. Micheloni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb03e3603fd08f857cb51ad4f82516a81e2a5858\",\"title\":\"Is First Person Vision Challenging for Object Tracking? The TREK-100 Benchmark Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bb03e3603fd08f857cb51ad4f82516a81e2a5858\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48186839\",\"name\":\"Yan Sun\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1727698\",\"name\":\"M. Nixon\"}],\"doi\":\"10.1016/j.patcog.2020.107710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eacf6707668d588696ba8b260170db6e2f1ae31\",\"title\":\"On parameterizing higher-order motion for behaviour recognition\",\"url\":\"https://www.semanticscholar.org/paper/1eacf6707668d588696ba8b260170db6e2f1ae31\",\"venue\":\"\",\"year\":2020}],\"corpusId\":5229785,\"doi\":\"10.1109/CVPR.2016.209\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":24,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2011.5995444\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc900a187b6f0115417f4b7dfd2cf44c62875bf8\",\"title\":\"Learning to recognize objects in egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bc900a187b6f0115417f4b7dfd2cf44c62875bf8\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2013.333\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42f55af5a0c774d5140df601b39167f94062ad6a\",\"title\":\"Modeling Actions through State Changes\",\"url\":\"https://www.semanticscholar.org/paper/42f55af5a0c774d5140df601b39167f94062ad6a\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"34420250\",\"name\":\"X. Chen\"},{\"authorId\":\"144799773\",\"name\":\"Xiaobai Liu\"},{\"authorId\":\"2853939\",\"name\":\"Nam-Gyu Cho\"},{\"authorId\":\"1703007\",\"name\":\"S. Lee\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2014.119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3419ccd5c94d301ee08d716d037f0c3c6a62e78e\",\"title\":\"The Role of Context for Object Detection and Semantic Segmentation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/3419ccd5c94d301ee08d716d037f0c3c6a62e78e\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Gupta\"},{\"authorId\":null,\"name\":\"A Kembhavi\"},{\"authorId\":null,\"name\":\"L S Davis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Observing humanobject interactions: Using spatial and functional compatibility for recognition. Pattern Analysis and Machine Intelligence\",\"url\":\"\",\"venue\":\"IEEE Transactions on\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"102595883\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1109/ICCV.2015.226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ef40f47e6f20c87391dd77b6e8c081709e1b8bd\",\"title\":\"Lending A Hand: Detecting Hands and Recognizing Activities in Complex Egocentric Interactions\",\"url\":\"https://www.semanticscholar.org/paper/7ef40f47e6f20c87391dd77b6e8c081709e1b8bd\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2093491\",\"name\":\"M. Oquab\"},{\"authorId\":\"119267979\",\"name\":\"L. Bottou\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2014.222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c08f5fa876181fc040d76c75fe2433eee3c9b001\",\"title\":\"Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c08f5fa876181fc040d76c75fe2433eee3c9b001\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.02897\",\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"145682405\",\"name\":\"J. Charles\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2015.222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f22f25904f85c657e10fcc262653ebb6187193f9\",\"title\":\"Flowing ConvNets for Human Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f22f25904f85c657e10fcc262653ebb6187193f9\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84362927\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"123108776\",\"name\":\"M.S. Ryoo\"}],\"doi\":\"10.1145/1922649.1922653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"title\":\"Human activity analysis: A review\",\"url\":\"https://www.semanticscholar.org/paper/56ca1bcc0ee88770e86554ce54471130c9acf0e3\",\"venue\":\"CSUR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2013.458\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a90a0d0d4f349c2c330d9d137baf5076ee3f717\",\"title\":\"Pixel-Level Hand Detection in Ego-centric Videos\",\"url\":\"https://www.semanticscholar.org/paper/5a90a0d0d4f349c2c330d9d137baf5076ee3f717\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/CVPR.2011.5995406\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8848d1abd31873594fc372e0022789f153112174\",\"title\":\"Fast unsupervised ego-action learning for first-person sports videos\",\"url\":\"https://www.semanticscholar.org/paper/8848d1abd31873594fc372e0022789f153112174\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1504.07469\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":\"10.1109/WACV.2016.7477708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f2b075d527e7d3b29219e5955f294f539c4764f\",\"title\":\"Compact CNN for indexing egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6f2b075d527e7d3b29219e5955f294f539c4764f\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2008.4587735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"560171665e78c9341c0a735be437ee7f99bb2f2c\",\"title\":\"Action recognition by learning mid-level motion features\",\"url\":\"https://www.semanticscholar.org/paper/560171665e78c9341c0a735be437ee7f99bb2f2c\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/TPAMI.2009.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a8da6accff92f915c1b8ac26d8176308c425b61\",\"title\":\"Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a8da6accff92f915c1b8ac26d8176308c425b61\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1412.6505\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2015.7298691\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"title\":\"Pooled motion features for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009}],\"title\":\"Going Deeper into First-Person Activity Recognition\",\"topics\":[{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Neuron\",\"topicId\":\"8353\",\"url\":\"https://www.semanticscholar.org/topic/8353\"},{\"topic\":\"Network planning and design\",\"topicId\":\"26472\",\"url\":\"https://www.semanticscholar.org/topic/26472\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"}],\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"