"{\"abstract\":\"Much recent progress in Vision-to-Language (V2L) problems has been achieved through a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). This approach does not explicitly represent high-level semantic concepts, but rather seeks to progress directly from image features to text. In this paper we investigate whether this direct approach succeeds due to, or despite, the fact that it avoids the explicit representation of high-level information. We propose a method of incorporating high-level concepts into the successful CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art in both image captioning and visual question answering. We also show that the same mechanism can be used to introduce external semantic information and that doing so further improves performance. We achieve the best reported results on both image captioning and VQA on several benchmark datasets, and provide an analysis of the value of explicit high-level concepts in V2L problems.\",\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\",\"url\":\"https://www.semanticscholar.org/author/34902783\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\",\"url\":\"https://www.semanticscholar.org/author/12459603\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\",\"url\":\"https://www.semanticscholar.org/author/2161037\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\",\"url\":\"https://www.semanticscholar.org/author/2699095\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\",\"url\":\"https://www.semanticscholar.org/author/5546141\"}],\"citationVelocity\":79,\"citations\":[{\"arxivId\":\"1706.09601\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"title\":\"Actor-Critic Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1712.02051\",\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"49490596\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d190282ed59639b16e726a3237938b53976077\",\"title\":\"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d190282ed59639b16e726a3237938b53976077\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934466\",\"name\":\"Junwei Zhou\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2710247\",\"name\":\"Jizhong Han\"},{\"authorId\":\"144553025\",\"name\":\"S. Hu\"},{\"authorId\":\"2755326\",\"name\":\"Hongchao Gao\"}],\"doi\":\"10.1109/BigMM.2018.8499060\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"title\":\"Spatial- Temporal Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Fan\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":\"10.1109/ICTAI.2018.00047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdea9a5054f3b5f4dd4c3e75f9278e9548c2de7a\",\"title\":\"Long-Term Recurrent Merge Network Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cdea9a5054f3b5f4dd4c3e75f9278e9548c2de7a\",\"venue\":\"2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yongzhuang Wang\"},{\"authorId\":\"49746133\",\"name\":\"Yangmei Shen\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICIP.2019.8803418\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93368542c1774e2cbd12187a4ccc2c882c791d94\",\"title\":\"Adaptive Hard Example Mining for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93368542c1774e2cbd12187a4ccc2c882c791d94\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672743\",\"name\":\"C. Li\"},{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"}],\"doi\":\"10.1007/978-3-319-71607-7_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"title\":\"Combining Object-Based Attention and Attributes for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.07613\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dde6ed569684356c46217fa53224272b668bae8\",\"title\":\"Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dde6ed569684356c46217fa53224272b668bae8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ICASSP.2018.8461507\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54969341ec539ddaaf7537b7353e3cea84790eac\",\"title\":\"A Novel Semantic Attribute-Based Feature for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/54969341ec539ddaaf7537b7353e3cea84790eac\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"51487414\",\"name\":\"Yunshan Ma\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8384387a3739280b15d38f39429aadb7c9bd620f\",\"title\":\"Knowledge-aware Multimodal Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/8384387a3739280b15d38f39429aadb7c9bd620f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7535a97bcb06b78531f95b7443671a2c0d319476\",\"title\":\"Combining Knowledge and Reasoning through Probabilistic Soft Logic for Image Puzzle Solving\",\"url\":\"https://www.semanticscholar.org/paper/7535a97bcb06b78531f95b7443671a2c0d319476\",\"venue\":\"UAI\",\"year\":2018},{\"arxivId\":\"1905.02963\",\"authors\":[{\"authorId\":\"145114776\",\"name\":\"L. Sun\"},{\"authorId\":\"143721383\",\"name\":\"Bing Li\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICME.2019.00226\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"title\":\"Multimodal Semantic Attention Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"39943835\",\"name\":\"Gui-Song Xia\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"2872774\",\"name\":\"W. Dong\"}],\"doi\":\"10.1016/J.PATREC.2017.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390d0bb977b7473b8b76d045875c767d743de943\",\"title\":\"Image Caption Generation with Part of Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/390d0bb977b7473b8b76d045875c767d743de943\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"144914662\",\"name\":\"F. Xiao\"},{\"authorId\":\"143728443\",\"name\":\"Le An\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"48305363\",\"name\":\"Xiaochuan Sun\"}],\"doi\":\"10.1145/3300938\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"title\":\"Semantic Concept Network and Deep Walk-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"48325104\",\"name\":\"Z. Bai\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1145/3330393.3330410\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd0b66c3fdee9aebdb56d5998e955fd7cd5cd6a6\",\"title\":\"An Improved Approach Based on CNN-RNNs for Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cd0b66c3fdee9aebdb56d5998e955fd7cd5cd6a6\",\"venue\":\"ICMSSP 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dee5c6c65684f91bfe212f44b79383f69f4d84c\",\"title\":\"EasyChair Preprint No 1046 Image Caption Generation With Adaptive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/9dee5c6c65684f91bfe212f44b79383f69f4d84c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134473603\",\"name\":\"Mohammedsayeemuddin K Shaikh\"},{\"authorId\":\"3226334\",\"name\":\"M. V. Joshi\"}],\"doi\":\"10.1109/SPCOM.2018.8724400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c85da5f3b2de5a681d0d97a27f0db47b89c84d0\",\"title\":\"Recursive Network with Explicit Neighbor Connection for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c85da5f3b2de5a681d0d97a27f0db47b89c84d0\",\"venue\":\"2018 International Conference on Signal Processing and Communications (SPCOM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1438623667\",\"name\":\"Khaled Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/CSCI49370.2019.00055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d4a2308f7ce78cf0a28dcf5873348baccc036ce\",\"title\":\"Image Captioning with Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/1d4a2308f7ce78cf0a28dcf5873348baccc036ce\",\"venue\":\"2019 International Conference on Computational Science and Computational Intelligence (CSCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52423203\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3985dbf7616c7d2c6178eaa262389815f95290e6\",\"title\":\"Cross-view learning\",\"url\":\"https://www.semanticscholar.org/paper/3985dbf7616c7d2c6178eaa262389815f95290e6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1912.11619\",\"authors\":[{\"authorId\":\"24332496\",\"name\":\"Q. Wei\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"48729616\",\"name\":\"Weihong Yu\"},{\"authorId\":\"47957797\",\"name\":\"X. Zhang\"},{\"authorId\":\"2646526\",\"name\":\"Y. Zhang\"},{\"authorId\":\"6841398\",\"name\":\"Bojie Hu\"},{\"authorId\":\"48226606\",\"name\":\"B. Mo\"},{\"authorId\":\"49067192\",\"name\":\"Di Gong\"},{\"authorId\":\"153708417\",\"name\":\"Ning Chen\"},{\"authorId\":\"50792192\",\"name\":\"Dayong Ding\"},{\"authorId\":\"50581019\",\"name\":\"You-xin Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3de5e67c97b844c639c68ba46eac357cc5701123\",\"title\":\"Learn to Segment Retinal Lesions and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/3de5e67c97b844c639c68ba46eac357cc5701123\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"49865085\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-20876-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"title\":\"Multivariate Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"title\":\"Think and Tell: Preview Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"1848462\",\"name\":\"Yarong Han\"},{\"authorId\":\"144530696\",\"name\":\"Li Wan\"},{\"authorId\":\"144025048\",\"name\":\"Xing Zhou\"},{\"authorId\":\"144975798\",\"name\":\"Min Deng\"}],\"doi\":\"10.1080/01431161.2019.1594439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"title\":\"Geospatial relation captioning for high-spatial-resolution images by using an attention-based neural network\",\"url\":\"https://www.semanticscholar.org/paper/baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145471480\",\"name\":\"Yunmeng Feng\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46446912\",\"name\":\"X. Zhang\"},{\"authorId\":\"7521170\",\"name\":\"Chuanfu Xu\"},{\"authorId\":\"2243533\",\"name\":\"Zhenghua Wang\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1145/3302425.3302464\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"title\":\"AttResNet: Attention-based ResNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22066021\",\"name\":\"Xishan Zhang\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"2069818\",\"name\":\"D. Zhang\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2017.662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b0b706fc94b35a1eddd830685e07870315b9565\",\"title\":\"Task-Driven Dynamic Fusion: Reducing Ambiguity in Video Description\",\"url\":\"https://www.semanticscholar.org/paper/3b0b706fc94b35a1eddd830685e07870315b9565\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1145/3303083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91aa0eb38446643cd622b060a76043b0ca2d7991\",\"title\":\"Rich Visual and Language Representation with Complementary Semantics for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/91aa0eb38446643cd622b060a76043b0ca2d7991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2486c41d1ec20dd53de912c77035743816638b6\",\"title\":\"An Active Information Seeking Model for Goal-oriented Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c2486c41d1ec20dd53de912c77035743816638b6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31465302\",\"name\":\"E. Wang\"},{\"authorId\":\"46182609\",\"name\":\"X. Zhang\"},{\"authorId\":\"39907479\",\"name\":\"F. Wang\"},{\"authorId\":\"1682589\",\"name\":\"T. Wu\"},{\"authorId\":\"144404748\",\"name\":\"Chien-Ming Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2917771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"title\":\"Multilayer Dense Attention Model for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1016/j.neucom.2020.03.087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1c830d89069401945c430c6ddccc3ea4b3bd924\",\"title\":\"Evolutionary recurrent neural network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1c830d89069401945c430c6ddccc3ea4b3bd924\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1612.04949\",\"authors\":[{\"authorId\":\"38314901\",\"name\":\"H. Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5793958cd1654b4817ebb57f5484dfd8861f916\",\"title\":\"Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering\",\"url\":\"https://www.semanticscholar.org/paper/b5793958cd1654b4817ebb57f5484dfd8861f916\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288466\",\"name\":\"Xian-Hua Zeng\"},{\"authorId\":\"145780928\",\"name\":\"B. Liu\"},{\"authorId\":\"40318021\",\"name\":\"M. Zhou\"}],\"doi\":\"10.1007/s11390-018-1874-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0243850576e364368c3f743012e78165d8bf249\",\"title\":\"Understanding and Generating Ultrasound Image Description\",\"url\":\"https://www.semanticscholar.org/paper/f0243850576e364368c3f743012e78165d8bf249\",\"venue\":\"Journal of Computer Science and Technology\",\"year\":2018},{\"arxivId\":\"1903.01072\",\"authors\":[{\"authorId\":\"47060391\",\"name\":\"J. Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"38900275\",\"name\":\"Joon Huang Chuah\"}],\"doi\":\"10.1109/TMM.2019.2904878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"title\":\"COMIC: Toward A Compact Image Captioning Model With Attention\",\"url\":\"https://www.semanticscholar.org/paper/9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W17-4752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"title\":\"Sheffield MultiMT: Using Object Posterior Predictions for Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92187979\",\"name\":\"C. Xu\"},{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"16003095\",\"name\":\"Meng-long Zhang\"},{\"authorId\":\"49470161\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ICUSAI47366.2019.9124779\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72364b3cd61221a99fb6be65e34a10c53db531cd\",\"title\":\"Attention-gated LSTM for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72364b3cd61221a99fb6be65e34a10c53db531cd\",\"venue\":\"2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/978-3-319-51811-4_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"title\":\"What Convnets Make for Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39142510\",\"name\":\"Jiang Lu\"},{\"authorId\":\"144762632\",\"name\":\"Zhong Cao\"},{\"authorId\":\"12953211\",\"name\":\"Kailun Wu\"},{\"authorId\":\"47776868\",\"name\":\"G. Zhang\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/ICTAI.2018.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"952ef1fae7f1ad08e7258d8777a9df3654462202\",\"title\":\"Boosting Few-Shot Image Recognition Via Domain Alignment Prototypical Networks\",\"url\":\"https://www.semanticscholar.org/paper/952ef1fae7f1ad08e7258d8777a9df3654462202\",\"venue\":\"2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2018},{\"arxivId\":\"1810.06245\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58d16e23e1192be4acaf6a29c1f5995817146554\",\"title\":\"Bringing back simplicity and lightliness into neural image captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d16e23e1192be4acaf6a29c1f5995817146554\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5482750\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72f9116a04e584081635500e9f0789fa26e4d15f\",\"title\":\"Hierarchical Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72f9116a04e584081635500e9f0789fa26e4d15f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4492316\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"145886114\",\"name\":\"Jun Guo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"745f54a822bdbd33cf08e65b665ab3f3528cdf78\",\"title\":\"Object-Oriented Video Captioning with Temporal Graph and Prior Knowledge Building\",\"url\":\"https://www.semanticscholar.org/paper/745f54a822bdbd33cf08e65b665ab3f3528cdf78\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2018/114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"title\":\"Multi-Level Policy and Reward Reinforcement Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50385621\",\"name\":\"Yu Weng\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"9264646\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/ACCESS.2019.2923694\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f7094647510995a7d9020e4eb01e31dd743d9ab\",\"title\":\"Improved Density Peak Clustering Based on Information Entropy for Ancient Character Images\",\"url\":\"https://www.semanticscholar.org/paper/8f7094647510995a7d9020e4eb01e31dd743d9ab\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1812.04239\",\"authors\":[{\"authorId\":\"2126047\",\"name\":\"Xiu-Shen Wei\"},{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"47968029\",\"name\":\"Lingqiao Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"}],\"doi\":\"10.1007/978-3-030-20890-5_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01b94ffeef22187587a9d3b9aeefa6377f85baa7\",\"title\":\"Coarse-to-fine: A RNN-based hierarchical attention model for vehicle re-identification\",\"url\":\"https://www.semanticscholar.org/paper/01b94ffeef22187587a9d3b9aeefa6377f85baa7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.01881\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03158341c61b8bfedc9ccd503610ab150678a7c1\",\"title\":\"Better Understanding Hierarchical Visual Relationship for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/03158341c61b8bfedc9ccd503610ab150678a7c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414749\",\"name\":\"Kun Fu\"},{\"authorId\":\"3068555\",\"name\":\"Jin Li\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/TNNLS.2018.2813306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"title\":\"Image-Text Surgery: Efficient Concept Learning in Image Captioning by Generating Pseudopairs\",\"url\":\"https://www.semanticscholar.org/paper/f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52366010\",\"name\":\"Zhi-bin Guan\"},{\"authorId\":\"49600007\",\"name\":\"Kang Liu\"},{\"authorId\":\"47009350\",\"name\":\"Yan Ma\"},{\"authorId\":\"144222488\",\"name\":\"Xu Qian\"},{\"authorId\":\"35260608\",\"name\":\"Tongkai Ji\"}],\"doi\":\"10.3390/sym10110626\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"title\":\"Sequential Dual Attention: Coarse-to-Fine-Grained Hierarchical Generation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"venue\":\"Symmetry\",\"year\":2018},{\"arxivId\":\"1909.03918\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05106b86ec45914d1136719d311078182d437872\",\"title\":\"Hierarchy Parsing for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/05106b86ec45914d1136719d311078182d437872\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1017/S1351324918000116\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"title\":\"The role of image representations in vision to language tasks\",\"url\":\"https://www.semanticscholar.org/paper/2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICIP.2019.8803785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"title\":\"A Novel Attribute Selection Mechanism for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9719479\",\"name\":\"Ziyue Luo\"},{\"authorId\":\"122090721\",\"name\":\"Huixian Kang\"},{\"authorId\":\"51250530\",\"name\":\"Pin Yao\"},{\"authorId\":\"145524181\",\"name\":\"W. Wan\"}],\"doi\":\"10.1109/ICALIP.2018.8455856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a4a539281f805a623f5afafa10efb76d029c6b4\",\"title\":\"Chinese Image Caption Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3a4a539281f805a623f5afafa10efb76d029c6b4\",\"venue\":\"2018 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3128377\",\"name\":\"Shuaijun Wang\"},{\"authorId\":\"143818279\",\"name\":\"F. Jiang\"},{\"authorId\":\"37654198\",\"name\":\"Bin Zhang\"},{\"authorId\":\"143811463\",\"name\":\"Rui Ma\"},{\"authorId\":\"1785422\",\"name\":\"Qi Hao\"}],\"doi\":\"10.1109/TITS.2019.2927838\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f5b6047cfa95e2128dc4fd76ac0d05587bc5893\",\"title\":\"Development of UAV-Based Target Tracking and Recognition Systems\",\"url\":\"https://www.semanticscholar.org/paper/2f5b6047cfa95e2128dc4fd76ac0d05587bc5893\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783874\",\"name\":\"T. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144751998\",\"name\":\"C. He\"}],\"doi\":\"10.1007/s11063-019-09979-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a54a18073b4b4a788e106d540d26817c8c898a63\",\"title\":\"Image Caption with Endogenous\\u2013Exogenous Attention\",\"url\":\"https://www.semanticscholar.org/paper/a54a18073b4b4a788e106d540d26817c8c898a63\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"title\":\"Role of Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1145/3293353.3293391\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"title\":\"A Bottom-Up and Top-Down Approach for Image Captioning using Transformer\",\"url\":\"https://www.semanticscholar.org/paper/acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13210115\",\"name\":\"S. Xing\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"2896799\",\"name\":\"Ye Zhao\"}],\"doi\":\"10.1007/978-3-319-77380-3_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c85a85330b747802885fc23cb4231348352b6062\",\"title\":\"Generating Chinese Poems from Images Based on Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c85a85330b747802885fc23cb4231348352b6062\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152628978\",\"name\":\"Zhiwang Luo\"},{\"authorId\":\"49268539\",\"name\":\"Jiwei Hu\"},{\"authorId\":\"24825378\",\"name\":\"Q. Liu\"},{\"authorId\":\"50060682\",\"name\":\"J. Deng\"}],\"doi\":\"10.1117/12.2540579\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fba6e52ac4855a71037a648d199b8e3afd6268cb\",\"title\":\"An image caption model incorporating high-level semantic features\",\"url\":\"https://www.semanticscholar.org/paper/fba6e52ac4855a71037a648d199b8e3afd6268cb\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46447554\",\"name\":\"Xiaodong Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1109/ACCESS.2019.2917979\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"title\":\"Cascade Semantic Fusion for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"1974929\",\"name\":\"Jiewu Xia\"},{\"authorId\":\"102599406\",\"name\":\"Y. Tan\"},{\"authorId\":\"46513749\",\"name\":\"Bin Tan\"}],\"doi\":\"10.1007/s11042-020-09674-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3f2e97df8488767e7d6f71f628e2169ec0969c\",\"title\":\"Double-channel language feature mining based model for video description\",\"url\":\"https://www.semanticscholar.org/paper/0d3f2e97df8488767e7d6f71f628e2169ec0969c\",\"venue\":\"Multim. Tools Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774112\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"Changyin Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"789c76749a15614d97ac8f4ec18b3ce7d80a2d28\",\"title\":\"Explorer Multiplicative LSTM for sequence modelling\",\"url\":\"https://www.semanticscholar.org/paper/789c76749a15614d97ac8f4ec18b3ce7d80a2d28\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"49ac61eed8301f41da85e0053be3be790293faac\",\"title\":\"Recurrent Highway Networks with Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49ac61eed8301f41da85e0053be3be790293faac\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1612.00576\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/D17-1098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"title\":\"Guided Open Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"78507285\",\"name\":\"Zhiping Zhou\"},{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/s11042-019-08165-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"title\":\"An image retrieval method based on semantic matching with multiple positional representations\",\"url\":\"https://www.semanticscholar.org/paper/0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1809.07257\",\"authors\":[{\"authorId\":\"2662002\",\"name\":\"Oliver Nina\"},{\"authorId\":\"47238599\",\"name\":\"W. Garcia\"},{\"authorId\":\"47637016\",\"name\":\"Scott Clouse\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81e31899aa9f0f54db069f0f4c2a29ed9587fe89\",\"title\":\"MTLE: A Multitask Learning Encoder of Visual Feature Representations for Video and Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/81e31899aa9f0f54db069f0f4c2a29ed9587fe89\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1965909970\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"1755773\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"143930562\",\"name\":\"G. Chen\"},{\"authorId\":\"153016830\",\"name\":\"J. Guo\"}],\"doi\":\"10.1109/ACCESS.2020.3021857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3a02eab3df6ec8bfaf0711cd1d87ab837fe437b\",\"title\":\"Understanding Objects in Video: Object-Oriented Video Captioning via Structured Trajectory and Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/e3a02eab3df6ec8bfaf0711cd1d87ab837fe437b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TIP.2020.3034494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"title\":\"Learning Dual Encoding Model for Adaptive Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46812189\",\"name\":\"K. Gao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-3-319-77383-4_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23de896c1b3487803ec6989b1ec1c3bd0c0f8136\",\"title\":\"Spatio-Temporal Context Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/23de896c1b3487803ec6989b1ec1c3bd0c0f8136\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"}],\"doi\":\"10.1145/3240508.3240583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"title\":\"Look Deeper See Richer: Depth-aware Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14414455\",\"name\":\"Mengdan Gu\"},{\"authorId\":\"49444962\",\"name\":\"X. Huang\"},{\"authorId\":\"145577083\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1109/ICAIT.2019.8935910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52c01fff7282fb7bed666329a282c97e297a6264\",\"title\":\"Automatic Generation of Pulmonary Radiology Reports with Semantic Tags\",\"url\":\"https://www.semanticscholar.org/paper/52c01fff7282fb7bed666329a282c97e297a6264\",\"venue\":\"2019 IEEE 11th International Conference on Advanced Infocomm Technology (ICAIT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"47655360\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1445303213\",\"name\":\"Jiaqi Zhao\"},{\"authorId\":\"49353948\",\"name\":\"Mingming Liu\"}],\"doi\":\"10.1016/j.knosys.2020.105920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"title\":\"Remote sensing image captioning via Variational Autoencoder and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Yunchen Pu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ce86da3e0a0ab5f6cf944cdfef7a607a61b16e2\",\"title\":\"Deep Generative Models for Image Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ce86da3e0a0ab5f6cf944cdfef7a607a61b16e2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1016/j.jvcir.2018.12.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58323b889d916403c6674eb3112370a13bd63fe9\",\"title\":\"Scene graph captioner: Image captioning based on structural visual representation\",\"url\":\"https://www.semanticscholar.org/paper/58323b889d916403c6674eb3112370a13bd63fe9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2017.8019408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bb66ba1ef18110b422a8a7a2ce0e6400181b952\",\"title\":\"Image captioning with deep LSTM based on sequential residual\",\"url\":\"https://www.semanticscholar.org/paper/2bb66ba1ef18110b422a8a7a2ce0e6400181b952\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1805.09701\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"29943965\",\"name\":\"Nan Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"}],\"doi\":\"10.1145/3219819.3220036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"title\":\"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.05658\",\"authors\":[{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"39369840\",\"name\":\"Feng Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.24963/ijcai.2017/563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2498124e6466ccde28c95477c923e7cd5843f4c0\",\"title\":\"MAT: A Multimodal Attentive Translator for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2498124e6466ccde28c95477c923e7cd5843f4c0\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"2896799\",\"name\":\"Ye Zhao\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/BigMM.2018.8499172\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96418bb981ac738468340c7836a8362fa08cc1f2\",\"title\":\"Enhanced Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96418bb981ac738468340c7836a8362fa08cc1f2\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1809.04144\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"title\":\"End-to-end Image Captioning Exploits Multimodal Distributional Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1612.03557\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afbff808f4a4c6eafcce3858451b9b1a508ecba3\",\"title\":\"Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/afbff808f4a4c6eafcce3858451b9b1a508ecba3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014498\",\"name\":\"Q. Liu\"},{\"authorId\":\"50580380\",\"name\":\"Yingying Chen\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"27356041\",\"name\":\"Sijiong Zhang\"}],\"doi\":\"10.1016/j.compind.2018.01.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ed73cea8227a9a4733146053c2d1baa52de9572\",\"title\":\"Multi-view pedestrian captioning with an attention topic CNN model\",\"url\":\"https://www.semanticscholar.org/paper/1ed73cea8227a9a4733146053c2d1baa52de9572\",\"venue\":\"Comput. Ind.\",\"year\":2018},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89766800\",\"name\":\"Zhenru Li\"},{\"authorId\":\"121704343\",\"name\":\"Yaoyi Li\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-36802-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"title\":\"Improve Image Captioning by Self-attention\",\"url\":\"https://www.semanticscholar.org/paper/c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1807.03514\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1109/ICIP.2018.8451083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdab688a49bb873d36ae638c647d6ca9e3d75d18\",\"title\":\"Topic-Guided Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fdab688a49bb873d36ae638c647d6ca9e3d75d18\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672151\",\"name\":\"Ning Xu\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TCSVT.2018.2867286\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dbb5b0a9ccb8a1f70b49524285b7bc3cbcc2d91b\",\"title\":\"Dual-Stream Recurrent Neural Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/dbb5b0a9ccb8a1f70b49524285b7bc3cbcc2d91b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177145\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dadb7ddfde3478238d23a8bacf5eddecc59e84c9\",\"title\":\"Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/dadb7ddfde3478238d23a8bacf5eddecc59e84c9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50581334\",\"name\":\"Y. Chen\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1007/s11042-018-6228-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"title\":\"Looking deeper and transferring attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"145414746\",\"name\":\"Kun Fu\"},{\"authorId\":\"143900006\",\"name\":\"Lei Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851721\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"title\":\"Image Captioning with Partially Rewarded Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825632087\",\"name\":\"Peichao Jiang\"},{\"authorId\":\"47119622\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3042775\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e9283dd01236b7c82bfab5463e73ff5d4d251c4\",\"title\":\"Preference Cognitive Diagnosis for Student Performance Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7e9283dd01236b7c82bfab5463e73ff5d4d251c4\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.03715\",\"authors\":[{\"authorId\":\"4492316\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"145505204\",\"name\":\"J. Guo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d507f3088e5c8411bc06e274958cbe263169a39d\",\"title\":\"OVC-Net: Object-Oriented Video Captioning with Temporal Graph and Detail Enhancement.\",\"url\":\"https://www.semanticscholar.org/paper/d507f3088e5c8411bc06e274958cbe263169a39d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"144474380\",\"name\":\"X. Tang\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"},{\"authorId\":\"33161908\",\"name\":\"C. Li\"}],\"doi\":\"10.3390/rs11060612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"944e93e74379afedced307ca30fc6d31365dc96e\",\"title\":\"Description Generation for Remote Sensing Images Using Attribute Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/944e93e74379afedced307ca30fc6d31365dc96e\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1438623667\",\"name\":\"Khaled Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afa8032f794011884be0b06f808540f36b404c0b\",\"title\":\"A Short Review on Image Caption Generation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/afa8032f794011884be0b06f808540f36b404c0b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"66628761\",\"name\":\"Wenbo Nie\"},{\"authorId\":\"50079235\",\"name\":\"X. Li\"},{\"authorId\":\"1704871\",\"name\":\"Yao Yu\"}],\"doi\":\"10.1109/YAC.2019.8787715\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e46bfa93fb5874069b4bcdd6e887e96308babb2b\",\"title\":\"Image Caption Generation With Adaptive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/e46bfa93fb5874069b4bcdd6e887e96308babb2b\",\"venue\":\"2019 34rd Youth Academic Annual Conference of Chinese Association of Automation (YAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1612.01082\",\"authors\":[{\"authorId\":\"49050563\",\"name\":\"J. Zhang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"49051258\",\"name\":\"J. Zhang\"},{\"authorId\":\"145313246\",\"name\":\"Jianfeng Lu\"}],\"doi\":\"10.1109/TMM.2018.2812605\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fc5465f3aa9c3efddd23cbaedf96399d9d40711\",\"title\":\"Multilabel Image Classification With Regional Latent Semantic Dependencies\",\"url\":\"https://www.semanticscholar.org/paper/1fc5465f3aa9c3efddd23cbaedf96399d9d40711\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1705.02751\",\"authors\":[{\"authorId\":\"10771870\",\"name\":\"A. Ali\"},{\"authorId\":\"3164047\",\"name\":\"Usman Shahid\"},{\"authorId\":\"144908682\",\"name\":\"Mohsen Ali\"},{\"authorId\":\"144850973\",\"name\":\"J. Ho\"}],\"doi\":\"10.1109/WACV.2017.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b20db215418a6d70b6665715899a4037d402c5b3\",\"title\":\"High-Level Concepts for Affective Understanding of Images\",\"url\":\"https://www.semanticscholar.org/paper/b20db215418a6d70b6665715899a4037d402c5b3\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1612.01033\",\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.1109/ICCV.2017.140\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"title\":\"Areas of Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1909.00692\",\"authors\":[{\"authorId\":\"35345881\",\"name\":\"S. N. Chowdhury\"},{\"authorId\":\"2499758\",\"name\":\"Simon Razniewski\"},{\"authorId\":\"1751591\",\"name\":\"G. Weikum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"971bf8654232421843ba35e632c9602a5acdf341\",\"title\":\"Story-oriented Image Selection and Placement\",\"url\":\"https://www.semanticscholar.org/paper/971bf8654232421843ba35e632c9602a5acdf341\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"1790251284\",\"name\":\"Lin Li\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"9594118\",\"name\":\"C. Gu\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/s11063-020-10352-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"title\":\"Adaptively Converting Auxiliary Attributes and Textual Embedding for Video Captioning Based on BiLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"venue\":\"Neural Process. Lett.\",\"year\":2020},{\"arxivId\":\"1908.00120\",\"authors\":[{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"102574232\",\"name\":\"C. Chen\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"}],\"doi\":\"10.1145/3394171.3413889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66e87d0adf7df03fdd74e6dfea81f21aa03afab0\",\"title\":\"ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences\",\"url\":\"https://www.semanticscholar.org/paper/66e87d0adf7df03fdd74e6dfea81f21aa03afab0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-319-69005-6_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"title\":\"Topic-Specific Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"venue\":\"CCL\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1611.05490\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2017.443\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"title\":\"Semantic Regularisation for Recurrent Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144187895\",\"name\":\"Zhihong Zeng\"},{\"authorId\":\"39738087\",\"name\":\"X. Li\"}],\"doi\":\"10.1007/S00542-019-04473-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"638e4d81bc43a22add5f3cca181f468c5ac40b8c\",\"title\":\"Application of human computing in image captioning under deep learning\",\"url\":\"https://www.semanticscholar.org/paper/638e4d81bc43a22add5f3cca181f468c5ac40b8c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-36718-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"title\":\"SACIC: A Semantics-Aware Convolutional Image Captioner Using Multi-level Pervasive Attention\",\"url\":\"https://www.semanticscholar.org/paper/9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978802390\",\"name\":\"Haolei Pei\"},{\"authorId\":\"8559954\",\"name\":\"Q. Chen\"},{\"authorId\":\"13257164\",\"name\":\"J. Wang\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"1680030\",\"name\":\"Yubo Jia\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206815\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"title\":\"Visual Relational Reasoning for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.04390\",\"authors\":[{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"}],\"doi\":\"10.1145/3123266.3123366\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"title\":\"Fluency-Guided Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152998639\",\"name\":\"Y. Li\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"47968029\",\"name\":\"Lingqiao Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f90b744cf3a4959689935416b9d40169b646e00\",\"title\":\"CNN joint embedding LSTM LSTM CNN joint embedding LSTM CNN joint embedding LSTM CNN joint embedding LSTM CNN joint embedding\",\"url\":\"https://www.semanticscholar.org/paper/2f90b744cf3a4959689935416b9d40169b646e00\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1109/CVPRW.2018.00260\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bd5fceb1f885f690f63a58c289607c85069be3d\",\"title\":\"Image Caption Generation with Hierarchical Contextual Visual Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bd5fceb1f885f690f63a58c289607c85069be3d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48032469\",\"name\":\"X. Liu\"},{\"authorId\":\"1795699\",\"name\":\"M. Milanova\"}],\"doi\":\"10.1007/978-3-030-20984-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df2f287d6e774917c3528be8dece5f221b0a4328\",\"title\":\"An Image Captioning Method for Infant Sleeping Environment Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/df2f287d6e774917c3528be8dece5f221b0a4328\",\"venue\":\"MPRSS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5543239\",\"name\":\"Yongzhuang Wang\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":\"10.1007/978-3-319-71589-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a6b518aa83c1ca918f7e272bf5c1fdde0596c69\",\"title\":\"Neural Image Caption Generation with Global Feature Based Attention Scheme\",\"url\":\"https://www.semanticscholar.org/paper/8a6b518aa83c1ca918f7e272bf5c1fdde0596c69\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51127875\",\"name\":\"Y. Cai\"},{\"authorId\":\"3331651\",\"name\":\"H. Cai\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"}],\"doi\":\"10.18653/v1/P19-1239\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4fdd17e212bedd5cb288bf756e44e5af07ebc86c\",\"title\":\"Multi-Modal Sarcasm Detection in Twitter with Hierarchical Fusion Model\",\"url\":\"https://www.semanticscholar.org/paper/4fdd17e212bedd5cb288bf756e44e5af07ebc86c\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"2894465\",\"name\":\"Benyou Wang\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"144346838\",\"name\":\"Min Yang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.24963/ijcai.2018/168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbe4eac494fa7bc0bcd958d67393f097e0cb17db\",\"title\":\"A Multi-task Learning Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbe4eac494fa7bc0bcd958d67393f097e0cb17db\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"3374688\",\"name\":\"M. Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":null,\"name\":\"Heng Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"}],\"doi\":\"10.1016/J.PATREC.2019.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749f376d0addb83569fcc7536e46308abbb232d4\",\"title\":\"How much do cross-modal related semantics benefit image captioning by weighting attributes and re-ranking sentences?\",\"url\":\"https://www.semanticscholar.org/paper/749f376d0addb83569fcc7536e46308abbb232d4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121856633\",\"name\":\"Xiu Li\"},{\"authorId\":\"49108004\",\"name\":\"Kun Jin\"},{\"authorId\":\"143799988\",\"name\":\"Rujiao Long\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da78a3202d7e06b0badae1c8add271bcfe8ff8cd\",\"title\":\"End-to-end semantic-aware object retrieval based on region-wise attention\",\"url\":\"https://www.semanticscholar.org/paper/da78a3202d7e06b0badae1c8add271bcfe8ff8cd\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153804074\",\"name\":\"Heng Quan Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"}],\"doi\":\"10.1117/12.2524235\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"title\":\"When visual object-context features meet generic and specific semantic priors in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405709193\",\"name\":\"Gonzalo Vaca-Castano\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/J.CVIU.2019.02.006\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e0efecabff90401ea60cc5bca791d00f5113fa73\",\"title\":\"Holistic object detection and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0efecabff90401ea60cc5bca791d00f5113fa73\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1703.06233\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"title\":\"Recurrent Models for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1810.11536\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1007/978-3-030-20876-9_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"695420559bd694f0fe084b64556e8241c3d02868\",\"title\":\"Automatic Graphics Program Generation using Attention-Based Hierarchical Decoder\",\"url\":\"https://www.semanticscholar.org/paper/695420559bd694f0fe084b64556e8241c3d02868\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2002.12585\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"145558281\",\"name\":\"Kai Lei\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.24963/ijcai.2019/708\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"title\":\"Exploring and Distilling Cross-Modal Information for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453279481\",\"name\":\"Gonzalo Vaca Castano\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a851ad57feec3140b574c85851c436dacad8e70\",\"title\":\"Understanding images and videos using context\",\"url\":\"https://www.semanticscholar.org/paper/4a851ad57feec3140b574c85851c436dacad8e70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"30889568\",\"name\":\"Abdulmotaleb El Saddik\"}],\"doi\":\"10.1145/3279952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"title\":\"Deep Learning\\u2013Based Multimedia Analytics\",\"url\":\"https://www.semanticscholar.org/paper/bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900967\",\"name\":\"U. Zia\"},{\"authorId\":\"145759322\",\"name\":\"M. M. Riaz\"},{\"authorId\":\"144683577\",\"name\":\"A. Ghafoor\"},{\"authorId\":\"145602758\",\"name\":\"Seyyed Salehi Seyyed Ali\"}],\"doi\":\"10.1007/s00521-019-04587-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"title\":\"Topic sensitive image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461583\",\"name\":\"Kun Zhang\"},{\"authorId\":\"2767360\",\"name\":\"Guangyi Lv\"},{\"authorId\":\"47767796\",\"name\":\"L. Wu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"50383774\",\"name\":\"Q. Liu\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"153710346\",\"name\":\"Xing Xie\"},{\"authorId\":\"2397264\",\"name\":\"Fangzhao Wu\"}],\"doi\":\"10.1109/tsmc.2019.2932410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da0c294c84ef6d48822eeb383d36015a5bbc96eb\",\"title\":\"Multilevel Image-Enhanced Sentence Representation Net for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/da0c294c84ef6d48822eeb383d36015a5bbc96eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.13122\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5318abd4f12a5b25c2847e9c66713951341af504\",\"title\":\"SubICap: Towards Subword-informed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5318abd4f12a5b25c2847e9c66713951341af504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40353639\",\"name\":\"D. Vasile\"},{\"authorId\":\"1690572\",\"name\":\"Thomas Lukasiewicz\"}],\"doi\":\"10.1007/978-3-030-02671-4_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72afe5d25da6dfbb611b2c3dab4efc4b1c8447cf\",\"title\":\"Learning Structured Video Descriptions: Automated Video Knowledge Extraction for Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/72afe5d25da6dfbb611b2c3dab4efc4b1c8447cf\",\"venue\":\"OTM Conferences\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3241910\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"title\":\"Images2Poem: Generating Chinese Poetry from Image Streams\",\"url\":\"https://www.semanticscholar.org/paper/c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4421716\",\"name\":\"F. Wang\"},{\"authorId\":\"21776508\",\"name\":\"X. Gong\"},{\"authorId\":\"1754542\",\"name\":\"Linpeng Huang\"}],\"doi\":\"10.1109/ICPR.2018.8545355\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"title\":\"Time-Dependent Pre-attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3126686.3126714\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"title\":\"Image Caption with Synchronous Cross-Attention\",\"url\":\"https://www.semanticscholar.org/paper/b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"}],\"doi\":\"10.1109/BigMM.2018.8499357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"title\":\"Video Captioning with Semantic Guiding\",\"url\":\"https://www.semanticscholar.org/paper/ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414742\",\"name\":\"Kun Fu\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TPAMI.2016.2642953\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"title\":\"Aligning Where to See and What to Tell: Image Captioning with Region-Based Attention and Scene-Specific Contexts\",\"url\":\"https://www.semanticscholar.org/paper/afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wenhui Li\"},{\"authorId\":null,\"name\":\"Song Yang\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":null,\"name\":\"Dan Song\"},{\"authorId\":null,\"name\":\"Xuanya Li\"}],\"doi\":\"10.1016/j.ipm.2020.102432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"title\":\"Multi-level similarity learning for image-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702778\",\"name\":\"H. Zhang\"},{\"authorId\":\"2913523\",\"name\":\"Diedie Qiu\"},{\"authorId\":\"50477983\",\"name\":\"R. Wu\"},{\"authorId\":\"103624776\",\"name\":\"Dong-Hong Ji\"},{\"authorId\":\"49461429\",\"name\":\"Guangli Li\"},{\"authorId\":\"9201022\",\"name\":\"Zhenyu Niu\"},{\"authorId\":\"50289773\",\"name\":\"Tao Li\"}],\"doi\":\"10.1007/S00500-019-03973-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f7104056642c03263508957f20505a1dbba03ce\",\"title\":\"Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images\",\"url\":\"https://www.semanticscholar.org/paper/7f7104056642c03263508957f20505a1dbba03ce\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39054424\",\"name\":\"Min Gao\"},{\"authorId\":\"121685794\",\"name\":\"Xian-Hua Han\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"144562060\",\"name\":\"Hui Ji\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"},{\"authorId\":\"51299154\",\"name\":\"Jiande Sun\"}],\"doi\":\"10.1007/s11042-018-6751-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b737a81ff05e64e29596415c65dbc156e3481f95\",\"title\":\"Image super-resolution based on two-level residual learning CNN\",\"url\":\"https://www.semanticscholar.org/paper/b737a81ff05e64e29596415c65dbc156e3481f95\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48387339\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":\"40478963\",\"name\":\"J. Liu\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.3390/APP8050739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da958d2604e9f86f94a441d60488d0e93451c248\",\"title\":\"Captioning Transformer with Stacked Attention Modules\",\"url\":\"https://www.semanticscholar.org/paper/da958d2604e9f86f94a441d60488d0e93451c248\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1016/j.neucom.2018.05.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6723a565d4d7bc221fff7160bebfe54d16a40607\",\"title\":\"Deep sequential fusion LSTM network for image description\",\"url\":\"https://www.semanticscholar.org/paper/6723a565d4d7bc221fff7160bebfe54d16a40607\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"153028537\",\"name\":\"X. Wu\"},{\"authorId\":\"36263371\",\"name\":\"Shen Ge\"},{\"authorId\":\"93249636\",\"name\":\"W. Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1609/AAAI.V34I07.6824\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"title\":\"Federated Learning for Vision-and-Language Grounding Problems\",\"url\":\"https://www.semanticscholar.org/paper/d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1612.05386\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.416\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"title\":\"The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions\",\"url\":\"https://www.semanticscholar.org/paper/7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145959949\",\"name\":\"J. Serrano\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"title\":\"Boosting image captioning with an attentional mechanism = Boosting image captioning using diverse beam search\",\"url\":\"https://www.semanticscholar.org/paper/e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113789456\",\"name\":\"Rijul Dhir\"},{\"authorId\":\"48043196\",\"name\":\"S. K. Mishra\"},{\"authorId\":\"145470045\",\"name\":\"S. Saha\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.13053/CYS-23-3-3269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d749c8bdd9e3358adc64af0a620366cc10f5489\",\"title\":\"A Deep Attention based Framework for Image Caption Generation in Hindi Language\",\"url\":\"https://www.semanticscholar.org/paper/0d749c8bdd9e3358adc64af0a620366cc10f5489\",\"venue\":\"Computaci\\u00f3n y Sistemas\",\"year\":2019},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1611.09967\",\"authors\":[{\"authorId\":\"48513733\",\"name\":\"Y. Li\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.600\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d24b386d003bee176a942c26336dbe8f427aadd\",\"title\":\"Sequential Person Recognition in Photo Albums with a Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/3d24b386d003bee176a942c26336dbe8f427aadd\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035835\",\"name\":\"Qimin Cheng\"},{\"authorId\":\"1737486\",\"name\":\"Q. Zhang\"},{\"authorId\":\"36274417\",\"name\":\"P. Fu\"},{\"authorId\":\"9188943\",\"name\":\"Conghuan Tu\"},{\"authorId\":\"50341650\",\"name\":\"Sen Li\"}],\"doi\":\"10.1016/j.patcog.2018.02.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9ff4fed2344c25670faed4bffd22a5cd3f42c28\",\"title\":\"A survey and analysis on automatic image annotation\",\"url\":\"https://www.semanticscholar.org/paper/c9ff4fed2344c25670faed4bffd22a5cd3f42c28\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145478715\",\"name\":\"I. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.1109/ICIP.2017.8296600\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"title\":\"A cascaded long short-term memory (LSTM) driven generic visual question answering (VQA)\",\"url\":\"https://www.semanticscholar.org/paper/4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"}],\"doi\":\"10.1109/CCDC.2017.7979342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7926df884c677ecbd2f44402f33024ccd942a6b\",\"title\":\"Visual attention based on long-short term memory model for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/f7926df884c677ecbd2f44402f33024ccd942a6b\",\"venue\":\"2017 29th Chinese Control And Decision Conference (CCDC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672151\",\"name\":\"Ning Xu\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1007/s00530-018-0598-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f386d25bfbb0399fd6c8116add5faa66ffcfa467\",\"title\":\"Multi-guiding long short-term memory for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/f386d25bfbb0399fd6c8116add5faa66ffcfa467\",\"venue\":\"Multimedia Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9741677\",\"name\":\"Senmao Ye\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"}],\"doi\":\"10.1109/TIP.2018.2855406\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"title\":\"Attentive Linear Transformation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2008.08012\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"1882516497\",\"name\":\"Kancheti Sai Srinivas\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"title\":\"Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1904.09421\",\"authors\":[{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1007/s11042-018-5856-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c03b9770f8cfa7b1420af68cd4d2236c182df967\",\"title\":\"Multi-modal gated recurrent units for image description\",\"url\":\"https://www.semanticscholar.org/paper/c03b9770f8cfa7b1420af68cd4d2236c182df967\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2011.01565\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"1920933367\",\"name\":\"Jing Li\"},{\"authorId\":\"145609003\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"145310663\",\"name\":\"Irwin King\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dd1dd0f2b52b3b37be7229363101fa4fbbf1a50\",\"title\":\"Cross-Media Keyphrase Prediction: A Unified Framework with Multi-Modality Multi-Head Attention and Image Wordings\",\"url\":\"https://www.semanticscholar.org/paper/6dd1dd0f2b52b3b37be7229363101fa4fbbf1a50\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab7048d6fd8ea5b6daa060aa9996554bd4058f09\",\"title\":\"Areas of Attention for Image Captioning \\u2014 Supplementary Material \\u2014\",\"url\":\"https://www.semanticscholar.org/paper/ab7048d6fd8ea5b6daa060aa9996554bd4058f09\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":\"10.1145/3372278.3390679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1fd4006dd7edbdf6c28fb6db21c59dda8e16d08\",\"title\":\"Actor-Critic Sequence Generation for Relative Difference Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1fd4006dd7edbdf6c28fb6db21c59dda8e16d08\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3428883\",\"name\":\"Zhengxia Gao\"},{\"authorId\":\"3335651\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"33876479\",\"name\":\"Jianyi Wan\"}],\"doi\":\"10.1117/12.2502901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f7b31b06ebdc65a295dff62bae960d5458def3c\",\"title\":\"Explore fine-grained discriminative visual explanation when making classification decision\",\"url\":\"https://www.semanticscholar.org/paper/2f7b31b06ebdc65a295dff62bae960d5458def3c\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2018},{\"arxivId\":\"1909.07459\",\"authors\":[{\"authorId\":\"103393695\",\"name\":\"C. Jiang\"},{\"authorId\":\"3560734\",\"name\":\"Steven Weikai Lu\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3467c9977b875544221abbd8153facf2cb176759\",\"title\":\"Constructing Dynamic Knowledge Graph for Visual Semantic Understanding and Applications in Autonomous Robotics\",\"url\":\"https://www.semanticscholar.org/paper/3467c9977b875544221abbd8153facf2cb176759\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3151799\",\"name\":\"Fudong Nian\"},{\"authorId\":\"47775167\",\"name\":\"Teng Li\"},{\"authorId\":\"47906413\",\"name\":\"Y. Wang\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1016/j.cviu.2017.06.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94a86a758ae2608c00e9690e9951e805755bb1a1\",\"title\":\"Learning explicit video attributes from mid-level representation for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/94a86a758ae2608c00e9690e9951e805755bb1a1\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"49890870\",\"name\":\"Yan-Ning Zhang\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"49725227\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/j.image.2019.115648\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db67ace5932bbae9b141e0d05ba5dfcb80e94d6a\",\"title\":\"Visual question answering model based on visual relationship detection\",\"url\":\"https://www.semanticscholar.org/paper/db67ace5932bbae9b141e0d05ba5dfcb80e94d6a\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144343897\",\"name\":\"R. Guo\"},{\"authorId\":\"22771932\",\"name\":\"Shubo Ma\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/s11042-018-7118-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"title\":\"Image captioning: from structural tetrad to translated sentences\",\"url\":\"https://www.semanticscholar.org/paper/ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2008.04858\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"1643931890\",\"name\":\"Siyi Du\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"}],\"doi\":\"10.1145/3394171.3413826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"title\":\"KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40061480\",\"name\":\"Z. Dong\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"2000237078\",\"name\":\"Qi Cui\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/978-3-030-55187-2_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78a1094e0968cf4e2b61c83100d971031597ae4b\",\"title\":\"Adaptive Attention Mechanism Based Semantic Compositional Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/78a1094e0968cf4e2b61c83100d971031597ae4b\",\"venue\":\"IntelliSys\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/CVPR.2018.00808\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"title\":\"Visual Grounding via Accumulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1805.00314\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-1198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"title\":\"Object Counts! Bringing Explicit Detections Back into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.24963/ijcai.2019/726\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29100728a77fb48d977474652ad90104125e9a07\",\"title\":\"Swell-and-Shrink: Decomposing Image Captioning by Transformation and Summarization\",\"url\":\"https://www.semanticscholar.org/paper/29100728a77fb48d977474652ad90104125e9a07\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1799121\",\"name\":\"K. Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/ACCESS.2020.3042484\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"832aafb4989c24211a8377f82228c31f7a90ef81\",\"title\":\"Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap\",\"url\":\"https://www.semanticscholar.org/paper/832aafb4989c24211a8377f82228c31f7a90ef81\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3390891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb9fb10f604a196515e48ad90f217d33794f5991\",\"title\":\"Recurrent Attention Network with Reinforced Generator for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cb9fb10f604a196515e48ad90f217d33794f5991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921534\",\"name\":\"Philip Kinghorn\"},{\"authorId\":\"41204462\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.neucom.2017.07.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"title\":\"A region-based image caption generator with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"144067957\",\"name\":\"K. Mao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"title\":\"Semantic-filtered Soft-Split-Aware video captioning with audio-augmented feature\",\"url\":\"https://www.semanticscholar.org/paper/fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391204924\",\"name\":\"Zongjian Zhang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"50528721\",\"name\":\"Qiuyun Wu\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/IJCNN.2019.8851832\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"title\":\"Visual Relationship Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"50025928\",\"name\":\"Yuqian Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"}],\"doi\":\"10.1007/s11063-019-09997-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"title\":\"Hierarchical Deep Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1901.08942\",\"authors\":[{\"authorId\":\"143959713\",\"name\":\"Yimin Zhou\"},{\"authorId\":\"3156408\",\"name\":\"Y. Sun\"},{\"authorId\":\"145513516\",\"name\":\"Vasant G Honavar\"}],\"doi\":\"10.1109/WACV.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4c45108cb41051010d8a5175b8da23eb246c967\",\"title\":\"Improving Image Captioning by Leveraging Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/f4c45108cb41051010d8a5175b8da23eb246c967\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39904503\",\"name\":\"C. A. Henning\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"}],\"doi\":\"10.1007/s13735-017-0142-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24d967ac44319cd053544c1b77e2e294b90efe81\",\"title\":\"Estimating the information gap between textual and visual representations\",\"url\":\"https://www.semanticscholar.org/paper/24d967ac44319cd053544c1b77e2e294b90efe81\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2017},{\"arxivId\":\"1609.08976\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145153424\",\"name\":\"Ricardo Henao\"},{\"authorId\":\"50242822\",\"name\":\"X. Yuan\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9074631\",\"name\":\"A. Stevens\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"title\":\"Variational Autoencoder for Deep Learning of Images, Labels and Captions\",\"url\":\"https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3321318\",\"name\":\"W. Liu\"},{\"authorId\":\"2263674\",\"name\":\"Yidong Li\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/ACCESS.2018.2886597\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40c97ba0f8c50cae18151901c0ea2504bba4e79b\",\"title\":\"An Attribute-Based High-Level Image Representation for Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/40c97ba0f8c50cae18151901c0ea2504bba4e79b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2018.2811621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a17310abb249ce8fce8f409709b5395da32e0a6\",\"title\":\"Bundled Object Context for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/8a17310abb249ce8fce8f409709b5395da32e0a6\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1807.09434\",\"authors\":[{\"authorId\":\"2183432\",\"name\":\"Boeun Kim\"},{\"authorId\":\"49380412\",\"name\":\"Y. Lee\"},{\"authorId\":\"3011724\",\"name\":\"Hyedong Jung\"},{\"authorId\":\"2529532\",\"name\":\"C. S. Cho\"}],\"doi\":\"10.1007/978-3-030-11018-5_12\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"239a38663967140e026385f6625a913a3e7b1cd7\",\"title\":\"Distinctive-attribute Extraction for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/239a38663967140e026385f6625a913a3e7b1cd7\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40630836\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1591126916\",\"name\":\"Yunye Zhang\"},{\"authorId\":\"151486938\",\"name\":\"Yan Shi\"},{\"authorId\":\"51303869\",\"name\":\"Wenxin Yu\"},{\"authorId\":\"145191696\",\"name\":\"Li Nie\"},{\"authorId\":\"153179411\",\"name\":\"Gang He\"},{\"authorId\":\"119905363\",\"name\":\"Yibo Fan\"},{\"authorId\":\"144557426\",\"name\":\"Zhuo Yang\"}],\"doi\":\"10.1007/978-3-030-36802-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a5aaf408be292c1b6cbe1a4553f395c5a5c5ba5\",\"title\":\"Dense Image Captioning Based on Precise Feature Extraction\",\"url\":\"https://www.semanticscholar.org/paper/0a5aaf408be292c1b6cbe1a4553f395c5a5c5ba5\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152356310\",\"name\":\"Danyang Cao\"},{\"authorId\":\"152223852\",\"name\":\"Menggui Zhu\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11042-019-08116-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e19260676bbc8185830528773d54b83ba3f12a2\",\"title\":\"An image caption method based on object detection\",\"url\":\"https://www.semanticscholar.org/paper/3e19260676bbc8185830528773d54b83ba3f12a2\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1804.00887\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dc2c3be0796f65154d2106ed4442889c84546df\",\"title\":\"Learning to Guide Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3dc2c3be0796f65154d2106ed4442889c84546df\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2915033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"title\":\"Deep Hierarchical Encoder\\u2013Decoder Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1704.06972\",\"authors\":[{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1109/CVPR.2017.780\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1de837d76d6513aa664f2d032d49ef12c938bbbb\",\"title\":\"Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/1de837d76d6513aa664f2d032d49ef12c938bbbb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2007.03877\",\"authors\":[{\"authorId\":\"1826472\",\"name\":\"Dooseop Choi\"},{\"authorId\":\"2197109\",\"name\":\"Seung-Jun Han\"},{\"authorId\":\"97999178\",\"name\":\"K. Min\"},{\"authorId\":\"51428464\",\"name\":\"Jeongdan Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ad369ae7920f7305417bf26ba33b1b4490f462\",\"title\":\"PathGAN: Local Path Planning with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/10ad369ae7920f7305417bf26ba33b1b4490f462\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"145459055\",\"name\":\"Yong Rui\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3328994\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a95bd7b671a163225d9d319827f5a40fce17fed\",\"title\":\"Learning Click-Based Deep Structure-Preserving Embeddings with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/0a95bd7b671a163225d9d319827f5a40fce17fed\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66511580\",\"name\":\"Mirza Muhammad Ali Baig\"},{\"authorId\":\"67307335\",\"name\":\"Mian Ihtisham Shah\"},{\"authorId\":\"9223428\",\"name\":\"Muhammad Abdullah Wajahat\"},{\"authorId\":\"2384836\",\"name\":\"Nauman Zafar\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/DICTA.2018.8615810\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"title\":\"Image Caption Generator with Novel Object Injection\",\"url\":\"https://www.semanticscholar.org/paper/d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014498\",\"name\":\"Q. Liu\"},{\"authorId\":\"50580380\",\"name\":\"Yingying Chen\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"27356041\",\"name\":\"Sijiong Zhang\"}],\"doi\":\"10.1007/978-981-10-8530-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b31a49cfbc04f0b5ee174db72f1dc001c42b156f\",\"title\":\"Joint Visual Context for Pedestrian Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b31a49cfbc04f0b5ee174db72f1dc001c42b156f\",\"venue\":\"ICIMCS\",\"year\":2017},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2018.8486437\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0f0076476fc81a344b8bdec771802a8584dd10f\",\"title\":\"Refining Attention: A Sequential Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0f0076476fc81a344b8bdec771802a8584dd10f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152347102\",\"name\":\"F. Yu\"},{\"authorId\":\"30490097\",\"name\":\"Haonan Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3343031.3350931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47e8c51d8293eb59416456179c606cb3ae08692\",\"title\":\"Instance of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/c47e8c51d8293eb59416456179c606cb3ae08692\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1708.05851\",\"authors\":[{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/ICCV.2017.602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9519d66f9844fcf306cc205593a55cf01090633\",\"title\":\"Image2song: Song Retrieval via Bridging Image Content and Lyric Words\",\"url\":\"https://www.semanticscholar.org/paper/d9519d66f9844fcf306cc205593a55cf01090633\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31196120\",\"name\":\"Lizhao Gao\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"}],\"doi\":\"10.1145/3195106.3195114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3adf719a5f451a61e98823783b5f2e049bbffa2d\",\"title\":\"Image Captioning with Scene-graph Based Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/3adf719a5f451a61e98823783b5f2e049bbffa2d\",\"venue\":\"ICMLC\",\"year\":2018},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"}],\"doi\":\"10.1051/JNWPU/20183630522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a49e34cf529989963a7a2d64dd92798621e1a748\",\"title\":\"Image Caption Description of Traffic Scene Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a49e34cf529989963a7a2d64dd92798621e1a748\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2301765\",\"name\":\"Tsung-Wei Ke\"},{\"authorId\":\"3172276\",\"name\":\"Che-Wei Lin\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"14489533\",\"name\":\"D. Geiger\"}],\"doi\":\"10.1007/978-3-319-54190-7_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1df74a5047e953766fa07dec356bba285c605a1\",\"title\":\"Variational Convolutional Networks for Human-Centric Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d1df74a5047e953766fa07dec356bba285c605a1\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1802.10240\",\"authors\":[{\"authorId\":\"3174935\",\"name\":\"Wenshan Wang\"},{\"authorId\":\"4456978\",\"name\":\"S. Yang\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2985995\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1049/iet-cvi.2019.0361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2f950677e6a42beb234e507b3022964980b6556\",\"title\":\"Neural Aesthetic Image Reviewer\",\"url\":\"https://www.semanticscholar.org/paper/e2f950677e6a42beb234e507b3022964980b6556\",\"venue\":\"IET Comput. Vis.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"52196222\",\"name\":\"Y. Qiu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/ACCESS.2018.2879642\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6b0247896a9d2eca0f4901032f5cfabd5b09dbe\",\"title\":\"A Fine-Grained Spatial-Temporal Attention Model for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e6b0247896a9d2eca0f4901032f5cfabd5b09dbe\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1708.09666\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1145/3078971.3079000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"title\":\"Generating Video Descriptions with Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1109/CVPR.2018.00521\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"title\":\"Categorizing Concepts with Basic Level for Vision-to-Language\",\"url\":\"https://www.semanticscholar.org/paper/7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2012.07333\",\"authors\":[{\"authorId\":\"1733071048\",\"name\":\"Chao Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7212df671c50beb567e3d3d608b0c14405c40e3\",\"title\":\"Intrinsic Image Captioning Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7212df671c50beb567e3d3d608b0c14405c40e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.11903\",\"authors\":[{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"title\":\"Visual Question Answering as Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1610.02947\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dc37dab102a0465098111b7ccf6f95b736397f2\",\"title\":\"End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3dc37dab102a0465098111b7ccf6f95b736397f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"144981699\",\"name\":\"Huadong Tang\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.eswa.2018.08.056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0500b22ad2195fc36f8fc62b814c1e29b3b73fd6\",\"title\":\"Coordinate CNNs and LSTMs to categorize scene images with multi-views and multi-levels of abstraction\",\"url\":\"https://www.semanticscholar.org/paper/0500b22ad2195fc36f8fc62b814c1e29b3b73fd6\",\"venue\":\"Expert Syst. Appl.\",\"year\":2019},{\"arxivId\":\"2012.15484\",\"authors\":[{\"authorId\":null,\"name\":\"Kiran Ramnath\"},{\"authorId\":null,\"name\":\"Mark Hasegawa-Johnson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7f02cc0d8266d41acb8e1040384b2db1d665c81\",\"title\":\"Seeing is Knowing! Fact-based Visual Question Answering using Knowledge Graph Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/c7f02cc0d8266d41acb8e1040384b2db1d665c81\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.05896\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55f2626b7250b3b24dd0d2bab3ef3c3bbd9b3758\",\"title\":\"Answering Image Riddles using Vision and Reasoning through Probabilistic Soft Logic\",\"url\":\"https://www.semanticscholar.org/paper/55f2626b7250b3b24dd0d2bab3ef3c3bbd9b3758\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6806161\",\"name\":\"A. Khamparia\"},{\"authorId\":\"48413825\",\"name\":\"B. Pandey\"},{\"authorId\":\"74600005\",\"name\":\"Shrasti Tiwari\"},{\"authorId\":\"144786228\",\"name\":\"D. Gupta\"},{\"authorId\":\"103319292\",\"name\":\"A. Khanna\"},{\"authorId\":\"144091143\",\"name\":\"J. Rodrigues\"}],\"doi\":\"10.1007/s00034-019-01306-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8e5e775da93348382f198fa22f3cda7f04c71f\",\"title\":\"An Integrated Hybrid CNN\\u2013RNN Model for Visual Description and Generation of Captions\",\"url\":\"https://www.semanticscholar.org/paper/dc8e5e775da93348382f198fa22f3cda7f04c71f\",\"venue\":\"Circuits Syst. Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39904503\",\"name\":\"C. A. Henning\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"}],\"doi\":\"10.1145/3078971.3078991\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfe4c02324d7adc8ef059c02cee4798f3b296763\",\"title\":\"Estimating the Information Gap between Textual and Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/cfe4c02324d7adc8ef059c02cee4798f3b296763\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.neucom.2018.02.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a24f013cbae0f349c54aaf958dca944d561a6efd\",\"title\":\"VD-SAN: Visual-Densely Semantic Attention Network for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a24f013cbae0f349c54aaf958dca944d561a6efd\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543226\",\"name\":\"Xiaoxiao Liu\"},{\"authorId\":\"40096492\",\"name\":\"Q. Xu\"},{\"authorId\":null,\"name\":\"Ning Wang\"}],\"doi\":\"10.1007/s00371-018-1566-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f79c03f977d1c9acb71d87301272682422b0b14f\",\"title\":\"A survey on deep neural network-based image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79c03f977d1c9acb71d87301272682422b0b14f\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":206593820,\"doi\":\"10.1109/CVPR.2016.29\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":35,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"references\":[{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742448\",\"name\":\"K. Bollacker\"},{\"authorId\":\"144572178\",\"name\":\"C. Evans\"},{\"authorId\":\"2990264\",\"name\":\"Praveen Paritosh\"},{\"authorId\":\"1399112633\",\"name\":\"Tim Sturge\"},{\"authorId\":\"37715132\",\"name\":\"J. Taylor\"}],\"doi\":\"10.1145/1376616.1376746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\"title\":\"Freebase: a collaboratively created graph database for structuring human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\"venue\":\"SIGMOD Conference\",\"year\":2008},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1501.03302\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4a397577302ad1f270c2541e6230064882921cc\",\"title\":\"Hard to Cheat: A Turing Test based on Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/f4a397577302ad1f270c2541e6230064882921cc\",\"venue\":\"AAAI 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145044578\",\"name\":\"S. Auer\"},{\"authorId\":\"1729154\",\"name\":\"C. Bizer\"},{\"authorId\":\"2051816\",\"name\":\"Georgi Kobilarov\"},{\"authorId\":\"144568027\",\"name\":\"Jens Lehmann\"},{\"authorId\":\"1702661\",\"name\":\"Richard Cyganiak\"},{\"authorId\":\"1804315\",\"name\":\"Z. Ives\"}],\"doi\":\"10.1007/978-3-540-76298-0_52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b2c30dfd3968c5d9418bb2c14b2382d3ccc64b2\",\"title\":\"DBpedia: A Nucleus for a Web of Open Data\",\"url\":\"https://www.semanticscholar.org/paper/2b2c30dfd3968c5d9418bb2c14b2382d3ccc64b2\",\"venue\":\"ISWC/ASWC\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144096985\",\"name\":\"G. Miller\"}],\"doi\":\"10.1145/219717.219748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68c03788224000794d5491ab459be0b2a2c38677\",\"title\":\"WordNet: a lexical database for English\",\"url\":\"https://www.semanticscholar.org/paper/68c03788224000794d5491ab459be0b2a2c38677\",\"venue\":\"CACM\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2011.6126524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85cb25e88d3b0548a26e7a70b6953e500d27eb9a\",\"title\":\"Learning cross-modality similarity for multinomial data\",\"url\":\"https://www.semanticscholar.org/paper/85cb25e88d3b0548a26e7a70b6953e500d27eb9a\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1648075979\",\"name\":\"B. A. R. Kernfach\"},{\"authorId\":\"1648268257\",\"name\":\"Nur IM Sommersemester\"},{\"authorId\":\"1648268256\",\"name\":\"\\u00dcbersicht Franz\\u00f6sisch\"},{\"authorId\":\"1648134774\",\"name\":\"\\u00dcbersicht Italienisch\"}],\"doi\":\"10.1515/9783111697888-004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fff1b293b45d06c8462021aa6c90c81e743e131b\",\"title\":\"B\",\"url\":\"https://www.semanticscholar.org/paper/fff1b293b45d06c8462021aa6c90c81e743e131b\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40538579\",\"name\":\"J. Vogel\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-006-8614-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e264e1e55433f158bf8aa8b260bf430d76d5fa28\",\"title\":\"Semantic Modeling of Natural Scenes for Content-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/e264e1e55433f158bf8aa8b260bf430d76d5fa28\",\"venue\":\"International Journal of Computer Vision\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"cmp-lg/9406033\",\"authors\":[{\"authorId\":\"2459057\",\"name\":\"Z. Wu\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":\"10.3115/981732.981751\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"title\":\"Verb Semantics and Lexical Selection\",\"url\":\"https://www.semanticscholar.org/paper/0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"venue\":\"ACL\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G Kulkarni\"},{\"authorId\":null,\"name\":\"V Premraj\"},{\"authorId\":null,\"name\":\"V Ordonez\"},{\"authorId\":null,\"name\":\"S Dhar\"},{\"authorId\":null,\"name\":\"S Li\"},{\"authorId\":null,\"name\":\"Y Choi\"},{\"authorId\":null,\"name\":\"A C Berg\"},{\"authorId\":null,\"name\":\"T L Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE Trans. Pattern Anal. Mach. Intell\",\"url\":\"\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2831988\",\"name\":\"Ian Endres\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2009.5206772\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5e999a8d9b40600d669324eadd836b3895852cb\",\"title\":\"Describing objects by their attributes\",\"url\":\"https://www.semanticscholar.org/paper/d5e999a8d9b40600d669324eadd836b3895852cb\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":\"1507.05670\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1776014\",\"name\":\"Ce Zhang\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9563d6fafb6ba09c082a57e8d9b31494029a45ac\",\"title\":\"Building a Large-scale Multimodal Knowledge Base for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9563d6fafb6ba09c082a57e8d9b31494029a45ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-10593-2_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"title\":\"Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections\",\"url\":\"https://www.semanticscholar.org/paper/fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"},{\"authorId\":\"1748758\",\"name\":\"H. Nickisch\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPRW.2009.5206594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"title\":\"Learning to detect unseen object classes by between-class attribute transfer\",\"url\":\"https://www.semanticscholar.org/paper/0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.06272\",\"authors\":[{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"2266415\",\"name\":\"K. Fu\"},{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56ffece2817a0363f551210733a611830ba1155d\",\"title\":\"Aligning where to see and what to tell: image caption with region-based attention and scene factorization\",\"url\":\"https://www.semanticscholar.org/paper/56ffece2817a0363f551210733a611830ba1155d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1411.5654\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"title\":\"Learning a Recurrent Visual Representation for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/f4af49a1ead3c81cc5d023878cb67c5646dd8a04\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731948\",\"name\":\"P. Viola\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"521768f7772163bc7c57ae2c9855889abb747fbb\",\"title\":\"Multiple Instance Boosting for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/521768f7772163bc7c57ae2c9855889abb747fbb\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1503.00848\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"},{\"authorId\":\"48509230\",\"name\":\"F. Marqu\\u00e9s\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/TPAMI.2016.2537320\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb2c4afc60b074d74a1cf5dd0b8b4f768a20626d\",\"title\":\"Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb2c4afc60b074d74a1cf5dd0b8b4f768a20626d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/ICCV.2015.277\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3640aae13e344ad70a926510221dada626a44de\",\"title\":\"Guiding the Long-Short Term Memory Model for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/c3640aae13e344ad70a926510221dada626a44de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1509.04942\",\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"title\":\"Guiding Long-Short Term Memory for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1406.5726\",\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"144529354\",\"name\":\"Wei Xia\"},{\"authorId\":\"1753492\",\"name\":\"Junshi Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145550812\",\"name\":\"J. Dong\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TPAMI.2015.2491929\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67bb920c40b161a543f29943e7d945789ef208cd\",\"title\":\"CNN: Single-label to Multi-label\",\"url\":\"https://www.semanticscholar.org/paper/67bb920c40b161a543f29943e7d945789ef208cd\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569483\",\"name\":\"Xuchun Li\"},{\"authorId\":\"36547165\",\"name\":\"L. Wang\"},{\"authorId\":\"1725702\",\"name\":\"E. Sung\"}],\"doi\":\"10.1109/ICIP.2004.1421535\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09df7834d76e4e90b1f14ce95c1f124fad8a68f\",\"title\":\"Multilabel SVM active learning for image classification\",\"url\":\"https://www.semanticscholar.org/paper/b09df7834d76e4e90b1f14ce95c1f124fad8a68f\",\"venue\":\"2004 International Conference on Image Processing, 2004. ICIP '04.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825717984\",\"name\":\"HodoshMicah\"},{\"authorId\":\"150355309\",\"name\":\"YoungPeter\"},{\"authorId\":\"1825722682\",\"name\":\"HockenmaierJulia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"802e85172bb1418bdfb8211062aa3049e9bd765d\",\"title\":\"Framing image description as a ranking task\",\"url\":\"https://www.semanticscholar.org/paper/802e85172bb1418bdfb8211062aa3049e9bd765d\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145970060\",\"name\":\"A. Aker\"},{\"authorId\":\"1718590\",\"name\":\"R. Gaizauskas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8dbc756ea246f599250c09e3efd9bba9909a842\",\"title\":\"Generating Image Descriptions Using Dependency Relational Patterns\",\"url\":\"https://www.semanticscholar.org/paper/e8dbc756ea246f599250c09e3efd9bba9909a842\",\"venue\":\"ACL\",\"year\":2010},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6286a82f72f632672c1890f3dd6bbb15b8e5168b\",\"title\":\"Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification\",\"url\":\"https://www.semanticscholar.org/paper/6286a82f72f632672c1890f3dd6bbb15b8e5168b\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"144529354\",\"name\":\"Wei Xia\"},{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"1753492\",\"name\":\"Junshi Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145550812\",\"name\":\"J. Dong\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TPAMI.2015.2491929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32d850e556f39f6bbedcdef0e38f5cd295a6144f\",\"title\":\"HCP: A Flexible CNN Framework for Multi-Label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/32d850e556f39f6bbedcdef0e38f5cd295a6144f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Young Hodosh\"},{\"authorId\":null,\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hochreiter and J . Schmidhuber . Long short - term memory\",\"url\":\"\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bengio . Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"\",\"venue\":\"Proc . Int . Conf . Artificial Intell . & Stat . , pages\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df4f851e3c37017822a683b1356c6c390b5b5487\",\"title\":\"Image Question Answering: A Visual Semantic Embedding Model and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/df4f851e3c37017822a683b1356c6c390b5b5487\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1162/tacl_a_00188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59927ded86ab4f7253fc32efb351e5a13e746ead\",\"title\":\"TreeTalk: Composition and Compression of Trees for Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/59927ded86ab4f7253fc32efb351e5a13e746ead\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1776014\",\"name\":\"Ce Zhang\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"131125a5aadb48ec3eceb404cedbff713c401feb\",\"title\":\"Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries\",\"url\":\"https://www.semanticscholar.org/paper/131125a5aadb48ec3eceb404cedbff713c401feb\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":\"1410.4615\",\"authors\":[{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a\",\"title\":\"Learning to Execute\",\"url\":\"https://www.semanticscholar.org/paper/0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a\",\"venue\":\"ArXiv\",\"year\":2014}],\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Commonsense reasoning\",\"topicId\":\"922\",\"url\":\"https://www.semanticscholar.org/topic/922\"},{\"topic\":\"High-level programming language\",\"topicId\":\"212045\",\"url\":\"https://www.semanticscholar.org/topic/212045\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Commonsense knowledge (artificial intelligence)\",\"topicId\":\"326287\",\"url\":\"https://www.semanticscholar.org/topic/326287\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Neural Networks\",\"topicId\":\"99954\",\"url\":\"https://www.semanticscholar.org/topic/99954\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Random neural network\",\"topicId\":\"136146\",\"url\":\"https://www.semanticscholar.org/topic/136146\"}],\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"