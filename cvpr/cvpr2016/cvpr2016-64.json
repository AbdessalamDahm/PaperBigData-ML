"{\"abstract\":\"The prediction of salient areas in images has been traditionally addressed with hand-crafted features based on neuroscience principles. This paper, however, addresses the problem with a completely data-driven approach by training a convolutional neural network (convnet). The learning process is formulated as a minimization of a loss function that measures the Euclidean distance of the predicted saliency map with the provided ground truth. The recent publication of large datasets of saliency prediction has provided enough data to train end-to-end architectures that are both fast and accurate. Two designs are proposed: a shallow convnet trained from scratch, and a another deeper solution whose first three layers are adapted from another network trained for classification. To the authors' knowledge, these are the first end-to-end CNNs trained and tested for the purpose of saliency prediction.\",\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\",\"url\":\"https://www.semanticscholar.org/author/7588865\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\",\"url\":\"https://www.semanticscholar.org/author/2470219\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\",\"url\":\"https://www.semanticscholar.org/author/3100480\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\",\"url\":\"https://www.semanticscholar.org/author/145470864\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\",\"url\":\"https://www.semanticscholar.org/author/98536322\"}],\"citationVelocity\":77,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"30777707\",\"name\":\"Fang-Yi Chao\"},{\"authorId\":\"144679055\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1931304\",\"name\":\"W. Hamidouche\"},{\"authorId\":\"144598687\",\"name\":\"O. D\\u00e9forges\"}],\"doi\":\"10.1109/ICMEW.2018.8551543\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8b1bcd397d987d7bb0963ec7e472c3ee6ebfa4\",\"title\":\"Salgan360: Visual Saliency Prediction On 360 Degree Images With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a8b1bcd397d987d7bb0963ec7e472c3ee6ebfa4\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50446711\",\"name\":\"Tanmayee Joshi\"},{\"authorId\":\"31215717\",\"name\":\"S. Sivaprasad\"},{\"authorId\":\"48868525\",\"name\":\"Savita Bhat\"},{\"authorId\":\"2072630\",\"name\":\"N. Pedanekar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"630ec3813ba9df4919b7e06e3fabea21edaf283a\",\"title\":\"Multimodal Approach to Predicting Media Memorability\",\"url\":\"https://www.semanticscholar.org/paper/630ec3813ba9df4919b7e06e3fabea21edaf283a\",\"venue\":\"MediaEval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"96b16a497c2b7f584898930b935ffea1b60abb0e\",\"title\":\"Time-Sensitive Egocentric Image Retrieval for Finding Objects in Lifelogs Degree\",\"url\":\"https://www.semanticscholar.org/paper/96b16a497c2b7f584898930b935ffea1b60abb0e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48048f2fe3705d7d645450f31696045bf3c8312e\",\"title\":\"BubbleView: an alternative to eye-tracking for crowdsourcing image importance\",\"url\":\"https://www.semanticscholar.org/paper/48048f2fe3705d7d645450f31696045bf3c8312e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9335681\",\"name\":\"O. Gorokhovatskyi\"},{\"authorId\":\"51447443\",\"name\":\"O. Peredrii\"},{\"authorId\":\"82811834\",\"name\":\"V. Gorokhovatskyi\"}],\"doi\":\"10.1109/DSMP47368.2020.9204310\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2008ab93363c02d291cf5811efba6c71358655f\",\"title\":\"Interpretability of Neural Network Binary Classification with Part Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f2008ab93363c02d291cf5811efba6c71358655f\",\"venue\":\"2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-48881-3_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"title\":\"Multi-level Net: A Visual Saliency Prediction Model\",\"url\":\"https://www.semanticscholar.org/paper/874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20688889\",\"name\":\"T. Khan\"},{\"authorId\":\"15734915\",\"name\":\"Faizan Abdullah\"},{\"authorId\":\"32278120\",\"name\":\"S. S. Naqvi\"},{\"authorId\":\"1491637170\",\"name\":\"Muhammad Arsalan\"},{\"authorId\":\"1978337531\",\"name\":\"Muhamamd Aurangzeb Khan\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207668\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f2a7379a29bd742a4d56de270420b1e5d27a7fa\",\"title\":\"Shallow Vessel Segmentation Network for Automatic Retinal Vessel Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/4f2a7379a29bd742a4d56de270420b1e5d27a7fa\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144480984\",\"name\":\"Qiang Hu\"},{\"authorId\":\"49895169\",\"name\":\"J. Zhou\"},{\"authorId\":\"47957191\",\"name\":\"Xiao-yun Zhang\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"49538591\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/s11042-019-08390-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"title\":\"Viewport-adaptive 360-degree video coding\",\"url\":\"https://www.semanticscholar.org/paper/9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145661621\",\"name\":\"Bo-Han Wu\"},{\"authorId\":\"2856639\",\"name\":\"Iretiayo Akinola\"},{\"authorId\":null,\"name\":\"Abhi Gupta\"},{\"authorId\":\"143979421\",\"name\":\"F. Xu\"},{\"authorId\":\"31568090\",\"name\":\"J. Varley\"},{\"authorId\":\"1389760740\",\"name\":\"David Watkins-Valls\"},{\"authorId\":\"2193888\",\"name\":\"P. Allen\"}],\"doi\":\"10.1007/s10514-020-09907-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa03d14cccda3c064cf447808a62372320bb87cb\",\"title\":\"Generative Attention Learning: a \\\"GenerAL\\\" framework for high-performance multi-fingered grasping in clutter\",\"url\":\"https://www.semanticscholar.org/paper/aa03d14cccda3c064cf447808a62372320bb87cb\",\"venue\":\"Auton. Robots\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb7b53aa874fa97484f7bc77ca55c461116a15cc\",\"title\":\"SUPPLEMENTAL MATERIAL : Where should saliency models look next ?\",\"url\":\"https://www.semanticscholar.org/paper/cb7b53aa874fa97484f7bc77ca55c461116a15cc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1910.02461\",\"authors\":[{\"authorId\":\"2078645\",\"name\":\"Majid Khonji\"},{\"authorId\":\"143820959\",\"name\":\"Jorge Dias\"},{\"authorId\":\"153549114\",\"name\":\"L. Seneviratne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5115381e185c0a5f44fdc2211a8bf7c8e446527e\",\"title\":\"Risk-Aware Reasoning for Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/5115381e185c0a5f44fdc2211a8bf7c8e446527e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72339339\",\"name\":\"Won-Dong Jang\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/CVPR.2019.00544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f12d63bfe90833fe2bd49d1e7fc67798d76eed4e\",\"title\":\"Interactive Image Segmentation via Backpropagating Refinement Scheme\",\"url\":\"https://www.semanticscholar.org/paper/f12d63bfe90833fe2bd49d1e7fc67798d76eed4e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.00161\",\"authors\":[{\"authorId\":\"49235564\",\"name\":\"M. Xu\"},{\"authorId\":\"32462959\",\"name\":\"Chen Li\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/JSTSP.2020.2966864\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"title\":\"State-of-the-Art in 360\\u00b0 Video/Image Processing: Perception, Assessment and Compression\",\"url\":\"https://www.semanticscholar.org/paper/42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2342453\",\"name\":\"Wentao Bao\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.03.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7e4167fc24c7a64953cbabdd0a6d7790d45102\",\"title\":\"Human scanpath prediction based on deep convolutional saccadic model\",\"url\":\"https://www.semanticscholar.org/paper/0d7e4167fc24c7a64953cbabdd0a6d7790d45102\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"3332324\",\"name\":\"X. Zhao\"},{\"authorId\":\"47378234\",\"name\":\"R. Mo\"}],\"doi\":\"10.1007/978-3-030-00563-4_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"title\":\"Bottom-Up Saliency Prediction by Simulating End-Stopping with Log-Gabor\",\"url\":\"https://www.semanticscholar.org/paper/bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46205813\",\"name\":\"K\\u00e9vin Bannier\"},{\"authorId\":\"2617152\",\"name\":\"E. Jain\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1145/3204493.3204560\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ca3d3b2b1bec4e39e3889734db608949c26880c\",\"title\":\"Deepcomics: saliency estimation for comics\",\"url\":\"https://www.semanticscholar.org/paper/6ca3d3b2b1bec4e39e3889734db608949c26880c\",\"venue\":\"ETRA\",\"year\":2018},{\"arxivId\":\"1804.00112\",\"authors\":[{\"authorId\":\"50357985\",\"name\":\"S. Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00138\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"d3a0240a2dde30e3c7b977358843a5013b3f4d42\",\"title\":\"Compare and Contrast: Learning Prominent Visual Differences\",\"url\":\"https://www.semanticscholar.org/paper/d3a0240a2dde30e3c7b977358843a5013b3f4d42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.06236\",\"authors\":[{\"authorId\":\"2912641\",\"name\":\"I. Kavasidis\"},{\"authorId\":\"1681089\",\"name\":\"S. Palazzo\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"145587660\",\"name\":\"C. Pino\"},{\"authorId\":\"144027622\",\"name\":\"D. Giordano\"},{\"authorId\":\"39097156\",\"name\":\"D. Giuffrida\"},{\"authorId\":\"144136542\",\"name\":\"P. Messina\"}],\"doi\":\"10.1007/978-3-030-30645-8_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03672cfa599950f208d424d5298cdc12b72c2492\",\"title\":\"A Saliency-based Convolutional Neural Network for Table and Chart Detection in Digitized Documents\",\"url\":\"https://www.semanticscholar.org/paper/03672cfa599950f208d424d5298cdc12b72c2492\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403185\",\"name\":\"A. Leibetseder\"},{\"authorId\":\"1937120\",\"name\":\"K. Sch\\u00f6ffmann\"}],\"doi\":\"10.1145/3206025.3206082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bc0d7343f541edead718dbb7aafb85db17d69c7\",\"title\":\"Extracting and Using Medical Expert Knowledge to Advance in Video Processing for Gynecologic Endoscopy\",\"url\":\"https://www.semanticscholar.org/paper/9bc0d7343f541edead718dbb7aafb85db17d69c7\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6042907\",\"name\":\"Jintao Wu\"},{\"authorId\":\"34831475\",\"name\":\"Guijun Yang\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"143778544\",\"name\":\"B. Xu\"},{\"authorId\":\"143837977\",\"name\":\"Liang Han\"},{\"authorId\":\"48270284\",\"name\":\"Yaohui Zhu\"}],\"doi\":\"10.3390/rs11060691\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2c902383df6d242ff09b7f3b60f26fc5cc2a6c4\",\"title\":\"Automatic Counting of in situ Rice Seedlings from UAV Images Based on a Deep Fully Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c2c902383df6d242ff09b7f3b60f26fc5cc2a6c4\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693461\",\"name\":\"Ping Hu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2017.65\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d97dd1d3d6481c8687d54ed7e0adda3e37f2887\",\"title\":\"Deep Level Sets for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/0d97dd1d3d6481c8687d54ed7e0adda3e37f2887\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742368876\",\"name\":\"Heecheol Kim\"},{\"authorId\":\"1771982\",\"name\":\"Y. Ohmura\"},{\"authorId\":\"73394480\",\"name\":\"Y. Kuniyoshi\"}],\"doi\":\"10.1109/LRA.2020.2998410\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72db25e29524f84f29bc4598d72a3a60a2b348bd\",\"title\":\"Using Human Gaze to Improve Robustness Against Irrelevant Objects in Robot Manipulation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/72db25e29524f84f29bc4598d72a3a60a2b348bd\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3480262\",\"name\":\"Zenglin Shi\"},{\"authorId\":\"47058950\",\"name\":\"Le Zhang\"},{\"authorId\":null,\"name\":\"Yibo Sun\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"}],\"doi\":\"10.1109/TII.2018.2852481\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e27680dea38b7a0272042a82577eb58eb552785c\",\"title\":\"Multiscale Multitask Deep NetVLAD for Crowd Counting\",\"url\":\"https://www.semanticscholar.org/paper/e27680dea38b7a0272042a82577eb58eb552785c\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"145098609\",\"name\":\"A. Fathi\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"}],\"doi\":\"10.1007/s11263-019-01170-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa1dce9ca680ea2da13733d6050b17a969badd8f\",\"title\":\"The Devil is in the Decoder: Classification, Regression and GANs\",\"url\":\"https://www.semanticscholar.org/paper/fa1dce9ca680ea2da13733d6050b17a969badd8f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"Lorenzo Baraldi\"},{\"authorId\":\"145518528\",\"name\":\"G. Serra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"title\":\"1 Paying More A ention to Saliency : Image Captioning with Saliency and Context A ention\",\"url\":\"https://www.semanticscholar.org/paper/96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.10432\",\"authors\":[{\"authorId\":\"30718292\",\"name\":\"G. Pantazis\"},{\"authorId\":\"2494584\",\"name\":\"G. Dimas\"},{\"authorId\":\"143932347\",\"name\":\"D. Iakovidis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"198a8cba6c8692a3526ed7f1c2bfa276fa0c5adc\",\"title\":\"SalSum: Saliency-based Video Summarization using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/198a8cba6c8692a3526ed7f1c2bfa276fa0c5adc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.05785\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2232582\",\"name\":\"D. Kangin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICPR.2018.8546051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3067da31693248e1e966e1fb46658279cc468ccd\",\"title\":\"Aggregated Sparse Attention for Steering Angle Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3067da31693248e1e966e1fb46658279cc468ccd\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1414646282\",\"name\":\"A. Rodr\\u00edguez-Hidalgo\"},{\"authorId\":\"1399233089\",\"name\":\"Carmen Pel\\u00e1ez-Moreno\"},{\"authorId\":\"1398099309\",\"name\":\"A. Gallardo-Antol\\u00edn\"}],\"doi\":\"10.1016/j.eswa.2018.07.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6e61bc713d32d64b92324ad8aad542f553c10e7\",\"title\":\"Echoic log-surprise: A multi-scale scheme for acoustic saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/f6e61bc713d32d64b92324ad8aad542f553c10e7\",\"venue\":\"Expert Syst. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3884219\",\"name\":\"Shiping Zhu\"},{\"authorId\":\"1765822\",\"name\":\"Ziyao Xu\"}],\"doi\":\"10.1016/j.neucom.2017.08.054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25dadd45a34506c3e44154ce79b223e115bc4e79\",\"title\":\"Spatiotemporal visual saliency guided perceptual high efficiency video coding with neural network\",\"url\":\"https://www.semanticscholar.org/paper/25dadd45a34506c3e44154ce79b223e115bc4e79\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"145395437\",\"name\":\"F. Doctor\"},{\"authorId\":\"2031669\",\"name\":\"A. Herrera\"},{\"authorId\":\"1959195375\",\"name\":\"Sohail Sahab\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a50e6b64d5351cd3d4780c232fc3f7512a72aec4\",\"title\":\"Multimodal Deep Features Fusion for Video Memorability Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a50e6b64d5351cd3d4780c232fc3f7512a72aec4\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":\"1709.06505\",\"authors\":[{\"authorId\":\"145030054\",\"name\":\"R. Monroy\"},{\"authorId\":\"32882525\",\"name\":\"S. Lutz\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1016/j.image.2018.05.005\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"title\":\"SalNet360: Saliency Maps for omni-directional images with CNN\",\"url\":\"https://www.semanticscholar.org/paper/b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2017.354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"034cf7f98153dada78bcffc72ed5a13890482a94\",\"title\":\"Learning Visual Attention to Identify People with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/034cf7f98153dada78bcffc72ed5a13890482a94\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2757212\",\"name\":\"L. Fan\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2018.00676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"037ad2159097dcb7ff29b6c328b859fb64f7078e\",\"title\":\"Inferring Shared Attention in Social Scene Videos\",\"url\":\"https://www.semanticscholar.org/paper/037ad2159097dcb7ff29b6c328b859fb64f7078e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.04702\",\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/TPAMI.2018.2865794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"347ce37f15cea5bb8d0a676562664f80e3609b78\",\"title\":\"Pixel Objectness: Learning to Segment Generic Objects Automatically in Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/347ce37f15cea5bb8d0a676562664f80e3609b78\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":null,\"name\":\"Patr Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae447685c5dddac6b961079d2c15cf92fa1a8d0a\",\"title\":\"How Many Glances? Modeling Multi-duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/ae447685c5dddac6b961079d2c15cf92fa1a8d0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1709.05307\",\"authors\":[{\"authorId\":\"2004177\",\"name\":\"F. Murabito\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"3403160\",\"name\":\"Konstantin Pogorelov\"},{\"authorId\":\"1410046696\",\"name\":\"Michael Riegler\"}],\"doi\":\"10.1016/j.cviu.2018.03.005\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"706f314f3b66f0ede47ec9ca7157426915739244\",\"title\":\"Top-Down Saliency Detection Driven by Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/706f314f3b66f0ede47ec9ca7157426915739244\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49111436\",\"name\":\"Jonathan Chung\"},{\"authorId\":\"2331840\",\"name\":\"M. Eizenman\"},{\"authorId\":\"8609038\",\"name\":\"Uros Rakita\"},{\"authorId\":\"143635045\",\"name\":\"R. McIntyre\"},{\"authorId\":\"3710455\",\"name\":\"P. Giacobbe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"457ad1ae9b26e80bb7171ff7bcbf635a802d5c35\",\"title\":\"Learning Differences Between Visual Scanning Patterns Can Disambiguate Bipolar and Unipolar Patients\",\"url\":\"https://www.semanticscholar.org/paper/457ad1ae9b26e80bb7171ff7bcbf635a802d5c35\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"3411472\",\"name\":\"G. Panagiotaropoulou\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2018.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"113eda25ece35fd7ecb51cb104182a973ea2313e\",\"title\":\"Audio-Visual Temporal Saliency Modeling Validated by fMRI Data\",\"url\":\"https://www.semanticscholar.org/paper/113eda25ece35fd7ecb51cb104182a973ea2313e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6271074\",\"name\":\"Kirsten A Dalrymple\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"3048594\",\"name\":\"J. Elison\"}],\"doi\":\"10.1038/s41598-019-42764-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5920514d8807b434fed19cb938c9a434b6979265\",\"title\":\"Machine learning accurately classifies age of toddlers based on eye tracking\",\"url\":\"https://www.semanticscholar.org/paper/5920514d8807b434fed19cb938c9a434b6979265\",\"venue\":\"Scientific Reports\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004798009\",\"name\":\"V. V. Babenko\"},{\"authorId\":\"6461856\",\"name\":\"D. Yavna\"},{\"authorId\":\"2036518579\",\"name\":\"E. G. Rodionov\"}],\"doi\":\"10.1007/s11055-020-00994-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30988b8bec915b744ea7686bfbfc91014644d1b3\",\"title\":\"Contributions of Different Spatial Modulations of Brightness Gradients to the Control of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/30988b8bec915b744ea7686bfbfc91014644d1b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.00567\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1007/978-3-030-11021-5_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"title\":\"PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2565778\",\"name\":\"H. Gao\"},{\"authorId\":\"8157822\",\"name\":\"Z. Chen\"},{\"authorId\":\"49467580\",\"name\":\"Ge Ma\"},{\"authorId\":\"6187832\",\"name\":\"W. Xie\"},{\"authorId\":\"46947423\",\"name\":\"Zhifu Li\"}],\"doi\":\"10.1109/ICPR.2018.8546010\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"22fbd5367ab861ef485e353ef6e2d66e17ffc14c\",\"title\":\"Deep Pixel Probabilistic Model for Super Resolution Based on Human Visual Saliency Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/22fbd5367ab861ef485e353ef6e2d66e17ffc14c\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77a4096c59f51711469d4a2d8936fc5ef62ffdf8\",\"title\":\"BubbleView: a validation of a mouse-contingent interface for crowdsourcing image importance and tracking visual attention\",\"url\":\"https://www.semanticscholar.org/paper/77a4096c59f51711469d4a2d8936fc5ef62ffdf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-70169-1_29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"title\":\"Attentive Models in Vision: Computing Saliency Maps in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"venue\":\"AI*IA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41aa48241071f8fa15145c3452679aa91c13459e\",\"title\":\"Salient Object Detection Driven by Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/41aa48241071f8fa15145c3452679aa91c13459e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825282\",\"name\":\"Wei-Ning Wang\"},{\"authorId\":\"153870946\",\"name\":\"Rui Deng\"}],\"doi\":\"10.1109/ICIP.2019.8803749\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0699fb752175c9b10ba4a3f4e8acdbce918e65f6\",\"title\":\"Modeling Human Perception for Image Aesthetic Assessme\",\"url\":\"https://www.semanticscholar.org/paper/0699fb752175c9b10ba4a3f4e8acdbce918e65f6\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490750795\",\"name\":\"Huimin Zou\"},{\"authorId\":\"40555350\",\"name\":\"Juanjuan He\"},{\"authorId\":\"1490748703\",\"name\":\"Song Xiang\"},{\"authorId\":\"34611435\",\"name\":\"Ziqi Zhu\"}],\"doi\":\"10.1117/12.2557743\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8efb47872057a18fcb003a6f3b56f74df8748916\",\"title\":\"Saliency detection based on non-local neural networks in low-contrast images\",\"url\":\"https://www.semanticscholar.org/paper/8efb47872057a18fcb003a6f3b56f74df8748916\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"153870946\",\"name\":\"Rui Deng\"},{\"authorId\":\"123698261\",\"name\":\"L. Li\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"}],\"doi\":\"10.1007/978-3-030-31723-2_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a718400b6b3ce53374cb91cf4bf500e009197f9a\",\"title\":\"Image Aesthetic Assessment Based on Perception Consistency\",\"url\":\"https://www.semanticscholar.org/paper/a718400b6b3ce53374cb91cf4bf500e009197f9a\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2115104\",\"name\":\"Wenjia Niu\"},{\"authorId\":\"100613971\",\"name\":\"Gang Li\"},{\"authorId\":\"8190315\",\"name\":\"Jiqiang Liu\"},{\"authorId\":\"40062477\",\"name\":\"J. Tan\"},{\"authorId\":\"72055377\",\"name\":\"L. Guo\"},{\"authorId\":\"114687731\",\"name\":\"Zhen Han\"},{\"authorId\":\"1731028\",\"name\":\"L. Batten\"}],\"doi\":\"10.1007/978-3-662-48683-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"title\":\"Applications and Techniques in Information Security\",\"url\":\"https://www.semanticscholar.org/paper/58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"venue\":\"Communications in Computer and Information Science\",\"year\":2015},{\"arxivId\":\"1705.01759\",\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.153\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba227bb94ea9414bad8846673c904a10d813e443\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360\\u00b0 Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba227bb94ea9414bad8846673c904a10d813e443\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10604706\",\"name\":\"Ali Selman Aydin\"},{\"authorId\":\"113653487\",\"name\":\"Shirin Feiz\"},{\"authorId\":\"145070406\",\"name\":\"V. Ashok\"},{\"authorId\":\"1519965383\",\"name\":\"I. Ramakrishnan\"}],\"doi\":\"10.1145/3377325.3377540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5bb5375a3e63568447dc3b7e20e8e3c6aee2da8d\",\"title\":\"SaIL: saliency-driven injection of ARIA landmarks\",\"url\":\"https://www.semanticscholar.org/paper/5bb5375a3e63568447dc3b7e20e8e3c6aee2da8d\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c01a827fd687791b92e393b203028fa1bca4c5ff\",\"title\":\"Leverage eye-movement data for saliency modeling: Invariance Analysis and a Robust New Model\",\"url\":\"https://www.semanticscholar.org/paper/c01a827fd687791b92e393b203028fa1bca4c5ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39249670\",\"name\":\"D. Zhu\"},{\"authorId\":\"145978454\",\"name\":\"L. Dai\"},{\"authorId\":\"47403551\",\"name\":\"Xuan Shao\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145378980\",\"name\":\"Ye Luo\"},{\"authorId\":\"49301770\",\"name\":\"Jianwei Lu\"}],\"doi\":\"10.1117/1.JEI.26.6.063018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ea52d6a422b4d09828b6f1c743b4fa4fa4be4f1\",\"title\":\"Image salient object detection with refined deep features via convolution neural network\",\"url\":\"https://www.semanticscholar.org/paper/2ea52d6a422b4d09828b6f1c743b4fa4fa4be4f1\",\"venue\":\"J. Electronic Imaging\",\"year\":2017},{\"arxivId\":\"1707.05847\",\"authors\":[{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"}],\"doi\":\"10.5244/c.31.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c887397c89a8739fc1208c2ef8cab2994b6be8d9\",\"title\":\"The Devil is in the Decoder\",\"url\":\"https://www.semanticscholar.org/paper/c887397c89a8739fc1208c2ef8cab2994b6be8d9\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"title\":\"From Coarse Attention to Fine-Grained Gaze: A Two-stage 3D Fully Convolutional Network for Predicting Eye Gaze in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9435406\",\"name\":\"Huanzhao Chen\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"}],\"doi\":\"10.1155/2018/5368624\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84d7db1126891b2cbc4c81b909de174c41fb9f26\",\"title\":\"A Computing Model of Selective Attention for Service Robot Based on Spatial Data Fusion\",\"url\":\"https://www.semanticscholar.org/paper/84d7db1126891b2cbc4c81b909de174c41fb9f26\",\"venue\":\"J. Robotics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"title\":\"Visual context for verb sense disambiguation and multilingual representation learning\",\"url\":\"https://www.semanticscholar.org/paper/49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9441635\",\"name\":\"O. Rajankar\"},{\"authorId\":\"47310912\",\"name\":\"Uttam D. Kolekar\"},{\"authorId\":\"39970431\",\"name\":\"S. Talbar\"}],\"doi\":\"10.1007/s11760-018-1371-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d7a17d61cedb73f22cef3ff0cc08c1d8d1d9ca0\",\"title\":\"Heuristics approach to speeding up saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/1d7a17d61cedb73f22cef3ff0cc08c1d8d1d9ca0\",\"venue\":\"Signal Image Video Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50219447\",\"name\":\"Zheng Wang\"},{\"authorId\":\"145811527\",\"name\":\"J. Ren\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.01.076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a35ba189491bb8ae59df3c8b41a5f157e34231d2\",\"title\":\"A deep-learning based feature hybrid framework for spatiotemporal saliency detection inside videos\",\"url\":\"https://www.semanticscholar.org/paper/a35ba189491bb8ae59df3c8b41a5f157e34231d2\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":\"10.18201/IJISAE.2016426384\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f58636338dd536340e5576dae07d7e1b782291f\",\"title\":\"A Region Covariances-based Visual Attention Model for RGB-D Images\",\"url\":\"https://www.semanticscholar.org/paper/4f58636338dd536340e5576dae07d7e1b782291f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48926031\",\"name\":\"Chen Xia\"},{\"authorId\":\"145877494\",\"name\":\"J. Han\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"}],\"doi\":\"10.1109/TIP.2019.2897966\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed56acb6964af0c814266f289d46859c33b8b5be\",\"title\":\"Predicting Human Saccadic Scanpaths Based on Iterative Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/ed56acb6964af0c814266f289d46859c33b8b5be\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2008.13227\",\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7dd07f677210aa27defdd0f471771860566f674\",\"title\":\"A Compact Deep Architecture for Real-time Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b7dd07f677210aa27defdd0f471771860566f674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"title\":\"Related Work 2 . 1 Visual Saliency Prediction Saliency maps\",\"url\":\"https://www.semanticscholar.org/paper/504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12524096\",\"name\":\"B. Kandemir\"},{\"authorId\":\"2519795\",\"name\":\"Zihan Zhou\"},{\"authorId\":\"40116905\",\"name\":\"Jia Li\"},{\"authorId\":\"1699550\",\"name\":\"J. Z. Wang\"}],\"doi\":\"10.1145/3126686.3126712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927238e321d3ce5d05315deafc835a1266ff705a\",\"title\":\"Beyond Saliency: Assessing Visual Balance with High-level Cues\",\"url\":\"https://www.semanticscholar.org/paper/927238e321d3ce5d05315deafc835a1266ff705a\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153385438\",\"name\":\"A. Mane\"},{\"authorId\":\"151440546\",\"name\":\"S. Mali\"},{\"authorId\":\"90315386\",\"name\":\"Priyanka D. Mali\"},{\"authorId\":\"151426605\",\"name\":\"Sonam Mulik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9066cd93949c29c0197f4e4fceaf00888532f46d\",\"title\":\"International Journal of Scientific Research in Computer Science, Engineering and Information Technology\",\"url\":\"https://www.semanticscholar.org/paper/9066cd93949c29c0197f4e4fceaf00888532f46d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1805.11374\",\"authors\":[{\"authorId\":\"3503889\",\"name\":\"Yu Li\"},{\"authorId\":\"2910574\",\"name\":\"Ya Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a320538e0ea0a2e013f5730e8c72e26b76544efd\",\"title\":\"Webpage Saliency Prediction with Two-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a320538e0ea0a2e013f5730e8c72e26b76544efd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"2656592\",\"name\":\"Zhisheng Yan\"}],\"doi\":\"10.1145/3304109.3325820\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"25488bb3a7d469d49822f8a27e779d7e963368a2\",\"title\":\"A saliency dataset for 360-degree videos\",\"url\":\"https://www.semanticscholar.org/paper/25488bb3a7d469d49822f8a27e779d7e963368a2\",\"venue\":\"MMSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2297669\",\"name\":\"Sourodeep Biswas\"},{\"authorId\":\"2657624\",\"name\":\"S. Fezza\"},{\"authorId\":\"1755023\",\"name\":\"Mohamed-Chaker Larabi\"}],\"doi\":\"10.1109/IPTA.2017.8310119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1261997e3a3ac4660bc7b558733e8f6e354355b\",\"title\":\"Towards light-compensated saliency prediction for omnidirectional images\",\"url\":\"https://www.semanticscholar.org/paper/d1261997e3a3ac4660bc7b558733e8f6e354355b\",\"venue\":\"2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2017},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"}],\"doi\":\"10.15781/T2R20SC9C\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5a14671f53b010acefc0ed9ea8ce7dca65fb413\",\"title\":\"Human machine collaboration for foreground segmentation in images and videos\",\"url\":\"https://www.semanticscholar.org/paper/e5a14671f53b010acefc0ed9ea8ce7dca65fb413\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1702.05150\",\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/3131275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc2e0b445dc1825c634768517de557ba4bf22e81\",\"title\":\"BubbleView\",\"url\":\"https://www.semanticscholar.org/paper/fc2e0b445dc1825c634768517de557ba4bf22e81\",\"venue\":\"ACM Trans. Comput. Hum. Interact.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422382\",\"name\":\"Qier Meng\"},{\"authorId\":\"1406138715\",\"name\":\"Yohei Hashimoto\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/JBHI.2020.3011805\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f00a322525d7a617808fc920c9096829e63b530e\",\"title\":\"How to Extract More Information With Less Burden: Fundus Image Classification and Retinal Disease Localization With Ophthalmologist Intervention\",\"url\":\"https://www.semanticscholar.org/paper/f00a322525d7a617808fc920c9096829e63b530e\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"1618896088\",\"name\":\"Hong Kong\"}],\"doi\":\"10.1109/cvpr42600.2020.00453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffc481c86d46ca812eff85030f812588bb20b80\",\"title\":\"How Much Time Do You Have? Modeling Multi-Duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cffc481c86d46ca812eff85030f812588bb20b80\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3029535\",\"name\":\"Fumio Nihei\"},{\"authorId\":\"1718158\",\"name\":\"Yukiko I. Nakano\"},{\"authorId\":\"2473784\",\"name\":\"Yutaka Takase\"}],\"doi\":\"10.1145/3279981.3279987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37f392e2ce1fdf5d189df459a13084d360103618\",\"title\":\"Fusing Verbal and Nonverbal Information for Extractive Meeting Summarization\",\"url\":\"https://www.semanticscholar.org/paper/37f392e2ce1fdf5d189df459a13084d360103618\",\"venue\":\"GIFT@ICMI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3029535\",\"name\":\"Fumio Nihei\"},{\"authorId\":\"1718158\",\"name\":\"Yukiko I. Nakano\"}],\"doi\":\"10.3390/MTI3030050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f139cd1873b9bae3f95e947c10963aabc7a500f4\",\"title\":\"Exploring Methods for Predicting Important Utterances Contributing to Meeting Summarization\",\"url\":\"https://www.semanticscholar.org/paper/f139cd1873b9bae3f95e947c10963aabc7a500f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1886286\",\"name\":\"A. Nguyen\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"2066677\",\"name\":\"H. Oh\"},{\"authorId\":\"1931368\",\"name\":\"Haksub Kim\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"},{\"authorId\":\"38107409\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/TIP.2018.2879408\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0aee1700334e2d9de1c0866855bb6fec99b91b8d\",\"title\":\"Deep Visual Saliency on Stereoscopic Images\",\"url\":\"https://www.semanticscholar.org/paper/0aee1700334e2d9de1c0866855bb6fec99b91b8d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46237872\",\"name\":\"Issei Mochizuki\"},{\"authorId\":\"2343461\",\"name\":\"Masahiro Toyoura\"},{\"authorId\":\"2084839\",\"name\":\"X. Mao\"}],\"doi\":\"10.1007/s00371-018-1518-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcc10f963d4816cbb3dd8e77b8135d8869ef6ba3\",\"title\":\"Visual attention prediction for images with leading line structure\",\"url\":\"https://www.semanticscholar.org/paper/bcc10f963d4816cbb3dd8e77b8135d8869ef6ba3\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35552047\",\"name\":\"Eunpil Park\"},{\"authorId\":\"28987028\",\"name\":\"Byeong-Ju Han\"},{\"authorId\":\"7388924\",\"name\":\"Seungjoon Yang\"},{\"authorId\":\"37874485\",\"name\":\"J. Sim\"}],\"doi\":\"10.23919/APSIPA.2018.8659618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"586ad876941e50c7e0b89c5205e97e09b55177f8\",\"title\":\"Video Saliency Detection Using Adaptive Feature Combination and Localized Saliency Computation\",\"url\":\"https://www.semanticscholar.org/paper/586ad876941e50c7e0b89c5205e97e09b55177f8\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40810404\",\"name\":\"Hooman Misaghi\"},{\"authorId\":\"15456805\",\"name\":\"R. Moghadam\"},{\"authorId\":\"50743324\",\"name\":\"Ali Akbar Mahmoudi\"},{\"authorId\":\"81414380\",\"name\":\"A. Salemi\"}],\"doi\":\"10.1109/ICROM.2018.8657572\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d98443fb3b410b6d9810396048c1fd6b451b4d0\",\"title\":\"Image Saliency Detection By Residual And Inception-like CNNs\",\"url\":\"https://www.semanticscholar.org/paper/4d98443fb3b410b6d9810396048c1fd6b451b4d0\",\"venue\":\"2018 6th RSI International Conference on Robotics and Mechatronics (IcRoM)\",\"year\":2018},{\"arxivId\":\"2008.11151\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"205d3644e73c1e5cbce9ce08ea94bbfbc6c13a91\",\"title\":\"FastSal: a Computationally Efficient Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/205d3644e73c1e5cbce9ce08ea94bbfbc6c13a91\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1608.08139\",\"authors\":[{\"authorId\":\"144032116\",\"name\":\"C. Reyes\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":\"10.1145/2983576.2983582\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ee5e26d1b024d79f9d07068663244f1edbed7f\",\"title\":\"Where is my Phone?: Personal Object Retrieval from Egocentric Images\",\"url\":\"https://www.semanticscholar.org/paper/f8ee5e26d1b024d79f9d07068663244f1edbed7f\",\"venue\":\"LTA@MM\",\"year\":2016},{\"arxivId\":\"1612.00220\",\"authors\":[{\"authorId\":\"101085204\",\"name\":\"Mark Marsden\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"145777800\",\"name\":\"S. Little\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0006097300270033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d9d1c34852a2eb059feffa81a6fa77e5db23606\",\"title\":\"Fully Convolutional Crowd Counting on Highly Congested Scenes\",\"url\":\"https://www.semanticscholar.org/paper/0d9d1c34852a2eb059feffa81a6fa77e5db23606\",\"venue\":\"VISIGRAPP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":null,\"name\":\"Songyang Zhang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2017.343\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"title\":\"Predicting Salient Face in Multiple-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117562053\",\"name\":\"M. A. Reina\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f1996c60dec75d575f20880a49d646a42584f3a\",\"title\":\"The temporal dimension of visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/1f1996c60dec75d575f20880a49d646a42584f3a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32187938\",\"name\":\"D. Martin\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15120de369d7733dfce9ab4b98a4bd2e6b5357c2\",\"title\":\"Panoramic convolutions for 360o single-image saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/15120de369d7733dfce9ab4b98a4bd2e6b5357c2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.01869\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"144011211\",\"name\":\"J. J. Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"title\":\"Simple vs complex temporal recurrences for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.3233/IA-170033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"title\":\"Attentive models in vision: Computing saliency maps in the deep learning era\",\"url\":\"https://www.semanticscholar.org/paper/9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"venue\":\"Intelligenza Artificiale\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294797\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1007/978-3-030-01234-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"title\":\"Saliency Detection in 360 ^\\\\circ \\u2218 Videos\",\"url\":\"https://www.semanticscholar.org/paper/6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"1772775\",\"name\":\"A. Mishra\"},{\"authorId\":\"27407096\",\"name\":\"A. Achkar\"},{\"authorId\":\"1795380\",\"name\":\"Justin A. Eichel\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"},{\"authorId\":\"1687510\",\"name\":\"Pierre-Marc Jodoin\"}],\"doi\":\"10.1109/CVPR.2017.698\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7eccc1cd55e70802b017a2cadb9a778e47c7879\",\"title\":\"Non-local Deep Features for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d7eccc1cd55e70802b017a2cadb9a778e47c7879\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1806.01320\",\"authors\":[{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"50993085\",\"name\":\"Chun-Hung Chao\"},{\"authorId\":\"46181955\",\"name\":\"Jin-Dong Dong\"},{\"authorId\":\"2486384\",\"name\":\"Hao-Kai Wen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2018.00154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"title\":\"Cube Padding for Weakly-Supervised Saliency Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"46363837\",\"name\":\"K. Aizawa\"},{\"authorId\":\"144990548\",\"name\":\"Go Irie\"}],\"doi\":\"10.1007/s11042-020-09474-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"title\":\"Computational attention model for children, adults and the elderly\",\"url\":\"https://www.semanticscholar.org/paper/ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33610144\",\"name\":\"X. Chen\"},{\"authorId\":\"28964350\",\"name\":\"Anlin Zheng\"},{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"145053996\",\"name\":\"Feng Lu\"}],\"doi\":\"10.1109/ICCV.2017.119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42ab23233586d626d49b422ac8cc238a8e14bf8a\",\"title\":\"Look, Perceive and Segment: Finding the Salient Objects in Images via Two-stream Fixation-Semantic CNNs\",\"url\":\"https://www.semanticscholar.org/paper/42ab23233586d626d49b422ac8cc238a8e14bf8a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4fa0b4e518de397fafa3fe8c9d925bcd4a3438e\",\"title\":\"Online action detection\",\"url\":\"https://www.semanticscholar.org/paper/f4fa0b4e518de397fafa3fe8c9d925bcd4a3438e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67054334\",\"name\":\"Erik Perillo\"},{\"authorId\":\"2210164\",\"name\":\"Esther Colombini\"}],\"doi\":\"10.1109/SMC.2018.00290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c1cec446da3af680e256838793de0e8831ec6d3\",\"title\":\"Efficient Visual Saliency Detection with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8c1cec446da3af680e256838793de0e8831ec6d3\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34570209\",\"name\":\"Kshitij Dwivedi\"},{\"authorId\":\"145729589\",\"name\":\"Nitin Singh\"},{\"authorId\":\"1392783891\",\"name\":\"Sabari R. Shanmugham\"},{\"authorId\":\"153792660\",\"name\":\"M. Kumar\"}],\"doi\":\"10.1007/978-981-32-9291-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"title\":\"DeepAttent: Saliency Prediction with Deep Multi-scale Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731831\",\"name\":\"A. Chetouani\"},{\"authorId\":\"3349256\",\"name\":\"M. Qureshi\"},{\"authorId\":\"2500259\",\"name\":\"Mohamed Deriche\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":\"10.1109/QoMEX.2019.8743152\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55c8f1bfe39c42448614df8421eba83b55d2ec26\",\"title\":\"A Novel Ranking Algorithm of Enhanced Images using a Convolutional Neural Network and a Saliency-based Patch Selection Scheme\",\"url\":\"https://www.semanticscholar.org/paper/55c8f1bfe39c42448614df8421eba83b55d2ec26\",\"venue\":\"2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2470063\",\"name\":\"Yuzhu Ji\"},{\"authorId\":\"2427559\",\"name\":\"H. Zhang\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1016/j.neucom.2018.08.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78f6209ebef12393511089137352a4fd683ee6f6\",\"title\":\"Saliency detection via conditional adversarial image-to-image network\",\"url\":\"https://www.semanticscholar.org/paper/78f6209ebef12393511089137352a4fd683ee6f6\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dc540300335e27773e2b5f16c481476448d5b83\",\"title\":\"An Integrated Model for Effective Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8dc540300335e27773e2b5f16c481476448d5b83\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993416510\",\"name\":\"Haoran Lv\"},{\"authorId\":\"1387823256\",\"name\":\"Qin Yang\"},{\"authorId\":\"48161566\",\"name\":\"Chenglin Li\"},{\"authorId\":\"3207464\",\"name\":\"Wenrui Dai\"},{\"authorId\":\"38871632\",\"name\":\"J. Zou\"},{\"authorId\":\"144045764\",\"name\":\"Hongkai Xiong\"}],\"doi\":\"10.1145/3394171.3413733\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c87dcaca25fc2bab113076222abb27ccc8c38052\",\"title\":\"SalGCN: Saliency Prediction for 360-Degree Images Based on Spherical Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c87dcaca25fc2bab113076222abb27ccc8c38052\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144800793\",\"name\":\"Cuiping Shi\"},{\"authorId\":\"1922145804\",\"name\":\"Ruiyang Xia\"},{\"authorId\":\"120692851\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3016116\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ac7fa3d8124c2c1815c88c8364a0573f7817c0d8\",\"title\":\"A Novel Multi-Branch Channel Expansion Network for Garbage Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/ac7fa3d8124c2c1815c88c8364a0573f7817c0d8\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2016.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf54a133c89f730adc5ea12c3ac646971120781c\",\"title\":\"A comparative study for feature integration strategies in dynamic saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/cf54a133c89f730adc5ea12c3ac646971120781c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/cvpr42600.2020.00305\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"title\":\"Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1809.07499\",\"authors\":[{\"authorId\":\"144445177\",\"name\":\"K. J. Joseph\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":\"10.1007/978-3-030-11021-5_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54b679d02d33b6d23df5fc11454f5d7376980a51\",\"title\":\"MASON: A Model AgnoStic ObjectNess Framework\",\"url\":\"https://www.semanticscholar.org/paper/54b679d02d33b6d23df5fc11454f5d7376980a51\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1707.06029\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"4945045\",\"name\":\"Yeonhwa Kim\"},{\"authorId\":\"143912065\",\"name\":\"Kyung Yoo\"},{\"authorId\":\"2135453\",\"name\":\"S. Lee\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.648\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"title\":\"Supervising Neural Attention Models for Video Captioning by Human Gaze Data\",\"url\":\"https://www.semanticscholar.org/paper/1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1706.09650\",\"authors\":[{\"authorId\":\"144629275\",\"name\":\"D. Jeong\"},{\"authorId\":\"7493516\",\"name\":\"Insung Hwang\"},{\"authorId\":\"1707645\",\"name\":\"N. I. Cho\"}],\"doi\":\"10.1109/TIP.2018.2859752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4cf6efebfd2796b93b25baa2ad6819b8120dde6\",\"title\":\"Co-Salient Object Detection Based on Deep Saliency Networks and Seed Propagation Over an Integrated Graph\",\"url\":\"https://www.semanticscholar.org/paper/e4cf6efebfd2796b93b25baa2ad6819b8120dde6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"7503327\",\"name\":\"Vennela Gudisa\"},{\"authorId\":\"2313878\",\"name\":\"Jaley H. Dholakiya\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/CVPR.2016.623\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ca43c217aceabea4cff14bff1d81df2debe058f\",\"title\":\"Saliency Unified: A Deep Architecture for simultaneous Eye Fixation Prediction and Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1ca43c217aceabea4cff14bff1d81df2debe058f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294217\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"219bac0d46072291b129748809973618646935e6\",\"title\":\"Saliency Detection in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/219bac0d46072291b129748809973618646935e6\",\"venue\":\"ECCV 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"Vittorio Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"Martial Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"30400079\",\"name\":\"Yair Weiss\"}],\"doi\":\"10.1007/978-3-030-01264-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e47ada58f5b7817acc46240f1090ba51dd0c637\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/5e47ada58f5b7817acc46240f1090ba51dd0c637\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1429655276\",\"name\":\"Avishek Majumder\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"},{\"authorId\":\"1429640900\",\"name\":\"Anirban Chakraborty\"}],\"doi\":\"10.1007/s11042-019-08388-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbcfb8263d4085e4b83fbbe998968eab5510953c\",\"title\":\"PerSeg : segmenting salient objects from bag of single image perturbations\",\"url\":\"https://www.semanticscholar.org/paper/dbcfb8263d4085e4b83fbbe998968eab5510953c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46446912\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Wei Yang\"},{\"authorId\":\"40078088\",\"name\":\"X. Tang\"},{\"authorId\":\"49721997\",\"name\":\"J. Liu\"}],\"doi\":\"10.3390/s18124308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a7bbe5a9eadf158f3a50835650b35ae56ceb297\",\"title\":\"A Fast Learning Method for Accurate and Robust Lane Detection Using Two-Stage Feature Extraction with YOLO v3\",\"url\":\"https://www.semanticscholar.org/paper/8a7bbe5a9eadf158f3a50835650b35ae56ceb297\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1911.10492\",\"authors\":[{\"authorId\":\"145779450\",\"name\":\"Y. Tu\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"47749019\",\"name\":\"W. Zhao\"},{\"authorId\":\"2476347\",\"name\":\"Dawei Cheng\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cb36b1cd622756d1bfc4bedbb05c6dc51bc9bad\",\"title\":\"Image Cropping with Composition and Saliency Aware Aesthetic Score Map\",\"url\":\"https://www.semanticscholar.org/paper/0cb36b1cd622756d1bfc4bedbb05c6dc51bc9bad\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"40588149\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"143621876\",\"name\":\"X. Peng\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"042a825ca52d51b7e4766fd43715e4dcd330b767\",\"title\":\"Aesthetic guided deep regression network for image cropping\",\"url\":\"https://www.semanticscholar.org/paper/042a825ca52d51b7e4766fd43715e4dcd330b767\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"151469503\",\"name\":\"Yifan Zhao\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"}],\"doi\":\"10.1109/MIPR49039.2020.00011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"title\":\"Cross-Domain Visual Attention Model Adaption with One-Shot GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3029535\",\"name\":\"Fumio Nihei\"},{\"authorId\":\"1718158\",\"name\":\"Yukiko I. Nakano\"},{\"authorId\":\"2473784\",\"name\":\"Yutaka Takase\"}],\"doi\":\"10.1145/3136755.3136803\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8f46c001419810a95d73e35ccc8984e0ea8401f\",\"title\":\"Predicting meeting extracts in group discussions using multimodal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c8f46c001419810a95d73e35ccc8984e0ea8401f\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"XU Hai-shuia\"},{\"authorId\":null,\"name\":\"XIA Lin-yueb\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"753dcada306a1be081af8c0f8eb178306a99da8d\",\"title\":\"A Review of Visual Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/753dcada306a1be081af8c0f8eb178306a99da8d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"8189996\",\"name\":\"Jingxian Liu\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TMM.2017.2767784\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"title\":\"Saliency Detection in Face Videos: A Data-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1903.03227\",\"authors\":[{\"authorId\":\"10983632\",\"name\":\"B. Wu\"},{\"authorId\":\"2856639\",\"name\":\"Iretiayo Akinola\"},{\"authorId\":\"2193888\",\"name\":\"P. Allen\"}],\"doi\":\"10.1109/IROS40897.2019.8968263\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bf1667348bb7caf6e82d188a62be39c1f776b32\",\"title\":\"Pixel-Attentive Policy Gradient for Multi-Fingered Grasping in Cluttered Scenes\",\"url\":\"https://www.semanticscholar.org/paper/7bf1667348bb7caf6e82d188a62be39c1f776b32\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47835189\",\"name\":\"Qi Zhang\"},{\"authorId\":\"153239184\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1117/12.2503058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9c4688fb7a80f9f479203d7e3a0eccd2ff2ff0e\",\"title\":\"Dynamic saliency detection via CNN and spatial-temporal fusion\",\"url\":\"https://www.semanticscholar.org/paper/c9c4688fb7a80f9f479203d7e3a0eccd2ff2ff0e\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2018},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"2010.14793\",\"authors\":[{\"authorId\":\"31047940\",\"name\":\"A. Sharma\"},{\"authorId\":\"2756167\",\"name\":\"Naeemullah Khan\"},{\"authorId\":\"2095031\",\"name\":\"G. Sundaramoorthi\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5562b132eaea90701127553ab7353f38cf44951a\",\"title\":\"Class-Agnostic Segmentation Loss and Its Application to Salient Object Detection and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5562b132eaea90701127553ab7353f38cf44951a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2470063\",\"name\":\"Yuzhu Ji\"},{\"authorId\":\"2427559\",\"name\":\"H. Zhang\"},{\"authorId\":\"1750296\",\"name\":\"K. Tseng\"},{\"authorId\":\"144134805\",\"name\":\"T. Chow\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1016/j.neucom.2018.09.081\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91f0e1376667025d230af6d5bb8592ef28a2396d\",\"title\":\"Graph model-based salient object detection using objectness and multiple saliency cues\",\"url\":\"https://www.semanticscholar.org/paper/91f0e1376667025d230af6d5bb8592ef28a2396d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1803.00127\",\"authors\":[{\"authorId\":\"3345547\",\"name\":\"Huai-Jen Liang\"},{\"authorId\":\"9217768\",\"name\":\"N. J. Sanket\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1109/TASE.2019.2900980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52e19729230252b7f77b20a644921949f755aa37\",\"title\":\"SalientDSO: Bringing Attention to Direct Sparse Odometry\",\"url\":\"https://www.semanticscholar.org/paper/52e19729230252b7f77b20a644921949f755aa37\",\"venue\":\"IEEE Transactions on Automation Science and Engineering\",\"year\":2019},{\"arxivId\":\"1804.10361\",\"authors\":[{\"authorId\":\"145856471\",\"name\":\"J. Chang\"},{\"authorId\":\"46868037\",\"name\":\"Ya Zhang\"},{\"authorId\":\"47905788\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1145/3319921.3319932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"020fbc3ad135fbdeee04b3a04404bb665571822e\",\"title\":\"An Element Sensitive Saliency Model with Position Prior Learning for Web Pages\",\"url\":\"https://www.semanticscholar.org/paper/020fbc3ad135fbdeee04b3a04404bb665571822e\",\"venue\":\"ICIAI 2019\",\"year\":2019},{\"arxivId\":\"2010.01220\",\"authors\":[{\"authorId\":\"1986291097\",\"name\":\"Giovanni Bellitto\"},{\"authorId\":\"1985894550\",\"name\":\"Federica Proietto Salanitri\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"50528328\",\"name\":\"F. Rundo\"},{\"authorId\":\"35906202\",\"name\":\"D. Giordano\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36081963c58871adc8706e2cfcbf94872a42c5ae\",\"title\":\"Video Saliency Detection with Domain Adaptation using Hierarchical Gradient Reversal Layers\",\"url\":\"https://www.semanticscholar.org/paper/36081963c58871adc8706e2cfcbf94872a42c5ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.02501\",\"authors\":[{\"authorId\":\"39832600\",\"name\":\"E. Chong\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/cvpr42600.2020.00544\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95bdf80c6d53003374694eea9707a1d20ac93195\",\"title\":\"Detecting Attended Visual Targets in Video\",\"url\":\"https://www.semanticscholar.org/paper/95bdf80c6d53003374694eea9707a1d20ac93195\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2017.160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"241b86d3c71d14b8cc6044a425b047a0724cfdc9\",\"title\":\"Following Gaze in Video\",\"url\":\"https://www.semanticscholar.org/paper/241b86d3c71d14b8cc6044a425b047a0724cfdc9\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120105829\",\"name\":\"D. Konstantinidis\"},{\"authorId\":\"1689047\",\"name\":\"V. Argyriou\"},{\"authorId\":\"1783374\",\"name\":\"T. Stathaki\"},{\"authorId\":\"48603481\",\"name\":\"N. Grammalidis\"}],\"doi\":\"10.1016/j.comnet.2019.107034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68b9be9554d209856431e54acfd9c5b2b844c352\",\"title\":\"A modular CNN-based building detector for remote sensing images\",\"url\":\"https://www.semanticscholar.org/paper/68b9be9554d209856431e54acfd9c5b2b844c352\",\"venue\":\"Comput. Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144272947\",\"name\":\"Chen Xia\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/j.neucom.2018.09.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbeede6ad49a09a6c72031d55454f0fff767ffcb\",\"title\":\"Stereoscopic saliency estimation with background priors based deep reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/bbeede6ad49a09a6c72031d55454f0fff767ffcb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"79439415\",\"name\":\"Haoyu Dong\"},{\"authorId\":\"2560900\",\"name\":\"Shengxi Li\"}],\"doi\":\"10.1109/CVPRW.2017.208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7d81091f909f718425eb428336ff72de5f3ad0e\",\"title\":\"Learning Dynamic GMM for Attention Distribution on Single-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/f7d81091f909f718425eb428336ff72de5f3ad0e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1711.03726\",\"authors\":[{\"authorId\":\"46479926\",\"name\":\"Prakhar Gupta\"},{\"authorId\":\"28823342\",\"name\":\"Shubh Gupta\"},{\"authorId\":\"30039163\",\"name\":\"Ajaykrishnan Jayagopal\"},{\"authorId\":\"143775710\",\"name\":\"S. Pal\"},{\"authorId\":\"2703103\",\"name\":\"R. Sinha\"}],\"doi\":\"10.1109/WACV.2018.00171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"329836fe1afe6d3ee48c901175a0219756dd2927\",\"title\":\"Saliency Prediction for Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/329836fe1afe6d3ee48c901175a0219756dd2927\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099272\",\"name\":\"W. Chen\"},{\"authorId\":\"5489917\",\"name\":\"F. Kou\"},{\"authorId\":\"145678164\",\"name\":\"C. Wen\"},{\"authorId\":\"1737029\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/TCE.2017.014952\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f4a04ecd3ee7bc89e18fb414b93997c1ac85150\",\"title\":\"Automatic synthetic background defocus for a single portrait image\",\"url\":\"https://www.semanticscholar.org/paper/3f4a04ecd3ee7bc89e18fb414b93997c1ac85150\",\"venue\":\"IEEE Transactions on Consumer Electronics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"47842446\",\"name\":\"MingYu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360{\\\\deg} Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1704.00248\",\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\"},{\"authorId\":\"5611651\",\"name\":\"J. Liu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/CVPR.2017.84\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d646c9707686def885557c0aad1fc160b80d5d5\",\"title\":\"A-Lamp: Adaptive Layout-Aware Multi-patch Deep Convolutional Neural Network for Photo Aesthetic Assessment\",\"url\":\"https://www.semanticscholar.org/paper/2d646c9707686def885557c0aad1fc160b80d5d5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29398271\",\"name\":\"Keigo Ishikura\"},{\"authorId\":\"29418459\",\"name\":\"N. Kurita\"},{\"authorId\":\"13113212\",\"name\":\"D. Chandler\"},{\"authorId\":\"2014433\",\"name\":\"G. Ohashi\"}],\"doi\":\"10.1109/TIP.2017.2767288\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"107c6f258986e8574f2924d119518f60b57b019b\",\"title\":\"Saliency Detection Based on Multiscale Extrema of Local Perceptual Color Differences\",\"url\":\"https://www.semanticscholar.org/paper/107c6f258986e8574f2924d119518f60b57b019b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40063957\",\"name\":\"Eric Arazo Sanchez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55761bdf5cbbff5fbede8ee9d0573d1561a9254b\",\"title\":\"The impact of visual saliency prediction in image classification\",\"url\":\"https://www.semanticscholar.org/paper/55761bdf5cbbff5fbede8ee9d0573d1561a9254b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"title\":\"How Drones Look: Crowdsourced Knowledge Transfer for Aerial Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1708.04366\",\"authors\":[{\"authorId\":\"49050949\",\"name\":\"J. Zhang\"},{\"authorId\":\"1681554\",\"name\":\"Yuchao Dai\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"40214723\",\"name\":\"M. He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f0f12104f576a9253d408d484f4e7ec2e21d5f7\",\"title\":\"Deep Edge-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/2f0f12104f576a9253d408d484f4e7ec2e21d5f7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2772489\",\"name\":\"Eghbal G. Mansoori\"},{\"authorId\":\"145105283\",\"name\":\"M. Yazdi\"}],\"doi\":\"10.1016/J.JVCIR.2020.102931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"title\":\"Exploiting object features in deep gaze prediction models\",\"url\":\"https://www.semanticscholar.org/paper/20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1709.09215\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"145899760\",\"name\":\"Sami Alsheikh\"},{\"authorId\":\"7232330\",\"name\":\"Spandan Madan\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"26331328\",\"name\":\"Kimberli Zhong\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"220c5c5ec1fc209beee9d6d2af1531a1de83f5ca\",\"title\":\"Understanding Infographics through Textual and Visual Tag Prediction\",\"url\":\"https://www.semanticscholar.org/paper/220c5c5ec1fc209beee9d6d2af1531a1de83f5ca\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2017.370\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"title\":\"Attentional Push: A Deep Convolutional Network for Augmenting Image Salience with Shared Attention Modeling in Social Scenes\",\"url\":\"https://www.semanticscholar.org/paper/9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"1680223\",\"name\":\"A. Smeaton\"}],\"doi\":\"10.1007/978-3-319-73603-7_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd46626755e1fdd028a442a7dd09b78cec027f51\",\"title\":\"Image Aesthetics and Content in Selecting Memorable Keyframes from Lifelogs\",\"url\":\"https://www.semanticscholar.org/paper/dd46626755e1fdd028a442a7dd09b78cec027f51\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":\"1904.01231\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"23993939\",\"name\":\"Suiyi Ling\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"title\":\"Adversarial Attacks against Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1807.05511\",\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"144528245\",\"name\":\"P. Zheng\"},{\"authorId\":\"51132438\",\"name\":\"Shou-tao Xu\"},{\"authorId\":\"1748808\",\"name\":\"X. Wu\"}],\"doi\":\"10.1109/TNNLS.2018.2876865\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7998468d99ab07bb982294d1c9b53a3bf3934fa6\",\"title\":\"Object Detection With Deep Learning: A Review\",\"url\":\"https://www.semanticscholar.org/paper/7998468d99ab07bb982294d1c9b53a3bf3934fa6\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30777707\",\"name\":\"Fang-Yi Chao\"},{\"authorId\":\"48571144\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1931304\",\"name\":\"W. Hamidouche\"},{\"authorId\":\"144598687\",\"name\":\"O. D\\u00e9forges\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"11be33019f591214c8f79dbcb24a50d8f7fa5c95\",\"title\":\"SALGAN 360 : VISUAL SALIENCY PREDICTION ON 360 DEGREE IMAGES WITH GENERATIVE ADVERSARIAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/11be33019f591214c8f79dbcb24a50d8f7fa5c95\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000900657\",\"name\":\"Yung-Yuan Tseng\"},{\"authorId\":\"35323140\",\"name\":\"Tien-Ruey Hsiang\"}],\"doi\":\"10.1109/MLSP49062.2020.9231937\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f32400b6d0a3b6a0d4af726790fbf20f02efa02\",\"title\":\"A Multi-Patch Aggregated Aesthetic Rating System Based on Eyefixation\",\"url\":\"https://www.semanticscholar.org/paper/7f32400b6d0a3b6a0d4af726790fbf20f02efa02\",\"venue\":\"2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"50085218\",\"name\":\"Xiankai Lu\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"}],\"doi\":\"10.1109/tpami.2020.2966453\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d68898ef2835de010154711291d7d457b2ac6c18\",\"title\":\"Paying Attention to Video Object Pattern Understanding.\",\"url\":\"https://www.semanticscholar.org/paper/d68898ef2835de010154711291d7d457b2ac6c18\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586319\",\"name\":\"A. Nguyen\"},{\"authorId\":\"2656592\",\"name\":\"Zhisheng Yan\"},{\"authorId\":\"1688353\",\"name\":\"K. Nahrstedt\"}],\"doi\":\"10.1145/3240508.3240669\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"79f1bd70cc474b02bafd5c89063aff204f43959c\",\"title\":\"Your Attention is Unique: Detecting 360-Degree Video Saliency in Head-Mounted Display for Head Movement Prediction\",\"url\":\"https://www.semanticscholar.org/paper/79f1bd70cc474b02bafd5c89063aff204f43959c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2007.13839\",\"authors\":[{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ba67b0734477ff392367f52542ad2dab179da83\",\"title\":\"Saliency Prediction with External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/4ba67b0734477ff392367f52542ad2dab179da83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.07480\",\"authors\":[{\"authorId\":\"50251712\",\"name\":\"Ziqi Zhou\"},{\"authorId\":\"40514580\",\"name\":\"Z. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"47673404\",\"name\":\"S. Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1016/j.patcog.2020.107275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7de478275fdc5e154f6d904b910e8d291033edd\",\"title\":\"Global and Local Sensitivity Guided Key Salient Object Re-augmentation for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7de478275fdc5e154f6d904b910e8d291033edd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"153448727\",\"name\":\"M. Shehata\"},{\"authorId\":\"2810321\",\"name\":\"P. Mcguire\"}],\"doi\":\"10.3390/INFO10080257\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"816094379592bb9faeebbaeea4275340c731fa82\",\"title\":\"Visual Saliency Prediction Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/816094379592bb9faeebbaeea4275340c731fa82\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2019.2905607\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"title\":\"Inferring Salient Objects from Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1810.10974\",\"authors\":[{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"2912641\",\"name\":\"I. Kavasidis\"},{\"authorId\":\"144027622\",\"name\":\"D. Giordano\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/tpami.2020.2995909\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0232f39cf09a47982c24e311a7424f466f964b22\",\"title\":\"Decoding Brain Representations by Multimodal Learning of Neural Activity and Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/0232f39cf09a47982c24e311a7424f466f964b22\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9379498\",\"name\":\"F. Sun\"},{\"authorId\":\"145742543\",\"name\":\"W. Li\"}],\"doi\":\"10.1117/1.JEI.27.4.043014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50772bcae752337be1f6990297bf10c436d5926\",\"title\":\"Saliency detection based on aggregated Wasserstein distance\",\"url\":\"https://www.semanticscholar.org/paper/d50772bcae752337be1f6990297bf10c436d5926\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740586345\",\"name\":\"Naoyuki Awano\"},{\"authorId\":\"1740584291\",\"name\":\"Y. Hayashi\"}],\"doi\":\"10.1007/s41095-020-0169-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"431dddd3de684ac0d208f46dceef3fe206444e1d\",\"title\":\"Psychological potential field and human eye fixation on binary line-drawing images: A comparative experimental study\",\"url\":\"https://www.semanticscholar.org/paper/431dddd3de684ac0d208f46dceef3fe206444e1d\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":\"1801.05787\",\"authors\":[{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"46400982\",\"name\":\"I. Korshunova\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"title\":\"Faster gaze prediction with dense networks and Fisher pruning\",\"url\":\"https://www.semanticscholar.org/paper/d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144205296\",\"name\":\"W. Yang\"},{\"authorId\":\"38278958\",\"name\":\"Xiaomei Zhang\"},{\"authorId\":\"144072492\",\"name\":\"Q. Lei\"},{\"authorId\":\"1736816828\",\"name\":\"Dengye Shen\"},{\"authorId\":\"48596959\",\"name\":\"Ping Xiao\"},{\"authorId\":\"48356288\",\"name\":\"Y. Huang\"}],\"doi\":\"10.3390/s20113115\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5252664b5d701c9bea7c300ac84b2e7333000724\",\"title\":\"Lane Position Detection Based on Long Short-Term Memory (LSTM)\",\"url\":\"https://www.semanticscholar.org/paper/5252664b5d701c9bea7c300ac84b2e7333000724\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48551624\",\"name\":\"Z. Wu\"},{\"authorId\":\"145235481\",\"name\":\"Li Su\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2018.2870954\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"title\":\"Learning Coupled Convolutional Networks Fusion for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-54407-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa804644b886535440db045117a1375b47536c76\",\"title\":\"Bottom-Up Fixation Prediction Using Unsupervised Hierarchical Models\",\"url\":\"https://www.semanticscholar.org/paper/aa804644b886535440db045117a1375b47536c76\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372798\",\"name\":\"Fei Zhao\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"47095772\",\"name\":\"Y. Wu\"},{\"authorId\":\"123469433\",\"name\":\"M. Tang\"}],\"doi\":\"10.1109/TCSVT.2018.2856540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a85cceeded560c54b1d4b03df53c80aa93a562d5\",\"title\":\"Adversarial Deep Tracking\",\"url\":\"https://www.semanticscholar.org/paper/a85cceeded560c54b1d4b03df53c80aa93a562d5\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/TPAMI.2018.2840724\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"title\":\"A Deep Network Solution for Attention and Aesthetics Aware Photo Cropping\",\"url\":\"https://www.semanticscholar.org/paper/55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150177956\",\"name\":\"Kohei Sendo\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.23919/MVA.2019.8757971\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6992ae8a0e3ae00e038936c43cc32ba377df17c\",\"title\":\"Heatmapping of People Involved in Group Activities\",\"url\":\"https://www.semanticscholar.org/paper/b6992ae8a0e3ae00e038936c43cc32ba377df17c\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47ce131f8904027f18eaf8f55fccbcedef351d11\",\"title\":\"The Time Dimension of Visual Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/47ce131f8904027f18eaf8f55fccbcedef351d11\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1905.11522\",\"authors\":[{\"authorId\":\"3210710\",\"name\":\"Anuj Pahuja\"},{\"authorId\":\"50393486\",\"name\":\"Avishek Majumder\"},{\"authorId\":\"37287044\",\"name\":\"A. Chakraborty\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23da436f3bd41c372ce7548d6295c3bb1473ced6\",\"title\":\"Enhancing Salient Object Segmentation Through Attention\",\"url\":\"https://www.semanticscholar.org/paper/23da436f3bd41c372ce7548d6295c3bb1473ced6\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1806.10359\",\"authors\":[{\"authorId\":\"9275594\",\"name\":\"Aymen Azaza\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1766272\",\"name\":\"A. Douik\"},{\"authorId\":\"37077230\",\"name\":\"Marc Masana\"}],\"doi\":\"10.1016/j.cviu.2018.06.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b43745fe3e9a999e13fb9ecab01d28f33ae4973\",\"title\":\"Context Proposals for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/8b43745fe3e9a999e13fb9ecab01d28f33ae4973\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1712219465\",\"name\":\"PIERRE-ADRIEN Fons\"}],\"doi\":\"10.1145/3379156.3391362\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72ba40459e6ca39e30af999db2bb2668372b6e2\",\"title\":\"Predicting image influence on visual saliency distribution: the focal and ambient dichotomy\",\"url\":\"https://www.semanticscholar.org/paper/c72ba40459e6ca39e30af999db2bb2668372b6e2\",\"venue\":\"ETRA Short Papers\",\"year\":2020},{\"arxivId\":\"1904.03571\",\"authors\":[{\"authorId\":\"144545126\",\"name\":\"S. Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TMM.2019.2947352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"023b11c04e5ea605fe999b015cbf62502cab068b\",\"title\":\"A Dilated Inception Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/023b11c04e5ea605fe999b015cbf62502cab068b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1910.14260\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"46756438\",\"name\":\"Chen Yu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"title\":\"A Self Validation Network for Object-Level Human Attention Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217518\",\"name\":\"Q. Zhou\"},{\"authorId\":\"48265412\",\"name\":\"J. Cheng\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"2576377\",\"name\":\"Yawen Fan\"},{\"authorId\":\"2819904\",\"name\":\"Suofei Zhang\"},{\"authorId\":\"34885692\",\"name\":\"X. Wu\"},{\"authorId\":\"143918844\",\"name\":\"Baoyu Zheng\"},{\"authorId\":\"2147977\",\"name\":\"W. Ou\"},{\"authorId\":\"1686678\",\"name\":\"L. Latecki\"}],\"doi\":\"10.1007/s11042-018-6770-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64be44cb454246afc8323d239e7c4539f6df326b\",\"title\":\"Learning adaptive contrast combinations for visual saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/64be44cb454246afc8323d239e7c4539f6df326b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783507\",\"name\":\"Anni Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1016/j.neucom.2020.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"title\":\"Multi-attention guided feature fusion network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15713742\",\"name\":\"M. B. Zerihun\"},{\"authorId\":\"2071095\",\"name\":\"F. Pucci\"},{\"authorId\":\"1904835\",\"name\":\"A. Schug\"}],\"doi\":\"10.1101/2020.07.30.229484\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a593c8b484e3e3abe34577b732a5ef31dc8c029\",\"title\":\"CoCoNet: Boosting RNA contact prediction by convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9a593c8b484e3e3abe34577b732a5ef31dc8c029\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9435406\",\"name\":\"Huanzhao Chen\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"145689285\",\"name\":\"Guoliang Liu\"}],\"doi\":\"10.1007/S11633-018-1139-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8eaceae1c2a9dbe00b9b7f72a6ea362b1279c70\",\"title\":\"A Selective Attention Guided Initiative Semantic Cognition Algorithm for Service Robot\",\"url\":\"https://www.semanticscholar.org/paper/c8eaceae1c2a9dbe00b9b7f72a6ea362b1279c70\",\"venue\":\"Int. J. Autom. Comput.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37503295\",\"name\":\"J. Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"102937546\",\"name\":\"Weimin Wu\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"17668082\",\"name\":\"Baiyan Zhang\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802611\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"title\":\"Saliency Detection via Topological Feature Modulated Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930674\",\"name\":\"Kelwin Fernandes\"},{\"authorId\":\"3698192\",\"name\":\"Jaime S. Cardoso\"},{\"authorId\":\"4468431\",\"name\":\"B. S. Astrup\"}],\"doi\":\"10.1007/978-3-319-58838-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b11032a8b4879c9b52c27325cee8973872796f3\",\"title\":\"Automated Detection and Categorization of Genital Injuries Using Digital Colposcopy\",\"url\":\"https://www.semanticscholar.org/paper/7b11032a8b4879c9b52c27325cee8973872796f3\",\"venue\":\"IbPRIA\",\"year\":2017},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90357138\",\"name\":\"Marta Coll Pol\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be0947fa430a3bf16436d20239550c39d1425d08\",\"title\":\"The importance of time in visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/be0947fa430a3bf16436d20239550c39d1425d08\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1803.05753\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ce33cd6c192f3226d52e59f5f26b2091727780f\",\"title\":\"What Catches the Eye? Visualizing and Understanding Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/4ce33cd6c192f3226d52e59f5f26b2091727780f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1456147593\",\"name\":\"Bernhard Anzengruber-Tanase\"},{\"authorId\":\"1745790\",\"name\":\"A. Ferscha\"},{\"authorId\":\"121230910\",\"name\":\"Martin Schobesberger\"}],\"doi\":\"10.1109/ACII.2019.8925517\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4083801f393b50497b4671d4f77273d230a9118\",\"title\":\"Attention/Distraction Estimation for Surgeons during Laparoscopic Cholecystectomies\",\"url\":\"https://www.semanticscholar.org/paper/c4083801f393b50497b4671d4f77273d230a9118\",\"venue\":\"2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"144785138\",\"name\":\"P. Li\"},{\"authorId\":\"145312326\",\"name\":\"Y. Han\"},{\"authorId\":\"145233508\",\"name\":\"Lei Wu\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"9315669\",\"name\":\"Weimin Wu\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e6b579a40169e2158858f75e36b1be54969cf4\",\"title\":\"Saliency prediction by Mahalanobis distance of topological feature on deep color components\",\"url\":\"https://www.semanticscholar.org/paper/d7e6b579a40169e2158858f75e36b1be54969cf4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50543166\",\"name\":\"Anne-Flore Perrin\"},{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1007/978-3-030-29888-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"title\":\"How Well Current Saliency Prediction Models Perform on UAVs Videos?\",\"url\":\"https://www.semanticscholar.org/paper/3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"venue\":\"CAIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1965894899\",\"name\":\"Kelam Goutam\"},{\"authorId\":\"144021807\",\"name\":\"S. Balasubramanian\"}],\"doi\":\"10.1007/978-981-15-8697-2_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1e4c26de91726ab92a6c3f5b6db68c95c220433\",\"title\":\"iSalGAN - An Improvised Saliency GAN\",\"url\":\"https://www.semanticscholar.org/paper/e1e4c26de91726ab92a6c3f5b6db68c95c220433\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.03508\",\"authors\":[{\"authorId\":\"47129852\",\"name\":\"Shengjie Liu\"},{\"authorId\":\"1807633840\",\"name\":\"Qian Shi\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/tgrs.2020.3018879\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bee02cb6e12f6f6ecc8d46e646352bf55598dd20\",\"title\":\"Few-Shot Hyperspectral Image Classification With Unknown Classes Using Multitask Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/bee02cb6e12f6f6ecc8d46e646352bf55598dd20\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07469\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"48568655\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fd298c1c4061fd2e9bace16241538e123fd3ba2\",\"title\":\"Unsupervised Self-training Algorithm Based on Deep Learning for Optical Aerial Images Change Detection\",\"url\":\"https://www.semanticscholar.org/paper/6fd298c1c4061fd2e9bace16241538e123fd3ba2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2705801\",\"name\":\"Si Liu\"},{\"authorId\":\"145314998\",\"name\":\"Z. Wei\"},{\"authorId\":\"143725619\",\"name\":\"Yao Sun\"},{\"authorId\":\"2456308\",\"name\":\"Xinyu Ou\"},{\"authorId\":\"2090292\",\"name\":\"Junyu Lin\"},{\"authorId\":\"49166933\",\"name\":\"B. Liu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2018.2836313\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71659a32d6be503572e27c1c32755c91ae370271\",\"title\":\"Composing Semantic Collage for Image Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/71659a32d6be503572e27c1c32755c91ae370271\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2426112\",\"name\":\"N. Kim\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fefcfdfe517e2e670bf345bc2a4fc2c52a9db35\",\"title\":\"BubbleView: An Interface for Crowdsourcing Image Importance Maps and Tracking Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6fefcfdfe517e2e670bf345bc2a4fc2c52a9db35\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"47469967\",\"name\":\"Jianwu Fang\"},{\"authorId\":\"48754122\",\"name\":\"P. Zhang\"}],\"doi\":\"10.1007/S11633-018-1126-Y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"171b81fda05c90384246a28bb0831c9e6b0ce10b\",\"title\":\"A Survey of Scene Understanding by Event Reasoning in Autonomous Driving\",\"url\":\"https://www.semanticscholar.org/paper/171b81fda05c90384246a28bb0831c9e6b0ce10b\",\"venue\":\"Int. J. Autom. Comput.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73919690\",\"name\":\"Nidhinandana Salian\"}],\"doi\":\"10.1007/978-981-13-2907-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2a0048e23a2e88768d155eac351443573cd4f5d\",\"title\":\"Visual Attention and Memory Augmented Activity Recognition and Behavioral Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b2a0048e23a2e88768d155eac351443573cd4f5d\",\"venue\":\"ATIS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.24963/ijcai.2017/543\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aca8c4a62ed6e590889f1e859d7bc79311fa6f4d\",\"title\":\"Beyond Universal Saliency: Personalized Saliency Prediction with Multi-task CNN\",\"url\":\"https://www.semanticscholar.org/paper/aca8c4a62ed6e590889f1e859d7bc79311fa6f4d\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"46962451\",\"name\":\"Chuan Yang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TPAMI.2016.2609426\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5733d1b65ded6ebf2c35802966e637218b529aaa\",\"title\":\"Ranking Saliency\",\"url\":\"https://www.semanticscholar.org/paper/5733d1b65ded6ebf2c35802966e637218b529aaa\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610290\",\"name\":\"Nan Mu\"},{\"authorId\":\"145813732\",\"name\":\"X. Xu\"},{\"authorId\":\"35288217\",\"name\":\"Xiaolong Zhang\"},{\"authorId\":\"46701933\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1007/s00521-017-2870-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5edaf0974557ab89c69ed53965fac5bf8eca0b9\",\"title\":\"Salient object detection using a covariance-based CNN model in low-contrast images\",\"url\":\"https://www.semanticscholar.org/paper/d5edaf0974557ab89c69ed53965fac5bf8eca0b9\",\"venue\":\"Neural Computing and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"37006600\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5bea0fddd9acb316179b895bb1d5f0e72a5c402\",\"title\":\"An Iterative and Cooperative Top-Down and Bottom-Up Inference Network for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/e5bea0fddd9acb316179b895bb1d5f0e72a5c402\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73299296\",\"name\":\"Cheng Deng\"},{\"authorId\":\"40393034\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1109/TMM.2019.2934833\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bed3865dba8bb3edf979a3c277c837c810348343\",\"title\":\"Saliency Detection via a Multiple Self-Weighted Graph-Based Manifold Ranking\",\"url\":\"https://www.semanticscholar.org/paper/bed3865dba8bb3edf979a3c277c837c810348343\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74308116\",\"name\":\"S. Nandagopalan\"},{\"authorId\":\"152934078\",\"name\":\"P. Kesava Kumar\"}],\"doi\":\"10.1007/978-3-030-00979-3_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d36bf1aa49c5a937da3134798140e5633cee4a76\",\"title\":\"Deep Convolutional Network Based Saliency Prediction for Retrieval of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/d36bf1aa49c5a937da3134798140e5633cee4a76\",\"venue\":\"ICIC 2018\",\"year\":2018},{\"arxivId\":\"1810.04456\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"be0d5d28fafe262e509a04b7fc7673d63f563747\",\"title\":\"Invariance Analysis of Saliency Models versus Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/be0d5d28fafe262e509a04b7fc7673d63f563747\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1016/j.patcog.2020.107234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"947b42503e78f29fd64ab864a76721dae8cad26e\",\"title\":\"DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/947b42503e78f29fd64ab864a76721dae8cad26e\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-020-01371-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"title\":\"DeepVS2.0: A Saliency-Structured Deep Learning Method for Predicting Dynamic Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49048391\",\"name\":\"Abraham Montoya Obeso\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1381345955\",\"name\":\"M. S. Garc\\u00eda-V\\u00e1zquez\"},{\"authorId\":\"1381345944\",\"name\":\"A. A. Ram\\u00edrez-Acosta\"}],\"doi\":\"10.1109/CBMI.2019.8877380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"868a924473153de5780370d2214be89395f702f3\",\"title\":\"Dropping Activations in Convolutional Neural Networks with Visual Attention Maps\",\"url\":\"https://www.semanticscholar.org/paper/868a924473153de5780370d2214be89395f702f3\",\"venue\":\"2019 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119924024\",\"name\":\"Yinan Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"}],\"doi\":\"10.1109/ACCESS.2017.2753830\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c90427085909029afd2af01d1967e80b78e01b88\",\"title\":\"Gaze-Assisted Multi-Stream Deep Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c90427085909029afd2af01d1967e80b78e01b88\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865728407\",\"name\":\"Avishek Siris\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"1888880\",\"name\":\"G. Tam\"},{\"authorId\":\"1388037008\",\"name\":\"Xianghua Xie\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/cvpr42600.2020.01215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06348f0f10a9599fe4c9b18fb7a2a972c49ba806\",\"title\":\"Inferring Attention Shift Ranks of Objects for Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/06348f0f10a9599fe4c9b18fb7a2a972c49ba806\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.10795\",\"authors\":[{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CBMI.2018.8516500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e303b9f18cf5096ed04d6d902321fa77e49dd74\",\"title\":\"Saliency Weighted Convolutional Features for Instance Search\",\"url\":\"https://www.semanticscholar.org/paper/9e303b9f18cf5096ed04d6d902321fa77e49dd74\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"33610144\",\"name\":\"X. Chen\"},{\"authorId\":\"28964350\",\"name\":\"Anlin Zheng\"},{\"authorId\":\"48380141\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/CVPR.2017.468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6dfcbac47bb9b100c8fb93b1c5c5b86f1241083\",\"title\":\"What is and What is Not a Salient Object? Learning Salient Object Detector by Ensembling Linear Exemplar Regressors\",\"url\":\"https://www.semanticscholar.org/paper/c6dfcbac47bb9b100c8fb93b1c5c5b86f1241083\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3029535\",\"name\":\"Fumio Nihei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c42d8a984537396b3fbc8a0cf2ec3e4639b6c24a\",\"title\":\"Predicting Important Utterance based on Fusing Verbal and Nonverbal Information\",\"url\":\"https://www.semanticscholar.org/paper/c42d8a984537396b3fbc8a0cf2ec3e4639b6c24a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47543815\",\"name\":\"Eunsoo Park\"},{\"authorId\":\"2932704\",\"name\":\"S. Kim\"},{\"authorId\":\"2267529\",\"name\":\"E. Ryu\"}],\"doi\":\"10.5909/JBE.2020.25.3.374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b238a27ab62caaaaf80dd685c0244a844978a49\",\"title\":\"Preprocessing Technique for Improving Action Recognition Performance in ERP Video with Multiple Objects\",\"url\":\"https://www.semanticscholar.org/paper/7b238a27ab62caaaaf80dd685c0244a844978a49\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1612.04335\",\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"title\":\"How do people explore virtual environments\",\"url\":\"https://www.semanticscholar.org/paper/c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050949\",\"name\":\"J. Zhang\"},{\"authorId\":\"1681554\",\"name\":\"Yuchao Dai\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2017.8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63660c50e2669a5115c2379e622549d8ed79be00\",\"title\":\"Deep Salient Object Detection by Integrating Multi-level Cues\",\"url\":\"https://www.semanticscholar.org/paper/63660c50e2669a5115c2379e622549d8ed79be00\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47336681\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a6bba2e81d5fb3c0fd0e6b757cf50ba7bf8e924\",\"title\":\"Compare and Contrast : Learning Prominent Differences in Relative Attributes by\",\"url\":\"https://www.semanticscholar.org/paper/2a6bba2e81d5fb3c0fd0e6b757cf50ba7bf8e924\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70123445\",\"name\":\"Duzhen Zhang\"},{\"authorId\":\"143814710\",\"name\":\"Z. Ali\"}],\"doi\":\"10.1142/S1469026819500093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dd268d78209640485160518b12f5f9a7f51f60f\",\"title\":\"Top-Down Saliency Detection Based on Deep-Learned Features\",\"url\":\"https://www.semanticscholar.org/paper/5dd268d78209640485160518b12f5f9a7f51f60f\",\"venue\":\"Int. J. Comput. Intell. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15149911\",\"name\":\"R. Huang\"},{\"authorId\":\"143612281\",\"name\":\"W. Feng\"},{\"authorId\":\"2798471\",\"name\":\"Zezheng Wang\"},{\"authorId\":\"145606372\",\"name\":\"Yan Xing\"},{\"authorId\":\"40596220\",\"name\":\"Y. Zou\"}],\"doi\":\"10.1016/j.neucom.2019.09.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2590f58619a03b435610f72c0a47acdd302a2d17\",\"title\":\"Exemplar-based image saliency and co-saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/2590f58619a03b435610f72c0a47acdd302a2d17\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2008.01874\",\"authors\":[{\"authorId\":\"46675382\",\"name\":\"Yutong Sun\"},{\"authorId\":\"3458098\",\"name\":\"M. Prabhushankar\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1109/ICIP40778.2020.9191186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6e9dcec9c8447983af63f7d52378456f06731d5\",\"title\":\"Implicit Saliency In Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e6e9dcec9c8447983af63f7d52378456f06731d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1610.06449\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1016/j.neucom.2017.03.018\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9995d891a5d6737eadd7b386de23fbd7aef77903\",\"title\":\"Exploiting inter-image similarity and ensemble of extreme learners for fixation prediction using deep features\",\"url\":\"https://www.semanticscholar.org/paper/9995d891a5d6737eadd7b386de23fbd7aef77903\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"2824995\",\"name\":\"Lixin Liao\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"27081045\",\"name\":\"Qinjie Zheng\"},{\"authorId\":\"14684673\",\"name\":\"Fei Yang\"},{\"authorId\":\"145093507\",\"name\":\"Yao Zhao\"}],\"doi\":\"10.1109/TIP.2019.2913513\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f31c3f8c8744e61e9142080787841d0e8465898d\",\"title\":\"Saliency Inside: Learning Attentive CNNs for Content-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f31c3f8c8744e61e9142080787841d0e8465898d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"34854725\",\"name\":\"F. Marqu\\u00e9s\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"572fb7b3df053ea644415218fbcd075228bafb14\",\"title\":\"Object Retrieval with Deep Convolutional Features\",\"url\":\"https://www.semanticscholar.org/paper/572fb7b3df053ea644415218fbcd075228bafb14\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2018.00783\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a2fae46c67189fb2aea33f12091772e635361f1\",\"title\":\"Going from Image to Video Saliency: Augmenting Image Salience with Dynamic Attentional Push\",\"url\":\"https://www.semanticscholar.org/paper/9a2fae46c67189fb2aea33f12091772e635361f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"9284635\",\"name\":\"Hongmei Song\"},{\"authorId\":\"152836879\",\"name\":\"Shuyang Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/CVPR.2019.00318\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f53761ea6276df40089753a4e008d1283f28e768\",\"title\":\"Learning Unsupervised Video Object Segmentation Through Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f53761ea6276df40089753a4e008d1283f28e768\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Prachi Moghe\"},{\"authorId\":\"2005790\",\"name\":\"Prachi Mukherji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e069119ecb67c07f936c11532658e107e2aee31\",\"title\":\"Efficient Algorithm for Object Detection using Active Contours\",\"url\":\"https://www.semanticscholar.org/paper/4e069119ecb67c07f936c11532658e107e2aee31\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"title\":\"Attentive Models in Vision 3 Input Image Human Fixation Map Loss Function Final Convolutional Layers Learned Prior Low , Medium and High Level Features Predicted Saliency Map Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.06803\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"134585167\",\"name\":\"P. le Callet\"}],\"doi\":\"10.1109/TIP.2019.2945857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"183802f07521d16b78d27c5229002d49a789b298\",\"title\":\"How is Gaze Influenced by Image Transformations? Dataset and Model\",\"url\":\"https://www.semanticscholar.org/paper/183802f07521d16b78d27c5229002d49a789b298\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2019.00248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9363966\",\"name\":\"Tengda Guo\"},{\"authorId\":\"1856580538\",\"name\":\"Xin Xu\"}],\"doi\":\"10.1007/s00371-020-01964-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32664d12f35543473a263c5bb68c6f4c5848be09\",\"title\":\"Salient object detection from low contrast images based on local contrast enhancing and non-local feature learning\",\"url\":\"https://www.semanticscholar.org/paper/32664d12f35543473a263c5bb68c6f4c5848be09\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"2035969\",\"name\":\"S. Pini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-73165-0_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a14e113d5e31defec38f2233d0783d8c97b4a62a\",\"title\":\"Automatic Image Cropping and Selection Using Saliency: An Application to Historical Manuscripts\",\"url\":\"https://www.semanticscholar.org/paper/a14e113d5e31defec38f2233d0783d8c97b4a62a\",\"venue\":\"IRCDL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67016734\",\"name\":\"S. Zhu\"},{\"authorId\":\"39772032\",\"name\":\"C. Liu\"},{\"authorId\":\"1765822\",\"name\":\"Ziyao Xu\"}],\"doi\":\"10.1109/TCSVT.2019.2911396\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47abf02a79bb70cc9fd4ac14b6c9dc7b5063978b\",\"title\":\"High-Definition Video Compression System Based on Perception Guidance of Salient Information of a Convolutional Neural Network and HEVC Compression Domain\",\"url\":\"https://www.semanticscholar.org/paper/47abf02a79bb70cc9fd4ac14b6c9dc7b5063978b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1708.02660\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"1411051436\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"145899760\",\"name\":\"Sami Alsheikh\"},{\"authorId\":\"7232330\",\"name\":\"Spandan Madan\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"}],\"doi\":\"10.1145/3126594.3126653\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"title\":\"Learning Visual Importance for Graphic Designs and Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"venue\":\"UIST\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2012.11863\",\"authors\":[{\"authorId\":\"1739174065\",\"name\":\"Ke Wang\"},{\"authorId\":\"1400359889\",\"name\":\"Sai Ma\"},{\"authorId\":\"1740146246\",\"name\":\"Junlan Chen\"},{\"authorId\":\"49301701\",\"name\":\"Jianbo Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"title\":\"Salient Bundle Adjustment for Visual SLAM\",\"url\":\"https://www.semanticscholar.org/paper/4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.10004\",\"authors\":[{\"authorId\":\"21319564\",\"name\":\"J. Li\"},{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"title\":\"Visual Attention on the Sun: What Do Existing Models Actually Predict?\",\"url\":\"https://www.semanticscholar.org/paper/6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700619\",\"name\":\"Jing Liu\"},{\"authorId\":\"3493187\",\"name\":\"Jincheng Lv\"},{\"authorId\":\"2026992233\",\"name\":\"Min Yuan\"},{\"authorId\":\"50560979\",\"name\":\"J. Zhang\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/LSP.2020.3035065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"title\":\"ABSNet: Aesthetics-Based Saliency Network Using Multi-Task Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da951412f75aac6cffb310656770552548a11798\",\"title\":\"SalGAN : Visual Saliency Prediction with Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/da951412f75aac6cffb310656770552548a11798\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1811.03736\",\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"title\":\"Semantic and Contrast-Aware Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"315511e474b59b6469f5697e8b4e4abd14663b66\",\"title\":\"Human attention simulation on nature scenes in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/315511e474b59b6469f5697e8b4e4abd14663b66\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd369da5f97e9d3ca6863030ec10a689754bcbb6\",\"title\":\"LINARDOS ET AL: TEMPORAL RECURRENCES FOR VIDEO SALIENCY PREDICTION 1 Temporal Recurrences for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd369da5f97e9d3ca6863030ec10a689754bcbb6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145880437\",\"name\":\"Xin Xu\"},{\"authorId\":\"51468382\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3a9340157390f964c508444736638ef05a35633\",\"title\":\"Extended Non-local Feature for Visual Saliency Detection in Low Contrast Images\",\"url\":\"https://www.semanticscholar.org/paper/f3a9340157390f964c508444736638ef05a35633\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3428118\",\"name\":\"Suzi Kim\"},{\"authorId\":\"2280247\",\"name\":\"Sunghee Choi\"}],\"doi\":\"10.1145/3372278.3390685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"813867c23f89a8798d623417c32403dfd73ddb20\",\"title\":\"Automatic Color Scheme Extraction from Movies\",\"url\":\"https://www.semanticscholar.org/paper/813867c23f89a8798d623417c32403dfd73ddb20\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39249670\",\"name\":\"D. Zhu\"},{\"authorId\":\"145378980\",\"name\":\"Ye Luo\"},{\"authorId\":\"145978454\",\"name\":\"L. Dai\"},{\"authorId\":\"47403551\",\"name\":\"Xuan Shao\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"49301770\",\"name\":\"Jianwei Lu\"}],\"doi\":\"10.1007/978-3-319-70090-8_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ab70de1c718c27f430f5be6784f0396a4383fc9\",\"title\":\"Deep Salient Object Detection via Hierarchical Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/0ab70de1c718c27f430f5be6784f0396a4383fc9\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/CVPR.2019.01045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27876489\",\"name\":\"S. Basavaraju\"},{\"authorId\":\"1784609\",\"name\":\"A. Sur\"}],\"doi\":\"10.1007/s11042-019-08202-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7397bac98f34ef118e99e291a0da673665d2ffc6\",\"title\":\"Multiple instance learning based deep CNN for image memorability prediction\",\"url\":\"https://www.semanticscholar.org/paper/7397bac98f34ef118e99e291a0da673665d2ffc6\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1702.00372\",\"authors\":[{\"authorId\":\"143635238\",\"name\":\"Samuel F. Dodge\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/TIP.2018.2834826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fc290cec880b22ca61544eca84157821ea7b0c6\",\"title\":\"Visual Saliency Prediction Using a Mixture of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fc290cec880b22ca61544eca84157821ea7b0c6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"title\":\"Computational modeling for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.03791\",\"authors\":[{\"authorId\":\"2763037\",\"name\":\"Lingjiao Chen\"},{\"authorId\":\"3148801\",\"name\":\"H. Wang\"},{\"authorId\":\"26128283\",\"name\":\"Jinman Zhao\"},{\"authorId\":\"1740595\",\"name\":\"Dimitris Papailiopoulos\"},{\"authorId\":\"1713920\",\"name\":\"Paraschos Koutris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a138415032b1ee0cb2fa2763cba1f3f9e2d9bbe7\",\"title\":\"The Effect of Network Width on the Performance of Large-batch Training\",\"url\":\"https://www.semanticscholar.org/paper/a138415032b1ee0cb2fa2763cba1f3f9e2d9bbe7\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10604706\",\"name\":\"Ali Selman Aydin\"},{\"authorId\":\"113653487\",\"name\":\"Shirin Feiz\"},{\"authorId\":\"145070406\",\"name\":\"V. Ashok\"},{\"authorId\":\"1519965383\",\"name\":\"I. Ramakrishnan\"}],\"doi\":\"10.1145/3377325.3377494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b581597fe0576ebc88a0aade41cbf1366a33ecb8\",\"title\":\"Towards making videos accessible for low vision screen magnifier users\",\"url\":\"https://www.semanticscholar.org/paper/b581597fe0576ebc88a0aade41cbf1366a33ecb8\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48955531\",\"name\":\"Noman Khan\"},{\"authorId\":\"1516175879\",\"name\":\"Amin Ullah\"},{\"authorId\":\"29438845\",\"name\":\"I. Haq\"},{\"authorId\":\"3375904\",\"name\":\"V. Menon\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1007/S11554-020-01020-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d84a73d4d932989bc5a9464a19b7562ad38af12\",\"title\":\"SD-Net: Understanding overcrowded scenes in real-time via an efficient dilated convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/6d84a73d4d932989bc5a9464a19b7562ad38af12\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"48268905\",\"name\":\"W. J. MacInnes\"}],\"doi\":\"10.3390/vision3040056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"title\":\"Salience Models: A Computational Cognitive Neuroscience Review\",\"url\":\"https://www.semanticscholar.org/paper/f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"2863871\",\"name\":\"Xinyu Yan\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1145/3343031.3350882\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"775373c4992f616d4dc55a1eb4e2602aed48f6de\",\"title\":\"Ranking Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/775373c4992f616d4dc55a1eb4e2602aed48f6de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2733405\",\"name\":\"H. Li\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/J.JVCIR.2019.102611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"title\":\"A multiscale dilated dense convolutional network for saliency prediction with instance-level attention competition\",\"url\":\"https://www.semanticscholar.org/paper/6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"47043085\",\"name\":\"Katherine A J Daniels\"},{\"authorId\":\"3988217\",\"name\":\"J. Burn\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":\"10.1109/TCYB.2017.2734946\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"35f72d85384f4e5841587b37da2c309d678149f5\",\"title\":\"Fixation Prediction and Visual Priority Maps for Biped Locomotion\",\"url\":\"https://www.semanticscholar.org/paper/35f72d85384f4e5841587b37da2c309d678149f5\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46319694\",\"name\":\"F. Yang\"},{\"authorId\":\"46275685\",\"name\":\"J. Li\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"27081045\",\"name\":\"Qinjie Zheng\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"}],\"doi\":\"10.1145/3123266.3123396\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce636ad263167b5612c4a2a85376855f39de9eb2\",\"title\":\"Two-stream Attentive CNNs for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/ce636ad263167b5612c4a2a85376855f39de9eb2\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1016/j.patcog.2017.07.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"968695df20f365ad05733f6f0a7d421d60f996df\",\"title\":\"Gaze latent support vector machine for image classification\",\"url\":\"https://www.semanticscholar.org/paper/968695df20f365ad05733f6f0a7d421d60f996df\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1904.07080\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"Mai Xu\"},{\"authorId\":\"40248914\",\"name\":\"Li Yang\"},{\"authorId\":\"144978572\",\"name\":\"Xiaoming Tao\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"1754571\",\"name\":\"Zulin Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"title\":\"Saliency Prediction on Omnidirectional Images with Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"120738218\",\"name\":\"Hanqin Huang\"},{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"}],\"doi\":\"10.1109/TIP.2019.2916766\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43ab863771fc376aed88fed89ac5c5370903f0bb\",\"title\":\"Visual Attention Prediction for Stereoscopic Video by Multi-Module Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/43ab863771fc376aed88fed89ac5c5370903f0bb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1812.01802\",\"authors\":[{\"authorId\":\"143775710\",\"name\":\"S. Pal\"},{\"authorId\":\"4211203\",\"name\":\"T. Mohandoss\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1117/12.2522915\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0faa94ed3b14e56cf3c3dd0eeb71a381e028c81\",\"title\":\"Visual attention for behavioral cloning in autonomous driving\",\"url\":\"https://www.semanticscholar.org/paper/a0faa94ed3b14e56cf3c3dd0eeb71a381e028c81\",\"venue\":\"International Conference on Machine Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510712042\",\"name\":\"Yongtao Yu\"},{\"authorId\":\"21704078\",\"name\":\"H. Guan\"},{\"authorId\":\"2672180\",\"name\":\"D. Li\"},{\"authorId\":\"122357657\",\"name\":\"Tiannan Gu\"},{\"authorId\":\"153607310\",\"name\":\"E. Tang\"},{\"authorId\":\"49779374\",\"name\":\"Aixia Li\"}],\"doi\":\"10.1016/j.isprsjprs.2019.12.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5e8556770bf22f11d213212b74ffc7219ed36d6\",\"title\":\"Orientation guided anchoring for geospatial object detection from remote sensing imagery\",\"url\":\"https://www.semanticscholar.org/paper/f5e8556770bf22f11d213212b74ffc7219ed36d6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50177237\",\"name\":\"Xia Hua\"},{\"authorId\":\"1915447\",\"name\":\"X. Wang\"},{\"authorId\":\"34668628\",\"name\":\"Ting Rui\"},{\"authorId\":\"46349080\",\"name\":\"D. Wang\"},{\"authorId\":\"51294540\",\"name\":\"Faming Shao\"}],\"doi\":\"10.3390/electronics8101151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bebc2d896dc901e58358aeb915a52ad7d4677d76\",\"title\":\"Real-Time Object Detection in Remote Sensing Images Based on Visual Perception and Memory Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/bebc2d896dc901e58358aeb915a52ad7d4677d76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"title\":\"GazeGAN: A Generative Adversarial Saliency Model based on Invariance Analysis of Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31057181\",\"name\":\"Gongwei Xiao\"},{\"authorId\":\"4731807\",\"name\":\"Muhong Wu\"},{\"authorId\":\"2494213\",\"name\":\"Qian Shi\"},{\"authorId\":\"145447664\",\"name\":\"Zhi Zhou\"},{\"authorId\":\"121022998\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/TCCN.2019.2938947\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"193b8b36f5d62a05b9501baa93d54c764a631df9\",\"title\":\"DeepVR: Deep Reinforcement Learning for Predictive Panoramic Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/193b8b36f5d62a05b9501baa93d54c764a631df9\",\"venue\":\"IEEE Transactions on Cognitive Communications and Networking\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2018.00250\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"title\":\"SAM: Pushing the Limits of Saliency Prediction Models\",\"url\":\"https://www.semanticscholar.org/paper/cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1802.10062\",\"authors\":[{\"authorId\":\"47001856\",\"name\":\"Yuhong Li\"},{\"authorId\":\"2739998\",\"name\":\"Xiaofan Zhang\"},{\"authorId\":\"1713644\",\"name\":\"D. Chen\"}],\"doi\":\"10.1109/CVPR.2018.00120\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a964f13abb3cdc5675dbfd612fa0409608e28c7\",\"title\":\"CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes\",\"url\":\"https://www.semanticscholar.org/paper/1a964f13abb3cdc5675dbfd612fa0409608e28c7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1701.05349\",\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d541bf669dda499f86b4dd2ac4e263134a3cd4c\",\"title\":\"Pixel Objectness\",\"url\":\"https://www.semanticscholar.org/paper/2d541bf669dda499f86b4dd2ac4e263134a3cd4c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27651985\",\"name\":\"Austin Le\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"title\":\"Predicting Visual Saliency : Where Do People Look ?\",\"url\":\"https://www.semanticscholar.org/paper/0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80937411\",\"name\":\"Quanlong Zheng\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"143864954\",\"name\":\"Y. Cao\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1007/978-3-030-01264-9_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"83990b5527c2447085125fd79cffb3ce34a7b517\",\"title\":\"Task-Driven Webpage Saliency\",\"url\":\"https://www.semanticscholar.org/paper/83990b5527c2447085125fd79cffb3ce34a7b517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1710.08014\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/ICCV.2017.240\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"title\":\"Deep Cropping via Attention Box Prediction and Aesthetics Assessment\",\"url\":\"https://www.semanticscholar.org/paper/b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1907.01432\",\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"145140331\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"150344105\",\"name\":\"Xiaofu Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"title\":\"An End-to-End Neural Network for Image Cropping by Learning Composition from Aesthetic Photos\",\"url\":\"https://www.semanticscholar.org/paper/dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144539624\",\"name\":\"B. Yan\"},{\"authorId\":\"1789710\",\"name\":\"Haoqian Wang\"},{\"authorId\":\"3291129\",\"name\":\"X. Wang\"},{\"authorId\":\"5094646\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICIP.2017.8296700\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d1d71e0149bc601363f7e24825b06b36af13f5f\",\"title\":\"An accurate saliency prediction method based on generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/6d1d71e0149bc601363f7e24825b06b36af13f5f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1608.01536\",\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"143861275\",\"name\":\"X. Liu\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/TMM.2018.2856126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c9d0084bea756fe3ebe33571220f54fd5020048\",\"title\":\"Saliency Integration: An Arbitrator Model\",\"url\":\"https://www.semanticscholar.org/paper/1c9d0084bea756fe3ebe33571220f54fd5020048\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1711.01984\",\"authors\":[{\"authorId\":\"48624955\",\"name\":\"Wei-Hong Li\"},{\"authorId\":\"9186191\",\"name\":\"B. Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/FG.2018.00042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e95e2dc37dc64906d9f9f18e3a461fc056ce398f\",\"title\":\"PersonRank: Detecting Important People in Images\",\"url\":\"https://www.semanticscholar.org/paper/e95e2dc37dc64906d9f9f18e3a461fc056ce398f\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":\"1710.03011\",\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"},{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"46380769\",\"name\":\"Jingyi Yu\"}],\"doi\":\"10.1109/TPAMI.2018.2866563\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"title\":\"Personalized Saliency and Its Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1610.01708\",\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2817047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"title\":\"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3215589\",\"name\":\"F. Putze\"},{\"authorId\":\"2042310709\",\"name\":\"Merlin Burri\"},{\"authorId\":\"1380237732\",\"name\":\"Lisa-Marie Vortmann\"},{\"authorId\":\"94063590\",\"name\":\"T. Schultz\"}],\"doi\":\"10.1145/3395035.3425206\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35224094c416bea1228d100dd1cd98dda507eec7\",\"title\":\"Model-based Prediction of Exogeneous and Endogeneous Attention Shifts During an Everyday Activity\",\"url\":\"https://www.semanticscholar.org/paper/35224094c416bea1228d100dd1cd98dda507eec7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9228892\",\"name\":\"P. Zhang\"},{\"authorId\":\"47155200\",\"name\":\"X. Hua\"},{\"authorId\":\"50141120\",\"name\":\"X. Wang\"},{\"authorId\":\"34668628\",\"name\":\"Ting Rui\"},{\"authorId\":\"49724535\",\"name\":\"H. Zhang\"},{\"authorId\":\"51294540\",\"name\":\"Faming Shao\"},{\"authorId\":\"24981485\",\"name\":\"Dong Wang\"}],\"doi\":\"10.1109/access.2020.3012185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc6450c2444a642f0204786828ce1472f2737bea\",\"title\":\"VSA-CGAN: An Intelligent Generation Model for Deep Learning Sample Database Construction\",\"url\":\"https://www.semanticscholar.org/paper/bc6450c2444a642f0204786828ce1472f2737bea\",\"venue\":\"IEEE Access\",\"year\":2020}],\"corpusId\":16408631,\"doi\":\"10.1109/CVPR.2016.71\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":46,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"49312774\",\"name\":\"K. Murphy\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-007-0090-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"092c275005ae49dc1303214f6d02d134457c7053\",\"title\":\"LabelMe: A Database and Web-Based Tool for Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/092c275005ae49dc1303214f6d02d134457c7053\",\"venue\":\"International Journal of Computer Vision\",\"year\":2007},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1211.5590\",\"authors\":[{\"authorId\":\"3227028\",\"name\":\"Fr\\u00e9d\\u00e9ric Bastien\"},{\"authorId\":\"3087941\",\"name\":\"Pascal Lamblin\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"47944877\",\"name\":\"Arnaud Bergeron\"},{\"authorId\":\"14362225\",\"name\":\"Nicolas Bouchard\"},{\"authorId\":\"1923596\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"855d0f722d75cc56a66a00ede18ace96bafee6bd\",\"title\":\"Theano: new features and speed improvements\",\"url\":\"https://www.semanticscholar.org/paper/855d0f722d75cc56a66a00ede18ace96bafee6bd\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1504.06755\",\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"2507239\",\"name\":\"Y. Zhang\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"1697413\",\"name\":\"S. Kulkarni\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3433627f803953280b66ae1576d083fc9a68385a\",\"title\":\"TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking\",\"url\":\"https://www.semanticscholar.org/paper/3433627f803953280b66ae1576d083fc9a68385a\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2330182\",\"name\":\"S. Wen\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"}],\"doi\":\"10.1109/CVPR.2015.7298633\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"title\":\"Predicting eye fixations using convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1207.0580\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1366de5bb112746a555e9c0cd00de3ad8628aea8\",\"title\":\"Improving neural networks by preventing co-adaptation of feature detectors\",\"url\":\"https://www.semanticscholar.org/paper/1366de5bb112746a555e9c0cd00de3ad8628aea8\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24492532\",\"name\":\"Jian-xiong Xiao\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2010.5539970\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"title\":\"SUN database: Large-scale scene recognition from abbey to zoo\",\"url\":\"https://www.semanticscholar.org/paper/908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Ouyang\"},{\"authorId\":null,\"name\":\"H. Li\"},{\"authorId\":null,\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Large - scale scene understanding challenge : Eye tracking saliency estimation\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145638781\",\"name\":\"R. Zhao\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2015.7298731\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd126c7db89f1a66b17a6ef1152412876f4c0cbe\",\"title\":\"Saliency detection by multi-context deep learning\",\"url\":\"https://www.semanticscholar.org/paper/cd126c7db89f1a66b17a6ef1152412876f4c0cbe\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1503.08663\",\"authors\":[{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"}],\"doi\":\"10.1109/CVPR.2015.7299184\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"207dcaf83f6855c7bfe8f5a4747b9f65fe505900\",\"title\":\"Visual saliency based on multiscale deep features\",\"url\":\"https://www.semanticscholar.org/paper/207dcaf83f6855c7bfe8f5a4747b9f65fe505900\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":\"1412.7062\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39ad6c911f3351a3b390130a6e4265355b4d593b\",\"title\":\"Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs\",\"url\":\"https://www.semanticscholar.org/paper/39ad6c911f3351a3b390130a6e4265355b4d593b\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1302.4389\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7b915d508987b73b61eccd2b237e7ed099a2d29\",\"title\":\"Maxout Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7b915d508987b73b61eccd2b237e7ed099a2d29\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Zhang\"},{\"authorId\":null,\"name\":\"F Yu\"},{\"authorId\":null,\"name\":\"S Song\"},{\"authorId\":null,\"name\":\"P Xu\"},{\"authorId\":null,\"name\":\"A Seff\"},{\"authorId\":null,\"name\":\"J Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Largescale scene understanding challenge: Eye tracking saliency estimation\",\"url\":\"\",\"venue\":\"Largescale scene understanding challenge: Eye tracking saliency estimation\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Bergstra\"},{\"authorId\":null,\"name\":\"O. Breuleux\"},{\"authorId\":null,\"name\":\"F. Bastien\"},{\"authorId\":null,\"name\":\"P. Lamblin\"},{\"authorId\":null,\"name\":\"R. Pascanu\"},{\"authorId\":null,\"name\":\"G. Desjardins\"},{\"authorId\":null,\"name\":\"J. Turian\"},{\"authorId\":null,\"name\":\"D. Warde-Farley\"},{\"authorId\":null,\"name\":\"Y. Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Theano: a cpu and gpu math expression compiler\",\"url\":\"\",\"venue\":\"Conference on Python for Scientific Computing, volume 4, page 3\",\"year\":2010},{\"arxivId\":\"1411.1045\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"title\":\"Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet\",\"url\":\"https://www.semanticscholar.org/paper/652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145131953\",\"name\":\"L. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2015.7298938\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"338e14e0c5e368efc79361adc5ba4957d1c17ef1\",\"title\":\"Deep networks for saliency detection via local estimation and global search\",\"url\":\"https://www.semanticscholar.org/paper/338e14e0c5e368efc79361adc5ba4957d1c17ef1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbc31c14529b64cd7ad833b8a270b3b3e515c75\",\"title\":\"Best of both worlds: Human-machine collaboration for object annotation\",\"url\":\"https://www.semanticscholar.org/paper/1bbc31c14529b64cd7ad833b8a270b3b3e515c75\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492727\",\"name\":\"Radoslaw Martin Cichy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"8152383\",\"name\":\"D. Pantazis\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1167/15.12.376\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b895ad8620d00da9786f2a4bfff3f453ba14a3\",\"title\":\"Mapping human visual representations in space and time by neural networks.\",\"url\":\"https://www.semanticscholar.org/paper/52b895ad8620d00da9786f2a4bfff3f453ba14a3\",\"venue\":\"Journal of vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Koch\"},{\"authorId\":null,\"name\":\"E. Niebur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Reducing the semantic gap in saliency prediction by adapting neural networks\",\"url\":\"\",\"venue\":\"Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30262222\",\"name\":\"A. Carlier\"},{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"2476460\",\"name\":\"F. Cabezas\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"1747107\",\"name\":\"V. Charvillat\"},{\"authorId\":\"144161771\",\"name\":\"O. Marques\"}],\"doi\":\"10.1007/s11042-015-2897-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7df750805d6c025d0a1a74a05a83bcf8cc63dd7\",\"title\":\"Assessment of crowdsourcing and gamification loss in user-assisted object segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e7df750805d6c025d0a1a74a05a83bcf8cc63dd7\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2011.5995347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302bb2d5476540cfb21467473f5eca843caf90b\",\"title\":\"Unbiased look at dataset bias\",\"url\":\"https://www.semanticscholar.org/paper/0302bb2d5476540cfb21467473f5eca843caf90b\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"143648071\",\"name\":\"S. Eslami\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-014-0733-5\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"616b246e332573af1f4859aa91440280774c183a\",\"title\":\"The Pascal Visual Object Classes Challenge: A Retrospective\",\"url\":\"https://www.semanticscholar.org/paper/616b246e332573af1f4859aa91440280774c183a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":\"1312.6034\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71\",\"title\":\"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688714\",\"name\":\"Laurent Najman\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/TPAMI.2012.231\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"237a04dd8291cbdb59b6dc4b53e689af743fe2a3\",\"title\":\"Learning Hierarchical Features for Scene Labeling\",\"url\":\"https://www.semanticscholar.org/paper/237a04dd8291cbdb59b6dc4b53e689af743fe2a3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1510.05484\",\"authors\":[{\"authorId\":\"40286484\",\"name\":\"Xi Li\"},{\"authorId\":\"46586815\",\"name\":\"Liming Zhao\"},{\"authorId\":\"50589478\",\"name\":\"Lina Wei\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/TIP.2016.2579306\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b2197fad455f016eaa7a08a8861ed752ca1cd96\",\"title\":\"DeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/4b2197fad455f016eaa7a08a8861ed752ca1cd96\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"F. Yu\"},{\"authorId\":null,\"name\":\"S. Song\"},{\"authorId\":null,\"name\":\"P. Xu\"},{\"authorId\":null,\"name\":\"A. Seff\"},{\"authorId\":null,\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Large - scale scene understanding challenge : Eye tracking saliency estimation\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"3028207\",\"name\":\"Makiese Mibulumukini\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1016/j.image.2013.03.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83ec029e1a7b41669f8254b24c070050d9d01d75\",\"title\":\"RARE2012: A multi-scale rarity-based saliency detection with its comparative statistical analysis\",\"url\":\"https://www.semanticscholar.org/paper/83ec029e1a7b41669f8254b24c070050d9d01d75\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2013},{\"arxivId\":\"1407.5104\",\"authors\":[{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"2774233\",\"name\":\"D. Stansbury\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"40373111\",\"name\":\"J. Gallant\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d36c1fc605dff28c9f06d60e04dae25ad7d50d36\",\"title\":\"Pixels to Voxels: Modeling Visual Representation in the Human Brain\",\"url\":\"https://www.semanticscholar.org/paper/d36c1fc605dff28c9f06d60e04dae25ad7d50d36\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015}],\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Euclidean distance\",\"topicId\":\"23240\",\"url\":\"https://www.semanticscholar.org/topic/23240\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"GeForce 700 series\",\"topicId\":\"728192\",\"url\":\"https://www.semanticscholar.org/topic/728192\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"},{\"topic\":\"GeForce 6 series\",\"topicId\":\"547556\",\"url\":\"https://www.semanticscholar.org/topic/547556\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"End-to-end encryption\",\"topicId\":\"854929\",\"url\":\"https://www.semanticscholar.org/topic/854929\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"GeForce 900 series\",\"topicId\":\"643331\",\"url\":\"https://www.semanticscholar.org/topic/643331\"},{\"topic\":\"Titan (supercomputer)\",\"topicId\":\"30537\",\"url\":\"https://www.semanticscholar.org/topic/30537\"},{\"topic\":\"Titan Rain\",\"topicId\":\"4328201\",\"url\":\"https://www.semanticscholar.org/topic/4328201\"}],\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"