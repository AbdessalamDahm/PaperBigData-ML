"{\"abstract\":\"When people observe and interact with physical spaces, they are able to associate functionality to regions in the environment. Our goal is to automate dense functional understanding of large spaces by leveraging sparse activity demonstrations recorded from an ego-centric viewpoint. The method we describe enables functionality estimation in large scenes where people have behaved, as well as novel scenes where no behaviors are observed. Our method learns and predicts \\\"Action Maps\\\", which encode the ability for a user to perform activities at various locations. With the usage of an egocentric camera to observe human activities, our method scales with the size of the scene without the need for mounting multiple static surveillance cameras and is well-suited to the task of observing activities up-close. We demonstrate that by capturing appearance-based attributes of the environment and associating these attributes with activity demonstrations, our proposed mathematical framework allows for the prediction of Action Maps in new environments. Additionally, we offer a preliminary glance of the applicability of Action Maps by demonstrating a proof-of concept application in which they are used in concert with activity detections to perform localization.\",\"arxivId\":\"1605.01679\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\",\"url\":\"https://www.semanticscholar.org/author/1974383\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\",\"url\":\"https://www.semanticscholar.org/author/37991449\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":\"2008.09241\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f7f381fe77d1b6b21e10a9c7136a99eb111893e\",\"title\":\"Learning Affordance Landscapes forInteraction Exploration in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/7f7f381fe77d1b6b21e10a9c7136a99eb111893e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/TPAMI.2018.2873794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"title\":\"First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2018.01.019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"title\":\"Personal-location-based temporal segmentation of egocentric videos for lifelogging applications\",\"url\":\"https://www.semanticscholar.org/paper/79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1701.00142\",\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"32776367\",\"name\":\"Mohammad Shafiei\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2980179.2980235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"title\":\"EgoCap: egocentric marker-less motion capture with two fisheye cameras\",\"url\":\"https://www.semanticscholar.org/paper/ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73235537\",\"name\":\"Timo L\\u00fcddecke\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1763a449f167528610fb100fc217c655228c8922\",\"title\":\"Learning to Label Affordances from Simulated and Real Data\",\"url\":\"https://www.semanticscholar.org/paper/1763a449f167528610fb100fc217c655228c8922\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alexandra Maha Abbas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0b8971c6a7f7d9fb73bc4414623a6dc7e8a183c\",\"title\":\"Object Detection on Large-Scale Egocentric Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e0b8971c6a7f7d9fb73bc4414623a6dc7e8a183c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1109/CVPR.2018.00772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3586c182a3450f6eea4d64d69217383bae77e6c1\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/3586c182a3450f6eea4d64d69217383bae77e6c1\",\"venue\":\"CVPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"}],\"doi\":\"10.22028/D291-26685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"title\":\"From motion capture to interactive virtual worlds: towards unconstrained motion-capture algorithms for real-time performance-driven character animation\",\"url\":\"https://www.semanticscholar.org/paper/62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73235537\",\"name\":\"Timo L\\u00fcddecke\"},{\"authorId\":\"1705543\",\"name\":\"Tomas Kulvicius\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":\"10.1016/J.ROBOT.2019.05.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdd2d905ad09df66f50bcbc72186d1f33e8add6e\",\"title\":\"Context-based affordance segmentation from 2D images for robot actions\",\"url\":\"https://www.semanticscholar.org/paper/cdd2d905ad09df66f50bcbc72186d1f33e8add6e\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73235537\",\"name\":\"Timo L\\u00fcddecke\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":\"10.1109/ICCVW.2017.96\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ce76250731cb19ccc5ffff43e4c6abec8f5af79\",\"title\":\"Learning to Segment Affordances\",\"url\":\"https://www.semanticscholar.org/paper/2ce76250731cb19ccc5ffff43e4c6abec8f5af79\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1910938\",\"name\":\"S. Akizuki\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"794020b601a6d01a95e8cabcab20ba82d5630dc0\",\"title\":\"Tactile Logging for Understanding Plausible Tool Use Based on Human Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/794020b601a6d01a95e8cabcab20ba82d5630dc0\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbe18855b85bc6f218c53993cf289e2607518b1\",\"title\":\"Learning Policies to Forecast Agent Behavior with Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/6dbe18855b85bc6f218c53993cf289e2607518b1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/TIP.2017.2772904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a955ee69174fb97c7017f2e227a5fa26b900537\",\"title\":\"Egocentric Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/7a955ee69174fb97c7017f2e227a5fa26b900537\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1804.09627\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1145/3265987.3265995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.07796\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2017.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"title\":\"First-Person Activity Forecasting with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79993756\",\"name\":\"Haruya Ishikawa\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"48589121\",\"name\":\"Shuichi Akizuki\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.23919/MVA.2019.8757896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a019ef99567561824c50196f013eb73657b96232\",\"title\":\"Human-Object Maps for Daily Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a019ef99567561824c50196f013eb73657b96232\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9362227\",\"name\":\"Sagar Verma\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72379808573cc333f63a3c774457d1770aca052d\",\"title\":\"Action recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/72379808573cc333f63a3c774457d1770aca052d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1016/j.cviu.2018.05.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a38a87330e434dedaadccc3add90f95c8c48a080\",\"title\":\"An exocentric look at egocentric actions and vice versa\",\"url\":\"https://www.semanticscholar.org/paper/a38a87330e434dedaadccc3add90f95c8c48a080\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1812.04558\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"title\":\"Grounded Human-Object Interaction Hotspots From Video\",\"url\":\"https://www.semanticscholar.org/paper/316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1807.06775\",\"authors\":[{\"authorId\":\"145867132\",\"name\":\"Mohammed Hassanin\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"},{\"authorId\":\"2312383\",\"name\":\"M. Tahtali\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81d327ec41c67728b15438bca86d10b72de1d88f\",\"title\":\"Visual Affordance and Function Understanding: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/81d327ec41c67728b15438bca86d10b72de1d88f\",\"venue\":\"ArXiv\",\"year\":2018}],\"corpusId\":6799759,\"doi\":\"10.1109/CVPR.2016.69\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8f38d907b60602c79a3368e96e54cd5c14cdd84f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2949240\",\"name\":\"Scott Satkin\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2011.5995448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e700356dae7a0a54c91567801c8c5f09bdd8c05\",\"title\":\"From 3D scene geometry to human workspace\",\"url\":\"https://www.semanticscholar.org/paper/0e700356dae7a0a54c91567801c8c5f09bdd8c05\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144872229\",\"name\":\"P. Hanrahan\"}],\"doi\":\"10.1145/2661229.2661230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1817e2285bfa850d01d92b65b0fd2e1525c727c9\",\"title\":\"SceneGrok: inferring action maps in 3D environments\",\"url\":\"https://www.semanticscholar.org/paper/1817e2285bfa850d01d92b65b0fd2e1525c727c9\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2423230\",\"name\":\"L. Breiman\"}],\"doi\":\"10.1023/A:1010933404324\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986\",\"title\":\"Random Forests\",\"url\":\"https://www.semanticscholar.org/paper/13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L Breiman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Random forests. Machine learning\",\"url\":\"\",\"venue\":\"Random forests. Machine learning\",\"year\":2001},{\"arxivId\":\"1210.1207\",\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1996326\",\"name\":\"Rudhir Gupta\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1177/0278364913478446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f\",\"title\":\"Learning human activities and object affordances from RGB-D videos\",\"url\":\"https://www.semanticscholar.org/paper/e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2013},{\"arxivId\":\"1010.4891\",\"authors\":[{\"authorId\":\"39400685\",\"name\":\"P. Ramachandran\"},{\"authorId\":\"3025780\",\"name\":\"G. Varoquaux\"}],\"doi\":\"10.1109/MCSE.2011.35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb490e4feffddcfbbbc29e5380d442bd3a65573a\",\"title\":\"Mayavi: 3D Visualization of Scientific Data\",\"url\":\"https://www.semanticscholar.org/paper/fb490e4feffddcfbbbc29e5380d442bd3a65573a\",\"venue\":\"Computing in Science & Engineering\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2483785\",\"name\":\"Patrick Peursum\"},{\"authorId\":\"145227675\",\"name\":\"G. West\"},{\"authorId\":\"143761093\",\"name\":\"S. Venkatesh\"}],\"doi\":\"10.1109/ICCV.2005.57\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddc37d14d12b81afae1d3e44864766ca01721cd5\",\"title\":\"Combining image regions and human activity for indirect object recognition in indoor wide-angle views\",\"url\":\"https://www.semanticscholar.org/paper/ddc37d14d12b81afae1d3e44864766ca01721cd5\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6856\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"title\":\"Object Detectors Emerge in Deep Scene CNNs\",\"url\":\"https://www.semanticscholar.org/paper/9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/s11263-014-0710-z\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf6adca17eb4b9d26de29f10f2be20bcf8e522ee\",\"title\":\"People Watching: Human Actions as a Cue for Single View Geometry\",\"url\":\"https://www.semanticscholar.org/paper/cf6adca17eb4b9d26de29f10f2be20bcf8e522ee\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. K. Nathan Silberman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Derek Hoiem and R\",\"url\":\"\",\"venue\":\"Fergus. Indoor segmentation and support inference from rgbd images. In ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"11573252\",\"name\":\"T. Chen\"},{\"authorId\":\"27375808\",\"name\":\"Francine Chen\"},{\"authorId\":\"145698468\",\"name\":\"D. Kimber\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2008.4587511\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7c22e1267b590f0f7dbb25cd28d2a6340c5fc49\",\"title\":\"Context and observation driven latent variable model for human pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/f7c22e1267b590f0f7dbb25cd28d2a6340c5fc49\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"In Computer Vision \\u2013 ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2010.5540235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927432c50d920e647260c67506859d7845c7f729\",\"title\":\"Modeling mutual context of object and human pose in human-object interaction activities\",\"url\":\"https://www.semanticscholar.org/paper/927432c50d920e647260c67506859d7845c7f729\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-642-33783-3_21\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b85674090c2d15ce3221c6d0c4c8a6d8f7e77e4d\",\"title\":\"Scene Semantics from Long-Term Observation of People\",\"url\":\"https://www.semanticscholar.org/paper/b85674090c2d15ce3221c6d0c4c8a6d8f7e77e4d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50262304\",\"name\":\"Yun Jiang\"},{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/CVPR.2013.385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0c2e331fea01cc4a30608507a9f0693142169e5\",\"title\":\"Hallucinated Humans as the Hidden Context for Labeling 3D Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c0c2e331fea01cc4a30608507a9f0693142169e5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32713089\",\"name\":\"D. Moore\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"144449603\",\"name\":\"M. Hayes\"}],\"doi\":\"10.1109/ICCV.1999.791201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f090df944fceaf52cda458ed6116802cd36ca08e\",\"title\":\"Exploiting human actions and object context for recognition tasks\",\"url\":\"https://www.semanticscholar.org/paper/f090df944fceaf52cda458ed6116802cd36ca08e\",\"venue\":\"Proceedings of the Seventh IEEE International Conference on Computer Vision\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Ye Y. Li\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Delving into egocentric actions\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9937103\",\"name\":\"Quanquan Gu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"},{\"authorId\":\"1737469\",\"name\":\"C. Ding\"}],\"doi\":\"10.1137/1.9781611972801.18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"69ade5b90100d7f54ad3ea92a873ed2dfdc2b18f\",\"title\":\"Collaborative Filtering: Weighted Nonnegative Matrix Factorization Incorporating User and Item Graphs\",\"url\":\"https://www.semanticscholar.org/paper/69ade5b90100d7f54ad3ea92a873ed2dfdc2b18f\",\"venue\":\"SDM\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"Computer Vision \\u2013 ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38955885\",\"name\":\"Changchang Wu\"}],\"doi\":\"10.1109/3DV.2013.25\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51b685fe8ce6b917993aecbf9e16cdd07d3b1b7c\",\"title\":\"Towards Linear-Time Incremental Structure from Motion\",\"url\":\"https://www.semanticscholar.org/paper/51b685fe8ce6b917993aecbf9e16cdd07d3b1b7c\",\"venue\":\"2013 International Conference on 3D Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"47427259\",\"name\":\"A. Fossati\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2011.5995582\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a23344eda43e0eff2de71a3af5d30ff783d226f4\",\"title\":\"Functional categorization of objects using real-time markerless motion capture\",\"url\":\"https://www.semanticscholar.org/paper/a23344eda43e0eff2de71a3af5d30ff783d226f4\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Delving into egocentric actions\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-642-33715-4_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1994ba5946456fc70948c549daf62363f13fa2d\",\"title\":\"Indoor Segmentation and Support Inference from RGBD Images\",\"url\":\"https://www.semanticscholar.org/paper/c1994ba5946456fc70948c549daf62363f13fa2d\",\"venue\":\"ECCV\",\"year\":2012}],\"title\":\"Learning Action Maps of Large Environments via First-Person Vision\",\"topics\":[{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"IBM Research\",\"topicId\":\"265853\",\"url\":\"https://www.semanticscholar.org/topic/265853\"},{\"topic\":\"Closed-circuit television\",\"topicId\":\"34046\",\"url\":\"https://www.semanticscholar.org/topic/34046\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"},{\"topic\":\"PA-RISC\",\"topicId\":\"702703\",\"url\":\"https://www.semanticscholar.org/topic/702703\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"}],\"url\":\"https://www.semanticscholar.org/paper/8f38d907b60602c79a3368e96e54cd5c14cdd84f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"