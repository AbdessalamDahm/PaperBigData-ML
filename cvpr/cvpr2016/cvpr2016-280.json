"{\"abstract\":\"We focus on the problem of wearer's action recognition in first person a.k.a. egocentric videos. This problem is more challenging than third person activity recognition due to unavailability of wearer's pose and sharp movements in the videos caused by the natural head motion of the wearer. Carefully crafted features based on hands and objects cues for the problem have been shown to be successful for limited targeted datasets. We propose convolutional neural networks (CNNs) for end to end learning and classification of wearer's actions. The proposed network makes use of egocentric cues by capturing hand pose, head motion and saliency map. It is compact. It can also be trained from relatively small number of labeled egocentric videos that are available. We show that the proposed network can generalize and give state of the art performance on various disparate egocentric action datasets.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\",\"url\":\"https://www.semanticscholar.org/author/48039353\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\",\"url\":\"https://www.semanticscholar.org/author/145676233\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\",\"url\":\"https://www.semanticscholar.org/author/1694502\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":\"1703.09026\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/iccv.2017.314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"title\":\"Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4947266e0caa3d8be726b98f5be08217748a6e20\",\"title\":\"Input Mask Encoder z Decoder Reconstructed Mask a ) VAE Input Mask Action CNN b ) Action CNN Predicted Action Probability Fixed Action\",\"url\":\"https://www.semanticscholar.org/paper/4947266e0caa3d8be726b98f5be08217748a6e20\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733072400\",\"name\":\"Min-Huan Fu\"},{\"authorId\":\"26958446\",\"name\":\"An-Zi Yen\"},{\"authorId\":\"2611607\",\"name\":\"Hen-Hsen Huang\"},{\"authorId\":\"153924342\",\"name\":\"Hsin-Hsi Chen\"}],\"doi\":\"10.1145/3372278.3390700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665576b67476e4f9e259fe831fab09657c323b80\",\"title\":\"Incorporating Semantic Knowledge for Visual Lifelog Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/665576b67476e4f9e259fe831fab09657c323b80\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1907.01481\",\"authors\":[{\"authorId\":\"150296901\",\"name\":\"Shreyas Hampali\"},{\"authorId\":\"144536317\",\"name\":\"M. Rad\"},{\"authorId\":\"2650133\",\"name\":\"Markus Oberweger\"},{\"authorId\":\"144447227\",\"name\":\"Vincent Lepetit\"}],\"doi\":\"10.1109/cvpr42600.2020.00326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b2c6bf5ca7f54a1d32c02fe7a1fe28b274c6ba3\",\"title\":\"HOnnotate: A Method for 3D Annotation of Hand and Object Poses\",\"url\":\"https://www.semanticscholar.org/paper/5b2c6bf5ca7f54a1d32c02fe7a1fe28b274c6ba3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1608.08242\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1007/978-3-319-49409-8_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6903ea1adc08200dfe2df5a54896c4c76a0088d1\",\"title\":\"Temporal Convolutional Networks: A Unified Approach to Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6903ea1adc08200dfe2df5a54896c4c76a0088d1\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"2001.01083\",\"authors\":[{\"authorId\":\"51991145\",\"name\":\"Naina Dhingra\"},{\"authorId\":\"143717147\",\"name\":\"A. Kunz\"}],\"doi\":\"10.1109/3DV.2019.00061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"title\":\"Res3ATN - Deep 3D Residual Attention Network for Hand Gesture Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":\"1909.09283\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/WACV.2019.00027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ced33344402d74f69367caa163e94918f307ab78\",\"title\":\"Coupled Generative Adversarial Network for Continuous Fine-Grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ced33344402d74f69367caa163e94918f307ab78\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"22192364\",\"name\":\"Kartikeya Gupta\"},{\"authorId\":\"25732952\",\"name\":\"F. Ahmad\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"}],\"doi\":\"10.1109/WACV.2019.00011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ac4863f4d5c0868c6151c6b0eb78d23debd063b\",\"title\":\"EGO-SLAM: A Robust Monocular SLAM for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/9ac4863f4d5c0868c6151c6b0eb78d23debd063b\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51228744\",\"name\":\"Girmaw Abebe Tadesse\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1145/3211960.3211978\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d531875e928ae0e64df8a1618f47c111c9306b11\",\"title\":\"Visual features for ego-centric activity recognition: a survey\",\"url\":\"https://www.semanticscholar.org/paper/d531875e928ae0e64df8a1618f47c111c9306b11\",\"venue\":\"WearSys@MobiSys\",\"year\":2018},{\"arxivId\":\"2010.08055\",\"authors\":[{\"authorId\":\"27478395\",\"name\":\"K. Bhandari\"},{\"authorId\":\"1998945138\",\"name\":\"Mario A. DeLaGarza\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"3422205\",\"name\":\"Hugo Latapie\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"title\":\"Egok360: A 360 Egocentric Kinetic Human Activity Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1812.01922\",\"authors\":[{\"authorId\":\"48379459\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"7595315\",\"name\":\"Christian Jarvers\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1109/CVPR.2019.01228\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"428934f26e240aadeec86b40b23182455fb25c1a\",\"title\":\"Local Temporal Bilinear Pooling for Fine-Grained Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/428934f26e240aadeec86b40b23182455fb25c1a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1709.06495\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/ICCVW.2017.276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5155499812dafee92316bdbca5937f0e134514f3\",\"title\":\"Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5155499812dafee92316bdbca5937f0e134514f3\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1705.07818\",\"authors\":[{\"authorId\":\"144529493\",\"name\":\"Li Ding\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1219c1334c292fb4e5fd0c434dacd0e1e4d5e28\",\"title\":\"TricorNet: A Hybrid Temporal Convolutional and Recurrent Network for Video Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c1219c1334c292fb4e5fd0c434dacd0e1e4d5e28\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995028\",\"name\":\"K. Suma\"},{\"authorId\":\"71879392\",\"name\":\"G. Aditya\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1145/3293353.3293362\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc5e3095ce86de685418fb7ca2062eab21214801\",\"title\":\"Activity Recognition in Egocentric Videos Using Bag of Key Action Units\",\"url\":\"https://www.semanticscholar.org/paper/dc5e3095ce86de685418fb7ca2062eab21214801\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1704.02463\",\"authors\":[{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"3325819\",\"name\":\"Shanxin Yuan\"},{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/CVPR.2018.00050\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"title\":\"First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations\",\"url\":\"https://www.semanticscholar.org/paper/e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.09078\",\"authors\":[{\"authorId\":\"2129493\",\"name\":\"Timur M. Bagautdinov\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"2721983\",\"name\":\"F. Fleuret\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/CVPR.2017.365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81ba5202424906f64b77f68afca063658139fbb2\",\"title\":\"Social Scene Understanding: End-to-End Multi-person Action Localization and Collective Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/81ba5202424906f64b77f68afca063658139fbb2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCVW.2017.280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"title\":\"How Shall We Evaluate Egocentric Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152460549\",\"name\":\"Antonia Breuer\"},{\"authorId\":\"153269740\",\"name\":\"Jana Kirschner\"},{\"authorId\":\"1694892\",\"name\":\"S. Homoceanu\"},{\"authorId\":\"1679795\",\"name\":\"T. Fingscheidt\"}],\"doi\":\"10.1109/IVS.2019.8813816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"title\":\"Towards Tactical Maneuver Detection for Autonomous Driving Based on Vision Only\",\"url\":\"https://www.semanticscholar.org/paper/d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":\"1912.10867\",\"authors\":[{\"authorId\":\"39612426\",\"name\":\"A. Bandini\"},{\"authorId\":\"1870273\",\"name\":\"J. Zariffa\"}],\"doi\":\"10.1109/TPAMI.2020.2986648\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ee84cebd99eca11eaf826a803feeb804634536dc\",\"title\":\"Analysis of the hands in egocentric vision: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ee84cebd99eca11eaf826a803feeb804634536dc\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1707.05564\",\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"22192364\",\"name\":\"Kartikeya Gupta\"},{\"authorId\":\"25732952\",\"name\":\"F. Ahmad\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57d55ecd850ce02e95e7f8a0b942a0debaf63a1f\",\"title\":\"Batch based Monocular SLAM for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/57d55ecd850ce02e95e7f8a0b942a0debaf63a1f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564762\",\"name\":\"Sho Ooi\"},{\"authorId\":\"32523963\",\"name\":\"Tsuyoshi Ikegaya\"},{\"authorId\":\"1783113\",\"name\":\"Mutsuo Sano\"}],\"doi\":\"10.20965/jrm.2017.p0728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fed5e198d624108c480035882c3df40760809c50\",\"title\":\"Cooking Behavior Recognition Using Egocentric Vision for Cooking Navigation\",\"url\":\"https://www.semanticscholar.org/paper/fed5e198d624108c480035882c3df40760809c50\",\"venue\":\"J. Robotics Mechatronics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150296901\",\"name\":\"Shreyas Hampali\"},{\"authorId\":\"2650133\",\"name\":\"Markus Oberweger\"},{\"authorId\":\"144536317\",\"name\":\"M. Rad\"},{\"authorId\":\"144447227\",\"name\":\"Vincent Lepetit\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f649b8652703dd3053f798eae9e4b1fd44cd2f\",\"title\":\"HO-3D: A Multi-User, Multi-Object Dataset for Joint 3D Hand-Object Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/18f649b8652703dd3053f798eae9e4b1fd44cd2f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9362227\",\"name\":\"Sagar Verma\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72379808573cc333f63a3c774457d1770aca052d\",\"title\":\"Action recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/72379808573cc333f63a3c774457d1770aca052d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1910.07766\",\"authors\":[{\"authorId\":\"9362227\",\"name\":\"Sagar Verma\"},{\"authorId\":\"9361887\",\"name\":\"Pravin Nagar\"},{\"authorId\":\"3451954\",\"name\":\"Divam Gupta\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":\"10.1109/ICIP.2018.8451249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d94136016e14bcce68ec68b443c9d1b29535ca3b\",\"title\":\"Making Third Person Techniques Recognize First-Person Actions in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d94136016e14bcce68ec68b443c9d1b29535ca3b\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740811711\",\"name\":\"Shinya Michibata\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"},{\"authorId\":\"1733070603\",\"name\":\"Atsushi Hashimoto\"}],\"doi\":\"10.1145/3379175.3391712\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"66bead45f2fff3f9175658eb036f1a38031f2ba7\",\"title\":\"Cooking Activity Recognition in Egocentric Videos with a Hand Mask Image Branch in the Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/66bead45f2fff3f9175658eb036f1a38031f2ba7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2450903\",\"name\":\"Rawan Alharbi\"},{\"authorId\":\"153876788\",\"name\":\"Mariam Tolba\"},{\"authorId\":\"49489155\",\"name\":\"L. C. Petito\"},{\"authorId\":\"15918293\",\"name\":\"J. Hester\"},{\"authorId\":\"2959332\",\"name\":\"Nabil Alshurafa\"}],\"doi\":\"10.1145/3351230\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52ad405f439b1fc84956463bfe9346874c1e1164\",\"title\":\"To Mask or Not to Mask?\",\"url\":\"https://www.semanticscholar.org/paper/52ad405f439b1fc84956463bfe9346874c1e1164\",\"venue\":\"Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies\",\"year\":2019},{\"arxivId\":\"1710.04112\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/s10044-018-0708-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"726493da25879c1579941e9cbcd5e9a15c7665d1\",\"title\":\"Recognizing Daily Activities from Egocentric Photo-Streams\",\"url\":\"https://www.semanticscholar.org/paper/726493da25879c1579941e9cbcd5e9a15c7665d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9361887\",\"name\":\"Pravin Nagar\"},{\"authorId\":\"67153756\",\"name\":\"Mansi Khemka\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"}],\"doi\":\"10.1145/3394171.3413713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25df842658e7adb7535f4d154d49bb9961b0eb6e\",\"title\":\"Concept Drift Detection for Multivariate Data Streams and Temporal Segmentation of Daylong Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/25df842658e7adb7535f4d154d49bb9961b0eb6e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1803.01413\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2018.00617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bfa0c14c2ae48c1ee6b145008137e4d69688416\",\"title\":\"Egocentric Basketball Motion Planning from a Single First-Person Image\",\"url\":\"https://www.semanticscholar.org/paper/8bfa0c14c2ae48c1ee6b145008137e4d69688416\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48003030\",\"name\":\"Haibin Yu\"},{\"authorId\":\"49166770\",\"name\":\"W. Jia\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"144645724\",\"name\":\"M. Pan\"},{\"authorId\":\"35588611\",\"name\":\"Yuan-yuan Liu\"},{\"authorId\":\"31179730\",\"name\":\"Mingui Sun\"}],\"doi\":\"10.1007/s12652-020-02241-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed03223d7702f28b41f7f61398050fdf711bfbb1\",\"title\":\"A hierarchical parallel fusion framework for egocentric ADL recognition based on discernment frame partitioning and belief coarsening\",\"url\":\"https://www.semanticscholar.org/paper/ed03223d7702f28b41f7f61398050fdf711bfbb1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.05380\",\"authors\":[{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"2050262\",\"name\":\"J. Ondrej\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ISMAR-Adjunct.2018.00045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75367cd0e81c32dad80d62372bde5b49a4feca53\",\"title\":\"Egocentric Gesture Recognition for Head-Mounted AR Devices\",\"url\":\"https://www.semanticscholar.org/paper/75367cd0e81c32dad80d62372bde5b49a4feca53\",\"venue\":\"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31689549\",\"name\":\"H. F. Nweke\"},{\"authorId\":\"1717493\",\"name\":\"Teh Ying Wah\"},{\"authorId\":\"1403206186\",\"name\":\"M. A. Al-garadi\"},{\"authorId\":\"40994774\",\"name\":\"U. R. Alo\"}],\"doi\":\"10.1016/j.eswa.2018.03.056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0cf8271b76661b58936f443bfe7387d18ddf9a5\",\"title\":\"Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges\",\"url\":\"https://www.semanticscholar.org/paper/d0cf8271b76661b58936f443bfe7387d18ddf9a5\",\"venue\":\"Expert Syst. Appl.\",\"year\":2018},{\"arxivId\":\"1812.00104\",\"authors\":[{\"authorId\":\"46419391\",\"name\":\"M. Elfeki\"},{\"authorId\":\"50528026\",\"name\":\"Krishna Regmi\"},{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1c8fd832fe393034fad096f3296493ef6f807ad\",\"title\":\"From Third Person to First Person: Dataset and Baselines for Synthesis and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a1c8fd832fe393034fad096f3296493ef6f807ad\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35014907\",\"name\":\"F. Ozkan\"},{\"authorId\":\"3299076\",\"name\":\"Elif Surer\"},{\"authorId\":\"1787799\",\"name\":\"Alptekin Temizel\"}],\"doi\":\"10.1109/SIU.2018.8404221\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d85f3cf2cc464b67ff0ead1a82197878da7494d\",\"title\":\"Ranking based boosted multiple kernel learning for activity recognition on first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/9d85f3cf2cc464b67ff0ead1a82197878da7494d\",\"venue\":\"2018 26th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145295896\",\"name\":\"Y. Shen\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"2492392\",\"name\":\"N. Zhuang\"}],\"doi\":\"10.1007/978-3-030-01216-8_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"title\":\"Egocentric Activity Prediction via Event Modulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129493\",\"name\":\"Timur M. Bagautdinov\"}],\"doi\":\"10.5075/epfl-thesis-8680\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e586547a63400881c7a95d6ad6d5fa31ac237ca9\",\"title\":\"Variational Methods for Human Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e586547a63400881c7a95d6ad6d5fa31ac237ca9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.721\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36e093e2c6142017e61c37200e915fd08d2456a1\",\"title\":\"Jointly Learning Energy Expenditures and Activities Using Egocentric Multimodal Signals\",\"url\":\"https://www.semanticscholar.org/paper/36e093e2c6142017e61c37200e915fd08d2456a1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23276966\",\"name\":\"A. Nakazawa\"},{\"authorId\":\"51285606\",\"name\":\"Yu Mitsuzumi\"},{\"authorId\":\"102305500\",\"name\":\"Y. Watanabe\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"},{\"authorId\":\"46330846\",\"name\":\"S. Yoshikawa\"},{\"authorId\":\"6101063\",\"name\":\"M. Honda\"}],\"doi\":\"10.1007/S10846-019-01052-8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a12e9ef876fb6f621fe9414bb7d17974fdbc00b0\",\"title\":\"First-person Video Analysis for Evaluating Skill Level in the Humanitude Tender-Care Technique\",\"url\":\"https://www.semanticscholar.org/paper/a12e9ef876fb6f621fe9414bb7d17974fdbc00b0\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"3190022\",\"name\":\"Danping Liao\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICCVW.2019.00543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"title\":\"Learning Spatiotemporal Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47528018\",\"name\":\"Weiming Zhang\"},{\"authorId\":\"11833179\",\"name\":\"Y. Huang\"},{\"authorId\":\"50239804\",\"name\":\"Wanting Yu\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"152958348\",\"name\":\"J. Sang\"}],\"doi\":\"10.1145/3338533.3366592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ffa55458f24787542860c8224cd97249836576c\",\"title\":\"Multimodal Attribute and Feature Embedding for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ffa55458f24787542860c8224cd97249836576c\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47003295\",\"name\":\"Yonggang Li\"},{\"authorId\":\"48843874\",\"name\":\"Rui Ge\"},{\"authorId\":\"36352159\",\"name\":\"Y. Ji\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1109/TCSVT.2017.2759299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e18c35667c46829a6c7374de11c937359c2b837\",\"title\":\"Trajectory-Pooled Spatial-Temporal Architecture of Deep Convolutional Neural Networks for Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/5e18c35667c46829a6c7374de11c937359c2b837\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2005.03209\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.patrec.2020.01.023\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43d62be979c811e521a749d6b747b3d8af36d0b8\",\"title\":\"Hierarchical Attention Network for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/43d62be979c811e521a749d6b747b3d8af36d0b8\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1908.10406\",\"authors\":[{\"authorId\":\"83053815\",\"name\":\"R. J. Vis\\u00e9e\"},{\"authorId\":\"48006417\",\"name\":\"J. Likitlersuang\"},{\"authorId\":\"1870273\",\"name\":\"J. Zariffa\"}],\"doi\":\"10.1109/TNSRE.2020.2968912\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8094d96b357a9991b5bb756506bd0b489c30ef55\",\"title\":\"An Effective and Efficient Method for Detecting Hands in Egocentric Videos for Rehabilitation Applications\",\"url\":\"https://www.semanticscholar.org/paper/8094d96b357a9991b5bb756506bd0b489c30ef55\",\"venue\":\"IEEE Transactions on Neural Systems and Rehabilitation Engineering\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"}],\"doi\":\"10.1145/3394171.3413654\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87fc465274a3ee292606e81ae1b9e232c0ff0c39\",\"title\":\"Recognizing Camera Wearer from Hand Gestures in Egocentric Videos: https://egocentricbiometric.github.io/\",\"url\":\"https://www.semanticscholar.org/paper/87fc465274a3ee292606e81ae1b9e232c0ff0c39\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1611.05365\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICCV.2017.239\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"61f8b4a736d5d7aebc64144112720edaef05610a\",\"title\":\"Am I a Baller? Basketball Performance Assessment from First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/61f8b4a736d5d7aebc64144112720edaef05610a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1710.07477\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"16261770\",\"name\":\"Ting-An Chien\"},{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2017.15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"604575bf821ad655e195a78d53badb0a636ffa0f\",\"title\":\"Anticipating Daily Intention Using On-wrist Motion Triggered Sensing\",\"url\":\"https://www.semanticscholar.org/paper/604575bf821ad655e195a78d53badb0a636ffa0f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"title\":\"Inertial-Vision: Cross-Domain Knowledge Transfer for Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1807.11794\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"title\":\"Attention is All We Need: Nailing Down Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d572e5851306d7d420a619469c8f449943f5880\",\"title\":\"Modeling Long-Term Interactions to Enhance Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d572e5851306d7d420a619469c8f449943f5880\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1410235731\",\"name\":\"A. Garcia-Garcia\"},{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1422589705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"145897522\",\"name\":\"J. Rodr\\u00edguez\"}],\"doi\":\"10.1007/978-3-030-36150-1_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c59399086221d8f80493efa7f0d1fd037dd1b2c8\",\"title\":\"3D Hand Joints Position Estimation with Graph Convolutional Networks: A GraphHands Baseline\",\"url\":\"https://www.semanticscholar.org/paper/c59399086221d8f80493efa7f0d1fd037dd1b2c8\",\"venue\":\"ROBOT\",\"year\":2019},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1016/j.cviu.2018.05.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a38a87330e434dedaadccc3add90f95c8c48a080\",\"title\":\"An exocentric look at egocentric actions and vice versa\",\"url\":\"https://www.semanticscholar.org/paper/a38a87330e434dedaadccc3add90f95c8c48a080\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1906.01004\",\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"152284539\",\"name\":\"Qianli Ma\"},{\"authorId\":\"143627576\",\"name\":\"Heiko Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"title\":\"Frontal Low-rank Random Tensors for Fine-grained Action Segmentation.\",\"url\":\"https://www.semanticscholar.org/paper/8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50333150\",\"name\":\"Ning Zhuang\"},{\"authorId\":\"49347106\",\"name\":\"Q. Zhang\"},{\"authorId\":\"46724087\",\"name\":\"Y. Shen\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1016/J.PATREC.2019.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e2bcdd3632f7627ca00169cc3ca27be90d99154\",\"title\":\"Long term activity prediction in first person viewpoint\",\"url\":\"https://www.semanticscholar.org/paper/4e2bcdd3632f7627ca00169cc3ca27be90d99154\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1709.01630\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"46865173\",\"name\":\"Jianbo Shi\"}],\"doi\":\"10.1109/ICCVW.2017.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eb200cc606ec9290acdf4679fa4315c1bbe725d\",\"title\":\"Using Cross-Model EgoSupervision to Learn Cooperative Basketball Intention\",\"url\":\"https://www.semanticscholar.org/paper/5eb200cc606ec9290acdf4679fa4315c1bbe725d\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8311413\",\"name\":\"Vinodh Buddubariki\"},{\"authorId\":\"8392068\",\"name\":\"Sunitha Gowd Tulluri\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1145/3009977.3010011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7de79a149568048db336d92dba9ea5ca54145628\",\"title\":\"Event recognition in egocentric videos using a novel trajectory based feature\",\"url\":\"https://www.semanticscholar.org/paper/7de79a149568048db336d92dba9ea5ca54145628\",\"venue\":\"ICVGIP '16\",\"year\":2016},{\"arxivId\":\"1811.08815\",\"authors\":[{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/ICCV.2019.00638\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"title\":\"Learning Motion in Feature Space: Locally-Consistent Deformable Convolution Networks for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50218246\",\"name\":\"Z. Wang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TCSVT.2018.2875441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a90a56267b66c060b235339a0080a00585fdeb41\",\"title\":\"Multi-Stream Deep Neural Networks for RGB-D Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a90a56267b66c060b235339a0080a00585fdeb41\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"1763134\",\"name\":\"Yeonho Kim\"},{\"authorId\":\"144499950\",\"name\":\"J. S. Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1016/j.patrec.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c81c88f74d466a65520ea9751970ff781352ec0a\",\"title\":\"First Person Action Recognition via Two-stream ConvNet with Long-term Fusion Pooling\",\"url\":\"https://www.semanticscholar.org/paper/c81c88f74d466a65520ea9751970ff781352ec0a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be35517555e01428ed04577f4e7e566041706aa9\",\"title\":\"Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be35517555e01428ed04577f4e7e566041706aa9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.08714\",\"authors\":[{\"authorId\":\"2964097\",\"name\":\"A. Ghosh\"},{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/WACV.2018.00039\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a2359c0f81a7eb032cff1fe45e3b80007facaa2a\",\"title\":\"Towards Structured Analysis of Broadcast Badminton Videos\",\"url\":\"https://www.semanticscholar.org/paper/a2359c0f81a7eb032cff1fe45e3b80007facaa2a\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1604.02115\",\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.patcog.2016.07.031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45b6562ffd8df53de69e39c91b1f28abece412d9\",\"title\":\"Trajectory aligned features for first person action recognition\",\"url\":\"https://www.semanticscholar.org/paper/45b6562ffd8df53de69e39c91b1f28abece412d9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964097\",\"name\":\"A. Ghosh\"},{\"authorId\":null,\"name\":\"Kartheek Alahari\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e62b5f5e17c1093ea090c3512358210570f1086\",\"title\":\"Analyzing Racket Sports From Broadcast Videos\",\"url\":\"https://www.semanticscholar.org/paper/1e62b5f5e17c1093ea090c3512358210570f1086\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23400572\",\"name\":\"K. Hirota\"},{\"authorId\":\"145286719\",\"name\":\"T. Komuro\"}],\"doi\":\"10.1109/AIVR46125.2019.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e660d6984d2831a0e336b345c7843119123ff00\",\"title\":\"Situation-Adaptive Object Grasping Recognition in VR Environment\",\"url\":\"https://www.semanticscholar.org/paper/9e660d6984d2831a0e336b345c7843119123ff00\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48046803\",\"name\":\"Bharat Lal Bhatnagar\"},{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.24963/ijcai.2017/200\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dcf17cc3b4f8519a6789c1ea086689bcbc1d6f11\",\"title\":\"Unsupervised Learning of Deep Feature Representation for Clustering Egocentric Actions\",\"url\":\"https://www.semanticscholar.org/paper/dcf17cc3b4f8519a6789c1ea086689bcbc1d6f11\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.159\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a671cb0d366ab895249349ca457673150ecc8ee2\",\"title\":\"A Long Short-Term Memory Convolutional Neural Network for First-Person Vision Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a671cb0d366ab895249349ca457673150ecc8ee2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ACCESS.2020.2990333\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b516f02c6fc6f923100f377b6aaa4ca3e515331d\",\"title\":\"Activities of Daily Living Monitoring via a Wearable Camera: Toward Real-World Applications\",\"url\":\"https://www.semanticscholar.org/paper/b516f02c6fc6f923100f377b6aaa4ca3e515331d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.13586\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"50204657\",\"name\":\"Yijun Cai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"title\":\"Deep Dual Relation Modeling for Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2568376\",\"name\":\"Abhimanyu Sahu\"},{\"authorId\":\"1384438931\",\"name\":\"Rajit Bhattacharya\"},{\"authorId\":\"1397164455\",\"name\":\"Pallabh Bhura\"},{\"authorId\":\"40272229\",\"name\":\"A. S. Chowdhury\"}],\"doi\":\"10.1007/978-981-32-9291-8_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3702830eeb1bc771a3a9b0133c407b1fe8afb4d3\",\"title\":\"Action Recognition from Egocentric Videos Using Random Walks\",\"url\":\"https://www.semanticscholar.org/paper/3702830eeb1bc771a3a9b0133c407b1fe8afb4d3\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8748110\",\"name\":\"Taha Alhersh\"},{\"authorId\":\"102804035\",\"name\":\"S. B. Belhaouari\"},{\"authorId\":\"1698459\",\"name\":\"H. Stuckenschmidt\"}],\"doi\":\"10.1007/978-3-030-34255-5_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b02536161966e8b9285af4817435509be71e7c1\",\"title\":\"Action Recognition Using Local Visual Descriptors and Inertial Data\",\"url\":\"https://www.semanticscholar.org/paper/1b02536161966e8b9285af4817435509be71e7c1\",\"venue\":\"AmI\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32154590\",\"name\":\"Krit Karan Singh\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1007/978-981-13-0020-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d428f98e0bad7c34e3acd6064f7967ba8d5cd59\",\"title\":\"Recognizing Human Activities in Videos Using Improved Dense Trajectories over LSTM\",\"url\":\"https://www.semanticscholar.org/paper/4d428f98e0bad7c34e3acd6064f7967ba8d5cd59\",\"venue\":\"NCVPRIPG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08825ffe4dc4f673eb86de43f9a708c85cdf9947\",\"title\":\"Contextually Driven First-person Action Recognition From Videos\",\"url\":\"https://www.semanticscholar.org/paper/08825ffe4dc4f673eb86de43f9a708c85cdf9947\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2002.08219\",\"authors\":[{\"authorId\":\"1489467112\",\"name\":\"Yeji Kim\"},{\"authorId\":\"122808682\",\"name\":\"Dong-Gyu Lee\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"title\":\"Three-Stream Fusion Network for First-Person Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452223\",\"name\":\"Kazuto Nakashima\"},{\"authorId\":\"1795530\",\"name\":\"Y. Iwashita\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"}],\"doi\":\"10.1186/s40648-020-00181-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76b4b7aa99a8434d80f3af553fbfa013f5cbfe6b\",\"title\":\"Lifelogging caption generation via fourth-person vision in a human\\u2013robot symbiotic environment\",\"url\":\"https://www.semanticscholar.org/paper/76b4b7aa99a8434d80f3af553fbfa013f5cbfe6b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.09220\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4673e744d0ded47fe6df3b6314f79a41359578b\",\"title\":\"MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b4673e744d0ded47fe6df3b6314f79a41359578b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/TIP.2017.2772904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a955ee69174fb97c7017f2e227a5fa26b900537\",\"title\":\"Egocentric Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/7a955ee69174fb97c7017f2e227a5fa26b900537\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2009.07470\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"46836072\",\"name\":\"S. Kundu\"},{\"authorId\":\"1945699686\",\"name\":\"Nikhil Gunti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"051dc6c1821721151bea555307c5a6bc72965a55\",\"title\":\"Knowledge Guided Learning: Towards Open Domain Egocentric Action Recognition with Zero Supervision\",\"url\":\"https://www.semanticscholar.org/paper/051dc6c1821721151bea555307c5a6bc72965a55\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3293353.3293363\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"title\":\"Multimodal Egocentric Activity Recognition Using Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"2011.12102\",\"authors\":[{\"authorId\":\"1773047\",\"name\":\"Qing Gao\"},{\"authorId\":\"3356854\",\"name\":\"Ming-Tao Pei\"},{\"authorId\":\"2187859\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c195c6aa7269a7d4b64d24b079e3fd61d97f6e9c\",\"title\":\"Do You Live a Healthy Life? Analyzing Lifestyle by Visual Life Logging\",\"url\":\"https://www.semanticscholar.org/paper/c195c6aa7269a7d4b64d24b079e3fd61d97f6e9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122150713\",\"name\":\"Shuichi Urabe\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":\"10.1145/3230519.3230584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"title\":\"Cooking activities recognition in egocentric videos using combining 2DCNN and 3DCNN\",\"url\":\"https://www.semanticscholar.org/paper/43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"venue\":\"CEA@IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400685790\",\"name\":\"Jessica Beltr\\u00e1n-M\\u00e1rquez\"},{\"authorId\":\"1399106107\",\"name\":\"M. Garc\\u00eda-V\\u00e1zquez\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1384122700\",\"name\":\"L. Guti\\u00e9rrez-Robledo\"},{\"authorId\":\"80153973\",\"name\":\"J. Dartigues\"}],\"doi\":\"10.1155/2018/2676409\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9a94545c781b455d962690c0d5b3e076bad233c\",\"title\":\"Computational Techniques for Eye Movements Analysis towards Supporting Early Diagnosis of Alzheimer's Disease: A Review\",\"url\":\"https://www.semanticscholar.org/paper/f9a94545c781b455d962690c0d5b3e076bad233c\",\"venue\":\"Comput. Math. Methods Medicine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789861350\",\"name\":\"Teerawat Kumrai\"},{\"authorId\":\"1789889055\",\"name\":\"Joseph Korpela\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"153020914\",\"name\":\"Y. Yu\"},{\"authorId\":\"1800112\",\"name\":\"R. Kanai\"}],\"doi\":\"10.1109/PerCom45495.2020.9127376\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75a7031603f16a51c9c1aa7998643bd8503a9ec6\",\"title\":\"Human Activity Recognition with Deep Reinforcement Learning using the Camera of a Mobile Robot\",\"url\":\"https://www.semanticscholar.org/paper/75a7031603f16a51c9c1aa7998643bd8503a9ec6\",\"venue\":\"2020 IEEE International Conference on Pervasive Computing and Communications (PerCom)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/s10044-018-0708-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a625b55cf8914d6f275478773b84f58ad8ffdd85\",\"title\":\"Batch-based activity recognition from egocentric photo-streams revisited\",\"url\":\"https://www.semanticscholar.org/paper/a625b55cf8914d6f275478773b84f58ad8ffdd85\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"1910.02201\",\"authors\":[{\"authorId\":\"21173784\",\"name\":\"Motoki Kojima\"},{\"authorId\":\"1691940\",\"name\":\"Jun Miura\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5519bc90c012a9f912f88fa76d2af7b0a34a01e\",\"title\":\"Early Estimation of User's Intention of Tele-Operation Using Object Affordance and Hand Motion in a Dual First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/e5519bc90c012a9f912f88fa76d2af7b0a34a01e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.05836\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"50528026\",\"name\":\"Krishna Regmi\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a74c9affc7209343026f8cd47d9b35fd818253c\",\"title\":\"EgoTransfer: Transferring Motion Across Egocentric and Exocentric Domains using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a74c9affc7209343026f8cd47d9b35fd818253c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ajeeta Rajkumar Khatri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2152989920c63cfd7ce2342fe93ef41d472b6eba\",\"title\":\"Interaction Recognition in a Paired Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/2152989920c63cfd7ce2342fe93ef41d472b6eba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.318\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"414c85e333a24456a3bb5b194d97e95e69175dea\",\"title\":\"Jointly Recognizing Object Fluents and Tasks in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/414c85e333a24456a3bb5b194d97e95e69175dea\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.05267\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"49447925\",\"name\":\"M. Flynn\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1109/CVPR.2017.113\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"title\":\"Temporal Convolutional Networks for Action Segmentation and Detection\",\"url\":\"https://www.semanticscholar.org/paper/210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23276966\",\"name\":\"A. Nakazawa\"},{\"authorId\":\"6101063\",\"name\":\"M. Honda\"}],\"doi\":\"10.1109/ICCVW.2019.00544\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c388f71d209556c66415ff091a9c50864cf69ea9\",\"title\":\"First-Person Camera System to Evaluate Tender Dementia-Care Skill\",\"url\":\"https://www.semanticscholar.org/paper/c388f71d209556c66415ff091a9c50864cf69ea9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51207457\",\"name\":\"Chengzhang Zhong\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"},{\"authorId\":\"1423744921\",\"name\":\"Hansel Mina Cordoba\"},{\"authorId\":\"40268177\",\"name\":\"A. Deering\"}],\"doi\":\"10.1109/MMSP.2019.8901753\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eff8bfd489acbb0444a2b8def9632ae48029b7df\",\"title\":\"Hand-hygiene activity recognition in egocentric video\",\"url\":\"https://www.semanticscholar.org/paper/eff8bfd489acbb0444a2b8def9632ae48029b7df\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":\"1607.08414\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1007/978-3-319-46604-0_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995447f98766c17b414fd25b7f836c8bdda79225\",\"title\":\"SEMBED: Semantic Embedding of Egocentric Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/995447f98766c17b414fd25b7f836c8bdda79225\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380599561\",\"name\":\"Ioannis Chatzigiannakis\"},{\"authorId\":\"69336068\",\"name\":\"B.E.R. de Ruyter\"},{\"authorId\":\"2995898\",\"name\":\"Irene Mavrommati\"}],\"doi\":\"10.1007/978-3-030-34255-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96a4df64e462f3bb47a77f591115d0946c494ea4\",\"title\":\"Ambient Intelligence: 15th European Conference, AmI 2019, Rome, Italy, November 13\\u201315, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/96a4df64e462f3bb47a77f591115d0946c494ea4\",\"venue\":\"AmI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51295994\",\"name\":\"Ee Heng Chen\"},{\"authorId\":\"1791260\",\"name\":\"Darius Burschka\"}],\"doi\":\"10.1109/ICRA.2018.8462973\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33cd5da38a699142c1868f6e6e4080818897ff8b\",\"title\":\"Object-Centric Approach to Prediction and Labeling of Manipulation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/33cd5da38a699142c1868f6e6e4080818897ff8b\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":\"1805.04026\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2abaa1476fe1f00358f3eaa77dde2f348f58982\",\"title\":\"Towards an Unequivocal Representation of Actions\",\"url\":\"https://www.semanticscholar.org/paper/f2abaa1476fe1f00358f3eaa77dde2f348f58982\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48607291\",\"name\":\"Yi Wu\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/ICCV.2017.406\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"title\":\"Egocentric Gesture Recognition Using Recurrent 3D Convolutional Neural Networks with Spatiotemporal Transformer Modules\",\"url\":\"https://www.semanticscholar.org/paper/f8772fee6517a64f6381a8eb2af96aff43a9bf95\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16185102\",\"name\":\"Lingling Fa\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1007/978-3-319-73600-6_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e796f2e22d4598de4a80f6796df5ec2067e63a55\",\"title\":\"Global and Local C3D Ensemble System for First Person Interactive Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e796f2e22d4598de4a80f6796df5ec2067e63a55\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":\"1909.09269\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.patcog.2019.107039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e593d38f35d340e8da0cf62a29a180dbe42e8047\",\"title\":\"Fine-grained Action Segmentation using the Semi-Supervised Action GAN\",\"url\":\"https://www.semanticscholar.org/paper/e593d38f35d340e8da0cf62a29a180dbe42e8047\",\"venue\":\"Pattern Recognit.\",\"year\":2020}],\"corpusId\":206593792,\"doi\":\"10.1109/CVPR.2016.287\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":15,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Poleg\"},{\"authorId\":null,\"name\":\"T Halperin\"},{\"authorId\":null,\"name\":\"C Arora\"},{\"authorId\":null,\"name\":\"S Peleg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Egosampling: Fastforward and stereo for egocentric videos. CoRR, abs/1412\",\"url\":\"\",\"venue\":\"Egosampling: Fastforward and stereo for egocentric videos. CoRR, abs/1412\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"3041721\",\"name\":\"M. Philipose\"}],\"doi\":\"10.1109/CVPRW.2009.5204360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e538042f6513cf1d07fda9fab52dd96f80f534c\",\"title\":\"Egocentric recognition of handled objects: Benchmark and analysis\",\"url\":\"https://www.semanticscholar.org/paper/9e538042f6513cf1d07fda9fab52dd96f80f534c\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1023/A:1011139631724\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"869171b2f56cfeaa9b81b2626cb4956fea590a57\",\"title\":\"Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope\",\"url\":\"https://www.semanticscholar.org/paper/869171b2f56cfeaa9b81b2626cb4956fea590a57\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2014.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"title\":\"Temporal Segmentation of Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2405888\",\"name\":\"Lahav Yeffet\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/ICCV.2009.5459201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68080fa24fef0f6eaa3dfd6f63978de01bc251bf\",\"title\":\"Local Trinary Patterns for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/68080fa24fef0f6eaa3dfd6f63978de01bc251bf\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"39599498\",\"name\":\"C. Gu\"}],\"doi\":\"10.1109/CVPR.2010.5540074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"title\":\"Figure-ground segmentation improves handled object recognition in egocentric video\",\"url\":\"https://www.semanticscholar.org/paper/04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1411.7591\",\"authors\":[{\"authorId\":\"2776254\",\"name\":\"Yedid Hoshen\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c6be0034477b07222f41f6fc558a64f0222a192\",\"title\":\"Egocentric Video Biometrics\",\"url\":\"https://www.semanticscholar.org/paper/3c6be0034477b07222f41f6fc558a64f0222a192\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-10602-1_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"title\":\"Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Action recognition by dense trajectories Action recognition with improved trajectories\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2013.352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"title\":\"First-Person Activity Recognition: What Are They Doing to Me?\",\"url\":\"https://www.semanticscholar.org/paper/aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37335907\",\"name\":\"G. Willems\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-540-88688-4_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"title\":\"An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector\",\"url\":\"https://www.semanticscholar.org/paper/117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Grauman.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Delving into egocentric actions\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2013.458\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a90a0d0d4f349c2c330d9d137baf5076ee3f717\",\"title\":\"Pixel-Level Hand Detection in Ego-centric Videos\",\"url\":\"https://www.semanticscholar.org/paper/5a90a0d0d4f349c2c330d9d137baf5076ee3f717\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2260110\",\"name\":\"Sudeep Sundaram\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/CVPRW.2009.5204355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65a034b8d81498c7c70192980d34abd5b7d6bf58\",\"title\":\"High level activity recognition using low resolution wearable vision\",\"url\":\"https://www.semanticscholar.org/paper/65a034b8d81498c7c70192980d34abd5b7d6bf58\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1685141\",\"name\":\"F. Paci\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1710649\",\"name\":\"L. Benini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2014.107\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9138623a41dc272227db16f9f9381778d56a3821\",\"title\":\"Gesture Recognition in Ego-centric Videos Using Dense Trajectories and Hand Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9138623a41dc272227db16f9f9381778d56a3821\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d3ad3770ea08455de14149f77a5144882dcb124\",\"title\":\"First-person Hyperlapse Videos\",\"url\":\"https://www.semanticscholar.org/paper/8d3ad3770ea08455de14149f77a5144882dcb124\",\"venue\":\"SIGGRAPH 2014\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143616798\",\"name\":\"Zheng Lu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"title\":\"Story-Driven Summarization for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":\"1412.3596\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2015.7299109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ce71f5bd42cf343a0f33deb2174b165d3463e89\",\"title\":\"EgoSampling: Fast-forward and stereo for egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6ce71f5bd42cf343a0f33deb2174b165d3463e89\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354558\",\"name\":\"E. Kraft\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-16814-2_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"714383394790bc8f2d2b465da2ee10cf2c89a536\",\"title\":\"Motion Based Foreground Detection and Poselet Motion Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/714383394790bc8f2d2b465da2ee10cf2c89a536\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Microsoft Sensecam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"http://research.microsoft.com/ en-us/um/cambridge/projects/sensecam\",\"url\":\"\",\"venue\":\"http://research.microsoft.com/ en-us/um/cambridge/projects/sensecam\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2011},{\"arxivId\":\"1604.02115\",\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.patcog.2016.07.031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45b6562ffd8df53de69e39c91b1f28abece412d9\",\"title\":\"Trajectory aligned features for first person action recognition\",\"url\":\"https://www.semanticscholar.org/paper/45b6562ffd8df53de69e39c91b1f28abece412d9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048032\",\"name\":\"P. Scovanner\"},{\"authorId\":\"38245610\",\"name\":\"Saad Ali\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1145/1291233.1291311\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"title\":\"A 3-dimensional sift descriptor and its application to action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"venue\":\"ACM Multimedia\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1007/978-3-319-16811-1_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02366fb058f22a12c8963c3be7f435e338944bf9\",\"title\":\"Head Motion Signatures from Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/02366fb058f22a12c8963c3be7f435e338944bf9\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.1109/CVPR.2013.330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"title\":\"Better Exploiting Motion for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2011.5995444\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bc900a187b6f0115417f4b7dfd2cf44c62875bf8\",\"title\":\"Learning to recognize objects in egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bc900a187b6f0115417f4b7dfd2cf44c62875bf8\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Hoshen\"},{\"authorId\":null,\"name\":\"S Peleg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Egocentric video biometrics. CoRR, abs/1411\",\"url\":\"\",\"venue\":\"Egocentric video biometrics. CoRR, abs/1411\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/CVPR.2011.5995406\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8848d1abd31873594fc372e0022789f153112174\",\"title\":\"Fast unsupervised ego-action learning for first-person sports videos\",\"url\":\"https://www.semanticscholar.org/paper/8848d1abd31873594fc372e0022789f153112174\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1510.01576\",\"authors\":[{\"authorId\":\"118242229\",\"name\":\"D. Castro\"},{\"authorId\":\"2935619\",\"name\":\"Steven Hickson\"},{\"authorId\":\"3115428\",\"name\":\"Vinay Bettadapura\"},{\"authorId\":\"39642711\",\"name\":\"E. Thomaz\"},{\"authorId\":\"9267108\",\"name\":\"Gregory D. Abowd\"},{\"authorId\":\"1723059\",\"name\":\"H. Christensen\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1145/2802083.2808398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d23260f8cb9d0ef5f1e0e9f43e9ebd1131f0e71\",\"title\":\"Predicting daily activities from egocentric images using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/0d23260f8cb9d0ef5f1e0e9f43e9ebd1131f0e71\",\"venue\":\"SEMWEB\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2012.6247805\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"title\":\"Social interactions: A first-person perspective\",\"url\":\"https://www.semanticscholar.org/paper/014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145865884\",\"name\":\"T. McCandless\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.5244/C.27.30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6aa058aa564efbaaed8ea4e5a164574a69f3034\",\"title\":\"Object-Centric Spatio-Temporal Pyramids for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e6aa058aa564efbaaed8ea4e5a164574a69f3034\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235516\",\"name\":\"K. Matsuo\"},{\"authorId\":\"50295846\",\"name\":\"K. Yamada\"},{\"authorId\":\"50269200\",\"name\":\"S. Ueno\"},{\"authorId\":\"144889095\",\"name\":\"S. Naito\"}],\"doi\":\"10.1109/CVPRW.2014.87\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c75d5a3be94eb106000aae7049c89adc369c6e67\",\"title\":\"An Attention-Based Activity Recognition for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/c75d5a3be94eb106000aae7049c89adc369c6e67\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Google glass. https://www.google.com/glass/start\",\"url\":\"\",\"venue\":\"Google glass. https://www.google.com/glass/start\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687322\",\"name\":\"O. Aghazadeh\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPR.2011.5995731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53dff6a36e9537a9d2547d471004d83e29cb8e19\",\"title\":\"Novelty detection from an ego-centric perspective\",\"url\":\"https://www.semanticscholar.org/paper/53dff6a36e9537a9d2547d471004d83e29cb8e19\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32635753\",\"name\":\"K. Ogaki\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPRW.2012.6239188\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d4b2f645efef25f102b3d0c84d5185af296d152\",\"title\":\"Coupling eye-motion and ego-motion features for first-person activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d4b2f645efef25f102b3d0c84d5185af296d152\",\"venue\":\"2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"E. Shelhamer\"},{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"S. Karayev\"},{\"authorId\":null,\"name\":\"J. Long\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"d convolutional neural networks for human action recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2013}],\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"topics\":[{\"topic\":\"First-person (video games)\",\"topicId\":\"622459\",\"url\":\"https://www.semanticscholar.org/topic/622459\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Virtual camera system\",\"topicId\":\"493894\",\"url\":\"https://www.semanticscholar.org/topic/493894\"},{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Unavailability\",\"topicId\":\"184609\",\"url\":\"https://www.semanticscholar.org/topic/184609\"}],\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"