"{\"abstract\":\"We introduce the concept of dynamic image, a novel compact representation of videos useful for video analysis especially when convolutional neural networks (CNNs) are used. The dynamic image is based on the rank pooling concept and is obtained through the parameters of a ranking machine that encodes the temporal evolution of the frames of the video. Dynamic images are obtained by directly applying rank pooling on the raw image pixels of a video producing a single RGB image per video. This idea is simple but powerful as it enables the use of existing CNN models directly on video data with fine-tuning. We present an efficient and effective approximate rank pooling operator, speeding it up orders of magnitude compared to rank pooling. Our new approximate rank pooling CNN layer allows us to generalize dynamic images to dynamic feature maps and we demonstrate the power of our new representations on standard benchmarks in action recognition achieving state-of-the-art performance.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\",\"url\":\"https://www.semanticscholar.org/author/2518212\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\",\"url\":\"https://www.semanticscholar.org/author/1688071\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\",\"url\":\"https://www.semanticscholar.org/author/2304222\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\",\"url\":\"https://www.semanticscholar.org/author/1687524\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\",\"url\":\"https://www.semanticscholar.org/author/145273587\"}],\"citationVelocity\":95,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9102201\",\"name\":\"Yaxiang Fan\"},{\"authorId\":\"144334479\",\"name\":\"Gongjian Wen\"},{\"authorId\":\"143638182\",\"name\":\"D. Li\"},{\"authorId\":\"3437649\",\"name\":\"Shaohua Qiu\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"}],\"doi\":\"10.1016/j.jvcir.2018.01.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2c0800ac15344d3f5b285b665e226af4f7da155\",\"title\":\"Early event detection based on dynamic images of surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/f2c0800ac15344d3f5b285b665e226af4f7da155\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1806.08152\",\"authors\":[{\"authorId\":\"46185180\",\"name\":\"A. Masullo\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1751117\",\"name\":\"S. Hannuna\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5ce5ae9e855efa88724aa3f0c4b004862dc534d5\",\"title\":\"CaloriNet: From silhouettes to calorie estimation in private environments\",\"url\":\"https://www.semanticscholar.org/paper/5ce5ae9e855efa88724aa3f0c4b004862dc534d5\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"title\":\"View-Invariant Deep Architecture for Human Action Recognition Using Two-Stream Motion and Shape Temporal Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050512\",\"name\":\"Eman Mohammadi\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"145278886\",\"name\":\"M. Saif\"}],\"doi\":\"10.1109/SMC.2017.8122801\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fa93e140487b4ed1d233d7348411ab254148461\",\"title\":\"Improved rank pooling strategy for complex action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7fa93e140487b4ed1d233d7348411ab254148461\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":\"1706.08807\",\"authors\":[{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1007/978-3-319-66709-6_11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"edd7504be47ebc28b0d608502ca78c0aea6a65a2\",\"title\":\"Recurrent Residual Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/edd7504be47ebc28b0d608502ca78c0aea6a65a2\",\"venue\":\"GCPR\",\"year\":2017},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24944572\",\"name\":\"Shahela Saif\"},{\"authorId\":\"51935429\",\"name\":\"Samabia Tehseen\"},{\"authorId\":\"1880755\",\"name\":\"Sumaira Kausar\"}],\"doi\":\"10.3390/s18113979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe4aa088362d371daf15ccf9290291c8867e4f23\",\"title\":\"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/fe4aa088362d371daf15ccf9290291c8867e4f23\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.09659\",\"authors\":[{\"authorId\":\"2329625\",\"name\":\"Yunhui Guo\"},{\"authorId\":\"1527095795\",\"name\":\"Yandong Li\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"3560620\",\"name\":\"T. Simunic\"}],\"doi\":\"10.1609/AAAI.V34I04.5824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cf9f5643f0485f6910cfd76fa8951459bccf931\",\"title\":\"AdaFilter: Adaptive Filter Fine-tuning for Deep Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/5cf9f5643f0485f6910cfd76fa8951459bccf931\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50117915\",\"name\":\"Y. Wu\"},{\"authorId\":\"37108050\",\"name\":\"S. Drucker\"},{\"authorId\":\"3041721\",\"name\":\"M. Philipose\"},{\"authorId\":\"40125198\",\"name\":\"L. Ravindranath\"}],\"doi\":\"10.1145/3209900.3209909\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8494ea1faf92982a2c6bf07674eeb6201a13b70d\",\"title\":\"Querying Videos Using DNN Generated Labels\",\"url\":\"https://www.semanticscholar.org/paper/8494ea1faf92982a2c6bf07674eeb6201a13b70d\",\"venue\":\"HILDA@SIGMOD\",\"year\":2018},{\"arxivId\":\"1907.05640\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2884918\",\"name\":\"M. Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"title\":\"AVD: Adversarial Video Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"1409918228\",\"name\":\"Xin Ma\"},{\"authorId\":\"9348561\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/TMM.2019.2953814\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9433095a4a5339815bc0fc000971797e99babdda\",\"title\":\"Convolutional Networks With Channel and STIPs Attention Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9433095a4a5339815bc0fc000971797e99babdda\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89909440\",\"name\":\"Se\\u00e1n Bruton\"},{\"authorId\":\"89087926\",\"name\":\"D. Ganter\"},{\"authorId\":\"1790513\",\"name\":\"M. Manzke\"}],\"doi\":\"10.1007/978-3-030-41590-7_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0118366a4a6a88d5dc890ff1d719e957c64b6692\",\"title\":\"Fast Approximate Light Field Volume Rendering: Using Volume Data to Improve Light Field Synthesis via Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0118366a4a6a88d5dc890ff1d719e957c64b6692\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35605350\",\"name\":\"Kankana Roy\"},{\"authorId\":\"31629324\",\"name\":\"R. R. Sahay\"}],\"doi\":\"10.1145/3293353.3293398\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1ed110bffa5b07de5e6c52cb8878de1cb76d0f9\",\"title\":\"Dynamic Gesture Recognition with Pose-based CNN Features derived from videos using LSTM\",\"url\":\"https://www.semanticscholar.org/paper/d1ed110bffa5b07de5e6c52cb8878de1cb76d0f9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"},{\"authorId\":\"152994876\",\"name\":\"Yunfeng Ji\"},{\"authorId\":\"144560368\",\"name\":\"M. Ye\"},{\"authorId\":\"46636010\",\"name\":\"Y. Gan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2983355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"title\":\"An Improved Attention-Based Spatiotemporal-Stream Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1016/J.INFRARED.2019.103014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"title\":\"Deep residual infrared action recognition by integrating local and global spatio-temporal cues\",\"url\":\"https://www.semanticscholar.org/paper/45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38764391\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"50561740\",\"name\":\"J. Zhang\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2017.2758524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"title\":\"Discriminative Part Selection for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"title\":\"Efficient and Effective Solutions for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2003.01888\",\"authors\":[{\"authorId\":\"1966561\",\"name\":\"S. Ghorbani\"},{\"authorId\":\"1519541371\",\"name\":\"Kimia Mahdaviani\"},{\"authorId\":\"40481439\",\"name\":\"A. Thaler\"},{\"authorId\":\"36121677\",\"name\":\"Konrad P. K\\u00f6rding\"},{\"authorId\":\"32104861\",\"name\":\"D. J. Cook\"},{\"authorId\":\"2015591\",\"name\":\"G. Blohm\"},{\"authorId\":\"2932365\",\"name\":\"N. Troje\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"title\":\"MoVi: A Large Multipurpose Motion and Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1608.02059\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e48f2456533874e26c31125e9fd1affc4321560c\",\"title\":\"Signs in time: Encoding human motion as a temporal image\",\"url\":\"https://www.semanticscholar.org/paper/e48f2456533874e26c31125e9fd1affc4321560c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123482139\",\"name\":\"R. Singh\"},{\"authorId\":\"38825416\",\"name\":\"Jagwinder Kaur Dhillon\"},{\"authorId\":\"3016430\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s11042-018-6425-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fec13c887410dc27a2a16b058a0ea4d114f2d68\",\"title\":\"Depth based enlarged temporal dimension of 3D deep convolutional network for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/8fec13c887410dc27a2a16b058a0ea4d114f2d68\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"52217578\",\"name\":\"S. Alavi\"}],\"doi\":\"10.1109/ICWR49608.2020.9122304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"title\":\"Human Action Recognition in Video Using DB-LSTM and ResNet\",\"url\":\"https://www.semanticscholar.org/paper/e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"venue\":\"2020 6th International Conference on Web Research (ICWR)\",\"year\":2020},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"47740566\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"title\":\"Action recognition with gradient boundary convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46701988\",\"name\":\"Haimin Zhang\"},{\"authorId\":\"143679002\",\"name\":\"Min Xu\"}],\"doi\":\"10.1109/TMM.2018.2808760\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecd3975e55798972deb89708ebe9365f67b7eaf5\",\"title\":\"Recognition of Emotions in User-Generated Videos With Kernelized Features\",\"url\":\"https://www.semanticscholar.org/paper/ecd3975e55798972deb89708ebe9365f67b7eaf5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"50081274\",\"name\":\"L. Zhang\"},{\"authorId\":\"39271955\",\"name\":\"Zhiwen Fang\"},{\"authorId\":\"50748225\",\"name\":\"J. Du\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"},{\"authorId\":\"1500394276\",\"name\":\"Xiao Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2962229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"945b53ede48dae40af9870030fc4985a119cd1b8\",\"title\":\"Attention-Driven Loss for Anomaly Detection in Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/945b53ede48dae40af9870030fc4985a119cd1b8\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"1704.01716\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"29905643\",\"name\":\"Fatih Murat Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"title\":\"Action Representation Using Classifier Decision Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144207083\",\"name\":\"Renato Baptista\"},{\"authorId\":\"144910981\",\"name\":\"Michel Antunes\"},{\"authorId\":\"2949307\",\"name\":\"Djamila Aouada\"},{\"authorId\":\"145303200\",\"name\":\"B. Ottersten\"}],\"doi\":\"10.5220/0006648703800386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"766893e08f288d50ad457ed32e27331cc0d12347\",\"title\":\"Anticipating Suspicious Actions using a Small Dataset of Action Templates\",\"url\":\"https://www.semanticscholar.org/paper/766893e08f288d50ad457ed32e27331cc0d12347\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f865770fa62204783c475186fdb92d496362c2b9\",\"title\":\"Large-Scale Multimodal Gesture Recognition Using Heterogeneous Networks\",\"url\":\"https://www.semanticscholar.org/paper/f865770fa62204783c475186fdb92d496362c2b9\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50088038\",\"name\":\"Xiaoxi Ma\"},{\"authorId\":\"145662587\",\"name\":\"Lap-Pui Chau\"},{\"authorId\":\"145053416\",\"name\":\"Kim-Hui Yap\"},{\"authorId\":\"120241766\",\"name\":\"Guiju Ping\"}],\"doi\":\"10.1109/ISCAS.2019.8702447\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"875753906e277e693b892c6c51b3e7ac273fe46f\",\"title\":\"Convolutional Three-Stream Network Fusion for Driver Fatigue Detection from Infrared Videos\",\"url\":\"https://www.semanticscholar.org/paper/875753906e277e693b892c6c51b3e7ac273fe46f\",\"venue\":\"2019 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1812881\",\"name\":\"R. Li\"},{\"authorId\":\"144452270\",\"name\":\"B. Bhanu\"}],\"doi\":\"10.1109/CVPRW.2019.00299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4717e5ce7250cf8466b9987aadccd70f1eacf581\",\"title\":\"Fine-Grained Visual Dribbling Style Analysis for Soccer Videos With Augmented Dribble Energy Image\",\"url\":\"https://www.semanticscholar.org/paper/4717e5ce7250cf8466b9987aadccd70f1eacf581\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00052\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"title\":\"Improving a 3-D Convolutional Neural Network Model Reinvented from VGG16 with Batch Normalization\",\"url\":\"https://www.semanticscholar.org/paper/50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"10628657\",\"name\":\"Ming-liang Xu\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"}],\"doi\":\"10.1007/s11063-020-10320-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bdd5fdab9327c3d8dae8fd6acfb1c9400f69d4c\",\"title\":\"A Review of Dynamic Maps for 3D Human Motion Recognition Using ConvNets and Its Improvement\",\"url\":\"https://www.semanticscholar.org/paper/1bdd5fdab9327c3d8dae8fd6acfb1c9400f69d4c\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66471378\",\"name\":\"Allah Bux\"}],\"doi\":\"10.17635/LANCASTER/THESIS/186\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"title\":\"Vision-based human action recognition using machine learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"title\":\"Watch, Think and Attend: End-to-End Video Classification via Dynamic Knowledge Evolution Modeling\",\"url\":\"https://www.semanticscholar.org/paper/eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681148\",\"name\":\"L. Wang\"},{\"authorId\":\"3034546\",\"name\":\"Lianzheng Ge\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e378d5258615b542484fb519f2ca28b0ab1f1394\",\"title\":\"Three-stream CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e378d5258615b542484fb519f2ca28b0ab1f1394\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/CVPR.2017.604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1701.03246\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2017.26\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"title\":\"Ordered Pooling of Optical Flow Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.08583\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49733ccd65c087f3f0cf3d2235bed1b76f66e693\",\"title\":\"Sequence Summarization Using Order-constrained Kernelized Feature Subspaces\",\"url\":\"https://www.semanticscholar.org/paper/49733ccd65c087f3f0cf3d2235bed1b76f66e693\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.11064\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/CVPR.2018.00234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13d93feb5431eda200ac482b5230f51667c0146a\",\"title\":\"Non-linear Temporal Subspace Representations for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13d93feb5431eda200ac482b5230f51667c0146a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"49025023\",\"name\":\"J. Huang\"},{\"authorId\":\"2898447\",\"name\":\"Shanshan Huang\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"}],\"doi\":\"10.1109/SmartWorld.2018.00089\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"title\":\"Dynamic Representation Learning for Video Action Recognition Using Temporal Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1905.06326\",\"authors\":[{\"authorId\":\"2994471\",\"name\":\"X. Zhang\"},{\"authorId\":\"40353974\",\"name\":\"K. Matzen\"},{\"authorId\":\"50393245\",\"name\":\"Vivien L. Nguyen\"},{\"authorId\":\"144210947\",\"name\":\"Dillon Yao\"},{\"authorId\":\"49890547\",\"name\":\"You Zhang\"},{\"authorId\":\"47383180\",\"name\":\"R. Ng\"}],\"doi\":\"10.1145/3306346.3323015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4150bde5405df091ad07e59e2480fd651758712f\",\"title\":\"Synthetic defocus and look-ahead autofocus for casual videography\",\"url\":\"https://www.semanticscholar.org/paper/4150bde5405df091ad07e59e2480fd651758712f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52454948\",\"name\":\"A. Verma\"},{\"authorId\":\"2903495\",\"name\":\"T. Meenpal\"},{\"authorId\":\"2456349\",\"name\":\"Bibhudendra Acharya\"}],\"doi\":\"10.1111/coin.12419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"title\":\"Multiperson interaction recognition in images: A body keypoint based feature image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"153817519\",\"name\":\"S. E. Alavi\"}],\"doi\":\"10.22133/IJWR.2020.242723.1063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9064d8220c7fb8fde958d700b825bf03a757dc46\",\"title\":\"CoReHAR: A Hybrid Deep Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9064d8220c7fb8fde958d700b825bf03a757dc46\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1709.06447\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"939232314d39b26c89cd190c005b2ca71f14220a\",\"title\":\"Human Activity Recognition Using Robust Adaptive Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/939232314d39b26c89cd190c005b2ca71f14220a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8092281\",\"name\":\"Hai-Hong Phan\"},{\"authorId\":\"9923528\",\"name\":\"Chi Trung Ha\"},{\"authorId\":\"47523551\",\"name\":\"T. T. Nguy\\u1ec5n\"}],\"doi\":\"10.1109/MAPR49794.2020.9237772\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"title\":\"Improving the efficiency of human action recognition using deep compression\",\"url\":\"https://www.semanticscholar.org/paper/14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"venue\":\"2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143636222\",\"name\":\"J. Ahmad\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"143993371\",\"name\":\"M. Sajjad\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1109/ACCESS.2017.2778011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5979489e11edd76607c219a8bdc83ba4a88ab38\",\"title\":\"Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/b5979489e11edd76607c219a8bdc83ba4a88ab38\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"3087532\",\"name\":\"G. Anbarjafari\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"1743797\",\"name\":\"I. Guyon\"},{\"authorId\":\"1920611\",\"name\":\"M. Madadi\"},{\"authorId\":\"26987012\",\"name\":\"Juri Allik\"},{\"authorId\":\"19207190\",\"name\":\"Jelena Gorbova\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"30527170\",\"name\":\"Yiliang Xie\"}],\"doi\":\"10.1109/ICCVW.2017.377\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a6adefcb723a3e52f24987115cc3ae7f6d08283c\",\"title\":\"Results and Analysis of ChaLearn LAP Multi-modal Isolated and Continuous Gesture Recognition, and Real Versus Fake Expressed Emotions Challenges\",\"url\":\"https://www.semanticscholar.org/paper/a6adefcb723a3e52f24987115cc3ae7f6d08283c\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"47672419\",\"name\":\"S. Wang\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d325e891a7b97471219e7cc15a825c297ebb47c2\",\"title\":\"Structured Images for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d325e891a7b97471219e7cc15a825c297ebb47c2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"47748577\",\"name\":\"C. Ouyang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117135549\",\"name\":\"Kartik Wadehra\"},{\"authorId\":\"117483324\",\"name\":\"Mukul Kathpalia\"},{\"authorId\":\"114035976\",\"name\":\"Vasudha Bahl\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cd8a79bd1b63a215098f02ac1c4cd7ba7e7d3a9\",\"title\":\"Hand Detection and Gesture Recognition in Real-Time Using Haar-Classification and Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4cd8a79bd1b63a215098f02ac1c4cd7ba7e7d3a9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1909.08297\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"1950475\",\"name\":\"Z. Lu\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"145670268\",\"name\":\"C. Yao\"},{\"authorId\":\"51055776\",\"name\":\"Yanzi Deng\"}],\"doi\":\"10.1155/2018/5345241\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd7a3e809bc94a07f2604c1ec97d5e11080a993e\",\"title\":\"Transferable Feature Representation for Visible-to-Infrared Cross-Dataset Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd7a3e809bc94a07f2604c1ec97d5e11080a993e\",\"venue\":\"Complex.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"39952920\",\"name\":\"Q. Qin\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.patcog.2018.01.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa733992a236258adf36a41413b96707c8e9f4c\",\"title\":\"Multi-stream CNN: Learning representations based on human-related regions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/baa733992a236258adf36a41413b96707c8e9f4c\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144436761\",\"name\":\"Tao Hu\"},{\"authorId\":\"145584605\",\"name\":\"Jian Lv\"},{\"authorId\":\"49725675\",\"name\":\"Kang Yin\"},{\"authorId\":\"1792403\",\"name\":\"Qingsheng Xie\"},{\"authorId\":\"145959473\",\"name\":\"Hui Sun\"},{\"authorId\":\"47697415\",\"name\":\"Qingni Yuan\"}],\"doi\":\"10.3166/ts.34.153-173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"341685b5b4f723f316c6d5049208e131b3422f9b\",\"title\":\"A novel human behaviour information coding method based on eye-tracking technology\",\"url\":\"https://www.semanticscholar.org/paper/341685b5b4f723f316c6d5049208e131b3422f9b\",\"venue\":\"Traitement du Signal\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643920490\",\"name\":\".T AbijithVignesh\"},{\"authorId\":\"1643930323\",\"name\":\"K. AishwaryaP\"},{\"authorId\":\"1643919991\",\"name\":\"Dr.S. Sobitha Ahila\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f012362869e28130c2a50e51b87c01456f508c2a\",\"title\":\"COMMUNICATION AID FOR PARALYZED PEOPLE BY EYELID TRACKING\",\"url\":\"https://www.semanticscholar.org/paper/f012362869e28130c2a50e51b87c01456f508c2a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"641421832f237b280644261a77eca3974ac9c0c1\",\"title\":\"Discriminative Hierarchical Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/641421832f237b280644261a77eca3974ac9c0c1\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.00558\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW.2017.205\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57c59011614c43f51a509e10717e47505c776389\",\"title\":\"Unsupervised Human Action Detection by Action Matching\",\"url\":\"https://www.semanticscholar.org/paper/57c59011614c43f51a509e10717e47505c776389\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"1452347342\",\"name\":\"M. Saxena\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/BigMM.2019.00-21\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ea36c13fd2ae92c8f5ef27d985f074b9e93e62e0\",\"title\":\"Skeleton-Based View Invariant Deep Features for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea36c13fd2ae92c8f5ef27d985f074b9e93e62e0\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007311898\",\"name\":\"Yangyang Qiao\"},{\"authorId\":\"2007310586\",\"name\":\"Whenhua Cui\"},{\"authorId\":\"1838022\",\"name\":\"Tianwei Shi\"}],\"doi\":\"10.1109/ACCESS.2020.3032533\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a19004227240cd365422eaa00b589469897a3d7\",\"title\":\"LaM-2SRN: A Method Which Can Enhance Local Features and Detect Moving Objects for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a19004227240cd365422eaa00b589469897a3d7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144732200\",\"name\":\"Bo Lin\"},{\"authorId\":\"143762036\",\"name\":\"B. Fang\"},{\"authorId\":\"2781714\",\"name\":\"Weibin Yang\"},{\"authorId\":\"2543829\",\"name\":\"Jiye Qian\"}],\"doi\":\"10.1016/J.NEUCOM.2018.05.121\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"733c9221c92fcd7b2c339ac1872a8d1331579d9b\",\"title\":\"Human action recognition based on spatio-temporal three-dimensional scattering transform descriptor and an improved VLAD feature encoding algorithm\",\"url\":\"https://www.semanticscholar.org/paper/733c9221c92fcd7b2c339ac1872a8d1331579d9b\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.00097\",\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"title\":\"Budget-Aware Activity Detection with A Recurrent Policy Network\",\"url\":\"https://www.semanticscholar.org/paper/11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38286801\",\"name\":\"Massimiliano Mancini\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1752593147\",\"name\":\"Barbara Caputo\"},{\"authorId\":\"1752580929\",\"name\":\"Samuel Rota Bul\\u00f2\"}],\"doi\":\"10.1007/s00138-020-01090-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4bb9e6150c483208224f7694d140afa359d1a1d\",\"title\":\"Boosting binary masks for multi-domain learning through affine transformations\",\"url\":\"https://www.semanticscholar.org/paper/e4bb9e6150c483208224f7694d140afa359d1a1d\",\"venue\":\"Machine Vision and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ISCAS.2018.8350912\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"title\":\"A 65 fps Full-HD Hardware Implementation of HOG, HOF, MBHx, and MBHy for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7769579\",\"name\":\"Zhikang Liu\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"}],\"doi\":\"10.1109/ICIP.2017.8296405\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81d232e1f432db7de67baf4f30f240c62d1a9055\",\"title\":\"Improving human action recognitionby temporal attention\",\"url\":\"https://www.semanticscholar.org/paper/81d232e1f432db7de67baf4f30f240c62d1a9055\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"title\":\"Making Convolutional Networks Recurrent for Visual Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"47557959\",\"name\":\"Y. Chen\"},{\"authorId\":\"47462870\",\"name\":\"Ruotao Xu\"},{\"authorId\":\"153172100\",\"name\":\"Hui Ji\"}],\"doi\":\"10.1016/J.CVIU.2019.102794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"title\":\"Attention with structure regularization for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12080269\",\"name\":\"Kun Niu\"},{\"authorId\":\"3190225\",\"name\":\"Huiyang Zhang\"},{\"authorId\":\"144137458\",\"name\":\"T. Zhou\"},{\"authorId\":\"93250272\",\"name\":\"C. Cheng\"},{\"authorId\":null,\"name\":\"Chao Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2902185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"899fab9290588ad796ab7adb786d72f3e6a4595e\",\"title\":\"A Novel Spatio-Temporal Model for City-Scale Traffic Speed Prediction\",\"url\":\"https://www.semanticscholar.org/paper/899fab9290588ad796ab7adb786d72f3e6a4595e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.06.071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"title\":\"Action recognition using spatial-optical data organization and sequential learning framework\",\"url\":\"https://www.semanticscholar.org/paper/f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-319-77380-3_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47cddc8b450fa9e766c6ce5c9696f59e06bfd604\",\"title\":\"Representing Discrimination of Video by a Motion Map\",\"url\":\"https://www.semanticscholar.org/paper/47cddc8b450fa9e766c6ce5c9696f59e06bfd604\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1705.08045\",\"authors\":[{\"authorId\":\"8478422\",\"name\":\"Sylvestre-Alvise Rebuffi\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d89ee98810039d2061ed42ee8026da49c503d16b\",\"title\":\"Learning multiple visual domains with residual adapters\",\"url\":\"https://www.semanticscholar.org/paper/d89ee98810039d2061ed42ee8026da49c503d16b\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1016/j.jvcir.2017.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"title\":\"A novel recurrent hybrid network for feature fusion in action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f23b737af93469efc4b7438377a3cec2e9c8febb\",\"title\":\"Ju l 2 01 8 Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f23b737af93469efc4b7438377a3cec2e9c8febb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ICASSP.2018.8461988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"title\":\"A 203 FPS VLSI Architecture of Improved Dense Trajectories for Real-Time Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2018.2877936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"title\":\"Toward Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2018.00840\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9baf01eb53abda6a169110477f2c7a3492559368\",\"title\":\"Learning and Using the Arrow of Time\",\"url\":\"https://www.semanticscholar.org/paper/9baf01eb53abda6a169110477f2c7a3492559368\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1922466081\",\"name\":\"Aayush Jain\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/ICSSIT48917.2020.9214153\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd0c68b39c353184077934b0726652a4dac44f97\",\"title\":\"Deep NeuralNet For Violence Detection Using Motion Features From Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/cd0c68b39c353184077934b0726652a4dac44f97\",\"venue\":\"2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9127897\",\"name\":\"A. Sasithradevi\"},{\"authorId\":\"2010132\",\"name\":\"S. Roomi\"}],\"doi\":\"10.1016/j.patcog.2019.107099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96e1bde6095d0db64ff46c689fda3d27ce0c02c8\",\"title\":\"Video classification and retrieval through spatio-temporal Radon features\",\"url\":\"https://www.semanticscholar.org/paper/96e1bde6095d0db64ff46c689fda3d27ce0c02c8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1904.09410\",\"authors\":[{\"authorId\":\"145809610\",\"name\":\"M. Verma\"},{\"authorId\":\"145353981\",\"name\":\"S. K. Vipparthi\"},{\"authorId\":\"39528728\",\"name\":\"Girdhari Singh\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/TIP.2019.2912358\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"008b957f8542860a2c6dbd4e27760f426a311dd0\",\"title\":\"LEARNet: Dynamic Imaging Network for Micro Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/008b957f8542860a2c6dbd4e27760f426a311dd0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2441809\",\"name\":\"A. Azcarraga\"}],\"doi\":\"10.1007/978-3-030-16142-2_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"702db9076b1851184e828d1eec7dc8808df537f1\",\"title\":\"Characterizing the SOM Feature Detectors Under Various Input Conditions\",\"url\":\"https://www.semanticscholar.org/paper/702db9076b1851184e828d1eec7dc8808df537f1\",\"venue\":\"PAKDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121030\",\"name\":\"Rajiv Singh\"},{\"authorId\":\"39727023\",\"name\":\"Swati Nigam\"}],\"doi\":\"10.1007/978-3-030-15887-3_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"title\":\"Deep Neural Networks for Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"venue\":\"Handbook of Multimedia Information Security\",\"year\":2019},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1604.06506\",\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-46454-1_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"574ab231627eadc1056162c38d0895f372121250\",\"title\":\"Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/574ab231627eadc1056162c38d0895f372121250\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491438016\",\"name\":\"Yuanye Fang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-030-39431-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"title\":\"Action Recognition in Videos with Temporal Segments Fusions\",\"url\":\"https://www.semanticscholar.org/paper/d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"48447152\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/ICME.2017.8019438\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"103c4fb711ffa318d9e1e8586df4664790ab63e1\",\"title\":\"3D action recognition using data visualization and convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/103c4fb711ffa318d9e1e8586df4664790ab63e1\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"},{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"5810483\",\"name\":\"R. Bom\"}],\"doi\":\"10.1007/978-3-030-25590-9_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"title\":\"Human Activity Identification in Smart Daily Environments\",\"url\":\"https://www.semanticscholar.org/paper/0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1016/j.jvcir.2020.102772\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46302cdf6eb829ba2f7582469ad50dd0a40fd856\",\"title\":\"Multimodal hand gesture recognition combining temporal and pose information based on CNN descriptors and histogram of cumulative magnitudes\",\"url\":\"https://www.semanticscholar.org/paper/46302cdf6eb829ba2f7582469ad50dd0a40fd856\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/DICTA.2017.8227428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b8b33481e92189044fd595ed9d177812017e0f3\",\"title\":\"Evaluation of Triple-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b8b33481e92189044fd595ed9d177812017e0f3\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP7010110\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a87e37d43d4c47bef8992ace408de0f872739efc\",\"title\":\"A Comprehensive Review on Handcrafted and Learning-Based Action Representation Approaches for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a87e37d43d4c47bef8992ace408de0f872739efc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47952527\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"40165419\",\"name\":\"M. Jaber\"},{\"authorId\":\"1694755\",\"name\":\"P. Tsakalides\"}],\"doi\":\"10.2352/ISSN.2470-1173.2018.2.VIPC-206\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed8950e10b57317b210c3868b3600aa7807a385a\",\"title\":\"Convolutional neural networks for the analysis of broadcasted tennis games\",\"url\":\"https://www.semanticscholar.org/paper/ed8950e10b57317b210c3868b3600aa7807a385a\",\"venue\":\"Visual Information Processing and Communication\",\"year\":2018},{\"arxivId\":\"1804.01194\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/TMM.2018.2818329\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"449dd87d10059ddfd345fed425af44d11dc7f812\",\"title\":\"Depth Pooling Based Large-Scale 3-D Action Recognition With Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/449dd87d10059ddfd345fed425af44d11dc7f812\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410106115\",\"name\":\"Tieu Binh Hoang\"},{\"authorId\":\"29543391\",\"name\":\"T. C. Ma\"},{\"authorId\":\"71752568\",\"name\":\"Sugimoto Akihiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"title\":\"Selecting active frames for action recognition with 3D convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.09342\",\"authors\":[{\"authorId\":\"1390977843\",\"name\":\"Jiateng Liu\"},{\"authorId\":\"40608983\",\"name\":\"W. Zheng\"},{\"authorId\":\"48115912\",\"name\":\"Yuan Zong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f1d816fe056d2614cd02f19c42b7b1a6a28f70c7\",\"title\":\"SMA-STN: Segmented Movement-Attending Spatiotemporal Network forMicro-Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1d816fe056d2614cd02f19c42b7b1a6a28f70c7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.09058\",\"authors\":[{\"authorId\":\"38286801\",\"name\":\"Massimiliano Mancini\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5937e2ee2c35da2b511c06a3ff3ea637e01835a\",\"title\":\"Towards Recognizing New Semantic Concepts in New Visual Domains\",\"url\":\"https://www.semanticscholar.org/paper/f5937e2ee2c35da2b511c06a3ff3ea637e01835a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"title\":\"Two-Stage Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"60d4cef56efd2f5452362d4d9ac1ae05afa970d1\",\"title\":\"Learning End-to-end Video Classification with Rank-Pooling\",\"url\":\"https://www.semanticscholar.org/paper/60d4cef56efd2f5452362d4d9ac1ae05afa970d1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49658876\",\"name\":\"Z. Zhu\"},{\"authorId\":\"153172093\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"73312165\",\"name\":\"Wen-bo Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.12.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"title\":\"Nonlinear gated channels networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/ICCVW.2017.375\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f0a0c9552ff698f613439a4c095e24431c3ce2b\",\"title\":\"Darwintrees for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f0a0c9552ff698f613439a4c095e24431c3ce2b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51161370\",\"name\":\"Sarah Taghavi Namin\"},{\"authorId\":\"8940956\",\"name\":\"Mohammad Esmaeilzadeh\"},{\"authorId\":\"50643503\",\"name\":\"Mohammad Najafi\"},{\"authorId\":\"32257370\",\"name\":\"T. Brown\"},{\"authorId\":\"2081020\",\"name\":\"J. Borevitz\"}],\"doi\":\"10.1186/s13007-018-0333-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11a604339d767d8718fefc589dbdcf548b899f15\",\"title\":\"Deep phenotyping: deep learning for temporal phenotype/genotype classification\",\"url\":\"https://www.semanticscholar.org/paper/11a604339d767d8718fefc589dbdcf548b899f15\",\"venue\":\"Plant Methods\",\"year\":2018},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2017.8296542\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"title\":\"Cascaded temporal spatial features for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3293353.3293363\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"title\":\"Multimodal Egocentric Activity Recognition Using Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2006.04843\",\"authors\":[{\"authorId\":\"138894940\",\"name\":\"Soren Pirk\"},{\"authorId\":\"1944801\",\"name\":\"Karol Hausman\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"30559411\",\"name\":\"Mohi Khansari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20f3973efecab0ee66adcb07dc33b7cdcfbfecf7\",\"title\":\"Modeling Long-horizon Tasks as Sequential Interaction Landscapes\",\"url\":\"https://www.semanticscholar.org/paper/20f3973efecab0ee66adcb07dc33b7cdcfbfecf7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945620\",\"name\":\"Tejinderpal Singh\"},{\"authorId\":\"2454842\",\"name\":\"S. Rustagi\"},{\"authorId\":\"1452345079\",\"name\":\"Aakash Garg\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/BigMM.2019.00-19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7dc306f2cfa6da783dd89b47cf4d5419656936f\",\"title\":\"Deep Learning Framework for Single and Dyadic Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b7dc306f2cfa6da783dd89b47cf4d5419656936f\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"48447152\",\"name\":\"H. Liu\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.patcog.2017.02.030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"928742fae8f5f6e3142cdab1976e9198e21092c6\",\"title\":\"Enhanced skeleton visualization for view invariant human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/928742fae8f5f6e3142cdab1976e9198e21092c6\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29715401\",\"name\":\"Q. Liu\"},{\"authorId\":\"144104145\",\"name\":\"Y. Qin\"},{\"authorId\":\"2122760\",\"name\":\"ZhengYu Xie\"},{\"authorId\":\"2630374\",\"name\":\"Tangwen Yang\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"}],\"doi\":\"10.1007/978-981-10-7989-4_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34f0933074287dc6986dbd555944f952a91a8634\",\"title\":\"Intrusion Detection for High-Speed Railway Perimeter Obstacle\",\"url\":\"https://www.semanticscholar.org/paper/34f0933074287dc6986dbd555944f952a91a8634\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"}],\"doi\":\"10.32657/10356/70099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"title\":\"Pose-invariant action recognition for automated behaviour analysis\",\"url\":\"https://www.semanticscholar.org/paper/fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50025139\",\"name\":\"Yunan Li\"},{\"authorId\":\"144145103\",\"name\":\"Qiguang Miao\"},{\"authorId\":\"3380556\",\"name\":\"Kuan Tian\"},{\"authorId\":\"40348704\",\"name\":\"Yingying Fan\"},{\"authorId\":\"145880437\",\"name\":\"Xin Xu\"},{\"authorId\":\"9249689\",\"name\":\"Zhenxin Ma\"},{\"authorId\":\"1757283\",\"name\":\"Jianfeng Song\"}],\"doi\":\"10.1016/J.PATREC.2017.12.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c974e23937c43228d3daf3926b1a52cc8fe6f80\",\"title\":\"Large-scale gesture recognition with a fusion of RGB-D data based on optical flow and the C3D model\",\"url\":\"https://www.semanticscholar.org/paper/0c974e23937c43228d3daf3926b1a52cc8fe6f80\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1705.10420\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-017-1030-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5615d6045301ecbc5be35e46cab711f676aadf3a\",\"title\":\"Discriminatively Learned Hierarchical Rank Pooling Networks\",\"url\":\"https://www.semanticscholar.org/paper/5615d6045301ecbc5be35e46cab711f676aadf3a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39691613\",\"name\":\"H. Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2018.00175\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"title\":\"Instance-Aware Detailed Action Labeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51427490\",\"name\":\"Edwin Escobedo\"},{\"authorId\":\"108202338\",\"name\":\"L. Ram\\u00edrez\"},{\"authorId\":\"51363101\",\"name\":\"G. C\\u00e1mara\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00043\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f32fdc91b27cf4782ba21eed6208d7dc13e632be\",\"title\":\"Dynamic Sign Language Recognition Based on Convolutional Neural Networks and Texture Maps\",\"url\":\"https://www.semanticscholar.org/paper/f32fdc91b27cf4782ba21eed6208d7dc13e632be\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35258643\",\"name\":\"S. Jothi\"},{\"authorId\":null,\"name\":\"Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.35940/ijitee.i7914.078919\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"611dc0fa4b0beb0ac8fa0bf3bbf24f089adf3fe5\",\"title\":\"Anomaly Detection in Video Events using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/611dc0fa4b0beb0ac8fa0bf3bbf24f089adf3fe5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/s00371-019-01725-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"812cfc1f88008476dc2ae90d0117065a4001a81b\",\"title\":\"Deep motion templates and extreme learning machine for sign language recognition\",\"url\":\"https://www.semanticscholar.org/paper/812cfc1f88008476dc2ae90d0117065a4001a81b\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"4509077\",\"name\":\"Xiaowei Gu\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"152734957\",\"name\":\"Zulfiqar Habib\"}],\"doi\":\"10.1007/s11042-020-09381-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"title\":\"Human action recognition using deep rule-based classifier\",\"url\":\"https://www.semanticscholar.org/paper/8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1910.00714\",\"authors\":[{\"authorId\":\"65914312\",\"name\":\"Clebeson Canuto dos Santos\"},{\"authorId\":\"1746258\",\"name\":\"P. Moreno\"},{\"authorId\":\"143622442\",\"name\":\"J. A. Samatelo\"},{\"authorId\":\"21859276\",\"name\":\"Raquel Frizera Vassallo\"},{\"authorId\":\"1398909021\",\"name\":\"J. Santos-Victor\"}],\"doi\":\"10.1016/j.neucom.2020.07.135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5569fdf87bab94014615a04c1ad16204180e7d1\",\"title\":\"Action Anticipation for Collaborative Environments: The Impact of Contextual Information and Uncertainty-Based Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d5569fdf87bab94014615a04c1ad16204180e7d1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145318418\",\"name\":\"X. Ma\"},{\"authorId\":\"8180253\",\"name\":\"Bing-Kun Bao\"},{\"authorId\":\"8012449\",\"name\":\"Lingling Yao\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICIP.2019.8803561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83813c661c18dbca63ed8d8b1838f883fa6c4751\",\"title\":\"Multimodal Latent Factor Model with Language Constraint for Predicate Detection\",\"url\":\"https://www.semanticscholar.org/paper/83813c661c18dbca63ed8d8b1838f883fa6c4751\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819203\",\"name\":\"Zufan Zhang\"},{\"authorId\":\"2000399066\",\"name\":\"Zongming Lv\"},{\"authorId\":\"2901849\",\"name\":\"Chenquan Gan\"},{\"authorId\":\"145649216\",\"name\":\"Qingyi Zhu\"}],\"doi\":\"10.1016/j.neucom.2020.06.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"851edff1c8deded530836d0338ea6cbe50f30594\",\"title\":\"Human action recognition using convolutional LSTM and fully-connected LSTM with different attentions\",\"url\":\"https://www.semanticscholar.org/paper/851edff1c8deded530836d0338ea6cbe50f30594\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"48239558\",\"name\":\"Chen Chen\"},{\"authorId\":\"48447152\",\"name\":\"H. Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"81b31bf02ebb7b6e4f90f4650ce30a73321cea3d\",\"title\":\"3 D ACTION RECOGNITION USING DATA VISUALIZATION AND CONVOLUTIONAL NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/81b31bf02ebb7b6e4f90f4650ce30a73321cea3d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.04668\",\"authors\":[{\"authorId\":\"2133342\",\"name\":\"Mohammadreza Babaee\"},{\"authorId\":\"119389363\",\"name\":\"David Full\"},{\"authorId\":\"145512909\",\"name\":\"Gerhard Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"138aedf23346d7d5a4a8c38c935735a436f7c839\",\"title\":\"On Flow Profile Image for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/138aedf23346d7d5a4a8c38c935735a436f7c839\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7680552\",\"name\":\"Ziliang Ren\"},{\"authorId\":\"51286715\",\"name\":\"Qieshi Zhang\"},{\"authorId\":\"46757766\",\"name\":\"X. Gao\"},{\"authorId\":\"51289240\",\"name\":\"Pengyi Hao\"},{\"authorId\":\"114675671\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1007/s11042-019-08576-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"683646753df25cb5ad91bdecc4bf6bb7bdf2f0bf\",\"title\":\"Multi-modality learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/683646753df25cb5ad91bdecc4bf6bb7bdf2f0bf\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patrec.2018.07.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"403f756f9f18948994e7a650ccb0be359d695530\",\"title\":\"Joint spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/403f756f9f18948994e7a650ccb0be359d695530\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2012.10283\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"title\":\"Temporal Bilinear Encoding Network of Audio-Visual Features at Low Sampling Rates\",\"url\":\"https://www.semanticscholar.org/paper/eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49897466\",\"name\":\"Xiaotian Zhu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551526\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"35cbb64d46dfa3e74aea367a173dcb94cb6125c4\",\"title\":\"Weighted Multi-Region Convolutional Neural Network for Action Recognition With Low-Latency Online Prediction\",\"url\":\"https://www.semanticscholar.org/paper/35cbb64d46dfa3e74aea367a173dcb94cb6125c4\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/LSP.2018.2843295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f2ddd35090bf4220c97f0bf1d87f76121c15963\",\"title\":\"Self-Paced AutoEncoder\",\"url\":\"https://www.semanticscholar.org/paper/0f2ddd35090bf4220c97f0bf1d87f76121c15963\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005372\",\"name\":\"Abdourrahmane M. Atto\"},{\"authorId\":\"144373800\",\"name\":\"A. Benoit\"},{\"authorId\":\"47858467\",\"name\":\"P. Lambert\"}],\"doi\":\"10.1016/j.patcog.2020.107353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d767c20bd91fc785b170e271a15508f56ee92fc4\",\"title\":\"Timed-image based deep learning for action recognition in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/d767c20bd91fc785b170e271a15508f56ee92fc4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1801.04134\",\"authors\":[{\"authorId\":\"35309584\",\"name\":\"Jonas Rothfuss\"},{\"authorId\":\"145839029\",\"name\":\"F. Ferreira\"},{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"46432716\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/LRA.2018.2860057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"970a8f1655ab329cba5fe26edf543e62fe354376\",\"title\":\"Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution\",\"url\":\"https://www.semanticscholar.org/paper/970a8f1655ab329cba5fe26edf543e62fe354376\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"50695608\",\"name\":\"S. Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ACCESS.2017.2782258\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"437db0cbf29b447cea2e090d26ba0cebb6d7aba3\",\"title\":\"Spatially and Temporally Structured Global to Local Aggregation of Dynamic Depth Information for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/437db0cbf29b447cea2e090d26ba0cebb6d7aba3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"- ING\"},{\"authorId\":\"69354043\",\"name\":\"Ang\"},{\"authorId\":null,\"name\":\"- IDA\"},{\"authorId\":\"102770090\",\"name\":\"Ussain\"},{\"authorId\":null,\"name\":\"- ESONG\"},{\"authorId\":\"115925168\",\"name\":\"Ei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"title\":\"Trajectory-based 3D Convolutional Descriptors for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31573550\",\"name\":\"Alejandro Hernandez Ruiz\"},{\"authorId\":\"3202308\",\"name\":\"Lorenzo Porzi\"},{\"authorId\":\"2145174\",\"name\":\"Samuel Rota Bul\\u00f2\"},{\"authorId\":\"1397181875\",\"name\":\"Francesc Moreno-Noguer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f2a89f22981e332bc4a47a3ba74f0d202aec64e\",\"title\":\"CNNs on Distance Matrices for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f2a89f22981e332bc4a47a3ba74f0d202aec64e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30075877\",\"name\":\"W. Ye\"},{\"authorId\":\"120971374\",\"name\":\"J. Cheng\"},{\"authorId\":\"145976802\",\"name\":\"F. Yang\"},{\"authorId\":\"48615395\",\"name\":\"Y. Xu\"}],\"doi\":\"10.1109/access.2019.2918808\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"title\":\"Two-Stream Convolutional Network for Improving Activity Recognition Using Convolutional Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576171686\",\"name\":\"Denys Volodymyrovych Soldatov\"}],\"doi\":\"10.20535/2617-0965.2019.2.3.164709\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"949981340608476488f5e287f9828546c64d9132\",\"title\":\"Action and movements recognition methods\",\"url\":\"https://www.semanticscholar.org/paper/949981340608476488f5e287f9828546c64d9132\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46528640\",\"name\":\"H. T. Binh\"},{\"authorId\":\"9283769\",\"name\":\"Ma Thi Chau\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"9349062\",\"name\":\"B. Duy\"}],\"doi\":\"10.1109/ICCCE.2018.8539313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3901f177642912be3fd132807a1e7d16796d1011\",\"title\":\"Selecting active frames for action recognition with vote fusion method\",\"url\":\"https://www.semanticscholar.org/paper/3901f177642912be3fd132807a1e7d16796d1011\",\"venue\":\"2018 7th International Conference on Computer and Communication Engineering (ICCCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120899385\",\"name\":\"Ruolin Huang\"},{\"authorId\":\"2488122\",\"name\":\"Hongbin Dong\"},{\"authorId\":\"1775866\",\"name\":\"Guisheng Yin\"},{\"authorId\":\"145142015\",\"name\":\"Q. Fu\"}],\"doi\":\"10.1109/IJCNN.2019.8852054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d05d78ebc53fad692942e84cc80d260131a2618\",\"title\":\"Ensembling 3D CNN Framework for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d05d78ebc53fad692942e84cc80d260131a2618\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2799968\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"title\":\"Multi-Modality Multi-Task Recurrent Neural Network for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153154393\",\"name\":\"J. Li\"},{\"authorId\":\"3085483\",\"name\":\"S. Xia\"},{\"authorId\":\"153641684\",\"name\":\"Q. Ding\"}],\"doi\":\"10.1145/3372278.3390702\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"98b1c9c1dfe23cf5478f7ff45c641a5576b66107\",\"title\":\"Multi-level Recognition on Falls from Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/98b1c9c1dfe23cf5478f7ff45c641a5576b66107\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119924024\",\"name\":\"Yinan Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"}],\"doi\":\"10.1109/ACCESS.2017.2753830\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c90427085909029afd2af01d1967e80b78e01b88\",\"title\":\"Gaze-Assisted Multi-Stream Deep Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c90427085909029afd2af01d1967e80b78e01b88\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1109/SIBGRAPI.2018.00019\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f5ad27ac1c33c4964848fdc85427ba2465b5b3f5\",\"title\":\"Multimodal Human Action Recognition Based on a Fusion of Dynamic Images Using CNN Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/f5ad27ac1c33c4964848fdc85427ba2465b5b3f5\",\"venue\":\"SIBGRAPI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001082\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"1755153\",\"name\":\"N. M. Charkari\"}],\"doi\":\"10.1049/iet-cvi.2016.0355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"title\":\"Survey on deep learning methods in human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1049/iet-cvi.2017.0005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"title\":\"Fully convolutional networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007998\",\"name\":\"Lars Andersson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"39271955\",\"name\":\"Zhiwen Fang\"}],\"doi\":\"10.1117/12.2285518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"title\":\"Action recognition in depth video from RGB perspective: A knowledge transfer manner\",\"url\":\"https://www.semanticscholar.org/paper/e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"1414105614\",\"name\":\"Tehseen Ul-Hassan\"},{\"authorId\":\"14858604\",\"name\":\"F. Hussain\"},{\"authorId\":\"152924726\",\"name\":\"Jing Wang\"},{\"authorId\":\"144506603\",\"name\":\"Zesong Fei\"}],\"doi\":\"10.1080/1206212X.2018.1486001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"title\":\"Video representation by dense trajectories motion map applied to human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47598805\",\"name\":\"Qing Wang\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"145235303\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1007/978-3-319-77380-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5107d9fa904543b7080b384435a59a6f8def60c4\",\"title\":\"Temporal Interval Regression Network for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/5107d9fa904543b7080b384435a59a6f8def60c4\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/s11042-017-4795-6\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"98127346920bdce9773aba6a2ffc8590b9558a4a\",\"title\":\"Efficient human action recognition using histograms of motion gradients and VLAD with descriptor shape information\",\"url\":\"https://www.semanticscholar.org/paper/98127346920bdce9773aba6a2ffc8590b9558a4a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"2977267\",\"name\":\"A. P. Cl\\u00e1udio\"},{\"authorId\":\"1767919\",\"name\":\"K. Bouatouch\"},{\"authorId\":\"2571670\",\"name\":\"Manuela Chessa\"},{\"authorId\":\"1717982\",\"name\":\"A. Paljic\"},{\"authorId\":\"2569160\",\"name\":\"A. Kerren\"},{\"authorId\":\"2433007\",\"name\":\"C. Hurter\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"}],\"doi\":\"10.1007/978-3-030-41590-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfd34a5453210cfd476d9ba8e2be5c47fcb7eaf7\",\"title\":\"Computer Vision, Imaging and Computer Graphics Theory and Applications: 14th International Joint Conference, VISIGRAPP 2019, Prague, Czech Republic, February 25\\u201327, 2019, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/bfd34a5453210cfd476d9ba8e2be5c47fcb7eaf7\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1801.07230\",\"authors\":[{\"authorId\":\"2308598\",\"name\":\"U. Ahsan\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f6d6c99fe5011d925d892725ff0c8cbbd7db3ba\",\"title\":\"DiscrimNet: Semi-Supervised Action Recognition from Videos using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5f6d6c99fe5011d925d892725ff0c8cbbd7db3ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.04741\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"250fabf66752c8729cbf286eadab271bd04da710\",\"title\":\"Generative Models for Novelty Detection: Applications in abnormal event and situational change detection from data series\",\"url\":\"https://www.semanticscholar.org/paper/250fabf66752c8729cbf286eadab271bd04da710\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89909440\",\"name\":\"Se\\u00e1n Bruton\"},{\"authorId\":\"89087926\",\"name\":\"D. Ganter\"},{\"authorId\":\"1790513\",\"name\":\"M. Manzke\"}],\"doi\":\"10.5220/0007407200960105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34ba8ce89e54bef43848e9487ff0982bdc4ff822\",\"title\":\"Synthesising Light Field Volumetric Visualizations in Real-time using a Compressed Volume Representation\",\"url\":\"https://www.semanticscholar.org/paper/34ba8ce89e54bef43848e9487ff0982bdc4ff822\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1708.09644\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ICIP.2017.8296547\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d5290fadb7625862a966e0330bd0f9e111fc99d\",\"title\":\"Abnormal event detection in videos using generative adversarial nets\",\"url\":\"https://www.semanticscholar.org/paper/9d5290fadb7625862a966e0330bd0f9e111fc99d\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1602.00224\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2019.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"title\":\"Order-aware Convolutional Pooling for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdde8d08733b4d9840089f8af07f042749675f\",\"title\":\"Deep network for human action recognition using Weber motion\",\"url\":\"https://www.semanticscholar.org/paper/66cdde8d08733b4d9840089f8af07f042749675f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7550195\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"47474011\",\"name\":\"M. Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":\"10.1145/3394171.3414003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"title\":\"Self-Paced Video Data Augmentation by Generative Adversarial Networks with Insufficient Samples\",\"url\":\"https://www.semanticscholar.org/paper/1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s11704-016-6066-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b9aa210e42ea808cc454be162fd1da0f6f3ea5\",\"title\":\"Attribute-based supervised deep learning model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/06b9aa210e42ea808cc454be162fd1da0f6f3ea5\",\"venue\":\"Frontiers of Computer Science\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571637\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/TIP.2018.2866688\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"title\":\"Learning Match Kernels on Grassmann Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2979082\",\"name\":\"M. Zhao\"},{\"authorId\":\"144025821\",\"name\":\"Chengquan Hu\"},{\"authorId\":\"66288759\",\"name\":\"Fenglin Wei\"},{\"authorId\":\"1728316\",\"name\":\"K. Wang\"},{\"authorId\":\"47074522\",\"name\":\"C. Wang\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.3390/s19020350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f604dafb11b5389de6fad09321e9551a79154eda\",\"title\":\"Real-Time Underwater Image Recognition with FPGA Embedded System for Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/f604dafb11b5389de6fad09321e9551a79154eda\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150296726\",\"name\":\"Shaunak Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b18ffc23de10bd246a238151f606eeba2dc2d7ad\",\"title\":\"Exploring neural networks for gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/b18ffc23de10bd246a238151f606eeba2dc2d7ad\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646959833\",\"name\":\"Yuecong Min\"},{\"authorId\":\"152550038\",\"name\":\"Xiujuan Chai\"},{\"authorId\":\"9055516\",\"name\":\"L. Zhao\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb74477f987459e27bc6b667b4535c378442bd6b\",\"title\":\"FlickerNet: Adaptive 3D Gesture Recognition from Sparse Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/fb74477f987459e27bc6b667b4535c378442bd6b\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1505718218\",\"name\":\"Shusheng Li\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/BigData47090.2019.9006260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ac91d8a72268deed399f6813cd7417b3440ddcf\",\"title\":\"VidAnomaly: LSTM-Autoencoder-Based Adversarial Learning for One-Class Video Classification With Multiple Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/3ac91d8a72268deed399f6813cd7417b3440ddcf\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94173091\",\"name\":\"Y. Wan\"},{\"authorId\":\"7822579\",\"name\":\"Zujun Yu\"},{\"authorId\":null,\"name\":\"Yao Wang\"},{\"authorId\":\"50079335\",\"name\":\"Xingxin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2993227\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"title\":\"Action Recognition Based on Two-Stream Convolutional Networks With Long-Short-Term Spatiotemporal Features\",\"url\":\"https://www.semanticscholar.org/paper/ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9191972\",\"name\":\"Xin Men\"},{\"authorId\":\"50813206\",\"name\":\"F. Zhou\"},{\"authorId\":\"33899331\",\"name\":\"Xiaoyong Li\"}],\"doi\":\"10.2312/PG.20181287\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f19c5d8116fbd3e7f9a4e2b078d4a09de9fdcdc\",\"title\":\"A Deep Learned Method for Video Indexing and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7f19c5d8116fbd3e7f9a4e2b078d4a09de9fdcdc\",\"venue\":\"PG\",\"year\":2018},{\"arxivId\":\"1612.06703\",\"authors\":[{\"authorId\":\"7619850\",\"name\":\"Adhavan Jayabalan\"},{\"authorId\":\"7318780\",\"name\":\"Harish Karunakaran\"},{\"authorId\":\"8461792\",\"name\":\"Shravan Murlidharan\"},{\"authorId\":\"7227417\",\"name\":\"Tesia Shizume\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6350fcd05c9eea4240f3e58b9bbd0d2039935b3a\",\"title\":\"Dynamic Action Recognition: A convolutional neural network model for temporally organized joint location data\",\"url\":\"https://www.semanticscholar.org/paper/6350fcd05c9eea4240f3e58b9bbd0d2039935b3a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51050729\",\"name\":\"Hongtao Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2018.00157\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"title\":\"One-Shot Action Localization by Learning Sequence Matching Network\",\"url\":\"https://www.semanticscholar.org/paper/bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"48447152\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/ICMEW.2017.8026280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9431af08bdca53bb6461e9f8c7d056e340651073\",\"title\":\"3D action recognition using multi-temporal skeleton visualization\",\"url\":\"https://www.semanticscholar.org/paper/9431af08bdca53bb6461e9f8c7d056e340651073\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"49605422\",\"name\":\"Jing Wang\"},{\"authorId\":\"4869835\",\"name\":\"T. Hassan\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.3390/fi11020042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"title\":\"3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"47002225\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1177/1729881418825093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"title\":\"Hierarchical dynamic depth projected difference images\\u2013based action recognition in videos with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1704.07160\",\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":null,\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TCYB.2017.2756840\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cec1d16a4d848fad0e92081294a1fde94a4d9f88\",\"title\":\"Body Joint Guided 3-D Deep Convolutional Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cec1d16a4d848fad0e92081294a1fde94a4d9f88\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47952527\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"40165419\",\"name\":\"M. Jaber\"},{\"authorId\":\"1694755\",\"name\":\"P. Tsakalides\"}],\"doi\":\"10.2352/ISSN.2470-1173.2017.16.CVAS-344\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30b515cc19bd8fed04bea6ea152f284525671f60\",\"title\":\"Goal!! Event detection in sports video\",\"url\":\"https://www.semanticscholar.org/paper/30b515cc19bd8fed04bea6ea152f284525671f60\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49124723\",\"name\":\"B. Banerjee\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/ICASSP.2017.7952634\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a62769c772b54d557953ae480a2f6e6e0d0f058\",\"title\":\"Efficient pooling of image based CNN features for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6a62769c772b54d557953ae480a2f6e6e0d0f058\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1918302\",\"name\":\"Weijian Li\"},{\"authorId\":\"40119164\",\"name\":\"D. Huang\"},{\"authorId\":\"1680740\",\"name\":\"Huibin Li\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/FG.2018.00014\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"26b2979ba5aace3b13c2e520a6cfc4e6a758a598\",\"title\":\"Automatic 4D Facial Expression Recognition Using Dynamic Geometrical Image Network\",\"url\":\"https://www.semanticscholar.org/paper/26b2979ba5aace3b13c2e520a6cfc4e6a758a598\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000272213\",\"name\":\"Mainak Chakraborty\"},{\"authorId\":\"2000636940\",\"name\":\"Alik Pramanick\"},{\"authorId\":\"9266339\",\"name\":\"S. Dhavale\"}],\"doi\":\"10.1007/978-981-15-5148-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d2b3f186c7310060163d3716ec9c46599306c8f\",\"title\":\"Two-Stream Mid-Level Fusion Network for Human Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/2d2b3f186c7310060163d3716ec9c46599306c8f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2012.01468\",\"authors\":[{\"authorId\":\"2030975823\",\"name\":\"Yuqi Ouyang\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beed3d46938a4cf406dfaf2d08124ee618822b80\",\"title\":\"Video Anomaly Detection by Estimating Likelihood of Representations\",\"url\":\"https://www.semanticscholar.org/paper/beed3d46938a4cf406dfaf2d08124ee618822b80\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034347747\",\"name\":\"Chang Liu\"},{\"authorId\":\"153690115\",\"name\":\"Yulin Yang\"},{\"authorId\":\"2034348002\",\"name\":\"Xingyan Liu\"},{\"authorId\":\"51310276\",\"name\":\"Linpu Fang\"},{\"authorId\":\"40497356\",\"name\":\"Wenxiong Kang\"}],\"doi\":\"10.1109/TIFS.2020.3036218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a93f6df11436e0f5df09d79c814930430104b75\",\"title\":\"Dynamic-Hand-Gesture Authentication Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4a93f6df11436e0f5df09d79c814930430104b75\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403026588\",\"name\":\"Pau Climent-P\\u00e9rez\"},{\"authorId\":\"1699905\",\"name\":\"S. Spinsante\"},{\"authorId\":\"2338883\",\"name\":\"A. Mihailidis\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.1016/J.ESWA.2019.112847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"title\":\"A review on video-based active and assisted living technologies for automated lifelogging\",\"url\":\"https://www.semanticscholar.org/paper/516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92599875\",\"name\":\"M. Nadeem\"},{\"authorId\":\"1828728\",\"name\":\"V. N. L. Franqueira\"},{\"authorId\":\"1881146\",\"name\":\"X. Zhai\"},{\"authorId\":\"1741168\",\"name\":\"F. Kurugollu\"}],\"doi\":\"10.1109/ACCESS.2019.2924733\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"255485196a869c98aacce60a86074fccf07c01eb\",\"title\":\"A Survey of Deep Learning Solutions for Multimedia Visual Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/255485196a869c98aacce60a86074fccf07c01eb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48951023\",\"name\":\"F. Husain\"},{\"authorId\":\"1724418\",\"name\":\"B. Dellen\"},{\"authorId\":\"1735976\",\"name\":\"C. Torras\"}],\"doi\":\"10.1016/B978-0-12-811318-9.00020-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1350c9f261a5d4e037ea6f6acbdba43abea909b0\",\"title\":\"Scene understanding using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/1350c9f261a5d4e037ea6f6acbdba43abea909b0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153122996\",\"name\":\"Josep Maria Carmona\"},{\"authorId\":\"145105992\",\"name\":\"J. Climent\"}],\"doi\":\"10.1016/j.patcog.2018.04.015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"17334201466dae9a7fa0c74e93472e1bb278fa80\",\"title\":\"Human action recognition by means of subtensor projections and dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/17334201466dae9a7fa0c74e93472e1bb278fa80\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921425\",\"name\":\"D. Thaker\"},{\"authorId\":\"46800227\",\"name\":\"K. Krishnakumar\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75768ff4129ca6cd122c5ca729e9cfc66cc798fe\",\"title\":\"k-Shot Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75768ff4129ca6cd122c5ca729e9cfc66cc798fe\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1809.08381\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7c9b3eb8737d29a779a0e21e355543c22ccca49\",\"title\":\"Learning to Localize and Align Fine-Grained Actions to Sparse Instructions\",\"url\":\"https://www.semanticscholar.org/paper/a7c9b3eb8737d29a779a0e21e355543c22ccca49\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152502426\",\"name\":\"Shaoqing Tan\"},{\"authorId\":\"8092869\",\"name\":\"R. Yang\"}],\"doi\":\"10.1109/IJCNN.2019.8851694\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f1964f5e913bc386707e98e872861dbdf00ed13e\",\"title\":\"Learning Similarity: Feature-Aligning Network for Few-shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1964f5e913bc386707e98e872861dbdf00ed13e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"2002.12392\",\"authors\":[{\"authorId\":\"1958036\",\"name\":\"Gongbo Liang\"},{\"authorId\":\"48631827\",\"name\":\"Xiaoqin Wang\"},{\"authorId\":\"46867976\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1491631303\",\"name\":\"Xin Xing\"},{\"authorId\":\"1491643960\",\"name\":\"Hunter Blanton\"},{\"authorId\":\"1491644479\",\"name\":\"Tawfiq Salem\"},{\"authorId\":\"47259377\",\"name\":\"Nathan B. Jacobs\"}],\"doi\":\"10.1109/BIBM47256.2019.8983048\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d0e1914fb9df12cf42d1f8621d0de024276b735\",\"title\":\"Joint 2D-3D Breast Cancer Classification\",\"url\":\"https://www.semanticscholar.org/paper/7d0e1914fb9df12cf42d1f8621d0de024276b735\",\"venue\":\"2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":\"10.1007/s11042-020-08917-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"title\":\"Fine grained sport action recognition with Twin spatio-temporal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798691\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144323097\",\"name\":\"W. Yu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9695232daa85651937569d1b7b2541faf2633dc\",\"title\":\"Actionness-pooled Deep-convolutional Descriptor for fine-grained action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9695232daa85651937569d1b7b2541faf2633dc\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1611.06646\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.607\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7b53a308a41507a2ef2faed78eb48812633e75fb\",\"title\":\"Self-Supervised Video Representation Learning with Odd-One-Out Networks\",\"url\":\"https://www.semanticscholar.org/paper/7b53a308a41507a2ef2faed78eb48812633e75fb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.06338\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"48642221\",\"name\":\"Song Liu\"},{\"authorId\":\"35061362\",\"name\":\"Y. Zhang\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/ICPR.2016.7899600\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5364ed5a6ebd9e6210ab9c92c37cf0268aa352aa\",\"title\":\"Large-scale Continuous Gesture Recognition Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5364ed5a6ebd9e6210ab9c92c37cf0268aa352aa\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1804.00326\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c75658b080a9baaac20db39af86016ffa36f6f0\",\"title\":\"Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching\",\"url\":\"https://www.semanticscholar.org/paper/2c75658b080a9baaac20db39af86016ffa36f6f0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"51036717\",\"name\":\"J. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f72405e74c3c4f962c4821bf5f34b9106009801c\",\"title\":\"Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f72405e74c3c4f962c4821bf5f34b9106009801c\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2005.05501\",\"authors\":[{\"authorId\":null,\"name\":\"Yancheng Wang\"},{\"authorId\":\"1409958726\",\"name\":\"Yang Xiao\"},{\"authorId\":\"5181059\",\"name\":\"F. Xiong\"},{\"authorId\":\"1406126531\",\"name\":\"Wenxiang Jiang\"},{\"authorId\":\"144762660\",\"name\":\"Zhiguo Cao\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/cvpr42600.2020.00059\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6a29fc09d4b6a093b39d370ff47fa84bb2d405cf\",\"title\":\"3DV: 3D Dynamic Voxel for Action Recognition in Depth Video\",\"url\":\"https://www.semanticscholar.org/paper/6a29fc09d4b6a093b39d370ff47fa84bb2d405cf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145222866\",\"name\":\"Muhammad Shahid\"},{\"authorId\":\"2457914\",\"name\":\"Cigdem Beyan\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-30642-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fca07763d1ae4b16af99ded9e38e9c48995677f5\",\"title\":\"Comparisons of Visual Activity Primitives for Voice Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/fca07763d1ae4b16af99ded9e38e9c48995677f5\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2058516\",\"name\":\"O. Oshin\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"3033982\",\"name\":\"B. Nair\"},{\"authorId\":\"1443749549\",\"name\":\"Jerry Ding\"},{\"authorId\":\"1443782889\",\"name\":\"Richa Varma\"},{\"authorId\":\"33177662\",\"name\":\"Richard W. Osborne\"},{\"authorId\":\"1443783806\",\"name\":\"Eddie Tunstel\"},{\"authorId\":\"1443782661\",\"name\":\"Francesca Stramandinoli\"}],\"doi\":\"10.1109/SMC.2019.8913974\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e63c2528d640d8746c9b2b1029eb17c3efd6d288\",\"title\":\"Coupling Deep Discriminative and Generative Models for Reactive Robot Planning in Human-Robot Collaboration\",\"url\":\"https://www.semanticscholar.org/paper/e63c2528d640d8746c9b2b1029eb17c3efd6d288\",\"venue\":\"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2009.13049\",\"authors\":[{\"authorId\":\"50419112\",\"name\":\"Chaoxing Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ff829cce213363d1db040656ef1ceddbea868e7\",\"title\":\"Event-based Action Recognition Using Timestamp Image Encoding Network\",\"url\":\"https://www.semanticscholar.org/paper/9ff829cce213363d1db040656ef1ceddbea868e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153795678\",\"name\":\"Muhammad Shahid\"},{\"authorId\":\"2457914\",\"name\":\"Cigdem Beyan\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/ICCVW.2019.00159\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71d07c051157e6783c30c9d0045b5bc8b637ecc4\",\"title\":\"Voice Activity Detection by Upper Body Motion Analysis and Unsupervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/71d07c051157e6783c30c9d0045b5bc8b637ecc4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"49835905\",\"name\":\"Xuesong Jiang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1007/s11042-017-5038-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf784156547c3be146706e2763c1a52d939d1722\",\"title\":\"Breaking video into pieces for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf784156547c3be146706e2763c1a52d939d1722\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"title\":\"Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units\",\"url\":\"https://www.semanticscholar.org/paper/2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31573550\",\"name\":\"Alejandro Hernandez Ruiz\"},{\"authorId\":\"3202308\",\"name\":\"L. Porzi\"},{\"authorId\":\"2145174\",\"name\":\"S. R. Bul\\u00f2\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"}],\"doi\":\"10.1145/3123266.3123299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c066754b84fb15f7ea09abdcd7279bb88c36e01d\",\"title\":\"3D CNNs on Distance Matrices for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c066754b84fb15f7ea09abdcd7279bb88c36e01d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"},{\"authorId\":\"2787806\",\"name\":\"A. S. Rajput\"}],\"doi\":\"10.1145/3341105.3373942\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e65ebe36e50cbd8bb9d0c581fb10e6fe3f719d1c\",\"title\":\"Robust, efficient and privacy-preserving violent activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/e65ebe36e50cbd8bb9d0c581fb10e6fe3f719d1c\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144865166\",\"name\":\"A. Javed\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"9748996\",\"name\":\"Yasmeen Khaliq\"},{\"authorId\":\"144955607\",\"name\":\"Hafiz Malik\"},{\"authorId\":\"49725394\",\"name\":\"M. Mahmood\"}],\"doi\":\"10.1007/s10489-019-01410-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b66b45ba5d12490f7101cc314d7c6c066455fe72\",\"title\":\"Replay and key-events detection for sports video summarization using confined elliptical local ternary patterns and extreme learning machine\",\"url\":\"https://www.semanticscholar.org/paper/b66b45ba5d12490f7101cc314d7c6c066455fe72\",\"venue\":\"Applied Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32998919\",\"name\":\"M. Safaei\"},{\"authorId\":\"3065592\",\"name\":\"Pooyan Balouchian\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/ICIP.2018.8451193\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c926043981a50113f77a92d1151a29a6c55d56c7\",\"title\":\"TICNN: A Hierarchical Deep Learning Framework for Still Image Action Recognition Using Temporal Image Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c926043981a50113f77a92d1151a29a6c55d56c7\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9280878\",\"name\":\"N. Khatir\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"},{\"authorId\":\"1405196499\",\"name\":\"Marcos Baptista-R\\u00edos\"},{\"authorId\":\"2277906\",\"name\":\"S. Bahloul\"},{\"authorId\":\"1402975934\",\"name\":\"F. J. Acevedo-Rodr\\u00edguez\"}],\"doi\":\"10.1007/978-3-030-31332-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99ab5881e10f262bfab8a9efee55477535b8f9f9\",\"title\":\"Combining Online Clustering and Rank Pooling Dynamics for Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/99ab5881e10f262bfab8a9efee55477535b8f9f9\",\"venue\":\"IbPRIA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145625558\",\"name\":\"Chuankun Li\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"40508657\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.1016/j.jvcir.2019.102640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c960014ee78d90479d34f2a0c75e46f4f3a78c86\",\"title\":\"Learning attentive dynamic maps (ADMs) for Understanding Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/c960014ee78d90479d34f2a0c75e46f4f3a78c86\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2011.03958\",\"authors\":[{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"1443776158\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c4fed2db84c9579bf67f465f8bcccb22d358e93\",\"title\":\"FlowCaps: Optical Flow Estimation with Capsule Networks For Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c4fed2db84c9579bf67f465f8bcccb22d358e93\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.06409\",\"authors\":[{\"authorId\":\"1909776\",\"name\":\"Anthony Hu\"},{\"authorId\":\"30467209\",\"name\":\"Fergal Cotter\"},{\"authorId\":\"145536619\",\"name\":\"N. Mohan\"},{\"authorId\":\"31618584\",\"name\":\"C. Gurau\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"}],\"doi\":\"10.1007/978-3-030-58517-4_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79685e5b72e31405ded418abe8af86166313aa0\",\"title\":\"Probabilistic Future Prediction for Video Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a79685e5b72e31405ded418abe8af86166313aa0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Muhammad Shahid\"},{\"authorId\":null,\"name\":\"Cigdem Beyan\"},{\"authorId\":null,\"name\":\"Vittorio Murino\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"239edcdf84019551f6cb78193e94754619ade996\",\"title\":\"S-VVAD: Visual Voice Activity Detection by Motion Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/239edcdf84019551f6cb78193e94754619ade996\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1709.07894\",\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29ffebd5dd7c16fa0c198ecfd238936c3e528514\",\"title\":\"A Real-time Action Prediction Framework by Encoding Temporal Evolution for Assembly Tasks\",\"url\":\"https://www.semanticscholar.org/paper/29ffebd5dd7c16fa0c198ecfd238936c3e528514\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/3078971.3078988\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"title\":\"Simple, Efficient and Effective Encodings of Local Deep Features for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1801.01080\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145590756\",\"name\":\"Xinwang Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"26702963c1718a29ed287b51ddd12793464cfdd2\",\"title\":\"Cooperative Training of Deep Aggregation Networks for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/26702963c1718a29ed287b51ddd12793464cfdd2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1805.00833\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"title\":\"Learnable PINs: Cross-Modal Embeddings for Person Identity\",\"url\":\"https://www.semanticscholar.org/paper/a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"title\":\"RECOGNITIONWITH GRADIENT BOUNDARY CONVOLUTIONAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1708.05465\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f257300b2b4141aab73f93c146bf94846aef5fa1\",\"title\":\"Eigen Evolution Pooling for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f257300b2b4141aab73f93c146bf94846aef5fa1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"50748225\",\"name\":\"J. Du\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"},{\"authorId\":\"1679704\",\"name\":\"Y. Liu\"},{\"authorId\":\"1729436\",\"name\":\"R. Goh\"}],\"doi\":\"10.1109/TIFS.2019.2900907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b20e564edbef25009fa1baa2c369437c89147e61\",\"title\":\"AnomalyNet: An Anomaly Detection Network for Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/b20e564edbef25009fa1baa2c369437c89147e61\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2019},{\"arxivId\":\"1912.03632\",\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"41d621492203f42a52317163b4091670a360324b\",\"title\":\"View-invariant Deep Architecture for Human Action Recognition using late fusion\",\"url\":\"https://www.semanticscholar.org/paper/41d621492203f42a52317163b4091670a360324b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.05448\",\"authors\":[{\"authorId\":null,\"name\":\"Yufei Wang\"},{\"authorId\":\"153175320\",\"name\":\"Haoliang Li\"},{\"authorId\":\"98738293\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053273\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d8728a567685e14e148a805b51a084d0f93763b8\",\"title\":\"Heterogeneous Domain Generalization Via Domain Mixup\",\"url\":\"https://www.semanticscholar.org/paper/d8728a567685e14e148a805b51a084d0f93763b8\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144195544\",\"name\":\"S. Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.1016/J.COMCOM.2019.07.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d10ce66a13a6e2d270329f47aae1761cf4389\",\"title\":\"Crowd Video Event Classification using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/476d10ce66a13a6e2d270329f47aae1761cf4389\",\"venue\":\"Comput. Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/SMC.2018.00675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"title\":\"TSNet: Deep Network for Human Action Recognition in Hazy Videos\",\"url\":\"https://www.semanticscholar.org/paper/634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1807.09380\",\"authors\":[{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"title\":\"Contrastive Video Representation Learning via Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"}],\"doi\":\"10.1016/j.neucom.2018.02.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"title\":\"Action recognition with motion map 3D network\",\"url\":\"https://www.semanticscholar.org/paper/c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1702.08652\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"35061362\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/CVPR.2017.52\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"title\":\"Scene Flow to Action Map: A New Representation for RGB-D Based Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e6dad2a6e7e7724bf2268fc4c08b69ab8b0a9a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.01848\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/TPAMI.2016.2558148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4defba71c686946351f5e7a090c7aa8136d32f\",\"title\":\"Rank Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4defba71c686946351f5e7a090c7aa8136d32f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-319-97909-0_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5549576809e8f9c3871c31285601f71d2d82ce5d\",\"title\":\"Residual Gating Fusion Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5549576809e8f9c3871c31285601f71d2d82ce5d\",\"venue\":\"CCBR\",\"year\":2018},{\"arxivId\":\"1909.08287\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"1950475\",\"name\":\"Z. Lu\"},{\"authorId\":\"40448837\",\"name\":\"Jing Li\"},{\"authorId\":\"49876187\",\"name\":\"T. Yang\"},{\"authorId\":\"145670268\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/LSP.2018.2823910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98e098ba9ff98fc58f22fed6d3d8540116284b91\",\"title\":\"Global Temporal Representation Based CNNs for Infrared Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/98e098ba9ff98fc58f22fed6d3d8540116284b91\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"32281398\",\"name\":\"V. Q. Tran\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"}],\"doi\":\"10.1109/FG.2018.00076\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bb36c875754a2a8919f2f9b00a336c00006e453\",\"title\":\"Eigen-Evolution Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2bb36c875754a2a8919f2f9b00a336c00006e453\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":\"1905.10793\",\"authors\":[{\"authorId\":\"122744867\",\"name\":\"S\\u00e9bastien Ehrhardt\"},{\"authorId\":\"2535033\",\"name\":\"Aron Monszpart\"},{\"authorId\":\"1710455\",\"name\":\"N. Mitra\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c33e8da8d5a7bc6fed2f15c785c0ebec6093ff31\",\"title\":\"Unsupervised Intuitive Physics from Past Experiences\",\"url\":\"https://www.semanticscholar.org/paper/c33e8da8d5a7bc6fed2f15c785c0ebec6093ff31\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.06215\",\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"48515277\",\"name\":\"Yajuan Li\"},{\"authorId\":\"36602757\",\"name\":\"Qinyi Lv\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dae1e039833db56735d54a992bb5cfb381bdadd9\",\"title\":\"Few-shot Action Recognition with Implicit Temporal Alignment and Pair Similarity Optimization\",\"url\":\"https://www.semanticscholar.org/paper/dae1e039833db56735d54a992bb5cfb381bdadd9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ca95f79a40e2a2851b3c66dd5e326203b8753cd\",\"title\":\"Latent Dynamic Space-Time Volumes for Predicting Human Facial Behavior in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4ca95f79a40e2a2851b3c66dd5e326203b8753cd\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1808.00141\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1007/978-3-030-11015-4_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"title\":\"Action Anticipation By Predicting Future Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICASSP.2018.8462612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88493c1952000cde64c3f2294d36fc76fd23bf3f\",\"title\":\"Mgn: Multi-Glimpse Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88493c1952000cde64c3f2294d36fc76fd23bf3f\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7496553\",\"name\":\"Dongli Wang\"},{\"authorId\":\"1455510526\",\"name\":\"Hexue Xiao\"},{\"authorId\":\"97713453\",\"name\":\"F. Ou\"},{\"authorId\":\"1692274\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/IECON.2019.8927440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce95957ae9f4e5353a59e4e75da73e7db3e0f3ec\",\"title\":\"Moving Human Focus Inference Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ce95957ae9f4e5353a59e4e75da73e7db3e0f3ec\",\"venue\":\"IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338163\",\"name\":\"S. Namin\"},{\"authorId\":\"8940956\",\"name\":\"Mohammad Esmaeilzadeh\"},{\"authorId\":\"144705167\",\"name\":\"M. Najafi\"},{\"authorId\":\"32257370\",\"name\":\"T. Brown\"},{\"authorId\":\"2081020\",\"name\":\"J. Borevitz\"}],\"doi\":\"10.1101/134205\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddb2dc8c1c23727fdc482cada2806c11009e20a9\",\"title\":\"Deep Phenotyping: Deep Learning for Temporal Phenotype/Genotype Classification\",\"url\":\"https://www.semanticscholar.org/paper/ddb2dc8c1c23727fdc482cada2806c11009e20a9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.02447\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"7718545\",\"name\":\"Z. Li\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1145/2964284.2967191\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce601575f213073c2e11c53eba169a695eaa4cad\",\"title\":\"Action Recognition Based on Joint Trajectory Maps Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce601575f213073c2e11c53eba169a695eaa4cad\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"2012.00119\",\"authors\":[{\"authorId\":\"144062928\",\"name\":\"Xin Xing\"},{\"authorId\":\"1958036\",\"name\":\"Gongbo Liang\"},{\"authorId\":\"1491643960\",\"name\":\"Hunter Blanton\"},{\"authorId\":\"3326665\",\"name\":\"M. U. Rafique\"},{\"authorId\":null,\"name\":\"Chris Wang\"},{\"authorId\":\"145560985\",\"name\":\"Ailing Lin\"},{\"authorId\":\"80872554\",\"name\":\"N. Jacobs\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7017e468991464b1bfca2b6fe82e6ddfba86cb8\",\"title\":\"Dynamic Image for 3D MRI Image Alzheimer's Disease Classification\",\"url\":\"https://www.semanticscholar.org/paper/b7017e468991464b1bfca2b6fe82e6ddfba86cb8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1704.02112\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.172\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"faae39b8708de562a78b2b4294694a935442844a\",\"title\":\"Generalized Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/faae39b8708de562a78b2b4294694a935442844a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108808263\",\"name\":\"Jian He\"},{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"98197525\",\"name\":\"Xinlin He\"},{\"authorId\":\"1786267\",\"name\":\"Ruihai Dong\"}],\"doi\":\"10.1016/j.neucom.2019.07.103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6fd8edaa5f7da9c9e2d8547a4d8381ea6a7a4e0\",\"title\":\"Visual Recognition of traffic police gestures with convolutional pose machine and handcrafted features\",\"url\":\"https://www.semanticscholar.org/paper/e6fd8edaa5f7da9c9e2d8547a4d8381ea6a7a4e0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/ICCV.2017.621\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcefb761034daeef1e735cf0a1787bc379ae0673\",\"title\":\"Learning Action Recognition Model from Depth and Skeleton Videos\",\"url\":\"https://www.semanticscholar.org/paper/bcefb761034daeef1e735cf0a1787bc379ae0673\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9102201\",\"name\":\"Yaxiang Fan\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"},{\"authorId\":\"144334479\",\"name\":\"Gongjian Wen\"},{\"authorId\":\"3437649\",\"name\":\"Shaohua Qiu\"}],\"doi\":\"10.1016/j.neucom.2017.02.082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fe7239546e34ede6579fad5d7f36317c850fefd\",\"title\":\"A deep neural network for real-time detection of falling humans in naturally occurring scenes\",\"url\":\"https://www.semanticscholar.org/paper/9fe7239546e34ede6579fad5d7f36317c850fefd\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1701.01814\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"48642221\",\"name\":\"Song Liu\"},{\"authorId\":\"49538629\",\"name\":\"Zhimin Gao\"},{\"authorId\":\"145199348\",\"name\":\"Chang Tang\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"}],\"doi\":\"10.1109/ICPR.2016.7899599\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ca553cfcaab0b14cc59eaa8fda2f2eac9c17980\",\"title\":\"Large-scale Isolated Gesture Recognition using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1ca553cfcaab0b14cc59eaa8fda2f2eac9c17980\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148336006\",\"name\":\"Weisong Che\"},{\"authorId\":\"9391708\",\"name\":\"Shuhua Peng\"}],\"doi\":\"10.1109/IAEAC47372.2019.8997745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d67b6135393720b4629c0eca95a16bf67e3f0364\",\"title\":\"3D Dual Path Networks and Multi-scale Feature Fusion for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d67b6135393720b4629c0eca95a16bf67e3f0364\",\"venue\":\"2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144183638\",\"name\":\"Xian Sun\"},{\"authorId\":\"2508428\",\"name\":\"Songhao Zhu\"},{\"authorId\":\"2716810\",\"name\":\"Songsong Wu\"},{\"authorId\":\"15132338\",\"name\":\"X. Jing\"}],\"doi\":\"10.1109/ICPR.2018.8545345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a02ea1541de7206c3fe4ff9908be161da3e5e9d\",\"title\":\"Weak Supervised Learning Based Abnormal Behavior Detection\",\"url\":\"https://www.semanticscholar.org/paper/6a02ea1541de7206c3fe4ff9908be161da3e5e9d\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67054241\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"51394016\",\"name\":\"Guillermo Camara Chavez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a295c14cb9b00eff47438c77a2ff1062998fc214\",\"title\":\"Multimodal Human Action Recognition Based on a Fusion of Dynamic Images Using CNN Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/a295c14cb9b00eff47438c77a2ff1062998fc214\",\"venue\":\"2018 31st SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2018},{\"arxivId\":\"2002.02100\",\"authors\":[{\"authorId\":\"153037548\",\"name\":\"S. H. Shabbeer Basha\"},{\"authorId\":\"51485920\",\"name\":\"Viswanath Pulabaigari\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42bf5be4b315c0eb68dd8d7fd4a6519304217c25\",\"title\":\"An Information-rich Sampling Technique over Spatio-Temporal CNN for Classification of Human Actions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/42bf5be4b315c0eb68dd8d7fd4a6519304217c25\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394421585\",\"name\":\"Matthew Korban\"},{\"authorId\":\"51484592\",\"name\":\"X. Li\"}],\"doi\":\"10.1007/978-3-030-58565-5_45\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"8f95972c62058480d34893095e1bdd5660e4641a\",\"title\":\"DDGCN: A Dynamic Directed Graph Convolutional Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f95972c62058480d34893095e1bdd5660e4641a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578886\",\"name\":\"Mohamed R. Ibrahim\"},{\"authorId\":\"38973565\",\"name\":\"J. Haworth\"},{\"authorId\":\"144944046\",\"name\":\"T. Cheng\"}],\"doi\":\"10.1016/j.cities.2019.102481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2213e058a897cb790070b53e53c765f09b6c44d8\",\"title\":\"Understanding cities with machine eyes: A review of deep computer vision in urban analytics\",\"url\":\"https://www.semanticscholar.org/paper/2213e058a897cb790070b53e53c765f09b6c44d8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50999137\",\"name\":\"M. R. Souza\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1016/j.neucom.2020.04.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"609651891f7605789894397f7d5c6f78b6dba2df\",\"title\":\"Survey on visual rhythms: A spatio-temporal representation for video sequences\",\"url\":\"https://www.semanticscholar.org/paper/609651891f7605789894397f7d5c6f78b6dba2df\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1803.07781\",\"authors\":[{\"authorId\":\"143635391\",\"name\":\"Huy-Hieu Pham\"},{\"authorId\":\"1683263\",\"name\":\"L. Khoudour\"},{\"authorId\":\"1751089\",\"name\":\"A. Crouzil\"},{\"authorId\":\"144919173\",\"name\":\"P. Zegers\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1016/j.cviu.2018.03.003\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6ac1f6e3e3b28e9e7713e515b61c405a35c59475\",\"title\":\"Exploiting deep residual networks for human action recognition from skeletal data\",\"url\":\"https://www.semanticscholar.org/paper/6ac1f6e3e3b28e9e7713e515b61c405a35c59475\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18186434\",\"name\":\"Nudrat Nida\"},{\"authorId\":null,\"name\":\"Muhammad Haroon Yousaf\"},{\"authorId\":null,\"name\":\"Aun Irtaza\"},{\"authorId\":null,\"name\":\"Sergio A. Velastin\"}],\"doi\":\"10.3906/elk-1907-214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ba6d9f33113ef9c29ce403c69ada4b011ffe980\",\"title\":\"Deep temporal motion descriptor DTMD for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ba6d9f33113ef9c29ce403c69ada4b011ffe980\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.12929\",\"authors\":[{\"authorId\":\"46868059\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"48985485\",\"name\":\"Mingrui Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3010141db561594cad7325554fbc6d41f88c8eba\",\"title\":\"Self-Paced Video Data Augmentation with Dynamic Images Generated by Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3010141db561594cad7325554fbc6d41f88c8eba\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.09044\",\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1007/978-3-030-20887-5_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"title\":\"VIENA2: A Driving Anticipation Dataset\",\"url\":\"https://www.semanticscholar.org/paper/44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1906.09955\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1109/TIP.2019.2925285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"title\":\"A Comparative Review of Recent Kinect-Based Action Recognition Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1810.01455\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2019.01018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"title\":\"Representation Flow for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2685285\",\"name\":\"P. Palasek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3507f5839b28cd385e477d7cadee3373c6bc3e67\",\"title\":\"Action recognition using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/3507f5839b28cd385e477d7cadee3373c6bc3e67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2017.341\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"title\":\"Spatio-Temporal Vector of Locally Max Pooled Features for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"9136930\",\"name\":\"Xuxin Lin\"},{\"authorId\":\"30527170\",\"name\":\"Yiliang Xie\"},{\"authorId\":\"48503912\",\"name\":\"Yanyan Liang\"}],\"doi\":\"10.1007/s00138-018-0969-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a52f8cfa6acc0600a20e5f25d2008f2e02a31d1b\",\"title\":\"Abnormal gesture recognition based on multi-model fusion strategy\",\"url\":\"https://www.semanticscholar.org/paper/a52f8cfa6acc0600a20e5f25d2008f2e02a31d1b\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":\"1805.02877\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49897466\",\"name\":\"Xiaotian Zhu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7f511a6a2b38a26f077a5aec4baf5dffc981d881\",\"title\":\"Low-Latency Human Action Recognition with Weighted Multi-Region Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/7f511a6a2b38a26f077a5aec4baf5dffc981d881\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TCSVT.2017.2746092\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"20970f0db883b76b56bbf080da79f7fc4c4fc805\",\"title\":\"Cross-Agent Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/20970f0db883b76b56bbf080da79f7fc4c4fc805\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1702.04037\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"faa29975169ba3bbb954e518bc9814a5819876f6\",\"title\":\"Evolution-Preserving Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/faa29975169ba3bbb954e518bc9814a5819876f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82599235\",\"name\":\"S. R. Ammar\"},{\"authorId\":\"152629075\",\"name\":\"M. R. Anjum\"},{\"authorId\":\"145614509\",\"name\":\"Md. Touhidul Islam Islam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24bb9e9785c714a8f2470366395f33a2cc339398\",\"title\":\"Using deep learning algorithms to detect violent activities\",\"url\":\"https://www.semanticscholar.org/paper/24bb9e9785c714a8f2470366395f33a2cc339398\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3091544\",\"name\":\"Enjie Ding\"},{\"authorId\":\"2643775\",\"name\":\"Zhongyu Liu\"},{\"authorId\":\"46398350\",\"name\":\"Y. Liu\"},{\"authorId\":\"46697303\",\"name\":\"Dawei Xu\"},{\"authorId\":\"2481620\",\"name\":\"Shimin Feng\"},{\"authorId\":\"3222657\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/GCWkshps45667.2019.9024615\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4b6ca6991dd154362791fa068cb8405b7eba09d\",\"title\":\"Unsafe Action Recognition of Miners Based on Video Description\",\"url\":\"https://www.semanticscholar.org/paper/d4b6ca6991dd154362791fa068cb8405b7eba09d\",\"venue\":\"2019 IEEE Globecom Workshops (GC Wkshps)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/978-3-319-51811-4_30\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be5276e9744c4445fe5b12b785650e8f173f56ff\",\"title\":\"Spatio-Temporal VLAD Encoding for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/be5276e9744c4445fe5b12b785650e8f173f56ff\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":\"1904.13003\",\"authors\":[{\"authorId\":\"143714141\",\"name\":\"H. Chen\"},{\"authorId\":\"1778107\",\"name\":\"G. Chirikjian\"}],\"doi\":\"10.1109/CVPRW50498.2020.00437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f91bdd76a8f50241fba9341c0eb67ed5a03b71f\",\"title\":\"Curvature: A signature for Action Recognition in Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3f91bdd76a8f50241fba9341c0eb67ed5a03b71f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145277843\",\"name\":\"J. Jiang\"},{\"authorId\":\"34269118\",\"name\":\"H. Wang\"},{\"authorId\":\"51160293\",\"name\":\"Laixin Xie\"},{\"authorId\":\"1786807\",\"name\":\"Junwen Zhang\"},{\"authorId\":\"50542782\",\"name\":\"Chunhua Deng\"}],\"doi\":\"10.1007/978-3-319-95957-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1b119bfd5de387cfc20639fdda1d5400b72f6fb\",\"title\":\"Dimensionality Deduction for Action Proposals: To Extract or to Select?\",\"url\":\"https://www.semanticscholar.org/paper/f1b119bfd5de387cfc20639fdda1d5400b72f6fb\",\"venue\":\"ICIC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/S12652-019-01239-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca3d26b3139d8f3db2e7f37c64d18e3cde27f322\",\"title\":\"Evaluating fusion of RGB-D and inertial sensors for multimodal human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca3d26b3139d8f3db2e7f37c64d18e3cde27f322\",\"venue\":\"J. Ambient Intell. Humaniz. Comput.\",\"year\":2020},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.05438\",\"authors\":[{\"authorId\":\"1846789641\",\"name\":\"Maxat Alibayev\"},{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"143971676\",\"name\":\"Y. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"title\":\"Developing Motion Code Embedding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.10136\",\"authors\":[{\"authorId\":\"1905356\",\"name\":\"K. Mullick\"},{\"authorId\":\"3185334\",\"name\":\"A. Namboodiri\"}],\"doi\":\"10.1109/ICIP.2017.8297033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ecd4cc01744619ee7c7a25257d0254cb7f45d12\",\"title\":\"Learning deep and compact models for gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ecd4cc01744619ee7c7a25257d0254cb7f45d12\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":\"1805.07550\",\"authors\":[{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6dee5bb3ff1b44f160259fa57815fa980b05659\",\"title\":\"DenseImage Network: Video Spatial-Temporal Evolution Encoding and Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a6dee5bb3ff1b44f160259fa57815fa980b05659\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2001.11657\",\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/tip.2020.2967577\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"title\":\"Modality Compensation Network: Cross-Modal Adaptation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1708.09825\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCVW.2017.307\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56426f6b86276b577f3d49c97189f609490022a0\",\"title\":\"Inferring Human Activities Using Robust Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/56426f6b86276b577f3d49c97189f609490022a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93589643\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s00521-020-05018-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d5ebb71384b8da236fd4ca903df1630bc62389c\",\"title\":\"A deeply coupled ConvNet for human activity recognition using dynamic and RGB images\",\"url\":\"https://www.semanticscholar.org/paper/9d5ebb71384b8da236fd4ca903df1630bc62389c\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12373810\",\"name\":\"S. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9c99179fb0ee3ec5e0466a531d22bb1e800c40f\",\"title\":\"Development of Recurrent Neural Networks and Its Applications to Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d9c99179fb0ee3ec5e0466a531d22bb1e800c40f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/ICIP.2017.8296599\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4985dde77a09674fa3264decc1a809da206fbae\",\"title\":\"3D convolutional neural network with multi-model framework for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4985dde77a09674fa3264decc1a809da206fbae\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9012538\",\"name\":\"Salah Alghyaline\"},{\"authorId\":\"144717607\",\"name\":\"Jun-Wei Hsieh\"},{\"authorId\":\"33689898\",\"name\":\"Chi-Hung Chuang\"}],\"doi\":\"10.1109/SMC.2017.8122640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"title\":\"Video action classification using symmelets and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"47628927\",\"name\":\"Mingyang Li\"},{\"authorId\":null,\"name\":\"He Bai\"},{\"authorId\":\"88502672\",\"name\":\"L. Ma\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"}],\"doi\":\"10.1007/s00521-019-04030-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"title\":\"DKD\\u2013DAD: a novel framework with discriminative kinematic descriptor and deep attention-pooled descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317087\",\"name\":\"Zhifei Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"743f592116b0a17f3eaca2fb3347058b038b5e91\",\"title\":\"Conditional Image Synthesis by Generative Adversarial Modeling\",\"url\":\"https://www.semanticscholar.org/paper/743f592116b0a17f3eaca2fb3347058b038b5e91\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405196499\",\"name\":\"Marcos Baptista-R\\u00edos\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"},{\"authorId\":\"1402975934\",\"name\":\"F. J. Acevedo-Rodr\\u00edguez\"},{\"authorId\":\"1412159037\",\"name\":\"Pilar Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"1398470117\",\"name\":\"S. Maldonado-Basc\\u00f3n\"}],\"doi\":\"10.3390/s20102953\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"250cff3f869805e76bf0cda34406f5def042148c\",\"title\":\"Unsupervised Action Proposals Using Support Vector Classifiers for Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/250cff3f869805e76bf0cda34406f5def042148c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1905.06242\",\"authors\":[{\"authorId\":\"2603310\",\"name\":\"Rodrigo Berriel\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"1397136266\",\"name\":\"Thiago Oliveira-Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"}],\"doi\":\"10.1109/ICCV.2019.00047\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c10d96b7f31cc488d3f89c2f5eb5f0d41eb0b43\",\"title\":\"Budget-Aware Adapters for Multi-Domain Learning\",\"url\":\"https://www.semanticscholar.org/paper/9c10d96b7f31cc488d3f89c2f5eb5f0d41eb0b43\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1805.11119\",\"authors\":[{\"authorId\":\"38286801\",\"name\":\"Massimiliano Mancini\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"},{\"authorId\":\"2145174\",\"name\":\"S. R. Bul\\u00f2\"}],\"doi\":\"10.1007/978-3-030-11012-3_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32a76a268e02502d945c9c2bf9a15cca008a2bd3\",\"title\":\"Adding New Tasks to a Single Network with Weight Trasformations using Binary Masks\",\"url\":\"https://www.semanticscholar.org/paper/32a76a268e02502d945c9c2bf9a15cca008a2bd3\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1806.11269\",\"authors\":[{\"authorId\":\"144209663\",\"name\":\"Y. Xiao\"},{\"authorId\":\"98894244\",\"name\":\"Jun Chen\"},{\"authorId\":\"144762660\",\"name\":\"Zhiguo Cao\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.ins.2018.12.050\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4508789311f47bf6f6bb348d001b9ab370b71de\",\"title\":\"Action Recognition for Depth Video using Multi-view Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/e4508789311f47bf6f6bb348d001b9ab370b71de\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/ICCVW.2017.371\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a2801b968c889a8625d4ab62e03323bd14d6eda\",\"title\":\"Large-Scale Multimodal Gesture Segmentation and Recognition Based on Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9a2801b968c889a8625d4ab62e03323bd14d6eda\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8092281\",\"name\":\"Hai-Hong Phan\"},{\"authorId\":\"30796666\",\"name\":\"Ngoc-Son Vu\"}],\"doi\":\"10.1109/AVSS.2019.8909826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ee232c3aca2b1583d5c765371012539e80c2f62\",\"title\":\"Information theory based pruning for CNN compression and its application to image classification and action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ee232c3aca2b1583d5c765371012539e80c2f62\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":\"1905.02319\",\"authors\":[{\"authorId\":\"11737018\",\"name\":\"Muzammil Behzad\"},{\"authorId\":\"143898997\",\"name\":\"N. Vo\"},{\"authorId\":\"33672691\",\"name\":\"X. Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bcbc84be8413d9d17f762bef3fcd6b06fe10673\",\"title\":\"Automatic 4D Facial Expression Recognition via Collaborative Cross-domain Dynamic Image Network\",\"url\":\"https://www.semanticscholar.org/paper/2bcbc84be8413d9d17f762bef3fcd6b06fe10673\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1956543819\",\"name\":\"Trang Thanh Quynh Le\"},{\"authorId\":\"104659629\",\"name\":\"Thuong-Khanh Tran\"},{\"authorId\":\"1382650201\",\"name\":\"Manjeet Rege\"}],\"doi\":\"10.1109/IRI49571.2020.00019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"585444d019ed1251f4207fc8c821ae6194f1214c\",\"title\":\"Dynamic image for micro-expression recognition on region-based framework\",\"url\":\"https://www.semanticscholar.org/paper/585444d019ed1251f4207fc8c821ae6194f1214c\",\"venue\":\"2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI)\",\"year\":2020},{\"arxivId\":\"1909.12673\",\"authors\":[{\"authorId\":\"1380165568\",\"name\":\"Jonathan S. Rosenfeld\"},{\"authorId\":\"32928116\",\"name\":\"Amir Rosenfeld\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"2613669\",\"name\":\"N. Shavit\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ff77dc78de70cf0b35234505095c33b4e62d096\",\"title\":\"A Constructive Prediction of the Generalization Error Across Scales\",\"url\":\"https://www.semanticscholar.org/paper/9ff77dc78de70cf0b35234505095c33b4e62d096\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134665127\",\"name\":\"Roberto S\\u00e1nchez P\\u00e1manes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c03323dc648d7739aa230ea2d65eb02a0558c6a\",\"title\":\"Learning temporal features of facial action units using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/4c03323dc648d7739aa230ea2d65eb02a0558c6a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.11992\",\"authors\":[{\"authorId\":\"152823401\",\"name\":\"Bram Wallace\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"}],\"doi\":\"10.1007/978-3-030-58574-7_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee9a2ff3952c25a6d78122c4366146829fd1c0e0\",\"title\":\"Extending and Analyzing Self-Supervised Learning Across Domains\",\"url\":\"https://www.semanticscholar.org/paper/ee9a2ff3952c25a6d78122c4366146829fd1c0e0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578886\",\"name\":\"Mohamed R. Ibrahim\"},{\"authorId\":\"38973565\",\"name\":\"J. Haworth\"},{\"authorId\":\"145561918\",\"name\":\"N. Christie\"},{\"authorId\":\"49829302\",\"name\":\"T. Cheng\"},{\"authorId\":\"1718391\",\"name\":\"S. Hailes\"}],\"doi\":\"10.1080/01441647.2020.1840456\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b89e059bbec06777dbba1d26464700c423b1fa\",\"title\":\"Cycling near misses: a review of the current methods, challenges and the potential of an AI-embedded system\",\"url\":\"https://www.semanticscholar.org/paper/46b89e059bbec06777dbba1d26464700c423b1fa\",\"venue\":\"\",\"year\":2020}],\"corpusId\":474607,\"doi\":\"10.1109/CVPR.2016.331\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":63,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"references\":[{\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/CVPR.2015.7298616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":\"10.1023/B:STCO.0000035301.49549.88\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"06bb5771e6b8a9356c5f4ae28c98b4397c043349\",\"title\":\"A tutorial on support vector regression\",\"url\":\"https://www.semanticscholar.org/paper/06bb5771e6b8a9356c5f4ae28c98b4397c043349\",\"venue\":\"Stat. Comput.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-16814-2_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"52e0c03dd661d032865dfedd91ca49542ccfc2a3\",\"title\":\"Improving Human Action Recognition Using Score Distribution and Ranking\",\"url\":\"https://www.semanticscholar.org/paper/52e0c03dd661d032865dfedd91ca49542ccfc2a3\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Srivastava\"},{\"authorId\":null,\"name\":\"E. Mansimov\"},{\"authorId\":null,\"name\":\"R. Salakhudinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsupervised learning of video representations using lstms\",\"url\":\"\",\"venue\":\"In Proc. ICML,\",\"year\":2015},{\"arxivId\":\"1505.05192\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2015.167\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"title\":\"Unsupervised Visual Representation Learning by Context Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"},{\"authorId\":\"144429686\",\"name\":\"J. Davis\"}],\"doi\":\"10.1109/34.910878\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"886431a362bfdbcc6dd518f844eb374950b9de86\",\"title\":\"The Recognition of Human Movement Using Temporal Templates\",\"url\":\"https://www.semanticscholar.org/paper/886431a362bfdbcc6dd518f844eb374950b9de86\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"641421832f237b280644261a77eca3974ac9c0c1\",\"title\":\"Discriminative Hierarchical Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/641421832f237b280644261a77eca3974ac9c0c1\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6505\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2015.7298691\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"title\":\"Pooled motion features for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2315504\",\"name\":\"Raia Hadsell\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/CVPR.2005.202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfaae9b6857b834043606df3342d8dc97524aa9d\",\"title\":\"Learning a similarity metric discriminatively, with application to face verification\",\"url\":\"https://www.semanticscholar.org/paper/cfaae9b6857b834043606df3342d8dc97524aa9d\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.01848\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/TPAMI.2016.2558148\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd4defba71c686946351f5e7a090c7aa8136d32f\",\"title\":\"Rank Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4defba71c686946351f5e7a090c7aa8136d32f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1503.04144\",\"authors\":[{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"1689313\",\"name\":\"Florian Luisier\"},{\"authorId\":\"144941335\",\"name\":\"Walter Andrews\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.5244/C.29.60\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"title\":\"Exploiting Image-trained CNN Architectures for Unconstrained Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":\"1507.05738\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"47243342\",\"name\":\"N. Jin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-017-1013-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"title\":\"Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPR.2014.330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48ce52c12e15300be979807ecf49978ad7f2f861\",\"title\":\"Towards Good Practices for Action Video Encoding\",\"url\":\"https://www.semanticscholar.org/paper/48ce52c12e15300be979807ecf49978ad7f2f861\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Caffe: An open source convolutional architecture for fast feature embedding\",\"url\":\"\",\"venue\":\"http://caffe. berkeleyvision.org/,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2690389\",\"name\":\"M. Mazloom\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/TMM.2014.2359771\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"413c659e330aefdf5412067f6fdcc640b20b2bcf\",\"title\":\"Conceptlets: Selective Semantics for Classifying Video Events\",\"url\":\"https://www.semanticscholar.org/paper/413c659e330aefdf5412067f6fdcc640b20b2bcf\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2014},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Dynamic Image Networks for Action Recognition\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Approximation algorithm\",\"topicId\":\"87\",\"url\":\"https://www.semanticscholar.org/topic/87\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Visual inspection\",\"topicId\":\"48727\",\"url\":\"https://www.semanticscholar.org/topic/48727\"},{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"Autostereogram\",\"topicId\":\"99453\",\"url\":\"https://www.semanticscholar.org/topic/99453\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Raw image format\",\"topicId\":\"786995\",\"url\":\"https://www.semanticscholar.org/topic/786995\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Image processing\",\"topicId\":\"7842\",\"url\":\"https://www.semanticscholar.org/topic/7842\"},{\"topic\":\"Learning to rank\",\"topicId\":\"135827\",\"url\":\"https://www.semanticscholar.org/topic/135827\"}],\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"