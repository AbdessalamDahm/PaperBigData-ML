"{\"abstract\":\"We present a method that learns to answer visual questions by selecting image regions relevant to the text-based query. Our method maps textual queries and visual features from various regions into a shared space where they are compared for relevance with an inner product. Our method exhibits significant improvements in answering questions such as \\\"what color,\\\" where it is necessary to evaluate a specific location, and \\\"what room,\\\" where it selectively identifies informative image regions. Our model is tested on the recently released VQA [1] dataset, which features free-form human-annotated questions and answers.\",\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\",\"url\":\"https://www.semanticscholar.org/author/143953573\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\",\"url\":\"https://www.semanticscholar.org/author/37415643\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\",\"url\":\"https://www.semanticscholar.org/author/2433269\"}],\"citationVelocity\":69,\"citations\":[{\"arxivId\":\"1603.07396\",\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"153778850\",\"name\":\"M. Salvato\"},{\"authorId\":\"3386570\",\"name\":\"Eric Kolve\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1007/978-3-319-46493-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"title\":\"A Diagram is Worth a Dozen Images\",\"url\":\"https://www.semanticscholar.org/paper/e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"48873415\",\"name\":\"Na Rong\"},{\"authorId\":\"145414551\",\"name\":\"Takashi Miyazaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"98025d3d44e9379736adb1228919272ded9298ae\",\"title\":\"Visual Question Answering Dataset for Bilingual Image Understanding: A Study of Cross-Lingual Transfer Using Attention Maps\",\"url\":\"https://www.semanticscholar.org/paper/98025d3d44e9379736adb1228919272ded9298ae\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"287c5be2610e1c61798851feb32b88c424acfbf9\",\"title\":\"Hierarchical Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/287c5be2610e1c61798851feb32b88c424acfbf9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145268319\",\"name\":\"Qiang Sun\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":\"10.1145/3323873.3325044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c6f05eac12622146fec4868735daa78f79f80a\",\"title\":\"Stacked Self-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33c6f05eac12622146fec4868735daa78f79f80a\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"269546925f0fd457b31c13c2870343b0aed761dc\",\"title\":\"Visual Question Answering with Question Representation Update (QRU)\",\"url\":\"https://www.semanticscholar.org/paper/269546925f0fd457b31c13c2870343b0aed761dc\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1704.02516\",\"authors\":[{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/CVPR.2017.773\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"title\":\"An Empirical Evaluation of Visual Question Answering for Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1806.00523\",\"authors\":[{\"authorId\":\"31352445\",\"name\":\"Kashyap Chitta\"}],\"doi\":\"10.1007/978-3-030-11018-5_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"title\":\"Targeted Kernel Networks: Faster Convolutions with Attentive Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1612.05386\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.416\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"title\":\"The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions\",\"url\":\"https://www.semanticscholar.org/paper/7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32285139\",\"name\":\"Hanxiao Wang\"},{\"authorId\":\"1699322\",\"name\":\"Venkatesh Saligrama\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"}],\"doi\":\"10.1109/ICCV.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a60524d43ad94aa448f84adb2d908fbefca9c0a\",\"title\":\"Cost-Aware Fine-Grained Recognition for IoTs Based on Sequential Fixations\",\"url\":\"https://www.semanticscholar.org/paper/2a60524d43ad94aa448f84adb2d908fbefca9c0a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/WACV.2018.00205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03c820f35afdc38dd05e4c663d2877e2602bcde0\",\"title\":\"Semantically Guided Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/03c820f35afdc38dd05e4c663d2877e2602bcde0\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66758719\",\"name\":\"Rahul Ambati\"},{\"authorId\":\"1574528555\",\"name\":\"Chakravardhan Reddy Dudyala\"}],\"doi\":\"10.1109/INDICON45594.2018.8987108\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72379e4fbbc8a0bb52eac863188261f9951a9352\",\"title\":\"A Sequence-to-Sequence Model Approach for ImageCLEF 2018 Medical Domain Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72379e4fbbc8a0bb52eac863188261f9951a9352\",\"venue\":\"2018 15th IEEE India Council International Conference (INDICON)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2017/492\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"title\":\"Video Question Answering via Hierarchical Spatio-Temporal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1811.06868\",\"authors\":[{\"authorId\":\"32285139\",\"name\":\"Hanxiao Wang\"},{\"authorId\":\"1699322\",\"name\":\"Venkatesh Saligrama\"},{\"authorId\":\"1749590\",\"name\":\"Stan Sclaroff\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61f8b19246a048e5a1a6f961f432c44e93801ed4\",\"title\":\"Learning Where to Fixate on Foveated Images\",\"url\":\"https://www.semanticscholar.org/paper/61f8b19246a048e5a1a6f961f432c44e93801ed4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.08697\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"51007384\",\"name\":\"Mary Arpita Pyreddy\"},{\"authorId\":\"40895015\",\"name\":\"Matthieu Felix\"},{\"authorId\":\"50745535\",\"name\":\"Narendra Nath Joshi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"title\":\"Textually Enriched Neural Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964003\",\"name\":\"C. Lee\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"2208161\",\"name\":\"Szu-Lin Wu\"},{\"authorId\":\"117660020\",\"name\":\"Chi-Liang Liu\"},{\"authorId\":\"145359071\",\"name\":\"Wei Fang\"},{\"authorId\":\"3451540\",\"name\":\"Juei-Yang Hsu\"},{\"authorId\":\"33870107\",\"name\":\"Bo-Hsiang Tseng\"}],\"doi\":\"10.1109/TASLP.2019.2913499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"title\":\"Machine Comprehension of Spoken Content: TOEFL Listening Test and Spoken SQuAD\",\"url\":\"https://www.semanticscholar.org/paper/76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49658047\",\"name\":\"Haifang Qin\"},{\"authorId\":\"3493754\",\"name\":\"Weixiang Hong\"},{\"authorId\":\"1761842\",\"name\":\"Wei-Chih Hung\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ea2fb93e755ac510b8d0e496ee62a3d77c1b438\",\"title\":\"A Top-Down Unified Framework for Instance-level Human Parsing\",\"url\":\"https://www.semanticscholar.org/paper/9ea2fb93e755ac510b8d0e496ee62a3d77c1b438\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1804.00298\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/CVPR.2018.00801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"title\":\"Differential Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1801.07853\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"48032659\",\"name\":\"Xiaoyi Liu\"},{\"authorId\":\"49330599\",\"name\":\"Liangjian Chen\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/WACV.2018.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"title\":\"Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"46264522\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICCV.2019.00470\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"title\":\"From Strings to Things: Knowledge-Enabled VQA Model That Can Read and Reason\",\"url\":\"https://www.semanticscholar.org/paper/ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"},{\"authorId\":\"145380213\",\"name\":\"B. He\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99a01a687f7959de4c86102342d4bcfec6382aa8\",\"title\":\"Multi-Channel Co-Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99a01a687f7959de4c86102342d4bcfec6382aa8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1711.07373\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"title\":\"Attentive Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1710.05126\",\"authors\":[{\"authorId\":\"2981096\",\"name\":\"Sagi Eppel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab419b13d6c16182860d8c151f8be5f4e2dc1b8c\",\"title\":\"Hierarchical semantic segmentation using modular convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/ab419b13d6c16182860d8c151f8be5f4e2dc1b8c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.02353\",\"authors\":[{\"authorId\":\"144057050\",\"name\":\"Changsong Yu\"},{\"authorId\":\"3391615\",\"name\":\"Karim Said Barsim\"},{\"authorId\":\"8391640\",\"name\":\"Qiuqiang Kong\"},{\"authorId\":\"49188298\",\"name\":\"B. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f5263cda2d58fb3dfaff5ec6db70b0d2ae53c68\",\"title\":\"Multi-level Attention Model for Weakly Supervised Audio Classification\",\"url\":\"https://www.semanticscholar.org/paper/9f5263cda2d58fb3dfaff5ec6db70b0d2ae53c68\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb4fc76dc335f89d258f38676ea6e92c9ddf66c6\",\"title\":\"Multimodal Learning and Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb4fc76dc335f89d258f38676ea6e92c9ddf66c6\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152309496\",\"name\":\"Lihua Lu\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"},{\"authorId\":\"15998344\",\"name\":\"Ruizhe Yu\"},{\"authorId\":\"1932096\",\"name\":\"Huijun Di\"},{\"authorId\":\"47058900\",\"name\":\"L. Zhang\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"}],\"doi\":\"10.1109/TMM.2019.2930344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47074a01fd7a9da34fa8b0496fda19d7dda7372\",\"title\":\"GAIM: Graph Attention Interaction Model for Collective Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c47074a01fd7a9da34fa8b0496fda19d7dda7372\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1610.06272\",\"authors\":[{\"authorId\":\"2369861\",\"name\":\"Bonggun Shin\"},{\"authorId\":\"145106230\",\"name\":\"Timothy Lee\"},{\"authorId\":\"4724587\",\"name\":\"Jinho D. Choi\"}],\"doi\":\"10.18653/v1/W17-5220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c755fd7686f8ed25f7c66ff27d99ff71fee1bd5\",\"title\":\"Lexicon Integrated CNN Models with Attention for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1c755fd7686f8ed25f7c66ff27d99ff71fee1bd5\",\"venue\":\"WASSA@EMNLP\",\"year\":2017},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1609.05600\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7d007ba376faddf0046930ea7375ed59600cee9\",\"title\":\"Graph-Structured Representations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c7d007ba376faddf0046930ea7375ed59600cee9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20506582\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"49167156\",\"name\":\"B. Liu\"},{\"authorId\":\"2607732\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11390-017-1755-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0801d539bacc3e3bc42e2e96bdb8f5d9bec67b41\",\"title\":\"Deep Multimodal Reinforcement Network with Contextually Guided Recurrent Attention for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0801d539bacc3e3bc42e2e96bdb8f5d9bec67b41\",\"venue\":\"Journal of Computer Science and Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.5244/C.31.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d814981606fe5954148e45c737f1debe7b5b36c4\",\"title\":\"Visual Textbook Network: Watch Carefully before Answering Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/d814981606fe5954148e45c737f1debe7b5b36c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"48696362\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894845\",\"name\":\"Fei Wu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3394171.3413745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"title\":\"Photo Stream Question Answer\",\"url\":\"https://www.semanticscholar.org/paper/a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/TMM.2019.2935678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8559c89a4df40ec6250cc8a04d1a5d5f3a84623e\",\"title\":\"Frame Augmented Alternating Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8559c89a4df40ec6250cc8a04d1a5d5f3a84623e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1909.13516\",\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"1380223985\",\"name\":\"Jingdong Shu\"},{\"authorId\":\"34296085\",\"name\":\"Yulei Sui\"},{\"authorId\":\"1747560\",\"name\":\"Guandong Xu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"97569165\",\"name\":\"Jian Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/ASE.2019.00012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0998353a6a342143c08e152650c0146adc61d94b\",\"title\":\"Multi-modal Attention Network Learning for Semantic Source Code Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0998353a6a342143c08e152650c0146adc61d94b\",\"venue\":\"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\"year\":2019},{\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/ICCV.2017.312\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1770702618\",\"name\":\"Majuran Shajini\"},{\"authorId\":\"34672932\",\"name\":\"A. Ramanan\"}],\"doi\":\"10.1007/s00371-020-01885-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deb30d2d1f72f7d76a809b0e575e91368c545bba\",\"title\":\"An improved landmark-driven and spatial\\u2013channel attentive convolutional neural network for fashion clothes classification\",\"url\":\"https://www.semanticscholar.org/paper/deb30d2d1f72f7d76a809b0e575e91368c545bba\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034270322\",\"name\":\"Liyana Sahir Kallooriyakath\"},{\"authorId\":\"2034269084\",\"name\":\"Jithin M V\"},{\"authorId\":\"81431088\",\"name\":\"B. V\"},{\"authorId\":\"2034269088\",\"name\":\"Adith P P\"}],\"doi\":\"10.1109/ICSTCEE49637.2020.9277374\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea0ab46474037363b0a52b758538e61ccb90ecec\",\"title\":\"Visual Question Answering: Methodologies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/ea0ab46474037363b0a52b758538e61ccb90ecec\",\"venue\":\"2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)\",\"year\":2020},{\"arxivId\":\"1604.04279\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46454-1_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"title\":\"Learning Visual Storylines with Skipping Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741390809\",\"name\":\"Weidong Tian\"},{\"authorId\":\"1657469716\",\"name\":\"Rencai Zhou\"},{\"authorId\":\"151481257\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"title\":\"Cascading Top-Down Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66353591\",\"name\":\"Amaia Salvador Aguilera\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"title\":\"Computer vision beyond the visible : image understanding through language\",\"url\":\"https://www.semanticscholar.org/paper/4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1574421683\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"40282454\",\"name\":\"Y. Li\"},{\"authorId\":\"50218711\",\"name\":\"Z. Wang\"},{\"authorId\":\"15696552\",\"name\":\"Bin Wang\"}],\"doi\":\"10.1007/s11042-020-08790-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"title\":\"Object-difference drived graph convolutional networks for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32482521\",\"name\":\"P. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"title\":\"Towards Interpretable Vision Systems\",\"url\":\"https://www.semanticscholar.org/paper/00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1606.04446\",\"authors\":[{\"authorId\":\"2475428\",\"name\":\"Spyros Gidaris\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4e9251d194b0ce95a9b7f35c7da07554228c689\",\"title\":\"Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization\",\"url\":\"https://www.semanticscholar.org/paper/a4e9251d194b0ce95a9b7f35c7da07554228c689\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30588063\",\"name\":\"F. Babiloni\"},{\"authorId\":\"47774782\",\"name\":\"I. Marras\"},{\"authorId\":\"1729399584\",\"name\":\"Gregory Slabaugh\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/cvpr42600.2020.01396\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c877932f3935679d21005a41958735809a13ca16\",\"title\":\"TESA: Tensor Element Self-Attention via Matricization\",\"url\":\"https://www.semanticscholar.org/paper/c877932f3935679d21005a41958735809a13ca16\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.08730\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1490642986\",\"name\":\"Shivansh Pate\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a487065408c44d387aa1cf7836cd58405f945983\",\"title\":\"Robust Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a487065408c44d387aa1cf7836cd58405f945983\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49408473\",\"name\":\"Wenhui Jiang\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"}],\"doi\":\"10.1007/s11042-017-5087-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"676600ed722d4739d669715c16a1ed2fc117b3d4\",\"title\":\"Weakly supervised detection with decoupled attention-based deep representation\",\"url\":\"https://www.semanticscholar.org/paper/676600ed722d4739d669715c16a1ed2fc117b3d4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1908.08527\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2019.00752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"title\":\"ViCo: Word Embeddings From Visual Co-Occurrences\",\"url\":\"https://www.semanticscholar.org/paper/ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.11475\",\"authors\":[{\"authorId\":\"48729196\",\"name\":\"Weijiang Yu\"},{\"authorId\":\"150167685\",\"name\":\"Jingwen Zhou\"},{\"authorId\":\"23476952\",\"name\":\"Weihao Yu\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1730284\",\"name\":\"N. Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ef318e7ff0883e72d853c75736d20cc123b556d5\",\"title\":\"Heterogeneous Graph Learning for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/ef318e7ff0883e72d853c75736d20cc123b556d5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1707.03067\",\"authors\":[{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"3186356\",\"name\":\"X. Zhang\"},{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"67100504\",\"name\":\"C. Thomas\"},{\"authorId\":\"6004292\",\"name\":\"Zuha Agha\"},{\"authorId\":\"34493995\",\"name\":\"Nathan Ong\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2017.123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d173f80797b0e7984d2faf1bd609252a3b365f20\",\"title\":\"Automatic Understanding of Image and Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/d173f80797b0e7984d2faf1bd609252a3b365f20\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1707.04968\",\"authors\":[{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00729\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"title\":\"Visual Question Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48925229\",\"name\":\"Byung-Ju Kim\"},{\"authorId\":\"100498018\",\"name\":\"\\uae40\\ubcd1\\uc8fc\"}],\"doi\":\"10.1049/EL.2017.1881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b86686436608b4083bbca19e6e71e2f780ff3ef7\",\"title\":\"Question aware prediction with candidate answer recommendation for visual question answering = \\ud6c4\\ubcf4 \\ub2f5\\ubcc0 \\uc608\\uce21\\uc744 \\ud1b5\\ud55c \\uc601\\uc0c1 \\uae30\\ubc18 \\uc9c8\\uc758\\uc751\\ub2f5\\uc5d0 \\ub300\\ud55c \\uc5f0\\uad6c\",\"url\":\"https://www.semanticscholar.org/paper/b86686436608b4083bbca19e6e71e2f780ff3ef7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3126686.3126695\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"title\":\"Generative Attention Model with Adversarial Self-learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46812189\",\"name\":\"K. Gao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-3-319-77383-4_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23de896c1b3487803ec6989b1ec1c3bd0c0f8136\",\"title\":\"Spatio-Temporal Context Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/23de896c1b3487803ec6989b1ec1c3bd0c0f8136\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48539596\",\"name\":\"U. Sharma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b715977048c3e112cab5bbae2265012890db7fe\",\"title\":\"Interpreting Decision-Making in Interactive Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/9b715977048c3e112cab5bbae2265012890db7fe\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717592\",\"name\":\"W. Zhang\"},{\"authorId\":\"1792246\",\"name\":\"C. Zhang\"},{\"authorId\":\"3114205\",\"name\":\"P. Liu\"},{\"authorId\":\"2035942\",\"name\":\"Zhiqiang Zhan\"},{\"authorId\":\"34985964\",\"name\":\"Xiaofeng Qiu\"}],\"doi\":\"10.1109/BIGCOM.2017.17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3f24a03b9b55327704fba3aed182323137113c2\",\"title\":\"Two-Step Joint Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a3f24a03b9b55327704fba3aed182323137113c2\",\"venue\":\"2017 3rd International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2017},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39771170\",\"name\":\"Andeep S. Toor\"},{\"authorId\":\"143979395\",\"name\":\"H. Wechsler\"},{\"authorId\":\"144759484\",\"name\":\"M. Nappi\"}],\"doi\":\"10.1007/s11042-018-6097-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bddf7da5a21a5d1915cc9ee784223adadbe0aec4\",\"title\":\"Question action relevance and editing for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/bddf7da5a21a5d1915cc9ee784223adadbe0aec4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1708.00584\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e390a6a6d783bc0898915dc48f7f1844db5137c\",\"title\":\"A Simple Loss Function for Improving the Convergence and Accuracy of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/6e390a6a6d783bc0898915dc48f7f1844db5137c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65885b53d54e52b8bbf31b1714be740eeb544c7f\",\"title\":\"Region Features ... ... Input Image Contextual Object Features ... ... ROI pooling C o n v Conv 5 _ 3 feature map Object Detection Region Proposal Network s Proposals Object Context Encoding\",\"url\":\"https://www.semanticscholar.org/paper/65885b53d54e52b8bbf31b1714be740eeb544c7f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"title\":\"Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network\",\"url\":\"https://www.semanticscholar.org/paper/396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1712.08697\",\"authors\":[{\"authorId\":\"3545259\",\"name\":\"A. Trott\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"title\":\"Interpretable Counting for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743434\",\"name\":\"W. Cheng\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fa1076a98a15cec083fb474f238237f1b3a341a\",\"title\":\"Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-based Method\",\"url\":\"https://www.semanticscholar.org/paper/6fa1076a98a15cec083fb474f238237f1b3a341a\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46812189\",\"name\":\"K. Gao\"},{\"authorId\":\"15318113\",\"name\":\"Xianglei Zhu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-981-10-8530-7_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"333ff6c4544ea083581476e4dc70548aff7fb365\",\"title\":\"Initialized Frame Attention Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/333ff6c4544ea083581476e4dc70548aff7fb365\",\"venue\":\"ICIMCS\",\"year\":2017},{\"arxivId\":\"1804.00105\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708223\",\"name\":\"B. Li\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"title\":\"Visual Question Reasoning on General Dependency Tree\",\"url\":\"https://www.semanticscholar.org/paper/eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.00306\",\"authors\":[{\"authorId\":\"2083816\",\"name\":\"Cun Mu\"},{\"authorId\":\"143951510\",\"name\":\"Guang Yang\"},{\"authorId\":\"145843573\",\"name\":\"Z. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca27ee5223234972288824514f4d96f191e6dae4\",\"title\":\"Revisiting Skip-Gram Negative Sampling Model with Rectification\",\"url\":\"https://www.semanticscholar.org/paper/ca27ee5223234972288824514f4d96f191e6dae4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"1752876325\",\"name\":\"Yi Cai\"},{\"authorId\":\"150068355\",\"name\":\"Changmeng Zheng\"},{\"authorId\":\"47740571\",\"name\":\"J. Chen\"},{\"authorId\":\"1701688\",\"name\":\"Ho-fung Leung\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"}],\"doi\":\"10.18653/v1/2020.acl-main.642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ede49ec0dd27849e57152d5116770bcbe3e01874\",\"title\":\"Aligned Dual Channel Graph Convolutional Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ede49ec0dd27849e57152d5116770bcbe3e01874\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471463062\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1522102572\",\"name\":\"Zhen Lei\"},{\"authorId\":\"1415720379\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"title\":\"Context-Aware Attention Network for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d5bb9b38c44448512973e5bbacb5f7468aee2b6\",\"title\":\"Asking Friendly Strangers: Non-Semantic Attribute Transfer\",\"url\":\"https://www.semanticscholar.org/paper/3d5bb9b38c44448512973e5bbacb5f7468aee2b6\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1910.06315\",\"authors\":[{\"authorId\":\"153636852\",\"name\":\"Soumik Ranjan Dasgupta\"},{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"title\":\"Dynamic Attention Networks for Task Oriented Grounding\",\"url\":\"https://www.semanticscholar.org/paper/361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471705596\",\"name\":\"Yali Cai\"},{\"authorId\":\"38435706\",\"name\":\"X. Wang\"},{\"authorId\":\"48567102\",\"name\":\"Zhihong Yu\"},{\"authorId\":\"145987554\",\"name\":\"F. Li\"},{\"authorId\":\"1471704334\",\"name\":\"Peirong Xu\"},{\"authorId\":\"93648239\",\"name\":\"Yueli Li\"},{\"authorId\":\"47681783\",\"name\":\"Lixian Li\"}],\"doi\":\"10.1109/ACCESS.2019.2958864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9770263651d8805bb0aac3eb93299867010f3cdd\",\"title\":\"Dualattn-GAN: Text to Image Synthesis With Dual Attentional Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/9770263651d8805bb0aac3eb93299867010f3cdd\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Yuxiao Chen\"},{\"authorId\":null,\"name\":\"Han Guo\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/BigData.2018.8622513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d77731d2b2e0c8be5bf2d247974029f769064529\",\"title\":\"You Type a Few Words and We Do the Rest: Image Recommendation for Social Multimedia Posts\",\"url\":\"https://www.semanticscholar.org/paper/d77731d2b2e0c8be5bf2d247974029f769064529\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"145863022\",\"name\":\"X. Zhang\"}],\"doi\":\"10.20944/PREPRINTS201804.0313.V1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"38387275\",\"name\":\"Y. Zhou\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"},{\"authorId\":\"145760952\",\"name\":\"C. Hou\"}],\"doi\":\"10.1109/ICIP.2017.8296323\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b73caad32e8af6e36696339c93ef4a34a65623f8\",\"title\":\"Label propagation based saliency detection via graph design\",\"url\":\"https://www.semanticscholar.org/paper/b73caad32e8af6e36696339c93ef4a34a65623f8\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1802.02598\",\"authors\":[{\"authorId\":\"35929071\",\"name\":\"Matthew Klawonn\"},{\"authorId\":\"39110759\",\"name\":\"E. Heim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8fcd2b0dfa4ebd77880726f671b9ec03332e7cde\",\"title\":\"Generating Triples with Adversarial Networks for Scene Graph Construction\",\"url\":\"https://www.semanticscholar.org/paper/8fcd2b0dfa4ebd77880726f671b9ec03332e7cde\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66119300\",\"name\":\"Shuangjia Zheng\"},{\"authorId\":null,\"name\":\"Yongjian Li\"},{\"authorId\":\"98498212\",\"name\":\"Sheng Chen\"},{\"authorId\":\"152327955\",\"name\":\"J. Xu\"},{\"authorId\":\"46286259\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1038/s42256-020-0152-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a6d56b10e8945b98f7ac17f234475e64736cb4\",\"title\":\"Predicting drug\\u2013protein interaction using quasi-visual question answering system\",\"url\":\"https://www.semanticscholar.org/paper/10a6d56b10e8945b98f7ac17f234475e64736cb4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1987725399\",\"name\":\"Jianhang Shuai\"},{\"authorId\":\"153152486\",\"name\":\"Ling Xu\"},{\"authorId\":\"47536010\",\"name\":\"Chao Liu\"},{\"authorId\":\"1491644251\",\"name\":\"Meng Yan\"},{\"authorId\":\"1516124572\",\"name\":\"Xin Xia\"},{\"authorId\":\"1664969571\",\"name\":\"Yan Lei\"}],\"doi\":\"10.1145/3387904.3389269\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8869b543e46ed50d403658c6a05d6fb4c9601e4\",\"title\":\"Improving Code Search with Co-Attentive Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a8869b543e46ed50d403658c6a05d6fb4c9601e4\",\"venue\":\"ICPC\",\"year\":2020},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.10889\",\"authors\":[{\"authorId\":\"39547281\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"23590685\",\"name\":\"Jinkun Cao\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-01249-6_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"544016b1d49a951de728d27a9b1183fabba000ec\",\"title\":\"Pairwise Body-Part Attention for Recognizing Human-Object Interactions\",\"url\":\"https://www.semanticscholar.org/paper/544016b1d49a951de728d27a9b1183fabba000ec\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Wang\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.5555/3398761.3399067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d309b15d13361257ab3099fb9af6908284fce52\",\"title\":\"An Interpretable Multimodal Visual Question Answering System using Attention-based Weighted Contextual Features\",\"url\":\"https://www.semanticscholar.org/paper/2d309b15d13361257ab3099fb9af6908284fce52\",\"venue\":\"AAMAS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3330224\",\"name\":\"Eu Wern Teh\"},{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"}],\"doi\":\"10.5244/C.30.52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcb7cebeb73a864ba8c0f1a5aa36531dfc18942a\",\"title\":\"Attention Networks for Weakly Supervised Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/dcb7cebeb73a864ba8c0f1a5aa36531dfc18942a\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1808.00300\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"}],\"doi\":\"10.1007/978-3-030-01231-1_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afe3a0d463e2f099305c745ddbf943844583795d\",\"title\":\"Learning Visual Question Answering by Bootstrapping Hard Attention\",\"url\":\"https://www.semanticscholar.org/paper/afe3a0d463e2f099305c745ddbf943844583795d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1911.08618\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1609/AAAI.V34I07.6858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"title\":\"Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA\",\"url\":\"https://www.semanticscholar.org/paper/dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1472939182\",\"name\":\"Sayedshayan Hashemi Hosseinabad\"},{\"authorId\":\"2179339\",\"name\":\"M. Safayani\"},{\"authorId\":\"145238808\",\"name\":\"A. Mirzaei\"}],\"doi\":\"10.1007/s00371-019-01786-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1072c09f843ba976803ea14b8bf2c4e932ac56d\",\"title\":\"Multiple answers to a question: a new approach for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/c1072c09f843ba976803ea14b8bf2c4e932ac56d\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1810.11261\",\"authors\":[{\"authorId\":\"50019203\",\"name\":\"Shivansh Rao\"},{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7965b2ce7d64991218515e20fc1fc0459fd20a38\",\"title\":\"Video-based Person Re-identification Using Spatial-Temporal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/7965b2ce7d64991218515e20fc1fc0459fd20a38\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":\"1808.03986\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"49596229\",\"name\":\"S. Kumar\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.18653/v1/D18-1434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"title\":\"Multimodal Differential Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1611.08481\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/CVPR.2017.475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bed7834ae7d371171977a590872f60d137c2f951\",\"title\":\"GuessWhat?! Visual Object Discovery through Multi-modal Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/bed7834ae7d371171977a590872f60d137c2f951\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.00460\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2018.00930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09efde3bd0a380e8cbcd55a13694648276c2c166\",\"title\":\"Customized Image Narrative Generation via Interactive Visual Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/09efde3bd0a380e8cbcd55a13694648276c2c166\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73453616\",\"name\":\"S. Sarath\"},{\"authorId\":\"67097178\",\"name\":\"J. Amudha\"}],\"doi\":\"10.1109/incet49848.2020.9154094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48495aac7c5b958f27f5d32951db35590dfb7e6e\",\"title\":\"V\\u03b9sual question answering models Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/48495aac7c5b958f27f5d32951db35590dfb7e6e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.02164\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1387254703\",\"name\":\"Giuseppe Carenini\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"title\":\"An Improved Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/AVSS.2019.8909869\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb06af4e0e459ae9e01aa9068fcd5922316400e9\",\"title\":\"Video-Based Person Re-Identification using Refined Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/bb06af4e0e459ae9e01aa9068fcd5922316400e9\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1708.02071\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"49339267\",\"name\":\"Yanpeng Zhao\"},{\"authorId\":\"24027493\",\"name\":\"Shuaiyi Huang\"},{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1109/ICCV.2017.145\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5823d18cd378898b12de537862d996443ce9c9e8\",\"title\":\"Structured Attentions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5823d18cd378898b12de537862d996443ce9c9e8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144905355\",\"name\":\"Chao Ma\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145950894\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"title\":\"Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"144914662\",\"name\":\"F. Xiao\"},{\"authorId\":\"143728443\",\"name\":\"Le An\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"48305363\",\"name\":\"Xiaochuan Sun\"}],\"doi\":\"10.1145/3300938\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"title\":\"Semantic Concept Network and Deep Walk-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"49899378\",\"name\":\"S. T. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICME.2017.8019540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb8f1f77a8b19d99dfe0c7b50dae3978cf646aa9\",\"title\":\"Adaptive attention fusion network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/cb8f1f77a8b19d99dfe0c7b50dae3978cf646aa9\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240687\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"title\":\"Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA\",\"url\":\"https://www.semanticscholar.org/paper/97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40939264\",\"name\":\"Jiaxu Leng\"},{\"authorId\":\"46399320\",\"name\":\"Y. Liu\"},{\"authorId\":\"9416328\",\"name\":\"Tianlin Zhang\"},{\"authorId\":\"46234628\",\"name\":\"Pei Quan\"}],\"doi\":\"10.1109/ICDMW.2018.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b80a7bbde2986a0b3474258ec2fad0a75813d89f\",\"title\":\"Context Learning Network for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b80a7bbde2986a0b3474258ec2fad0a75813d89f\",\"venue\":\"2018 IEEE International Conference on Data Mining Workshops (ICDMW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Yuxiao Chen\"},{\"authorId\":null,\"name\":\"Han Guo\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3184558.3186346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1bb6bf3de3101863b03fd6ce643a68bc30fa256\",\"title\":\"When E-commerce Meets Social Media: Identifying Business on WeChat Moment Using Bilateral-Attention LSTM\",\"url\":\"https://www.semanticscholar.org/paper/f1bb6bf3de3101863b03fd6ce643a68bc30fa256\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2083816\",\"name\":\"Cun Mu\"},{\"authorId\":\"38872334\",\"name\":\"G. Yang\"},{\"authorId\":\"145843579\",\"name\":\"Z. Yan\"}],\"doi\":\"10.1007/978-3-030-22871-2_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85e1cf2f07f128d03f9242d6fd248e7e11b6d37a\",\"title\":\"Revisiting Skip-Gram Negative Sampling Model with Regularization\",\"url\":\"https://www.semanticscholar.org/paper/85e1cf2f07f128d03f9242d6fd248e7e11b6d37a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":\"1812.01748\",\"authors\":[{\"authorId\":\"2741053\",\"name\":\"Wang-Cheng Kang\"},{\"authorId\":\"48568065\",\"name\":\"Eric Kim\"},{\"authorId\":\"1702139\",\"name\":\"J. Leskovec\"},{\"authorId\":\"144063294\",\"name\":\"C. Rosenberg\"},{\"authorId\":\"35660011\",\"name\":\"Julian McAuley\"}],\"doi\":\"10.1109/CVPR.2019.01078\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065ed240398c080fba162944846dac5d77561f22\",\"title\":\"Complete the Look: Scene-Based Complementary Product Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/065ed240398c080fba162944846dac5d77561f22\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.09375\",\"authors\":[{\"authorId\":\"145092222\",\"name\":\"Monika Sharma\"},{\"authorId\":\"47924853\",\"name\":\"Shikha Gupta\"},{\"authorId\":\"1391096615\",\"name\":\"Arindam Chowdhury\"},{\"authorId\":\"3213990\",\"name\":\"L. Vig\"}],\"doi\":\"10.1109/IJCNN.2019.8852427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82eba31adfeb607a91503251f0feb22d5577a21d\",\"title\":\"ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks\",\"url\":\"https://www.semanticscholar.org/paper/82eba31adfeb607a91503251f0feb22d5577a21d\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2003.09853\",\"authors\":[{\"authorId\":\"150257726\",\"name\":\"P. Bongini\"},{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1088/1757-899X/949/1/012074\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a08cb38aa4a5a4bc2f6fa0c4d379d23e874c0b7\",\"title\":\"Visual Question Answering for Cultural Heritage\",\"url\":\"https://www.semanticscholar.org/paper/0a08cb38aa4a5a4bc2f6fa0c4d379d23e874c0b7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.06828\",\"authors\":[{\"authorId\":\"2369861\",\"name\":\"Bonggun Shin\"},{\"authorId\":\"5288069\",\"name\":\"F. Chokshi\"},{\"authorId\":\"145106230\",\"name\":\"Timothy Lee\"},{\"authorId\":\"4724587\",\"name\":\"Jinho D. Choi\"}],\"doi\":\"10.1109/IJCNN.2017.7966408\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee706228f0e24855913b78b7e87f1c57f708eaf3\",\"title\":\"Classification of radiology reports using neural attention models\",\"url\":\"https://www.semanticscholar.org/paper/ee706228f0e24855913b78b7e87f1c57f708eaf3\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.08120\",\"authors\":[{\"authorId\":\"2321160\",\"name\":\"Abhijit Sharang\"},{\"authorId\":\"143756813\",\"name\":\"Eric Lau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c0c611ebc538662023c7e5e51654a47e8063c2e\",\"title\":\"Recurrent and Contextual Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c0c611ebc538662023c7e5e51654a47e8063c2e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":null,\"name\":\"James Storer Brandeis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f95ef25dc7f87c6f1224e6e46ff4b86df1a16e\",\"title\":\"Highway Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/39f95ef25dc7f87c6f1224e6e46ff4b86df1a16e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1705.03865\",\"authors\":[{\"authorId\":\"50178628\",\"name\":\"Akshay Kumar Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"637648198f9e91654ce27eaaa40512f2dc870fc1\",\"title\":\"Survey of Visual Question Answering: Datasets and Techniques\",\"url\":\"https://www.semanticscholar.org/paper/637648198f9e91654ce27eaaa40512f2dc870fc1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"2762640\",\"name\":\"Yuanlu Xu\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2018.00449\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71573d5dc03b28279c1a337e9fd91ffbeff47569\",\"title\":\"Attentive Fashion Grammar Network for Fashion Landmark Detection and Clothing Category Classification\",\"url\":\"https://www.semanticscholar.org/paper/71573d5dc03b28279c1a337e9fd91ffbeff47569\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1802.08129\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2018.00915\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"title\":\"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126416\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ICME.2019.00270\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"title\":\"Visual Dialog with Targeted Objects\",\"url\":\"https://www.semanticscholar.org/paper/16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2019.00203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bb60b737b53b23f5eb1f56cd145153d4581330\",\"title\":\"It's Not About the Journey; It's About the Destination: Following Soft Paths Under Question-Guidance for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/80bb60b737b53b23f5eb1f56cd145153d4581330\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1601.03317\",\"authors\":[{\"authorId\":\"144588144\",\"name\":\"Shi Feng\"},{\"authorId\":\"1803054\",\"name\":\"Shujie Liu\"},{\"authorId\":null,\"name\":\"Mu Li\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22358c1e6f371db45a0d237baff6052e0a50e498\",\"title\":\"Implicit Distortion and Fertility Models for Attention-based Encoder-Decoder NMT Model\",\"url\":\"https://www.semanticscholar.org/paper/22358c1e6f371db45a0d237baff6052e0a50e498\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51318557\",\"name\":\"N. Chinaev\"},{\"authorId\":\"2564281\",\"name\":\"Alexander Chigorin\"},{\"authorId\":\"143991677\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/978-3-030-11018-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40c0d8a09de7d7f999f77a4cdb00da33f51af11b\",\"title\":\"Computer Vision \\u2013 ECCV 2018 Workshops\",\"url\":\"https://www.semanticscholar.org/paper/40c0d8a09de7d7f999f77a4cdb00da33f51af11b\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1608.02717\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"117034854\",\"name\":\"Ashkan Mokarian\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.5244/C.30.111\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0c7c81571ff97881277bc37a218d885ec64beb1\",\"title\":\"Mean Box Pooling: A Rich Image Representation and Output Embedding for the Visual Madlibs Task\",\"url\":\"https://www.semanticscholar.org/paper/e0c7c81571ff97881277bc37a218d885ec64beb1\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1808.00265\",\"authors\":[{\"authorId\":\"2373307\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/WACV.2019.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"title\":\"Interpretable Visual Question Answering by Visual Grounding From Attention Supervision Mining\",\"url\":\"https://www.semanticscholar.org/paper/b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"51069511\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/JSTSP.2020.2989701\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b3478e680e957672c4fbc8e1da559588997b325\",\"title\":\"Learning to Recognize Visual Concepts for Visual Question Answering With Structural Label Space\",\"url\":\"https://www.semanticscholar.org/paper/5b3478e680e957672c4fbc8e1da559588997b325\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1704.03895\",\"authors\":[{\"authorId\":\"10730666\",\"name\":\"Siddha Ganju\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"title\":\"What's in a Question: Using Visual Questions as a Form of Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"1691826\",\"name\":\"Y. Li\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532764\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c42892bc5b012be2b2ac7421ccb15005781e6\",\"title\":\"Simple and effective visual question answering in a single modality\",\"url\":\"https://www.semanticscholar.org/paper/940c42892bc5b012be2b2ac7421ccb15005781e6\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2741053\",\"name\":\"Wang-Cheng Kang\"},{\"authorId\":\"48568065\",\"name\":\"Eric Kim\"},{\"authorId\":\"1702139\",\"name\":\"J. Leskovec\"},{\"authorId\":\"144063294\",\"name\":\"C. Rosenberg\"},{\"authorId\":\"35660011\",\"name\":\"Julian McAuley\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85c368b691397814b7100194392ce80ff42690b3\",\"title\":\"\\u201c Shoes \\u201d Output Shop the Look Complete the Look Query OutputQuery\",\"url\":\"https://www.semanticscholar.org/paper/85c368b691397814b7100194392ce80ff42690b3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.08656\",\"authors\":[{\"authorId\":\"7416107\",\"name\":\"Darong Liu\"},{\"authorId\":\"7146976\",\"name\":\"Shun-Po Chuang\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d4ff80851cd8d8fe74befeb4043b32880df1d59\",\"title\":\"Attention-based Memory Selection Recurrent Network for Language Modeling\",\"url\":\"https://www.semanticscholar.org/paper/5d4ff80851cd8d8fe74befeb4043b32880df1d59\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"143720148\",\"name\":\"Jinwoo Shin\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7adef3d0200207baec75e39bbb852cacfaf8268b\",\"title\":\"Learning to Specialize with Knowledge Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7adef3d0200207baec75e39bbb852cacfaf8268b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"1478185914\",\"name\":\"Zehan Song\"},{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/TIP.2020.2963950\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"title\":\"Open-Ended Video Question Answering via Multi-Modal Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"2236084\",\"name\":\"Weitong Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7835f6e76e810445a38f76892c5dc58ee17efddb\",\"title\":\"Question : What is on the plate ? S of tm ax Linear Tanh ResNet Faster-RCNN GRU Linear Tanh\",\"url\":\"https://www.semanticscholar.org/paper/7835f6e76e810445a38f76892c5dc58ee17efddb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"26900125\",\"name\":\"Jinghao Lin\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2411270f111a160c9289d56132651c896a5738f6\",\"title\":\"Video Question Answering via Hierarchical Dual-Level Attention Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/2411270f111a160c9289d56132651c896a5738f6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.05113\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1609/AAAI.V33I01.33019062\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"title\":\"Multilevel Language and Vision Integration for Text-to-Clip Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52152408\",\"name\":\"Zihan Guo\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20236758\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"title\":\"Multi-Modal Explicit Sparse Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2110665\",\"name\":\"A. Padmakumar\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"title\":\"Visual Question Answering using Natural Language Object Retrieval and Saliency Cues\",\"url\":\"https://www.semanticscholar.org/paper/aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1809.01810\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708631\",\"name\":\"Bailin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tpami.2019.2943456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"title\":\"Interpretable Visual Question Answering by Reasoning on Dependency Trees\",\"url\":\"https://www.semanticscholar.org/paper/97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1803.05268\",\"authors\":[{\"authorId\":\"3296335\",\"name\":\"D. Mascharka\"},{\"authorId\":\"46450184\",\"name\":\"Philip Tran\"},{\"authorId\":\"49902902\",\"name\":\"Ryan Soklaski\"},{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"}],\"doi\":\"10.1109/CVPR.2018.00519\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd0a7c58964905ccfddbad1614165320ccc56393\",\"title\":\"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cd0a7c58964905ccfddbad1614165320ccc56393\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898103\",\"name\":\"J. Glass\"}],\"doi\":\"10.1007/s11263-019-01205-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2625271\",\"name\":\"Mengfei Li\"},{\"authorId\":\"143628183\",\"name\":\"Li Gu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"title\":\"Text-Guided Dual-Branch Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"144889898\",\"name\":\"Mengqi Jiang\"},{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"46351963\",\"name\":\"Weixin Zhou\"},{\"authorId\":\"2181606\",\"name\":\"K. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2908035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0734fd670605a578b9e4b908e58b63e4142625e\",\"title\":\"Co-Attention Network With Question Type for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f0734fd670605a578b9e4b908e58b63e4142625e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1910.05728\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"title\":\"Granular Multimodal Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72887908\",\"name\":\"Kazuho Morohashi\"},{\"authorId\":\"145472435\",\"name\":\"J. Miura\"}],\"doi\":\"10.1109/ECMR.2019.8870919\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c664e9a3a6befb8b4bfa2fd7f8f15c7f381bd09\",\"title\":\"Query Generation for Resolving Ambiguity in User's Command for a Mobile Service Robot\",\"url\":\"https://www.semanticscholar.org/paper/3c664e9a3a6befb8b4bfa2fd7f8f15c7f381bd09\",\"venue\":\"2019 European Conference on Mobile Robots (ECMR)\",\"year\":2019},{\"arxivId\":\"1608.03410\",\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.5244/C.30.77\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"title\":\"Solving VIsual Madlibs with Multiple Cues\",\"url\":\"https://www.semanticscholar.org/paper/95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1606.06108\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICME.2017.8019436\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"121a9a160f1f2819a01edbe522024b58dbfee798\",\"title\":\"DualNet: Domain-invariant network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/121a9a160f1f2819a01edbe522024b58dbfee798\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740039\",\"name\":\"Jie Chen\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"}],\"doi\":\"10.1016/J.PATREC.2018.06.030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c93fcf73554f2cb9e0bc21da82f9611ae631f55\",\"title\":\"Movie fill in the blank by joint learning from video and text with adaptive temporal attention\",\"url\":\"https://www.semanticscholar.org/paper/3c93fcf73554f2cb9e0bc21da82f9611ae631f55\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6578200\",\"name\":\"Shiling Jiang\"},{\"authorId\":\"1405875318\",\"name\":\"Ming Ma\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"3417894\",\"name\":\"W. Deng\"},{\"authorId\":\"148123516\",\"name\":\"Siyu Ren\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"}],\"doi\":\"10.1007/978-3-030-31654-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87045ac2a065b14a3f6608ac9147fa81b89aa4fb\",\"title\":\"Semantic Reanalysis of Scene Words in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87045ac2a065b14a3f6608ac9147fa81b89aa4fb\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1711.06794\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a6268d2bc1221ea154097feadea0c58f234d02f\",\"title\":\"Co-attending Free-form Regions and Detections with Multi-modal Multiplicative Feature Embedding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9a6268d2bc1221ea154097feadea0c58f234d02f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40651401\",\"name\":\"N. Chaudhuri\"},{\"authorId\":\"153348803\",\"name\":\"I. Bose\"}],\"doi\":\"10.1016/j.dss.2019.113234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4989768a1d7d98fd5a854d5abd603ca71481a038\",\"title\":\"Exploring the role of deep neural networks for post-disaster decision support\",\"url\":\"https://www.semanticscholar.org/paper/4989768a1d7d98fd5a854d5abd603ca71481a038\",\"venue\":\"Decis. Support Syst.\",\"year\":2020},{\"arxivId\":\"1702.06700\",\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2385007824daaf9eac9476fccb1501b7ac166ceb\",\"title\":\"Task-driven Visual Saliency and Attention-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2385007824daaf9eac9476fccb1501b7ac166ceb\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103567595\",\"name\":\"Shayan Hassantabar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"880760777e3671593ba50b7a17b0d30b655fc86d\",\"title\":\"Visual Question Answering : Datasets , Methods , Challenges and Oppurtunities\",\"url\":\"https://www.semanticscholar.org/paper/880760777e3671593ba50b7a17b0d30b655fc86d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47030185\",\"name\":\"Wai-Leong Teh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"481105aa0b5a9b0fe9597447ffb0fff5cb79569d\",\"title\":\"Attention Networks for Weakly Supervised Object Localization Eu\",\"url\":\"https://www.semanticscholar.org/paper/481105aa0b5a9b0fe9597447ffb0fff5cb79569d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.04323\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799537fa855caf53a6a3a7cf20301a81e90da127\",\"title\":\"High-Order Attention Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/799537fa855caf53a6a3a7cf20301a81e90da127\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2086128\",\"name\":\"H. Du\"},{\"authorId\":\"66735072\",\"name\":\"Jingu Qian\"}],\"doi\":\"10.1109/ICSAI.2018.8599366\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9d08f8dc0646d55b94048b9329813ae80419013\",\"title\":\"Hierarchical Gated Convolutional Networks with Multi-Head Attention for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/c9d08f8dc0646d55b94048b9329813ae80419013\",\"venue\":\"2018 5th International Conference on Systems and Informatics (ICSAI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145382463\",\"name\":\"T. Zhao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01258-8_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"380d50f3ccc07fa4f41282395a78c51e33985c39\",\"title\":\"Deep Attention Neural Tensor Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/380d50f3ccc07fa4f41282395a78c51e33985c39\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1908.03289\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"title\":\"Question-Agnostic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"34711141\",\"name\":\"Ankita Bishnu\"},{\"authorId\":\"22267101\",\"name\":\"L. Patel\"}],\"doi\":\"10.18653/v1/P17-3008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8691980eeb827b10cdfb4cc402b3f43f020bc6a\",\"title\":\"Segmentation Guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e8691980eeb827b10cdfb4cc402b3f43f020bc6a\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"2002.10309\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"title\":\"Uncertainty based Class Activation Maps for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.08711\",\"authors\":[{\"authorId\":\"2981096\",\"name\":\"Sagi Eppel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7d2a1d42f0e3182d538cf8fb4d55f3e9d7ce779\",\"title\":\"Setting an attention region for convolutional neural networks using region selective features, for recognition of materials within glass vessels\",\"url\":\"https://www.semanticscholar.org/paper/d7d2a1d42f0e3182d538cf8fb4d55f3e9d7ce779\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"title\":\"Research Statement Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1806.03724\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00569\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"title\":\"Learning Answer Embeddings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3126238\",\"name\":\"Shuzhe Wu\"},{\"authorId\":\"1693589\",\"name\":\"M. Kan\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/s11263-019-01157-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8a4201641a541babfefe66851a1d06b0d3b3a5b\",\"title\":\"Hierarchical Attention for Part-Aware Face Detection\",\"url\":\"https://www.semanticscholar.org/paper/c8a4201641a541babfefe66851a1d06b0d3b3a5b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/s11263-018-1096-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"title\":\"Combining Multiple Cues for Visual Madlibs Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.09718\",\"authors\":[{\"authorId\":\"35358246\",\"name\":\"Mikyas T. Desta\"},{\"authorId\":\"2230576\",\"name\":\"Larry Chen\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"}],\"doi\":\"10.1109/WACV.2018.00201\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23d6bb8edcd86f8439072f932f414329b393473b\",\"title\":\"Object-Based Reasoning in VQA\",\"url\":\"https://www.semanticscholar.org/paper/23d6bb8edcd86f8439072f932f414329b393473b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1709.06308\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fafe70edc7067015ca2d49aef2773c22a71647d\",\"title\":\"Exploring Human-like Attention Supervision in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3fafe70edc7067015ca2d49aef2773c22a71647d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1709.00354\",\"authors\":[{\"authorId\":\"11513977\",\"name\":\"Chia-Wei Ao\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.1109/ICASSP.2018.8462570\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d20758b50a2105be44bc38711408153217a0a11\",\"title\":\"Query-by-Example Spoken Term Detection Using Attention-Based Multi-Hop Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d20758b50a2105be44bc38711408153217a0a11\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2003.08760\",\"authors\":[{\"authorId\":\"145097076\",\"name\":\"Minh H. Vu\"},{\"authorId\":\"40136362\",\"name\":\"T. L\\u00f6fstedt\"},{\"authorId\":\"1401897458\",\"name\":\"Tufve Nyholm\"},{\"authorId\":\"1824404\",\"name\":\"Raphael Sznitman\"}],\"doi\":\"10.1109/TMI.2020.2978284\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6adb61121ca4560915ade532910acde56440b88f\",\"title\":\"A Question-Centric Model for Visual Question Answering in Medical Imaging\",\"url\":\"https://www.semanticscholar.org/paper/6adb61121ca4560915ade532910acde56440b88f\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/512\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"title\":\"Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144588144\",\"name\":\"Shi Feng\"},{\"authorId\":\"1803054\",\"name\":\"Shujie Liu\"},{\"authorId\":\"144610884\",\"name\":\"Nan Yang\"},{\"authorId\":null,\"name\":\"Mu Li\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"1796651\",\"name\":\"K. Q. Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"734d0e41828b53a748336884078777cca127dc27\",\"title\":\"Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/734d0e41828b53a748336884078777cca127dc27\",\"venue\":\"COLING\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145865760\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3240508.3240527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81b3cfd55ca84802cdcc971410e633ed40e04980\",\"title\":\"Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/81b3cfd55ca84802cdcc971410e633ed40e04980\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"},{\"authorId\":\"1789431\",\"name\":\"C. Kroos\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"145022667\",\"name\":\"A. Mesaros\"}],\"doi\":\"10.33682/1syg-dy60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2af6d3e089ccc63757dd00c4a16fc4ffecbd242e\",\"title\":\"Proceedings of the Detection and Classification of Acoustic Scenes and Events 2018 Workshop (DCASE2018)\",\"url\":\"https://www.semanticscholar.org/paper/2af6d3e089ccc63757dd00c4a16fc4ffecbd242e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35458817\",\"name\":\"Sudan Jha\"},{\"authorId\":\"143699471\",\"name\":\"Anirban Dey\"},{\"authorId\":\"145835018\",\"name\":\"R. Kumar\"},{\"authorId\":\"2245174\",\"name\":\"Vijender Kumar Solanki\"}],\"doi\":\"10.9781/IJIMAI.2018.08.004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"title\":\"A Novel Approach on Visual Question Answering by Parameter Prediction using Faster Region Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"venue\":\"Int. J. Interact. Multim. Artif. Intell.\",\"year\":2019},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1704.00260\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2017.452\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"title\":\"Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1909.02218\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"2061528\",\"name\":\"Wenqing Chu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2018.2859820\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96f0908cc138aceb2d5e0180c440e5adc711d855\",\"title\":\"A Better Way to Attend: Attention With Trees for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/96f0908cc138aceb2d5e0180c440e5adc711d855\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144493079\",\"name\":\"Z. Hu\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1904290800\",\"name\":\"Hanyu Liang\"},{\"authorId\":\"1908173213\",\"name\":\"Xingmao Zhang\"},{\"authorId\":\"1901543027\",\"name\":\"Qingguang Liu\"}],\"doi\":\"10.1109/DSC50466.2020.00040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"title\":\"Graph Convolutional Network for Visual Question Answering Based on Fine-grained Question Representation\",\"url\":\"https://www.semanticscholar.org/paper/2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"venue\":\"2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)\",\"year\":2020},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2005.03784\",\"authors\":[{\"authorId\":\"39092446\",\"name\":\"Arianna Yuan\"},{\"authorId\":null,\"name\":\"Yang Li\"}],\"doi\":\"10.1145/3313831.3376870\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"202fa272d3979ae06f27a565eefb2df3d09cc544\",\"title\":\"Modeling Human Visual Search Performance on Realistic Webpages Using Analytical and Deep Learning Methods\",\"url\":\"https://www.semanticscholar.org/paper/202fa272d3979ae06f27a565eefb2df3d09cc544\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412530617\",\"name\":\"Aisha Al-Sadi\"},{\"authorId\":\"1409942322\",\"name\":\"Hana' Al-Theiabat\"},{\"authorId\":\"1398466553\",\"name\":\"Mahmoud Al-Ayyoub\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c01315f0840d8bead978cd9a9cb4c21f0400805\",\"title\":\"The Inception Team at VQA-Med 2020: Pretrained VGG with Data Augmentation for Medical VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/5c01315f0840d8bead978cd9a9cb4c21f0400805\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2310836\",\"name\":\"Bashar Talafha\"},{\"authorId\":\"1398466553\",\"name\":\"Mahmoud Al-Ayyoub\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"title\":\"JUST at VQA-Med: A VGG-Seq2Seq Model\",\"url\":\"https://www.semanticscholar.org/paper/4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488660\",\"name\":\"Rohan Doshi\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"be23e59fb7187e08c071d456a30bcd96f5a8dc76\",\"title\":\"Symbolic VQA on Visual Advertisements with SymViSe Networks\",\"url\":\"https://www.semanticscholar.org/paper/be23e59fb7187e08c071d456a30bcd96f5a8dc76\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7484d9e753ccc529018f8c01027bfef304dc1b9\",\"title\":\"An Interpretable (Conversational) VQA model using Attention based Weighted Contextual Features\",\"url\":\"https://www.semanticscholar.org/paper/d7484d9e753ccc529018f8c01027bfef304dc1b9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.06306\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/ICCV.2019.00754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"title\":\"U-CAM: Visual Explanation Using Uncertainty Based Class Activation Maps\",\"url\":\"https://www.semanticscholar.org/paper/5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2706269\",\"name\":\"Chengxiang Yin\"},{\"authorId\":\"152949437\",\"name\":\"Jian Tang\"},{\"authorId\":\"48559420\",\"name\":\"Zhiyuan Xu\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2938015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d796ff29f8798c418d5374a6632231f02233dbba\",\"title\":\"Memory Augmented Deep Recurrent Neural Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d796ff29f8798c418d5374a6632231f02233dbba\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134716732\",\"name\":\"Spyridon Gidaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4885be757dd23df698d70ac48debcfa8cb0542b6\",\"title\":\"Effective and annotation efficient deep learning for image understanding\",\"url\":\"https://www.semanticscholar.org/paper/4885be757dd23df698d70ac48debcfa8cb0542b6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150156999\",\"name\":\"J. Park\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d78eaf500f06764f635da3924a252490232f451e\",\"title\":\"GRE: Evaluating computer vision models on Generalizability, Robustness, and Extensibility\",\"url\":\"https://www.semanticscholar.org/paper/d78eaf500f06764f635da3924a252490232f451e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145986708\",\"name\":\"Bo Sun\"},{\"authorId\":\"14701865\",\"name\":\"Z. Yao\"},{\"authorId\":\"48380350\",\"name\":\"Yinghui Zhang\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"}],\"doi\":\"10.1016/j.jvcir.2020.102762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86475be7965eebb5edba838788d26c9272f14a3b\",\"title\":\"Local relation network with multilevel attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/86475be7965eebb5edba838788d26c9272f14a3b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1909.04743\",\"authors\":[{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/ICCV.2019.00402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"title\":\"Reasoning About Human-Object Interactions Through Dual Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1704.04224\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.440\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"title\":\"Spatial Memory for Context Reasoning in Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50498297\",\"name\":\"Liang Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"}],\"doi\":\"10.1007/s11042-018-6389-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"713dd629c183056202f31c2a98e5e37e0d83efa4\",\"title\":\"Word-to-region attention network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/713dd629c183056202f31c2a98e5e37e0d83efa4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143669174\",\"name\":\"G. Gunawan\"},{\"authorId\":\"66656850\",\"name\":\"A. Harjono\"},{\"authorId\":\"72895563\",\"name\":\"Hairunnisyah Sahidu\"},{\"authorId\":\"66168011\",\"name\":\"L. Herayanti\"}],\"doi\":\"10.15294/JPII.V6I2.9481\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d6d9593eff72cabf7fc6ae90e93c0f32306c0c\",\"title\":\"Virtual Laboratory to Improve Students' Problem-Solving Skills on Electricity Concept\",\"url\":\"https://www.semanticscholar.org/paper/58d6d9593eff72cabf7fc6ae90e93c0f32306c0c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/WACV.2017.63\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eba9452ba55a9d37e84dae7a4caf11c6ddd377d5\",\"title\":\"Learning Attributes from Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/eba9452ba55a9d37e84dae7a4caf11c6ddd377d5\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.06492\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"title\":\"VQABQ: Visual Question Answering by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1380065125\",\"name\":\"Narges Honarvar Nazari\"},{\"authorId\":\"90323489\",\"name\":\"J. Hahn\"},{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/tpami.2019.2947440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86df22f8dbec3489432063ef569a4793dc232c70\",\"title\":\"Interpreting the Rhetoric of Visual Advertisements.\",\"url\":\"https://www.semanticscholar.org/paper/86df22f8dbec3489432063ef569a4793dc232c70\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1709.07192\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"47353404\",\"name\":\"X. Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47aff6477f05ec32fc163e1943fe9464a8379552\",\"title\":\"Visual Question Generation as Dual Task of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47aff6477f05ec32fc163e1943fe9464a8379552\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1604.04808\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-46448-0_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de984e920b38b07421a1c17fb10e0c6677a4f5fb\",\"title\":\"Learning Models for Actions and Person-Object Interactions with Transfer to Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/de984e920b38b07421a1c17fb10e0c6677a4f5fb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4590286\",\"name\":\"Heyan Huang\"},{\"authorId\":\"7621447\",\"name\":\"X. Wei\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"40620796\",\"name\":\"Xin-Shun Xu\"}],\"doi\":\"10.1145/3233771\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8565e84f97173144a396a63bcdfaa76c583f251\",\"title\":\"From Question to Text\",\"url\":\"https://www.semanticscholar.org/paper/c8565e84f97173144a396a63bcdfaa76c583f251\",\"venue\":\"ACM Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"27563697\",\"name\":\"Pabitra Lenka\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"title\":\"A Unified Framework for Multilingual and Code-Mixed Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1811.11903\",\"authors\":[{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"title\":\"Visual Question Answering as Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1803.11185\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"021b08b823700f8053afc54356e8d0ce57a3df71\",\"title\":\"Unsupervised Textual Grounding: Linking Words to Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/021b08b823700f8053afc54356e8d0ce57a3df71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1109/CCIS.2018.8691361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e074ccab7b7c46b48d643c1026e71e563878885f\",\"title\":\"Sequential Visual Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e074ccab7b7c46b48d643c1026e71e563878885f\",\"venue\":\"2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}],\"corpusId\":11923637,\"doi\":\"10.1109/CVPR.2016.499\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":17,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"references\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Figure 8 Comparison of qualitative results from Val. The larger image shows the selection weights overlaid on the original image (smaller)\",\"url\":\"\",\"venue\":\"Figure 8 Comparison of qualitative results from Val. The larger image shows the selection weights overlaid on the original image (smaller)\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-10593-2_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"title\":\"Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections\",\"url\":\"https://www.semanticscholar.org/paper/fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Sukhbaatar\"},{\"authorId\":null,\"name\":\"A Szlam\"},{\"authorId\":null,\"name\":\"J Weston\"},{\"authorId\":null,\"name\":\"R Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Weakly supervised memory networks. CoRR, abs/1503.08895\",\"url\":\"\",\"venue\":\"Weakly supervised memory networks. CoRR, abs/1503.08895\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2241127\",\"name\":\"Marie-Catherine de Marneffe\"},{\"authorId\":\"3257930\",\"name\":\"Bill MacCartney\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cc228402f31ca749112197720b9ef6af0c16790\",\"title\":\"Generating Typed Dependency Parses from Phrase Structure Parses\",\"url\":\"https://www.semanticscholar.org/paper/3cc228402f31ca749112197720b9ef6af0c16790\",\"venue\":\"LREC\",\"year\":2006},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1007/978-3-319-10602-1_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b183947ee15718b45546eda6b01e179b9a95421f\",\"title\":\"Edge Boxes: Locating Object Proposals from Edges\",\"url\":\"https://www.semanticscholar.org/paper/b183947ee15718b45546eda6b01e179b9a95421f\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1412.4564\",\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"3257286\",\"name\":\"Karel Lenc\"}],\"doi\":\"10.1145/2733373.2807412\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"title\":\"MatConvNet: Convolutional Neural Networks for MATLAB\",\"url\":\"https://www.semanticscholar.org/paper/0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Vedaldi\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Vqa : Visual question answering Predict - ing deep zero - shot convolutional neural networks using textual descriptions\",\"url\":\"\",\"venue\":\"International Conference on Computer Vision ( ICCV )\",\"year\":2015},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Bordes X. Glorot\"},{\"authorId\":null,\"name\":\"Y. Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bengio . Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"\",\"venue\":\"International conference on artificial intelligence and statistics\",\"year\":2010},{\"arxivId\":\"1503.08895\",\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a583af2696030bcf5f556edc74573fbee902be0b\",\"title\":\"Weakly Supervised Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/a583af2696030bcf5f556edc74573fbee902be0b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"L: yes (1.5) I: yes (0.5) R: yes (1.0) Ans: yes!\",\"url\":\"\",\"venue\":\"L: yes (1.5) I: yes (0.5) R: yes (1.0) Ans: yes!\",\"year\":null},{\"arxivId\":\"1506.00511\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.1109/ICCV.2015.483\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6540cb7971d1a9d72562d465172e010fbb729bc3\",\"title\":\"Predicting Deep Zero-Shot Convolutional Neural Networks Using Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6540cb7971d1a9d72562d465172e010fbb729bc3\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67107f78a84bdb2411053cb54e94fa226eea6d8e\",\"title\":\"Deep Sparse Rectifier Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/67107f78a84bdb2411053cb54e94fa226eea6d8e\",\"venue\":\"AISTATS\",\"year\":2011}],\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Color\",\"topicId\":\"2390\",\"url\":\"https://www.semanticscholar.org/topic/2390\"},{\"topic\":\"Google Questions and Answers\",\"topicId\":\"2898125\",\"url\":\"https://www.semanticscholar.org/topic/2898125\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"}],\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"