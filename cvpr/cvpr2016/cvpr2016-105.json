"{\"abstract\":\"The emergence of wearable devices such as portable cameras and smart glasses makes it possible to record life logging first-person videos. Browsing such long unstructured videos is time-consuming and tedious. This paper studies the discovery of moments of user's major or special interest (i.e., highlights) in a video, for generating the summarization of first-person videos. Specifically, we propose a novel pairwise deep ranking model that employs deep learning techniques to learn the relationship between high-light and non-highlight video segments. A two-stream network structure by representing video segments from complementary information on appearance of video frames and temporal dynamics across frames is developed for video highlight detection. Given a long personal video, equipped with the highlight detection model, a highlight score is assigned to each segment. The obtained highlight segments are applied for summarization in two ways: video time-lapse and video skimming. The former plays the highlight (non-highlight) segments at low (high) speed rates, while the latter assembles the sequence of segments with the highest scores. On 100 hours of first-person videos for 15 unique sports categories, our highlight detection achieves the improvement over the state-of-the-art RankSVM method by 10.5% in terms of accuracy. Moreover, our approaches produce video summary with better quality by a user study from 35 human subjects.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\",\"url\":\"https://www.semanticscholar.org/author/2053452\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\",\"url\":\"https://www.semanticscholar.org/author/144025741\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\",\"url\":\"https://www.semanticscholar.org/author/145459057\"}],\"citationVelocity\":39,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1016/j.jvcir.2018.02.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4398b6dc8c524ba69cf44ba7e5a22bad703d9a5d\",\"title\":\"Making a long story short: A multi-importance fast-forwarding egocentric videos with the emphasis on relevant objects\",\"url\":\"https://www.semanticscholar.org/paper/4398b6dc8c524ba69cf44ba7e5a22bad703d9a5d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1907.09408\",\"authors\":[{\"authorId\":\"144125122\",\"name\":\"L. Jiao\"},{\"authorId\":\"70450696\",\"name\":\"Fan Zhang\"},{\"authorId\":\"47185755\",\"name\":\"F. Liu\"},{\"authorId\":\"1702138\",\"name\":\"Shuyuan Yang\"},{\"authorId\":\"47681309\",\"name\":\"L. Li\"},{\"authorId\":\"1897949\",\"name\":\"Zhixi Feng\"},{\"authorId\":\"145036586\",\"name\":\"R. Qu\"}],\"doi\":\"10.1109/ACCESS.2019.2939201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a\",\"title\":\"A Survey of Deep Learning-Based Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58523-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b26d5d20b073828898087f99b81736c0629c1798\",\"title\":\"Learning Trailer Moments in Full-Length Movies with Co-Contrastive Attention\",\"url\":\"https://www.semanticscholar.org/paper/b26d5d20b073828898087f99b81736c0629c1798\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.05538\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.00805\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86f6fda61a6d778055ba20daf486697d933a220e\",\"title\":\"The Pros and Cons: Rank-Aware Temporal Attention for Skill Determination in Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/86f6fda61a6d778055ba20daf486697d933a220e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2020.2969791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"title\":\"Multimedia Intelligence: When Multimedia Meets Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"1763134\",\"name\":\"Yeonho Kim\"},{\"authorId\":\"144499950\",\"name\":\"J. S. Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1016/j.patrec.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c81c88f74d466a65520ea9751970ff781352ec0a\",\"title\":\"First Person Action Recognition via Two-stream ConvNet with Long-term Fusion Pooling\",\"url\":\"https://www.semanticscholar.org/paper/c81c88f74d466a65520ea9751970ff781352ec0a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1007/s11042-019-08175-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"title\":\"Dilated temporal relational adversarial network for generic video summarization\",\"url\":\"https://www.semanticscholar.org/paper/5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1805.03134\",\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c253694c153cc016d745df089bae0220e7f297ee\",\"title\":\"Image Retrieval with Mixed Initiative and Multimodal Feedback\",\"url\":\"https://www.semanticscholar.org/paper/c253694c153cc016d745df089bae0220e7f297ee\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2005.03804\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7cd871b42efb42f507444386e4317efd7dfc10c\",\"title\":\"Text Synopsis Generation for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7cd871b42efb42f507444386e4317efd7dfc10c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145934350\",\"name\":\"Xin Ai\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"}],\"doi\":\"10.1109/BigMM.2018.8499188\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"23ce8736246b8379c343c18a3b6621ce43d5baef\",\"title\":\"Unsupervised Video Summarization Based on Consistent Clip Generation\",\"url\":\"https://www.semanticscholar.org/paper/23ce8736246b8379c343c18a3b6621ce43d5baef\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.3929/ethz-b-000204633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ef504d7e5c94b9f9b8bfd3d1c44c6aa0d0515f2\",\"title\":\"Interest-Based Video Summarization via Subset Selection\",\"url\":\"https://www.semanticscholar.org/paper/8ef504d7e5c94b9f9b8bfd3d1c44c6aa0d0515f2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2506370\",\"name\":\"Sinnu Susan Thomas\"},{\"authorId\":\"144879221\",\"name\":\"S. Gupta\"},{\"authorId\":\"32325586\",\"name\":\"V. Subramanian\"}],\"doi\":\"10.1109/TCSVT.2018.2873185\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b4335a255d9ea4b5dfa19f5c134f56119046769\",\"title\":\"Context Driven Optimized Perceptual Video Summarization and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9b4335a255d9ea4b5dfa19f5c134f56119046769\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2008.08502\",\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76e71fe84643b72ffb61afe54c9034be824604e3\",\"title\":\"Learning Trailer Moments in Full-Length Movies\",\"url\":\"https://www.semanticscholar.org/paper/76e71fe84643b72ffb61afe54c9034be824604e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144563875\",\"name\":\"Gang Pan\"},{\"authorId\":\"153697527\",\"name\":\"Y. Zheng\"},{\"authorId\":\"8618375\",\"name\":\"R. Zhang\"},{\"authorId\":\"1747832\",\"name\":\"Zhenjun Han\"},{\"authorId\":\"145604388\",\"name\":\"Di Sun\"},{\"authorId\":\"51301667\",\"name\":\"Xingming Qu\"}],\"doi\":\"10.1186/s13634-019-0611-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ee2776f4ce0716f83c7dc50d9b16178bc3d4e7c\",\"title\":\"A bottom-up summarization algorithm for videos in the wild\",\"url\":\"https://www.semanticscholar.org/paper/5ee2776f4ce0716f83c7dc50d9b16178bc3d4e7c\",\"venue\":\"EURASIP J. Adv. Signal Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259919\",\"name\":\"Jiatong Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"40177644\",\"name\":\"Q. Ling\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1016/j.neucom.2017.04.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0951a37ceca4ac90410bb3c9b14cb4a80ca0d1d\",\"title\":\"Detecting shot boundary with sparse coding for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/c0951a37ceca4ac90410bb3c9b14cb4a80ca0d1d\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1903.00859\",\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00135\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"title\":\"Less Is More: Learning Highlight Detection From Video Duration\",\"url\":\"https://www.semanticscholar.org/paper/85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1801.10281\",\"authors\":[{\"authorId\":\"39168231\",\"name\":\"Guangyu Zhong\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"4642456\",\"name\":\"Z. Su\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV.2018.00192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c050087b5af1bcdcd0a9c021efc0fe9f862a4e64\",\"title\":\"Learning Video-Story Composition via Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c050087b5af1bcdcd0a9c021efc0fe9f862a4e64\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143956493\",\"name\":\"I\\u00f1igo Alonso\"},{\"authorId\":\"1743291\",\"name\":\"L. Riazuelo\"},{\"authorId\":\"1991008\",\"name\":\"A. C. Murillo\"}],\"doi\":\"10.1109/ICRA.2019.8793923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84b853b647a8edcc53c6cf815e32dba4b2b60532\",\"title\":\"Enhancing V-SLAM Keyframe Selection with an Efficient ConvNet for Semantic Analysis\",\"url\":\"https://www.semanticscholar.org/paper/84b853b647a8edcc53c6cf815e32dba4b2b60532\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396536560\",\"name\":\"Ran Xu\"},{\"authorId\":\"1679009\",\"name\":\"S. Bagchi\"},{\"authorId\":\"2918969\",\"name\":\"Haoliang Wang\"},{\"authorId\":\"2668884\",\"name\":\"S. Petrangeli\"},{\"authorId\":\"153571209\",\"name\":\"Viswanathan Swaminathan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf47d0d8fde9fbd619188b0a3b259db86556f2db\",\"title\":\"Closing-the-Loop: A Data-Driven Framework for Effective Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/cf47d0d8fde9fbd619188b0a3b259db86556f2db\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"143738684\",\"name\":\"P. Cui\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1109/TCSVT.2017.2771247\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"493293a9f4b53146ef358269459205281fde96f9\",\"title\":\"Video Summarization by Learning Deep Side Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/493293a9f4b53146ef358269459205281fde96f9\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.12.040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0adddb83eb89da8ecd14a296fa016773dc774646\",\"title\":\"Video summarization via spatio-temporal deep architecture\",\"url\":\"https://www.semanticscholar.org/paper/0adddb83eb89da8ecd14a296fa016773dc774646\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87116461\",\"name\":\"M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"80510807\",\"name\":\"E. Nascimento\"}],\"doi\":\"10.1109/SIBGRAPI-T.2019.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"title\":\"Fast-Forward Methods for Egocentric Videos: A Review\",\"url\":\"https://www.semanticscholar.org/paper/380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2379129\",\"name\":\"Patrizia Varini\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TMM.2017.2705915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6465d833e1a050fd959d21eecdee613c1cc869e3\",\"title\":\"Personalized Egocentric Video Summarization of Cultural Tour on User Preferences Input\",\"url\":\"https://www.semanticscholar.org/paper/6465d833e1a050fd959d21eecdee613c1cc869e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1610.01376\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1705203\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TMM.2016.2644872\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"058fcc1f793e526544d5ece5a2c9374c8f913632\",\"title\":\"Recognizing and Presenting the Storytelling Video Structure With Deep Multimodal Networks\",\"url\":\"https://www.semanticscholar.org/paper/058fcc1f793e526544d5ece5a2c9374c8f913632\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1710.08011\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"35163655\",\"name\":\"K. Hata\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba11083602568bbc2514c0905e0d831a65c2af6e\",\"title\":\"ActivityNet Challenge 2017 Summary\",\"url\":\"https://www.semanticscholar.org/paper/ba11083602568bbc2514c0905e0d831a65c2af6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1802.08722\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR.2018.00253\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"title\":\"A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.03473\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"Michel Melo Silva\"},{\"authorId\":\"144151841\",\"name\":\"Washington Luis Souza Ramos\"},{\"authorId\":\"146694654\",\"name\":\"Felipe Cadar Chamone\"},{\"authorId\":\"40834129\",\"name\":\"Jo\\u00e3o Pedro Klock Ferreira\"},{\"authorId\":\"4661295\",\"name\":\"Mario Fernando Montenegro Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1016/j.jvcir.2018.02.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c693855b597cf2c15af9fafc9e14bd2d7c05e61\",\"title\":\"Making a long story short: A Multi-Importance Semantic for Fast-Forwarding Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/8c693855b597cf2c15af9fafc9e14bd2d7c05e61\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2315023\",\"name\":\"Jiachuan Sheng\"},{\"authorId\":\"47558497\",\"name\":\"Y. Chen\"},{\"authorId\":\"50024521\",\"name\":\"Yuzhi Li\"},{\"authorId\":\"49192698\",\"name\":\"L. Li\"}],\"doi\":\"10.1007/s11042-018-5943-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e38280fe35ea6fd39ba92d8e907261c060663d20\",\"title\":\"Embedded learning for computerized production of movie trailers\",\"url\":\"https://www.semanticscholar.org/paper/e38280fe35ea6fd39ba92d8e907261c060663d20\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121638702\",\"name\":\"Jungin Park\"},{\"authorId\":\"82536700\",\"name\":\"J. Lee\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICCVW.2019.00193\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"title\":\"Video Summarization by Learning Relationships between Action and Scene\",\"url\":\"https://www.semanticscholar.org/paper/62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2007.14552\",\"authors\":[{\"authorId\":\"46999304\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeafc087178102645be19fb6975f53b798061b4\",\"title\":\"Compare and Select: Video Summarization with Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/beeafc087178102645be19fb6975f53b798061b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04145\",\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"49473137\",\"name\":\"Zhixiang Shi\"},{\"authorId\":\"1492113737\",\"name\":\"Jiani Li\"},{\"authorId\":\"50248679\",\"name\":\"Guanshuo Wang\"},{\"authorId\":\"46499930\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"50177639\",\"name\":\"Xiaoping Zhou\"}],\"doi\":\"10.1609/AAAI.V34I07.6711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36e38dbfee27f7a34d184dd58186944636de5258\",\"title\":\"Accurate Temporal Action Proposal Generation with Relation-Aware Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/36e38dbfee27f7a34d184dd58186944636de5258\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40396836\",\"name\":\"Ke Niu\"},{\"authorId\":null,\"name\":\"Han Wang\"}],\"doi\":\"10.1007/s11042-019-7442-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb011e242a4eb0b9b4e7c5fc3f84dbcb5197aafd\",\"title\":\"Video highlight extraction via content-aware deep transfer\",\"url\":\"https://www.semanticscholar.org/paper/fb011e242a4eb0b9b4e7c5fc3f84dbcb5197aafd\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144193843\",\"name\":\"Minh Vo\"}],\"doi\":\"10.1184/R1/9816818.V1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd27161a32d1f6c1d9b62b46ce23878046a57b98\",\"title\":\"Exploiting Point Motion, Shape Deformation, and Semantic Priors for Dynamic 3D Reconstruction in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/bd27161a32d1f6c1d9b62b46ce23878046a57b98\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"144362750\",\"name\":\"A. Tan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72e366f26dc199c874874e4c8635403de0f3a9ed\",\"title\":\"Active Video Summarization: Customized Summaries via On-line Interaction with the User\",\"url\":\"https://www.semanticscholar.org/paper/72e366f26dc199c874874e4c8635403de0f3a9ed\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3132818.3132831\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fdac02fd55308be6580ba289134a91376906b1f\",\"title\":\"Egoscanning: quickly scanning first-person videos with egocentric elastic timelines\",\"url\":\"https://www.semanticscholar.org/paper/1fdac02fd55308be6580ba289134a91376906b1f\",\"venue\":\"SIGGRAPH ASIA Emerging Technologies\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528629\",\"name\":\"H. Wang\"},{\"authorId\":\"52144028\",\"name\":\"Huangyue Yu\"},{\"authorId\":\"143685287\",\"name\":\"Pei Chen\"},{\"authorId\":\"144722239\",\"name\":\"Rui Hua\"},{\"authorId\":\"52195887\",\"name\":\"Chuyi Yan\"},{\"authorId\":\"143972418\",\"name\":\"L. Zou\"}],\"doi\":\"10.1109/ICPR.2018.8545808\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7071c41a024acb83cec869a2d9ae524965bf82c8\",\"title\":\"Unsupervised Video Highlight Extraction via Query-related Deep Transfer\",\"url\":\"https://www.semanticscholar.org/paper/7071c41a024acb83cec869a2d9ae524965bf82c8\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1711.08922\",\"authors\":[{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"350fc542f1a6a93b74d74aee14d83bed8782afcd\",\"title\":\"Summarizing First-Person Videos from Third Persons' Points of Views\",\"url\":\"https://www.semanticscholar.org/paper/350fc542f1a6a93b74d74aee14d83bed8782afcd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40286484\",\"name\":\"Xi Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2889265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e3ec088d483f2302aa8b67069c82e8b59deb16d\",\"title\":\"User-Ranking Video Summarization With Multi-Stage Spatio\\u2013Temporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/8e3ec088d483f2302aa8b67069c82e8b59deb16d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1801.04264\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2018.00678\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"598fe25743f9492c5c1ba30274ea446f65426d85\",\"title\":\"Real-World Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/598fe25743f9492c5c1ba30274ea446f65426d85\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.03909\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/TMM.2019.2939711\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2227dede5b64dc40041e1b7517c1f00fd8dbed1\",\"title\":\"Deep Metric Learning With Density Adaptivity\",\"url\":\"https://www.semanticscholar.org/paper/b2227dede5b64dc40041e1b7517c1f00fd8dbed1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2009.05269\",\"authors\":[{\"authorId\":\"93192650\",\"name\":\"Neeraj Baghel\"},{\"authorId\":\"2126345\",\"name\":\"S. C. Raikwar\"},{\"authorId\":\"2479392\",\"name\":\"C. Bhatnagar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c6aff7e4c98f8f8127cf01ad4880796133249f9\",\"title\":\"Image Conditioned Keyframe-Based Video Summarization Using Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/8c6aff7e4c98f8f8127cf01ad4880796133249f9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9304398\",\"name\":\"Jiawei Zuo\"},{\"authorId\":\"16098412\",\"name\":\"Y. Chen\"},{\"authorId\":\"40476136\",\"name\":\"L. Wang\"},{\"authorId\":\"51018452\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1917497790\",\"name\":\"Ting Yao\"},{\"authorId\":\"78646416\",\"name\":\"K. Wang\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3414453\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"title\":\"iDirector: An Intelligent Directing System for Live Broadcast\",\"url\":\"https://www.semanticscholar.org/paper/506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"104008470\",\"name\":\"B. Cui\"},{\"authorId\":\"1476408861\",\"name\":\"Huihui Li\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":\"10.1109/TIP.2020.2991527\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b48e66e9aae8d948700030a31e68dab5c5787ad\",\"title\":\"Deep Ranking for Image Zero-Shot Multi-Label Classification\",\"url\":\"https://www.semanticscholar.org/paper/2b48e66e9aae8d948700030a31e68dab5c5787ad\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860640297\",\"name\":\"Chieh-Ming Liaw\"},{\"authorId\":\"2534439\",\"name\":\"Bi-Ru Dai\"}],\"doi\":\"10.1109/MDM48529.2020.00072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32b4908f630eff3170cb60892addfa9aa5c6d7e1\",\"title\":\"Live Stream Highlight Detection Using Chat Messages\",\"url\":\"https://www.semanticscholar.org/paper/32b4908f630eff3170cb60892addfa9aa5c6d7e1\",\"venue\":\"2020 21st IEEE International Conference on Mobile Data Management (MDM)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144020384\",\"name\":\"Hoseong Kim\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"}],\"doi\":\"10.1109/TMM.2018.2806224\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f27eb66e4aec7fda25ffcbd3cdd0fb4b285c6f67\",\"title\":\"Exploiting Web Images for Video Highlight Detection With Triplet Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/f27eb66e4aec7fda25ffcbd3cdd0fb4b285c6f67\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"2005.09525\",\"authors\":[{\"authorId\":\"50364466\",\"name\":\"Anand Ramakrishnan\"},{\"authorId\":\"29794370\",\"name\":\"Brian Zylich\"},{\"authorId\":\"2920948\",\"name\":\"Erin Ottmar\"},{\"authorId\":\"1403733761\",\"name\":\"Jennifer LoCasale-Crouch\"},{\"authorId\":\"143973061\",\"name\":\"Jacob Whitehill\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"a590eb812fbaf1e00eb3dd148cd42c905e8a6d1f\",\"title\":\"Toward Automated Classroom Observation: Multimodal Machine Learning to Estimate CLASS Positive Climate and Negative Climate\",\"url\":\"https://www.semanticscholar.org/paper/a590eb812fbaf1e00eb3dd148cd42c905e8a6d1f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICIP.2016.7532982\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"768eb5df23dbd95e6514ea7ed553de509a115dc0\",\"title\":\"Semantic highlight retrieval\",\"url\":\"https://www.semanticscholar.org/paper/768eb5df23dbd95e6514ea7ed553de509a115dc0\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1904.10669\",\"authors\":[{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"49217480\",\"name\":\"B. Zhao\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2017.2695887\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18a6a7edfbce1cc11fb7447a133c0ac150b2785c\",\"title\":\"A General Framework for Edited Video and Raw Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/18a6a7edfbce1cc11fb7447a133c0ac150b2785c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"},{\"authorId\":\"2585373\",\"name\":\"J. Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":\"10.1007/s11042-017-5002-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"138ff070ed3e0e4a4c0633d2d20e520a9240cee7\",\"title\":\"Deep learning based basketball video analysis for intelligent arena application\",\"url\":\"https://www.semanticscholar.org/paper/138ff070ed3e0e4a4c0633d2d20e520a9240cee7\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1904.12251\",\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1145/3123266.3123328\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"454e65c2a9b019a00790a1d6029dc5539edad35d\",\"title\":\"Hierarchical Recurrent Neural Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/454e65c2a9b019a00790a1d6029dc5539edad35d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52463586\",\"name\":\"S. El-Tawab\"},{\"authorId\":\"146989442\",\"name\":\"I. Nassar\"},{\"authorId\":\"5737683\",\"name\":\"M. Mehanna\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1148d0eace41ea4c06f4263d7613706d54090350\",\"title\":\"International Journal of Recent Technology and Engineering (IJRTE)\",\"url\":\"https://www.semanticscholar.org/paper/1148d0eace41ea4c06f4263d7613706d54090350\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004857242\",\"name\":\"Ye Zhao\"},{\"authorId\":\"2005410031\",\"name\":\"Xiaobin Hu\"},{\"authorId\":\"1390610633\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"10701403\",\"name\":\"Chunxiao Fan\"}],\"doi\":\"10.1007/978-981-15-7670-6_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86c23cf445c2b11148efa74f8b8019a5bf7c0dae\",\"title\":\"Learning Unsupervised Video Summarization with Semantic-Consistent Network\",\"url\":\"https://www.semanticscholar.org/paper/86c23cf445c2b11148efa74f8b8019a5bf7c0dae\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30799532\",\"name\":\"S. Wang\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"152201640\",\"name\":\"Wenxuan Wang\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f670d781d66200d9714827f894d5c2fe0dd4a1a\",\"title\":\"RUC at MediaEval 2016: Predicting Media Interestingness Task\",\"url\":\"https://www.semanticscholar.org/paper/1f670d781d66200d9714827f894d5c2fe0dd4a1a\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":\"1912.12655\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/WACV45572.2020.9093330\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0155df608af9c0024c6d557b16bdc15af78c5133\",\"title\":\"Personalizing Fast-Forward Videos Based on Visual and Textual Features from Social Network\",\"url\":\"https://www.semanticscholar.org/paper/0155df608af9c0024c6d557b16bdc15af78c5133\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1801.10312\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"35272603\",\"name\":\"Joonil Na\"},{\"authorId\":\"35365676\",\"name\":\"J. Kang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f14cdd95870baa38582f5d0022356cb241ea86f\",\"title\":\"A Deep Ranking Model for Spatio-Temporal Highlight Detection from a 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/9f14cdd95870baa38582f5d0022356cb241ea86f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"},{\"authorId\":\"47203059\",\"name\":\"W. Wu\"}],\"doi\":\"10.29007/21Q3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62d6a2eb42835b64dc3346d51f53d681b288ac26\",\"title\":\"Video Summarization: How to Use Deep-Learned Features Without a Large-Scale Dataset\",\"url\":\"https://www.semanticscholar.org/paper/62d6a2eb42835b64dc3346d51f53d681b288ac26\",\"venue\":\"2018 9th International Conference on Awareness Science and Technology (iCAST)\",\"year\":2018},{\"arxivId\":\"1801.00543\",\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"143810339\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1016/J.PATREC.2018.07.030\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6e20087e39f997631416b54fb67882817f36b56\",\"title\":\"Unsupervised Object-Level Video Summarization with Online Motion Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/c6e20087e39f997631416b54fb67882817f36b56\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/s13735-016-0117-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"title\":\"Learning hierarchical video representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2016},{\"arxivId\":\"2005.11724\",\"authors\":[{\"authorId\":\"47767796\",\"name\":\"L. Wu\"},{\"authorId\":\"46285799\",\"name\":\"Y. Yang\"},{\"authorId\":\"3619088\",\"name\":\"Lei Chen\"},{\"authorId\":\"1862782\",\"name\":\"Defu Lian\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3397271.3401145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb473dc961acb1fccc85693ffa55791151cb0220\",\"title\":\"Learning to Transfer Graph Embeddings for Inductive Graph based Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/fb473dc961acb1fccc85693ffa55791151cb0220\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"1705.00581\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1145/3123266.3123297\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48031e454325487b5fa7972280d1a2400bdef1d4\",\"title\":\"Query-adaptive Video Summarization via Quality-aware Relevance Estimation\",\"url\":\"https://www.semanticscholar.org/paper/48031e454325487b5fa7972280d1a2400bdef1d4\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1910.06189\",\"authors\":[{\"authorId\":\"1739538\",\"name\":\"L. Wang\"},{\"authorId\":\"21072153\",\"name\":\"Zixun Sun\"},{\"authorId\":\"3315113\",\"name\":\"Wentao Yao\"},{\"authorId\":\"47940636\",\"name\":\"Hui Zhan\"},{\"authorId\":\"3252265\",\"name\":\"Chengwei Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d760fc5d63705bd33d33b759fe727149f8e47e67\",\"title\":\"Unsupervised Multi-stream Highlight detection for the Game \\\"Honor of Kings\\\"\",\"url\":\"https://www.semanticscholar.org/paper/d760fc5d63705bd33d33b759fe727149f8e47e67\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.14229\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"46464798\",\"name\":\"M. Silva\"},{\"authorId\":\"152396628\",\"name\":\"E. Ara\\u00fajo\"},{\"authorId\":\"2211313\",\"name\":\"Leandro Soriano Marcolino\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR42600.2020.01094\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"title\":\"Straight to the Point: Fast-Forwarding Videos via Reinforcement Learning Using Textual Data\",\"url\":\"https://www.semanticscholar.org/paper/bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/s11042-018-5953-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"title\":\"Foveated convolutional neural networks for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2733735\",\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22245219e3ccda4026f103e5112329703c3439f1\",\"title\":\"For Your Eyes Only: Learning to Summarize First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/22245219e3ccda4026f103e5112329703c3439f1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/j.patrec.2016.12.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41b18ff48808e4138c6a22a86c281426e0b53d1c\",\"title\":\"Discovering overlooked objects: Context-based boosting of object detection in indoor scenes\",\"url\":\"https://www.semanticscholar.org/paper/41b18ff48808e4138c6a22a86c281426e0b53d1c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46783918\",\"name\":\"T. Hiraoka\"},{\"authorId\":\"2742155\",\"name\":\"Ryosuke Yamanishi\"},{\"authorId\":\"34600958\",\"name\":\"Y. Nishihara\"},{\"authorId\":\"8610596\",\"name\":\"J. Fukumoto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e2991ff55d00abb03d57958facde16bdd488bc2\",\"title\":\"Importance Estimation for Figures and Tables in Scientific Papers Based on Importance and Position of Referring Sentences\",\"url\":\"https://www.semanticscholar.org/paper/8e2991ff55d00abb03d57958facde16bdd488bc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66534613\",\"name\":\"Sukanya Kudi\"},{\"authorId\":\"3185334\",\"name\":\"A. Namboodiri\"}],\"doi\":\"10.1109/ACPR.2017.141\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9887fb200cd15bfa8374dca44caf0e0b3e823a3\",\"title\":\"Words Speak for Actions: Using Text to Find Video Highlights\",\"url\":\"https://www.semanticscholar.org/paper/d9887fb200cd15bfa8374dca44caf0e0b3e823a3\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":\"1910.12201\",\"authors\":[{\"authorId\":\"48637594\",\"name\":\"Ruochen Jiang\"},{\"authorId\":\"46694107\",\"name\":\"Changbo Qu\"},{\"authorId\":\"1743709\",\"name\":\"Jiannan Wang\"},{\"authorId\":\"48586406\",\"name\":\"Chunxin Wang\"},{\"authorId\":\"2985907\",\"name\":\"Yudian Zheng\"}],\"doi\":\"10.1109/ICDE48307.2020.00176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a14fe136c78719b4a1530780a3171bfe3094f32\",\"title\":\"Towards Extracting Highlights From Recorded Live Videos: An Implicit Crowdsourcing Approach\",\"url\":\"https://www.semanticscholar.org/paper/5a14fe136c78719b4a1530780a3171bfe3094f32\",\"venue\":\"2020 IEEE 36th International Conference on Data Engineering (ICDE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920099\",\"name\":\"S. Cai\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"36685537\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1007/978-3-030-01264-9_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"817a781e26c2eabb068973d3cc0bab9220fa401d\",\"title\":\"Weakly-Supervised Video Summarization Using Variational Encoder-Decoder and Web Prior\",\"url\":\"https://www.semanticscholar.org/paper/817a781e26c2eabb068973d3cc0bab9220fa401d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2f9b96c88d929b58d08cd2b2ec431555a018f8b\",\"title\":\"Contextually Customized Video Summaries Via Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/f2f9b96c88d929b58d08cd2b2ec431555a018f8b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"15429809\",\"name\":\"Yangliu Hu\"}],\"doi\":\"10.1007/978-3-030-05716-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"title\":\"Soccer Video Event Detection Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38397846\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"11675891\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1145/3343031.3350992\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a402ff486216270c38ee72f793e49e6f4b861e1\",\"title\":\"Stacked Memory Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/5a402ff486216270c38ee72f793e49e6f4b861e1\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29850862\",\"name\":\"He-Yen Hsieh\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190975\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d0a1105f231ffc200d7b299fb962d8b673369be\",\"title\":\"Temporal Action Proposal Generation Via Deep Feature Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1105f231ffc200d7b299fb962d8b673369be\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1807.04219\",\"authors\":[{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"49681507\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-030-01237-3_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdc254119ff7166d67aeedb544b987ccb8b9eae6\",\"title\":\"How Local is the Local Diversity? Reinforcing Sequential Determinantal Point Processes with Dynamic Ground Sets for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/cdc254119ff7166d67aeedb544b987ccb8b9eae6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.12948\",\"authors\":[{\"authorId\":\"1405222115\",\"name\":\"K. VivekrajV.\"},{\"authorId\":\"144789994\",\"name\":\"D. Sen\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3347712\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"title\":\"Video Skimming\",\"url\":\"https://www.semanticscholar.org/paper/8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":\"1703.09913\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"503db524b9a99220d430e741c44cd9c91ce1ddf8\",\"title\":\"Who's Better, Who's Best: Skill Determination in Video using Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/503db524b9a99220d430e741c44cd9c91ce1ddf8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1911.11306\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"50112704\",\"name\":\"Sumin Lee\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2019.2953187\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13aa627f35de78af64d1861fceb97c834a769b05\",\"title\":\"SRG: Snippet Relatedness-Based Temporal Action Proposal Generator\",\"url\":\"https://www.semanticscholar.org/paper/13aa627f35de78af64d1861fceb97c834a769b05\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2002.03740\",\"authors\":[{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1409909253\",\"name\":\"Xiaohui Yan\"},{\"authorId\":\"31991405\",\"name\":\"Min Yang\"}],\"doi\":\"10.1609/aaai.v34i07.6929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8ce6740c48b67697d0faeaf3926741ee0d6cfdf\",\"title\":\"Convolutional Hierarchical Attention Network for Query-Focused Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/a8ce6740c48b67697d0faeaf3926741ee0d6cfdf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46319670\",\"name\":\"N. Shruthi\"},{\"authorId\":\"7869663\",\"name\":\"S. Priyamvada\"}],\"doi\":\"10.1109/RTEICT.2017.8256909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c466d92335d399392f810b372056a904015425a\",\"title\":\"Dominant frame extraction for video indexing\",\"url\":\"https://www.semanticscholar.org/paper/3c466d92335d399392f810b372056a904015425a\",\"venue\":\"2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)\",\"year\":2017},{\"arxivId\":\"1707.07075\",\"authors\":[{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"143880942\",\"name\":\"Q. Nguyen\"},{\"authorId\":\"7641415\",\"name\":\"Stephen Hammer\"},{\"authorId\":\"143836309\",\"name\":\"J. Kent\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1109/CVPRW.2017.14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"837d7714da60b9033e18b42e5488ea41041b97bf\",\"title\":\"Automatic Curation of Golf Highlights Using Multimodal Excitement Features\",\"url\":\"https://www.semanticscholar.org/paper/837d7714da60b9033e18b42e5488ea41041b97bf\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"644f6f129debd38fa23da7be411ad981c0d3e534\",\"title\":\"Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/644f6f129debd38fa23da7be411ad981c0d3e534\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48116039\",\"name\":\"Jian Ren\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"}],\"doi\":\"10.1109/WACV45572.2020.9093615\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e94166bce09ca810b12e4b7a4ea920444893ffcf\",\"title\":\"Best Frame Selection in a Short Video\",\"url\":\"https://www.semanticscholar.org/paper/e94166bce09ca810b12e4b7a4ea920444893ffcf\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1702.01528\",\"authors\":[{\"authorId\":\"1751687\",\"name\":\"J. Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f28e2bb46e49799589787e466c3ca966a0897bf7\",\"title\":\"Textually Customized Video Summaries\",\"url\":\"https://www.semanticscholar.org/paper/f28e2bb46e49799589787e466c3ca966a0897bf7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51921758\",\"name\":\"J. Mohan\"},{\"authorId\":\"2365723\",\"name\":\"M. Nair\"}],\"doi\":\"10.1109/ACCESS.2018.2872685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76ae51c88725193cde6fde2e0af144f5a5f8f3d1\",\"title\":\"Dynamic Summarization of Videos Based on Descriptors in Space-Time Video Volumes and Sparse Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/76ae51c88725193cde6fde2e0af144f5a5f8f3d1\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1807.06677\",\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"143810339\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9beaabe21100c87757d703e657de6d3215a91e0\",\"title\":\"Query-Conditioned Three-Player Adversarial Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/c9beaabe21100c87757d703e657de6d3215a91e0\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49970148\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"49678929\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59e777069a4a24b47dfb27712bb3e5dcf3392f62\",\"title\":\"F \\\" , $ F % , $ conv Conv Fusion conv ReLU concat X $ Spatial Attention Submodule \\u03b1 $ \\u03a3 RNNtask Feature Encoding Attention Pooling Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/59e777069a4a24b47dfb27712bb3e5dcf3392f62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799538\",\"name\":\"Costas Panagiotakis\"},{\"authorId\":\"2542688\",\"name\":\"H. Papadakis\"},{\"authorId\":\"3099265\",\"name\":\"P. Fragopoulou\"}],\"doi\":\"10.1007/978-3-030-45442-5_38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"91f345861ffc505dba0ff2d10d7b90967855ce3b\",\"title\":\"Personalized Video Summarization Based Exclusively on User Preferences\",\"url\":\"https://www.semanticscholar.org/paper/91f345861ffc505dba0ff2d10d7b90967855ce3b\",\"venue\":\"ECIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2097156\",\"name\":\"M. Fei\"},{\"authorId\":\"152889332\",\"name\":\"Wei Jiang\"},{\"authorId\":\"39721136\",\"name\":\"Weijie Mao\"}],\"doi\":\"10.1016/J.ESWA.2020.114036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef76b3d6c7095c6e86eeb2d3a574c42859a7d406\",\"title\":\"Learning user interest with improved triplet deep ranking and web-image priors for topic-related video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ef76b3d6c7095c6e86eeb2d3a574c42859a7d406\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":\"1806.04620\",\"authors\":[{\"authorId\":\"21140516\",\"name\":\"Vinicius Signori Furlan\"},{\"authorId\":\"1784213\",\"name\":\"R. Bajcsy\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93de8ce11488740e4cc8eeef4d8bec31ef2433e7\",\"title\":\"Fast forwarding Egocentric Videos by Listening and Watching\",\"url\":\"https://www.semanticscholar.org/paper/93de8ce11488740e4cc8eeef4d8bec31ef2433e7\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"2585373\",\"name\":\"J. Liu\"},{\"authorId\":\"47019483\",\"name\":\"X. Gu\"},{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"36610657\",\"name\":\"Xiaowei Dai\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":\"10.1007/978-3-319-51811-4_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d042e1643297ecbad0343a7fb25774e2f192f393\",\"title\":\"Deep Learning Based Intelligent Basketball Arena with Energy Image\",\"url\":\"https://www.semanticscholar.org/paper/d042e1643297ecbad0343a7fb25774e2f192f393\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2506370\",\"name\":\"Sinnu Susan Thomas\"},{\"authorId\":\"144879221\",\"name\":\"S. Gupta\"},{\"authorId\":\"32325586\",\"name\":\"V. Subramanian\"}],\"doi\":\"10.1109/TITS.2017.2769719\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b25da6934526a549cbc3acb05db844fe61278\",\"title\":\"Event Detection on Roads Using Perceptual Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/a70b25da6934526a549cbc3acb05db844fe61278\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/978-3-030-00767-6_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c9222c188866351c994fee3ac2a2beaa843cc8\",\"title\":\"Gaze Aware Deep Learning Model for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/09c9222c188866351c994fee3ac2a2beaa843cc8\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1805.02838\",\"authors\":[{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"41051080\",\"name\":\"Jinyoung Sung\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2018.00153\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e68c133947bbf14834f5353126ae85cc048642db\",\"title\":\"A Memory Network Approach for Story-Based Temporal Summarization of 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/e68c133947bbf14834f5353126ae85cc048642db\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1634669632\",\"name\":\"M\\u00e9gane Millan\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":\"10.5220/0008924600570065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eda388cf09f8a7048ab8607a6fec30bad35d698b\",\"title\":\"Fine-tuning Siamese Networks to Assess Sport Gestures Quality\",\"url\":\"https://www.semanticscholar.org/paper/eda388cf09f8a7048ab8607a6fec30bad35d698b\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"2009.10942\",\"authors\":[{\"authorId\":\"2420746\",\"name\":\"P. Li\"},{\"authorId\":\"32813168\",\"name\":\"Qinghao Ye\"},{\"authorId\":\"1763785\",\"name\":\"Luming Zhang\"},{\"authorId\":\"2142172\",\"name\":\"L. Yuan\"},{\"authorId\":\"48670066\",\"name\":\"Xianghua Xu\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1016/J.PATCOG.2020.107677\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e3b914637e63c88eec0721e41eca195921476e94\",\"title\":\"Exploring global diverse attention via pairwise temporal relation for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/e3b914637e63c88eec0721e41eca195921476e94\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2007.09598\",\"authors\":[{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"1491322959\",\"name\":\"Mahesh Kumar Krishna Reddy\"},{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1007/978-3-030-58589-1_16\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d402204bd400df352c733ea232708d50d59b3be4\",\"title\":\"Adaptive Video Highlight Detection by Learning from User History\",\"url\":\"https://www.semanticscholar.org/paper/d402204bd400df352c733ea232708d50d59b3be4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48637594\",\"name\":\"Ruochen Jiang\"},{\"authorId\":\"50981392\",\"name\":\"S. Fraser\"},{\"authorId\":\"46694107\",\"name\":\"Changbo Qu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32589ac5f0fbc545eef3a57bd2ea56f75fa0fba4\",\"title\":\"Highlight Initializer Recorded Video ExtractedHighlights Live Video Prediction Adjustment Highlight Extractor Aggregation Classification Filtering\",\"url\":\"https://www.semanticscholar.org/paper/32589ac5f0fbc545eef3a57bd2ea56f75fa0fba4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8598253\",\"name\":\"Wang-Li Hao\"},{\"authorId\":\"1500387021\",\"name\":\"Ruixian Zhang\"},{\"authorId\":\"47319226\",\"name\":\"Shancang Li\"},{\"authorId\":\"1492111607\",\"name\":\"Junyu Li\"},{\"authorId\":\"49515557\",\"name\":\"F. Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"3103971\",\"name\":\"Wuping Zhang\"}],\"doi\":\"10.1155/2020/8876056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"title\":\"Anomaly Event Detection in Security Surveillance Using Two-Stream Based Model\",\"url\":\"https://www.semanticscholar.org/paper/d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.06604\",\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.1145/3240508.3240599\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"916218b7fd637d75f644c5ef5f7590c05fabca75\",\"title\":\"PHD-GIFs: Personalized Highlight Detection for Automatic GIF Creation\",\"url\":\"https://www.semanticscholar.org/paper/916218b7fd637d75f644c5ef5f7590c05fabca75\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"143880942\",\"name\":\"Q. Nguyen\"},{\"authorId\":\"7641415\",\"name\":\"Stephen Hammer\"},{\"authorId\":\"143836309\",\"name\":\"J. Kent\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":null,\"name\":\"John R. Smith\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1109/TMM.2018.2876046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f96cff446b72222d67665d3412b5889ccb10fba\",\"title\":\"Automatic Curation of Sports Highlights Using Multimodal Excitement Features\",\"url\":\"https://www.semanticscholar.org/paper/2f96cff446b72222d67665d3412b5889ccb10fba\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/CVPR.2018.00773\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ea6c0f1bde1f800e3c9c23573325e0d5283b12c\",\"title\":\"HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/1ea6c0f1bde1f800e3c9c23573325e0d5283b12c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1507204039\",\"name\":\"H. Han\"},{\"authorId\":\"49866494\",\"name\":\"Yu-chen Huang\"},{\"authorId\":\"2217849\",\"name\":\"C. C. Chen\"}],\"doi\":\"10.1145/3375959.3375965\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cbfe9256a1dd7277c2cca7532c0866ef841a337\",\"title\":\"A Deep Learning Model for Extracting Live Streaming Video Highlights using Audience Messages\",\"url\":\"https://www.semanticscholar.org/paper/2cbfe9256a1dd7277c2cca7532c0866ef841a337\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66365027\",\"name\":\"K. Abdalla\"},{\"authorId\":\"4500702\",\"name\":\"I. Menezes\"},{\"authorId\":\"122740538\",\"name\":\"L. Oliveira\"}],\"doi\":\"10.1016/J.ESWA.2019.04.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf75850944b2c66777192dce0afe3bdb3966f731\",\"title\":\"Modelling perceptions on the evaluation of video summarization\",\"url\":\"https://www.semanticscholar.org/paper/bf75850944b2c66777192dce0afe3bdb3966f731\",\"venue\":\"Expert Syst. Appl.\",\"year\":2019},{\"arxivId\":\"1811.11524\",\"authors\":[{\"authorId\":\"46398922\",\"name\":\"Y. Liu\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.00372\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"title\":\"Multi-Granularity Generator for Temporal Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48294886\",\"name\":\"T. Hiraoka\"},{\"authorId\":\"2742155\",\"name\":\"Ryosuke Yamanishi\"},{\"authorId\":\"34600958\",\"name\":\"Y. Nishihara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"193594766b14b7c6417a57e4c8dbdc6e77704f12\",\"title\":\"Propagating of Sentence Importance Estimates the Importance of Figures and Tables\",\"url\":\"https://www.semanticscholar.org/paper/193594766b14b7c6417a57e4c8dbdc6e77704f12\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13709325\",\"name\":\"G. Sukanya\"},{\"authorId\":\"39882382\",\"name\":\"A. Nithya\"},{\"authorId\":\"72574739\",\"name\":\"P. Veeralakshmi\"},{\"authorId\":\"4634792\",\"name\":\"J. Shankari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad752319ac038ca7f9d492be57925efab6fece61\",\"title\":\"( On the Spot ) Analyzing Accident Information and Claiming the Insurance\",\"url\":\"https://www.semanticscholar.org/paper/ad752319ac038ca7f9d492be57925efab6fece61\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.05899\",\"authors\":[{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"50814744\",\"name\":\"Jia-xiang Wang\"},{\"authorId\":\"144081363\",\"name\":\"Chao Li\"},{\"authorId\":\"1390667177\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"983e99bf560edcee1676b68dc81b570f03fb5835\",\"title\":\"TruNet: Short Videos Generation from Long Videos via Story-Preserving Truncation\",\"url\":\"https://www.semanticscholar.org/paper/983e99bf560edcee1676b68dc81b570f03fb5835\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73642793\",\"name\":\"B. Zhao\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIE.2020.2979573\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46e240ec1bedb1ca4481ae7648f18201364f7573\",\"title\":\"TTH-RNN: Tensor-Train Hierarchical Recurrent Neural Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/46e240ec1bedb1ca4481ae7648f18201364f7573\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"},{\"authorId\":\"47203059\",\"name\":\"W. Wu\"}],\"doi\":\"10.1109/ICAWST.2018.8517223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df40d96e8a12ac423d24c58ae4423b92ca62d082\",\"title\":\"Video Summarization: How to Use Deep-Learned Features Without a Large-Scale Dataset\",\"url\":\"https://www.semanticscholar.org/paper/df40d96e8a12ac423d24c58ae4423b92ca62d082\",\"venue\":\"iCAST\",\"year\":2018},{\"arxivId\":\"1512.04103\",\"authors\":[{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"3052825\",\"name\":\"Erfan Noury\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"}],\"doi\":\"10.1007/978-3-319-54193-8_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ce92cac0f3694be2f2918bf122679c6664a1e16\",\"title\":\"Deep Relative Attributes\",\"url\":\"https://www.semanticscholar.org/paper/3ce92cac0f3694be2f2918bf122679c6664a1e16\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1707.04960\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"20947424\",\"name\":\"Jacob S. Laurel\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/CVPR.2017.229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19ce02ad53571ebffd194eef670989ff3d6eaef4\",\"title\":\"Query-Focused Video Summarization: Dataset, Evaluation, and a Memory Network Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/19ce02ad53571ebffd194eef670989ff3d6eaef4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.03849\",\"authors\":[{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"title\":\"Weakly Supervised Dense Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"26296787\",\"name\":\"Yuanyuan Zhang\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"50617487\",\"name\":\"J. Pan\"}],\"doi\":\"10.1016/j.neucom.2018.12.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"302be2916514344d2806d4a890db3e13a3baaf60\",\"title\":\"Multi-video summarization with query-dependent weighted archetypal analysis\",\"url\":\"https://www.semanticscholar.org/paper/302be2916514344d2806d4a890db3e13a3baaf60\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2009.11063\",\"authors\":[{\"authorId\":\"46464798\",\"name\":\"M. Silva\"},{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"152471790\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/TPAMI.2020.2983929\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac374b7696e72c40c660c9dc5722d73b93667ec8\",\"title\":\"A Sparse Sampling-based framework for Semantic Fast-Forward of First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/ac374b7696e72c40c660c9dc5722d73b93667ec8\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2008.07577\",\"authors\":[{\"authorId\":\"32163640\",\"name\":\"B. Askari\"},{\"authorId\":\"1806938\",\"name\":\"Jaroslaw Szlichta\"},{\"authorId\":\"1403711294\",\"name\":\"Amirali Salehi-Abari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1276a050600e5fc1723cfca37cc5c183e52bf338\",\"title\":\"Joint Variational Autoencoders for Recommendation with Implicit Feedback\",\"url\":\"https://www.semanticscholar.org/paper/1276a050600e5fc1723cfca37cc5c183e52bf338\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024839\",\"name\":\"Yujie Li\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"},{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":\"10.1109/ICME.2017.8019352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf789e3770488c2690d1cca37366a79a5df99b0\",\"title\":\"Key frame extraction from first-person video with multi-sensor integration\",\"url\":\"https://www.semanticscholar.org/paper/aaf789e3770488c2690d1cca37366a79a5df99b0\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380729056\",\"name\":\"Anuj Rathore\"},{\"authorId\":\"9361887\",\"name\":\"Pravin Nagar\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"},{\"authorId\":\"1380374163\",\"name\":\"C.V. Jawahar\"}],\"doi\":\"10.1145/3343031.3350880\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b844e3eb550758d907c44729279760e4f981a6a\",\"title\":\"Generating 1 Minute Summaries of Day Long Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/4b844e3eb550758d907c44729279760e4f981a6a\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35384916\",\"name\":\"Y. Jiao\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"50178505\",\"name\":\"Shucheng Huang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1007/978-3-319-75786-5_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63d9eecad439b65f342ccf7a33f05aeaa79ad73e\",\"title\":\"Video Highlight Detection via Deep Ranking Modeling\",\"url\":\"https://www.semanticscholar.org/paper/63d9eecad439b65f342ccf7a33f05aeaa79ad73e\",\"venue\":\"PSIVT\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50385667\",\"name\":\"K. Kumar\"},{\"authorId\":\"145159347\",\"name\":\"Deepti D. Shrimankar\"}],\"doi\":\"10.1109/TMM.2017.2741423\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29d0c439241e65c51e19f7bd9430f50e900a6e32\",\"title\":\"F-DES: Fast and Deep Event Summarization\",\"url\":\"https://www.semanticscholar.org/paper/29d0c439241e65c51e19f7bd9430f50e900a6e32\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1904.05544\",\"authors\":[{\"authorId\":\"47745850\",\"name\":\"Zhuo Lei\"},{\"authorId\":null,\"name\":\"Chao Zhang\"},{\"authorId\":\"1737486\",\"name\":\"Q. Zhang\"},{\"authorId\":\"143740671\",\"name\":\"G. Qiu\"}],\"doi\":\"10.1109/ICME.2019.00071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c49a124b758257363a246c56d0fc6e7f79f9723\",\"title\":\"FrameRank: A Text Processing Approach to Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/1c49a124b758257363a246c56d0fc6e7f79f9723\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3025453.3025821\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"835680aa3c770a2360e62e467d82760936e52431\",\"title\":\"EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines\",\"url\":\"https://www.semanticscholar.org/paper/835680aa3c770a2360e62e467d82760936e52431\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3963027\",\"name\":\"Hyunwoo Nam\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/ICIP.2017.8297034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8d87a943c8ba31a18bf2d2b3f5d7e5abc3c2139\",\"title\":\"Content adaptive video summarization using spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/d8d87a943c8ba31a18bf2d2b3f5d7e5abc3c2139\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37146710\",\"name\":\"Michal Muszynski\"}],\"doi\":\"10.13097/archive-ouverte/unige:114609\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3c4761cb9638a950462df0f592116bc2bd6747e\",\"title\":\"Recognizing film aesthetics, spectators' affect and aesthetic emotions from multimodal signals\",\"url\":\"https://www.semanticscholar.org/paper/a3c4761cb9638a950462df0f592116bc2bd6747e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"46307804\",\"name\":\"L. Chen\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"2535030\",\"name\":\"Xianhui Liu\"}],\"doi\":\"10.1007/978-3-030-37731-1_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f16256ffdedf1028d44c7cf40a30af1af86b8dde\",\"title\":\"Wonderful Clips of Playing Basketball: A Database for Localizing Wonderful Actions\",\"url\":\"https://www.semanticscholar.org/paper/f16256ffdedf1028d44c7cf40a30af1af86b8dde\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"2007.09833\",\"authors\":[{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"1823519002\",\"name\":\"Xuanteng Huang\"},{\"authorId\":\"50135134\",\"name\":\"Weihong Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1007/978-3-030-58601-0_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4079558004efd97ddb20ea160909f7fa97d689c2\",\"title\":\"MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection\",\"url\":\"https://www.semanticscholar.org/paper/4079558004efd97ddb20ea160909f7fa97d689c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"153216896\",\"name\":\"D. Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"title\":\"MSR Asia MSM at ActivityNet Challenge 2017: Trimmed Action Recognition, Temporal Action Proposals and Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.5753/sibgrapi.est.2019.8302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1c2aa137332732a0ecc9b9818dee767896f4b0\",\"title\":\"Semantic Hyperlapse: a sparse coding based and multi-importance approach for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/9f1c2aa137332732a0ecc9b9818dee767896f4b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"144362750\",\"name\":\"A. Tan\"}],\"doi\":\"10.1109/THMS.2016.2623480\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"title\":\"Summarization of Egocentric Videos: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/1be1df8f3412961eaf4b7a9ca0023b06ca2c7344\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143972418\",\"name\":\"L. Zou\"},{\"authorId\":null,\"name\":\"Han Wang\"},{\"authorId\":\"143685287\",\"name\":\"Pei Chen\"},{\"authorId\":\"145923855\",\"name\":\"Bo Wei\"}],\"doi\":\"10.1007/978-3-030-04946-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d99571d37f519666d572f4f17447c82d7ef25a86\",\"title\":\"A Method of Film Clips Retrieval Using Image Queries Based on User Interests\",\"url\":\"https://www.semanticscholar.org/paper/d99571d37f519666d572f4f17447c82d7ef25a86\",\"venue\":\"Cognitive Internet of Things\",\"year\":2019},{\"arxivId\":\"1903.11328\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1109/CVPR.2019.00778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9835a04f6e5cd8b4c70edda704fddce813d18339\",\"title\":\"Rethinking the Evaluation of Video Summaries\",\"url\":\"https://www.semanticscholar.org/paper/9835a04f6e5cd8b4c70edda704fddce813d18339\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1706.03123\",\"authors\":[{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/TIP.2017.2708902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc7c8974c3990c9c7b6d20cfd748e3315c44bd26\",\"title\":\"Diversity-Aware Multi-Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/bc7c8974c3990c9c7b6d20cfd748e3315c44bd26\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35384916\",\"name\":\"Y. Jiao\"},{\"authorId\":\"3208023\",\"name\":\"Zhetao Li\"},{\"authorId\":\"50178505\",\"name\":\"Shucheng Huang\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"49166856\",\"name\":\"B. Liu\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1109/TMM.2018.2815998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9fc8efd1aa3d58f89c0f53f0cb112725b5bda10\",\"title\":\"Three-Dimensional Attention-Based Deep Ranking Model for Video Highlight Detection\",\"url\":\"https://www.semanticscholar.org/paper/a9fc8efd1aa3d58f89c0f53f0cb112725b5bda10\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47751104\",\"name\":\"Dali Yang\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":\"10.1109/ICIP.2018.8451740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"758d1c17569eea2a698cac31b2d9d2a772c84322\",\"title\":\"Hierarchical Context Encoding for Events Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/758d1c17569eea2a698cac31b2d9d2a772c84322\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2002.09424\",\"authors\":[{\"authorId\":\"1500721503\",\"name\":\"Ziyad Jappie\"},{\"authorId\":\"31915818\",\"name\":\"D. Torpey\"},{\"authorId\":\"48627696\",\"name\":\"T. \\u00c7elik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f9486264ebd4f609453f96a9df97588027f1dfb\",\"title\":\"SummaryNet: A Multi-Stage Deep Learning Model for Automatic Video Summarisation\",\"url\":\"https://www.semanticscholar.org/paper/1f9486264ebd4f609453f96a9df97588027f1dfb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.11228\",\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1145/3321408.3322622\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"title\":\"DTR-GAN: dilated temporal relational adversarial network for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"venue\":\"ACM TUR-C\",\"year\":2019},{\"arxivId\":\"1705.01759\",\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.153\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba227bb94ea9414bad8846673c904a10d813e443\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360\\u00b0 Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba227bb94ea9414bad8846673c904a10d813e443\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629502659\",\"name\":\"Ghulam Mujtaba\"},{\"authorId\":\"2267529\",\"name\":\"E. Ryu\"}],\"doi\":\"10.1109/ACCESS.2020.2982992\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"569fb4223560247892081163b788ccc295f49780\",\"title\":\"Client-Driven Personalized Trailer Framework Using Thumbnail Containers\",\"url\":\"https://www.semanticscholar.org/paper/569fb4223560247892081163b788ccc295f49780\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50695090\",\"name\":\"S. Wang\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3267935.3267952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccf45f1ddb5ba8c1a554dee90163c749f6487f7f\",\"title\":\"Video Interestingness Prediction Based on Ranking Model\",\"url\":\"https://www.semanticscholar.org/paper/ccf45f1ddb5ba8c1a554dee90163c749f6487f7f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1901.02579\",\"authors\":[{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/ICCVW.2019.00539\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70681bc4d3facb1839c3459ee1c68b048d46bca8\",\"title\":\"Manipulation-Skill Assessment from Videos with Spatial Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/70681bc4d3facb1839c3459ee1c68b048d46bca8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1846370\",\"name\":\"S. Marvaniya\"},{\"authorId\":\"7485037\",\"name\":\"Mogilipaka Damoder\"},{\"authorId\":\"20242463\",\"name\":\"Viswanath Gopalakrishnan\"},{\"authorId\":\"2914791\",\"name\":\"K. N. Iyer\"},{\"authorId\":\"39908315\",\"name\":\"Kapil Soni\"}],\"doi\":\"10.1109/ICIP.2016.7532342\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8d38c46944bc7f674756e20fb97728df817b4f9\",\"title\":\"Real-time video summarization on mobile\",\"url\":\"https://www.semanticscholar.org/paper/f8d38c46944bc7f674756e20fb97728df817b4f9\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"9148956\",\"name\":\"Chongyang Bai\"},{\"authorId\":\"51043468\",\"name\":\"Maksim Bolonkin\"},{\"authorId\":\"2896960\",\"name\":\"J. Burgoon\"},{\"authorId\":\"11775809\",\"name\":\"N. Dunbar\"},{\"authorId\":\"1728462\",\"name\":\"V. Subrahmanian\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ea71c17812ae71a22c89b9ced577a7cbe75424f\",\"title\":\"Attention-based Facial Behavior Analytics inSocial Communication\",\"url\":\"https://www.semanticscholar.org/paper/1ea71c17812ae71a22c89b9ced577a7cbe75424f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/CVPR.2018.00634\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e849bab6bc8195370208b6a99acdb44078857ed8\",\"title\":\"Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination\",\"url\":\"https://www.semanticscholar.org/paper/e849bab6bc8195370208b6a99acdb44078857ed8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49521346\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2916989\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"494f3bc2879b4273934e949ee6985f4ecf4b4932\",\"title\":\"Spatiotemporal Modeling for Video Summarization Using Convolutional Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/494f3bc2879b4273934e949ee6985f4ecf4b4932\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"},{\"authorId\":\"39497207\",\"name\":\"J. Ernst\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICCV.2017.395\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97b5800e144a8df48f1f7e91383b0f37bc37cf60\",\"title\":\"Weakly Supervised Summarization of Web Videos\",\"url\":\"https://www.semanticscholar.org/paper/97b5800e144a8df48f1f7e91383b0f37bc37cf60\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486212997\",\"name\":\"Mahesh Kini M\"},{\"authorId\":\"1486442882\",\"name\":\"Karthik Pai\"}],\"doi\":\"10.1109/i-PACT44901.2019.8960003\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9527683aeda5ba1fa12dd0d24fdc057633c2b0e7\",\"title\":\"A Survey on Video Summarization Techniques\",\"url\":\"https://www.semanticscholar.org/paper/9527683aeda5ba1fa12dd0d24fdc057633c2b0e7\",\"venue\":\"2019 Innovations in Power and Advanced Computing Technologies (i-PACT)\",\"year\":2019},{\"arxivId\":\"2002.03740\",\"authors\":[{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1749272\",\"name\":\"Ziyu Guan\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2985868\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"title\":\"Query-Biased Self-Attentive Network for Query-Focused Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73642793\",\"name\":\"B. Zhao\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TNNLS.2019.2951680\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b83b6069fc6ad861c6d7cb574825488e0fca8521\",\"title\":\"Property-Constrained Dual Learning for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b83b6069fc6ad861c6d7cb574825488e0fca8521\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33631140\",\"name\":\"B. Subudhi\"},{\"authorId\":\"3338740\",\"name\":\"T. Veerakumar\"},{\"authorId\":\"2085265\",\"name\":\"S. Esakkirajan\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"}],\"doi\":\"10.1016/j.eswa.2020.113341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2adfb3546529d4a828c520c69c276c7cefbc19fe\",\"title\":\"Automatic lecture video skimming using shot categorization and contrast based features\",\"url\":\"https://www.semanticscholar.org/paper/2adfb3546529d4a828c520c69c276c7cefbc19fe\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37146710\",\"name\":\"Michal Muszynski\"},{\"authorId\":\"2739790\",\"name\":\"Theodoros Kostoulas\"},{\"authorId\":\"2300629\",\"name\":\"P. Lombardo\"},{\"authorId\":\"1809085\",\"name\":\"T. Pun\"},{\"authorId\":\"2343145\",\"name\":\"Guillaume Chanel\"}],\"doi\":\"10.1145/3175497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb7bf0728ea2f751f8b0947266bd567124e94abf\",\"title\":\"Aesthetic Highlight Detection in Movies Based on Synchronization of Spectators\\u2019 Reactions\",\"url\":\"https://www.semanticscholar.org/paper/fb7bf0728ea2f751f8b0947266bd567124e94abf\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1910.04964\",\"authors\":[{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"}],\"doi\":\"10.1109/TCSVT.2019.2940647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"title\":\"Multi-Modal Deep Analysis for Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3441880\",\"name\":\"Wencheng Zhu\"},{\"authorId\":\"100475213\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"3392041\",\"name\":\"Jiahao Li\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TIP.2020.3039886\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49a547e6255bc323f65f0934f378ef0930863f9c\",\"title\":\"DSNet: A Flexible Detect-to-Summarize Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/49a547e6255bc323f65f0934f378ef0930863f9c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021}],\"corpusId\":206593280,\"doi\":\"10.1109/CVPR.2016.112\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":22,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"97398356607115f78d677663a682363eec3302d7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145459055\",\"name\":\"Yong Rui\"},{\"authorId\":\"9985189\",\"name\":\"A. Gupta\"},{\"authorId\":\"1723644\",\"name\":\"A. Acero\"}],\"doi\":\"10.1145/354384.354443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5138a7d65d6875191572291f3458b4de149b4d2a\",\"title\":\"Automatically extracting highlights for TV Baseball programs\",\"url\":\"https://www.semanticscholar.org/paper/5138a7d65d6875191572291f3458b4de149b4d2a\",\"venue\":\"MULTIMEDIA '00\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-10584-0_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"title\":\"Creating Summaries from User Videos\",\"url\":\"https://www.semanticscholar.org/paper/799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10599-4_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"title\":\"Category-Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1839622\",\"name\":\"Lin-Xie Tang\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":\"10.1145/2487268.2487269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c58e76649c7e87dca57dcc17bf615e7aa9dd062d\",\"title\":\"Near-lossless semantic video summarization and its applications to video analysis\",\"url\":\"https://www.semanticscholar.org/paper/c58e76649c7e87dca57dcc17bf615e7aa9dd062d\",\"venue\":\"TOMCCAP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784400\",\"name\":\"P. N\\u00e1vrat\"}],\"doi\":\"10.1145/992287.992293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbc5703dd8fe75fb130c6fe65b076af9dc41a77d\",\"title\":\"Review of \\\"Algorithm design: foundations, analysis and internet examples\\\" by Michael T. Goodrich and Roberto Tamassia. John Wiley & Sons, Inc. 2001.\",\"url\":\"https://www.semanticscholar.org/paper/dbc5703dd8fe75fb130c6fe65b076af9dc41a77d\",\"venue\":\"SIGA\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145989594\",\"name\":\"M. Goodale\"},{\"authorId\":\"2471113\",\"name\":\"A. Milner\"}],\"doi\":\"10.1016/0166-2236(92)90344-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a995afa8d3c114b2b431c4e2737777a0e051bff\",\"title\":\"Separate visual pathways for perception and action\",\"url\":\"https://www.semanticscholar.org/paper/0a995afa8d3c114b2b431c4e2737777a0e051bff\",\"venue\":\"Trends in Neurosciences\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1109/ICCV.2015.12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3946fcccd68ebbd10e9ca2b8250acfac1929951a\",\"title\":\"Learning Query and Image Similarities with Ranking Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3946fcccd68ebbd10e9ca2b8250acfac1929951a\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1145/2600428.2609568\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc52b35171e2864f6c1c9633815875a003299a32\",\"title\":\"Click-through-based cross-view learning for image search\",\"url\":\"https://www.semanticscholar.org/paper/fc52b35171e2864f6c1c9633815875a003299a32\",\"venue\":\"SIGIR\",\"year\":2014},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3351294\",\"name\":\"Yu-Fei Ma\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"40659377\",\"name\":\"L. Lu\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/TMM.2005.854410\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4541e6605c73c2499d145fb3c8621b91fddf3a78\",\"title\":\"A generic framework of user attention model and its application in video summarization\",\"url\":\"https://www.semanticscholar.org/paper/4541e6605c73c2499d145fb3c8621b91fddf3a78\",\"venue\":\"IEEE Trans. Multim.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"}],\"doi\":\"10.1007/978-3-642-33709-3_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d8de0f299ba20f2301900648bc2a6bd99df79bd\",\"title\":\"Scene Aligned Pooling for Complex Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d8de0f299ba20f2301900648bc2a6bd99df79bd\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1207.0580\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1366de5bb112746a555e9c0cd00de3ad8628aea8\",\"title\":\"Improving neural networks by preventing co-adaptation of feature detectors\",\"url\":\"https://www.semanticscholar.org/paper/1366de5bb112746a555e9c0cd00de3ad8628aea8\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1404.4661\",\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"145266091\",\"name\":\"Thomas Leung\"},{\"authorId\":\"17027818\",\"name\":\"C. Rosenberg\"},{\"authorId\":\"120465907\",\"name\":\"J. Wang\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2014.180\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6df192c9b654bc5cc371c55012cf99d85cb61df\",\"title\":\"Learning Fine-Grained Image Similarity with Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/e6df192c9b654bc5cc371c55012cf99d85cb61df\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681657\",\"name\":\"S. Nepal\"},{\"authorId\":\"34600558\",\"name\":\"U. Srinivasan\"},{\"authorId\":\"46708936\",\"name\":\"G. Reynolds\"}],\"doi\":\"10.1145/500141.500181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"217478d6a95a5bceef11d7846895b57718d63e73\",\"title\":\"Automatic detection of 'Goal' segments in basketball videos\",\"url\":\"https://www.semanticscholar.org/paper/217478d6a95a5bceef11d7846895b57718d63e73\",\"venue\":\"MULTIMEDIA '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849128\",\"name\":\"Rong-En Fan\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"8415802\",\"name\":\"Xiang-Rui Wang\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"}],\"doi\":\"10.1145/1390681.1442794\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"268a4f8da15a42f3e0e71691f760ff5edbf9cec8\",\"title\":\"LIBLINEAR: A Library for Large Linear Classification\",\"url\":\"https://www.semanticscholar.org/paper/268a4f8da15a42f3e0e71691f760ff5edbf9cec8\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"144007359\",\"name\":\"W. Kienzle\"},{\"authorId\":\"2441615\",\"name\":\"Mike Toelle\"},{\"authorId\":\"143711233\",\"name\":\"Matthew Uyttendaele\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1145/2766954\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b70d6c2fba3539d45fa0f2e15ec5a0ba3ba248\",\"title\":\"Real-time hyperlapse creation via optimal frame selection\",\"url\":\"https://www.semanticscholar.org/paper/19b70d6c2fba3539d45fa0f2e15ec5a0ba3ba248\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"3351294\",\"name\":\"Yu-Fei Ma\"},{\"authorId\":\"1718558\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1109/TCSVT.2004.841694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"284b13e5d9bd25f79ef953ee143f15a1a37693d9\",\"title\":\"Video summarization and scene detection by graph modeling\",\"url\":\"https://www.semanticscholar.org/paper/284b13e5d9bd25f79ef953ee143f15a1a37693d9\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679615\",\"name\":\"M. Goodrich\"},{\"authorId\":\"1751948\",\"name\":\"R. Tamassia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbe1df04080cfa26e7cdf830c6a11a42e0a1fc3d\",\"title\":\"Algorithm design - foundations, analysis and internet examples\",\"url\":\"https://www.semanticscholar.org/paper/dbe1df04080cfa26e7cdf830c6a11a42e0a1fc3d\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"1732412\",\"name\":\"Shipeng Li\"}],\"doi\":\"10.1145/2502081.2502085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a86f5f7d76117cd329cdb3bec5e6c96ba6fae45d\",\"title\":\"Annotation for free: video tagging by mining user search behavior\",\"url\":\"https://www.semanticscholar.org/paper/a86f5f7d76117cd329cdb3bec5e6c96ba6fae45d\",\"venue\":\"MM '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143616798\",\"name\":\"Zheng Lu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"title\":\"Story-Driven Summarization for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-319-10590-1_51\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c7adde982efb24c3786fa2d1f65f40a64e2afbf\",\"title\":\"Ranking Domain-Specific Highlights by Analyzing Edited Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c7adde982efb24c3786fa2d1f65f40a64e2afbf\",\"venue\":\"ECCV\",\"year\":2014}],\"title\":\"Highlight Detection with Pairwise Deep Ranking for First-Person Video Summarization\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Wearable technology\",\"topicId\":\"27874\",\"url\":\"https://www.semanticscholar.org/topic/27874\"},{\"topic\":\"Smartglasses\",\"topicId\":\"237558\",\"url\":\"https://www.semanticscholar.org/topic/237558\"},{\"topic\":\"Mac OS X 10.5 Leopard\",\"topicId\":\"350810\",\"url\":\"https://www.semanticscholar.org/topic/350810\"},{\"topic\":\"Browsing\",\"topicId\":\"11604\",\"url\":\"https://www.semanticscholar.org/topic/11604\"},{\"topic\":\"Usability testing\",\"topicId\":\"34160\",\"url\":\"https://www.semanticscholar.org/topic/34160\"},{\"topic\":\"Emergence\",\"topicId\":\"5580\",\"url\":\"https://www.semanticscholar.org/topic/5580\"},{\"topic\":\"Digital camera\",\"topicId\":\"55559\",\"url\":\"https://www.semanticscholar.org/topic/55559\"},{\"topic\":\"First-person (video games)\",\"topicId\":\"622459\",\"url\":\"https://www.semanticscholar.org/topic/622459\"},{\"topic\":\"Automatic summarization\",\"topicId\":\"36919\",\"url\":\"https://www.semanticscholar.org/topic/36919\"}],\"url\":\"https://www.semanticscholar.org/paper/97398356607115f78d677663a682363eec3302d7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"