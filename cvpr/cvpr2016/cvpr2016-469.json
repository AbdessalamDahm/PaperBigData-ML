"{\"abstract\":\"Light field depth estimation is an essential part of many light field applications. Numerous algorithms have been developed using various light field characteristics. However, conventional methods fail when handling noisy scene with occlusion. To remedy this problem, we present a light field depth estimation method which is more robust to occlusion and less sensitive to noise. Novel data costs using angular entropy metric and adaptive defocus response are introduced. Integration of both data costs improves the occlusion and noise invariant capability significantly. Cost volume filtering and graph cut optimization are utilized to improve the accuracy of the depth map. Experimental results confirm that the proposed method is robust and achieves high quality depth maps in various scenes. The proposed method outperforms the state-of-the-art light field depth estimation methods in qualitative and quantitative evaluation.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2429068\",\"name\":\"Williem\",\"url\":\"https://www.semanticscholar.org/author/2429068\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\",\"url\":\"https://www.semanticscholar.org/author/145789132\"}],\"citationVelocity\":11,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"79318121\",\"name\":\"\\ubc15\\ud574\\uc194\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0bc22fb0fb3f14933de0bb4d03618405560745e2\",\"title\":\"Solving Multi-view Stereo and Image Restoration using a Unified Framework\",\"url\":\"https://www.semanticscholar.org/paper/0bc22fb0fb3f14933de0bb4d03618405560745e2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1804.02379\",\"authors\":[{\"authorId\":\"41021241\",\"name\":\"Changha Shin\"},{\"authorId\":\"39060641\",\"name\":\"H. Jeon\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/CVPR.2018.00499\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d0a31b0f9d1eb28473b09d3e0e01b6325bcb866\",\"title\":\"EPINET: A Fully-Convolutional Neural Network Using Epipolar Geometry for Depth from Light Field Images\",\"url\":\"https://www.semanticscholar.org/paper/4d0a31b0f9d1eb28473b09d3e0e01b6325bcb866\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.07719\",\"authors\":[{\"authorId\":\"40326718\",\"name\":\"Hossein Javidnia\"},{\"authorId\":\"1734172\",\"name\":\"P. Corcoran\"}],\"doi\":\"10.1117/1.OE.57.6.063105\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f8102823ba4c6b6f8cf27b76ff54a94664696d7\",\"title\":\"Total variation-based dense depth from multicamera array\",\"url\":\"https://www.semanticscholar.org/paper/3f8102823ba4c6b6f8cf27b76ff54a94664696d7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89483533\",\"name\":\"Gabriel G. Baravdish\"},{\"authorId\":\"1807193\",\"name\":\"Ehsan Miandji\"},{\"authorId\":\"145446691\",\"name\":\"J. Unger\"}],\"doi\":\"10.5220/0007393101770182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99543805ee6c7ee126f0e1cc2bdd1b828ca44350\",\"title\":\"GPU Accelerated Sparse Representation of Light Fields\",\"url\":\"https://www.semanticscholar.org/paper/99543805ee6c7ee126f0e1cc2bdd1b828ca44350\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2861519\",\"name\":\"Gaochang Wu\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"2208378\",\"name\":\"A. Jarabo\"},{\"authorId\":null,\"name\":\"Yuchen Zhang\"},{\"authorId\":\"3095607\",\"name\":\"Liangyong Wang\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"},{\"authorId\":\"145011556\",\"name\":\"T. Chai\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\"}],\"doi\":\"10.1109/JSTSP.2017.2747126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed7038b052af85886bf96c3511910ad654e1811a\",\"title\":\"Light Field Image Processing: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/ed7038b052af85886bf96c3511910ad654e1811a\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2429068\",\"name\":\"Williem\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":\"10.1016/j.jvcir.2018.08.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7e439f93cf4d70216a5e6ea792feffcd9e9f267\",\"title\":\"Cost aggregation benchmark for light field depth estimation\",\"url\":\"https://www.semanticscholar.org/paper/a7e439f93cf4d70216a5e6ea792feffcd9e9f267\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145153298\",\"name\":\"H. Zhu\"},{\"authorId\":\"145090414\",\"name\":\"Q. Wang\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"}],\"doi\":\"10.1631/FITEE.1601727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d9d31ef0b4144abeae309d811437121ce93b49b\",\"title\":\"Light field imaging: models, calibrations, reconstructions, and applications\",\"url\":\"https://www.semanticscholar.org/paper/3d9d31ef0b4144abeae309d811437121ce93b49b\",\"venue\":\"Frontiers of Information Technology & Electronic Engineering\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51265495\",\"name\":\"Gou Houben\"},{\"authorId\":\"28259552\",\"name\":\"S. Fujita\"},{\"authorId\":\"145293858\",\"name\":\"K. Takahashi\"},{\"authorId\":\"1732969\",\"name\":\"T. Fujii\"}],\"doi\":\"10.1109/ICIP.2018.8451833\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf12a006011b3f772a30c571021b70b3d069edbe\",\"title\":\"Fast and Robust Disparity Estimation for Noisy Light Fields\",\"url\":\"https://www.semanticscholar.org/paper/bf12a006011b3f772a30c571021b70b3d069edbe\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1857559\",\"name\":\"Daisuke Sugimura\"},{\"authorId\":\"49988710\",\"name\":\"S. Kobayashi\"},{\"authorId\":\"34684870\",\"name\":\"T. Hamamoto\"}],\"doi\":\"10.1364/AO.56.008687\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8076e747f9c79b3319908d0853da48b651f43575\",\"title\":\"Concept of dual-resolution light field imaging using an organic photoelectric conversion film for high-resolution light field photography.\",\"url\":\"https://www.semanticscholar.org/paper/8076e747f9c79b3319908d0853da48b651f43575\",\"venue\":\"Applied optics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"1752257\",\"name\":\"Y. Wang\"},{\"authorId\":\"48211172\",\"name\":\"J. Liu\"},{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/TIP.2018.2814217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a4a94e5d210858957d64725099856d7a727360e\",\"title\":\"Benchmark Data Set and Method for Depth Estimation From Light Field Images\",\"url\":\"https://www.semanticscholar.org/paper/5a4a94e5d210858957d64725099856d7a727360e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153939215\",\"name\":\"Yasutaka Inagaki\"},{\"authorId\":\"28474811\",\"name\":\"Yuto Kobayashi\"},{\"authorId\":\"145293858\",\"name\":\"K. Takahashi\"},{\"authorId\":\"1732969\",\"name\":\"T. Fujii\"},{\"authorId\":\"144829054\",\"name\":\"H. Nagahara\"}],\"doi\":\"10.1007/978-3-030-01234-2_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7dc5aeef4242b24e1a4331597384b30d35a67\",\"title\":\"Learning to Capture Light Fields Through a Coded Aperture Camera\",\"url\":\"https://www.semanticscholar.org/paper/6fe7dc5aeef4242b24e1a4331597384b30d35a67\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"47003559\",\"name\":\"Y. Li\"},{\"authorId\":\"8186800\",\"name\":\"H. Kim\"},{\"authorId\":\"2042122\",\"name\":\"S. Serikawa\"}],\"doi\":\"10.1007/978-3-319-69877-9_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffc49870d2d034c34aa62c818fee2dc854dced8\",\"title\":\"Underwater Light Field Depth Map Restoration Using Deep Convolutional Neural Fields\",\"url\":\"https://www.semanticscholar.org/paper/cffc49870d2d034c34aa62c818fee2dc854dced8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1708.01964\",\"authors\":[{\"authorId\":\"1800745\",\"name\":\"J. Chen\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"144373693\",\"name\":\"Yun Ni\"},{\"authorId\":\"145662587\",\"name\":\"Lap-Pui Chau\"}],\"doi\":\"10.1109/TIP.2018.2839524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34020923fb10d5c92c71e1a5e9d90e0eef01e58a\",\"title\":\"Accurate Light Field Depth Estimation With Superpixel Regularization Over Partially Occluded Regions\",\"url\":\"https://www.semanticscholar.org/paper/34020923fb10d5c92c71e1a5e9d90e0eef01e58a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2182252\",\"name\":\"Hao Sheng\"},{\"authorId\":\"48691667\",\"name\":\"S. Zhang\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"},{\"authorId\":\"46335589\",\"name\":\"Zhang Xiong\"}],\"doi\":\"10.1109/TIP.2017.2745100\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d64fc8df8c81315c35fbef39bd1236f72d464612\",\"title\":\"Geometric Occlusion Analysis in Depth Estimation Using Integral Guided Filter for Light-Field Image\",\"url\":\"https://www.semanticscholar.org/paper/d64fc8df8c81315c35fbef39bd1236f72d464612\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244865\",\"name\":\"Mrinmoy Ghorai\"},{\"authorId\":\"146139278\",\"name\":\"A. Munteanu\"}],\"doi\":\"10.1109/ICIP.2019.8803722\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"477be51dba8e44662e2f945e6705ef5e73a54dc3\",\"title\":\"Depth Estimation with Occlusion Prediction in Light Field Images\",\"url\":\"https://www.semanticscholar.org/paper/477be51dba8e44662e2f945e6705ef5e73a54dc3\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3246963\",\"name\":\"Chao-Tsung Huang\"}],\"doi\":\"10.1109/ICCV.2017.11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"15c1810e3cf2d37526fed71276c63c21db261709\",\"title\":\"Robust Pseudo Random Fields for Light-Field Stereo Matching\",\"url\":\"https://www.semanticscholar.org/paper/15c1810e3cf2d37526fed71276c63c21db261709\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2182252\",\"name\":\"Hao Sheng\"},{\"authorId\":\"145105976\",\"name\":\"P. Zhao\"},{\"authorId\":\"47180156\",\"name\":\"Shuo Zhang\"},{\"authorId\":\"47593117\",\"name\":\"J. Zhang\"},{\"authorId\":\"143942184\",\"name\":\"D. Yang\"}],\"doi\":\"10.1016/j.patcog.2017.09.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"623b0682a4c688a9cedb8f60646390308d1626cf\",\"title\":\"Occlusion-aware depth estimation for light field using multi-orientation EPIs\",\"url\":\"https://www.semanticscholar.org/paper/623b0682a4c688a9cedb8f60646390308d1626cf\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1911.11619\",\"authors\":[{\"authorId\":\"31700532\",\"name\":\"A. Ivan\"},{\"authorId\":\"2429068\",\"name\":\"Williem\"},{\"authorId\":\"143941552\",\"name\":\"I. Park\"}],\"doi\":\"10.1109/ACCESS.2020.3002921\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a2ae43ce648288a5867400522843b7f7866d12f3\",\"title\":\"Joint Light Field Spatial and Angular Super-Resolution From a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/a2ae43ce648288a5867400522843b7f7866d12f3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48173915\",\"name\":\"Jae Young Lee\"},{\"authorId\":\"102442672\",\"name\":\"R. Park\"}],\"doi\":\"10.1109/LSP.2018.2874304\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db9bc8db23b867cf6c8ca80ba51e6a6331ce9010\",\"title\":\"Reduction of Aliasing Artifacts by Sign Function Approximation in Light Field Depth Estimation Based on Foreground\\u2013Background Separation\",\"url\":\"https://www.semanticscholar.org/paper/db9bc8db23b867cf6c8ca80ba51e6a6331ce9010\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458280\",\"name\":\"Matthieu Hog\"},{\"authorId\":\"144797922\",\"name\":\"Neus Sabater\"},{\"authorId\":\"1780587\",\"name\":\"C. Guillemot\"}],\"doi\":\"10.1109/jstsp.2017.2738619\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db0693df450137d3736d21519ecb1cf104f308ec\",\"title\":\"Superrays for Efficient Light Field Processing\",\"url\":\"https://www.semanticscholar.org/paper/db0693df450137d3736d21519ecb1cf104f308ec\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458280\",\"name\":\"Matthieu Hog\"},{\"authorId\":\"144797921\",\"name\":\"Neus Sabater\"},{\"authorId\":\"1950747\",\"name\":\"B. Vandame\"},{\"authorId\":\"2433214\",\"name\":\"V. Drazic\"}],\"doi\":\"10.1109/TCI.2017.2710906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7137c27d6f10e94917506549bb65e7258c117598\",\"title\":\"An Image Rendering Pipeline for Focused Plenoptic Cameras\",\"url\":\"https://www.semanticscholar.org/paper/7137c27d6f10e94917506549bb65e7258c117598\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458280\",\"name\":\"Matthieu Hog\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eeb93e878f84ad22b9ef015b6698a2c48c79bb7a\",\"title\":\"Light Field Editing and Rendering\",\"url\":\"https://www.semanticscholar.org/paper/eeb93e878f84ad22b9ef015b6698a2c48c79bb7a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.10918\",\"authors\":[{\"authorId\":\"1747673\",\"name\":\"Dongwoo Lee\"},{\"authorId\":\"2817496\",\"name\":\"Haesol Park\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1007/978-3-030-01270-0_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0708612093de2c4b1bcb84b269af20accf9222bf\",\"title\":\"Joint Blind Motion Deblurring and Depth Estimation of Light Field\",\"url\":\"https://www.semanticscholar.org/paper/0708612093de2c4b1bcb84b269af20accf9222bf\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11243461\",\"name\":\"Qihui Han\"},{\"authorId\":\"95055206\",\"name\":\"C. Jung\"}],\"doi\":\"10.1016/j.jvcir.2018.06.020\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"25ff3eb580ce1e1f2fd93fde2f9fe34cf7a1a800\",\"title\":\"Guided filtering based data fusion for light field depth estimation with L0 gradient minimization\",\"url\":\"https://www.semanticscholar.org/paper/25ff3eb580ce1e1f2fd93fde2f9fe34cf7a1a800\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7595474\",\"name\":\"Yanwen Qin\"},{\"authorId\":\"144898074\",\"name\":\"Xin Jin\"},{\"authorId\":\"16098911\",\"name\":\"Yanqin Chen\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"}],\"doi\":\"10.1109/ICASSP.2017.7952513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e50713834bc00a2108990906468f5e43c104ba\",\"title\":\"Enhanced depth estimation for hand-held light field cameras\",\"url\":\"https://www.semanticscholar.org/paper/93e50713834bc00a2108990906468f5e43c104ba\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36875638\",\"name\":\"J. Lee\"},{\"authorId\":\"102442672\",\"name\":\"R. Park\"}],\"doi\":\"10.1109/JSTSP.2017.2747154\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"51f9b94937c76c7e24003a44b1e04e3fffbf48ec\",\"title\":\"Depth Estimation From Light Field by Accumulating Binary Maps Based on Foreground\\u2013Background Separation\",\"url\":\"https://www.semanticscholar.org/paper/51f9b94937c76c7e24003a44b1e04e3fffbf48ec\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47180156\",\"name\":\"Shuo Zhang\"},{\"authorId\":\"2182252\",\"name\":\"Hao Sheng\"},{\"authorId\":\"145279121\",\"name\":\"D. Yang\"},{\"authorId\":\"39014860\",\"name\":\"J. Zhang\"},{\"authorId\":\"46335589\",\"name\":\"Zhang Xiong\"}],\"doi\":\"10.1109/TIP.2017.2763823\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"64d313caf4d4bfef8d6bc1830b4ce38da9349c20\",\"title\":\"Micro-Lens-Based Matching for Scene Recovery in Lenslet Cameras\",\"url\":\"https://www.semanticscholar.org/paper/64d313caf4d4bfef8d6bc1830b4ce38da9349c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878705236\",\"name\":\"Chunle Guo\"},{\"authorId\":\"145000882\",\"name\":\"J. Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/icme46284.2020.9102829\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4a2ab7a3055fd68e6ae1fc3be5fabc09f422151\",\"title\":\"Accurate Light Field Depth Estimation via an Occlusion-Aware Network\",\"url\":\"https://www.semanticscholar.org/paper/c4a2ab7a3055fd68e6ae1fc3be5fabc09f422151\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50207848\",\"name\":\"F. Liu\"},{\"authorId\":\"3311695\",\"name\":\"Shubo Zhou\"},{\"authorId\":null,\"name\":\"Yunlong Wang\"},{\"authorId\":\"2591189\",\"name\":\"Guangqi Hou\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1109/TIP.2019.2943019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"370f4fd2d5ef7ba7e3e28fe597a9ee23e71e5a62\",\"title\":\"Binocular Light-Field: Imaging Theory and Occlusion-Robust Depth Perception Application\",\"url\":\"https://www.semanticscholar.org/paper/370f4fd2d5ef7ba7e3e28fe597a9ee23e71e5a62\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51265495\",\"name\":\"Gou Houben\"},{\"authorId\":\"28259552\",\"name\":\"S. Fujita\"},{\"authorId\":\"145293858\",\"name\":\"K. Takahashi\"},{\"authorId\":\"1732969\",\"name\":\"T. Fujii\"}],\"doi\":\"10.1587/transinf.2019pcp0003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12e3c6f19c80dde801b11ead05bdd9fc834a0be9\",\"title\":\"Fast and Robust Disparity Estimation from Noisy Light Fields Using 1-D Slanted Filters\",\"url\":\"https://www.semanticscholar.org/paper/12e3c6f19c80dde801b11ead05bdd9fc834a0be9\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740741430\",\"name\":\"Vinh Van Duong\"},{\"authorId\":\"1740753290\",\"name\":\"Thuc Nguyen Huu\"},{\"authorId\":\"46427971\",\"name\":\"B. Jeon\"}],\"doi\":\"10.1117/12.2567014\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2e4c48999ffa55f0987639c7d04939e5c96f3534\",\"title\":\"Comparison of data costs for depth estimation from compressed light field images\",\"url\":\"https://www.semanticscholar.org/paper/2e4c48999ffa55f0987639c7d04939e5c96f3534\",\"venue\":\"Other Conferences\",\"year\":2020},{\"arxivId\":\"2007.04538\",\"authors\":[{\"authorId\":\"66454769\",\"name\":\"Kunyuan Li\"},{\"authorId\":\"47540306\",\"name\":\"J. Zhang\"},{\"authorId\":\"1596819794\",\"name\":\"Rui Sun\"},{\"authorId\":\"47957280\",\"name\":\"X. Zhang\"},{\"authorId\":\"1471362437\",\"name\":\"Jun Gao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"06c1a388996be59f6e4993f5cc3d75bbbdc4c80b\",\"title\":\"EPI-based Oriented Relation Networks for Light Field Depth Estimation\",\"url\":\"https://www.semanticscholar.org/paper/06c1a388996be59f6e4993f5cc3d75bbbdc4c80b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28938700\",\"name\":\"Yaoxiang Luo\"},{\"authorId\":\"40346014\",\"name\":\"Wenhui Zhou\"},{\"authorId\":\"10798700\",\"name\":\"Junpeng Fang\"},{\"authorId\":\"29075405\",\"name\":\"Linkai Liang\"},{\"authorId\":\"48212956\",\"name\":\"Hua Zhang\"},{\"authorId\":\"145259797\",\"name\":\"Guojun Dai\"}],\"doi\":\"10.1007/978-3-319-70090-8_65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a0f551eeaab689d872882769922b9b282407019\",\"title\":\"EPI-Patch Based Convolutional Neural Network for Depth Estimation on 4D Light Field\",\"url\":\"https://www.semanticscholar.org/paper/6a0f551eeaab689d872882769922b9b282407019\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47873277\",\"name\":\"H. Schilling\"},{\"authorId\":\"39082022\",\"name\":\"M. Diebold\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"1703781\",\"name\":\"B. J\\u00e4hne\"}],\"doi\":\"10.1109/CVPR.2018.00476\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55db258ebce8615751d3f30a98658aafbd4d0b94\",\"title\":\"Trust your Model: Light Field Depth Estimation with Inline Occlusion Handling\",\"url\":\"https://www.semanticscholar.org/paper/55db258ebce8615751d3f30a98658aafbd4d0b94\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/TPAMI.2017.2746858\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1a42c90450dad65ce54553605b294fb06dc9523\",\"title\":\"Robust Light Field Depth Estimation Using Occlusion-Noise Aware Data Costs\",\"url\":\"https://www.semanticscholar.org/paper/c1a42c90450dad65ce54553605b294fb06dc9523\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1912.10687\",\"authors\":[{\"authorId\":\"122016077\",\"name\":\"Kyuho Bae\"},{\"authorId\":\"31700532\",\"name\":\"A. Ivan\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8364066b62de2b261de9046946b6aed40cf8acd9\",\"title\":\"5D Light Field Synthesis from a Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/8364066b62de2b261de9046946b6aed40cf8acd9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40346014\",\"name\":\"Wenhui Zhou\"},{\"authorId\":\"11123083\",\"name\":\"P. Li\"},{\"authorId\":\"143962909\",\"name\":\"A. Lumsdaine\"},{\"authorId\":\"144778495\",\"name\":\"Lili Lin\"}],\"doi\":\"10.1109/ICIP.2017.8296558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4b9f1f3a53de9917d305823541f39d94a79c56d\",\"title\":\"Light-field flow: A subpixel-accuracy depth flow estimation with geometric occlusion model from a single light-field image\",\"url\":\"https://www.semanticscholar.org/paper/c4b9f1f3a53de9917d305823541f39d94a79c56d\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92041644\",\"name\":\"Xinshi Liu\"},{\"authorId\":\"49577824\",\"name\":\"Dongmei Fu\"},{\"authorId\":\"49762752\",\"name\":\"ChunHong Wu\"},{\"authorId\":\"1435354378\",\"name\":\"Ze Si\"}],\"doi\":\"10.1007/978-981-15-0474-7_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"519fbc6fb61e6515437cbb4bdc14e00ffcad0af2\",\"title\":\"The Depth Estimation Method Based on Double-Cues Fusion for Light Field Images\",\"url\":\"https://www.semanticscholar.org/paper/519fbc6fb61e6515437cbb4bdc14e00ffcad0af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47103629\",\"name\":\"Yichao Xu\"},{\"authorId\":\"39358389\",\"name\":\"Miu-Ling Lam\"}],\"doi\":\"10.1007/978-3-319-46245-5_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2e6b0e8cb0cfe086326e2abbd2e21e1ade4b1eb\",\"title\":\"Light Field Vision for Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a2e6b0e8cb0cfe086326e2abbd2e21e1ade4b1eb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39060641\",\"name\":\"H. Jeon\"},{\"authorId\":\"2870153\",\"name\":\"Jaesik Park\"},{\"authorId\":\"2056714\",\"name\":\"Gyeongmin Choe\"},{\"authorId\":\"46979140\",\"name\":\"Jinsun Park\"},{\"authorId\":\"1698615\",\"name\":\"Y. Bok\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/TPAMI.2018.2794979\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4db107e5d099f914658a6d3447b30496ecba231c\",\"title\":\"Depth from a Light Field Image with Learning-Based Matching Costs\",\"url\":\"https://www.semanticscholar.org/paper/4db107e5d099f914658a6d3447b30496ecba231c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2341951\",\"name\":\"P. Chandramouli\"},{\"authorId\":\"39866194\",\"name\":\"Meiguang Jin\"},{\"authorId\":\"2199804\",\"name\":\"D. Perrone\"},{\"authorId\":\"145646305\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1109/TIP.2017.2775062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cca50990b8ddf75b5b4cbc17ce0f65d04b21a2af\",\"title\":\"Plenoptic Image Motion Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/cca50990b8ddf75b5b4cbc17ce0f65d04b21a2af\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31700532\",\"name\":\"A. Ivan\"},{\"authorId\":\"2429068\",\"name\":\"Williem\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":\"10.1109/CVPRW.2018.00106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a79ca4dfd732f144bb2f7010bd9844d03ac3909\",\"title\":\"Light Field Depth Estimation on Off-the-Shelf Mobile GPU\",\"url\":\"https://www.semanticscholar.org/paper/6a79ca4dfd732f144bb2f7010bd9844d03ac3909\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3391060\",\"name\":\"K. Sakai\"},{\"authorId\":\"145293858\",\"name\":\"K. Takahashi\"},{\"authorId\":\"1732969\",\"name\":\"T. Fujii\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"}],\"doi\":\"10.1007/978-3-030-58529-7_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f32ad631db181a042e7c9eee67a50427fcb197b7\",\"title\":\"Acquiring Dynamic Light Fields Through Coded Aperture Camera\",\"url\":\"https://www.semanticscholar.org/paper/f32ad631db181a042e7c9eee67a50427fcb197b7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31083289\",\"name\":\"M. Ko\"},{\"authorId\":\"144118620\",\"name\":\"D. Kim\"},{\"authorId\":\"36741956\",\"name\":\"K. Kim\"}],\"doi\":\"10.1109/ICMLA.2018.00065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54f58d3ba6e26e4b3ad0d9a202bf1667fcda4396\",\"title\":\"GAN-Based Super Resolution for Accurate 3D Surface Reconstruction from Light Field Skin Images Towards Haptic Palpation\",\"url\":\"https://www.semanticscholar.org/paper/54f58d3ba6e26e4b3ad0d9a202bf1667fcda4396\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2760487\",\"name\":\"Zhaolin Xiao\"},{\"authorId\":\"33050863\",\"name\":\"Lipeng Si\"},{\"authorId\":\"33774421\",\"name\":\"Guoqing Zhou\"}],\"doi\":\"10.1109/JSTSP.2017.2715012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d29bdacc17ae1175873f594ebf061ff6c4b897b5\",\"title\":\"Seeing Beyond Foreground Occlusion: A Joint Framework for SAP-Based Scene Depth and Appearance Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/d29bdacc17ae1175873f594ebf061ff6c4b897b5\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1661026955\",\"name\":\"Wang Xin\"},{\"authorId\":\"1411146647\",\"name\":\"Zhang Xu-dong\"},{\"authorId\":\"144969144\",\"name\":\"Z. Jun\"},{\"authorId\":\"1965907825\",\"name\":\"Sun Rui\"}],\"doi\":\"10.12086/OEE.2020.190634\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7552896bfd79cadc7e57fe6965ba6d7ccf5e2b5a\",\"title\":\"Image dehazing algorithm by combining light field multi-cues and atmospheric scattering model\",\"url\":\"https://www.semanticscholar.org/paper/7552896bfd79cadc7e57fe6965ba6d7ccf5e2b5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31453821\",\"name\":\"Qiuxia Hou\"},{\"authorId\":\"95055206\",\"name\":\"C. Jung\"}],\"doi\":\"10.1109/ISM.2017.13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bef7dc601cd636d26adcb2f3a07e9077cb333795\",\"title\":\"Occlusion Robust Light Field Depth Estimation Using Segmentation Guided Bilateral Filtering\",\"url\":\"https://www.semanticscholar.org/paper/bef7dc601cd636d26adcb2f3a07e9077cb333795\",\"venue\":\"2017 IEEE International Symposium on Multimedia (ISM)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2134200\",\"name\":\"Yu Mo\"},{\"authorId\":\"2577413\",\"name\":\"J. Yang\"},{\"authorId\":\"145564407\",\"name\":\"C. Xiao\"},{\"authorId\":\"4431471\",\"name\":\"Wei An\"}],\"doi\":\"10.1109/ACCESS.2019.2928006\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bad115cf378f83c6ddf55d14d299acec9a1f572f\",\"title\":\"Toward Real-World Light Field Depth Estimation: A Noise-Aware Paradigm Using Multi-Stereo Disparity Integration\",\"url\":\"https://www.semanticscholar.org/paper/bad115cf378f83c6ddf55d14d299acec9a1f572f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1903.12364\",\"authors\":[{\"authorId\":\"31700532\",\"name\":\"A. Ivan\"},{\"authorId\":\"2429068\",\"name\":\"Williem\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"28c18703f3e99fd6fbd1b337d673e99e8ad0f2c0\",\"title\":\"Synthesizing a 4D Spatio-Angular Consistent Light Field from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/28c18703f3e99fd6fbd1b337d673e99e8ad0f2c0\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":15041564,\"doi\":\"10.1109/CVPR.2016.476\",\"fieldsOfStudy\":[\"Mathematics\",\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"2b96ca689a1c97b2c83c6c248cedcd6af93b994c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"}],\"doi\":\"10.1109/CVPR.2001.990462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48766e3ca12448a0b1f29a2ef68126023459a928\",\"title\":\"Handling occlusions in dense multi-view stereo\",\"url\":\"https://www.semanticscholar.org/paper/48766e3ca12448a0b1f29a2ef68126023459a928\",\"venue\":\"Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Jian Sun\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2012.213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b7fc36dc56a400f7a7f4c75e53550bbb6a0a4d8\",\"title\":\"Guided Image Filtering\",\"url\":\"https://www.semanticscholar.org/paper/1b7fc36dc56a400f7a7f4c75e53550bbb6a0a4d8\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2522642\",\"name\":\"Haiting Lin\"},{\"authorId\":\"2118531\",\"name\":\"Can Chen\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/ICCV.2015.394\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c71d08db88a9a7c108c56fef2d5320b51d2e417f\",\"title\":\"Depth Recovery from Light Field Using Focal Stack Symmetry\",\"url\":\"https://www.semanticscholar.org/paper/c71d08db88a9a7c108c56fef2d5320b51d2e417f\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2731965\",\"name\":\"D. Dansereau\"},{\"authorId\":\"49258747\",\"name\":\"O. Pizarro\"},{\"authorId\":\"2221004\",\"name\":\"Stefan B. Williams\"}],\"doi\":\"10.1109/CVPR.2013.137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"830dd2b32129b7795dbb7766ceb3f01918104c1b\",\"title\":\"Decoding, Calibration and Rectification for Lenselet-Based Plenoptic Cameras\",\"url\":\"https://www.semanticscholar.org/paper/830dd2b32129b7795dbb7766ceb3f01918104c1b\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47383180\",\"name\":\"R. Ng\"}],\"doi\":\"10.1145/1186822.1073256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea52789c6b73823f22e8ff2c48ad8474f502a83\",\"title\":\"Fourier slice photography\",\"url\":\"https://www.semanticscholar.org/paper/cea52789c6b73823f22e8ff2c48ad8474f502a83\",\"venue\":\"SIGGRAPH '05\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2146731\",\"name\":\"V. Vaish\"},{\"authorId\":\"1801789\",\"name\":\"M. Levoy\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/CVPR.2006.244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bba3283cdd4320acbc83d493f18d1ca9b00178b8\",\"title\":\"Reconstructing Occluded Surfaces Using Synthetic Apertures: Stereo, Focus and Robust Measures\",\"url\":\"https://www.semanticscholar.org/paper/bba3283cdd4320acbc83d493f18d1ca9b00178b8\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3270016\",\"name\":\"Michael W. Tao\"},{\"authorId\":\"1733732\",\"name\":\"Sunil Hadap\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1109/ICCV.2013.89\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ae818782111e26d42cdbb3d850b1f17b9578629a\",\"title\":\"Depth from Combining Defocus and Correspondence Using Light-Field Cameras\",\"url\":\"https://www.semanticscholar.org/paper/ae818782111e26d42cdbb3d850b1f17b9578629a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2737959\",\"name\":\"Minhaeng Lee\"},{\"authorId\":\"3358380\",\"name\":\"Sunyeong Kim\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2013.407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9076da9cdaa9c196d1f21a8aac6d7f58a77b9052\",\"title\":\"Modeling the Calibration Pipeline of the Lytro Camera for High Quality Light-Field Image Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/9076da9cdaa9c196d1f21a8aac6d7f58a77b9052\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692688\",\"name\":\"Yuri Boykov\"},{\"authorId\":\"1922280\",\"name\":\"Olga Veksler\"},{\"authorId\":\"2984143\",\"name\":\"R. Zabih\"}],\"doi\":\"10.1109/ICCV.1999.791245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3120324069ec20eed853d3f9bbbceb32e4173b93\",\"title\":\"Fast approximate energy minimization via graph cuts\",\"url\":\"https://www.semanticscholar.org/paper/3120324069ec20eed853d3f9bbbceb32e4173b93\",\"venue\":\"Proceedings of the Seventh IEEE International Conference on Computer Vision\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2086328\",\"name\":\"Christoph Rhemann\"},{\"authorId\":\"3115485\",\"name\":\"A. Hosni\"},{\"authorId\":\"2873656\",\"name\":\"M. Bleyer\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"1990797\",\"name\":\"M. Gelautz\"}],\"doi\":\"10.1109/CVPR.2011.5995372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f908d2fb9cfcaff17030a912e4811fb02aaeec03\",\"title\":\"Fast cost-volume filtering for visual correspondence and beyond\",\"url\":\"https://www.semanticscholar.org/paper/f908d2fb9cfcaff17030a912e4811fb02aaeec03\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698615\",\"name\":\"Y. Bok\"},{\"authorId\":\"39060641\",\"name\":\"H. Jeon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/TPAMI.2016.2541145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4faafe48372983fb241624d9d64db595fab9cc8\",\"title\":\"Geometric Calibration of Micro-Lens-Based Light Field Cameras Using Line Features\",\"url\":\"https://www.semanticscholar.org/paper/c4faafe48372983fb241624d9d64db595fab9cc8\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4753663\",\"name\":\"S. Wanner\"},{\"authorId\":\"48006440\",\"name\":\"S. Meister\"},{\"authorId\":\"2065814\",\"name\":\"Bastian Goldl\\u00fccke\"}],\"doi\":\"10.2312/PE.VMV.VMV13.225-226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4ae6dbcb6a7ebd3fd9287ad1e56a6944d6b1c09\",\"title\":\"Datasets and Benchmarks for Densely Sampled 4D Light Fields\",\"url\":\"https://www.semanticscholar.org/paper/f4ae6dbcb6a7ebd3fd9287ad1e56a6944d6b1c09\",\"venue\":\"VMV\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4753663\",\"name\":\"S. Wanner\"},{\"authorId\":\"2065814\",\"name\":\"Bastian Goldl\\u00fccke\"}],\"doi\":\"10.1109/CVPR.2012.6247656\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2a2aee9d65373ed6912dab5f009ad99f91905fd\",\"title\":\"Globally consistent depth labeling of 4D light fields\",\"url\":\"https://www.semanticscholar.org/paper/e2a2aee9d65373ed6912dab5f009ad99f91905fd\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118531\",\"name\":\"Can Chen\"},{\"authorId\":\"2522642\",\"name\":\"Haiting Lin\"},{\"authorId\":\"145948398\",\"name\":\"Zhan Yu\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/CVPR.2014.197\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c52ff7d9504cb4e732e286a69fbaeb1deb00f0b\",\"title\":\"Light Field Stereo Matching Using Bilateral Statistics of Surface Cameras\",\"url\":\"https://www.semanticscholar.org/paper/6c52ff7d9504cb4e732e286a69fbaeb1deb00f0b\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lytro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The Lytro camera\",\"url\":\"\",\"venue\":\"The Lytro camera\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"2431628\",\"name\":\"J. Ye\"},{\"authorId\":\"145306197\",\"name\":\"Y. Ji\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/TPAMI.2016.2610425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de1a6d76713aae081cff857033d38ac1d637e5af\",\"title\":\"Saliency Detection on Light Field\",\"url\":\"https://www.semanticscholar.org/paper/de1a6d76713aae081cff857033d38ac1d637e5af\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3270016\",\"name\":\"Michael W. Tao\"},{\"authorId\":\"2179732\",\"name\":\"Pratul P. Srinivasan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"7723706\",\"name\":\"S. Rusinkiewicz\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1109/CVPR.2015.7298804\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d8d059eaa9cd1b56e61c4985ccabfe6b8b7c0e03\",\"title\":\"Depth from shading, defocus, and correspondence using light-field angular coherence\",\"url\":\"https://www.semanticscholar.org/paper/d8d059eaa9cd1b56e61c4985ccabfe6b8b7c0e03\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"144645904\",\"name\":\"Long Quan\"}],\"doi\":\"10.1109/CVPR.2005.76\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52ac545fa9bc5bb8b0fcd08d0f8003aa02061642\",\"title\":\"Asymmetrical occlusion handling using graph cut for multi-view stereo\",\"url\":\"https://www.semanticscholar.org/paper/52ac545fa9bc5bb8b0fcd08d0f8003aa02061642\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Raytrix\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"3D light field camera technology\",\"url\":\"\",\"venue\":\"3D light field camera technology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2391035\",\"name\":\"Bennett S. Wilburn\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"2146731\",\"name\":\"V. Vaish\"},{\"authorId\":\"3129635\",\"name\":\"Eino-Ville Talvala\"},{\"authorId\":\"37254421\",\"name\":\"Emilio R. Ant\\u00fanez\"},{\"authorId\":\"145514355\",\"name\":\"A. Barth\"},{\"authorId\":\"145506199\",\"name\":\"Andrew Adams\"},{\"authorId\":\"144764328\",\"name\":\"M. Horowitz\"},{\"authorId\":\"1801789\",\"name\":\"M. Levoy\"}],\"doi\":\"10.1145/1073204.1073259\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4f951a82c84578ffbc017f995788029a89f81d5\",\"title\":\"High performance imaging using large camera arrays\",\"url\":\"https://www.semanticscholar.org/paper/c4f951a82c84578ffbc017f995788029a89f81d5\",\"venue\":\"SIGGRAPH 2005\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144653005\",\"name\":\"V. Kolmogorov\"},{\"authorId\":\"2984143\",\"name\":\"R. Zabih\"}],\"doi\":\"10.1007/3-540-47977-5_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"390ba243bb7648369ba6e8fed313e9d6f53846bd\",\"title\":\"Multi-camera Scene Reconstruction via Graph Cuts\",\"url\":\"https://www.semanticscholar.org/paper/390ba243bb7648369ba6e8fed313e9d6f53846bd\",\"venue\":\"ECCV\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"calibration and rectification for lenselet - based plenop - tic cameras\",\"url\":\"\",\"venue\":\"Proc . of IEEE Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1109/ICCV.2015.398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa94a5eb7716ea4aa73a215ad7ef28d338dfae21\",\"title\":\"Occlusion-Aware Depth Estimation Using Light-Field Cameras\",\"url\":\"https://www.semanticscholar.org/paper/aa94a5eb7716ea4aa73a215ad7ef28d338dfae21\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39060641\",\"name\":\"H. Jeon\"},{\"authorId\":\"2870153\",\"name\":\"Jaesik Park\"},{\"authorId\":\"2056714\",\"name\":\"Gyeongmin Choe\"},{\"authorId\":\"2704403\",\"name\":\"Jinsun Park\"},{\"authorId\":\"1698615\",\"name\":\"Y. Bok\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2015.7298762\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3bc4913d9fbbd2527fd3e582c729bba96b6467f2\",\"title\":\"Accurate depth map estimation from a lenslet light field camera\",\"url\":\"https://www.semanticscholar.org/paper/3bc4913d9fbbd2527fd3e582c729bba96b6467f2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2208378\",\"name\":\"A. Jarabo\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"2149814\",\"name\":\"A. Bousseau\"},{\"authorId\":\"1757883\",\"name\":\"F. Pellacini\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"}],\"doi\":\"10.1145/2601097.2601125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bbc3fffea381e82d2507800c7e5763dff00766f\",\"title\":\"How do people edit light fields?\",\"url\":\"https://www.semanticscholar.org/paper/6bbc3fffea381e82d2507800c7e5763dff00766f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"3358380\",\"name\":\"Sunyeong Kim\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1007/978-3-319-10593-2_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa31c1f24f5b50281a2f39fcadd0704adacc2e2a\",\"title\":\"Consistent Matting for Light Field Images\",\"url\":\"https://www.semanticscholar.org/paper/aa31c1f24f5b50281a2f39fcadd0704adacc2e2a\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48886131\",\"name\":\"M. Bleyer\"},{\"authorId\":\"150063676\",\"name\":\"C. Rother\"},{\"authorId\":\"143967473\",\"name\":\"Pushmeet Kohli\"}],\"doi\":\"10.1109/CVPR.2010.5539783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4cf565f63b8e08e6e51733f27ea1b696fa53313\",\"title\":\"Surface stereo with soft segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f4cf565f63b8e08e6e51733f27ea1b696fa53313\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010}],\"title\":\"Robust Light Field Depth Estimation for Noisy Scene with Occlusion\",\"topics\":[{\"topic\":\"Light field\",\"topicId\":\"203029\",\"url\":\"https://www.semanticscholar.org/topic/203029\"},{\"topic\":\"Graph cuts in computer vision\",\"topicId\":\"81198\",\"url\":\"https://www.semanticscholar.org/topic/81198\"},{\"topic\":\"Hidden surface determination\",\"topicId\":\"54802\",\"url\":\"https://www.semanticscholar.org/topic/54802\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Depth map\",\"topicId\":\"23196\",\"url\":\"https://www.semanticscholar.org/topic/23196\"},{\"topic\":\"AngularJS\",\"topicId\":\"458352\",\"url\":\"https://www.semanticscholar.org/topic/458352\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"3D reconstruction\",\"topicId\":\"63486\",\"url\":\"https://www.semanticscholar.org/topic/63486\"},{\"topic\":\"Randomness\",\"topicId\":\"726\",\"url\":\"https://www.semanticscholar.org/topic/726\"},{\"topic\":\"Display resolution\",\"topicId\":\"11387\",\"url\":\"https://www.semanticscholar.org/topic/11387\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Cut (graph theory)\",\"topicId\":\"197734\",\"url\":\"https://www.semanticscholar.org/topic/197734\"},{\"topic\":\"Markov random field\",\"topicId\":\"10898\",\"url\":\"https://www.semanticscholar.org/topic/10898\"}],\"url\":\"https://www.semanticscholar.org/paper/2b96ca689a1c97b2c83c6c248cedcd6af93b994c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"