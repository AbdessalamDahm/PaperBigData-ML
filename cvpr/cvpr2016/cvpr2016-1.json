"{\"abstract\":\"While recent deep neural network models have achieved promising results on the image captioning task, they rely largely on the availability of corpora with paired image and sentence captions to describe objects in context. In this work, we propose the Deep Compositional Captioner (DCC) to address the task of generating descriptions of novel objects which are not present in paired imagesentence datasets. Our method achieves this by leveraging large object recognition datasets and external text corpora and by transferring knowledge between semantically similar concepts. Current deep caption models can only describe objects contained in paired image-sentence corpora, despite the fact that they are pre-trained with large object recognition datasets, namely ImageNet. In contrast, our model can compose sentences that describe novel objects and their interactions with other objects. We demonstrate our model's ability to describe novel concepts by empirically evaluating its performance on MSCOCO and show qualitative results on ImageNet images of objects for which no paired image-sentence data exist. Further, we extend our approach to generate descriptions of objects in video clips. Our results show that DCC has distinct advantages over existing image and video captioning approaches for generating descriptions of new objects in context.\",\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\",\"url\":\"https://www.semanticscholar.org/author/2234342\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\",\"url\":\"https://www.semanticscholar.org/author/1811430\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\",\"url\":\"https://www.semanticscholar.org/author/1797655\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\",\"url\":\"https://www.semanticscholar.org/author/2903226\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\",\"url\":\"https://www.semanticscholar.org/author/1753210\"}],\"citationVelocity\":41,\"citations\":[{\"arxivId\":\"1811.02765\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33018965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"title\":\"Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2814633\",\"name\":\"M. Bustreo\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/ICCVW.2019.00165\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"68def1260e8040e6ff139e27ec101fc4911b8e04\",\"title\":\"Enhancing Visual Embeddings through Weakly Supervised Captioning for Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/68def1260e8040e6ff139e27ec101fc4911b8e04\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":\"1908.02726\",\"authors\":[{\"authorId\":\"94845899\",\"name\":\"Qianyu Feng\"},{\"authorId\":\"98264517\",\"name\":\"Y. Wu\"},{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"3863922\",\"name\":\"C. Yan\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1109/TCSVT.2020.2965966\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"daa87e86b469d975a9ad84bfb5eee230efa8af3e\",\"title\":\"Cascaded Revision Network for Novel Object Captioning\",\"url\":\"https://www.semanticscholar.org/paper/daa87e86b469d975a9ad84bfb5eee230efa8af3e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"title\":\"Role of Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"135273ea1521236e96bd79a319bf9386969bae5f\",\"title\":\"Exploiting independent visual and textual data sources to improve multi-modal methods for description and querying of visual data\",\"url\":\"https://www.semanticscholar.org/paper/135273ea1521236e96bd79a319bf9386969bae5f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.5244/C.31.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d814981606fe5954148e45c737f1debe7b5b36c4\",\"title\":\"Visual Textbook Network: Watch Carefully before Answering Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/d814981606fe5954148e45c737f1debe7b5b36c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46671592\",\"name\":\"Y. Xian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e11ad2a6c18112c13e9e65d64ef85cb1ff4883d0\",\"title\":\"Exploring the Internal Statistics: Single Image Super-Resolution, Completion and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e11ad2a6c18112c13e9e65d64ef85cb1ff4883d0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3123266.3123391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39836fbbcd2a664edb31119e88870c38b83df352\",\"title\":\"Adaptively Attending to Visual Attributes and Linguistic Knowledge for Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39836fbbcd2a664edb31119e88870c38b83df352\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"},{\"authorId\":\"51211765\",\"name\":\"A. Bhat\"},{\"authorId\":\"119713376\",\"name\":\"Aravindh Kuppusamy\"},{\"authorId\":\"1678800\",\"name\":\"S. Lyshevski\"}],\"doi\":\"10.1117/12.2519300\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d76c6d6f23680d596dc7d3e5c33c193ca5dc10e\",\"title\":\"Object recognition, identification and classification for intelligent surveillance and reconnaissance platforms\",\"url\":\"https://www.semanticscholar.org/paper/2d76c6d6f23680d596dc7d3e5c33c193ca5dc10e\",\"venue\":\"Defense + Commercial Sensing\",\"year\":2019},{\"arxivId\":\"1906.05518\",\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P19-1063\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d4e26768300d94850418de10484067707fec34ec\",\"title\":\"Know What You Don't Know: Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories\",\"url\":\"https://www.semanticscholar.org/paper/d4e26768300d94850418de10484067707fec34ec\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1903.01489\",\"authors\":[{\"authorId\":\"2035969\",\"name\":\"S. Pini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3490384\",\"name\":\"Federico Bolelli\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-018-7040-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1344317f255a9d338fb80f276126951b9644f7e3\",\"title\":\"M-VAD names: a dataset for video captioning with naming\",\"url\":\"https://www.semanticscholar.org/paper/1344317f255a9d338fb80f276126951b9644f7e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wadalkar Shruti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"472faa9c5fbc81dac9ee5405446dd8403415ac3a\",\"title\":\"International Journal of Innovative Technology and Exploring Engineering (IJITEE)\",\"url\":\"https://www.semanticscholar.org/paper/472faa9c5fbc81dac9ee5405446dd8403415ac3a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.02308\",\"authors\":[{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1721328\",\"name\":\"S. Antani\"},{\"authorId\":\"145949571\",\"name\":\"D. Bulterman\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"},{\"authorId\":\"144049352\",\"name\":\"Julia Hirschberg\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"},{\"authorId\":\"1398227667\",\"name\":\"K. Mayer-Patel\"},{\"authorId\":\"2337428\",\"name\":\"R. Meth\"},{\"authorId\":\"144447740\",\"name\":\"R. Mooney\"},{\"authorId\":\"1688353\",\"name\":\"K. Nahrstedt\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"},{\"authorId\":\"2807460\",\"name\":\"S. Oviatt\"},{\"authorId\":\"70295214\",\"name\":\"B. Prabhakaran\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"},{\"authorId\":\"145372008\",\"name\":\"H. Sundaram\"},{\"authorId\":\"51064498\",\"name\":\"Zhengyou Zhang\"},{\"authorId\":\"1705742\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"539a7061d4289b1aa72f319c680ea87ff695289c\",\"title\":\"Report of 2017 NSF Workshop on Multimedia Challenges, Opportunities and Research Roadmaps\",\"url\":\"https://www.semanticscholar.org/paper/539a7061d4289b1aa72f319c680ea87ff695289c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2873826\",\"name\":\"Chandranath Adak\"},{\"authorId\":\"1759420\",\"name\":\"B. Chaudhuri\"},{\"authorId\":\"30773936\",\"name\":\"Chin-Teng Lin\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207245\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0760cd0f4f519bf64e1cb40a3a79d99d8d7c12ad\",\"title\":\"Why Not? Tell us the Reason for Writer Dissimilarity\",\"url\":\"https://www.semanticscholar.org/paper/0760cd0f4f519bf64e1cb40a3a79d99d8d7c12ad\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1704.01502\",\"authors\":[{\"authorId\":\"145314568\",\"name\":\"Zhiqiang Shen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"},{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"3700393\",\"name\":\"Minjun Li\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2017.548\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"title\":\"Weakly Supervised Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51240443\",\"name\":\"Jacob A. Allison\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"},{\"authorId\":\"1678800\",\"name\":\"S. Lyshevski\"}],\"doi\":\"10.1109/ICUAS.2018.8453309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9575f9b22d4ef2d3898cb1b2ab65105ee0f5183a\",\"title\":\"Resilient Communication, Object Classification and Data Fusion in Unmanned Aerial Systems\",\"url\":\"https://www.semanticscholar.org/paper/9575f9b22d4ef2d3898cb1b2ab65105ee0f5183a\",\"venue\":\"2018 International Conference on Unmanned Aircraft Systems (ICUAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146680946\",\"name\":\"Faruk Ahmed\"},{\"authorId\":null,\"name\":\"Md. Sultan Mahmud\"},{\"authorId\":\"1404335751\",\"name\":\"Rakib Al-Fahad\"},{\"authorId\":\"2355122\",\"name\":\"Shahinur Alam\"},{\"authorId\":\"1828610\",\"name\":\"M. Yeasin\"}],\"doi\":\"10.1109/ICDIS.2018.00020\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9ff6fc68bf47d037382571de797ac01a05dcf6a\",\"title\":\"Image Captioning for Ambient Awareness on a Sidewalk\",\"url\":\"https://www.semanticscholar.org/paper/c9ff6fc68bf47d037382571de797ac01a05dcf6a\",\"venue\":\"2018 1st International Conference on Data Intelligence and Security (ICDIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"title\":\"ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144343897\",\"name\":\"R. Guo\"},{\"authorId\":\"22771932\",\"name\":\"Shubo Ma\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/s11042-018-7118-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"title\":\"Image captioning: from structural tetrad to translated sentences\",\"url\":\"https://www.semanticscholar.org/paper/ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1905.07075\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"123813779\",\"name\":\"Lucas Van Bramer\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"418003534843f0fdda7dfb1d41c35bef683b1dad\",\"title\":\"Deep Unified Multimodal Embeddings for Understanding both Content and Users in Social Media Networks\",\"url\":\"https://www.semanticscholar.org/paper/418003534843f0fdda7dfb1d41c35bef683b1dad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.00047\",\"authors\":[{\"authorId\":\"9424554\",\"name\":\"Berkan Demirel\"},{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d617b8cbf10b3fe776c16fa498e6420def3e000\",\"title\":\"Image Captioning with Unseen Objects\",\"url\":\"https://www.semanticscholar.org/paper/3d617b8cbf10b3fe776c16fa498e6420def3e000\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"2717138\",\"name\":\"W. T. Hsu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-54407-6_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"507d36a10ee5c3ca657bb2f41f9bb47552c30ed0\",\"title\":\"Video Captioning via Sentence Augmentation and Spatio-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/507d36a10ee5c3ca657bb2f41f9bb47552c30ed0\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"2003.05078\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"title\":\"Visual Grounding in Video for Unsupervised Word Translation\",\"url\":\"https://www.semanticscholar.org/paper/a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40960718\",\"name\":\"Michael Warren Skirpan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"419e8cae62ab7244ec73855b845433e28928b771\",\"title\":\"Negotiating the Future: Leveraging Socio-technical Narratives to Engage Multiple Voices in the Ethics of Our Future\",\"url\":\"https://www.semanticscholar.org/paper/419e8cae62ab7244ec73855b845433e28928b771\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.06543\",\"authors\":[{\"authorId\":\"1736750\",\"name\":\"N. Martinel\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"1708507\",\"name\":\"C. Micheloni\"}],\"doi\":\"10.1109/WACV.2018.00068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeda0531681764381b4c8b9c139ade3200e7f5cf\",\"title\":\"Wide-Slice Residual Networks for Food Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aeda0531681764381b4c8b9c139ade3200e7f5cf\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66881536\",\"name\":\"Danyu Lai\"},{\"authorId\":\"145711988\",\"name\":\"Wei Tian\"},{\"authorId\":null,\"name\":\"Long Chen\"}],\"doi\":\"10.1016/j.patcog.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30cafcd23ca64edea14aa86170d2d8fbea5cd8f3\",\"title\":\"Improving classification with semi-supervised and fine-grained learning\",\"url\":\"https://www.semanticscholar.org/paper/30cafcd23ca64edea14aa86170d2d8fbea5cd8f3\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-319-75928-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51280870657c72400b5de46ba56ee18b9891ab40\",\"title\":\"Multimodal Attention Agents in Visual Conversation\",\"url\":\"https://www.semanticscholar.org/paper/51280870657c72400b5de46ba56ee18b9891ab40\",\"venue\":\"EIDWT\",\"year\":2018},{\"arxivId\":\"2012.10575\",\"authors\":[{\"authorId\":\"1669661014\",\"name\":\"Zhuo Wang\"},{\"authorId\":\"30691613\",\"name\":\"X. Wang\"},{\"authorId\":\"3199434\",\"name\":\"W. Yang\"},{\"authorId\":\"114356818\",\"name\":\"Y. Xiao\"},{\"authorId\":\"9415854\",\"name\":\"Yucheng Liu\"},{\"authorId\":\"47818453\",\"name\":\"Lei Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0021554d69e87f9e6c73aeb3418c1575de1cb9b2\",\"title\":\"yNet: a multi-input convolutional network for ultra-fast simulation of field evolvement\",\"url\":\"https://www.semanticscholar.org/paper/0021554d69e87f9e6c73aeb3418c1575de1cb9b2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035969\",\"name\":\"S. Pini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-68548-9_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff44d8938c52cfdca48c80f8e1618bbcbf91cb2a\",\"title\":\"Towards Video Captioning with Naming: A Novel Dataset and a Multi-modal Approach\",\"url\":\"https://www.semanticscholar.org/paper/ff44d8938c52cfdca48c80f8e1618bbcbf91cb2a\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"66622154\",\"name\":\"Ray Ptucha\"}],\"doi\":\"10.1007/s10044-018-00770-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"title\":\"Understanding temporal structure for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1810.02358\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"1837923\",\"name\":\"Taehoon Kim\"},{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00858\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b80f128830114896df94999b4104cb75408e657e\",\"title\":\"Transfer Learning via Unsupervised Task Discovery for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b80f128830114896df94999b4104cb75408e657e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51349878\",\"name\":\"Y. C. Yoon\"},{\"authorId\":\"49591454\",\"name\":\"SoYoung Park\"},{\"authorId\":\"14966100\",\"name\":\"Soo Park\"},{\"authorId\":\"153803012\",\"name\":\"H. Lim\"}],\"doi\":\"10.4218/ETRIJ.2018-0621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"title\":\"Image classification and captioning model considering a CAM\\u2010based disagreement loss\",\"url\":\"https://www.semanticscholar.org/paper/ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1611.04021\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1da2431a799f68888b7e035fe49fe47a4735b71b\",\"title\":\"Leveraging Video Descriptions to Learn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1da2431a799f68888b7e035fe49fe47a4735b71b\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1807.02257\",\"authors\":[{\"authorId\":\"1414497291\",\"name\":\"Edgar Margffoy-Tuay\"},{\"authorId\":\"152978592\",\"name\":\"Juan C. P\\u00e9rez\"},{\"authorId\":\"51049657\",\"name\":\"E. Botero\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"}],\"doi\":\"10.1007/978-3-030-01252-6_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"title\":\"Dynamic Multimodal Instance Segmentation guided by natural language queries\",\"url\":\"https://www.semanticscholar.org/paper/810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40895688\",\"name\":\"Kaylee Burns\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9226675e413bb4b82ad419a10e4ac9ebd6aa7fef\",\"title\":\"Addressing and Understanding Shortcomings in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/9226675e413bb4b82ad419a10e4ac9ebd6aa7fef\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.02201\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.18653/v1/D19-1208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a87d5654c41f3dfa7252d079045d7094f601f78e\",\"title\":\"Image Captioning with Very Scarce Supervised Data: Adversarial Semi-Supervised Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/a87d5654c41f3dfa7252d079045d7094f601f78e\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1812.03283\",\"authors\":[{\"authorId\":\"4760298\",\"name\":\"J. Du\"},{\"authorId\":\"144485517\",\"name\":\"Yu Qin\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b75163ef32d63ba076e94d9321442ca8223fcd4\",\"title\":\"Attend More Times for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0b75163ef32d63ba076e94d9321442ca8223fcd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134342162\",\"name\":\"Li Wen-jie\"},{\"authorId\":\"153697517\",\"name\":\"Y. Zheng\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"},{\"authorId\":\"1878750882\",\"name\":\"Weiguo Fan\"}],\"doi\":\"10.1002/asi.24373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"title\":\"Cross\\u2010modal retrieval with dual multi\\u2010angle self\\u2010attention\",\"url\":\"https://www.semanticscholar.org/paper/fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.03803\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1145/3240508.3240640\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d64f52b94977b71976327eeb3db702b246ee39ce\",\"title\":\"Decoupled Novel Object Captioner\",\"url\":\"https://www.semanticscholar.org/paper/d64f52b94977b71976327eeb3db702b246ee39ce\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1563987322\",\"name\":\"Teng Wang\"},{\"authorId\":\"1500383979\",\"name\":\"Xinjie Tong\"},{\"authorId\":\"117194087\",\"name\":\"W. Cai\"}],\"doi\":\"10.1016/j.neucom.2020.03.023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f71c19eab123698920e8c1b0d73a571d53f4589c\",\"title\":\"Attention-based face alignment: A solution to speed/accuracy trade-off\",\"url\":\"https://www.semanticscholar.org/paper/f71c19eab123698920e8c1b0d73a571d53f4589c\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4445312\",\"name\":\"Joshua T. Abbott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dab73c94a0d0958343ff68f023ecd47a61998c3e\",\"title\":\"Statistical models of learning and using semantic representations\",\"url\":\"https://www.semanticscholar.org/paper/dab73c94a0d0958343ff68f023ecd47a61998c3e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1703.08338\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"Davide Moltisanti\"},{\"authorId\":\"1398236231\",\"name\":\"Walterio W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"Dima Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b408a3ca6fb39b0fda4d77e6a9679003b2dc9ab\",\"title\":\"Improving Classification by Improving Labelling: Introducing Probabilistic Multi-Label Object Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b408a3ca6fb39b0fda4d77e6a9679003b2dc9ab\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.05253\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"Fangyu Wu\"},{\"authorId\":\"33830793\",\"name\":\"Jeremy S. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"Bailing Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"title\":\"Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145959949\",\"name\":\"J. Serrano\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"title\":\"Boosting image captioning with an attentional mechanism = Boosting image captioning using diverse beam search\",\"url\":\"https://www.semanticscholar.org/paper/e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1603.08507\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46493-0_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"title\":\"Generating Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"38218192\",\"name\":\"X. Wang\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02844808a10aa27fad397d1941ec24f5e546ca0b\",\"title\":\"Bidirectional image-sentence retrieval by local and global deep matching\",\"url\":\"https://www.semanticscholar.org/paper/02844808a10aa27fad397d1941ec24f5e546ca0b\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752475\",\"name\":\"Erik Blasch\"},{\"authorId\":\"145502309\",\"name\":\"Alex Aved\"},{\"authorId\":\"144629409\",\"name\":\"S. Bhattacharyya\"}],\"doi\":\"10.1007/978-3-319-95504-9_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc0eaefe98f232428750779c608c741da994e4e4\",\"title\":\"Dynamic Data Driven Application Systems (DDDAS) for Multimedia Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dc0eaefe98f232428750779c608c741da994e4e4\",\"venue\":\"Handbook of Dynamic Data Driven Applications Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ruchitesh Malukani\"},{\"authorId\":null,\"name\":\"Nihaal Subhash\"},{\"authorId\":null,\"name\":\"Chhaya Zala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eefe9fe0b57b079d779d7c82162db4570b60bc3\",\"title\":\"Deep Learning Model Implementation in Web-Based Application for Automatic Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/0eefe9fe0b57b079d779d7c82162db4570b60bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98419684\",\"name\":\"Phil Kinghorn\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9549e8e59f5ce436cc4d81ddb859b3295d131c5b\",\"title\":\"Deep learning-based regional image caption generation with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/9549e8e59f5ce436cc4d81ddb859b3295d131c5b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-030-01174-1_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"title\":\"Multimodal Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.00930\",\"authors\":[{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"2717138\",\"name\":\"W. T. Hsu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2017.64\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"828a7b3122ebd5b8b0c617902bc04ac5a6c60240\",\"title\":\"Show, Adapt and Tell: Adversarial Training of Cross-Domain Image Captioner\",\"url\":\"https://www.semanticscholar.org/paper/828a7b3122ebd5b8b0c617902bc04ac5a6c60240\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2168767\",\"name\":\"Umanga Bista\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1748257\",\"name\":\"Achim Rettinger\"}],\"doi\":\"10.1007/978-3-319-93417-4_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f8e9524051c60fa11f498ae05710dd8239474ce\",\"title\":\"Knowledge Guided Attention and Inference for Describing Images Containing Unseen Objects\",\"url\":\"https://www.semanticscholar.org/paper/7f8e9524051c60fa11f498ae05710dd8239474ce\",\"venue\":\"ESWC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177145\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dadb7ddfde3478238d23a8bacf5eddecc59e84c9\",\"title\":\"Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/dadb7ddfde3478238d23a8bacf5eddecc59e84c9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"title\":\"A Semi-supervised Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500538466\",\"name\":\"Jinyu Ma\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1016/j.neucom.2020.05.090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86f847d58a773164a11778d1d1c4e6d3a731cbb9\",\"title\":\"Scene image retrieval with siamese spatial attention pooling\",\"url\":\"https://www.semanticscholar.org/paper/86f847d58a773164a11778d1d1c4e6d3a731cbb9\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2012.07248\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1527112562\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1807805250\",\"name\":\"Muchen Li\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"965571810fcb79fdaaed7329ff57b3720508a241\",\"title\":\"TDAF: Top-Down Attention Framework for Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/965571810fcb79fdaaed7329ff57b3720508a241\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144766612\",\"name\":\"S. Wu\"},{\"authorId\":\"143844413\",\"name\":\"H. Zhao\"},{\"authorId\":\"2724870\",\"name\":\"Shaoyuan Sun\"}],\"doi\":\"10.1007/S13042-018-0891-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6cd9cc99fb68c2ba488a46890e23ce758e72deca\",\"title\":\"Depth estimation from infrared video using local-feature-flow neural network\",\"url\":\"https://www.semanticscholar.org/paper/6cd9cc99fb68c2ba488a46890e23ce758e72deca\",\"venue\":\"Int. J. Mach. Learn. Cybern.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145865760\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3240508.3240527\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"81b3cfd55ca84802cdcc971410e633ed40e04980\",\"title\":\"Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/81b3cfd55ca84802cdcc971410e633ed40e04980\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1604.01729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D16-1204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"title\":\"Improving LSTM-based Video Description with Linguistic Knowledge Mined from Text\",\"url\":\"https://www.semanticscholar.org/paper/d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1804.04340\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1007/978-3-030-01246-5_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32bc9334ad0edaec29540320b9f00c9a7aab81f8\",\"title\":\"Zero-Shot Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/32bc9334ad0edaec29540320b9f00c9a7aab81f8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29072828\",\"name\":\"Seungwhan Moon\"},{\"authorId\":\"143712374\",\"name\":\"J. Carbonell\"}],\"doi\":\"10.24963/ijcai.2017/349\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d79d02ef34bb579da1b197aca18f7ec495c0aa1\",\"title\":\"Completely Heterogeneous Transfer Learning with Attention - What And What Not To Transfer\",\"url\":\"https://www.semanticscholar.org/paper/0d79d02ef34bb579da1b197aca18f7ec495c0aa1\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34692779\",\"name\":\"K. Chang\"},{\"authorId\":\"10421443\",\"name\":\"Kung-Hung Lu\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"}],\"doi\":\"10.1109/ICCV.2017.380\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"title\":\"Aesthetic Critiques Generation for Photos\",\"url\":\"https://www.semanticscholar.org/paper/c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"df9a08016fa553a169d893ce2d3fca375bab4781\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df9a08016fa553a169d893ce2d3fca375bab4781\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414749\",\"name\":\"Kun Fu\"},{\"authorId\":\"3068555\",\"name\":\"Jin Li\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/TNNLS.2018.2813306\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"title\":\"Image-Text Surgery: Efficient Concept Learning in Image Captioning by Generating Pseudopairs\",\"url\":\"https://www.semanticscholar.org/paper/f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1608.08305\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a20403b74e8fd1d56233d2f1a3a805410573e0a8\",\"title\":\"Utilizing Large Scale Vision and Text Datasets for Image Segmentation from Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a20403b74e8fd1d56233d2f1a3a805410573e0a8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46996739\",\"name\":\"Shuang Xia\"},{\"authorId\":\"1731914\",\"name\":\"K. Broda\"},{\"authorId\":\"144119475\",\"name\":\"A. Russo\"}],\"doi\":\"10.29007/wscr\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"271e77515cb082e6e15bd2c89b8943e1af4b86ba\",\"title\":\"Topical Neural Theorem Prover that Induces Rules\",\"url\":\"https://www.semanticscholar.org/paper/271e77515cb082e6e15bd2c89b8943e1af4b86ba\",\"venue\":\"GCAI\",\"year\":2020},{\"arxivId\":\"1807.08205\",\"authors\":[{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1726601\",\"name\":\"Rebecca Hwa\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a425e30375e3dd3cb9afed5dc31d2bda8e82384f\",\"title\":\"Equal But Not The Same: Understanding the Implicit Relationship Between Persuasive Images and Text\",\"url\":\"https://www.semanticscholar.org/paper/a425e30375e3dd3cb9afed5dc31d2bda8e82384f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934466\",\"name\":\"Junwei Zhou\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2710247\",\"name\":\"Jizhong Han\"},{\"authorId\":\"144553025\",\"name\":\"S. Hu\"},{\"authorId\":\"2755326\",\"name\":\"Hongchao Gao\"}],\"doi\":\"10.1109/BigMM.2018.8499060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"title\":\"Spatial- Temporal Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15181932\",\"name\":\"Rizal Setya Perdana\"},{\"authorId\":\"15167137\",\"name\":\"Y. Ishida\"}],\"doi\":\"10.1109/ELECSYM.2019.8901660\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"348a908617ff00c09c4d4456268da7bb60435441\",\"title\":\"Instance-based Deep Transfer Learning on Cross-domain Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/348a908617ff00c09c4d4456268da7bb60435441\",\"venue\":\"2019 International Electronics Symposium (IES)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46268303\",\"name\":\"Zhongqi Lin\"},{\"authorId\":\"52201264\",\"name\":\"Jingdun Jia\"},{\"authorId\":\"3302605\",\"name\":\"Wanlin Gao\"},{\"authorId\":\"152758739\",\"name\":\"F. Huang\"}],\"doi\":\"10.1109/ACCESS.2019.2938537\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7c9f62bee0ff3c87a6bed15f35d5be232c92eee\",\"title\":\"Increasingly Specialized Perception Network for Fine-Grained Visual Categorization of Butterfly Specimens\",\"url\":\"https://www.semanticscholar.org/paper/d7c9f62bee0ff3c87a6bed15f35d5be232c92eee\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1016/j.jvcir.2018.12.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58323b889d916403c6674eb3112370a13bd63fe9\",\"title\":\"Scene graph captioner: Image captioning based on structural visual representation\",\"url\":\"https://www.semanticscholar.org/paper/58323b889d916403c6674eb3112370a13bd63fe9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"WU Gao-Chang\"},{\"authorId\":\"48090634\",\"name\":\"Liu Qiang\"},{\"authorId\":null,\"name\":\"CHAI Tian-You\"},{\"authorId\":null,\"name\":\"QIN S. Joe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3016116d10f5f4a46354b0a0250a9cd626e7e12f\",\"title\":\"Abnormal Condition Diagnosis Through Deep Learning of Image Sequences for Fused Magnesium Furnaces\",\"url\":\"https://www.semanticscholar.org/paper/3016116d10f5f4a46354b0a0250a9cd626e7e12f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.06904\",\"authors\":[{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"9563639\",\"name\":\"Mengqing Jiang\"},{\"authorId\":null,\"name\":\"Chen Qian\"},{\"authorId\":\"1692609\",\"name\":\"S. Yang\"},{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"1720776\",\"name\":\"H. Zhang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2017.683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77d30cf9a34fb6b50979c6a68863099da9a060ad\",\"title\":\"Residual Attention Network for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/77d30cf9a34fb6b50979c6a68863099da9a060ad\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1901.10042\",\"authors\":[{\"authorId\":\"50020453\",\"name\":\"Shipeng Xie\"},{\"authorId\":\"144395119\",\"name\":\"Da Chen\"},{\"authorId\":\"145814758\",\"name\":\"Rong Zhang\"},{\"authorId\":\"143962062\",\"name\":\"Hui Xue\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5802caf10ad60d2a7da086d14337c215408a9b8e\",\"title\":\"Deep Features Analysis with Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/5802caf10ad60d2a7da086d14337c215408a9b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.11117\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b73ff5846772da8575262925aa7709b5e64079a0\",\"title\":\"Learning Visual Actions Using Multiple Verb-Only Labels\",\"url\":\"https://www.semanticscholar.org/paper/b73ff5846772da8575262925aa7709b5e64079a0\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66511580\",\"name\":\"Mirza Muhammad Ali Baig\"},{\"authorId\":\"67307335\",\"name\":\"Mian Ihtisham Shah\"},{\"authorId\":\"9223428\",\"name\":\"Muhammad Abdullah Wajahat\"},{\"authorId\":\"2384836\",\"name\":\"Nauman Zafar\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/DICTA.2018.8615810\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"title\":\"Image Caption Generator with Novel Object Injection\",\"url\":\"https://www.semanticscholar.org/paper/d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.06954\",\"authors\":[{\"authorId\":\"35885339\",\"name\":\"M. C. Iordan\"},{\"authorId\":\"148197927\",\"name\":\"Tyler Giallanza\"},{\"authorId\":\"113057216\",\"name\":\"C. T. Ellis\"},{\"authorId\":\"20966285\",\"name\":\"Nicole M. Beckage\"},{\"authorId\":\"144872055\",\"name\":\"J. Cohen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e9111d689af577433af9f8078fb847c730ddd6d\",\"title\":\"Context Matters: Recovering Human Semantic Structure from Machine Learning Analysis of Large-Scale Text Corpora\",\"url\":\"https://www.semanticscholar.org/paper/7e9111d689af577433af9f8078fb847c730ddd6d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1606.07770\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.130\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"title\":\"Captioning Images with Diverse Objects\",\"url\":\"https://www.semanticscholar.org/paper/b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"title\":\"Generalization to new compositions of known entities in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"}],\"doi\":\"10.1007/978-981-10-7299-4_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"title\":\"Automatic Image Description Generation with Emotional Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.10854\",\"authors\":[{\"authorId\":\"51151229\",\"name\":\"Daniel W. Otter\"},{\"authorId\":\"51149804\",\"name\":\"J. R. Medina\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/tnnls.2020.2979670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"title\":\"A Survey of the Usages of Deep Learning in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1710.06303\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2168767\",\"name\":\"Umanga Bista\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1748257\",\"name\":\"Achim Rettinger\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"631a1571d1a073369ec7c98e196de07e263ae130\",\"title\":\"Describing Natural Images Containing Novel Objects with Knowledge Guided Assitance\",\"url\":\"https://www.semanticscholar.org/paper/631a1571d1a073369ec7c98e196de07e263ae130\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.09472\",\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2017.554\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"title\":\"Weakly-Supervised Learning of Visual Relations\",\"url\":\"https://www.semanticscholar.org/paper/5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1901.01216\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"59d1603327fe00989f73d8b3316157903c34b020\",\"title\":\"Transfer learning from language models to image caption generators: Better models may not transfer better\",\"url\":\"https://www.semanticscholar.org/paper/59d1603327fe00989f73d8b3316157903c34b020\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.00576\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/D17-1098\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"title\":\"Guided Open Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1806.06198\",\"authors\":[{\"authorId\":\"49890262\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"2061510\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TMM.2019.2939747\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faf4d0e92691c94faeaa88d58849d5673221a532\",\"title\":\"Part-Aware Fine-Grained Object Categorization Using Weakly Supervised Part Detection Network\",\"url\":\"https://www.semanticscholar.org/paper/faf4d0e92691c94faeaa88d58849d5673221a532\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145269477\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1492126621\",\"name\":\"Y. Rao\"},{\"authorId\":\"49279687\",\"name\":\"Lianwei Wu\"},{\"authorId\":\"1978658363\",\"name\":\"Cong Feng\"}],\"doi\":\"10.1007/978-3-030-63823-8_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b686455c59af63ccd45b73b5445465bbd282bfd\",\"title\":\"Image Captioning Algorithm Based on Sufficient Visual Information and Text Information\",\"url\":\"https://www.semanticscholar.org/paper/0b686455c59af63ccd45b73b5445465bbd282bfd\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1806.06193\",\"authors\":[{\"authorId\":\"50355189\",\"name\":\"Yin Cui\"},{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144692242\",\"name\":\"A. Howard\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89c3355f5bc7130ae4ed090c8accc52dd885d558\",\"title\":\"Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/89c3355f5bc7130ae4ed090c8accc52dd885d558\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f22058a3003cee6b17c6c25c8a635a653e78614c\",\"title\":\"Multimodal Attention in Recurrent Neural Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f22058a3003cee6b17c6c25c8a635a653e78614c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"}],\"doi\":\"10.15781/T2QR4P68H\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"title\":\"Natural Language Video Description using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"145819866\",\"name\":\"J. Liang\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1016/j.neucom.2018.03.078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"title\":\"Image captioning by incorporating affective concepts learned from both visual and textual components\",\"url\":\"https://www.semanticscholar.org/paper/adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49035023\",\"name\":\"T. Nguyen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"title\":\"Automatic Video Captioning using Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1704.03944\",\"authors\":[{\"authorId\":\"145489055\",\"name\":\"Y. Zhang\"},{\"authorId\":\"27257564\",\"name\":\"Luyao Yuan\"},{\"authorId\":\"1857914\",\"name\":\"Yijie Guo\"},{\"authorId\":\"1755497\",\"name\":\"Zhiyuan He\"},{\"authorId\":\"38648777\",\"name\":\"Ian Huang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/CVPR.2017.122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"title\":\"Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"144934447\",\"name\":\"M. Dom\\u00ednguez\"},{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/CVPRW.2017.274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477d58ad32e0e54c40da135fb8db28b23ad0ffd0\",\"title\":\"Temporally Steered Gaussian Attention for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/477d58ad32e0e54c40da135fb8db28b23ad0ffd0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0bd9f4f10d47b82261410a39c8646fe354e9392\",\"title\":\"Captioning Images with Diverse Objects Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/a0bd9f4f10d47b82261410a39c8646fe354e9392\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"28331771\",\"name\":\"Heliang Zheng\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0ac9d4b0b02f6eb3a5188624e87e63e5eae6709\",\"title\":\"Look Closer to See Better: Recurrent Attention Convolutional Neural Network for Fine-Grained Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a0ac9d4b0b02f6eb3a5188624e87e63e5eae6709\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1806.00523\",\"authors\":[{\"authorId\":\"31352445\",\"name\":\"Kashyap Chitta\"}],\"doi\":\"10.1007/978-3-030-11018-5_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"title\":\"Targeted Kernel Networks: Faster Convolutions with Attentive Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1801.10300\",\"authors\":[{\"authorId\":\"48149965\",\"name\":\"W. Lin\"},{\"authorId\":\"143672077\",\"name\":\"K. Chen\"},{\"authorId\":\"29837150\",\"name\":\"HungYueh Chiang\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1145/3184558.3186354\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e1b3cf334aead8d2c29747f6ee7d1291dd83708\",\"title\":\"Netizen-Style Commenting on Fashion Photos: Dataset and Diversity Measures\",\"url\":\"https://www.semanticscholar.org/paper/9e1b3cf334aead8d2c29747f6ee7d1291dd83708\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"1703.09902\",\"authors\":[{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":\"10.1613/jair.5477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d13bb317e87f3f6da10da11059ebf4350b754814\",\"title\":\"Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d13bb317e87f3f6da10da11059ebf4350b754814\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346355\",\"name\":\"Ashish Bora\"},{\"authorId\":\"50292393\",\"name\":\"A. Sinha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddbfea5302fcb5cbc2ca4c498a592ddb063b9eff\",\"title\":\"L OW SUPERVISION VISUAL LEARNING THROUGH COOPERATIVE AGENTS\",\"url\":\"https://www.semanticscholar.org/paper/ddbfea5302fcb5cbc2ca4c498a592ddb063b9eff\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3212585\",\"name\":\"Huda Almuzaini\"},{\"authorId\":\"1406444047\",\"name\":\"T. N. Al-Yahya\"},{\"authorId\":\"90527313\",\"name\":\"Hafida Benhidour\"}],\"doi\":\"10.14569/IJACSA.2018.090610\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"1e0a5ce5204f3f7503c39df6d200627cc331efe2\",\"title\":\"Automatic Arabic Image Captioning using RNN-LSTM-Based Language Model and CNN\",\"url\":\"https://www.semanticscholar.org/paper/1e0a5ce5204f3f7503c39df6d200627cc331efe2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"46911598\",\"name\":\"Lin Zuo\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2020.2967597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"title\":\"Cross-Modal Attention With Semantic Consistence for Image\\u2013Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1811.10787\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"40474876\",\"name\":\"Wei Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"580fd9a601314ea32dc85ec98267b411dd3465cf\",\"title\":\"Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/580fd9a601314ea32dc85ec98267b411dd3465cf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.09788\",\"authors\":[{\"authorId\":\"1387971311\",\"name\":\"Somaye Jafaritazehjani\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"}],\"doi\":\"10.18653/v1/W19-8625\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fca889a5d95fa2df47edbfd65f886f8bf4856fe\",\"title\":\"Visuallly Grounded Generation of Entailments from Premises\",\"url\":\"https://www.semanticscholar.org/paper/6fca889a5d95fa2df47edbfd65f886f8bf4856fe\",\"venue\":\"INLG\",\"year\":2019},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113519586\",\"name\":\"T. X. Dang\"},{\"authorId\":\"31704596\",\"name\":\"A. Oh\"},{\"authorId\":\"9483271\",\"name\":\"In-Seop Na\"},{\"authorId\":\"2183069\",\"name\":\"S. Kim\"}],\"doi\":\"10.1145/3310986.3311002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"title\":\"The Role of Attention Mechanism and Multi-Feature in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"venue\":\"ICMLSC 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1856671082\",\"name\":\"Shengjia Chen\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1145/3340531.3411948\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3428bac9141f6db961fc4665db1cbc9a196152da\",\"title\":\"Image Captioning with Internal and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3428bac9141f6db961fc4665db1cbc9a196152da\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1704.03895\",\"authors\":[{\"authorId\":\"10730666\",\"name\":\"Siddha Ganju\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"title\":\"What's in a Question: Using Visual Questions as a Form of Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7051c20ffa6dacafb7ab96bc4ac80bda9603723f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ming Jiang\"},{\"authorId\":null,\"name\":\"Qi Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3977c0056755c2911811509ac38e0cef532004b0\",\"title\":\"Self-Distillation for Few-Shot Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3977c0056755c2911811509ac38e0cef532004b0\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48496963\",\"name\":\"F. Ahmed\"},{\"authorId\":null,\"name\":\"Md Sultan Mahmud\"},{\"authorId\":\"1828610\",\"name\":\"M. Yeasin\"}],\"doi\":\"10.1109/ICECE.2018.8636726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db30478abbb3875ba474994d0cb1fb10e3ffb099\",\"title\":\"Words to Meaningful Sentence: Analytics through Game Interface\",\"url\":\"https://www.semanticscholar.org/paper/db30478abbb3875ba474994d0cb1fb10e3ffb099\",\"venue\":\"2018 10th International Conference on Electrical and Computer Engineering (ICECE)\",\"year\":2018},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1608.07068\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-46475-6_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"title\":\"Title Generation for User Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144792753\",\"name\":\"Y. Qin\"},{\"authorId\":\"151046769\",\"name\":\"Jiajun Du\"},{\"authorId\":\"48379418\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00856\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c0ac3bb66203c32be81193fabeee44c3585582\",\"title\":\"Look Back and Predict Forward in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0c0ac3bb66203c32be81193fabeee44c3585582\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1708.02043\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.18653/v1/W17-3506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"title\":\"What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?\",\"url\":\"https://www.semanticscholar.org/paper/3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684133\",\"name\":\"Michael Skirpan\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1109/CVPRW.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f326914393ccc573521db6d1942c81e7f45d18b7\",\"title\":\"Designing a Moral Compass for the Future of Computer Vision Using Speculative Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f326914393ccc573521db6d1942c81e7f45d18b7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.08658\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"46395829\",\"name\":\"Yufei Wang\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607624548\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.1109/ICCV.2019.00904\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"title\":\"nocaps: novel object captioning at scale\",\"url\":\"https://www.semanticscholar.org/paper/8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.12633\",\"authors\":[{\"authorId\":\"24339915\",\"name\":\"Davis Gilton\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"145952380\",\"name\":\"R. Willett\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"title\":\"Detection and Description of Change in Visual Streams\",\"url\":\"https://www.semanticscholar.org/paper/dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.06004\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ceabd7ff28ce2d501511da998252aeb938adc98b\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ceabd7ff28ce2d501511da998252aeb938adc98b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2010.03071\",\"authors\":[{\"authorId\":\"1780786109\",\"name\":\"Ashiq Imran\"},{\"authorId\":\"1720747\",\"name\":\"V. Athitsos\"}],\"doi\":\"10.1007/978-3-030-64559-5_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0db9cd6929c9c4a0e7f89f3251ab288861c5e5b3\",\"title\":\"Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-grained Visual Categorization\",\"url\":\"https://www.semanticscholar.org/paper/0db9cd6929c9c4a0e7f89f3251ab288861c5e5b3\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724902\",\"name\":\"M. Yang\"},{\"authorId\":null,\"name\":\"Wei Zhao\"},{\"authorId\":\"145738414\",\"name\":\"Wei Xu\"},{\"authorId\":\"28106616\",\"name\":\"Yabing Feng\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"1784737\",\"name\":\"K. Lei\"}],\"doi\":\"10.1109/TMM.2018.2869276\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaa5625e0dbd9119b54dbb9c3840efd1199a071f\",\"title\":\"Multitask Learning for Cross-Domain Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaa5625e0dbd9119b54dbb9c3840efd1199a071f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"2009.13682\",\"authors\":[{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f147279c9d1edddda57f1f21f23b3b58998bad74\",\"title\":\"VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/f147279c9d1edddda57f1f21f23b3b58998bad74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1611.06949\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"title\":\"Dense Captioning with Joint Inference and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"28106616\",\"name\":\"Yabing Feng\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1145/3132847.3132920\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3844a6cef7960729125722e2d07024058dd9204a\",\"title\":\"Dual Learning for Cross-domain Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3844a6cef7960729125722e2d07024058dd9204a\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":\"1908.11310\",\"authors\":[{\"authorId\":\"19444389\",\"name\":\"Koustav Ghosal\"},{\"authorId\":\"36809068\",\"name\":\"Aakanksha Rana\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d204156022f65e34706d4211e05bcb578940939\",\"title\":\"Aesthetic Image Captioning From Weakly-Labelled Photographs\",\"url\":\"https://www.semanticscholar.org/paper/5d204156022f65e34706d4211e05bcb578940939\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1007/978-3-030-11479-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"title\":\"Deep Learning for Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"venue\":\"Handbook of Deep Learning Applications\",\"year\":2019},{\"arxivId\":\"1809.02156\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"40895688\",\"name\":\"Kaylee Burns\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D18-1437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4921243268c81d0d6db99053a9d004852225a622\",\"title\":\"Object Hallucination in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4921243268c81d0d6db99053a9d004852225a622\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1704.00248\",\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\"},{\"authorId\":\"5611651\",\"name\":\"J. Liu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/CVPR.2017.84\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d646c9707686def885557c0aad1fc160b80d5d5\",\"title\":\"A-Lamp: Adaptive Layout-Aware Multi-patch Deep Convolutional Neural Network for Photo Aesthetic Assessment\",\"url\":\"https://www.semanticscholar.org/paper/2d646c9707686def885557c0aad1fc160b80d5d5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10224549\",\"name\":\"S. Rogers\"},{\"authorId\":\"37987195\",\"name\":\"J. Culbertson\"},{\"authorId\":\"1693682\",\"name\":\"M. Oxley\"},{\"authorId\":\"1822631\",\"name\":\"H. S. Clouse\"},{\"authorId\":\"26414124\",\"name\":\"Bernard Abayowa\"},{\"authorId\":\"49947334\",\"name\":\"J. Patrick\"},{\"authorId\":\"70491647\",\"name\":\"Erik P. Blasch\"},{\"authorId\":\"102599796\",\"name\":\"John Trumpfheller\"}],\"doi\":\"10.1117/12.2229722\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dc8139071d537282f0df280450f998c6c8ab723\",\"title\":\"The QuEST for multi-sensor big data ISR situation understanding\",\"url\":\"https://www.semanticscholar.org/paper/0dc8139071d537282f0df280450f998c6c8ab723\",\"venue\":\"SPIE Defense + Security\",\"year\":2016},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.07662\",\"authors\":[{\"authorId\":\"47833739\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2112160\",\"name\":\"Y. Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00859\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"23e943809c131c50dc90c1d308373febc60b9029\",\"title\":\"Intention Oriented Image Captions With Guiding Objects\",\"url\":\"https://www.semanticscholar.org/paper/23e943809c131c50dc90c1d308373febc60b9029\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1007/978-3-030-58526-6_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"007ca8ca7a68451c32da034c72a06238434843c1\",\"title\":\"Learning to Learn Words from Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/007ca8ca7a68451c32da034c72a06238434843c1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1604.03249\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-319-50077-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"title\":\"Attributes as Semantic Units between Natural Language and Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2009.12524\",\"authors\":[{\"authorId\":\"1972263989\",\"name\":\"Zanyar Zohourianshahzadi\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/HCCAI49649.2020.00009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d3cf77a7eb87bf9c85c4631b196c4eb10ff5b51e\",\"title\":\"Neural Twins Talk\",\"url\":\"https://www.semanticscholar.org/paper/d3cf77a7eb87bf9c85c4631b196c4eb10ff5b51e\",\"venue\":\"2020 IEEE International Conference on Humanized Computing and Communication with Artificial Intelligence (HCCAI)\",\"year\":2020},{\"arxivId\":\"1611.05321\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cc23e554d98522b377d227dc78e9382a0ed35e5\",\"title\":\"Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8cc23e554d98522b377d227dc78e9382a0ed35e5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738607561\",\"name\":\"S. Nikiforova\"},{\"authorId\":\"2398266\",\"name\":\"Tejaswini Deoskar\"},{\"authorId\":\"2129425\",\"name\":\"D. Paperno\"},{\"authorId\":\"2021738\",\"name\":\"Y. Winter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"569459a9b1ca74bbf4b74908c30dc583d78b59ab\",\"title\":\"Geo-Aware Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/569459a9b1ca74bbf4b74908c30dc583d78b59ab\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752475\",\"name\":\"Erik Blasch\"},{\"authorId\":\"145502309\",\"name\":\"Alex Aved\"}],\"doi\":\"10.23919/ICIF.2018.8455599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"679bbf2497f625091c44bd3855172b4c10577c04\",\"title\":\"Physics-Based and Human-Derived Information Fusion Video Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/679bbf2497f625091c44bd3855172b4c10577c04\",\"venue\":\"2018 21st International Conference on Information Fusion (FUSION)\",\"year\":2018}],\"corpusId\":6918332,\"doi\":\"10.1109/CVPR.2016.8\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":28,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753110\",\"name\":\"M. Huiskes\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1145/1460096.1460104\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f79131806747fce087d0fe73d0867cc621547b2a\",\"title\":\"The MIR flickr retrieval evaluation\",\"url\":\"https://www.semanticscholar.org/paper/f79131806747fce087d0fe73d0867cc621547b2a\",\"venue\":\"MIR '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf60322f83714523e2d7c1d39983151fe9db7146\",\"title\":\"Collecting Image Annotations Using Amazon's Mechanical Turk\",\"url\":\"https://www.semanticscholar.org/paper/bf60322f83714523e2d7c1d39983151fe9db7146\",\"venue\":\"Mturk@HLT-NAACL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2577358\",\"name\":\"P. Srinivasan\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2009.5206492\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3743f425faf5cae6fb1e55a864e8361027fff6c\",\"title\":\"Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos\",\"url\":\"https://www.semanticscholar.org/paper/f3743f425faf5cae6fb1e55a864e8361027fff6c\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2013.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6a7a563640bf53953c4fda0997e4db176488510\",\"title\":\"YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6a7a563640bf53953c4fda0997e4db176488510\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"},{\"authorId\":\"1748758\",\"name\":\"H. Nickisch\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/TPAMI.2013.140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bc0295460089592d04e754a5fd427060b7bfa8c\",\"title\":\"Attribute-Based Classification for Zero-Shot Visual Object Categorization\",\"url\":\"https://www.semanticscholar.org/paper/9bc0295460089592d04e754a5fd427060b7bfa8c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":\"1504.06692\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"144287022\",\"name\":\"Xu Wei\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"152924551\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.291\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb847564774394c484e701437dbcffbf040ff3cc\",\"title\":\"Learning Like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images\",\"url\":\"https://www.semanticscholar.org/paper/eb847564774394c484e701437dbcffbf040ff3cc\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"title\":\"Generating Natural-Language Video Descriptions Using Text-Mined Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Malkarnenkar\"},{\"authorId\":null,\"name\":\"S. Venugopalan\"},{\"authorId\":null,\"name\":\"R. Mooney\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Devise : A deep visualsemantic embedding model\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Young Rashtchian\"},{\"authorId\":null,\"name\":\"M. Hodosh\"},{\"authorId\":null,\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Parikh and K . Grauman . Relative attributes\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Guptal\"},{\"authorId\":null,\"name\":\"P. Srinivasan\"},{\"authorId\":null,\"name\":\"J. Shi\"},{\"authorId\":null,\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Understanding videos\",\"url\":\"\",\"venue\":\"constructing plots learning a visually grounded storyline model from annotated videos. In CVPR\",\"year\":2009},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":\"1506.01698\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-24947-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"title\":\"The Long-Short Story of Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"venue\":\"GCPR\",\"year\":2015},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1301.3666\",\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2012435\",\"name\":\"M. Ganjoo\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"755e9f43ce398ae8737366720c5f82685b0c253e\",\"title\":\"Zero-Shot Learning Through Cross-Modal Transfer\",\"url\":\"https://www.semanticscholar.org/paper/755e9f43ce398ae8737366720c5f82685b0c253e\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20ab42c9b93b6e41f6e1d7b546f87c5a871db020\",\"title\":\"Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/20ab42c9b93b6e41f6e1d7b546f87c5a871db020\",\"venue\":\"COLING\",\"year\":2014},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Venugopalan\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Devise : A deep visualsemantic embedding model\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2011.6126281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23e568fcf0192e4ff5e6bed7507ee5b9e6c43598\",\"title\":\"Relative attributes\",\"url\":\"https://www.semanticscholar.org/paper/23e568fcf0192e4ff5e6bed7507ee5b9e6c43598\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":\"10.3115/1073445.1073478\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42a490cf4f186d3383c92963817d100afd81e2\",\"title\":\"Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network\",\"url\":\"https://www.semanticscholar.org/paper/eb42a490cf4f186d3383c92963817d100afd81e2\",\"venue\":\"HLT-NAACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"205e895e03969c96f3c482b0bd26308b16a12bd0\",\"title\":\"Image Captioning with an Intermediate Attributes Layer\",\"url\":\"https://www.semanticscholar.org/paper/205e895e03969c96f3c482b0bd26308b16a12bd0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Deng\"},{\"authorId\":null,\"name\":\"A. Berg\"},{\"authorId\":null,\"name\":\"K. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"Fei-Fei. What does classifying more than 10,000 image categories tell us? In ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"145561632\",\"name\":\"Adrian Popescu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c991c68eb9171a373e861a37e9e2a1889bcb3da\",\"title\":\"Overview of the ImageCLEF 2012 Flickr Photo Annotation and Retrieval Task\",\"url\":\"https://www.semanticscholar.org/paper/1c991c68eb9171a373e861a37e9e2a1889bcb3da\",\"venue\":\"CLEF\",\"year\":2012},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2577358\",\"name\":\"P. Srinivasan\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/cvprw.2009.5206492\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49927656ede0c75af22ca73dcf4abba028839650\",\"title\":\"Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos\",\"url\":\"https://www.semanticscholar.org/paper/49927656ede0c75af22ca73dcf4abba028839650\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1407.5035\",\"authors\":[{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40eac6e6bb54e0da7885989f220f4d3f70249950\",\"title\":\"LSDA: Large Scale Detection through Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/40eac6e6bb54e0da7885989f220f4d3f70249950\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32375492\",\"name\":\"Jia Deng\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15555-0_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9800e3c3394c569be83379ee2ebe3424e09c2919\",\"title\":\"What Does Classifying More Than 10, 000 Image Categories Tell Us?\",\"url\":\"https://www.semanticscholar.org/paper/9800e3c3394c569be83379ee2ebe3424e09c2919\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144421225\",\"name\":\"M. Stark\"},{\"authorId\":\"3081065\",\"name\":\"Gy\\u00f6rgy Szarvas\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2010.5540121\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a4b5ae5793696b861aa009932e7a121d36ad67a\",\"title\":\"What helps where \\u2013 and why? Semantic relatedness for knowledge transfer\",\"url\":\"https://www.semanticscholar.org/paper/4a4b5ae5793696b861aa009932e7a121d36ad67a\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"the FITweltweit-Program of the German Academic Exchange Service (DAAD) This work was supported by DARPA, AFRL, DoD MURI award N000141110688, NSF awards IIS-1427425 and IIS-1212798\",\"url\":\"\",\"venue\":\"the FITweltweit-Program of the German Academic Exchange Service (DAAD) This work was supported by DARPA, AFRL, DoD MURI award N000141110688, NSF awards IIS-1427425 and IIS-1212798\",\"year\":null}],\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"topics\":[{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Outline of object recognition\",\"topicId\":\"34569\",\"url\":\"https://www.semanticscholar.org/topic/34569\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Vocabulary\",\"topicId\":\"14901\",\"url\":\"https://www.semanticscholar.org/topic/14901\"},{\"topic\":\"KDE Applications\",\"topicId\":\"566427\",\"url\":\"https://www.semanticscholar.org/topic/566427\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"