"{\"abstract\":\"Recent applications of Convolutional Neural Networks (ConvNets) for human action recognition in videos have proposed different solutions for incorporating the appearance and motion information. We study a number of ways of fusing ConvNet towers both spatially and temporally in order to best take advantage of this spatio-temporal information. We make the following findings: (i) that rather than fusing at the softmax layer, a spatial and temporal network can be fused at a convolution layer without loss of performance, but with a substantial saving in parameters, (ii) that it is better to fuse such networks spatially at the last convolutional layer than earlier, and that additionally fusing at the class prediction layer can boost accuracy, finally (iii) that pooling of abstract convolutional features over spatiotemporal neighbourhoods further boosts performance. Based on these studies we propose a new ConvNet architecture for spatiotemporal fusion of video snippets, and evaluate its performance on standard benchmarks where this architecture achieves state-of-the-art results.\",\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\",\"url\":\"https://www.semanticscholar.org/author/2322150\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\",\"url\":\"https://www.semanticscholar.org/author/1718587\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\",\"url\":\"https://www.semanticscholar.org/author/1688869\"}],\"citationVelocity\":407,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31802065\",\"name\":\"Zhaoxuan Fan\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"47896893\",\"name\":\"W. Jiang\"},{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-319-71607-7_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0471a93e6bf5435fad106da97fcbbed7dbab4006\",\"title\":\"An Online Approach for Gesture Recognition Toward Real-World Applications\",\"url\":\"https://www.semanticscholar.org/paper/0471a93e6bf5435fad106da97fcbbed7dbab4006\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"1706028\",\"name\":\"L. Yang\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"2864709\",\"name\":\"F. Chao\"},{\"authorId\":\"48968697\",\"name\":\"R. Song\"},{\"authorId\":\"31851271\",\"name\":\"YanPeng Qu\"}],\"doi\":\"10.1109/TII.2019.2957268\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3bbe379ef5f12cab36ba86d93ec40b1fbe133b7\",\"title\":\"Histogram of Fuzzy Local Spatio-Temporal Descriptors for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3bbe379ef5f12cab36ba86d93ec40b1fbe133b7\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7967365\",\"name\":\"Sijia Tian\"}],\"doi\":\"10.14288/1.0375801\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74e620b52f0bb8d9d39871cbb05cc065c58184f4\",\"title\":\"Group event recognition in ice hockey\",\"url\":\"https://www.semanticscholar.org/paper/74e620b52f0bb8d9d39871cbb05cc065c58184f4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"title\":\"Multi-Level ResNets with Stacked SRUs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145366409\",\"name\":\"F. Ren\"},{\"authorId\":\"12053700\",\"name\":\"J. Deng\"}],\"doi\":\"10.3390/APP8122472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df422d9f28e73975096335014e258bb3872c7a23\",\"title\":\"Background Knowledge Based Multi-Stream Neural Network for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/df422d9f28e73975096335014e258bb3872c7a23\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97232650\",\"name\":\"W. Dai\"},{\"authorId\":\"50579817\",\"name\":\"Yi-min Chen\"},{\"authorId\":\"73067906\",\"name\":\"C. Huang\"},{\"authorId\":\"71543140\",\"name\":\"Mingke Gao\"},{\"authorId\":\"50812964\",\"name\":\"Xinyu Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851702\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"414e4a17e5b661c36e20937223bbe312ed227efc\",\"title\":\"Two-Stream Convolution Neural Network with Video-stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/414e4a17e5b661c36e20937223bbe312ed227efc\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48386255\",\"name\":\"Yun Han\"},{\"authorId\":\"36479497\",\"name\":\"Sheng-Luen Chung\"},{\"authorId\":\"50358287\",\"name\":\"Sheng-Fang Chen\"},{\"authorId\":\"145434054\",\"name\":\"S. Su\"}],\"doi\":\"10.1109/SMC.2018.00600\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b592c33d70c35a709956df767ec8fa63a9cf3ec\",\"title\":\"Two-Stream LSTM for Action Recognition with RGB-D-Based Hand-Crafted Features and Feature Combination\",\"url\":\"https://www.semanticscholar.org/paper/6b592c33d70c35a709956df767ec8fa63a9cf3ec\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2596486\",\"name\":\"Zhijian Hou\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec28b73028e7651894323e33409b82d235d2be39\",\"title\":\"VireoJD-MM @ TRECVid 2019: Activities in Extended Video (ActEV)\",\"url\":\"https://www.semanticscholar.org/paper/ec28b73028e7651894323e33409b82d235d2be39\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2020.2984904\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"title\":\"STA-CNN: Convolutional Spatial-Temporal Attention Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134649559\",\"name\":\"R. Kiziltepe\"},{\"authorId\":\"3000774\",\"name\":\"J. Gan\"},{\"authorId\":\"3361843\",\"name\":\"J. J. Escobar\"}],\"doi\":\"10.1007/978-3-030-20518-8_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9a51bfd7be0aeb061f318c3d9201e07aa8c7d6\",\"title\":\"Combining Very Deep Convolutional Neural Networks and Recurrent Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/bb9a51bfd7be0aeb061f318c3d9201e07aa8c7d6\",\"venue\":\"IWANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"439668462b3630ba6c43aec8a24a53ea8a316491\",\"title\":\"Domain learning joint with semantic adaptation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/439668462b3630ba6c43aec8a24a53ea8a316491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49741227\",\"name\":\"Haifeng Sang\"},{\"authorId\":\"152254334\",\"name\":\"Z. Zhao\"},{\"authorId\":\"3030181\",\"name\":\"Dakuo He\"}],\"doi\":\"10.1109/ACCESS.2019.2936628\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"title\":\"Two-Level Attention Model Based Video Action Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2008.11833\",\"authors\":[{\"authorId\":\"7582228\",\"name\":\"Francisco J Luongo\"},{\"authorId\":\"1572018514\",\"name\":\"Ryan Hakim\"},{\"authorId\":\"50004324\",\"name\":\"J. Nguyen\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"},{\"authorId\":\"1739831\",\"name\":\"A. Hung\"}],\"doi\":\"10.1016/j.surg.2020.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac3a69722b1d261fc50c8b4de046d0f501caf74\",\"title\":\"Deep learning-based computer vision to recognize and classify suturing gestures in robot-assisted surgery\",\"url\":\"https://www.semanticscholar.org/paper/6ac3a69722b1d261fc50c8b4de046d0f501caf74\",\"venue\":\"Surgery\",\"year\":2020},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"1840183\",\"name\":\"H. Liu\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/TMM.2018.2889563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f96ffd8c71b97e46eb3ba48263c9012d197494d4\",\"title\":\"A Deep Neural Framework for Continuous Sign Language Recognition by Iterative Training\",\"url\":\"https://www.semanticscholar.org/paper/f96ffd8c71b97e46eb3ba48263c9012d197494d4\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2017.176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"title\":\"Modeling Sub-Event Dynamics in First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f7b2087dd0784a04ba4d2a68c2db9588f36c33a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2149370\",\"name\":\"H. M. Peixoto\"},{\"authorId\":\"1411530409\",\"name\":\"Richardson Santiago Teles de Menezes\"},{\"authorId\":\"1413800477\",\"name\":\"John Victor Alves Luiz\"},{\"authorId\":\"1414715452\",\"name\":\"A. M. Henriques-Alves\"},{\"authorId\":\"145266107\",\"name\":\"R. Cruz\"}],\"doi\":\"10.7287/PEERJ.PREPRINTS.27880V1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc6c8777a985d5642cd5d916b3aa7ec2a84b09a1\",\"title\":\"Mice tracking using the YOLO algorithm\",\"url\":\"https://www.semanticscholar.org/paper/bc6c8777a985d5642cd5d916b3aa7ec2a84b09a1\",\"venue\":\"PeerJ Prepr.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3007561\",\"name\":\"Yinghui Kong\"},{\"authorId\":\"47681511\",\"name\":\"L. Li\"},{\"authorId\":\"46459368\",\"name\":\"Ke Zhang\"},{\"authorId\":\"143710669\",\"name\":\"Qiang Ni\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1117/1.JEI.28.4.043032\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cefcbafc3484c05a0d1d48fe7588f7af3ae8c37\",\"title\":\"Attention module-based spatial\\u2013temporal graph convolutional networks for skeleton-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cefcbafc3484c05a0d1d48fe7588f7af3ae8c37\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"2003.03030\",\"authors\":[{\"authorId\":\"50623801\",\"name\":\"Shihao Zhao\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"145014256\",\"name\":\"Xiang Zheng\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"40663515\",\"name\":\"J. Chen\"},{\"authorId\":\"152163873\",\"name\":\"Yugang Jiang\"}],\"doi\":\"10.1109/cvpr42600.2020.01445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"803f9bf6ab893073c514492a220747aa3d5fbf64\",\"title\":\"Clean-Label Backdoor Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/803f9bf6ab893073c514492a220747aa3d5fbf64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.12295\",\"authors\":[{\"authorId\":\"47244850\",\"name\":\"Rongcheng Lin\"},{\"authorId\":\"46852065\",\"name\":\"J. Xiao\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaca4be112f752d9aa6fa68412a5bb609b1642a0\",\"title\":\"MOD: A Deep Mixture Model with Online Knowledge Distillation for Large Scale Video Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/eaca4be112f752d9aa6fa68412a5bb609b1642a0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14499178\",\"name\":\"H. Chen\"},{\"authorId\":null,\"name\":\"Yunhe Wang\"},{\"authorId\":\"144305248\",\"name\":\"H. Shu\"},{\"authorId\":\"103603255\",\"name\":\"Yehui Tang\"},{\"authorId\":\"1691522\",\"name\":\"Chunjing Xu\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"1517686064\",\"name\":\"Chao Xu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"144962249\",\"name\":\"Chang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3a8c5bf6e2b966f482c11705601da060d8dd361\",\"title\":\"Frequency Domain Compact 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b3a8c5bf6e2b966f482c11705601da060d8dd361\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47039680\",\"name\":\"X. Zhao\"},{\"authorId\":\"145359183\",\"name\":\"Y. Yi\"},{\"authorId\":\"144186239\",\"name\":\"Zemin Qiu\"},{\"authorId\":\"9235546\",\"name\":\"Qingqing Zeng\"}],\"doi\":\"10.1109/ICCCS49078.2020.9118516\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"title\":\"Feature Retrieving for Human Action Recognition by Mixed Scale Deep Feature Combined with Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"venue\":\"2020 5th International Conference on Computer and Communication Systems (ICCCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113316024\",\"name\":\"A. Barbosa\"},{\"authorId\":\"114007357\",\"name\":\"T. Marinho\"},{\"authorId\":\"143609110\",\"name\":\"N. Martin\"},{\"authorId\":\"2130392\",\"name\":\"N. Hovakimyan\"}],\"doi\":\"10.1109/CVPRW50498.2020.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f09c89ebbb82204592ee1d2907bb55a578df327b\",\"title\":\"Multi-Stream CNN for Spatial Resource Allocation: a Crop Management Application\",\"url\":\"https://www.semanticscholar.org/paper/f09c89ebbb82204592ee1d2907bb55a578df327b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"7637298\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2552845\",\"name\":\"Hua-Wei Tu\"},{\"authorId\":\"2493372\",\"name\":\"Chengyong Liu\"}],\"doi\":\"10.1007/s42486-020-00048-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43f89149c6bc337dd6ced5be7639eb7b4cf0b5da\",\"title\":\"Fine-grained hand gesture recognition based on active acoustic signal for VR systems\",\"url\":\"https://www.semanticscholar.org/paper/43f89149c6bc337dd6ced5be7639eb7b4cf0b5da\",\"venue\":\"CCF Trans. Pervasive Comput. Interact.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34862938\",\"name\":\"L. Zhang\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"},{\"authorId\":\"2851775\",\"name\":\"E. Kebebew\"},{\"authorId\":\"150167064\",\"name\":\"Jianhua Yao\"}],\"doi\":\"10.1007/978-3-030-13969-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa8313853a328f258b6719abb423f3361af9abd\",\"title\":\"Tumor Growth Prediction Using Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/4aa8313853a328f258b6719abb423f3361af9abd\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144195544\",\"name\":\"S. Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.1016/J.COMCOM.2019.07.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d10ce66a13a6e2d270329f47aae1761cf4389\",\"title\":\"Crowd Video Event Classification using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/476d10ce66a13a6e2d270329f47aae1761cf4389\",\"venue\":\"Comput. Commun.\",\"year\":2019},{\"arxivId\":\"1905.04430\",\"authors\":[{\"authorId\":\"119352476\",\"name\":\"M. M. K. Moghaddam\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"title\":\"Follow the Attention: Combining Partial Pose and Object Motion for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.00484\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"49915485\",\"name\":\"Andrew Silva\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"title\":\"Action2Vec: A Crossmodal Embedding Approach to Action Learning\",\"url\":\"https://www.semanticscholar.org/paper/797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150177956\",\"name\":\"Kohei Sendo\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.23919/MVA.2019.8757971\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6992ae8a0e3ae00e038936c43cc32ba377df17c\",\"title\":\"Heatmapping of People Involved in Group Activities\",\"url\":\"https://www.semanticscholar.org/paper/b6992ae8a0e3ae00e038936c43cc32ba377df17c\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.3390/drones3040082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5804fb20edd6df75f0d47782ffa1cd4ecf7252f0\",\"title\":\"Drone-Action: An Outdoor Recorded Drone Video Dataset for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5804fb20edd6df75f0d47782ffa1cd4ecf7252f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.02108\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/TPAMI.2018.2889052\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcecc4ef2c32dbedda61648febb39a0f905c367e\",\"title\":\"Deep Audio-Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fcecc4ef2c32dbedda61648febb39a0f905c367e\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2018},{\"arxivId\":\"1708.07632\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICCVW.2017.373\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"title\":\"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2018.8639122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0793b85c46c29387a1cc3ef801dcbc4782126e3\",\"title\":\"Deep-Temporal LSTM for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e0793b85c46c29387a1cc3ef801dcbc4782126e3\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2100218\",\"name\":\"Aytac Cavent\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1049/iet-cvi.2017.0471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e8d33bb52865f2d929836301ba80e326ac282b0\",\"title\":\"Histograms of sequences: a novel representation for human interaction recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e8d33bb52865f2d929836301ba80e326ac282b0\",\"venue\":\"IET Comput. Vis.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81188084\",\"name\":\"Saima Nazir\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"},{\"authorId\":\"145643264\",\"name\":\"E. Izquierdo\"},{\"authorId\":\"30902466\",\"name\":\"Eduard Vazquez\"}],\"doi\":\"10.5220/0007371104200426\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"title\":\"Human Action Recognition using Multi-Kernel Learning for Temporal Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1802.06822\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01219-9_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"title\":\"Online Detection of Action Start in Untrimmed, Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00622\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49236757\",\"name\":\"Yujia Peng\"},{\"authorId\":\"49923416\",\"name\":\"H. Lee\"},{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\"},{\"authorId\":\"3269302\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/j.visres.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31e01954bbdf23acc39d33f72c612e59b2b5e702\",\"title\":\"Exploring biological motion perception in two-stream convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/31e01954bbdf23acc39d33f72c612e59b2b5e702\",\"venue\":\"Vision Research\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.11902\",\"authors\":[{\"authorId\":\"150282338\",\"name\":\"Roshan Prakash Rane\"},{\"authorId\":\"1573750032\",\"name\":\"Edit Szugyi\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"},{\"authorId\":\"2983978\",\"name\":\"S. Stober\"}],\"doi\":\"10.1145/3372278.3390694\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c39ab475793b349809d7af2d5797bc1e77f48d\",\"title\":\"PredNet and Predictive Coding: A Critical Review\",\"url\":\"https://www.semanticscholar.org/paper/48c39ab475793b349809d7af2d5797bc1e77f48d\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/TCDS.2018.2883368\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6335db9f35fe254bd37404bf896be033439fabe\",\"title\":\"Abnormal Event Detection From Videos Using a Two-Stream Recurrent Variational Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/f6335db9f35fe254bd37404bf896be033439fabe\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2020},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153504672\",\"name\":\"Hong Zhang\"},{\"authorId\":\"2000677733\",\"name\":\"Jiexiong Rong\"}],\"doi\":\"10.1007/S11042-020-09564-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe960aebd7429164f20643301456b06fadb89165\",\"title\":\"Enhanced 3D residual network for video event recognition in shipping monitoring\",\"url\":\"https://www.semanticscholar.org/paper/fe960aebd7429164f20643301456b06fadb89165\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153924558\",\"name\":\"Hsing-Yu Chen\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1007/978-3-030-41299-9_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"title\":\"Group Activity Recognition via Computing Human Pose Motion History and Collective Map from Video\",\"url\":\"https://www.semanticscholar.org/paper/aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"}],\"doi\":\"10.32657/10356/70099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"title\":\"Pose-invariant action recognition for automated behaviour analysis\",\"url\":\"https://www.semanticscholar.org/paper/fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arjun Venkat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a6f8acc58a59d5f9c5314792f35c6556f970f7\",\"title\":\"Venkatakrishnan Event Classification from Video Sequence Data\",\"url\":\"https://www.semanticscholar.org/paper/d1a6f8acc58a59d5f9c5314792f35c6556f970f7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.11264\",\"authors\":[{\"authorId\":\"1916516\",\"name\":\"M. Khodabandeh\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"15623770\",\"name\":\"I. Zharkov\"},{\"authorId\":\"3811436\",\"name\":\"V. Pradeep\"}],\"doi\":\"10.1109/CVPRW.2018.00194\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"title\":\"DIY Human Action Dataset Generation\",\"url\":\"https://www.semanticscholar.org/paper/74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K Sivaraman\"},{\"authorId\":null,\"name\":\"Gautam Somappa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"22f94c43dd8b203f073f782d91e701108909690b\",\"title\":\"MovieScope: Movie trailer classification using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/22f94c43dd8b203f073f782d91e701108909690b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"title\":\"RECOGNITIONWITH GRADIENT BOUNDARY CONVOLUTIONAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121586646\",\"name\":\"A. Sokolova\"},{\"authorId\":\"144608239\",\"name\":\"Anton Konushin\"}],\"doi\":\"10.5194/ISPRS-ARCHIVES-XLII-2-W4-207-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11346dfbb4b251e96fb40ca4666c863a2503b1f8\",\"title\":\"GAIT RECOGNITION BASED ON CONVOLUTIONAL NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/11346dfbb4b251e96fb40ca4666c863a2503b1f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"title\":\"Knowledge Fusion Transformers for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"10684139\",\"name\":\"J. Aires\"},{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9545da8b7194dd2172d2827f59a90d191336a637\",\"title\":\"Improving Action Recognition using Temporal Regions\",\"url\":\"https://www.semanticscholar.org/paper/9545da8b7194dd2172d2827f59a90d191336a637\",\"venue\":\"J. Inf. Data Manag.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"143672707\",\"name\":\"Y. Shu\"},{\"authorId\":\"3330973\",\"name\":\"Qingsheng Yuan\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/ICME.2018.8486447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d530c341b3eda84c0b0a2c3149232daf16056f4\",\"title\":\"Hierarchical Temporal Memory Enhanced One-Shot Distance Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d530c341b3eda84c0b0a2c3149232daf16056f4\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81324120\",\"name\":\"Changde Fan\"},{\"authorId\":\"79866680\",\"name\":\"Chunhai Hu\"},{\"authorId\":\"145117689\",\"name\":\"Bin Liu\"}],\"doi\":\"10.1007/s00371-018-1603-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3c1cb53558163e9328b11b01091ca25fa8a5d1a\",\"title\":\"Linearized kernel dictionary learning with group sparse priors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3c1cb53558163e9328b11b01091ca25fa8a5d1a\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48456191\",\"name\":\"Hirokatsu Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICRA.2019.8793709\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9ee0ef81eb1f5fa3c9dfebdec16933618d1f80e\",\"title\":\"Unsupervised Out-of-context Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9ee0ef81eb1f5fa3c9dfebdec16933618d1f80e\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1908.08916\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cebe8d2fda288261f4f6206a58d4f52a15f351c6\",\"title\":\"Cross-Enhancement Transform Two-Stream 3D ConvNets for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/cebe8d2fda288261f4f6206a58d4f52a15f351c6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"145832297\",\"name\":\"Mei Xue\"},{\"authorId\":\"14875040\",\"name\":\"He Yi\"},{\"authorId\":\"1770701\",\"name\":\"Zhang Jin\"}],\"doi\":\"10.1109/ARSO46408.2019.8948745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48e2cb007411d965b5ed323405e7148ea3fb0bd4\",\"title\":\"Attention alignment by linear space projection for video features extraction\",\"url\":\"https://www.semanticscholar.org/paper/48e2cb007411d965b5ed323405e7148ea3fb0bd4\",\"venue\":\"2019 IEEE International Conference on Advanced Robotics and its Social Impacts (ARSO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100510864\",\"name\":\"F. Nugraha\"},{\"authorId\":\"9292289\",\"name\":\"E. C. Djamal\"}],\"doi\":\"10.1109/ICEEI47359.2019.8988872\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c63d6733c4ef278a421fd1fa86a071d06559d34a\",\"title\":\"Video Recognition of American Sign Language Using Two-Stream Convolution Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c63d6733c4ef278a421fd1fa86a071d06559d34a\",\"venue\":\"2019 International Conference on Electrical Engineering and Informatics (ICEEI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"title\":\"Action Recognition in Multi-view Videos\",\"url\":\"https://www.semanticscholar.org/paper/ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47844774\",\"name\":\"Hongkai Wang\"},{\"authorId\":\"48639779\",\"name\":\"Shang Shang\"},{\"authorId\":\"47598149\",\"name\":\"Ling Long\"},{\"authorId\":\"81015120\",\"name\":\"Ruxue Hu\"},{\"authorId\":\"144084568\",\"name\":\"Yi Wu\"},{\"authorId\":\"71205660\",\"name\":\"N. Chen\"},{\"authorId\":\"7671112\",\"name\":\"S. Zhang\"},{\"authorId\":\"1766771\",\"name\":\"F. Cong\"},{\"authorId\":\"92427232\",\"name\":\"Sijie Lin\"}],\"doi\":\"10.4103/digm.digm_16_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"154b1c4d3cf40931e54992d250b471827a865aba\",\"title\":\"Biological image analysis using deep learning-based methods: Literature review\",\"url\":\"https://www.semanticscholar.org/paper/154b1c4d3cf40931e54992d250b471827a865aba\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdde8d08733b4d9840089f8af07f042749675f\",\"title\":\"Deep network for human action recognition using Weber motion\",\"url\":\"https://www.semanticscholar.org/paper/66cdde8d08733b4d9840089f8af07f042749675f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"1679704\",\"name\":\"Y. Liu\"},{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"}],\"doi\":\"10.1109/TIE.2018.2884206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58ff25ce1332b5fdc9ac430222d03e550b4e29e9\",\"title\":\"Learning-Based Hand Motion Capture and Understanding in Assembly Process\",\"url\":\"https://www.semanticscholar.org/paper/58ff25ce1332b5fdc9ac430222d03e550b4e29e9\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2019},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.00696\",\"authors\":[{\"authorId\":\"4712803\",\"name\":\"Jiaojiao Zhao\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2019.01017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"title\":\"Dance With Flow: Two-In-One Stream Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1902.06383\",\"authors\":[{\"authorId\":\"3388571\",\"name\":\"L. Tiong\"},{\"authorId\":\"9162326\",\"name\":\"A. Teoh\"},{\"authorId\":\"47868335\",\"name\":\"Yunli Lee\"}],\"doi\":\"10.1109/ICB45273.2019.8987278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cced5a1e8609909b4e8481581ac86382e15c10c\",\"title\":\"Periocular Recognition in the Wild with Orthogonal Combination of Local Binary Coded Pattern in Dual-stream Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3cced5a1e8609909b4e8481581ac86382e15c10c\",\"venue\":\"2019 International Conference on Biometrics (ICB)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/s10489-018-1395-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"title\":\"A motion-aware ConvLSTM network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":\"1710.07354\",\"authors\":[{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"},{\"authorId\":\"1753812\",\"name\":\"N. Srinivasa\"}],\"doi\":\"10.3389/fnins.2018.00126\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"ac4cd0cb132e34dc20a25c2fe14edd84dbf27ad3\",\"title\":\"Learning to Recognize Actions From Limited Training Examples Using a Recurrent Spiking Neural Model\",\"url\":\"https://www.semanticscholar.org/paper/ac4cd0cb132e34dc20a25c2fe14edd84dbf27ad3\",\"venue\":\"Front. Neurosci.\",\"year\":2018},{\"arxivId\":\"1708.01191\",\"authors\":[{\"authorId\":\"3334896\",\"name\":\"Timo Milbich\"},{\"authorId\":\"144258123\",\"name\":\"Miguel \\u00c1ngel Bautista\"},{\"authorId\":\"38486173\",\"name\":\"E. Sutter\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1109/ICCV.2017.471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95deb62b82ede5c6732c5c498d3f9452866eaba7\",\"title\":\"Unsupervised Video Understanding by Reconciliation of Posture Similarities\",\"url\":\"https://www.semanticscholar.org/paper/95deb62b82ede5c6732c5c498d3f9452866eaba7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1712.09184\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPR.2018.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"title\":\"Detect-and-Track: Efficient Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"}],\"doi\":\"10.1016/j.neucom.2018.02.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"title\":\"Action recognition with motion map 3D network\",\"url\":\"https://www.semanticscholar.org/paper/c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2167197\",\"name\":\"B. Mudassar\"},{\"authorId\":\"40862506\",\"name\":\"P. Saha\"},{\"authorId\":\"50363755\",\"name\":\"Y. Long\"},{\"authorId\":\"37879315\",\"name\":\"M. Amir\"},{\"authorId\":\"73128469\",\"name\":\"Evan Gebhardt\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"2813905\",\"name\":\"J. H. Ko\"},{\"authorId\":\"3517655\",\"name\":\"M. Wolf\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":\"10.1109/JETCAS.2019.2935207\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d8e64e941b6dbf62e7a8040a9532265796edb46\",\"title\":\"CAMEL: An Adaptive Camera With Embedded Machine Learning-Based Sensor Parameter Control\",\"url\":\"https://www.semanticscholar.org/paper/6d8e64e941b6dbf62e7a8040a9532265796edb46\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296302\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"title\":\"SCNN: Sequential convolutional neural network for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766333\",\"name\":\"D. Wei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ab023f9bac5c85b829be95c905b6d5dc51820c2\",\"title\":\"Discovering physics and design trends from visual temporal structures\",\"url\":\"https://www.semanticscholar.org/paper/4ab023f9bac5c85b829be95c905b6d5dc51820c2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1707.06923\",\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2227f978f084ebb18cb594c0cfaf124b0df6bf95\",\"title\":\"Pillar Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2227f978f084ebb18cb594c0cfaf124b0df6bf95\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101947437\",\"name\":\"J. Saric\"},{\"authorId\":\"3009751\",\"name\":\"M. Orsic\"},{\"authorId\":\"2111962\",\"name\":\"Tonci Antunovic\"},{\"authorId\":\"3237756\",\"name\":\"Sacha Vrazic\"},{\"authorId\":\"3166278\",\"name\":\"Sinisa Segvic\"}],\"doi\":\"10.1109/CVPR42600.2020.01066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"921faa221b44a3cac6587172866fb58073bbc3c0\",\"title\":\"Warp to the Future: Joint Forecasting of Features and Feature Motion\",\"url\":\"https://www.semanticscholar.org/paper/921faa221b44a3cac6587172866fb58073bbc3c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICPR.2018.8546325\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d45f7abeca184533ee0f0670c4946bcd34edda81\",\"title\":\"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/d45f7abeca184533ee0f0670c4946bcd34edda81\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527099865\",\"name\":\"Yiying Li\"},{\"authorId\":\"47003312\",\"name\":\"Y. Li\"},{\"authorId\":\"1894528779\",\"name\":\"Yanfei Gu\"}],\"doi\":\"10.1145/3404555.3404592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"539a59c0cee60a780ce0cc3f85781377e61356fb\",\"title\":\"Channel-Wise Spatial Attention with Spatiotemporal Heterogeneous Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/539a59c0cee60a780ce0cc3f85781377e61356fb\",\"venue\":\"ICCAI\",\"year\":2020},{\"arxivId\":\"2006.15617\",\"authors\":[{\"authorId\":\"1390625723\",\"name\":\"Zhihao Liu\"},{\"authorId\":\"153010888\",\"name\":\"Hailiang Yin\"},{\"authorId\":\"1737825594\",\"name\":\"Y. Mi\"},{\"authorId\":\"51516578\",\"name\":\"Mengyang Pu\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b41b79d35605cec59f36642c375a18b58d45144\",\"title\":\"Shadow Removal by a Lightness-Guided Network with Training on Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/0b41b79d35605cec59f36642c375a18b58d45144\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701257\",\"name\":\"L. Cavigelli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c8e4dc9ffba2c889d845c5e10d37fa116c91036\",\"title\":\"Towards energy-efficient convolutional neural network inference\",\"url\":\"https://www.semanticscholar.org/paper/7c8e4dc9ffba2c889d845c5e10d37fa116c91036\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825539\",\"name\":\"Wei Wang\"},{\"authorId\":\"152299675\",\"name\":\"Siyuan Hao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"3124720\",\"name\":\"Shengtao Xiao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ACCESS.2019.2936604\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74195742093c489401ef8dc3d7f8639fd12c20e8\",\"title\":\"Temporal Spiking Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74195742093c489401ef8dc3d7f8639fd12c20e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"47059230\",\"name\":\"L. Zhang\"},{\"authorId\":\"46665820\",\"name\":\"Lin Mei\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"}],\"doi\":\"10.1109/ICPR.2016.7899601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1866a3671c9af4dcf6f0236e13a960851669ea6\",\"title\":\"Large-scale Isolated Gesture Recognition using pyramidal 3D convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/c1866a3671c9af4dcf6f0236e13a960851669ea6\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41189343\",\"name\":\"A. E. Seghrouchni\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-56150-5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"title\":\"Artificial Intelligence. IJCAI 2019 International Workshops: Macao, China, August 10\\u201312, 2019, Revised Selected Best Papers\",\"url\":\"https://www.semanticscholar.org/paper/ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"146761298\",\"name\":\"Fu Xiaoc\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TCSVT.2019.2918591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"title\":\"Discriminative Multi-View Subspace Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66786330\",\"name\":\"Palak Girdhar\"},{\"authorId\":\"66786330\",\"name\":\"Palak Girdhar\"},{\"authorId\":\"47497940\",\"name\":\"Prashant Johri\"},{\"authorId\":\"1782083\",\"name\":\"Deepali Virmani\"}],\"doi\":\"10.1080/09720529.2020.1804132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1631ec6669e5f50170d9392fc1f5c0c7c08e912\",\"title\":\"Incept_LSTM : Accession for human activity concession in automatic surveillance\",\"url\":\"https://www.semanticscholar.org/paper/f1631ec6669e5f50170d9392fc1f5c0c7c08e912\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.06236\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1145/3123266.3123343\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"title\":\"Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"2011.12004\",\"authors\":[{\"authorId\":\"2028357556\",\"name\":\"Racha Friji\"},{\"authorId\":\"2641251\",\"name\":\"H. Drira\"},{\"authorId\":\"2446036\",\"name\":\"F. Chaieb\"},{\"authorId\":\"145766926\",\"name\":\"S. Kurtek\"},{\"authorId\":\"2028357554\",\"name\":\"Hamza Kchok\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ae03c97b1a6bfa3546646ab654c5bf652c0f12c\",\"title\":\"KShapeNet: Riemannian network on Kendall shape space for Skeleton based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae03c97b1a6bfa3546646ab654c5bf652c0f12c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10033\",\"authors\":[{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"9540121\",\"name\":\"M. Schl\\u00fcter\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1016/j.media.2020.101730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"title\":\"Deep learning with 4D spatio-temporal data representations for OCT-based force estimation\",\"url\":\"https://www.semanticscholar.org/paper/9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49989940\",\"name\":\"A. Jamal\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"2064509\",\"name\":\"Dipti Deodhare\"},{\"authorId\":\"145952735\",\"name\":\"K. Venkatesh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ecc793f0b4f8b7a41ed25f7f3bb34d157329cf1\",\"title\":\"Deep Domain Adaptation in Action Space\",\"url\":\"https://www.semanticscholar.org/paper/3ecc793f0b4f8b7a41ed25f7f3bb34d157329cf1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2006.07743\",\"authors\":[{\"authorId\":\"1749326359\",\"name\":\"Adrian Sanchez-Caballero\"},{\"authorId\":\"143645592\",\"name\":\"S. Diz\"},{\"authorId\":\"1406742079\",\"name\":\"David Fuentes-Jim\\u00e9nez\"},{\"authorId\":\"1637432258\",\"name\":\"Cristina Losada-Guti\\u00e9rrez\"},{\"authorId\":\"39343700\",\"name\":\"Marta Marr\\u00f3n Romera\"},{\"authorId\":\"1415064936\",\"name\":\"David Casillas-P\\u00e9rez\"},{\"authorId\":\"134470377\",\"name\":\"Mohammad Ibrahim Sarker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f613f166ec26e3e01e996f7f04ed1d747081d9c\",\"title\":\"3DFCNN: Real-Time Action Recognition using 3D Deep Neural Networks with Raw Depth Information\",\"url\":\"https://www.semanticscholar.org/paper/6f613f166ec26e3e01e996f7f04ed1d747081d9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.04127\",\"authors\":[{\"authorId\":\"51266875\",\"name\":\"Chuming Lin\"},{\"authorId\":\"50683988\",\"name\":\"J. Li\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"20595955\",\"name\":\"Zhipeng Cui\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1609/AAAI.V34I07.6815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2534a3c894c93053341d514967c45c78657969c\",\"title\":\"Fast Learning of Temporal Action Proposal via Dense Boundary Generator\",\"url\":\"https://www.semanticscholar.org/paper/e2534a3c894c93053341d514967c45c78657969c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1456168805\",\"name\":\"A. Roy\"},{\"authorId\":\"145848796\",\"name\":\"Deepak Mishra\"}],\"doi\":\"10.1109/TENCON.2019.8929519\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af9659b69f81f2d63a27df1ab60ac58d3fe6295c\",\"title\":\"ECNN: Activity Recognition Using Ensembled Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/af9659b69f81f2d63a27df1ab60ac58d3fe6295c\",\"venue\":\"TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47003295\",\"name\":\"Yonggang Li\"},{\"authorId\":\"48843874\",\"name\":\"Rui Ge\"},{\"authorId\":\"36352159\",\"name\":\"Y. Ji\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1109/TCSVT.2017.2759299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e18c35667c46829a6c7374de11c937359c2b837\",\"title\":\"Trajectory-Pooled Spatial-Temporal Architecture of Deep Convolutional Neural Networks for Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/5e18c35667c46829a6c7374de11c937359c2b837\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3415077\",\"name\":\"Sameera Ramasinghe\"},{\"authorId\":\"32548363\",\"name\":\"Jathushan Rajasegaran\"},{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"48430646\",\"name\":\"Kanchana Ranasinghe\"},{\"authorId\":\"144952844\",\"name\":\"R. Rodrigo\"},{\"authorId\":\"144224514\",\"name\":\"A. Pasqual\"}],\"doi\":\"10.1109/DICTA.2017.8227463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9382c7876fb93545a41082862b0bfced796a33f0\",\"title\":\"Micro Actions and Deep Static Features for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9382c7876fb93545a41082862b0bfced796a33f0\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393510822\",\"name\":\"Sudarsini Tekkam Gnanasekar\"},{\"authorId\":\"1728290\",\"name\":\"S. Yanushkevich\"}],\"doi\":\"10.1109/IJCNN.2019.8852046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69137a4786de975a20cc238435be3a94fabd3e3e\",\"title\":\"Face Attribute Prediction in Live Video using Fusion of Features and Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/69137a4786de975a20cc238435be3a94fabd3e3e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"152245395\",\"name\":\"Zexin Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2933303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"title\":\"Refined Spatial Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145259071\",\"name\":\"W. Shao\"},{\"authorId\":\"2034287287\",\"name\":\"Guangze Wang\"},{\"authorId\":\"1879113580\",\"name\":\"Hongliang Xi\"},{\"authorId\":\"144386102\",\"name\":\"Lei Feng\"}],\"doi\":\"10.1109/DDCLS49620.2020.9275066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d27339cc64394c015077378e83660c308b5e4e8d\",\"title\":\"Extraction and Recognition of Device Graphics in Process Flow Diagram\",\"url\":\"https://www.semanticscholar.org/paper/d27339cc64394c015077378e83660c308b5e4e8d\",\"venue\":\"2020 IEEE 9th Data Driven Control and Learning Systems Conference (DDCLS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2408106\",\"name\":\"Mokhtar B. Abdullah\"},{\"authorId\":\"34911220\",\"name\":\"Mobeen Ahmad\"},{\"authorId\":\"52271749\",\"name\":\"D. Han\"}],\"doi\":\"10.1109/ICEIC49074.2020.9051332\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9e74c827a29e5fb8bca1fd4451ec23aaa6713bc\",\"title\":\"Facial Expression Recognition in Videos: An CNN-LSTM based Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f9e74c827a29e5fb8bca1fd4451ec23aaa6713bc\",\"venue\":\"2020 International Conference on Electronics, Information, and Communication (ICEIC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15187304\",\"name\":\"Chien-Fang Chiu\"},{\"authorId\":\"1726411\",\"name\":\"Chien-Hao Kuo\"},{\"authorId\":\"145456212\",\"name\":\"P. Chang\"}],\"doi\":\"10.23919/APSIPA.2018.8659703\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"369e25b87bff71e350e995a890ab69965c20e488\",\"title\":\"Smoking Action Recognition Based on Spatial-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/369e25b87bff71e350e995a890ab69965c20e488\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1811.10636\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2019.00188\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"title\":\"Evolving Space-Time Neural Architectures for Videos\",\"url\":\"https://www.semanticscholar.org/paper/793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.07967\",\"authors\":[{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"7413451\",\"name\":\"Daoyu Lin\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3287827\",\"name\":\"Guangluan Xu\"},{\"authorId\":\"8118391\",\"name\":\"Chibiao Ding\"}],\"doi\":\"10.3390/rs12091366\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89b44921d04692f44a1c6c8730179a3de3df5767\",\"title\":\"Deep Discriminative Representation Learning with Attention Map for Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/89b44921d04692f44a1c6c8730179a3de3df5767\",\"venue\":\"Remote. Sens.\",\"year\":2020},{\"arxivId\":\"1902.09085\",\"authors\":[{\"authorId\":\"51495548\",\"name\":\"Zihao W. Wang\"},{\"authorId\":\"143729959\",\"name\":\"Vibhav Vineet\"},{\"authorId\":\"3018385\",\"name\":\"F. Pittaluga\"},{\"authorId\":\"1757937\",\"name\":\"Sudipta N. Sinha\"},{\"authorId\":\"1793812\",\"name\":\"O. Cossairt\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/CVPRW.2019.00007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"149328470c9a66b9cc6f7f4f4072e99267d28e6b\",\"title\":\"Privacy-Preserving Action Recognition Using Coded Aperture Videos\",\"url\":\"https://www.semanticscholar.org/paper/149328470c9a66b9cc6f7f4f4072e99267d28e6b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997924\",\"name\":\"Samira Pouyanfar\"},{\"authorId\":\"8062083\",\"name\":\"S. Sadiq\"},{\"authorId\":\"39588413\",\"name\":\"Yilin Yan\"},{\"authorId\":\"2229900\",\"name\":\"Haiman Tian\"},{\"authorId\":\"2868174\",\"name\":\"Yudong Tao\"},{\"authorId\":\"39611894\",\"name\":\"Maria E. Presa-Reyes\"},{\"authorId\":\"144987531\",\"name\":\"M. Shyu\"},{\"authorId\":\"1705664\",\"name\":\"Shu-Ching Chen\"},{\"authorId\":\"153093860\",\"name\":\"S. S. Iyengar\"}],\"doi\":\"10.1145/3234150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb8a1b8d87a3fef15635eb4a32173f9c6f966055\",\"title\":\"A Survey on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/cb8a1b8d87a3fef15635eb4a32173f9c6f966055\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TCSVT.2018.2864148\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"title\":\"Action Recognition With Spatio\\u2013Temporal Visual Attention on Skeleton Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403026588\",\"name\":\"Pau Climent-P\\u00e9rez\"},{\"authorId\":\"1699905\",\"name\":\"S. Spinsante\"},{\"authorId\":\"2338883\",\"name\":\"A. Mihailidis\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.1016/J.ESWA.2019.112847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"title\":\"A review on video-based active and assisted living technologies for automated lifelogging\",\"url\":\"https://www.semanticscholar.org/paper/516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1807.09380\",\"authors\":[{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"title\":\"Contrastive Video Representation Learning via Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1611.05358\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"title\":\"Lip Reading Sentences in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390076423\",\"name\":\"Guang Ting Foo\"},{\"authorId\":\"46917486\",\"name\":\"Kam Meng Goh\"}],\"doi\":\"10.3233/IDT-190360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"914f36710026d0796f133469c0839915af711490\",\"title\":\"Violence action recognition using region proposal in region convolution neural network\",\"url\":\"https://www.semanticscholar.org/paper/914f36710026d0796f133469c0839915af711490\",\"venue\":\"Intell. Decis. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"title\":\"Multi-Modal Sensor Fusion: A Principled Approach to Optimality.\",\"url\":\"https://www.semanticscholar.org/paper/c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4497379\",\"name\":\"D. L. S\\u00e1nchez\"},{\"authorId\":\"2593856\",\"name\":\"Ang\\u00e9lica Gonz\\u00e1lez Arrieta\"},{\"authorId\":\"1729096\",\"name\":\"J. Corchado\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea85092098a6eb57df28eb038fda58b4189ce114\",\"title\":\"Compact bilinear pooling via kernelized random projection for fine-grained image categorization on low computational power devices\",\"url\":\"https://www.semanticscholar.org/paper/ea85092098a6eb57df28eb038fda58b4189ce114\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"15223978\",\"name\":\"Xingming Sun\"},{\"authorId\":\"46583977\",\"name\":\"J. Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-981-15-8083-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"title\":\"Artificial Intelligence and Security: 6th International Conference, ICAIS 2020, Hohhot, China, July 17\\u201320, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007998\",\"name\":\"Lars Andersson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/2c3c9376ce87a5b90a18e1481d35d653b1792a2b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d1da876c30d12c4843b2788d9387b44acf714a\",\"title\":\"DETECTION AND FORECAST VIA MULTITASK DEEP RECURRENT NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/a6d1da876c30d12c4843b2788d9387b44acf714a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38825416\",\"name\":\"Jagwinder Kaur Dhillon\"},{\"authorId\":\"47542183\",\"name\":\"Chandni\"},{\"authorId\":\"3016430\",\"name\":\"A. Kushwaha\"}],\"doi\":\"10.1109/ICIIP.2017.8313715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bf4d37ae533a6b6fd4c16030077ab83afa8c94d\",\"title\":\"A recent survey for human activity recoginition based on deep learning approach\",\"url\":\"https://www.semanticscholar.org/paper/7bf4d37ae533a6b6fd4c16030077ab83afa8c94d\",\"venue\":\"2017 Fourth International Conference on Image Information Processing (ICIIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100856944\",\"name\":\"Muhammad Zeeshan Khan\"},{\"authorId\":\"46714878\",\"name\":\"Muhammad Khairul Ali Hassan\"},{\"authorId\":\"32824146\",\"name\":\"Ammarah Farooq\"},{\"authorId\":\"113607553\",\"name\":\"Muhammad Usman Ghanni Khan\"}],\"doi\":\"10.1109/ICAEM.2018.8536277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aa9f29b43e76049c3b302e373ebd010c4187df5\",\"title\":\"Deep CNN Based Data-Driven Recognition of Cricket Batting Shots\",\"url\":\"https://www.semanticscholar.org/paper/6aa9f29b43e76049c3b302e373ebd010c4187df5\",\"venue\":\"2018 International Conference on Applied and Engineering Mathematics (ICAEM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9272516\",\"name\":\"Suharjito\"},{\"authorId\":\"66416702\",\"name\":\"Herman Gunawan\"},{\"authorId\":\"66467949\",\"name\":\"Narada Thiracitta\"},{\"authorId\":\"1795227\",\"name\":\"A. Nugroho\"}],\"doi\":\"10.1109/INAPR.2018.8627014\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe4dbea7d530c21c77137f52fed28c9b0947172b\",\"title\":\"Sign Language Recognition Using Modified Convolutional Neural Network Model\",\"url\":\"https://www.semanticscholar.org/paper/fe4dbea7d530c21c77137f52fed28c9b0947172b\",\"venue\":\"2018 Indonesian Association for Pattern Recognition International Conference (INAPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50826496\",\"name\":\"Jiannan Fang\"},{\"authorId\":\"74213550\",\"name\":\"Lingling Sun\"},{\"authorId\":null,\"name\":\"Yaqi Wang\"}],\"doi\":\"10.1117/12.2539615\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e077e28cadfc36eda163a01702deb795824d939\",\"title\":\"Video question answering by frame attention\",\"url\":\"https://www.semanticscholar.org/paper/6e077e28cadfc36eda163a01702deb795824d939\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410106115\",\"name\":\"Tieu Binh Hoang\"},{\"authorId\":\"29543391\",\"name\":\"T. C. Ma\"},{\"authorId\":\"71752568\",\"name\":\"Sugimoto Akihiro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"title\":\"Selecting active frames for action recognition with 3D convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72434202\",\"name\":\"Zixian Cai\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b9c46f223dc0d48113f6da1415dc35b2f73eab\",\"title\":\"Activity Recognition in Videos with Segmented Streams\",\"url\":\"https://www.semanticscholar.org/paper/71b9c46f223dc0d48113f6da1415dc35b2f73eab\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.04685\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054200\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"title\":\"Learning Spatio-Temporal Representations With Temporal Squeeze Pooling\",\"url\":\"https://www.semanticscholar.org/paper/ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14556193\",\"name\":\"Sorina Smeureanu\"},{\"authorId\":\"1817759\",\"name\":\"Radu Tudor Ionescu\"},{\"authorId\":\"49006356\",\"name\":\"M. Popescu\"},{\"authorId\":\"2365442\",\"name\":\"B. Alexe\"}],\"doi\":\"10.1007/978-3-319-68548-9_70\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"992847be33f4bf7afbe66e198cb20a53e00dfa76\",\"title\":\"Deep Appearance Features for Abnormal Behavior Detection in Video\",\"url\":\"https://www.semanticscholar.org/paper/992847be33f4bf7afbe66e198cb20a53e00dfa76\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51427490\",\"name\":\"Edwin Escobedo\"},{\"authorId\":\"108202338\",\"name\":\"L. Ram\\u00edrez\"},{\"authorId\":\"51363101\",\"name\":\"G. C\\u00e1mara\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f32fdc91b27cf4782ba21eed6208d7dc13e632be\",\"title\":\"Dynamic Sign Language Recognition Based on Convolutional Neural Networks and Texture Maps\",\"url\":\"https://www.semanticscholar.org/paper/f32fdc91b27cf4782ba21eed6208d7dc13e632be\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.06536\",\"authors\":[{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"9359529\",\"name\":\"K. Wang\"},{\"authorId\":\"1492126129\",\"name\":\"Dan Zeng\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dc0bf7bfc8d72959245178a54cc1243b1e7d267\",\"title\":\"Robust Visual Object Tracking with Two-Stream Residual Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/6dc0bf7bfc8d72959245178a54cc1243b1e7d267\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.02203\",\"authors\":[{\"authorId\":\"143955758\",\"name\":\"Yang Hu\"},{\"authorId\":\"9725901\",\"name\":\"Guihua Wen\"},{\"authorId\":\"35816793\",\"name\":\"Huiqiang Liao\"},{\"authorId\":\"47073786\",\"name\":\"C. Wang\"},{\"authorId\":\"46925647\",\"name\":\"Dan Dai\"},{\"authorId\":\"144861834\",\"name\":\"Zhiwen Yu\"}],\"doi\":\"10.1109/TCYB.2019.2909925\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65b76c6b27206f2932e7993531af19aa769b407b\",\"title\":\"Automatic Construction of Chinese Herbal Prescriptions From Tongue Images Using CNNs and Auxiliary Latent Therapy Topics.\",\"url\":\"https://www.semanticscholar.org/paper/65b76c6b27206f2932e7993531af19aa769b407b\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5049995\",\"name\":\"Mingqi Qiao\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"}],\"doi\":\"10.1007/978-981-10-7305-2_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3761017435a06987685007fe5889061f564cc889\",\"title\":\"Learning the Frame-2-Frame Ego-Motion for Visual Odometry with Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3761017435a06987685007fe5889061f564cc889\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TSMC.2016.2625840\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"title\":\"Group Sparse-Based Mid-Level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733863\",\"name\":\"Ziqiang Li\"},{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"1878213307\",\"name\":\"Jiaruo Yu\"},{\"authorId\":\"145429878\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/icme46284.2020.9102727\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"998ff770cc593fa2d7a0ba1029cd78bf5d4c1ca0\",\"title\":\"Deep Selective Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/998ff770cc593fa2d7a0ba1029cd78bf5d4c1ca0\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51050729\",\"name\":\"Hongtao Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2018.00157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"title\":\"One-Shot Action Localization by Learning Sequence Matching Network\",\"url\":\"https://www.semanticscholar.org/paper/bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48354916\",\"name\":\"Ze Chen\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3297097.3297107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9fff8a34942053fd93760c8c84a40849b9db734\",\"title\":\"Recurrent Spatiotemporal Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9fff8a34942053fd93760c8c84a40849b9db734\",\"venue\":\"ICRAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0af1363c2d03e5d2435d9ba2b05ca5aecd568fd\",\"title\":\"PicSOM and EURECOM Experiments in TRECVID 2019\",\"url\":\"https://www.semanticscholar.org/paper/d0af1363c2d03e5d2435d9ba2b05ca5aecd568fd\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389422664\",\"name\":\"Roshan Singh\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1109/PARC49193.2020.236672\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82ce6e57645121e5f3db964bab76f560d5b30619\",\"title\":\"Some Contemporary Approaches for Human Activity Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/82ce6e57645121e5f3db964bab76f560d5b30619\",\"venue\":\"2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795189\",\"name\":\"T. Senst\"},{\"authorId\":\"1773756\",\"name\":\"V. Eiselein\"},{\"authorId\":\"145046715\",\"name\":\"A. Kuhn\"},{\"authorId\":\"144089337\",\"name\":\"T. Sikora\"}],\"doi\":\"10.1109/TIFS.2017.2725820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db412dcee9aba0615d7972fdee55655061ed0178\",\"title\":\"Crowd Violence Detection Using Global Motion-Compensated Lagrangian Features and Scale-Sensitive Video-Level Representation\",\"url\":\"https://www.semanticscholar.org/paper/db412dcee9aba0615d7972fdee55655061ed0178\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2017},{\"arxivId\":\"1801.02475\",\"authors\":[{\"authorId\":\"40507939\",\"name\":\"Yangyang Xu\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"},{\"authorId\":\"145131937\",\"name\":\"L. Wang\"},{\"authorId\":\"39827902\",\"name\":\"H. Xia\"},{\"authorId\":\"51013550\",\"name\":\"Feng Liu\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1109/LSP.2018.2841649\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7891577acd3038885ee807c85bd71a8c3135699d\",\"title\":\"Ensemble One-Dimensional Convolution Neural Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7891577acd3038885ee807c85bd71a8c3135699d\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46691985\",\"name\":\"Yuhao Shan\"},{\"authorId\":\"1738041\",\"name\":\"Shigang Li\"}],\"doi\":\"10.1109/ACCESS.2018.2825477\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"279120d58e7973515aa6fbc5ba82a0a643001eed\",\"title\":\"Descriptor Matching for a Discrete Spherical Image With a Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/279120d58e7973515aa6fbc5ba82a0a643001eed\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1612.00881\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1109/CVPR.2017.278\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f31de384bee955d8faffa1efe5f7b51cb299381\",\"title\":\"Procedural Generation of Videos to Train Deep Action Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f31de384bee955d8faffa1efe5f7b51cb299381\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"2954162\",\"name\":\"R. Serizel\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1772256\",\"name\":\"F. Antonacci\"},{\"authorId\":\"30136187\",\"name\":\"A. Sarti\"}],\"doi\":\"10.1007/978-3-319-63450-0_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ae031b519cbac99797320ad4bb405e8d07d62ed\",\"title\":\"Multiview Approaches to Event Detection and Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1ae031b519cbac99797320ad4bb405e8d07d62ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50141950\",\"name\":\"Xionghui Wang\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48c601d0029c25ba02480c473d1bd31960acb2e2\",\"title\":\"Progressive Teacher-Student Learning for Early Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/48c601d0029c25ba02480c473d1bd31960acb2e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"114320931\",\"name\":\"Hai-Zhen Xuan\"},{\"authorId\":\"41189853\",\"name\":\"H. Zhang\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"2840539\",\"name\":\"Kim-Kwang Raymond Choo\"}],\"doi\":\"10.1109/JIOT.2019.2911669\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"title\":\"Adaptive Fusion and Category-Level Dictionary Learning Model for Multiview Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69901495\",\"name\":\"H. Sadr\"},{\"authorId\":\"72476885\",\"name\":\"Mir Mohsen Pedram\"},{\"authorId\":\"1709359\",\"name\":\"M. Teshnehlab\"}],\"doi\":\"10.1109/ACCESS.2020.2992063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4464e0581393c4d96762a1cb73e9be206aa1b712\",\"title\":\"Multi-View Deep Network: A Deep Model Based on Learning Features From Heterogeneous Neural Networks for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4464e0581393c4d96762a1cb73e9be206aa1b712\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47320160\",\"name\":\"Shengchao Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1109/ROMAN.2018.8525781\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e667250b0407b262e9d15929c86b6da347f9cdc9\",\"title\":\"Improving Human Intention Prediction Using Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/e667250b0407b262e9d15929c86b6da347f9cdc9\",\"venue\":\"2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"},{\"authorId\":\"1701928\",\"name\":\"Jixiang Du\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"47416429\",\"name\":\"Shuang Ye\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19194129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"title\":\"A Survey of Vision-Based Human Action Evaluation Methods\",\"url\":\"https://www.semanticscholar.org/paper/fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451384\",\"name\":\"Felix J\\u00e4remo Lawin\"},{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"},{\"authorId\":\"15791955\",\"name\":\"Patrik Tosteberg\"},{\"authorId\":\"49922196\",\"name\":\"Goutam Bhat\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d817f8cd276d260617f81fa04a095ea8f2ca501\",\"title\":\"Deep Projective 3 D Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7d817f8cd276d260617f81fa04a095ea8f2ca501\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2003.01888\",\"authors\":[{\"authorId\":\"1966561\",\"name\":\"S. Ghorbani\"},{\"authorId\":\"1519541371\",\"name\":\"Kimia Mahdaviani\"},{\"authorId\":\"40481439\",\"name\":\"A. Thaler\"},{\"authorId\":\"36121677\",\"name\":\"Konrad P. K\\u00f6rding\"},{\"authorId\":\"32104861\",\"name\":\"D. J. Cook\"},{\"authorId\":\"2015591\",\"name\":\"G. Blohm\"},{\"authorId\":\"2932365\",\"name\":\"N. Troje\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"title\":\"MoVi: A Large Multipurpose Motion and Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.09796\",\"authors\":[{\"authorId\":\"50564082\",\"name\":\"Dinesh Khandelwal\"},{\"authorId\":\"49064336\",\"name\":\"Suyash Agrawal\"},{\"authorId\":\"35108153\",\"name\":\"Parag Singla\"},{\"authorId\":\"38772597\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c627234d074473574d09ba69bdeabec5d3667d40\",\"title\":\"A Novel Technique for Evidence based Conditional Inference in Deep Neural Networks via Latent Feature Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/c627234d074473574d09ba69bdeabec5d3667d40\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.01716\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"29905643\",\"name\":\"Fatih Murat Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"title\":\"Action Representation Using Classifier Decision Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144020384\",\"name\":\"Hoseong Kim\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"}],\"doi\":\"10.1109/TMM.2018.2806224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f27eb66e4aec7fda25ffcbd3cdd0fb4b285c6f67\",\"title\":\"Exploiting Web Images for Video Highlight Detection With Triplet Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/f27eb66e4aec7fda25ffcbd3cdd0fb4b285c6f67\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1706.09556\",\"authors\":[{\"authorId\":\"3251468\",\"name\":\"A. Bazzica\"},{\"authorId\":\"144044151\",\"name\":\"J. V. Gemert\"},{\"authorId\":\"1968667\",\"name\":\"Cynthia C. S. Liem\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eadd73c3e1c20d16e32ee8656c4f954603b37450\",\"title\":\"Vision-based Detection of Acoustic Timed Events: a Case Study on Clarinet Note Onsets\",\"url\":\"https://www.semanticscholar.org/paper/eadd73c3e1c20d16e32ee8656c4f954603b37450\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430959\",\"name\":\"Wenyan Bi\"},{\"authorId\":\"50820195\",\"name\":\"Peiran Jin\"},{\"authorId\":\"4314957\",\"name\":\"H. Nienborg\"},{\"authorId\":\"48062465\",\"name\":\"B. Xiao\"}],\"doi\":\"10.1101/238782\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a443c8790be80cdf8cf42aa364372f3d22b0fc14\",\"title\":\"Estimating mechanical properties of cloth from videos using dense motion trajectories: human psychophysics and machine learning\",\"url\":\"https://www.semanticscholar.org/paper/a443c8790be80cdf8cf42aa364372f3d22b0fc14\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47149750\",\"name\":\"Xinhui Wu\"},{\"authorId\":\"1719370\",\"name\":\"Shiqi Yu\"},{\"authorId\":\"145501833\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1007/978-3-030-31456-9_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f65891ab12ca77b6eddcd63df9e36776f115eec2\",\"title\":\"Multiscale Temporal Network for Video-Based Gait Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f65891ab12ca77b6eddcd63df9e36776f115eec2\",\"venue\":\"CCBR\",\"year\":2019},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2918593\",\"name\":\"X. Chen\"},{\"authorId\":\"92993470\",\"name\":\"Huan Yang\"},{\"authorId\":\"22565765\",\"name\":\"Jinjing Yu\"},{\"authorId\":\"66357527\",\"name\":\"Weichao Yue\"},{\"authorId\":\"7767746\",\"name\":\"Yongfang Xie\"}],\"doi\":\"10.1109/CAC.2018.8623274\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9dd111110d2e67be9cc00ec33dedc5211f8442e7\",\"title\":\"A Feature Extraction Strategy of Fire Hole Video Based on VGG16 and Migration Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dd111110d2e67be9cc00ec33dedc5211f8442e7\",\"venue\":\"2018 Chinese Automation Congress (CAC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144935651\",\"name\":\"Sitthichok Chaichulee\"},{\"authorId\":\"39761409\",\"name\":\"M. Villarroel\"},{\"authorId\":\"143858666\",\"name\":\"Jo\\u00e3o Jorge\"},{\"authorId\":\"2901486\",\"name\":\"C. Arteta\"},{\"authorId\":\"46306789\",\"name\":\"K. McCormick\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"143923114\",\"name\":\"L. Tarassenko\"}],\"doi\":\"10.1088/1361-6579/ab525c\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd3037b22f21bcc543fe78dc182d474241f4c890\",\"title\":\"Cardio-respiratory signal extraction from video camera data for continuous non-contact vital sign monitoring using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/dd3037b22f21bcc543fe78dc182d474241f4c890\",\"venue\":\"Physiological measurement\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145131937\",\"name\":\"L. Wang\"},{\"authorId\":\"143709258\",\"name\":\"Yangyang Xu\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"},{\"authorId\":\"39827902\",\"name\":\"H. Xia\"},{\"authorId\":\"1890165\",\"name\":\"J. Yin\"},{\"authorId\":\"26883623\",\"name\":\"Jiaji Wu\"}],\"doi\":\"10.1109/ACCESS.2018.2817253\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"263ed62f94ea615c747c00ebbb4008385285b33b\",\"title\":\"Human Action Recognition by Learning Spatio-Temporal Features With Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/263ed62f94ea615c747c00ebbb4008385285b33b\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"}],\"doi\":\"10.1109/TCSVT.2019.2962063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d787811e26606b598ba22ad3b4b1e30096b3bedc\",\"title\":\"Joint Learning of Local and Global Context for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/d787811e26606b598ba22ad3b4b1e30096b3bedc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1709.00944\",\"authors\":[{\"authorId\":\"8726117\",\"name\":\"Jen-Cheng Hou\"},{\"authorId\":\"2426246\",\"name\":\"S. Wang\"},{\"authorId\":\"145274548\",\"name\":\"Y. Lai\"},{\"authorId\":\"66191041\",\"name\":\"Jen-Chun Lin\"},{\"authorId\":\"145403933\",\"name\":\"Y. Tsao\"},{\"authorId\":\"144600099\",\"name\":\"Hsiu-Wen Chang\"},{\"authorId\":\"1710199\",\"name\":\"H. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b83a4395be8b79e693118b95cd7cca764390ec8f\",\"title\":\"Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b83a4395be8b79e693118b95cd7cca764390ec8f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"9637828\",\"name\":\"Junho Jin\"},{\"authorId\":\"144396280\",\"name\":\"Yongjin Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"144341935\",\"name\":\"K. Park\"}],\"doi\":\"10.4218/ETRIJ.17.0116.0054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58c692a2ac35d4beab97836c4c95881d52beb61\",\"title\":\"Extensible Hierarchical Method of Detecting Interactive Actions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e58c692a2ac35d4beab97836c4c95881d52beb61\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145461143\",\"name\":\"Bin Liang\"},{\"authorId\":\"8507555\",\"name\":\"Lihong Zheng\"}],\"doi\":\"10.1109/TIP.2017.2740122\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbddc7faa2ee50d5e39edbe1afa461254f77fe2d\",\"title\":\"Specificity and Latent Correlation Learning for Action Recognition Using Synthetic Multi-View Data From Depth Maps\",\"url\":\"https://www.semanticscholar.org/paper/cbddc7faa2ee50d5e39edbe1afa461254f77fe2d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"2011.11695\",\"authors\":[{\"authorId\":\"50811700\",\"name\":\"A. Nori\"},{\"authorId\":\"32108989\",\"name\":\"R. Bera\"},{\"authorId\":\"1703505\",\"name\":\"S. Balachandran\"},{\"authorId\":\"39213970\",\"name\":\"Joydeep Rakshit\"},{\"authorId\":\"123918823\",\"name\":\"O. J. Omer\"},{\"authorId\":\"2028358086\",\"name\":\"Avishaii Abuhatzera\"},{\"authorId\":\"119771774\",\"name\":\"Belliappa Kuttanna\"},{\"authorId\":\"1706165\",\"name\":\"Sreenivas Subramoney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3f2e272176c60793b22701eb8e8918435d0766e\",\"title\":\"Proximu: Efficiently Scaling DNN Inference in Multi-core CPUs through Near-Cache Compute\",\"url\":\"https://www.semanticscholar.org/paper/f3f2e272176c60793b22701eb8e8918435d0766e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9206207\",\"name\":\"Ahmed R. Abas\"},{\"authorId\":\"2905919\",\"name\":\"I. El-Henawy\"},{\"authorId\":\"113326266\",\"name\":\"Hossam Mohamed\"},{\"authorId\":\"73551512\",\"name\":\"Amr M. AbdelLatif\"}],\"doi\":\"10.1109/ACCESS.2020.3008824\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b0453ddb2e02b1acd2047001b3fcceb2bd5eef3\",\"title\":\"Deep Learning Model for Fine-Grained Aspect-Based Opinion Mining\",\"url\":\"https://www.semanticscholar.org/paper/4b0453ddb2e02b1acd2047001b3fcceb2bd5eef3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1907.12743\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"66370228\",\"name\":\"J. Yoo\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"15460136\",\"name\":\"Jianqiu Zheng\"}],\"doi\":\"10.1109/ICCV.2019.00642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89917e19175eb4f3bca02e0bace8f99d6910b054\",\"title\":\"Temporal Attentive Alignment for Large-Scale Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/89917e19175eb4f3bca02e0bace8f99d6910b054\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.09917\",\"authors\":[{\"authorId\":\"47058824\",\"name\":\"Lamei Zhang\"},{\"authorId\":\"39256302\",\"name\":\"H. Dong\"},{\"authorId\":\"143625022\",\"name\":\"B. Zou\"}],\"doi\":\"10.1016/j.isprsjprs.2019.09.002\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4de5c52aec1eec59de4d68215ef52016498885b\",\"title\":\"Efficiently utilizing complex-valued PolSAR image data via a multi-task deep learning framework\",\"url\":\"https://www.semanticscholar.org/paper/a4de5c52aec1eec59de4d68215ef52016498885b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406678671\",\"name\":\"\\u00d8yvind Meinich-Bache\"},{\"authorId\":\"1557403564\",\"name\":\"Simon Lennart Austnes\"},{\"authorId\":\"2691592\",\"name\":\"K. Engan\"},{\"authorId\":\"1704325\",\"name\":\"Ivar Austvoll\"},{\"authorId\":\"8985915\",\"name\":\"T. Eftest\\u00f8l\"},{\"authorId\":\"2665808\",\"name\":\"H. Myklebust\"},{\"authorId\":\"16935010\",\"name\":\"S. Kusulla\"},{\"authorId\":\"143762843\",\"name\":\"H. Kidanto\"},{\"authorId\":\"40423610\",\"name\":\"H. Ersdal\"}],\"doi\":\"10.1109/JBHI.2020.2978252\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"936f4a0a53ca9b08cc0380da8ef806f957d17d12\",\"title\":\"Activity Recognition From Newborn Resuscitation Videos\",\"url\":\"https://www.semanticscholar.org/paper/936f4a0a53ca9b08cc0380da8ef806f957d17d12\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2967555\",\"name\":\"J. Wang\"},{\"authorId\":\"47357865\",\"name\":\"R. Ju\"},{\"authorId\":\"40432210\",\"name\":\"Yuan-Yuan Chen\"},{\"authorId\":\"47061631\",\"name\":\"Guijun Liu\"},{\"authorId\":\"144622704\",\"name\":\"Zhang Yi\"}],\"doi\":\"10.1016/j.neucom.2020.01.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d40cb15266fe915ad6d177afd582422a1adeead2\",\"title\":\"Automated diagnosis of neonatal encephalopathy on aEEG using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d40cb15266fe915ad6d177afd582422a1adeead2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2012.02970\",\"authors\":[{\"authorId\":\"9332112\",\"name\":\"T. Li\"},{\"authorId\":\"49775481\",\"name\":\"R. Zhang\"},{\"authorId\":\"2018164756\",\"name\":\"Qing Li\"}],\"doi\":\"10.5121/csit.2020.101605\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f50874b01de1f0e788f0b47973f552cba3a61ff\",\"title\":\"Multi Scale Temporal Graph Networks For Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f50874b01de1f0e788f0b47973f552cba3a61ff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102696161\",\"name\":\"Rui Wang\"},{\"authorId\":\"122112895\",\"name\":\"Xiaojun Wu\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/TMM.2020.2981189\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"555c9dc158a2079a66e019f68ac38ff97b824009\",\"title\":\"Graph Embedding Multi-Kernel Metric Learning for Image Set Classification With Grassmannian Manifold-Valued Features\",\"url\":\"https://www.semanticscholar.org/paper/555c9dc158a2079a66e019f68ac38ff97b824009\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.01148\",\"authors\":[{\"authorId\":\"2804902\",\"name\":\"M. M. Islam\"},{\"authorId\":\"32229358\",\"name\":\"Tariq Iqbal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab3f612125a13410373c33600abd3fccdf79ce31\",\"title\":\"HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/ab3f612125a13410373c33600abd3fccdf79ce31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2481662\",\"name\":\"Y. Zhou\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00775\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"title\":\"Now You Shake Me: Towards Automatic 4D Cinema\",\"url\":\"https://www.semanticscholar.org/paper/ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ISCAS.2018.8350912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"title\":\"A 65 fps Full-HD Hardware Implementation of HOG, HOF, MBHx, and MBHy for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":\"1907.09702\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"48032598\",\"name\":\"X. Liu\"},{\"authorId\":\"48568672\",\"name\":\"Xin Li\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faf5651d82885243f5d310ced0e39e0703add073\",\"title\":\"BMN: Boundary-Matching Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/faf5651d82885243f5d310ced0e39e0703add073\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49854896\",\"name\":\"M. Fang\"},{\"authorId\":\"47055440\",\"name\":\"X. Bai\"},{\"authorId\":\"113734234\",\"name\":\"J. Zhao\"},{\"authorId\":\"119704789\",\"name\":\"F. Yang\"},{\"authorId\":\"144042438\",\"name\":\"C. Hung\"},{\"authorId\":\"122050993\",\"name\":\"Shuhua Liu\"}],\"doi\":\"10.1007/s00530-020-00683-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"340ef80d63c6514598839e29e6f24ffb9dc22212\",\"title\":\"Integrating Gaussian mixture model and dilated residual network for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/340ef80d63c6514598839e29e6f24ffb9dc22212\",\"venue\":\"Multimedia Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490678582\",\"name\":\"David Ouyang\"},{\"authorId\":\"118832513\",\"name\":\"Bryan He\"},{\"authorId\":\"1490678740\",\"name\":\"Amirata Ghorbani\"},{\"authorId\":\"66795291\",\"name\":\"M. Lungren\"},{\"authorId\":\"2668259\",\"name\":\"E. Ashley\"},{\"authorId\":\"31863078\",\"name\":\"D. Liang\"},{\"authorId\":\"145085302\",\"name\":\"James Y. Zou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44bfcf2409c0826584c7c409b6a2fcf8c9910c88\",\"title\":\"EchoNet-Dynamic: a Large New Cardiac Motion Video Data Resource for Medical Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/44bfcf2409c0826584c7c409b6a2fcf8c9910c88\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145271111\",\"name\":\"N. Henderson\"},{\"authorId\":\"3867127\",\"name\":\"R. Aygun\"}],\"doi\":\"10.1109/ISM.2017.22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cba090a5bfae7dd8a60a973259f0870ed68c4dd3\",\"title\":\"Human Action Classification Using Temporal Slicing for Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cba090a5bfae7dd8a60a973259f0870ed68c4dd3\",\"venue\":\"2017 IEEE International Symposium on Multimedia (ISM)\",\"year\":2017},{\"arxivId\":\"1904.13080\",\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e3fc2a67967b1355609094175f19b2412dd4851d\",\"title\":\"Memory-Augmented Temporal Dynamic Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e3fc2a67967b1355609094175f19b2412dd4851d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49520427\",\"name\":\"X. Fang\"},{\"authorId\":\"12464207\",\"name\":\"Han Fang\"},{\"authorId\":\"145892592\",\"name\":\"Zhan Feng\"},{\"authorId\":\"144213485\",\"name\":\"Jie Wang\"},{\"authorId\":\"48207185\",\"name\":\"Libin Zhou\"}],\"doi\":\"10.3390/app10010139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8bc673379d76bdc211e45d45c5996a5fa35e336\",\"title\":\"Artificial Auditory Perception Pattern Recognition System Based on Spatiotemporal Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/e8bc673379d76bdc211e45d45c5996a5fa35e336\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39412489\",\"name\":\"Christopher Reale\"},{\"authorId\":\"3202888\",\"name\":\"Claire Bonial\"},{\"authorId\":\"1688527\",\"name\":\"H. Kwon\"},{\"authorId\":\"1817166\",\"name\":\"Clare R. Voss\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d48bd355d091e7ae75ade4e878fe346741e7da1a\",\"title\":\"Can You Spot the Semantic Predicate in this Video?\",\"url\":\"https://www.semanticscholar.org/paper/d48bd355d091e7ae75ade4e878fe346741e7da1a\",\"venue\":\"EventStory@Coling\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"title\":\"Learning to Recognize Actions with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9426119\",\"name\":\"Xinlei Wei\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"},{\"authorId\":\"1750649\",\"name\":\"Zhe Xue\"},{\"authorId\":\"50847093\",\"name\":\"MeiYu Liang\"},{\"authorId\":\"145383419\",\"name\":\"Yue Geng\"},{\"authorId\":\"145880436\",\"name\":\"X. Xu\"},{\"authorId\":\"48174655\",\"name\":\"J. Lee\"}],\"doi\":\"10.1016/J.NEUCOM.2018.10.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d595c44367f1755830502a34df5151cc6b10214f\",\"title\":\"A very deep two-stream network for crowd type recognition\",\"url\":\"https://www.semanticscholar.org/paper/d595c44367f1755830502a34df5151cc6b10214f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1709.06447\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"939232314d39b26c89cd190c005b2ca71f14220a\",\"title\":\"Human Activity Recognition Using Robust Adaptive Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/939232314d39b26c89cd190c005b2ca71f14220a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410137437\",\"name\":\"Manal AlGhamdi\"},{\"authorId\":\"1407758842\",\"name\":\"M. Abdel-Mottaleb\"},{\"authorId\":\"1402132170\",\"name\":\"F. Collado-Mesa\"}],\"doi\":\"10.1109/TMI.2020.2989737\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0aa8800f6db6e8fe62d0bf9b43afce38adbf8274\",\"title\":\"DU-Net: Convolutional Network for the Detection of Arterial Calcifications in Mammograms\",\"url\":\"https://www.semanticscholar.org/paper/0aa8800f6db6e8fe62d0bf9b43afce38adbf8274\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":\"1811.05014\",\"authors\":[{\"authorId\":\"47244850\",\"name\":\"Rongcheng Lin\"},{\"authorId\":\"144033366\",\"name\":\"J. Xiao\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1007/978-3-030-11018-5_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"919548553251d5cf92a2cb50e87d29b862613bb5\",\"title\":\"NeXtVLAD: An Efficient Neural Network to Aggregate Frame-level Features for Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/919548553251d5cf92a2cb50e87d29b862613bb5\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.05666\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"143881914\",\"name\":\"J. Romero\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"07d6238d8f8edbfe0fd2887fa0a7939735f21e13\",\"title\":\"Learning Human Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/07d6238d8f8edbfe0fd2887fa0a7939735f21e13\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2017.161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"title\":\"Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks\",\"url\":\"https://www.semanticscholar.org/paper/28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3106211\",\"name\":\"K. Blekas\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"41e63845f61e989a5b4cd2d8c42d36b749f1c540\",\"title\":\"Hand Pose Estimation with Convolutional Networks using RGB-D Data\",\"url\":\"https://www.semanticscholar.org/paper/41e63845f61e989a5b4cd2d8c42d36b749f1c540\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10025937\",\"name\":\"Z. Xu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"46868155\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICMEW.2018.8551529\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"title\":\"S2L: Single-Streamline For Complex Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48072671\",\"name\":\"Dongfeng Gu\"}],\"doi\":\"10.20381/RUOR-21013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98a81baa53847a397d7948b9ecfcb72f67691518\",\"title\":\"3D Densely Connected Convolutional Network for the Recognition of Human Shopping Actions\",\"url\":\"https://www.semanticscholar.org/paper/98a81baa53847a397d7948b9ecfcb72f67691518\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411918861\",\"name\":\"Paul Dixon Coen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b26bbca0d5e8c8a898a82961476091de90d3a29\",\"title\":\"Human Activity Recognition and Prediction using RGBD Data\",\"url\":\"https://www.semanticscholar.org/paper/7b26bbca0d5e8c8a898a82961476091de90d3a29\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152153140\",\"name\":\"Xiuping Bao\"},{\"authorId\":\"49706674\",\"name\":\"J. Yuan\"},{\"authorId\":null,\"name\":\"Bei Chen\"}],\"doi\":\"10.1109/ICTAI.2019.00089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60de1895702532f93b93b616d7a47096dfd1dc6c\",\"title\":\"ECPNet: An Efficient Attention-Based Convolution Network with Pseudo-3D Block for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60de1895702532f93b93b616d7a47096dfd1dc6c\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1417198481\",\"name\":\"Narada Warakagoda\"},{\"authorId\":\"74872156\",\"name\":\"Johann Dirdal\"},{\"authorId\":\"118207278\",\"name\":\"Erlend Faxvaag\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"91aa1d0aa6d2283cdc1d5e468fb901211292d5cf\",\"title\":\"Fusion of LiDAR and Camera Images in End-to-end Deep Learning for Steering an Off-road Unmanned Ground Vehicle\",\"url\":\"https://www.semanticscholar.org/paper/91aa1d0aa6d2283cdc1d5e468fb901211292d5cf\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3021550\",\"name\":\"Jiachen Yang\"},{\"authorId\":\"2098545\",\"name\":\"Yinghao Zhu\"},{\"authorId\":\"2098946\",\"name\":\"Chaofan Ma\"},{\"authorId\":\"145440137\",\"name\":\"W. Lu\"},{\"authorId\":\"1686135\",\"name\":\"Q. Meng\"}],\"doi\":\"10.1016/j.neucom.2018.04.072\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2c568ce64c797af1a37327772c0282e15e61fb\",\"title\":\"Stereoscopic video quality assessment based on 3D convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/bf2c568ce64c797af1a37327772c0282e15e61fb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1109/WACV.2017.24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1a8686b5350c30205ee76d55629c4cfb218e2f6\",\"title\":\"On Geometric Features for Skeleton-Based Action Recognition Using Multilayer LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/e1a8686b5350c30205ee76d55629c4cfb218e2f6\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5d85a741f7926d8774e037c57a245ae6c94356\",\"title\":\"Online Action Detection in Untrimmed, Streaming Videos - Modeling and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/2d5d85a741f7926d8774e037c57a245ae6c94356\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.05790\",\"authors\":[{\"authorId\":\"36124320\",\"name\":\"Yan Zhang\"},{\"authorId\":\"47218017\",\"name\":\"H. Sun\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"597d62e665d5b3103b0b62c1c029b8fdc856cd67\",\"title\":\"Temporal Human Action Segmentation via Dynamic Clustering\",\"url\":\"https://www.semanticscholar.org/paper/597d62e665d5b3103b0b62c1c029b8fdc856cd67\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/ICASSP.2017.7952447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66f40e4ec173a2337fa42ff9d85c6e7a18ef16e1\",\"title\":\"Online action detection and forecast via Multitask deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/66f40e4ec173a2337fa42ff9d85c6e7a18ef16e1\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1922466081\",\"name\":\"Aayush Jain\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/ICSSIT48917.2020.9214153\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd0c68b39c353184077934b0726652a4dac44f97\",\"title\":\"Deep NeuralNet For Violence Detection Using Motion Features From Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/cd0c68b39c353184077934b0726652a4dac44f97\",\"venue\":\"2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"},{\"authorId\":\"152684187\",\"name\":\"Wei-Yun Yau\"},{\"authorId\":\"1714572\",\"name\":\"E. Teoh\"},{\"authorId\":\"1387241200\",\"name\":\"N. Magnenat-Thalmann\"}],\"doi\":\"10.1109/APSIPA.2017.8282038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13876f084198f182f4d031c4927585a3623a181f\",\"title\":\"Pose-invariant kinematic features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/13876f084198f182f4d031c4927585a3623a181f\",\"venue\":\"2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2017},{\"arxivId\":\"1810.09044\",\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1007/978-3-030-20887-5_28\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"title\":\"VIENA2: A Driving Anticipation Dataset\",\"url\":\"https://www.semanticscholar.org/paper/44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081808\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1801395\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9506707\",\"name\":\"Hangqi Yan\"},{\"authorId\":null,\"name\":\"Yifan Gao\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"}],\"doi\":\"10.1016/j.neucom.2018.02.070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e378342fce378ff314fc7377d3799ddc42183c3d\",\"title\":\"Salient object detection in hyperspectral imagery using multi-scale spectral-spatial gradient\",\"url\":\"https://www.semanticscholar.org/paper/e378342fce378ff314fc7377d3799ddc42183c3d\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"2011.07915\",\"authors\":[{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"144742695\",\"name\":\"D. Xu\"},{\"authorId\":\"1491152801\",\"name\":\"Jinhu Dong\"},{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"title\":\"LAP-Net: Adaptive Features Sampling via Learning Action Progression for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144466227\",\"name\":\"Q. Xia\"},{\"authorId\":\"145333125\",\"name\":\"P. Zhang\"},{\"authorId\":\"145210497\",\"name\":\"JingJing Wang\"},{\"authorId\":\"145095511\",\"name\":\"Ming Tian\"},{\"authorId\":\"16101332\",\"name\":\"C. Fei\"}],\"doi\":\"10.1007/978-3-319-97909-0_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89323a8dc46b0372e1667a05b84a351722120a6b\",\"title\":\"Real Time Violence Detection Based on Deep Spatio-Temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/89323a8dc46b0372e1667a05b84a351722120a6b\",\"venue\":\"CCBR\",\"year\":2018},{\"arxivId\":\"1811.12248\",\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.12.019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac360c948a81738b892869fafe950e05cf477618\",\"title\":\"Discovering Spatio-Temporal Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/ac360c948a81738b892869fafe950e05cf477618\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1904.13085\",\"authors\":[{\"authorId\":\"144766725\",\"name\":\"D. Wang\"},{\"authorId\":\"49521346\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2904857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"title\":\"Early Action Prediction With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117185645\",\"name\":\"Sen-Zhe Xu\"},{\"authorId\":\"1745787\",\"name\":\"J. Hu\"},{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"31471368\",\"name\":\"Tai-Jiang Mu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1111/cgf.13566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"title\":\"Deep Video Stabilization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018},{\"arxivId\":\"2002.05907\",\"authors\":[{\"authorId\":\"153108483\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"},{\"authorId\":\"10114692\",\"name\":\"Hong Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"title\":\"A Survey on 3D Skeleton-Based Action Recognition Using Learning Method\",\"url\":\"https://www.semanticscholar.org/paper/0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2012.02109\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72b19a0125ddda2752cfcf8c5758a13c52275665\",\"title\":\"SAFCAR: Structured Attention Fusion for Compositional Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b19a0125ddda2752cfcf8c5758a13c52275665\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"74530494\",\"name\":\"Nathan Schucher\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.23915/DISTILL.00011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee4df5b7d4b2af78dc593a34e3d8f4835e782370\",\"title\":\"Feature-wise transformations\",\"url\":\"https://www.semanticscholar.org/paper/ee4df5b7d4b2af78dc593a34e3d8f4835e782370\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.01984\",\"authors\":[{\"authorId\":\"48624955\",\"name\":\"Wei-Hong Li\"},{\"authorId\":\"9186191\",\"name\":\"B. Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/FG.2018.00042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e95e2dc37dc64906d9f9f18e3a461fc056ce398f\",\"title\":\"PersonRank: Detecting Important People in Images\",\"url\":\"https://www.semanticscholar.org/paper/e95e2dc37dc64906d9f9f18e3a461fc056ce398f\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chengjun Chen\"},{\"authorId\":\"1749704087\",\"name\":\"Tiannuo Wang\"},{\"authorId\":\"49620724\",\"name\":\"Dongnian Li\"},{\"authorId\":\"144705148\",\"name\":\"J. Hong\"}],\"doi\":\"10.1016/j.jmsy.2020.04.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"150063c773fefa6028bdd1302dd1205e4b525c8d\",\"title\":\"Repetitive assembly action recognition based on object detection and pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/150063c773fefa6028bdd1302dd1205e4b525c8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.09662\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3005508\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c075cfd9a4b300a3386eb0bcba2f940e72e84977\",\"title\":\"Biased Mixtures of Experts: Enabling Computer Vision Inference Under Data Transfer Limitations\",\"url\":\"https://www.semanticscholar.org/paper/c075cfd9a4b300a3386eb0bcba2f940e72e84977\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143715927\",\"name\":\"D. Liu\"},{\"authorId\":\"143715927\",\"name\":\"D. Liu\"},{\"authorId\":\"3470285\",\"name\":\"M. Oczak\"},{\"authorId\":\"3470169\",\"name\":\"K. Maschat\"},{\"authorId\":\"1471271517\",\"name\":\"J. Baumgartner\"},{\"authorId\":\"2023474587\",\"name\":\"Bernadette Pletzer\"},{\"authorId\":\"46566363\",\"name\":\"Dongjian He\"},{\"authorId\":\"143855369\",\"name\":\"T. Norton\"}],\"doi\":\"10.1016/j.biosystemseng.2020.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7316cd3ee2e46d254155ed3d5194c1a2f44c678b\",\"title\":\"A computer vision-based method for spatial-temporal action recognition of tail-biting behaviour in group-housed pigs\",\"url\":\"https://www.semanticscholar.org/paper/7316cd3ee2e46d254155ed3d5194c1a2f44c678b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"49185004\",\"name\":\"Shuhang Wang\"},{\"authorId\":\"46285365\",\"name\":\"Yifan Yang\"},{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"}],\"doi\":\"10.1007/s00138-018-0956-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"title\":\"End-to-end temporal attention extraction and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"title\":\"LSTM with Hand-crafted View-Invariant and Differential Cues (HVDC) for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1703.08338\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"Davide Moltisanti\"},{\"authorId\":\"1398236231\",\"name\":\"Walterio W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"Dima Damen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b408a3ca6fb39b0fda4d77e6a9679003b2dc9ab\",\"title\":\"Improving Classification by Improving Labelling: Introducing Probabilistic Multi-Label Object Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b408a3ca6fb39b0fda4d77e6a9679003b2dc9ab\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"49835905\",\"name\":\"Xuesong Jiang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1007/s11042-017-5038-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf784156547c3be146706e2763c1a52d939d1722\",\"title\":\"Breaking video into pieces for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf784156547c3be146706e2763c1a52d939d1722\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51295994\",\"name\":\"Ee Heng Chen\"},{\"authorId\":\"1791260\",\"name\":\"Darius Burschka\"}],\"doi\":\"10.1109/ICRA.2018.8462973\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33cd5da38a699142c1868f6e6e4080818897ff8b\",\"title\":\"Object-Centric Approach to Prediction and Labeling of Manipulation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/33cd5da38a699142c1868f6e6e4080818897ff8b\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22339495\",\"name\":\"Takamasa Tsunoda\"},{\"authorId\":\"36687978\",\"name\":\"Y. Komori\"},{\"authorId\":\"3241082\",\"name\":\"M. Matsugu\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPRW.2017.25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"95288fa7ff4683e32fe021a78cbf7d3376e6e400\",\"title\":\"Football Action Recognition Using Hierarchical LSTM\",\"url\":\"https://www.semanticscholar.org/paper/95288fa7ff4683e32fe021a78cbf7d3376e6e400\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"13941326\",\"name\":\"Fuxian Liu\"}],\"doi\":\"10.3390/rs10071158\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af672029a42f31665bfbc660ca209c2694a60706\",\"title\":\"Dense Connectivity Based Two-Stream Deep Feature Fusion Framework for Aerial Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/af672029a42f31665bfbc660ca209c2694a60706\",\"venue\":\"Remote. Sens.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47599321\",\"name\":\"Qian Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"title\":\"Zero-shot visual recognition via latent embedding learning\",\"url\":\"https://www.semanticscholar.org/paper/6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67055826\",\"name\":\"Renfei Sun\"},{\"authorId\":\"48708295\",\"name\":\"Z. Wang\"},{\"authorId\":\"153321393\",\"name\":\"K. E. Martens\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"}],\"doi\":\"10.1109/DICTA.2018.8615791\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22bce54fddaaf359f348badfb49b7a168ab53cc6\",\"title\":\"Convolutional 3D Attention Network for Video Based Freezing of Gait Recognition\",\"url\":\"https://www.semanticscholar.org/paper/22bce54fddaaf359f348badfb49b7a168ab53cc6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145031814\",\"name\":\"J. Walker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"title\":\"Data-Driven Visual Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.03308\",\"authors\":[{\"authorId\":\"51264689\",\"name\":\"S. Azar\"},{\"authorId\":\"51443392\",\"name\":\"Mina Ghadimi Atigh\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"}],\"doi\":\"10.1109/CVPR.2019.00808\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c147261ad2a359865d5780607816c05dc4b48b56\",\"title\":\"Convolutional Relational Machine for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c147261ad2a359865d5780607816c05dc4b48b56\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129493\",\"name\":\"Timur M. Bagautdinov\"}],\"doi\":\"10.5075/epfl-thesis-8680\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e586547a63400881c7a95d6ad6d5fa31ac237ca9\",\"title\":\"Variational Methods for Human Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e586547a63400881c7a95d6ad6d5fa31ac237ca9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"39271955\",\"name\":\"Zhiwen Fang\"}],\"doi\":\"10.1117/12.2285518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"title\":\"Action recognition in depth video from RGB perspective: A knowledge transfer manner\",\"url\":\"https://www.semanticscholar.org/paper/e145adff9d05a2eb636f633106f4ceab9bd1a62c\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.13245\",\"authors\":[{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"48570813\",\"name\":\"L. Zhang\"},{\"authorId\":\"49502400\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9775814d9454fb805e4f77ed357c6b237aec45e\",\"title\":\"Spatiotemporal Co-attention Recurrent Neural Networks for Human-Skeleton Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f9775814d9454fb805e4f77ed357c6b237aec45e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"Mahmoud Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Yanyan Yang\"},{\"authorId\":\"105033173\",\"name\":\"David Ndzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"title\":\"UWS Academic Portal Deep learning of fuzzy weighted multi-resolution depth motion maps with spatial feature fusion for action recognition Al-Faris,\",\"url\":\"https://www.semanticscholar.org/paper/728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500424473\",\"name\":\"Sadia Ilyas\"},{\"authorId\":\"1471459683\",\"name\":\"Hafeez Ur Rehman\"}],\"doi\":\"10.1109/ICET48972.2019.8994567\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db9b8afff5592b62829762879c35383337ebffba\",\"title\":\"A Deep Learning based Approach for Precise Video Tagging\",\"url\":\"https://www.semanticscholar.org/paper/db9b8afff5592b62829762879c35383337ebffba\",\"venue\":\"2019 15th International Conference on Emerging Technologies (ICET)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779835\",\"name\":\"Soon Ki Jung\"},{\"authorId\":\"145337089\",\"name\":\"Simone D. J. Barbosa\"},{\"authorId\":\"40913232\",\"name\":\"Phoebe Beverly Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"Krishna M. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"Dominik Slezak\"},{\"authorId\":\"1704749\",\"name\":\"Takashi Washio\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145078769\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1690892\",\"name\":\"Raquel Oliveira Prates\"},{\"authorId\":\"1744332\",\"name\":\"Wataru Ohyama\"}],\"doi\":\"10.1007/978-981-15-4818-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee18580b267693d8cf906d191f07d171248a588e\",\"title\":\"Frontiers of Computer Vision: 26th International Workshop, IW-FCV 2020, Ibusuki, Kagoshima, Japan, February 20\\u201322, 2020, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/ee18580b267693d8cf906d191f07d171248a588e\",\"venue\":\"IW-FCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"Srijan Das\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"Fran\\u00e7ois Br\\u00e9mond\"}],\"doi\":\"10.1145/3293353.3293376\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"631a704edb53b0a4b852421891172ff785879727\",\"title\":\"Spatio-Temporal Grids for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/631a704edb53b0a4b852421891172ff785879727\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1016/j.jvcir.2017.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"title\":\"A novel recurrent hybrid network for feature fusion in action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"1907.12919\",\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"152477216\",\"name\":\"P. Abreu\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"102c5f96b879de46921cfc1f589dbc364310cf54\",\"title\":\"Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/102c5f96b879de46921cfc1f589dbc364310cf54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8708983\",\"name\":\"Nour El Din Elmadany\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/TIP.2018.2855438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e28bb5189c06ac97cf2b7702dbdf0b4fece14da\",\"title\":\"Information Fusion for Human Action Recognition via Biset/Multiset Globality Locality Preserving Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3e28bb5189c06ac97cf2b7702dbdf0b4fece14da\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91755291\",\"name\":\"Y. Chen\"},{\"authorId\":\"153153980\",\"name\":\"Li Yu\"},{\"authorId\":\"144705313\",\"name\":\"K. Ota\"},{\"authorId\":\"1714082\",\"name\":\"M. Dong\"}],\"doi\":\"10.1109/TCSS.2019.2934639\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52d0e375a3f1eeac1b7e089d3e5805e5bc014818\",\"title\":\"Hierarchical Posture Representation for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/52d0e375a3f1eeac1b7e089d3e5805e5bc014818\",\"venue\":\"IEEE Transactions on Computational Social Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40145256\",\"name\":\"J. Lee\"},{\"authorId\":\"1862090\",\"name\":\"Ryan A. Rossi\"},{\"authorId\":\"1833914\",\"name\":\"Xiangnan Kong\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"47652687\",\"name\":\"A. Rao\"}],\"doi\":\"10.1145/3357384.3357880\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1fd81af050dbdc4232ff8b1ab71cf0973d530b6\",\"title\":\"Graph Convolutional Networks with Motif-based Attention\",\"url\":\"https://www.semanticscholar.org/paper/e1fd81af050dbdc4232ff8b1ab71cf0973d530b6\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40457242\",\"name\":\"Yu Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.5220/0007257803110318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1a55c7452bd65a989d22a766a26bac7b7fb7cc9\",\"title\":\"Supervised Spatial Transformer Networks for Attention Learning in Fine-grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1a55c7452bd65a989d22a766a26bac7b7fb7cc9\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/IPAS.2018.8708895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"title\":\"Analysis on Temporal Dimension of Inputs for 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430731\",\"name\":\"Adarsh Jamadandi\"},{\"authorId\":\"1584997238\",\"name\":\"Sunidhi Kotturshettar\"},{\"authorId\":\"2938896\",\"name\":\"U. Mudenagudi\"}],\"doi\":\"10.1007/978-981-13-9683-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db5f9852cbbd9dfdf8f1c4d5b8cb5f0ab715840c\",\"title\":\"Two Stream Convolutional Neural Networks for Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/db5f9852cbbd9dfdf8f1c4d5b8cb5f0ab715840c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145530174\",\"name\":\"Li Du\"},{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"},{\"authorId\":\"3268756\",\"name\":\"B. Zhuang\"},{\"authorId\":\"47195274\",\"name\":\"N. Boulgouris\"}],\"doi\":\"10.1109/TVT.2019.2905598\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c06c698de5ad3beadcc326adcdcf477253c0a44a\",\"title\":\"Adaptive Visual Interaction Based Multi-Target Future State Prediction For Autonomous Driving Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/c06c698de5ad3beadcc326adcdcf477253c0a44a\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2019},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3388571\",\"name\":\"L. Tiong\"},{\"authorId\":\"49899378\",\"name\":\"S. T. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1007/s11042-019-7618-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9a869f7f72c11daf14a5e700f9ba1fa1cef280e\",\"title\":\"Implementation of multimodal biometric recognition via multi-feature deep learning networks and feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/f9a869f7f72c11daf14a5e700f9ba1fa1cef280e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490897734\",\"name\":\"Zichun Dai\"},{\"authorId\":\"144972482\",\"name\":\"Chao Sun\"},{\"authorId\":\"38763335\",\"name\":\"Xinguo Yu\"},{\"authorId\":\"47063230\",\"name\":\"Ying Xiang\"}],\"doi\":\"10.1007/978-3-030-39770-8_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69126197beb19f64060dcc8ba1a61070cd3d41e8\",\"title\":\"Detecting Global Exam Events in Invigilation Videos Using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/69126197beb19f64060dcc8ba1a61070cd3d41e8\",\"venue\":\"PSIVT Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40257207\",\"name\":\"Jiyoung Lee\"},{\"authorId\":\"2352565\",\"name\":\"Sunok Kim\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1145/3264869.3264873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4147937489e94d2e7168146c28550b6a7ffd68a4\",\"title\":\"Audio-Visual Attention Networks for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4147937489e94d2e7168146c28550b6a7ffd68a4\",\"venue\":\"AVSU@MM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121030\",\"name\":\"Rajiv Singh\"},{\"authorId\":\"39727023\",\"name\":\"Swati Nigam\"}],\"doi\":\"10.1007/978-3-030-15887-3_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"title\":\"Deep Neural Networks for Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"venue\":\"Handbook of Multimedia Information Security\",\"year\":2019},{\"arxivId\":\"1804.06248\",\"authors\":[{\"authorId\":\"48169955\",\"name\":\"L. Wang\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"2858139\",\"name\":\"L. Yang\"},{\"authorId\":\"47827548\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"}],\"doi\":\"10.1007/978-3-030-01231-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f1afe81db19cc4a60d597f5480c9d8e9346f21e\",\"title\":\"PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities\",\"url\":\"https://www.semanticscholar.org/paper/8f1afe81db19cc4a60d597f5480c9d8e9346f21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.07203\",\"authors\":[{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1145/3240508.3240592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb285efdb73d57ab425fbbffc4327c4f1f441c85\",\"title\":\"Few-Shot Adaptation for Multimedia Semantic Indexing\",\"url\":\"https://www.semanticscholar.org/paper/eb285efdb73d57ab425fbbffc4327c4f1f441c85\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1612.06543\",\"authors\":[{\"authorId\":\"1736750\",\"name\":\"N. Martinel\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"1708507\",\"name\":\"C. Micheloni\"}],\"doi\":\"10.1109/WACV.2018.00068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeda0531681764381b4c8b9c139ade3200e7f5cf\",\"title\":\"Wide-Slice Residual Networks for Food Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aeda0531681764381b4c8b9c139ade3200e7f5cf\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"145684947\",\"name\":\"M. Yu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"}],\"doi\":\"10.1007/978-3-030-05716-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"title\":\"Action Recognition Using Visual Attention with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978827882\",\"name\":\"Dighanchal Banerjee\"},{\"authorId\":\"2528842\",\"name\":\"Smriti Rani\"},{\"authorId\":\"46572037\",\"name\":\"A. George\"},{\"authorId\":\"1477950964\",\"name\":\"Arijit Chowdhury\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"37840630\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"145622300\",\"name\":\"T. Chakravarty\"},{\"authorId\":\"47178669\",\"name\":\"A. Pal\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae872ebb4427e1d97672631f0caadc8799387faa\",\"title\":\"Application of Spiking Neural Networks for Action Recognition from Radar Data\",\"url\":\"https://www.semanticscholar.org/paper/ae872ebb4427e1d97672631f0caadc8799387faa\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005372\",\"name\":\"Abdourrahmane M. Atto\"},{\"authorId\":\"144373800\",\"name\":\"A. Benoit\"},{\"authorId\":\"47858467\",\"name\":\"P. Lambert\"}],\"doi\":\"10.1016/j.patcog.2020.107353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d767c20bd91fc785b170e271a15508f56ee92fc4\",\"title\":\"Timed-image based deep learning for action recognition in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/d767c20bd91fc785b170e271a15508f56ee92fc4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571637\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/TIP.2018.2866688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"title\":\"Learning Match Kernels on Grassmann Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2003.07514\",\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60e02426feb3ca9345659f54deaf5070110f530a\",\"title\":\"Predictively Encoded Graph Convolutional Network for Noise-Robust Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60e02426feb3ca9345659f54deaf5070110f530a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50188449\",\"name\":\"Xiangchun Yu\"},{\"authorId\":\"144904783\",\"name\":\"Z. Zhang\"},{\"authorId\":\"50789978\",\"name\":\"L. Wu\"},{\"authorId\":\"144052839\",\"name\":\"Wei Pang\"},{\"authorId\":\"2721051\",\"name\":\"Hechang Chen\"},{\"authorId\":\"1713578\",\"name\":\"Zhezhou Yu\"},{\"authorId\":\"143824908\",\"name\":\"B. Li\"}],\"doi\":\"10.1155/2020/9428612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d187e3302ba15757947148e37aaa035e9f66cbec\",\"title\":\"Deep Ensemble Learning for Human Action Recognition in Still Images\",\"url\":\"https://www.semanticscholar.org/paper/d187e3302ba15757947148e37aaa035e9f66cbec\",\"venue\":\"Complex.\",\"year\":2020},{\"arxivId\":\"2001.06769\",\"authors\":[{\"authorId\":\"151080964\",\"name\":\"Kaiyu Shan\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"},{\"authorId\":\"5744018\",\"name\":\"Z. Wang\"},{\"authorId\":\"47715977\",\"name\":\"Ting-Ting Liang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"},{\"authorId\":\"50581109\",\"name\":\"Y. Chen\"},{\"authorId\":\"1920864\",\"name\":\"Yangyan Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"title\":\"MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion\",\"url\":\"https://www.semanticscholar.org/paper/0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/TPAMI.2017.2723400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddef0c93cd9f604e5905b81dc56818a477f171e2\",\"title\":\"Bilinear Convolutional Neural Networks for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ddef0c93cd9f604e5905b81dc56818a477f171e2\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"2010.07217\",\"authors\":[{\"authorId\":\"2595119\",\"name\":\"X. Yang\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"af44b51ac01b2599961107a7a76a5892601c5f7c\",\"title\":\"Back to the Future: Cycle Encoding Prediction for Self-supervised Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/af44b51ac01b2599961107a7a76a5892601c5f7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00212\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"50753313\",\"name\":\"Minghui Yu\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1038/s42256-020-0168-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"title\":\"Complex sequential understanding through the awareness of spatial and temporal concepts\",\"url\":\"https://www.semanticscholar.org/paper/86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"2000194881\",\"name\":\"R. Zhang\"},{\"authorId\":\"47530538\",\"name\":\"G. Han\"},{\"authorId\":\"144202010\",\"name\":\"Ning Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1016/J.SYSARC.2020.101882\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ecda34f73c1512466b6441022f127be279a2288\",\"title\":\"Video action recognition with visual privacy protection based on compressed sensing\",\"url\":\"https://www.semanticscholar.org/paper/5ecda34f73c1512466b6441022f127be279a2288\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1790322\",\"name\":\"J. Liu\"},{\"authorId\":\"1865017658\",\"name\":\"Yongcheng Liu\"},{\"authorId\":null,\"name\":\"Ying Wang\"},{\"authorId\":\"1865840230\",\"name\":\"V\\u00e9ronique Prinet\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/cvpr42600.2020.00579\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d85a32fd41352918f8acadbb9bfb8825d02e6003\",\"title\":\"Decoupled Representation Learning for Skeleton-Based Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d85a32fd41352918f8acadbb9bfb8825d02e6003\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1874862797\",\"name\":\"Boge Wen\"},{\"authorId\":\"122665402\",\"name\":\"Siyuan Chen\"},{\"authorId\":\"3090858\",\"name\":\"Chenhui Shao\"}],\"doi\":\"10.1016/j.compind.2020.103255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"title\":\"Temporal action proposal for online driver action monitoring using Dilated Convolutional Temporal Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"venue\":\"Comput. Ind.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2902458\",\"name\":\"Sajith Kecheril Sadanandan\"},{\"authorId\":\"2926399\",\"name\":\"P. Ranefall\"},{\"authorId\":\"1705606\",\"name\":\"Carolina W\\u00e4hlby\"}],\"doi\":\"10.1007/978-3-319-46604-0_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e7d89cedf34613d1bcd0d04b0a6f6202f52a3a\",\"title\":\"Feature Augmented Deep Neural Networks for Segmentation of Cells\",\"url\":\"https://www.semanticscholar.org/paper/c0e7d89cedf34613d1bcd0d04b0a6f6202f52a3a\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1580441027\",\"name\":\"Aashish Dhakal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c942dcd29e3510246aea0dc25bc0a1fb9fa381ec\",\"title\":\"Political-advertisement video classification using deep learning methods\",\"url\":\"https://www.semanticscholar.org/paper/c942dcd29e3510246aea0dc25bc0a1fb9fa381ec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.06749\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89d7aa10ad97251089d0204916f784f137f3a1ec\",\"title\":\"Action Completion: A Temporal Model for Moment Detection\",\"url\":\"https://www.semanticscholar.org/paper/89d7aa10ad97251089d0204916f784f137f3a1ec\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1906.06813\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/WACV.2018.00045\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"title\":\"A Temporal Sequence Learning for Action Recognition and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1611.10195\",\"authors\":[{\"authorId\":\"12010968\",\"name\":\"G. Borghi\"},{\"authorId\":\"7662702\",\"name\":\"Marco Venturelli\"},{\"authorId\":\"1723285\",\"name\":\"R. Vezzani\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2017.583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17c8c5f9737644f853677615754063e3408ac8e7\",\"title\":\"POSEidon: Face-from-Depth for Driver Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/17c8c5f9737644f853677615754063e3408ac8e7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":null,\"name\":\"Yu WANG\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1587/transinf.2019edp7045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e1d13a84e105f9ce6e176d2ebf22e10c473bae5\",\"title\":\"Attention-Guided Spatial Transformer Networks for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e1d13a84e105f9ce6e176d2ebf22e10c473bae5\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39611591\",\"name\":\"Lucas Beyer\"},{\"authorId\":\"36665147\",\"name\":\"A. Hermans\"},{\"authorId\":\"2699877\",\"name\":\"T. Linder\"},{\"authorId\":\"1699080\",\"name\":\"K. Arras\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":\"10.1109/LRA.2018.2835510\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de766183e3d71db39682fdd2010b5492eb094103\",\"title\":\"Deep Person Detection in Two-Dimensional Range Data\",\"url\":\"https://www.semanticscholar.org/paper/de766183e3d71db39682fdd2010b5492eb094103\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"144805693\",\"name\":\"C. Kuo\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"103483753\",\"name\":\"Yu-Hung Liu\"},{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"1491078400\",\"name\":\"Zijun Li\"},{\"authorId\":\"121418048\",\"name\":\"J. Shen\"},{\"authorId\":\"1743408\",\"name\":\"L. Fu\"}],\"doi\":\"10.1109/IROS40897.2019.8968533\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f98c4ae113621fdddaf5321b6f2f22310698f994\",\"title\":\"ResFlow: Multi-tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/f98c4ae113621fdddaf5321b6f2f22310698f994\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50749347\",\"name\":\"Ahmad Saeed Mohammad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4a7f0044492b4f4b366e404961f1cebd78cca10\",\"title\":\"Multi-Modal Ocular Recognition in presence of occlusion in Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/a4a7f0044492b4f4b366e404961f1cebd78cca10\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.06644\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"50652944\",\"name\":\"Xiangyu Wei\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"title\":\"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40370451\",\"name\":\"H. Kim\"},{\"authorId\":\"10263579\",\"name\":\"Seokmok Park\"},{\"authorId\":\"1820264163\",\"name\":\"Hyeokjin Park\"},{\"authorId\":\"9238090\",\"name\":\"J. Paik\"}],\"doi\":\"10.3390/s20143894\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d76a567188604c227000de1d8e44fe64a176c654\",\"title\":\"Enhanced Action Recognition Using Multiple Stream Deep Learning with Optical Flow and Weighted Sum\",\"url\":\"https://www.semanticscholar.org/paper/d76a567188604c227000de1d8e44fe64a176c654\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1706.04122\",\"authors\":[{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76798bddd0f12ae03de26b7c7743c008d505215\",\"title\":\"Joint Max Margin and Semantic Features for Continuous Event Detection in Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/e76798bddd0f12ae03de26b7c7743c008d505215\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"48624966\",\"name\":\"Wei Li\"},{\"authorId\":\"15316116\",\"name\":\"J. Shao\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":null,\"name\":\"ByteDance AI Lab\"},{\"authorId\":\"46197004\",\"name\":\"S. Tong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec00a57820335f136efe96eada551fddb83cde08\",\"title\":\"Multiple Attempts for AVA-Kinetics challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/ec00a57820335f136efe96eada551fddb83cde08\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.06724\",\"authors\":[{\"authorId\":\"32082024\",\"name\":\"Ali Javidani\"},{\"authorId\":\"2757076\",\"name\":\"Ahmad Mahmoudi Aznaveh\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"075ec6ce86828da112558e4c73e7135e0a7a269f\",\"title\":\"Learning Representative Temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/075ec6ce86828da112558e4c73e7135e0a7a269f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921425\",\"name\":\"D. Thaker\"},{\"authorId\":\"46800227\",\"name\":\"K. Krishnakumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75768ff4129ca6cd122c5ca729e9cfc66cc798fe\",\"title\":\"k-Shot Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75768ff4129ca6cd122c5ca729e9cfc66cc798fe\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551536\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"title\":\"Enhanced Action Recognition With Visual Attribute-Augmented 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"1909.08287\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"1950475\",\"name\":\"Z. Lu\"},{\"authorId\":\"40448837\",\"name\":\"Jing Li\"},{\"authorId\":\"49876187\",\"name\":\"T. Yang\"},{\"authorId\":\"145670268\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/LSP.2018.2823910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98e098ba9ff98fc58f22fed6d3d8540116284b91\",\"title\":\"Global Temporal Representation Based CNNs for Infrared Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/98e098ba9ff98fc58f22fed6d3d8540116284b91\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":\"1809.06191\",\"authors\":[{\"authorId\":\"3422706\",\"name\":\"M. Aygun\"},{\"authorId\":\"51293746\",\"name\":\"Yusuf Huseyin cSahin\"},{\"authorId\":\"50372899\",\"name\":\"G. Unal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1701f10ddd819e317849b75fdd15c688ac2ef92\",\"title\":\"Multi Modal Convolutional Neural Networks for Brain Tumor Segmentation.\",\"url\":\"https://www.semanticscholar.org/paper/e1701f10ddd819e317849b75fdd15c688ac2ef92\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1804.06026\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1389036863\",\"name\":\"Jordan L. Boyd-Graber\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.18653/v1/N18-2120\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ee96dd7e3395d8a53d6d3ceb62593477a4e0fe1\",\"title\":\"Learning to Color from Language\",\"url\":\"https://www.semanticscholar.org/paper/5ee96dd7e3395d8a53d6d3ceb62593477a4e0fe1\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3053828\",\"name\":\"T. Ishihara\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1851536\",\"name\":\"C. Asakawa\"},{\"authorId\":\"145582886\",\"name\":\"M. Hirose\"}],\"doi\":\"10.1109/WACV.2018.00071\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f57d49927ab87653c20b1ed7bf8a0bedfa4cc350\",\"title\":\"Deep Radio-Visual Localization\",\"url\":\"https://www.semanticscholar.org/paper/f57d49927ab87653c20b1ed7bf8a0bedfa4cc350\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1904.06074\",\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Y. Yang\"},{\"authorId\":\"49152746\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.1007/s10044-020-00886-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c36c598afc9217b8e6f4da7601a9695bf2000fd\",\"title\":\"Multi-view region-adaptive multi-temporal DMM and RGB action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c36c598afc9217b8e6f4da7601a9695bf2000fd\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2020},{\"arxivId\":\"1706.00699\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"Alexander Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7577a1ddf9195513a5c976887ad806d1386bb1e9\",\"title\":\"Temporal Action Labeling using Action Sets\",\"url\":\"https://www.semanticscholar.org/paper/7577a1ddf9195513a5c976887ad806d1386bb1e9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47703700\",\"name\":\"Kun Hu\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"39145049\",\"name\":\"W. Wang\"},{\"authorId\":\"66155252\",\"name\":\"Kaylena A Ehgoetz Martens\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"},{\"authorId\":\"144119247\",\"name\":\"S. J. Lewis\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1109/TIP.2019.2946469\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf6a957eba57632f240cd3617bc6e88b51806403\",\"title\":\"Graph Sequence Recurrent Neural Network for Vision-Based Freezing of Gait Detection\",\"url\":\"https://www.semanticscholar.org/paper/bf6a957eba57632f240cd3617bc6e88b51806403\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"2366119\",\"name\":\"Weiqing Min\"},{\"authorId\":\"145790673\",\"name\":\"Y. Lyu\"},{\"authorId\":\"51225051\",\"name\":\"Linhu Liu\"}],\"doi\":\"10.1145/3391624\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"72488865f640b78a5f53b937699cf5eb5f1000c9\",\"title\":\"Few-shot Food Recognition via Multi-view Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/72488865f640b78a5f53b937699cf5eb5f1000c9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659108374\",\"name\":\"Filip Ilic\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"}],\"doi\":\"10.1109/WACV45572.2020.9093410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56858364c6287bc40b7ec1c9052e07604725716d\",\"title\":\"Representing Objects in Video as Space-Time Volumes by Combining Top-Down and Bottom-Up Processes\",\"url\":\"https://www.semanticscholar.org/paper/56858364c6287bc40b7ec1c9052e07604725716d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123482139\",\"name\":\"R. Singh\"},{\"authorId\":\"38825416\",\"name\":\"Jagwinder Kaur Dhillon\"},{\"authorId\":\"3016430\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s11042-018-6425-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fec13c887410dc27a2a16b058a0ea4d114f2d68\",\"title\":\"Depth based enlarged temporal dimension of 3D deep convolutional network for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/8fec13c887410dc27a2a16b058a0ea4d114f2d68\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997924\",\"name\":\"Samira Pouyanfar\"},{\"authorId\":\"145758552\",\"name\":\"S. Chen\"},{\"authorId\":\"144987531\",\"name\":\"M. Shyu\"}],\"doi\":\"10.1109/IRI.2018.00064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beb2f1a6f3f781443580ffec9161d9ce6852bf48\",\"title\":\"Deep Spatio-Temporal Representation Learning for Multi-Class Imbalanced Data Classification\",\"url\":\"https://www.semanticscholar.org/paper/beb2f1a6f3f781443580ffec9161d9ce6852bf48\",\"venue\":\"2018 IEEE International Conference on Information Reuse and Integration (IRI)\",\"year\":2018},{\"arxivId\":\"1703.10893\",\"authors\":[{\"authorId\":\"8726117\",\"name\":\"Jen-Cheng Hou\"},{\"authorId\":\"2426246\",\"name\":\"S. Wang\"},{\"authorId\":\"46329677\",\"name\":\"Ying-Hui Lai\"},{\"authorId\":\"145403933\",\"name\":\"Y. Tsao\"},{\"authorId\":\"144600098\",\"name\":\"Hsiu-Wen Chang\"},{\"authorId\":\"46506453\",\"name\":\"Hsin-Min Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58ba304ca0c37d94c7227feeeffb600a492d902\",\"title\":\"Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a58ba304ca0c37d94c7227feeeffb600a492d902\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88999446\",\"name\":\"Lovish Chum\"},{\"authorId\":\"37390198\",\"name\":\"A. Subramanian\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1007/s41745-019-0099-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"title\":\"Beyond Supervised Learning: A Computer Vision Perspective\",\"url\":\"https://www.semanticscholar.org/paper/d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"venue\":\"Journal of the Indian Institute of Science\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46889237\",\"name\":\"Aqing Yang\"},{\"authorId\":\"2001434\",\"name\":\"Huasheng Huang\"},{\"authorId\":\"46875450\",\"name\":\"Xunmu Zhu\"},{\"authorId\":\"1742989\",\"name\":\"X. Yang\"},{\"authorId\":\"49525049\",\"name\":\"Chen Peng-fei\"},{\"authorId\":\"2024192910\",\"name\":\"Li Shimei\"},{\"authorId\":\"3104125\",\"name\":\"Yueju Xue\"}],\"doi\":\"10.1016/J.BIOSYSTEMSENG.2018.09.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89761a091b1c7582b406d5741e9f50f7fd41395c\",\"title\":\"Automatic recognition of sow nursing behaviour using deep learning-based segmentation and spatial and temporal features\",\"url\":\"https://www.semanticscholar.org/paper/89761a091b1c7582b406d5741e9f50f7fd41395c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1712.01938\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2018.00556\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"title\":\"Learning Latent Super-Events to Detect Multiple Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.01171\",\"authors\":[{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"2064401\",\"name\":\"M. Molinier\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1016/j.isprsjprs.2018.01.023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76efb113cfae383020b449f807dd1047ff795432\",\"title\":\"Binary Patterns Encoded Convolutional Neural Networks for Texture Recognition and Remote Sensing Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/76efb113cfae383020b449f807dd1047ff795432\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1701.00599\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TMM.2017.2751969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1da240dd35a4923b623b7bae66b1b7f074890852\",\"title\":\"AENet: Learning Deep Audio Features for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1da240dd35a4923b623b7bae66b1b7f074890852\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1812.04429\",\"authors\":[{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"145091764\",\"name\":\"An Zhao\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"2259699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":\"10.1109/CVPR.2019.00799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ae43e25b04f5c35173b0bf490612015bd86c08f\",\"title\":\"Face-Focused Cross-Stream Network for Deception Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9ae43e25b04f5c35173b0bf490612015bd86c08f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.06879\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"144037701\",\"name\":\"Z. Yang\"},{\"authorId\":\"2842106\",\"name\":\"Jiaoyu He\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"3471034\",\"name\":\"Y. Xu\"},{\"authorId\":\"144983032\",\"name\":\"D. Xu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2912529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30e4e817459b0d032d11ae6759e717bc4213836b\",\"title\":\"Ontology-Based Global and Collective Motion Patterns for Event Classification in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/30e4e817459b0d032d11ae6759e717bc4213836b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"101386498\",\"name\":\"T. T. Ogunwa\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.1109/THMS.2020.2971958\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"title\":\"A Multiviewpoint Outdoor Dataset for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2020},{\"arxivId\":\"2007.10060\",\"authors\":[{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"46931357\",\"name\":\"Yunpeng Bai\"},{\"authorId\":\"47002010\",\"name\":\"Y. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"536e3311cc47a2c4b4d99b80bc27e4bca15e4732\",\"title\":\"Multispectral Pan-sharpening via Dual-Channel Convolutional Network with Convolutional LSTM Based Hierarchical Spatial-Spectral Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/536e3311cc47a2c4b4d99b80bc27e4bca15e4732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09883\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1768672172\",\"name\":\"Zhenyu Jiang\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"title\":\"Complementary Boundary Generator with Scale-Invariant Relation Modeling for Temporal Action Localization: Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.00781\",\"authors\":[{\"authorId\":\"2030527072\",\"name\":\"Anirudh Tunga\"},{\"authorId\":\"71070791\",\"name\":\"Sai Vidyaranya Nuthalapati\"},{\"authorId\":\"1768610\",\"name\":\"J. Wachs\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e0d7289231dc4b1cd822186690b426810da620b\",\"title\":\"Pose-based Sign Language Recognition using GCN and BERT\",\"url\":\"https://www.semanticscholar.org/paper/2e0d7289231dc4b1cd822186690b426810da620b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004905657\",\"name\":\"Rihem Mahmoud\"},{\"authorId\":\"1757886\",\"name\":\"S. Belgacem\"},{\"authorId\":\"3169159\",\"name\":\"M. Omri\"}],\"doi\":\"10.1016/j.jksuci.2020.08.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"title\":\"Deep Signature-based Isolated and Large Scale Continuous Gesture Recognition Approach\",\"url\":\"https://www.semanticscholar.org/paper/52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70441825\",\"name\":\"Preksha Pareek\"},{\"authorId\":\"2136673\",\"name\":\"A. Thakkar\"}],\"doi\":\"10.1007/S10462-020-09904-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d11a704eeae83031e6141f87412cfe9b5b1585e2\",\"title\":\"A survey on video-based Human Action Recognition: recent updates, datasets, challenges, and applications\",\"url\":\"https://www.semanticscholar.org/paper/d11a704eeae83031e6141f87412cfe9b5b1585e2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/DICTA.2017.8227417\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a240ef33c4b98fa8b8857100c53aeb03510f6e2\",\"title\":\"Collision Risk Rating of Traffic Scene from Dashboard Cameras\",\"url\":\"https://www.semanticscholar.org/paper/9a240ef33c4b98fa8b8857100c53aeb03510f6e2\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"50469612\",\"name\":\"Guangyu Guo\"},{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/CVPR.2018.00707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f8b1030baee3c1350662903d76510754793db83\",\"title\":\"PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0f8b1030baee3c1350662903d76510754793db83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2577842\",\"name\":\"R. An\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"50444385\",\"name\":\"Q. Li\"},{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49347106\",\"name\":\"Q. Zhang\"}],\"doi\":\"10.1117/1.JEI.28.2.023007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea9d0ab37fd0ab42ede12271a6eb1ff2eb55aab1\",\"title\":\"Spatiotemporal visual-semantic embedding network for zero-shot action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea9d0ab37fd0ab42ede12271a6eb1ff2eb55aab1\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767364\",\"name\":\"A. Amir\"},{\"authorId\":\"1736425\",\"name\":\"B. Taba\"},{\"authorId\":\"89761435\",\"name\":\"D. Berg\"},{\"authorId\":\"2555407\",\"name\":\"T. Melano\"},{\"authorId\":\"46571359\",\"name\":\"J. L. McKinstry\"},{\"authorId\":\"1894356\",\"name\":\"C. D. Nolfo\"},{\"authorId\":\"145185131\",\"name\":\"T. Nayak\"},{\"authorId\":\"2542089\",\"name\":\"Alexander Andreopoulos\"},{\"authorId\":\"3185763\",\"name\":\"G. Garreau\"},{\"authorId\":\"145048528\",\"name\":\"M. Mendoza\"},{\"authorId\":\"2082795\",\"name\":\"Jeffrey A. Kusnitz\"},{\"authorId\":\"1723845\",\"name\":\"M. DeBole\"},{\"authorId\":\"2357931\",\"name\":\"Steven K. Esser\"},{\"authorId\":\"1694635\",\"name\":\"T. Delbr\\u00fcck\"},{\"authorId\":\"1712991\",\"name\":\"M. Flickner\"},{\"authorId\":\"1944330\",\"name\":\"D. Modha\"}],\"doi\":\"10.1109/CVPR.2017.781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e5f6ff1971072530a8bc50036d7de5fc3e80f67\",\"title\":\"A Low Power, Fully Event-Based Gesture Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/1e5f6ff1971072530a8bc50036d7de5fc3e80f67\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.02031\",\"authors\":[{\"authorId\":\"1840108\",\"name\":\"J. Liu\"},{\"authorId\":\"1689230\",\"name\":\"Y. Yang\"},{\"authorId\":\"1798258\",\"name\":\"S. Jeng\"}],\"doi\":\"10.1109/TMM.2018.2871418\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e48c060d490a8bb2109a6b6f8340610d797b2b5\",\"title\":\"Weakly-Supervised Visual Instrument-Playing Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4e48c060d490a8bb2109a6b6f8340610d797b2b5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145742542\",\"name\":\"W. Li\"},{\"authorId\":\"144536247\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2018.2863943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd22e6532211f679ba6057d15a801ba448b9915c\",\"title\":\"Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/cd22e6532211f679ba6057d15a801ba448b9915c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a57c4e0db828710c6b6449598e6a3b471beaaf0\",\"title\":\"ProcNets: Learning to Segment Procedures in Untrimmed and Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/2a57c4e0db828710c6b6449598e6a3b471beaaf0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50394552\",\"name\":\"Rui Lu\"},{\"authorId\":\"72028302\",\"name\":\"Zhiyao Duan\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TASLP.2019.2928140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90f8b5d87c41230c691e6a243aef9d62063522b0\",\"title\":\"Audio\\u2013Visual Deep Clustering for Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/90f8b5d87c41230c691e6a243aef9d62063522b0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145791568\",\"name\":\"Y. Bo\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"},{\"authorId\":\"33276033\",\"name\":\"Jie Xiang\"}],\"doi\":\"10.1109/BigMM.2018.8499251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af13aae576f4d9ecc3de73a9ef8ff4396d057b8c\",\"title\":\"DVD: Constructing a Discriminative Video Descriptor by Convolving Frame Features\",\"url\":\"https://www.semanticscholar.org/paper/af13aae576f4d9ecc3de73a9ef8ff4396d057b8c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144682579\",\"name\":\"J. Carvajal\"}],\"doi\":\"10.14264/UQL.2016.1059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"efde9c76df694c1b9a47bb3e57eaa6e51c411609\",\"title\":\"Action analysis and video summarisation to efficiently manage and interpret video data\",\"url\":\"https://www.semanticscholar.org/paper/efde9c76df694c1b9a47bb3e57eaa6e51c411609\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1703.09026\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/iccv.2017.314\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"title\":\"Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":\"1803.10861\",\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"title\":\"Memory Warps for Learning Long-Term Online Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.02860\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f414a4f51748d548c2e72971f1e428ebb34754bd\",\"title\":\"Visual Attribute-augmented Three-dimensional Convolutional Neural Network for Enhanced Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f414a4f51748d548c2e72971f1e428ebb34754bd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.02964\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"3004751\",\"name\":\"Chongjing Wang\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-030-01225-0_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49e2b4db35a408e91353578764be9085ac1210da\",\"title\":\"BSN: Boundary Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/49e2b4db35a408e91353578764be9085ac1210da\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.13782\",\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29df95ddda4e52ada0564458fe6f438f462b5651\",\"title\":\"Knowledge Fusion Transformers for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29df95ddda4e52ada0564458fe6f438f462b5651\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.04237\",\"authors\":[{\"authorId\":\"153315956\",\"name\":\"Xiuheng Wang\"},{\"authorId\":\"46669153\",\"name\":\"J. Chen\"},{\"authorId\":\"1864127544\",\"name\":\"Qi Wei\"},{\"authorId\":\"145664778\",\"name\":\"C. Richard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2181c999b858c4f9faf89311094c8b6b4974c224\",\"title\":\"Hyperspectral Image Super-Resolution via Deep Prior Regularization with Parameter Estimation\",\"url\":\"https://www.semanticscholar.org/paper/2181c999b858c4f9faf89311094c8b6b4974c224\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.05112\",\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2017.2786999\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"title\":\"Video Classification With CNNs: Using the Codec as a Spatio-Temporal Activity Sensor\",\"url\":\"https://www.semanticscholar.org/paper/ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"}],\"doi\":\"10.1109/ICME.2018.8486452\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"title\":\"Temporal Attentive Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"47748577\",\"name\":\"C. Ouyang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1812.10786\",\"authors\":[{\"authorId\":\"29899438\",\"name\":\"Talha Ahmad Siddiqui\"},{\"authorId\":\"34173298\",\"name\":\"Samarth Bharadwaj\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac0f6e63cefbc5c9a3fba3f3166d6b3af83cfd03\",\"title\":\"Future semantic segmentation of time-lapsed videos with large temporal displacement\",\"url\":\"https://www.semanticscholar.org/paper/ac0f6e63cefbc5c9a3fba3f3166d6b3af83cfd03\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"Li Yao\"},{\"authorId\":\"144350546\",\"name\":\"Ying Qian\"}],\"doi\":\"10.1109/WACVW.2019.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f9a9031fdff486aac00815f83cf5a9cc5d7a392\",\"title\":\"Novel Activities Detection Algorithm in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/9f9a9031fdff486aac00815f83cf5a9cc5d7a392\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31672791\",\"name\":\"Erwin Wu\"},{\"authorId\":\"1684942\",\"name\":\"H. Koike\"}],\"doi\":\"10.1109/WACV.2019.00152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8f731b2ea17166b4176dcd1f2a4d03a014c50bd\",\"title\":\"FuturePose - Mixed Reality Martial Arts Training Using Real-Time 3D Human Pose Forecasting With a RGB Camera\",\"url\":\"https://www.semanticscholar.org/paper/d8f731b2ea17166b4176dcd1f2a4d03a014c50bd\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1905.06286\",\"authors\":[{\"authorId\":\"9739960\",\"name\":\"R. Gu\"},{\"authorId\":\"49387520\",\"name\":\"J. Wu\"},{\"authorId\":\"2213494\",\"name\":\"S. Zhang\"},{\"authorId\":\"92896134\",\"name\":\"Lianwu Chen\"},{\"authorId\":\"50126200\",\"name\":\"Y. Xu\"},{\"authorId\":\"143872260\",\"name\":\"M. Yu\"},{\"authorId\":\"144610227\",\"name\":\"Dan Su\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3db59f27e0e7ed0b4b70096cdc75759eff43462d\",\"title\":\"End-to-End Multi-Channel Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/3db59f27e0e7ed0b4b70096cdc75759eff43462d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10155\",\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"title\":\"Mobile Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97596665\",\"name\":\"Y. Liu\"},{\"authorId\":\"145338223\",\"name\":\"F. Yang\"},{\"authorId\":\"1873153\",\"name\":\"D. Ginhac\"}],\"doi\":\"10.1145/3349801.3349821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dd1565509362d0aef7db0a93bed20c422e3e818\",\"title\":\"Accurate Single-Stream Action Detection in Real-Time\",\"url\":\"https://www.semanticscholar.org/paper/8dd1565509362d0aef7db0a93bed20c422e3e818\",\"venue\":\"ICDSC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959138\",\"name\":\"Shibo Cai\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"2291937\",\"name\":\"Guanjun Bao\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":null,\"name\":\"Nannan Li\"}],\"doi\":\"10.1177/1729881416675137\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cf5cfe5654e7c3dd671f74f9be33cf5e9d2d8b65\",\"title\":\"Real-time running event detection via a community patrol robot\",\"url\":\"https://www.semanticscholar.org/paper/cf5cfe5654e7c3dd671f74f9be33cf5e9d2d8b65\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6152731\",\"name\":\"Wenhao Wang\"},{\"authorId\":\"144898651\",\"name\":\"Xiaobo Lu\"},{\"authorId\":\"1517229473\",\"name\":\"Pengguo Zhang\"},{\"authorId\":\"1515090731\",\"name\":\"Huibin Xie\"},{\"authorId\":\"35510153\",\"name\":\"W. Zeng\"}],\"doi\":\"10.1109/ICSAI48974.2019.9010589\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d30bf3296bafccf970b439a17027f10c72595c0\",\"title\":\"Driver Action Recognition Based on Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/7d30bf3296bafccf970b439a17027f10c72595c0\",\"venue\":\"2019 6th International Conference on Systems and Informatics (ICSAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"},{\"authorId\":\"20624177\",\"name\":\"F. Ziaeetabar\"},{\"authorId\":\"153091386\",\"name\":\"S. Pfeiffer\"},{\"authorId\":\"144108901\",\"name\":\"O. Kaya\"},{\"authorId\":\"1518685532\",\"name\":\"T. Kulvicius\"},{\"authorId\":\"152716499\",\"name\":\"M. Tamosiunaite\"}],\"doi\":\"10.1038/s41598-020-60923-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ca4989ac8316cfe0e243c7cd54f8a517f58aea0\",\"title\":\"Humans Predict Action using Grammar-like Structures\",\"url\":\"https://www.semanticscholar.org/paper/8ca4989ac8316cfe0e243c7cd54f8a517f58aea0\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392991300\",\"name\":\"Hans H\\u00f5rak\"}],\"doi\":\"10.3390/info10090269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e181a5c57c712abb311d1014d6338709d2abeea8\",\"title\":\"Computer Vision-Based Unobtrusive Physical Activity Monitoring in School by Room-Level Physical Activity Estimation: A Method Proposition\",\"url\":\"https://www.semanticscholar.org/paper/e181a5c57c712abb311d1014d6338709d2abeea8\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2443605\",\"name\":\"Deqiang Ouyang\"},{\"authorId\":\"48380035\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"}],\"doi\":\"10.1016/j.patrec.2018.05.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4963c9d2b56eafaa9c84dccabb97f0db28f19473\",\"title\":\"Video-based person re-identification via spatio-temporal attentional and two-stream fusion convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/4963c9d2b56eafaa9c84dccabb97f0db28f19473\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49b911544ebfca12bed8cbf09b4f48679a8a8ae2\",\"title\":\"Efficient Inference on Video, In Real-Time and At Scale\",\"url\":\"https://www.semanticscholar.org/paper/49b911544ebfca12bed8cbf09b4f48679a8a8ae2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.07711\",\"authors\":[{\"authorId\":\"1637242169\",\"name\":\"Guglielmo Camporese\"},{\"authorId\":\"29776698\",\"name\":\"Pasquale Coscia\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc24772bf84d9ff92166d8f228284c4079619ed0\",\"title\":\"Knowledge Distillation for Action Anticipation via Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/dc24772bf84d9ff92166d8f228284c4079619ed0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.06882\",\"authors\":[{\"authorId\":\"5954374\",\"name\":\"S. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"46174575\",\"name\":\"J. Choi\"}],\"doi\":\"10.1109/WACV.2019.00014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0426e75aca4177af6396561cfaf945fb22194ef2\",\"title\":\"Skeleton-Based Action Recognition of People Handling Objects\",\"url\":\"https://www.semanticscholar.org/paper/0426e75aca4177af6396561cfaf945fb22194ef2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9582233\",\"name\":\"Runnan Li\"},{\"authorId\":\"3860920\",\"name\":\"Zhiyong Wu\"},{\"authorId\":\"144202060\",\"name\":\"Jia Jia\"},{\"authorId\":\"50873936\",\"name\":\"Jingbei Li\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"145199941\",\"name\":\"H. Meng\"}],\"doi\":\"10.1145/3240508.3240575\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4621e8fd89bf87301aa3a440bcafd19579280326\",\"title\":\"Inferring User Emotive State Changes in Realistic Human-Computer Conversational Dialogs\",\"url\":\"https://www.semanticscholar.org/paper/4621e8fd89bf87301aa3a440bcafd19579280326\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1708.01204\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"3203099\",\"name\":\"Tavi Halperin\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/ICCVW.2017.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b598c73e9335277106fcb8acdad6cda227c6cdf\",\"title\":\"Improved Speech Reconstruction from Silent Video\",\"url\":\"https://www.semanticscholar.org/paper/2b598c73e9335277106fcb8acdad6cda227c6cdf\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/SMC.2018.00675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"title\":\"TSNet: Deep Network for Human Action Recognition in Hazy Videos\",\"url\":\"https://www.semanticscholar.org/paper/634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":\"1608.08851\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"title\":\"Efficient Two-Stream Motion and Appearance 3D CNNs for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730228\",\"name\":\"M. Liu\"},{\"authorId\":\"47781541\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1145/3347450.3357654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d062058cdef85163512c3984f0f1ba78f625582e\",\"title\":\"Deep Reinforcement Learning Visual-Text Attention for Multimodal Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d062058cdef85163512c3984f0f1ba78f625582e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19236985\",\"name\":\"Emel Boyaci\"},{\"authorId\":\"1700011\",\"name\":\"M. Sert\"}],\"doi\":\"10.1109/SIU.2017.7960515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a1f751b58e30a8bc43b31b75e48ed8cd7c471c3\",\"title\":\"Video classification based on ConvNet collaboration and feature selection\",\"url\":\"https://www.semanticscholar.org/paper/1a1f751b58e30a8bc43b31b75e48ed8cd7c471c3\",\"venue\":\"2017 25th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3388571\",\"name\":\"L. Tiong\"},{\"authorId\":\"49899378\",\"name\":\"S. T. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1016/j.imavis.2020.103977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f616f669a57de26a46a3c2a84fc745342d482869\",\"title\":\"Multimodal facial biometrics recognition: Dual-stream convolutional neural networks with multi-feature fusion layers\",\"url\":\"https://www.semanticscholar.org/paper/f616f669a57de26a46a3c2a84fc745342d482869\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"30477181\",\"name\":\"Yie-Tarng Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1007/978-3-030-58452-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f62e6f851da560037f1ed008d2eb51bb80f062\",\"title\":\"Empowering Relational Network by Self-attention Augmented Conditional Random Fields for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33f62e6f851da560037f1ed008d2eb51bb80f062\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1804.07187\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"41020760\",\"name\":\"Neslihan K\\u00f6se\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/CVPRW.2018.00284\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8829b95fcb8492c6fbb4a727ac6543932e5cc86\",\"title\":\"Motion Fused Frames: Data Level Fusion Strategy for Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8829b95fcb8492c6fbb4a727ac6543932e5cc86\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3130030\",\"name\":\"M. Farrajota\"},{\"authorId\":\"143955056\",\"name\":\"J. Rodrigues\"},{\"authorId\":\"1394604631\",\"name\":\"J. M. H. du Buf\"}],\"doi\":\"10.1007/s10044-018-0727-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b999364980e4c21d9c22cc5a9f14501432999ca4\",\"title\":\"Human action recognition in videos with articulated pose information by deep networks\",\"url\":\"https://www.semanticscholar.org/paper/b999364980e4c21d9c22cc5a9f14501432999ca4\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46324489\",\"name\":\"Qing Zhang\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"title\":\"Multi-scale Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27020162\",\"name\":\"Abolfazl Taghribi\"},{\"authorId\":\"2229535\",\"name\":\"A. Raie\"},{\"authorId\":\"145311269\",\"name\":\"M. Shalchian\"}],\"doi\":\"10.1109/IRANIANMVIP.2017.8342366\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"253fa75a9a9e64505950ef2bed5d650b07a09b08\",\"title\":\"A novel fast bio-inspired feature for motion estimation\",\"url\":\"https://www.semanticscholar.org/paper/253fa75a9a9e64505950ef2bed5d650b07a09b08\",\"venue\":\"2017 10th Iranian Conference on Machine Vision and Image Processing (MVIP)\",\"year\":2017},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.09955\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1109/TIP.2019.2925285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"title\":\"A Comparative Review of Recent Kinect-Based Action Recognition Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144259463\",\"name\":\"F. M. Noori\"},{\"authorId\":\"34662377\",\"name\":\"M. Riegler\"},{\"authorId\":\"3241032\",\"name\":\"M. Z. Uddin\"},{\"authorId\":\"70019186\",\"name\":\"Jim T\\u00f8rresen\"}],\"doi\":\"10.1145/3377882\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e0f25eca181a495e1bb8678865797b3b548814e\",\"title\":\"Human Activity Recognition from Multiple Sensors Data Using Multi-fusion Representations and CNNs\",\"url\":\"https://www.semanticscholar.org/paper/1e0f25eca181a495e1bb8678865797b3b548814e\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48475588\",\"name\":\"Y. Gu\"},{\"authorId\":\"47161996\",\"name\":\"Xiaofeng Ye\"},{\"authorId\":\"143891949\",\"name\":\"W. Sheng\"}],\"doi\":\"10.1109/WCICA.2018.8630370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc3e1420b468bafc8edd8f2da665a8613fc2912c\",\"title\":\"Depth MHI Based Deep Learning Model for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bc3e1420b468bafc8edd8f2da665a8613fc2912c\",\"venue\":\"2018 13th World Congress on Intelligent Control and Automation (WCICA)\",\"year\":2018},{\"arxivId\":\"2002.09423\",\"authors\":[{\"authorId\":\"31915818\",\"name\":\"D. Torpey\"},{\"authorId\":\"48627696\",\"name\":\"T. \\u00c7elik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e7f485a76d95127158683b7bbe386df98394f42\",\"title\":\"Human Action Recognition using Local Two-Stream Convolution Neural Network Features and Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/5e7f485a76d95127158683b7bbe386df98394f42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"1604959773\",\"name\":\"Yichu Liu\"}],\"doi\":\"10.1007/s11063-019-10091-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"title\":\"Action Recognition with Multiple Relative Descriptors of Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199572\",\"name\":\"Chenglong Li\"},{\"authorId\":\"3606633\",\"name\":\"Xiaohao Wu\"},{\"authorId\":\"32088472\",\"name\":\"Nan Zhao\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"}],\"doi\":\"10.1016/j.neucom.2017.11.068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11841185405c5d17e92110e5067b24e410d5c8de\",\"title\":\"Fusing two-stream convolutional neural networks for RGB-T object tracking\",\"url\":\"https://www.semanticscholar.org/paper/11841185405c5d17e92110e5067b24e410d5c8de\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1707.05357\",\"authors\":[{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"},{\"authorId\":\"22234092\",\"name\":\"Dhruv Singal\"},{\"authorId\":\"20400898\",\"name\":\"Harvineet Singh\"},{\"authorId\":\"3419748\",\"name\":\"Manav Kedia\"},{\"authorId\":\"37722215\",\"name\":\"Akhil Shetty\"}],\"doi\":\"10.1109/ICCVW.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21efd287c95b045d929761cbd7c35d331398df21\",\"title\":\"Show and Recall: Learning What Makes Videos Memorable\",\"url\":\"https://www.semanticscholar.org/paper/21efd287c95b045d929761cbd7c35d331398df21\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"144738967\",\"name\":\"S. Zhang\"},{\"authorId\":\"40617972\",\"name\":\"X. Wang\"},{\"authorId\":\"1990206\",\"name\":\"Yudi He\"},{\"authorId\":\"8531710\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-981-10-7305-2_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67bb1577b01522ef3c916728642fd78d354c0d72\",\"title\":\"Deep Key Frame Extraction for Sport Training\",\"url\":\"https://www.semanticscholar.org/paper/67bb1577b01522ef3c916728642fd78d354c0d72\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1710.06512\",\"authors\":[{\"authorId\":\"144339373\",\"name\":\"A. Sokolova\"},{\"authorId\":\"1934937\",\"name\":\"A. Konushin\"}],\"doi\":\"10.1049/iet-bmt.2018.5046\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61c29d9c49bd4104cfb9039e3f3d96f1695a894b\",\"title\":\"Pose-based Deep Gait Recognition\",\"url\":\"https://www.semanticscholar.org/paper/61c29d9c49bd4104cfb9039e3f3d96f1695a894b\",\"venue\":\"IET Biom.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.sigpro.2017.10.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778e6aee04548ec06a52fd3f6aff32074132abdd\",\"title\":\"Distinctive action sketch for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/778e6aee04548ec06a52fd3f6aff32074132abdd\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patrec.2018.03.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a04a58aad375de685526b2492bb6cf61e807ccde\",\"title\":\"Deep generative video prediction\",\"url\":\"https://www.semanticscholar.org/paper/a04a58aad375de685526b2492bb6cf61e807ccde\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2615568\",\"name\":\"Shao-nian Huang\"},{\"authorId\":\"2615568\",\"name\":\"Shao-nian Huang\"},{\"authorId\":\"2258587\",\"name\":\"D. Huang\"},{\"authorId\":\"1934264\",\"name\":\"X. Zhou\"}],\"doi\":\"10.1155/2018/6323942\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"803a984ab5cdbc2b4619b4b005687acf23cef98d\",\"title\":\"Learning Multimodal Deep Representations for Crowd Anomaly Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/803a984ab5cdbc2b4619b4b005687acf23cef98d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.00241\",\"authors\":[{\"authorId\":\"47287745\",\"name\":\"Ankit Shah\"},{\"authorId\":\"51434736\",\"name\":\"Harini Kesavamoorthy\"},{\"authorId\":\"51441023\",\"name\":\"Poorva Rane\"},{\"authorId\":\"1989712\",\"name\":\"Pramati Kalwad\"},{\"authorId\":\"7661726\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"1740721\",\"name\":\"Florian Metze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"72f4c415b5f3ecf63380b6985c95c5af2ba72632\",\"title\":\"Activity Recognition on a Large Scale in Short Videos - Moments in Time Dataset\",\"url\":\"https://www.semanticscholar.org/paper/72f4c415b5f3ecf63380b6985c95c5af2ba72632\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"},{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"46622630\",\"name\":\"C. Hu\"},{\"authorId\":\"47009372\",\"name\":\"Y. Ma\"},{\"authorId\":\"50062340\",\"name\":\"Zhiyuan Wu\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"79981257\",\"name\":\"Fuming Jia\"},{\"authorId\":\"143613123\",\"name\":\"C. Gong\"},{\"authorId\":\"3913152\",\"name\":\"Sen Wan\"},{\"authorId\":\"2863483\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/TNSRE.2018.2875738\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3e245a276cd6e5db0a42163a89915a1de80791e\",\"title\":\"Automatic Timed Up-and-Go Sub-Task Segmentation for Parkinson\\u2019s Disease Patients Using Video-Based Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/c3e245a276cd6e5db0a42163a89915a1de80791e\",\"venue\":\"IEEE Transactions on Neural Systems and Rehabilitation Engineering\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"title\":\"y 1 ? ? ? ? ? open jar scoop sugar ? ? ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"title\":\"Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units\",\"url\":\"https://www.semanticscholar.org/paper/2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145401272\",\"name\":\"Zhi Lu\"},{\"authorId\":\"1793858\",\"name\":\"Shiyin Qin\"},{\"authorId\":\"51489410\",\"name\":\"Xiaojie Li\"},{\"authorId\":\"151484259\",\"name\":\"Lianwei Li\"},{\"authorId\":\"151485199\",\"name\":\"Dinghao Zhang\"}],\"doi\":\"10.1007/s00138-019-01043-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a550eec016c93ab89167a3ffd11fd889cbffd706\",\"title\":\"One-shot learning hand gesture recognition based on modified 3d convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/a550eec016c93ab89167a3ffd11fd889cbffd706\",\"venue\":\"Machine Vision and Applications\",\"year\":2019},{\"arxivId\":\"1909.10695\",\"authors\":[{\"authorId\":\"51310352\",\"name\":\"Philipp V. Rouast\"},{\"authorId\":\"24235135\",\"name\":\"M. Adam\"}],\"doi\":\"10.1109/JBHI.2019.2942845\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"61b86a3b0c3dd290d2a6a67a335e4473ff69f92b\",\"title\":\"Learning Deep Representations for Video-Based Intake Gesture Detection\",\"url\":\"https://www.semanticscholar.org/paper/61b86a3b0c3dd290d2a6a67a335e4473ff69f92b\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990601\",\"name\":\"Hao Sun\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TGRS.2019.2931801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd6df50588d6c65c4dd9b95d85cba62d766a29f5\",\"title\":\"Remote Sensing Scene Classification by Gated Bidirectional Network\",\"url\":\"https://www.semanticscholar.org/paper/dd6df50588d6c65c4dd9b95d85cba62d766a29f5\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"144061516\",\"name\":\"L. Tao\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1109/WACV.2017.20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b3aaa685bcfe24081f33005b3be051f079a5411\",\"title\":\"Deep Moving Poselets for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3aaa685bcfe24081f33005b3be051f079a5411\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"2008.09228\",\"authors\":[{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"3428585\",\"name\":\"Chengqi Li\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24e0f42c1fb9d46f5381342139236647745c943\",\"title\":\"AWNet: Attentive Wavelet Network for Image ISP\",\"url\":\"https://www.semanticscholar.org/paper/c24e0f42c1fb9d46f5381342139236647745c943\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.11333\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-018-1120-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90f457c30a678ea879827b6d576ec4b97e404c28\",\"title\":\"Pointly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/90f457c30a678ea879827b6d576ec4b97e404c28\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50570717\",\"name\":\"M. Yuan\"},{\"authorId\":\"13800522\",\"name\":\"L. Zhang\"},{\"authorId\":\"27068208\",\"name\":\"Zheng-tao Wu\"},{\"authorId\":\"2131811\",\"name\":\"D. Zheng\"}],\"doi\":\"10.1109/IWQoS49365.2020.9212956\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae4d0accae0a556efcfd158273b40f5d4e0b7309\",\"title\":\"High-quality Activity-Level Video Advertising\",\"url\":\"https://www.semanticscholar.org/paper/ae4d0accae0a556efcfd158273b40f5d4e0b7309\",\"venue\":\"2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490866837\",\"name\":\"Chan Zheng\"},{\"authorId\":\"50030933\",\"name\":\"X. Yang\"},{\"authorId\":\"46875450\",\"name\":\"Xunmu Zhu\"},{\"authorId\":\"2023742062\",\"name\":\"Chen Changxin\"},{\"authorId\":\"49681427\",\"name\":\"L. Wang\"},{\"authorId\":\"41157630\",\"name\":\"Shuqin Tu\"},{\"authorId\":\"46889237\",\"name\":\"Aqing Yang\"},{\"authorId\":\"3104125\",\"name\":\"Yueju Xue\"}],\"doi\":\"10.1016/j.biosystemseng.2020.04.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"title\":\"Automatic posture change analysis of lactating sows by action localisation and tube optimisation from untrimmed depth videos\",\"url\":\"https://www.semanticscholar.org/paper/c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986765\",\"name\":\"Y. Gu\"},{\"authorId\":\"49353848\",\"name\":\"Meiqin Liu\"},{\"authorId\":\"46320777\",\"name\":\"Weihua Sheng\"},{\"authorId\":\"144897720\",\"name\":\"Yongsheng Ou\"},{\"authorId\":\"48514206\",\"name\":\"Y. Li\"}],\"doi\":\"10.1007/s10514-020-09943-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b40e9b64eed008384511a9f635b64e198b8d2369\",\"title\":\"Sensor fusion based manipulative action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b40e9b64eed008384511a9f635b64e198b8d2369\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20992076\",\"name\":\"Timothy Callemein\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"74922038\",\"name\":\"Floris De Feyter\"},{\"authorId\":\"73664580\",\"name\":\"Wim Boes\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2003472752\",\"name\":\"Tinne Tuytelaars\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1007/s11042-020-09616-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32921da55d7127169e901c4b3e5d6e2333185561\",\"title\":\"Show me where the action is!: Automatic capturing and timeline generation for reality TV.\",\"url\":\"https://www.semanticscholar.org/paper/32921da55d7127169e901c4b3e5d6e2333185561\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058862\",\"name\":\"L. Zhang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"153580417\",\"name\":\"M. Prakash\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1016/j.patcog.2020.107348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"title\":\"Few-shot activity recognition with cross-modal memory network\",\"url\":\"https://www.semanticscholar.org/paper/c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98523676\",\"name\":\"Herman Prawiro\"},{\"authorId\":\"152330682\",\"name\":\"Jianwei Peng\"},{\"authorId\":\"1471707097\",\"name\":\"Tse-Yu Pan\"},{\"authorId\":\"1384601232\",\"name\":\"Min-Chun Hu\"}],\"doi\":\"10.1109/ICMEW46912.2020.9105987\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02c7d1546d928cd153b0eee30d0735ad999b915e\",\"title\":\"Abnormal Event Detection in Surveillance Videos Using Two-Stream Decoder\",\"url\":\"https://www.semanticscholar.org/paper/02c7d1546d928cd153b0eee30d0735ad999b915e\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381769372\",\"name\":\"D. Srihari\"},{\"authorId\":\"144186025\",\"name\":\"P. Kishore\"},{\"authorId\":\"79324299\",\"name\":\"Kiran Kumar Eepuri\"},{\"authorId\":\"41212177\",\"name\":\"D. Kumar\"},{\"authorId\":\"48387925\",\"name\":\"Maddala Teja Kiran Kumar\"},{\"authorId\":\"1477672383\",\"name\":\"M. D. Prasad\"},{\"authorId\":\"9177966\",\"name\":\"C. R. Prasad\"}],\"doi\":\"10.1007/s11042-019-08588-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ba232488d9082c0f14bc568d42d5a44a4e867a1\",\"title\":\"A four-stream ConvNet based on spatial and depth flow for human action classification using RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/4ba232488d9082c0f14bc568d42d5a44a4e867a1\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2008.05732\",\"authors\":[{\"authorId\":\"2715566\",\"name\":\"K. Lai\"},{\"authorId\":\"1728290\",\"name\":\"S. Yanushkevich\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55255772dd2839674a4e5565a5b0c8676f714405\",\"title\":\"An Ensemble of Knowledge Sharing Models for Dynamic Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/55255772dd2839674a4e5565a5b0c8676f714405\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2019178\",\"name\":\"Y. Cho\"},{\"authorId\":\"1734661\",\"name\":\"S. Shin\"},{\"authorId\":\"11155836\",\"name\":\"Sung-Hyuk Yim\"},{\"authorId\":\"40692546\",\"name\":\"Kyeongbo Kong\"},{\"authorId\":\"49275485\",\"name\":\"Hyun-Woong Cho\"},{\"authorId\":\"3104882\",\"name\":\"Woo-Jin Song\"}],\"doi\":\"10.1109/ACCESS.2018.2885736\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bc2630ff97cd08a645ee8a08f7a48a260d2db5c\",\"title\":\"Multistage Fusion With Dissimilarity Regularization for SAR/IR Target Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3bc2630ff97cd08a645ee8a08f7a48a260d2db5c\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13250162\",\"name\":\"Qijun Tian\"},{\"authorId\":\"1735825\",\"name\":\"Shouhong Wan\"},{\"authorId\":\"8481239\",\"name\":\"P. Jin\"},{\"authorId\":\"33771136\",\"name\":\"J. Xu\"},{\"authorId\":\"145799156\",\"name\":\"Chang Zou\"},{\"authorId\":\"4123963\",\"name\":\"Xingyue Li\"}],\"doi\":\"10.1007/978-3-030-00776-8_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adea2d778eea4209bf05abf0492c9913c898ed2c\",\"title\":\"A Novel Feature Fusion with Self-adaptive Weight Method Based on Deep Learning for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/adea2d778eea4209bf05abf0492c9913c898ed2c\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3303577\",\"name\":\"Y. Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"}],\"doi\":\"10.1109/ICMEW.2017.8026246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f7094ba898a248e1e6b37e3d9fb795e59131cdc\",\"title\":\"Frame-skip Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f7094ba898a248e1e6b37e3d9fb795e59131cdc\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740590214\",\"name\":\"Mustansar Fiaz\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"1779835\",\"name\":\"S. K. Jung\"}],\"doi\":\"10.3390/s20144021\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fe233b41ddb40188187dc7c4122aa59f6809ae8\",\"title\":\"Learning Soft Mask Based Feature Fusion with Channel and Spatial Attention for Robust Visual Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/9fe233b41ddb40188187dc7c4122aa59f6809ae8\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1911.07757\",\"authors\":[{\"authorId\":\"67228021\",\"name\":\"Vivien Sainte Fare Garnot\"},{\"authorId\":\"115987954\",\"name\":\"Loic Landrieu\"},{\"authorId\":\"12465445\",\"name\":\"S. Giordano\"},{\"authorId\":\"2710204\",\"name\":\"Nesrine Chehata\"}],\"doi\":\"10.1109/cvpr42600.2020.01234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e32d1023b01e122cf4b00580b8b21782ab33455\",\"title\":\"Satellite Image Time Series Classification With Pixel-Set Encoders and Temporal Self-Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e32d1023b01e122cf4b00580b8b21782ab33455\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152473412\",\"name\":\"Jingye Zheng\"},{\"authorId\":\"67059036\",\"name\":\"Dihu Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2933360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8b63ee3f2c625ce2ccd848a535c8309c1e550b1\",\"title\":\"Multi-Scale Proposal Regression Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/f8b63ee3f2c625ce2ccd848a535c8309c1e550b1\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51208565\",\"name\":\"S. Cheng\"},{\"authorId\":\"92194342\",\"name\":\"Guoyi Qin\"},{\"authorId\":\"47320067\",\"name\":\"S. Li\"},{\"authorId\":\"144917416\",\"name\":\"M. Xie\"},{\"authorId\":\"1730232\",\"name\":\"Zheng Ma\"}],\"doi\":\"10.1109/ICCWAMTIP47768.2019.9067588\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04538c624c44c9735f519a411c95732cc638e469\",\"title\":\"VLAD-SSTA: VLAD with Soft Spatio-Temporal Assignment for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/04538c624c44c9735f519a411c95732cc638e469\",\"venue\":\"2019 16th International Computer Conference on Wavelet Active Media Technology and Information Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"},{\"authorId\":\"152994876\",\"name\":\"Yunfeng Ji\"},{\"authorId\":\"144560368\",\"name\":\"M. Ye\"},{\"authorId\":\"46636010\",\"name\":\"Y. Gan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2983355\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"title\":\"An Improved Attention-Based Spatiotemporal-Stream Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3794315\",\"name\":\"Yutong Cai\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":\"10.1109/VCIP.2018.8698676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e51635fe9554db3b10a262cc113c237ffcb759bf\",\"title\":\"Multi-scale Spatiotemporal Information Fusion Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e51635fe9554db3b10a262cc113c237ffcb759bf\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773194\",\"name\":\"Fei Pan\"},{\"authorId\":\"1720424\",\"name\":\"Y. Guo\"},{\"authorId\":\"151485208\",\"name\":\"Z. Yan\"},{\"authorId\":\"50115448\",\"name\":\"Jie Guo\"}],\"doi\":\"10.1109/ICME.2019.00283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"title\":\"Temporal Segment Convolutional Kernel Networks for Sequence Modeling of Videos\",\"url\":\"https://www.semanticscholar.org/paper/85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388559096\",\"name\":\"J. Paulo\"},{\"authorId\":\"7627107\",\"name\":\"P. Gir\\u00e3o\"},{\"authorId\":\"143696506\",\"name\":\"P. Peixoto\"}],\"doi\":\"10.1007/978-3-030-31635-8_205\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ef7db0c84f2dae52aa6329c72d09dc3b1b6c8d2\",\"title\":\"Multi-view Robust Gesture Recognition for Assistive Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/7ef7db0c84f2dae52aa6329c72d09dc3b1b6c8d2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29516300\",\"name\":\"V. O. Silva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5b9269c7499be1bf6d50678c2b06db648dbd283\",\"title\":\"Human action recognition in image sequences based on a two-stream convolutional neural network classifier\",\"url\":\"https://www.semanticscholar.org/paper/e5b9269c7499be1bf6d50678c2b06db648dbd283\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906550\",\"name\":\"Yanfeng Gu\"},{\"authorId\":\"1563987327\",\"name\":\"Tengfei Wang\"},{\"authorId\":\"47540712\",\"name\":\"Xudong Jin\"},{\"authorId\":\"1910913\",\"name\":\"Guoming Gao\"}],\"doi\":\"10.1109/TGRS.2020.2984656\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19c7d7842974c0a0ae43a346592266d036b360a6\",\"title\":\"Detection of Event of Interest for Satellite Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/19c7d7842974c0a0ae43a346592266d036b360a6\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741412659\",\"name\":\"Zhijian Liu\"},{\"authorId\":\"1617799530\",\"name\":\"Yi Han\"},{\"authorId\":\"153267954\",\"name\":\"Zhiwei Chen\"},{\"authorId\":\"83718004\",\"name\":\"Yuelong Fang\"},{\"authorId\":\"47151506\",\"name\":\"Huimin Qian\"},{\"authorId\":\"1491231425\",\"name\":\"Jun Zhou\"}],\"doi\":\"10.1007/978-981-15-8462-6_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f54aca3fdd41af5b266cb59ed3d8e800a2b1b41c\",\"title\":\"Human Activities Recognition from Videos Based on Compound Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/f54aca3fdd41af5b266cb59ed3d8e800a2b1b41c\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8207793\",\"name\":\"James P. Bohnslav\"},{\"authorId\":\"8419711\",\"name\":\"Nivanthika K Wimalasena\"},{\"authorId\":\"1945164690\",\"name\":\"Kelsey J Clausing\"},{\"authorId\":\"1976696822\",\"name\":\"David Yarmolinksy\"},{\"authorId\":\"144998880\",\"name\":\"T. Cruz\"},{\"authorId\":\"71489902\",\"name\":\"Eugenia Chiappe\"},{\"authorId\":\"48926043\",\"name\":\"Lauren L. Orefice\"},{\"authorId\":\"3824034\",\"name\":\"C. Woolf\"},{\"authorId\":\"3966889\",\"name\":\"C. Harvey\"}],\"doi\":\"10.1101/2020.09.24.312504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ddfc8674186fdf356ccc2bd030e187ba5232682\",\"title\":\"DeepEthogram: a machine learning pipeline for supervised behavior classification from raw pixels\",\"url\":\"https://www.semanticscholar.org/paper/5ddfc8674186fdf356ccc2bd030e187ba5232682\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.06809\",\"authors\":[{\"authorId\":\"9435157\",\"name\":\"Ehsan Asali\"},{\"authorId\":\"1646641382\",\"name\":\"Farzan Shenavarmasouleh\"},{\"authorId\":\"3261667\",\"name\":\"F. Mohammadi\"},{\"authorId\":\"153046351\",\"name\":\"P. Suresh\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eda77ac0d52cd89a49e03081832765fccd8a228\",\"title\":\"DeepMSRF: A novel Deep Multimodal Speaker Recognition framework with Feature selection\",\"url\":\"https://www.semanticscholar.org/paper/8eda77ac0d52cd89a49e03081832765fccd8a228\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08670\",\"authors\":[{\"authorId\":\"31469067\",\"name\":\"Jia-Ming Wang\"},{\"authorId\":\"153140559\",\"name\":\"Jun Du\"},{\"authorId\":\"47539230\",\"name\":\"Jian-Shu Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"533b40bdeed5539703163ef77faddc1a96639d91\",\"title\":\"Stroke Constrained Attention Network for Online Handwritten Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/533b40bdeed5539703163ef77faddc1a96639d91\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.03266\",\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":\"10.1109/WACV45572.2020.9093283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.11476\",\"authors\":[{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":\"10.1109/cvpr42600.2020.00658\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"title\":\"Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/VCIP47243.2019.8965878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"title\":\"A Spatio-temporal Hybrid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49658876\",\"name\":\"Z. Zhu\"},{\"authorId\":\"153172093\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"73312165\",\"name\":\"Wen-bo Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.12.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"title\":\"Nonlinear gated channels networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1708.09825\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCVW.2017.307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56426f6b86276b577f3d49c97189f609490022a0\",\"title\":\"Inferring Human Activities Using Robust Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/56426f6b86276b577f3d49c97189f609490022a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430959\",\"name\":\"Wenyan Bi\"},{\"authorId\":\"50820195\",\"name\":\"Peiran Jin\"},{\"authorId\":\"4314957\",\"name\":\"H. Nienborg\"},{\"authorId\":\"38829969\",\"name\":\"Bei Xiao\"}],\"doi\":\"10.1167/18.5.12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa822f445f04ec456c3cf283bc15f0a1b03c5ad5\",\"title\":\"Estimating mechanical properties of cloth from videos using dense motion trajectories: Human psychophysics and machine learning.\",\"url\":\"https://www.semanticscholar.org/paper/aa822f445f04ec456c3cf283bc15f0a1b03c5ad5\",\"venue\":\"Journal of vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904901470\",\"name\":\"Chengfeng Dou\"},{\"authorId\":\"151490870\",\"name\":\"Shikun Zhang\"},{\"authorId\":\"7643704\",\"name\":\"Hanping Wang\"},{\"authorId\":\"144622635\",\"name\":\"L. Sun\"},{\"authorId\":\"153268490\",\"name\":\"Yu-long Huang\"},{\"authorId\":\"35481850\",\"name\":\"W. Yue\"}],\"doi\":\"10.1016/j.sysarc.2020.101834\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59359e6f7d27b8b8afea1ba20d4762d677991558\",\"title\":\"ADHD fMRI short-time analysis method for edge computing based on multi-instance learning\",\"url\":\"https://www.semanticscholar.org/paper/59359e6f7d27b8b8afea1ba20d4762d677991558\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2205770\",\"name\":\"Tackgeun You\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1007/978-3-030-58571-6_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39fad4820b9a1d5186c915e171e8ef307f6ef98d\",\"title\":\"Traffic Accident Benchmark for Causality Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39fad4820b9a1d5186c915e171e8ef307f6ef98d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICASSP.2019.8683606\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"750c885ee644cb19d89f52ab31639f56254273a2\",\"title\":\"Neuromorphic Vision Sensing for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/750c885ee644cb19d89f52ab31639f56254273a2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2216476\",\"name\":\"Y. Cai\"},{\"authorId\":\"120519597\",\"name\":\"Xinran Kong\"},{\"authorId\":\"4042796\",\"name\":\"Xueyan Wang\"}],\"doi\":\"10.1145/3278198.3278224\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9cc255a1de58a91dc3156c825d0afa3bb36cb281\",\"title\":\"Temporal Action Detection with Long Action Seam Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/9cc255a1de58a91dc3156c825d0afa3bb36cb281\",\"venue\":\"ICBEB 2018\",\"year\":2018},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50462030\",\"name\":\"B. Chen\"},{\"authorId\":\"3110318\",\"name\":\"Chunsheng Hua\"},{\"authorId\":\"102448261\",\"name\":\"D. He\"},{\"authorId\":\"66686037\",\"name\":\"Jianda Han\"}],\"doi\":\"10.3390/APP9163277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b360ae0a87985b4dcae7c5feb88d56a4f52fc6d\",\"title\":\"Intelligent Human\\u2013UAV Interaction System with Joint Cross-Validation over Action\\u2013Gesture Recognition and Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/2b360ae0a87985b4dcae7c5feb88d56a4f52fc6d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"144129720\",\"name\":\"Xiao Wang\"},{\"authorId\":\"145473096\",\"name\":\"Yu Zheng\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/ICPR.2018.8545513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"288db6d3369ddb6aba5d753e0a46ee32e2383bcd\",\"title\":\"From Text to Video: Exploiting Mid-Level Semantics for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/288db6d3369ddb6aba5d753e0a46ee32e2383bcd\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718226\",\"name\":\"C. Li\"},{\"authorId\":\"3128157\",\"name\":\"Ruofeng Tong\"},{\"authorId\":\"50627816\",\"name\":\"Min Tang\"}],\"doi\":\"10.1007/S13369-018-3189-Z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0b7c8345d065f7326f3835fe022e43d020ce050\",\"title\":\"Modelling Human Body Pose for Action Recognition Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0b7c8345d065f7326f3835fe022e43d020ce050\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36124320\",\"name\":\"Yan Zhang\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47218017\",\"name\":\"H. Sun\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f688c91d2a41df93145f7467fd8187b85c94745a\",\"title\":\"Human Motion Parsing by Hierarchical Dynamic Clustering\",\"url\":\"https://www.semanticscholar.org/paper/f688c91d2a41df93145f7467fd8187b85c94745a\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCVW.2017.280\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"title\":\"How Shall We Evaluate Egocentric Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153008120\",\"name\":\"Zineng Xu\"},{\"authorId\":\"1798046\",\"name\":\"Ver\\u00f3nica Vilaplana\"},{\"authorId\":\"2585946\",\"name\":\"J. R. Morros\"}],\"doi\":\"10.1109/CBMI.2018.8516450\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"084a5a1699ab799517baa316bc4c8d0754b145a9\",\"title\":\"Action Tube Extraction Based 3D-CNN for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/084a5a1699ab799517baa316bc4c8d0754b145a9\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":\"1909.03466\",\"authors\":[{\"authorId\":\"14370059\",\"name\":\"M. U. Khalid\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/ICPR.2018.8546131\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"59478365451b82f5227bc4b694a2ff319025cc33\",\"title\":\"Multi-Modal Three-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/59478365451b82f5227bc4b694a2ff319025cc33\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49394516\",\"name\":\"J. Xu\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1796620\",\"name\":\"H. Yanagihara\"}],\"doi\":\"10.1109/ICPR.2018.8546165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0920e6a665c9b99fcc2ea1a06ff93673c3fd041d\",\"title\":\"Beyond Two-stream: Skeleton-based Three-stream Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0920e6a665c9b99fcc2ea1a06ff93673c3fd041d\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"},{\"authorId\":\"6881850\",\"name\":\"S. Oikawa\"},{\"authorId\":\"1720770\",\"name\":\"Y. Matsui\"}],\"doi\":\"10.3390/s18020627\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e0d878cc095eaae220ad1f681b33d7d61eb5e425\",\"title\":\"Temporal and Fine-Grained Pedestrian Action Recognition on Driving Recorder Database\",\"url\":\"https://www.semanticscholar.org/paper/e0d878cc095eaae220ad1f681b33d7d61eb5e425\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74872156\",\"name\":\"Johann Dirdal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cd165288beca818d49ba32e0734a9dfc5ef76d7\",\"title\":\"End-to-end learning and sensor fusion with deep convolutional networks for steering an off-road unmanned ground vehicle\",\"url\":\"https://www.semanticscholar.org/paper/1cd165288beca818d49ba32e0734a9dfc5ef76d7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.04689\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.01015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"title\":\"Action Recognition From Single Timestamp Supervision in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1903.09616\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"title\":\"On the Importance of Video Action Recognition for Visual Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.09165\",\"authors\":[{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"3235234\",\"name\":\"Mengyuan Yan\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/ICCV.2019.00934\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b653666bfda393adbc765fc5cac8a3a6b0cdf54\",\"title\":\"MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences\",\"url\":\"https://www.semanticscholar.org/paper/1b653666bfda393adbc765fc5cac8a3a6b0cdf54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1609.01693\",\"authors\":[{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-319-49409-8_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20f5be36bf8347276130eb5764fd3c0e7b99240d\",\"title\":\"Making a Case for Learning Motion Representations with Phase\",\"url\":\"https://www.semanticscholar.org/paper/20f5be36bf8347276130eb5764fd3c0e7b99240d\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1803.08834\",\"authors\":[{\"authorId\":\"3314448\",\"name\":\"Isma Hadji\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"title\":\"What Do We Understand About Convolutional Networks?\",\"url\":\"https://www.semanticscholar.org/paper/5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.13607\",\"authors\":[{\"authorId\":\"119413444\",\"name\":\"G. Storey\"},{\"authorId\":\"144725605\",\"name\":\"R. Jiang\"},{\"authorId\":\"32676664\",\"name\":\"Shelagh Keogh\"},{\"authorId\":\"1690116\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/ACCESS.2019.2937285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"title\":\"3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework Using Fully 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866136\",\"name\":\"Eralda Nishani\"},{\"authorId\":\"20577673\",\"name\":\"B. Cico\"}],\"doi\":\"10.1109/MECO.2017.7977207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"740d4a7322eec687d1e6f0d2b71fe2d804e1ae70\",\"title\":\"Computer vision approaches based on deep learning and neural networks: Deep neural networks for video analysis of human pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/740d4a7322eec687d1e6f0d2b71fe2d804e1ae70\",\"venue\":\"2017 6th Mediterranean Conference on Embedded Computing (MECO)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13c7a20098b4818087c4c51adaf74c377ac0e2bf\",\"title\":\"Sentences in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/13c7a20098b4818087c4c51adaf74c377ac0e2bf\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47952527\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"40165419\",\"name\":\"M. Jaber\"},{\"authorId\":\"1694755\",\"name\":\"P. Tsakalides\"}],\"doi\":\"10.2352/ISSN.2470-1173.2017.16.CVAS-344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b515cc19bd8fed04bea6ea152f284525671f60\",\"title\":\"Goal!! Event detection in sports video\",\"url\":\"https://www.semanticscholar.org/paper/30b515cc19bd8fed04bea6ea152f284525671f60\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48321132\",\"name\":\"Y. Zou\"},{\"authorId\":\"9641665\",\"name\":\"X. Ren\"}],\"doi\":\"10.1007/978-981-15-8458-9_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"title\":\"An Efficient Action Recognition Framework Based on ELM and 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/S12652-019-01239-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca3d26b3139d8f3db2e7f37c64d18e3cde27f322\",\"title\":\"Evaluating fusion of RGB-D and inertial sensors for multimodal human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca3d26b3139d8f3db2e7f37c64d18e3cde27f322\",\"venue\":\"J. Ambient Intell. Humaniz. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1016/J.JVCIR.2019.102596\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"title\":\"Magnitude-Orientation Stream network and depth information applied to activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1712.08416\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2699340\",\"name\":\"Yiyi Liao\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"150013821\",\"name\":\"A. Geiger\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"title\":\"On the Integration of Optical Flow and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":\"1801.10304\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICPR.2018.8546012\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"title\":\"Action Recognition with Visual Attention on Skeleton Images\",\"url\":\"https://www.semanticscholar.org/paper/e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744456\",\"name\":\"D. Hulens\"},{\"authorId\":\"3449009\",\"name\":\"Bram Aerts\"},{\"authorId\":\"1846419\",\"name\":\"P. Chakravarty\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"19233388\",\"name\":\"J. Zegers\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2246565\",\"name\":\"Joost Vennekens\"}],\"doi\":\"10.1007/978-3-319-73603-7_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"539ca4a74e5791f78e56843e0db58f2f9e128710\",\"title\":\"The CAMETRON Lecture Recording System: High Quality Video Recording and Editing with Minimal Human Supervision\",\"url\":\"https://www.semanticscholar.org/paper/539ca4a74e5791f78e56843e0db58f2f9e128710\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":\"1809.01372\",\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":\"2063358\",\"name\":\"Senzhe Xu\"},{\"authorId\":\"15996814\",\"name\":\"Junxiong Cai\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144110127\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TIP.2019.2925550\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14d1e3c6405ed22d30d88d577275233cca89d3a0\",\"title\":\"Temporally Coherent Video Harmonization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/14d1e3c6405ed22d30d88d577275233cca89d3a0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1807.02929\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"title\":\"Step-by-step Erasion, One-by-one Collection: A Weakly Supervised Temporal Action Detector\",\"url\":\"https://www.semanticscholar.org/paper/d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001082\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"1755153\",\"name\":\"N. M. Charkari\"}],\"doi\":\"10.1049/iet-cvi.2016.0355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"title\":\"Survey on deep learning methods in human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2698357\",\"name\":\"Kailing Guo\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TSP.2017.2684746\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2729e12ecb777a553e5ed0a1ac52dd37924e813d\",\"title\":\"Discriminative GoDec+ for Classification\",\"url\":\"https://www.semanticscholar.org/paper/2729e12ecb777a553e5ed0a1ac52dd37924e813d\",\"venue\":\"IEEE Transactions on Signal Processing\",\"year\":2017},{\"arxivId\":\"2009.02650\",\"authors\":[{\"authorId\":\"50419112\",\"name\":\"Chaoxing Huang\"},{\"authorId\":\"1932574\",\"name\":\"Xuanying Zhu\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1007/978-3-030-63830-6_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ef2570d340d730b5aa90d84a290c9a9c93369e2\",\"title\":\"A Genetic Feature Selection Based Two-stream Neural Network for Anger Veracity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ef2570d340d730b5aa90d84a290c9a9c93369e2\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b217f438697476c3fbffd3f1595c17fd05ee89\",\"title\":\"Adapting computer vision models to limitations on input dimensionality and model complexity\",\"url\":\"https://www.semanticscholar.org/paper/38b217f438697476c3fbffd3f1595c17fd05ee89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36972849\",\"name\":\"Shun Shibata\"},{\"authorId\":\"3015832\",\"name\":\"Y. Kaneda\"},{\"authorId\":\"1714824\",\"name\":\"H. Mineno\"}],\"doi\":\"10.1007/978-3-319-65172-9_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21615bb6b945a43c08055f51567be44281dc57f5\",\"title\":\"Motion-Specialized Deep Convolutional Descriptor for Plant Water Stress Estimation\",\"url\":\"https://www.semanticscholar.org/paper/21615bb6b945a43c08055f51567be44281dc57f5\",\"venue\":\"EANN\",\"year\":2017},{\"arxivId\":\"1804.03247\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2018.00226\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7404a8d77ba515633b61c68164210d3422d0aaf0\",\"title\":\"Fine-Grained Activity Recognition in Baseball Videos\",\"url\":\"https://www.semanticscholar.org/paper/7404a8d77ba515633b61c68164210d3422d0aaf0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51111081\",\"name\":\"L. Xie\"},{\"authorId\":\"145756137\",\"name\":\"X. Xiang\"},{\"authorId\":\"6347924\",\"name\":\"Huining Xu\"},{\"authorId\":\"95266097\",\"name\":\"L. Wang\"},{\"authorId\":\"47966286\",\"name\":\"L. Lin\"},{\"authorId\":\"39424012\",\"name\":\"Guofu Yin\"}],\"doi\":\"10.1109/TIE.2020.2982115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04a420199b43f5ecdc703aa4e661af802c706218\",\"title\":\"FFCNN: A Deep Neural Network for Surface Defect Detection of Magnetic Tile\",\"url\":\"https://www.semanticscholar.org/paper/04a420199b43f5ecdc703aa4e661af802c706218\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145144953\",\"name\":\"Zhen Qin\"},{\"authorId\":\"48380268\",\"name\":\"Y. Zhang\"},{\"authorId\":\"104451417\",\"name\":\"Shuyu Meng\"},{\"authorId\":\"7477697\",\"name\":\"Zhiguang Qin\"},{\"authorId\":\"2840539\",\"name\":\"Kim-Kwang Raymond Choo\"}],\"doi\":\"10.1016/j.inffus.2019.06.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adad4f22adb80299a2e2057c39e0364726fad6f8\",\"title\":\"Imaging and fusing time series for wearable sensor-based human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/adad4f22adb80299a2e2057c39e0364726fad6f8\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37614515\",\"name\":\"J. Duan\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"145182505\",\"name\":\"Shuai Zhou\"},{\"authorId\":\"3315491\",\"name\":\"Xiaoyuan Guo\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1145/3131343\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6f5461679e7caa7841a5e1d369f5c2aa86ff83af\",\"title\":\"A Unified Framework for Multi-Modal Isolated Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5461679e7caa7841a5e1d369f5c2aa86ff83af\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"1766722\",\"name\":\"Y. Ge\"},{\"authorId\":\"107836313\",\"name\":\"Liuwei Zhan\"},{\"authorId\":\"107717257\",\"name\":\"Guangrui Li\"},{\"authorId\":\"1786011\",\"name\":\"Sheng Huang\"},{\"authorId\":\"19226165\",\"name\":\"Hongxing Wang\"},{\"authorId\":\"47591280\",\"name\":\"Feiyu Chen\"}],\"doi\":\"10.1109/VCIP.2018.8698624\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"324f081aa68b93468de13c4c799377d6ab18b37b\",\"title\":\"Joint Deep Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/324f081aa68b93468de13c4c799377d6ab18b37b\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2577842\",\"name\":\"R. An\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"50444385\",\"name\":\"Q. Li\"}],\"doi\":\"10.1109/ICSP.2018.8652415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"751df4b242cddabdf9c4a542de15e90e79036ce9\",\"title\":\"Joint Embedding with Multi-Task Learning for Multi-Label Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/751df4b242cddabdf9c4a542de15e90e79036ce9\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47527828\",\"name\":\"W. Zhang\"},{\"authorId\":\"2634975\",\"name\":\"J. Wang\"},{\"authorId\":\"2029678802\",\"name\":\"Fangping Lan\"}],\"doi\":\"10.1109/JAS.2020.1003465\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78ad2f90ee6b3c1350f068f4d9e4e039248b189\",\"title\":\"Dynamic hand gesture recognition based on short-term sampling neural networks\",\"url\":\"https://www.semanticscholar.org/paper/a78ad2f90ee6b3c1350f068f4d9e4e039248b189\",\"venue\":\"IEEE/CAA Journal of Automatica Sinica\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52454948\",\"name\":\"A. Verma\"},{\"authorId\":\"2903495\",\"name\":\"T. Meenpal\"},{\"authorId\":\"2456349\",\"name\":\"Bibhudendra Acharya\"}],\"doi\":\"10.1111/coin.12419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"title\":\"Multiperson interaction recognition in images: A body keypoint based feature image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01225-w\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"43cbabdac51091773d1b003d76adaf8426d17b24\",\"title\":\"Deep Insights into Convolutional Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/43cbabdac51091773d1b003d76adaf8426d17b24\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1905.13388\",\"authors\":[{\"authorId\":\"46506975\",\"name\":\"Haonan Wang\"},{\"authorId\":\"145394369\",\"name\":\"J. Lin\"},{\"authorId\":\"2539310\",\"name\":\"Z. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56563001d7a177bdd4ddf332a2a9cdad858ee3a7\",\"title\":\"Design Light-weight 3D Convolutional Networks for Video Recognition Temporal Residual, Fully Separable Block, and Fast Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/56563001d7a177bdd4ddf332a2a9cdad858ee3a7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39796129\",\"name\":\"Hayden Faulkner\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":\"10.1109/DICTA.2017.8227494\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"title\":\"TenniSet: A Dataset for Dense Fine-Grained Event Recognition, Localisation and Description\",\"url\":\"https://www.semanticscholar.org/paper/4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1016/j.jvcir.2020.102772\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46302cdf6eb829ba2f7582469ad50dd0a40fd856\",\"title\":\"Multimodal hand gesture recognition combining temporal and pose information based on CNN descriptors and histogram of cumulative magnitudes\",\"url\":\"https://www.semanticscholar.org/paper/46302cdf6eb829ba2f7582469ad50dd0a40fd856\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1804.02463\",\"authors\":[{\"authorId\":\"39611591\",\"name\":\"Lucas Beyer\"},{\"authorId\":\"36665147\",\"name\":\"A. Hermans\"},{\"authorId\":\"2699877\",\"name\":\"T. Linder\"},{\"authorId\":\"1699080\",\"name\":\"K. Arras\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f74421b96abf13fc1e91d88387d32e70c13050f1\",\"title\":\"Deep Person Detection in 2D Range Data\",\"url\":\"https://www.semanticscholar.org/paper/f74421b96abf13fc1e91d88387d32e70c13050f1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"1481023982\",\"name\":\"Jiajie Chen\"},{\"authorId\":\"32125534\",\"name\":\"Lvran Chen\"},{\"authorId\":\"50024252\",\"name\":\"Y. Li\"},{\"authorId\":\"7833644\",\"name\":\"Zhiwei Yan\"}],\"doi\":\"10.1007/s11063-019-10182-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9cc0e1897ec5556e2491e018c6ddfa978f879510\",\"title\":\"Feature Enhancement for Multi-scale Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/9cc0e1897ec5556e2491e018c6ddfa978f879510\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"2007.12034\",\"authors\":[{\"authorId\":\"1809218238\",\"name\":\"Xiaofang Wang\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"7679232\",\"name\":\"M. Neumann\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"145221796\",\"name\":\"W. Hua\"}],\"doi\":\"10.1007/978-3-030-58598-3_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"title\":\"AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"48093650\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"}],\"doi\":\"10.1145/3365212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f6ca119c719cd9f9362a160fb15af2b895095f\",\"title\":\"A Benchmark Dataset and Comparison Study for Multi-modal Human Action Analytics\",\"url\":\"https://www.semanticscholar.org/paper/76f6ca119c719cd9f9362a160fb15af2b895095f\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83172278\",\"name\":\"Y. Li\"},{\"authorId\":\"2303180\",\"name\":\"S. Xu\"},{\"authorId\":\"66678312\",\"name\":\"Xiangqian Cheng\"},{\"authorId\":\"1471662289\",\"name\":\"L. Zhou\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"48430112\",\"name\":\"BoJin Zhuang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de47d9734fcb028339e95d5052281050ff237351\",\"title\":\"An Effective Detection Framework for Activities in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/de47d9734fcb028339e95d5052281050ff237351\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.14661\",\"authors\":[{\"authorId\":\"1500399016\",\"name\":\"Tong Yu\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"title\":\"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"107698641\",\"name\":\"Abdullah M. Algamdi\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/ICASSP.2019.8683720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a958eaba99834612735ab45c4b78eca7c317a97\",\"title\":\"Learning Temporal Information from Spatial Information Using CapsNets for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4a958eaba99834612735ab45c4b78eca7c317a97\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1707.00823\",\"authors\":[{\"authorId\":\"79993273\",\"name\":\"Jian Liu\"},{\"authorId\":\"151475004\",\"name\":\"Hossein Rahmani\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1007/s11263-019-01192-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57ba391f7462d2f6b7957d30682670c7f833009d\",\"title\":\"Learning Human Pose Models from Synthesized Data for Robust RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57ba391f7462d2f6b7957d30682670c7f833009d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/TIP.2018.2791180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"title\":\"Real-Time Action Recognition With Deeply Transferred Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"68974941\",\"name\":\"Kanishk Lohumi\"},{\"authorId\":\"38542228\",\"name\":\"S. Roy\"}],\"doi\":\"10.1109/ICT-DM.2018.8636373\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02b6d01ca1f5f11b3ab6c92e35b934dd58fd0a5b\",\"title\":\"Automatic Detection of Flood Severity Level from Flood Videos using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/02b6d01ca1f5f11b3ab6c92e35b934dd58fd0a5b\",\"venue\":\"2018 5th International Conference on Information and Communication Technologies for Disaster Management (ICT-DM)\",\"year\":2018},{\"arxivId\":\"1906.03857\",\"authors\":[{\"authorId\":null,\"name\":\"Yufei Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"425c33485b32301df75d16cb9cd224763782da8c\",\"title\":\"UniDual: A Unified Model for Image and Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/425c33485b32301df75d16cb9cd224763782da8c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1430785963\",\"name\":\"Habib Ullah\"},{\"authorId\":\"2966975\",\"name\":\"S. D. Khan\"},{\"authorId\":\"14200860\",\"name\":\"M. Ullah\"},{\"authorId\":\"1795667\",\"name\":\"F. A. Cheikh\"},{\"authorId\":\"47102862\",\"name\":\"M. Uzair\"}],\"doi\":\"10.1109/EUVIP47703.2019.8946170\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"686d4f82c28c8571aa2aca8f17f67b170cc6f363\",\"title\":\"Two Stream Model for Crowd Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686d4f82c28c8571aa2aca8f17f67b170cc6f363\",\"venue\":\"2019 8th European Workshop on Visual Information Processing (EUVIP)\",\"year\":2019},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1907.11475\",\"authors\":[{\"authorId\":\"101947437\",\"name\":\"J. Saric\"},{\"authorId\":\"3009751\",\"name\":\"M. Orsic\"},{\"authorId\":\"2111962\",\"name\":\"Tonci Antunovic\"},{\"authorId\":\"3237756\",\"name\":\"Sacha Vrazic\"},{\"authorId\":\"3166278\",\"name\":\"Sinisa Segvic\"}],\"doi\":\"10.1007/978-3-030-33676-9_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cceeaf0deec726961dc1627e786943f3cbdcbe1c\",\"title\":\"Single Level Feature-to-Feature Forecasting with Deformable Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/cceeaf0deec726961dc1627e786943f3cbdcbe1c\",\"venue\":\"GCPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b9127cbb1180c228475eefa8ca28be9eab1db2e9\",\"title\":\"A Survey of MultiView Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9127cbb1180c228475eefa8ca28be9eab1db2e9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.04741\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"250fabf66752c8729cbf286eadab271bd04da710\",\"title\":\"Generative Models for Novelty Detection: Applications in abnormal event and situational change detection from data series\",\"url\":\"https://www.semanticscholar.org/paper/250fabf66752c8729cbf286eadab271bd04da710\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376597\",\"name\":\"Yuxin Cai\"},{\"authorId\":\"1758575\",\"name\":\"Yanfeng Shang\"},{\"authorId\":\"152362971\",\"name\":\"Yixian Tan\"},{\"authorId\":\"48859082\",\"name\":\"Zhiwei Tang\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"}],\"doi\":\"10.1007/978-3-030-25128-4_198\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7197a36f367baa2319fd8bd6846d8f5b529dc4bc\",\"title\":\"Human Action Recognition Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/7197a36f367baa2319fd8bd6846d8f5b529dc4bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1801.04065\",\"authors\":[{\"authorId\":\"2173656\",\"name\":\"Lidong Yu\"},{\"authorId\":\"47906104\",\"name\":\"Yucheng Wang\"},{\"authorId\":\"32161932\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"779dd5ee0f34b8a63ad693fc7e4f946370ac6783\",\"title\":\"Deep Stereo Matching with Explicit Cost Aggregation Sub-Architecture\",\"url\":\"https://www.semanticscholar.org/paper/779dd5ee0f34b8a63ad693fc7e4f946370ac6783\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"36352159\",\"name\":\"Y. Ji\"},{\"authorId\":\"2998391\",\"name\":\"B. Zhong\"},{\"authorId\":\"47003295\",\"name\":\"Yonggang Li\"},{\"authorId\":\"2693554\",\"name\":\"Husheng Dong\"}],\"doi\":\"10.1007/978-3-319-77223-3_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a232352d250bf13de7e8383d6279bdec3fc176b4\",\"title\":\"Image and Video Understanding Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a232352d250bf13de7e8383d6279bdec3fc176b4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"40013571\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/WCICA.2018.8630333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e6695e24f9f6e74f57f26925d7ace2a34d49574\",\"title\":\"Kinematics Features for 3D Action Recognition Using Two-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/6e6695e24f9f6e74f57f26925d7ace2a34d49574\",\"venue\":\"2018 13th World Congress on Intelligent Control and Automation (WCICA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patrec.2018.07.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"403f756f9f18948994e7a650ccb0be359d695530\",\"title\":\"Joint spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/403f756f9f18948994e7a650ccb0be359d695530\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2310278\",\"name\":\"Cagdas Bas\"},{\"authorId\":\"2581044\",\"name\":\"Cemil Zalluhoglu\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1109/SIU.2017.7960551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c51b57ddc5854a69439d9367c0a749033efa838\",\"title\":\"Using deep multiple instance learning for action recognition in still images\",\"url\":\"https://www.semanticscholar.org/paper/9c51b57ddc5854a69439d9367c0a749033efa838\",\"venue\":\"2017 25th Signal Processing and Communications Applications Conference (SIU)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3418004\",\"name\":\"Spyridon Thermos\"},{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"}],\"doi\":\"10.1109/ICIP.2018.8451158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b79d9ce2824f2ddeb2bdbf425c0496010437fbb\",\"title\":\"Attention-Enhanced Sensorimotor Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b79d9ce2824f2ddeb2bdbf425c0496010437fbb\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1892008902\",\"name\":\"Xiaoyu Zhang\"}],\"doi\":\"10.1145/3404555.3404628\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fd084823dae54cc32c07361e749b3932919da35\",\"title\":\"Learning Temporal Structure of Videos for Action Recognition Using Pattern Theory\",\"url\":\"https://www.semanticscholar.org/paper/7fd084823dae54cc32c07361e749b3932919da35\",\"venue\":\"ICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48708296\",\"name\":\"Zhaoyuan Wang\"},{\"authorId\":\"49050083\",\"name\":\"J. Zhang\"},{\"authorId\":\"2657604\",\"name\":\"Shenggong Ji\"},{\"authorId\":\"2598592\",\"name\":\"Chuishi Meng\"},{\"authorId\":\"8036732\",\"name\":\"T. Li\"},{\"authorId\":\"145143274\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1016/j.inffus.2020.02.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f2af4e8ac012b2703e8fa205ce540e9ffa53544\",\"title\":\"Predicting and ranking box office revenue of movies based on big data\",\"url\":\"https://www.semanticscholar.org/paper/5f2af4e8ac012b2703e8fa205ce540e9ffa53544\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9521309\",\"name\":\"Reem Alfaifi\"},{\"authorId\":\"46845102\",\"name\":\"A M Artoli\"}],\"doi\":\"10.1007/s42979-020-00293-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"title\":\"Human Action Prediction with 3D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1907.10885\",\"authors\":[{\"authorId\":\"145765727\",\"name\":\"R. Li\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"90736633\",\"name\":\"Mengyu Gu\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeec210bafc09fe27113703bb38b21dbff12ad89\",\"title\":\"Adaptive Noise Injection: A Structure-Expanding Regularization for RNN\",\"url\":\"https://www.semanticscholar.org/paper/eeec210bafc09fe27113703bb38b21dbff12ad89\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2581044\",\"name\":\"Cemil Zalluhoglu\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1016/j.imavis.2020.103870\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cd8441db0c344897d728c013dd600baf918113a\",\"title\":\"Collective Sports: A multi-task dataset for collective activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cd8441db0c344897d728c013dd600baf918113a\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.09366\",\"authors\":[{\"authorId\":\"46286082\",\"name\":\"Y. Yang\"},{\"authorId\":\"143803348\",\"name\":\"F. Gao\"},{\"authorId\":\"2410278\",\"name\":\"Chengwen Xing\"},{\"authorId\":\"47700062\",\"name\":\"Jianping An\"},{\"authorId\":\"10162459\",\"name\":\"Ahmed Alkhateeb\"}],\"doi\":\"10.1109/jsac.2020.3041383\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e656ddea99e0229cb9e164e3c971ace6743a7bef\",\"title\":\"Deep Multimodal Learning: Merging Sensory Data for Massive MIMO Channel Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e656ddea99e0229cb9e164e3c971ace6743a7bef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1611.09502\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"title\":\"Deep Quantization: Encoding Convolutional Activations with Deep Generative Model\",\"url\":\"https://www.semanticscholar.org/paper/ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.04471\",\"authors\":[{\"authorId\":\"9541177\",\"name\":\"Navaneeth Bodla\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2680836\",\"name\":\"H. Xu\"},{\"authorId\":\"36407236\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/WACV.2017.71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f017e25b4269e88e077239f8d47777a779b624e8\",\"title\":\"Deep Heterogeneous Feature Fusion for Template-Based Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f017e25b4269e88e077239f8d47777a779b624e8\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1804.04899\",\"authors\":[{\"authorId\":\"19255629\",\"name\":\"P. Nagorny\"},{\"authorId\":\"2149576\",\"name\":\"M. Pillet\"},{\"authorId\":\"19224197\",\"name\":\"E. Pairel\"},{\"authorId\":\"46524329\",\"name\":\"R. Goff\"},{\"authorId\":\"65954316\",\"name\":\"J\\u00e9r\\u00f4me Loureaux\"},{\"authorId\":\"66970400\",\"name\":\"Marl\\u00e8ne Wali\"},{\"authorId\":\"46605900\",\"name\":\"Patrice Kiener\"}],\"doi\":\"10.1109/CIVEMSA.2017.7995316\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e00e28392bb5f4cb7fccfdf9b8b8cd4d5f6de4c\",\"title\":\"Quality prediction in injection molding\",\"url\":\"https://www.semanticscholar.org/paper/8e00e28392bb5f4cb7fccfdf9b8b8cd4d5f6de4c\",\"venue\":\"2017 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e78232f23508b879c6c5ae372030487ed071ca1f\",\"title\":\"Video Action Classification Using Deep Predictive Coding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e78232f23508b879c6c5ae372030487ed071ca1f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52213085\",\"name\":\"Tristan Langenberg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eddbb7638e97493b60567ef40fced9fa23a5dd7\",\"title\":\"Deep Learning Metadata Fusion for Traffic Light to Lane Assignment\",\"url\":\"https://www.semanticscholar.org/paper/8eddbb7638e97493b60567ef40fced9fa23a5dd7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144821367\",\"name\":\"Tian Jin\"},{\"authorId\":\"152237365\",\"name\":\"Zhihao He\"},{\"authorId\":\"152449715\",\"name\":\"Amlan Basu\"},{\"authorId\":\"1684980\",\"name\":\"J. Soraghan\"},{\"authorId\":\"27469280\",\"name\":\"G. Di Caterina\"},{\"authorId\":\"69329588\",\"name\":\"L. Petropoulakis\"}],\"doi\":\"10.1109/ICCAR.2019.8813408\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c245c67fcf0e472bb2eb1fe6fa9821c0c4bd2f0\",\"title\":\"Dense Convolutional Networks for Efficient Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0c245c67fcf0e472bb2eb1fe6fa9821c0c4bd2f0\",\"venue\":\"2019 5th International Conference on Control, Automation and Robotics (ICCAR)\",\"year\":2019},{\"arxivId\":\"1909.04837\",\"authors\":[{\"authorId\":\"144890263\",\"name\":\"Xiaojun Jia\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"50322422\",\"name\":\"Xiaochun Cao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d62ebb972866d8d39f8632966abfeb04c097dae\",\"title\":\"Identifying and Resisting Adversarial Videos Using Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/9d62ebb972866d8d39f8632966abfeb04c097dae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3087877\",\"name\":\"Saleh M. Basalamah\"},{\"authorId\":\"145568216\",\"name\":\"Sultan A. Daud\"}],\"doi\":\"10.14569/ijacsa.2020.0110187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c57fa2ee72d82e827e86cec8da1ddd3cf1de120\",\"title\":\"Pedestrian Crowd Detection and Segmentation using Multi-Source Feature Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/0c57fa2ee72d82e827e86cec8da1ddd3cf1de120\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1704.02112\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.172\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faae39b8708de562a78b2b4294694a935442844a\",\"title\":\"Generalized Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/faae39b8708de562a78b2b4294694a935442844a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153257940\",\"name\":\"H. Patil\"},{\"authorId\":null,\"name\":\"Aishwarya C Kuratti\"},{\"authorId\":null,\"name\":\"Disha Bhanushali\"},{\"authorId\":null,\"name\":\"Sandhya Belgaonkar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"adf57ec760099272ab74151567d2626cebbd3475\",\"title\":\"Implementation of Driver Vigilance System using Deep Learning and Advance Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/adf57ec760099272ab74151567d2626cebbd3475\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"2800581\",\"name\":\"Yuheng Huang\"},{\"authorId\":\"6473875\",\"name\":\"Yu-e Sun\"},{\"authorId\":\"40504730\",\"name\":\"Zhun Cai\"},{\"authorId\":\"50353283\",\"name\":\"Hao Guo\"}],\"doi\":\"10.1109/WACV45572.2020.9093517\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a1bf4170f4c2b1bc8e4bb70575b9cdf114fc934\",\"title\":\"Fine-Grained Motion Representation For Template-Free Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/5a1bf4170f4c2b1bc8e4bb70575b9cdf114fc934\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"49046516\",\"name\":\"C. Liu\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.5244/C.31.72\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b61fdc47b5eeae6bc0a52523f519eaeaadbc8c8\",\"title\":\"Temporal Perceptive Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b61fdc47b5eeae6bc0a52523f519eaeaadbc8c8\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1612.00558\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW.2017.205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57c59011614c43f51a509e10717e47505c776389\",\"title\":\"Unsupervised Human Action Detection by Action Matching\",\"url\":\"https://www.semanticscholar.org/paper/57c59011614c43f51a509e10717e47505c776389\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003409110\",\"name\":\"Mithun Channayanamath\"},{\"authorId\":\"2003409212\",\"name\":\"Akshay Math\"},{\"authorId\":\"1819870\",\"name\":\"V. Peddigari\"},{\"authorId\":\"153394743\",\"name\":\"Shilpa Kamath\"},{\"authorId\":\"151071329\",\"name\":\"Kavita Chachadi\"},{\"authorId\":\"2003416005\",\"name\":\"Faisal Sabeeh\"},{\"authorId\":\"2003092239\",\"name\":\"Ameen Attar\"}],\"doi\":\"10.1007/978-981-15-5397-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09efe1d2e504f323cb06672dfc6fee212f86f0d8\",\"title\":\"Dynamic Hand Gesture Recognition Using 3D-Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/09efe1d2e504f323cb06672dfc6fee212f86f0d8\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1803.11064\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/CVPR.2018.00234\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13d93feb5431eda200ac482b5230f51667c0146a\",\"title\":\"Non-linear Temporal Subspace Representations for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13d93feb5431eda200ac482b5230f51667c0146a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145302989\",\"name\":\"P. Novais\"},{\"authorId\":\"143869061\",\"name\":\"David Camacho\"},{\"authorId\":\"1709042\",\"name\":\"H. Yin\"}],\"doi\":\"10.1007/978-3-030-62362-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ef549fbd0aa3c6b0cd3cdbc01320e53e72ded9f\",\"title\":\"Intelligent Data Engineering and Automated Learning \\u2013 IDEAL 2020: 21st International Conference, Guimaraes, Portugal, November 4\\u20136, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/2ef549fbd0aa3c6b0cd3cdbc01320e53e72ded9f\",\"venue\":\"IDEAL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39926981\",\"name\":\"H. Zhang\"}],\"doi\":\"10.7282/T3Z89GMT\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2405915cdc35e067ad82f3cc476c9df4c1897762\",\"title\":\"Reflectance and texture encoding for material recognition and synthesis\",\"url\":\"https://www.semanticscholar.org/paper/2405915cdc35e067ad82f3cc476c9df4c1897762\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.08094\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"40893359\",\"name\":\"Byungsu Min\"},{\"authorId\":\"40893002\",\"name\":\"Nadha Gafoor\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f52b5bbc2678d3bebef7e00e281d5ccdbac9f4b\",\"title\":\"T-RECS: Training for Rate-Invariant Embeddings by Controlling Speed for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f52b5bbc2678d3bebef7e00e281d5ccdbac9f4b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471707097\",\"name\":\"Tse-Yu Pan\"},{\"authorId\":\"1717645\",\"name\":\"Chen-Yuan Chang\"},{\"authorId\":\"7518775\",\"name\":\"Wan-Lun Tsai\"},{\"authorId\":\"1384601232\",\"name\":\"Min-Chun Hu\"}],\"doi\":\"10.1109/JSEN.2020.3012887\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"454d71a5c3c678426bc3567dabf2aa905356e9f5\",\"title\":\"Multisensor-Based 3D Gesture Recognition for a Decision-Making Training System\",\"url\":\"https://www.semanticscholar.org/paper/454d71a5c3c678426bc3567dabf2aa905356e9f5\",\"venue\":\"IEEE Sensors Journal\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8598253\",\"name\":\"Wang-Li Hao\"},{\"authorId\":\"1500387021\",\"name\":\"Ruixian Zhang\"},{\"authorId\":\"47319226\",\"name\":\"Shancang Li\"},{\"authorId\":\"1492111607\",\"name\":\"Junyu Li\"},{\"authorId\":\"49515557\",\"name\":\"F. Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"3103971\",\"name\":\"Wuping Zhang\"}],\"doi\":\"10.1155/2020/8876056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"title\":\"Anomaly Event Detection in Security Surveillance Using Two-Stream Based Model\",\"url\":\"https://www.semanticscholar.org/paper/d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"88728572\",\"name\":\"Yalong Jia\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"title\":\"Channel-wise Temporal Attention Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1712.01652\",\"authors\":[{\"authorId\":\"50077927\",\"name\":\"Zeng Yu\"},{\"authorId\":\"8036732\",\"name\":\"T. Li\"},{\"authorId\":null,\"name\":\"Ning Yu\"},{\"authorId\":\"145389876\",\"name\":\"X. Gong\"},{\"authorId\":\"32811782\",\"name\":\"Ke Chen\"},{\"authorId\":\"144680113\",\"name\":\"Yi Pan\"}],\"doi\":\"10.1109/ISKE47853.2019.9170280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f1b39e8d157b74181c666e85e5d55550d762409\",\"title\":\"Three-Stream Convolutional Networks for Video-based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/9f1b39e8d157b74181c666e85e5d55550d762409\",\"venue\":\"2019 IEEE 14th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)\",\"year\":2019},{\"arxivId\":\"1711.09618\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e25c57a6395b7c8861088699eef1a56b6f1d70ad\",\"title\":\"Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture\",\"url\":\"https://www.semanticscholar.org/paper/e25c57a6395b7c8861088699eef1a56b6f1d70ad\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"49025023\",\"name\":\"J. Huang\"},{\"authorId\":\"2898447\",\"name\":\"Shanshan Huang\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"}],\"doi\":\"10.1109/SmartWorld.2018.00089\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"title\":\"Dynamic Representation Learning for Video Action Recognition Using Temporal Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491438016\",\"name\":\"Yuanye Fang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-030-39431-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"title\":\"Action Recognition in Videos with Temporal Segments Fusions\",\"url\":\"https://www.semanticscholar.org/paper/d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23124669\",\"name\":\"Jiewan Zheng\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"7883602\",\"name\":\"Xiangbo Su\"}],\"doi\":\"10.1109/TNNLS.2018.2844464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc95fb644c12ee9caa989390af29c969b4c1d646\",\"title\":\"Deep Ensemble Machine for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc95fb644c12ee9caa989390af29c969b4c1d646\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2239974\",\"name\":\"K. Gadiraju\"},{\"authorId\":\"1415112439\",\"name\":\"Bharathkumar Ramachandra\"},{\"authorId\":\"121238711\",\"name\":\"Zexi Chen\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":\"10.1145/3394486.3403375\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb86790019b051d0a3e5f7276292eb298009cea4\",\"title\":\"Multimodal Deep Learning Based Crop Classification Using Multispectral and Multitemporal Satellite Imagery\",\"url\":\"https://www.semanticscholar.org/paper/fb86790019b051d0a3e5f7276292eb298009cea4\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2611778\",\"name\":\"Yongmei Ren\"},{\"authorId\":\"2611778\",\"name\":\"Yongmei Ren\"},{\"authorId\":\"46478255\",\"name\":\"Jie Yang\"},{\"authorId\":\"1844429\",\"name\":\"Qingnian Zhang\"},{\"authorId\":\"145363350\",\"name\":\"Z. Guo\"}],\"doi\":\"10.1007/s11042-020-09574-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"743149571cd6149097635bdc8cbae60121434676\",\"title\":\"Ship recognition based on Hu invariant moments and convolutional neural network for video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/743149571cd6149097635bdc8cbae60121434676\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"2733886\",\"name\":\"Panagiotis C. Petrantonakis\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"119661806\",\"name\":\"I. Kompatsiaris\"}],\"doi\":\"10.1007/S11042-020-09902-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44c0abc3ac54c69ba68362708c2a5c06b088287b\",\"title\":\"First-person activity recognition from micro-action representations using convolutional neural networks and object flow histograms\",\"url\":\"https://www.semanticscholar.org/paper/44c0abc3ac54c69ba68362708c2a5c06b088287b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fang Liu\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"50728655\",\"name\":\"Tong Zhang\"},{\"authorId\":\"2698357\",\"name\":\"Kailing Guo\"},{\"authorId\":\"1390771080\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.neucom.2019.11.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9df354b00c6450198371172c96be48fea0b78d28\",\"title\":\"Exploring privileged information from simple actions for complex action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9df354b00c6450198371172c96be48fea0b78d28\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46875450\",\"name\":\"Xunmu Zhu\"},{\"authorId\":\"2023742062\",\"name\":\"Chen Changxin\"},{\"authorId\":\"144055215\",\"name\":\"Bin Zheng\"},{\"authorId\":\"50030933\",\"name\":\"X. Yang\"},{\"authorId\":\"101179387\",\"name\":\"Gan Haiming\"},{\"authorId\":\"1490866837\",\"name\":\"Chan Zheng\"},{\"authorId\":\"9502932\",\"name\":\"Aqing Yang\"},{\"authorId\":\"1491792583\",\"name\":\"Liang Mao\"},{\"authorId\":\"9095682\",\"name\":\"Yue-ju Xue\"}],\"doi\":\"10.1016/j.biosystemseng.2019.11.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13a09478b108697121490ca5e95b3282b3fc255e\",\"title\":\"Automatic recognition of lactating sow postures by refined two-stream RGB-D faster R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/13a09478b108697121490ca5e95b3282b3fc255e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.08685\",\"authors\":[{\"authorId\":\"1409877474\",\"name\":\"Jen-Yen Chang\"},{\"authorId\":\"1399435786\",\"name\":\"Antonio Tejero-de-Pablos\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICRA.2019.8793825\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cf61b3eb9679182f50b61a4ab4373e893898bf9\",\"title\":\"Improved Optical Flow for Gesture-based Human-robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/1cf61b3eb9679182f50b61a4ab4373e893898bf9\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"1696389\",\"name\":\"G. Meditskos\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1007/978-3-030-37734-2_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f8bd23919c36db7e1f3eb9c57b7ef72e4632ed1\",\"title\":\"Real-Time Recognition of Daily Actions Based on 3D Joint Movements and Fisher Encoding\",\"url\":\"https://www.semanticscholar.org/paper/0f8bd23919c36db7e1f3eb9c57b7ef72e4632ed1\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1703.06953\",\"authors\":[{\"authorId\":\"46702541\",\"name\":\"H. Zhang\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-11018-5_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a525cb3779d5eb19880faf8aa7a34a34cfbdef40\",\"title\":\"Multi-style Generative Network for Real-time Transfer\",\"url\":\"https://www.semanticscholar.org/paper/a525cb3779d5eb19880faf8aa7a34a34cfbdef40\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1007/978-3-319-58771-4_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a244a8188f586a9fd8aedb728fe4f0e3c2ad05da\",\"title\":\"Spatio-Temporal Scale Selection in Video Data\",\"url\":\"https://www.semanticscholar.org/paper/a244a8188f586a9fd8aedb728fe4f0e3c2ad05da\",\"venue\":\"SSVM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"title\":\"Diversity encouraging ensemble of convolutional networks for high performance action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.03898\",\"authors\":[{\"authorId\":\"1684800\",\"name\":\"J. Chen\"},{\"authorId\":\"33455548\",\"name\":\"Jonathan Wu\"},{\"authorId\":\"144055319\",\"name\":\"J. Konrad\"},{\"authorId\":\"1756038\",\"name\":\"P. Ishwar\"}],\"doi\":\"10.1109/WACV.2017.23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6e502fa918beeb033b9e7f6d0de83d55fa59d99\",\"title\":\"Semi-Coupled Two-Stream Fusion ConvNets for Action Recognition at Extremely Low Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/c6e502fa918beeb033b9e7f6d0de83d55fa59d99\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37007863\",\"name\":\"Xu Dong\"},{\"authorId\":\"144539547\",\"name\":\"L. Tan\"},{\"authorId\":\"46696927\",\"name\":\"Lina Zhou\"},{\"authorId\":\"152991070\",\"name\":\"Yanyan Song\"}],\"doi\":\"10.1109/ICAIBD.2019.8837029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e487f60d2e57331dc68224b89ffe91f0fb74a1e0\",\"title\":\"Scene Recognition in Short Video with Multi-Resolution CNNs\",\"url\":\"https://www.semanticscholar.org/paper/e487f60d2e57331dc68224b89ffe91f0fb74a1e0\",\"venue\":\"2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)\",\"year\":2019},{\"arxivId\":\"1903.07256\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/CVPR.2019.00133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a03bda078490e8ee991a1f86b53f27df7cf93a14\",\"title\":\"Graph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/a03bda078490e8ee991a1f86b53f27df7cf93a14\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651877\",\"name\":\"Changlin Li\"},{\"authorId\":\"49969948\",\"name\":\"Zhihui Li\"},{\"authorId\":\"1808390\",\"name\":\"ZongYuan Ge\"},{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"}],\"doi\":\"10.1016/j.jvcir.2019.102628\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2afb75192852c9bc56727070fbd3f0c502bebdf6\",\"title\":\"Knowledge driven temporal activity localization\",\"url\":\"https://www.semanticscholar.org/paper/2afb75192852c9bc56727070fbd3f0c502bebdf6\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2010.11594\",\"authors\":[{\"authorId\":\"3191371\",\"name\":\"Yuanhao Zhai\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2914452\",\"name\":\"W. Tang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-58539-6_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"title\":\"Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367041\",\"name\":\"Himanshu Buckchash\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1109/ICTAI50040.2020.00082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44c37249c9d4298d526f56435476311ff74106ff\",\"title\":\"DuTriNet: Dual-Stream Triplet Siamese Network for Self-Supervised Action Recognition by Modeling Temporal Correlations\",\"url\":\"https://www.semanticscholar.org/paper/44c37249c9d4298d526f56435476311ff74106ff\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645390\",\"name\":\"D. Liu\"},{\"authorId\":\"36803798\",\"name\":\"F. Liu\"},{\"authorId\":\"145104391\",\"name\":\"X. Xie\"},{\"authorId\":\"47736188\",\"name\":\"L. Su\"},{\"authorId\":\"144292269\",\"name\":\"M. Liu\"},{\"authorId\":\"47907277\",\"name\":\"Xiao-hua Xie\"},{\"authorId\":\"143865806\",\"name\":\"M. Kuang\"},{\"authorId\":\"3914405\",\"name\":\"Guang-liang Huang\"},{\"authorId\":null,\"name\":\"Yuqi Wang\"},{\"authorId\":\"46544514\",\"name\":\"H. Zhou\"},{\"authorId\":\"31034293\",\"name\":\"K. Wang\"},{\"authorId\":\"12971943\",\"name\":\"M. Lin\"},{\"authorId\":\"145883431\",\"name\":\"J. Tian\"}],\"doi\":\"10.1007/s00330-019-06553-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bf0a91eeb593f510be7a73533e1651978bad72b\",\"title\":\"Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound\",\"url\":\"https://www.semanticscholar.org/paper/0bf0a91eeb593f510be7a73533e1651978bad72b\",\"venue\":\"European Radiology\",\"year\":2020},{\"arxivId\":\"1708.06250\",\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"501bfe67683ddfecf3710f5946c3b77f1ffe9adf\",\"title\":\"Pillar Networks++: Distributed non-parametric deep and wide networks\",\"url\":\"https://www.semanticscholar.org/paper/501bfe67683ddfecf3710f5946c3b77f1ffe9adf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3281413\",\"name\":\"Diangang Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1993699405\",\"name\":\"Yuka Hayashi\"},{\"authorId\":\"144042991\",\"name\":\"Jun Suzuki\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"}],\"doi\":\"10.1145/3394171.3413801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2587144054982adc9b4c5adef760f45bf3be0a26\",\"title\":\"Multi-Person Action Recognition in Microwave Sensors\",\"url\":\"https://www.semanticscholar.org/paper/2587144054982adc9b4c5adef760f45bf3be0a26\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145258837\",\"name\":\"Chao Zhu\"},{\"authorId\":\"3128146\",\"name\":\"Y. Li\"},{\"authorId\":\"47908631\",\"name\":\"Y. Liu\"},{\"authorId\":\"71506962\",\"name\":\"Zhiqiang Tian\"},{\"authorId\":\"2502126\",\"name\":\"Zhichao Cui\"},{\"authorId\":\"145697902\",\"name\":\"C. Zhang\"},{\"authorId\":\"93513286\",\"name\":\"X. Zhu\"}],\"doi\":\"10.1109/IVS.2019.8813836\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9de1c8361f9fedd37010d555fecf38e19ea6875f\",\"title\":\"Road Scene Layout Reconstruction based on CNN and its Application in Traffic Simulation\",\"url\":\"https://www.semanticscholar.org/paper/9de1c8361f9fedd37010d555fecf38e19ea6875f\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":\"1706.06905\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"title\":\"Learnable pooling with Context Gating for video classification\",\"url\":\"https://www.semanticscholar.org/paper/1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.11667\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"151491781\",\"name\":\"David T. Hoffmann\"},{\"authorId\":\"1940674\",\"name\":\"Dimitrios Tzionas\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"144516670\",\"name\":\"J. Romero\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/s11263-019-01279-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6caa038decc7e083fdcac4a3d5797eaf19036016\",\"title\":\"Learning Multi-human Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/6caa038decc7e083fdcac4a3d5797eaf19036016\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"66350669\",\"name\":\"Y. Huang\"},{\"authorId\":\"1721716\",\"name\":\"J. Peng\"}],\"doi\":\"10.1007/978-3-030-63830-6_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b1b056b835a34c7616039ba8b8d52c8359b2484\",\"title\":\"Video-Interfaced Human Motion Capture Data Retrieval Based on the Normalized Motion Energy Image Representation\",\"url\":\"https://www.semanticscholar.org/paper/3b1b056b835a34c7616039ba8b8d52c8359b2484\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1905.08711\",\"authors\":[{\"authorId\":\"48085995\",\"name\":\"A. Kozlov\"},{\"authorId\":\"117171023\",\"name\":\"V. Andronov\"},{\"authorId\":\"122388064\",\"name\":\"Y. Gritsenko\"}],\"doi\":\"10.1145/3341105.3373906\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4262413c55cf0319922c42b796c74879a0632a8\",\"title\":\"Lightweight network architecture for real-time action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4262413c55cf0319922c42b796c74879a0632a8\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48114960\",\"name\":\"Ali Mohammad Nickfarjam\"},{\"authorId\":\"1402318194\",\"name\":\"H. Ebrahimpour-Komleh\"}],\"doi\":\"10.1007/s11042-018-7076-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"title\":\"Multi-input 1-dimensional deep belief network: action and activity recognition as case study\",\"url\":\"https://www.semanticscholar.org/paper/cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81748251\",\"name\":\"Ahmed Z. Alsinan\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"},{\"authorId\":\"1836588\",\"name\":\"I. Hacihaliloglu\"}],\"doi\":\"10.1007/s11548-019-01934-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"335214b04ef12dfa86d396baa0424cf27af5923b\",\"title\":\"Automatic segmentation of bone surfaces from ultrasound using a filter-layer-guided CNN\",\"url\":\"https://www.semanticscholar.org/paper/335214b04ef12dfa86d396baa0424cf27af5923b\",\"venue\":\"International Journal of Computer Assisted Radiology and Surgery\",\"year\":2019},{\"arxivId\":\"1901.04622\",\"authors\":[{\"authorId\":\"145462888\",\"name\":\"Hao Tang\"},{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"144443748\",\"name\":\"W. Xiao\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1016/j.neucom.2018.11.038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90950b0901643271aa18df7ff368b557e39742c9\",\"title\":\"Fast and Robust Dynamic Hand Gesture Recognition via Key Frames Extraction and Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/90950b0901643271aa18df7ff368b557e39742c9\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/WACV.2018.00173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f38813f1c9dac44dcb992ebe51c5ede66fd0f491\",\"title\":\"Modeling Temporal Structure with LSTM for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f38813f1c9dac44dcb992ebe51c5ede66fd0f491\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152237619\",\"name\":\"Zheng-ping Hu\"},{\"authorId\":\"50081274\",\"name\":\"L. Zhang\"},{\"authorId\":\"50341810\",\"name\":\"Shufang Li\"},{\"authorId\":\"1789083\",\"name\":\"Degang Sun\"}],\"doi\":\"10.1016/j.jvcir.2020.102765\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20695729ff761de24f687297d7e33272e7ee9b38\",\"title\":\"Parallel spatial-temporal convolutional neural networks for anomaly detection and location in crowded scenes\",\"url\":\"https://www.semanticscholar.org/paper/20695729ff761de24f687297d7e33272e7ee9b38\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40618572\",\"name\":\"Shih-Yao Lin\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"},{\"authorId\":\"145458451\",\"name\":\"Y. Hung\"}],\"doi\":\"10.1145/3089250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76547bebfccf21342d35c37c12dfb97b74674a49\",\"title\":\"Recognizing Human Actions with Outlier Frames by Observation Filtering and Completion\",\"url\":\"https://www.semanticscholar.org/paper/76547bebfccf21342d35c37c12dfb97b74674a49\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/TMM.2017.2771462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c09fb7fe1886072670e0c4dd632d052102a3733\",\"title\":\"Content-Attention Representation by Factorized Action-Scene Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c09fb7fe1886072670e0c4dd632d052102a3733\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9929684\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"144761066\",\"name\":\"Yan Yan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"1807998\",\"name\":\"I. Tsang\"}],\"doi\":\"10.1109/TIP.2018.2867747\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f96cc4f09e6ba42c97fe5acf3e0827580c8d22e\",\"title\":\"Late Fusion via Subspace Search With Consistency Preservation\",\"url\":\"https://www.semanticscholar.org/paper/9f96cc4f09e6ba42c97fe5acf3e0827580c8d22e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1811.04407\",\"authors\":[{\"authorId\":\"51877876\",\"name\":\"Liu Yuezhang\"},{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd8b4466906ef2af88981bacbb02266c17671055\",\"title\":\"An Initial Attempt of Combining Visual Selective Attention with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/dd8b4466906ef2af88981bacbb02266c17671055\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24944572\",\"name\":\"Shahela Saif\"},{\"authorId\":\"51935429\",\"name\":\"Samabia Tehseen\"},{\"authorId\":\"1880755\",\"name\":\"Sumaira Kausar\"}],\"doi\":\"10.3390/s18113979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe4aa088362d371daf15ccf9290291c8867e4f23\",\"title\":\"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/fe4aa088362d371daf15ccf9290291c8867e4f23\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1710.05179\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"2205770\",\"name\":\"Tackgeun You\"},{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4873c78f0cd5a1fad96300e49e196af75800a24e\",\"title\":\"Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization\",\"url\":\"https://www.semanticscholar.org/paper/4873c78f0cd5a1fad96300e49e196af75800a24e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2173656\",\"name\":\"Lidong Yu\"},{\"authorId\":\"47906104\",\"name\":\"Yucheng Wang\"},{\"authorId\":\"32161932\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"7415267\",\"name\":\"Yunde Jia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a587ec1fdde89b8943e1433642f6226d4790ca2\",\"title\":\"Initial Left Image R ight Image Hand-Designed Cost Aggregation Disparity Map Disparity Computation A ggregated C ost Volume Extracting Guidance Aggregation Guidance Generaing Aggregation Proposals Aggregation Proposals Fusion Aggregated Cost Volume Disparity Map Disparity Computation A : The Typical\",\"url\":\"https://www.semanticscholar.org/paper/8a587ec1fdde89b8943e1433642f6226d4790ca2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/VCIP.2018.8698720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ecb08611d79b5799a99ea6d4dd32cebc5023d65\",\"title\":\"Convolutional Neural Networks with Generalized Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0ecb08611d79b5799a99ea6d4dd32cebc5023d65\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152502426\",\"name\":\"Shaoqing Tan\"},{\"authorId\":\"8092869\",\"name\":\"R. Yang\"}],\"doi\":\"10.1109/IJCNN.2019.8851694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1964f5e913bc386707e98e872861dbdf00ed13e\",\"title\":\"Learning Similarity: Feature-Aligning Network for Few-shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1964f5e913bc386707e98e872861dbdf00ed13e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"48278763\",\"name\":\"J. Morlier\"}],\"doi\":\"10.1109/ICIP.2019.8803780\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3eb7533610afea095afd443bac0d20565d6a66df\",\"title\":\"Optimal Choice of Motion Estimation Methods for Fine-Grained Action Classification with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3eb7533610afea095afd443bac0d20565d6a66df\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51193280\",\"name\":\"Salisu Wada Yahaya\"},{\"authorId\":\"118362140\",\"name\":\"Ahmad Lotfi\"},{\"authorId\":\"144774721\",\"name\":\"Mufti Mahmud\"},{\"authorId\":\"143863194\",\"name\":\"P. Machado\"},{\"authorId\":\"145350352\",\"name\":\"N. Kubota\"}],\"doi\":\"10.1109/SSCI44817.2019.9003121\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dbae0753ceb7da9b001069f2b2b415ce7eb06750\",\"title\":\"Gesture Recognition Intermediary Robot for Abnormality Detection in Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/dbae0753ceb7da9b001069f2b2b415ce7eb06750\",\"venue\":\"2019 IEEE Symposium Series on Computational Intelligence (SSCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387727361\",\"name\":\"Haitao Guo\"},{\"authorId\":\"38968784\",\"name\":\"Yunsick Sung\"}],\"doi\":\"10.3390/s20061801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35c051f58cf1a0660bd69beb0869914f2da51562\",\"title\":\"Movement Estimation Using Soft Sensors Based on Bi-LSTM and Two-Layer LSTM for Human Motion Capture\",\"url\":\"https://www.semanticscholar.org/paper/35c051f58cf1a0660bd69beb0869914f2da51562\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94173091\",\"name\":\"Y. Wan\"},{\"authorId\":\"7822579\",\"name\":\"Zujun Yu\"},{\"authorId\":null,\"name\":\"Yao Wang\"},{\"authorId\":\"50079335\",\"name\":\"Xingxin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2993227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"title\":\"Action Recognition Based on Two-Stream Convolutional Networks With Long-Short-Term Spatiotemporal Features\",\"url\":\"https://www.semanticscholar.org/paper/ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46528640\",\"name\":\"H. T. Binh\"},{\"authorId\":\"9283769\",\"name\":\"Ma Thi Chau\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"9349062\",\"name\":\"B. Duy\"}],\"doi\":\"10.1109/ICCCE.2018.8539313\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3901f177642912be3fd132807a1e7d16796d1011\",\"title\":\"Selecting active frames for action recognition with vote fusion method\",\"url\":\"https://www.semanticscholar.org/paper/3901f177642912be3fd132807a1e7d16796d1011\",\"venue\":\"2018 7th International Conference on Computer and Communication Engineering (ICCCE)\",\"year\":2018},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1965957878\",\"name\":\"Juhyoung Lee\"},{\"authorId\":\"22051640\",\"name\":\"Changhyeon Kim\"},{\"authorId\":\"2267220\",\"name\":\"Sungpill Choi\"},{\"authorId\":\"2966754\",\"name\":\"Dongjoo Shin\"},{\"authorId\":\"144018175\",\"name\":\"Sanghoon Kang\"},{\"authorId\":\"1678901\",\"name\":\"H. Yoo\"}],\"doi\":\"10.1109/ISCAS.2018.8351177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69eb86b4501a516b983b6269b7f154e4a8a4d588\",\"title\":\"A 46.1 fps Global Matching Optical Flow Estimation Processor for Action Recognition in Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/69eb86b4501a516b983b6269b7f154e4a8a4d588\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"title\":\"Recognition Prediction ? ? ? ? ? ? ? ? Gap fi lling\",\"url\":\"https://www.semanticscholar.org/paper/5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145281972\",\"name\":\"F. Yan\"},{\"authorId\":\"151212267\",\"name\":\"S. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86953383f1306a4dc08459f8ee182aca8a6107f4\",\"title\":\"Two-Stream Convolutional Neural Networks with Natural Light and Depth Images for Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/86953383f1306a4dc08459f8ee182aca8a6107f4\",\"venue\":\"2019 12th Asian Control Conference (ASCC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanran Wang\"},{\"authorId\":\"2985716\",\"name\":\"Hengkang Wang\"},{\"authorId\":\"9350135\",\"name\":\"S. Chen\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"},{\"authorId\":\"5578795\",\"name\":\"Adam Martersteck\"},{\"authorId\":\"143731577\",\"name\":\"J. S. Higgins\"},{\"authorId\":\"145359909\",\"name\":\"V. Hill\"},{\"authorId\":\"1779590\",\"name\":\"T. Parrish\"}],\"doi\":\"10.1109/ICIP.2019.8803092\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d315b06556bb7198d1ca91dca213a20209c9b20b\",\"title\":\"A 3D Cross-Hemisphere Neighborhood Difference Convnet for Chronic Stroke Lesion Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d315b06556bb7198d1ca91dca213a20209c9b20b\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"46583677\",\"name\":\"J. Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"},{\"authorId\":\"1776581\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Global-Local Temporal Representations for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145859238\",\"name\":\"Liping Xie\"},{\"authorId\":\"1930070\",\"name\":\"Junsheng Zhao\"},{\"authorId\":\"3140817\",\"name\":\"Haikun Wei\"},{\"authorId\":\"145208719\",\"name\":\"Z. Fan\"},{\"authorId\":\"40542981\",\"name\":\"Guochen Pang\"}],\"doi\":\"10.1109/ACCESS.2019.2925916\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52fbb7ee98835f099c1021c939b0088859c7a2c3\",\"title\":\"Efficient Early Event Detector for Streaming Sequence\",\"url\":\"https://www.semanticscholar.org/paper/52fbb7ee98835f099c1021c939b0088859c7a2c3\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2685285\",\"name\":\"P. Palasek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3507f5839b28cd385e477d7cadee3373c6bc3e67\",\"title\":\"Action recognition using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/3507f5839b28cd385e477d7cadee3373c6bc3e67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1605.04988\",\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.imavis.2017.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"title\":\"Going deeper into action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.786\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"title\":\"Temporal Residual Networks for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.10049\",\"authors\":[{\"authorId\":\"47787021\",\"name\":\"J. Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TIP.2020.2972108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Multi-Scale Temporal Cues Learning for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350339\",\"name\":\"Chirag I. Patel\"},{\"authorId\":\"2042647646\",\"name\":\"Dileep Labana\"},{\"authorId\":\"47706103\",\"name\":\"S. Pandya\"},{\"authorId\":\"3438822\",\"name\":\"Kirit Modi\"},{\"authorId\":\"3424424\",\"name\":\"H. Ghayvat\"},{\"authorId\":\"1622021877\",\"name\":\"Muhammad Awais\"}],\"doi\":\"10.3390/s20247299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"title\":\"Histogram of Oriented Gradient-Based Fusion of Features for Human Action Recognition in Action Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2011.04364\",\"authors\":[{\"authorId\":\"46480156\",\"name\":\"P. Gupta\"},{\"authorId\":\"144622883\",\"name\":\"A. Majumdar\"},{\"authorId\":\"102425592\",\"name\":\"\\u00c9. Chouzenoux\"},{\"authorId\":\"24284226\",\"name\":\"G. Chierchia\"}],\"doi\":\"10.1016/j.eswa.2020.114206\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a91afd6e694db55505c31f628cd6be1c479ecfc9\",\"title\":\"SuperDeConFuse: A Supervised Deep Convolutional Transform based Fusion Framework for Financial Trading Systems\",\"url\":\"https://www.semanticscholar.org/paper/a91afd6e694db55505c31f628cd6be1c479ecfc9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01065\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58580-8_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"202c79bbb45ab6524141feacc81caacc4ba00401\",\"title\":\"Memory-augmented Dense Predictive Coding for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/202c79bbb45ab6524141feacc81caacc4ba00401\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"1390631689\",\"name\":\"Shan Liu\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/TCSVT.2019.2923712\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71780727bad491d006a97ee365c08ea616b707c3\",\"title\":\"Spatial\\u2013Temporal Context-Aware Online Action Detection and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/71780727bad491d006a97ee365c08ea616b707c3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10229\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"title\":\"Intra- and Inter-Action Understanding via Temporal Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ACCESS.2020.3025931\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"title\":\"Multi-Label Multi-Class Action Recognition With Deep Spatio-Temporal Layers Based on Temporal Gaussian Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.01494\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"title\":\"Two-Stream AMTnet for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"title\":\"Video Action Classification Using PredNet\",\"url\":\"https://www.semanticscholar.org/paper/bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1701.03246\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2017.26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"title\":\"Ordered Pooling of Optical Flow Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1707.06750\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"title\":\"Temporal Convolution Based Action Proposal: Submission to ActivityNet 2017\",\"url\":\"https://www.semanticscholar.org/paper/af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.10021\",\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"2404621\",\"name\":\"Hanlin Qin\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e03419db32dd1a68394a545dcc400653df58f5\",\"title\":\"Deep Keyframe Detection in Human Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/22e03419db32dd1a68394a545dcc400653df58f5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2074878\",\"name\":\"Weixin Luo\"},{\"authorId\":\"48152297\",\"name\":\"W. Liu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/ICME.2017.8019325\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"792250ae660b7c25f85eeea7dcae623e4301d97c\",\"title\":\"Remembering history with convolutional LSTM for anomaly detection\",\"url\":\"https://www.semanticscholar.org/paper/792250ae660b7c25f85eeea7dcae623e4301d97c\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51268431\",\"name\":\"Xinshu Qiao\"},{\"authorId\":\"9764225\",\"name\":\"Chuanwei Zhou\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":null,\"name\":\"Jian Yang\"}],\"doi\":\"10.1109/ICIP.2018.8451548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53da7e4e193b334ce3891a55c61593a9fe479e19\",\"title\":\"Action Recognition with Spatial-Temporal Representation Analysis Across Grassmannian Manifold and Euclidean Space\",\"url\":\"https://www.semanticscholar.org/paper/53da7e4e193b334ce3891a55c61593a9fe479e19\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1708.05465\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f257300b2b4141aab73f93c146bf94846aef5fa1\",\"title\":\"Eigen Evolution Pooling for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f257300b2b4141aab73f93c146bf94846aef5fa1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1903.12389\",\"authors\":[{\"authorId\":\"38026005\",\"name\":\"Mingyang Zhang\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"2339200\",\"name\":\"Fuming Fang\"},{\"authorId\":\"1711271\",\"name\":\"Haizhou Li\"},{\"authorId\":\"1716857\",\"name\":\"J. Yamagishi\"}],\"doi\":\"10.21437/interspeech.2019-1357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27376bd3085e30d5264c73d5b74a318f9895949d\",\"title\":\"Joint training framework for text-to-speech and voice conversion using multi-source Tacotron and WaveNet\",\"url\":\"https://www.semanticscholar.org/paper/27376bd3085e30d5264c73d5b74a318f9895949d\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1905.04668\",\"authors\":[{\"authorId\":\"2133342\",\"name\":\"Mohammadreza Babaee\"},{\"authorId\":\"119389363\",\"name\":\"David Full\"},{\"authorId\":\"145512909\",\"name\":\"Gerhard Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"138aedf23346d7d5a4a8c38c935735a436f7c839\",\"title\":\"On Flow Profile Image for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/138aedf23346d7d5a4a8c38c935735a436f7c839\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890165\",\"name\":\"J. Yin\"},{\"authorId\":\"46521842\",\"name\":\"X. Liu\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"27029800\",\"name\":\"Z. Liu\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"38728795\",\"name\":\"J. Liu\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":\"10.1109/TCSVT.2018.2847305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29fd92a56ee55136ee65ab6975760b68dd4637c9\",\"title\":\"One-Shot SADI-EPE: A Visual Framework of Event Progress Estimation\",\"url\":\"https://www.semanticscholar.org/paper/29fd92a56ee55136ee65ab6975760b68dd4637c9\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379882732\",\"name\":\"L. Tani\"},{\"authorId\":\"2512422\",\"name\":\"Abdelghani Ghomari\"},{\"authorId\":\"2782248\",\"name\":\"M. Y. K. Tani\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-135-2019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4823216083b8fbab8e246dc0867f2aac4718bc32\",\"title\":\"EVENTS RECOGNITION FOR A SEMI-AUTOMATIC ANNOTATION OF SOCCER VIDEOS: A STUDY BASED DEEP LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/4823216083b8fbab8e246dc0867f2aac4718bc32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409338179\",\"name\":\"Ruibing Jin\"},{\"authorId\":\"100739830\",\"name\":\"Jianliang Wang\"}],\"doi\":\"10.1109/ICCA.2019.8899924\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f13b70821c42a4b04a26dd887426cb2ab6205924\",\"title\":\"Two-stream network for online quadrotor detection without dedicated annotations\",\"url\":\"https://www.semanticscholar.org/paper/f13b70821c42a4b04a26dd887426cb2ab6205924\",\"venue\":\"2019 IEEE 15th International Conference on Control and Automation (ICCA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150356708\",\"name\":\"Zhongyin Huang\"},{\"authorId\":\"73227160\",\"name\":\"Wei Chen\"}],\"doi\":\"10.2991/icaita-18.2018.3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1321f366a1c58124039664a9a40c8d188b78d80a\",\"title\":\"Research of Action Recognition Methods Based on RGB+D Videos\",\"url\":\"https://www.semanticscholar.org/paper/1321f366a1c58124039664a9a40c8d188b78d80a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28108620\",\"name\":\"Eli Chen\"},{\"authorId\":\"1904028\",\"name\":\"Oren Haik\"},{\"authorId\":\"1779830\",\"name\":\"Yitzhak Yitzhaky\"}],\"doi\":\"10.1117/12.2534670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"934265518e2f3a15698132a997b8266e1f7f1f84\",\"title\":\"Action localization and classification in long-distance surveillance\",\"url\":\"https://www.semanticscholar.org/paper/934265518e2f3a15698132a997b8266e1f7f1f84\",\"venue\":\"Security + Defence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117257245\",\"name\":\"Negar Moslemi\"},{\"authorId\":\"2854562\",\"name\":\"R. Azmi\"},{\"authorId\":\"2522837\",\"name\":\"M. Soryani\"}],\"doi\":\"10.1109/PRIA.2019.8786012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ed0a147c4ef174e4243deff70bf43781a3519fa\",\"title\":\"Driver Distraction Recognition using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9ed0a147c4ef174e4243deff70bf43781a3519fa\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2018.00840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9baf01eb53abda6a169110477f2c7a3492559368\",\"title\":\"Learning and Using the Arrow of Time\",\"url\":\"https://www.semanticscholar.org/paper/9baf01eb53abda6a169110477f2c7a3492559368\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119924024\",\"name\":\"Yinan Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"}],\"doi\":\"10.1109/ACCESS.2017.2753830\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c90427085909029afd2af01d1967e80b78e01b88\",\"title\":\"Gaze-Assisted Multi-Stream Deep Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c90427085909029afd2af01d1967e80b78e01b88\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752988299\",\"name\":\"Abdelmalek khebli\"},{\"authorId\":\"1752988572\",\"name\":\"Hocine Meglouli\"},{\"authorId\":\"3095853\",\"name\":\"L. Bentabet\"},{\"authorId\":\"3232735\",\"name\":\"Mohamed Airouche\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9157ffcf1c33eebc547651e80fca6952aeefc313\",\"title\":\"A new technique based on 3D convolutional neural networks and filtering optical flow maps for action classification in infrared video\",\"url\":\"https://www.semanticscholar.org/paper/9157ffcf1c33eebc547651e80fca6952aeefc313\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768755261\",\"name\":\"Valentin Bencteux\"},{\"authorId\":\"1491035169\",\"name\":\"Guinther Saibro\"},{\"authorId\":\"1768756867\",\"name\":\"Eran Shlomovitz\"},{\"authorId\":\"47708442\",\"name\":\"P. Mascagni\"},{\"authorId\":\"1743911\",\"name\":\"S. Perretta\"},{\"authorId\":\"2029086\",\"name\":\"A. Hostettler\"},{\"authorId\":\"144688664\",\"name\":\"J. Marescaux\"},{\"authorId\":\"2161419\",\"name\":\"T. Collins\"}],\"doi\":\"10.1007/s11548-020-02208-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e74d8654a761466a4b6d6f4f2d0a83c3787acec\",\"title\":\"Automatic task recognition in a flexible endoscopy benchtop trainer with semi-supervised learning\",\"url\":\"https://www.semanticscholar.org/paper/5e74d8654a761466a4b6d6f4f2d0a83c3787acec\",\"venue\":\"International Journal of Computer Assisted Radiology and Surgery\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Liang Xu\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"46641540\",\"name\":\"W. Liu\"},{\"authorId\":\"152671983\",\"name\":\"Bin Feng\"}],\"doi\":\"10.1109/TCSVT.2019.2944430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"517c23e4dfc3c58270ef0475028a7adcffae2cbe\",\"title\":\"Cascaded Boundary Network for High-Quality Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/517c23e4dfc3c58270ef0475028a7adcffae2cbe\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144433\",\"name\":\"Baptist Vandersmissen\"},{\"authorId\":\"31042607\",\"name\":\"Nicolas Knudde\"},{\"authorId\":\"49812011\",\"name\":\"Azarakhsh Jalalvand\"},{\"authorId\":\"2426172\",\"name\":\"I. Couckuyt\"},{\"authorId\":\"1806487\",\"name\":\"T. Dhaene\"},{\"authorId\":\"134860754\",\"name\":\"W. De Neve\"}],\"doi\":\"10.1007/s00521-019-04408-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9173cf7ca2576621d8e7dbc4c49f2cbd6cd46a51\",\"title\":\"Indoor human activity recognition using high-dimensional sensors and deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9173cf7ca2576621d8e7dbc4c49f2cbd6cd46a51\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"2004.09215\",\"authors\":[{\"authorId\":\"50218817\",\"name\":\"Zhengwei Wang\"},{\"authorId\":\"1486411393\",\"name\":\"Qi She\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/CVPRW50498.2020.00123\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"title\":\"CatNet: Class Incremental 3D ConvNets for Lifelong Egocentric Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"4509077\",\"name\":\"Xiaowei Gu\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"152734957\",\"name\":\"Zulfiqar Habib\"}],\"doi\":\"10.1007/s11042-020-09381-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"title\":\"Human action recognition using deep rule-based classifier\",\"url\":\"https://www.semanticscholar.org/paper/8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"}],\"doi\":\"10.1007/978-3-030-56150-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"title\":\"Action Recognition Using Co-trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1807.06667\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":\"10.1109/CVPR.2019.00907\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866e158776c422e95829770c0f24dfa4b0a9a4bd\",\"title\":\"Accel: A Corrective Fusion Network for Efficient Semantic Segmentation on Video\",\"url\":\"https://www.semanticscholar.org/paper/866e158776c422e95829770c0f24dfa4b0a9a4bd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.05349\",\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/CVPR.2019.00464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"title\":\"H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"35528948\",\"name\":\"M. A. Khan\"}],\"doi\":\"10.1109/ACCESS.2019.2902507\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fe47bbcd536bb9ce80661b17dae92f41328e91f\",\"title\":\"ASoVS: Abstractive Summarization of Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/1fe47bbcd536bb9ce80661b17dae92f41328e91f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00627\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96ce111119624888be47d998cf87c9df18988c4d\",\"title\":\"Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints\",\"url\":\"https://www.semanticscholar.org/paper/96ce111119624888be47d998cf87c9df18988c4d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.10420\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-017-1030-x\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5615d6045301ecbc5be35e46cab711f676aadf3a\",\"title\":\"Discriminatively Learned Hierarchical Rank Pooling Networks\",\"url\":\"https://www.semanticscholar.org/paper/5615d6045301ecbc5be35e46cab711f676aadf3a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":\"46674577\",\"name\":\"W. Feng\"}],\"doi\":\"10.1016/j.sigpro.2017.05.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b920626df0c1fd90b6d8a8dfcf1260c6d88196f6\",\"title\":\"Multi-stream deep networks for human action classification with sequential tensor decomposition\",\"url\":\"https://www.semanticscholar.org/paper/b920626df0c1fd90b6d8a8dfcf1260c6d88196f6\",\"venue\":\"Signal Process.\",\"year\":2017},{\"arxivId\":\"1807.00612\",\"authors\":[{\"authorId\":\"3172278\",\"name\":\"Mehmet Ali Arabaci\"},{\"authorId\":\"11255888\",\"name\":\"F. \\u00d6zkan\"},{\"authorId\":\"3299076\",\"name\":\"Elif Surer\"},{\"authorId\":\"1784515\",\"name\":\"P. Jancovic\"},{\"authorId\":\"1787799\",\"name\":\"Alptekin Temizel\"}],\"doi\":\"10.1007/s11042-020-08789-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77181ce3e55e25da06d0ac584c3ceef313bdde3f\",\"title\":\"Multi-modal egocentric activity recognition using multi-kernel learning\",\"url\":\"https://www.semanticscholar.org/paper/77181ce3e55e25da06d0ac584c3ceef313bdde3f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1610.09334\",\"authors\":[{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/WACV.2017.25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7fe851e1acc8a974697fb74d913736a3a849003\",\"title\":\"Real-Time Online Action Detection Forests Using Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/c7fe851e1acc8a974697fb74d913736a3a849003\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1801.08468\",\"authors\":[{\"authorId\":\"47059386\",\"name\":\"Ling Zhang\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"},{\"authorId\":\"2851775\",\"name\":\"E. Kebebew\"},{\"authorId\":\"1722252\",\"name\":\"J. Yao\"}],\"doi\":\"10.1109/TMI.2017.2774044\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f4919a098fc7a71db08afc8651d27e9fe66e862\",\"title\":\"Convolutional Invasion and Expansion Networks for Tumor Growth Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7f4919a098fc7a71db08afc8651d27e9fe66e862\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2018},{\"arxivId\":\"1709.03655\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e19ebad4739d59f999d192bac7d596b20b887f78\",\"title\":\"Learning Gating ConvNet for Two-Stream based Methods in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e19ebad4739d59f999d192bac7d596b20b887f78\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Daniel Sahle Chemere\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"085316884c47d7bf61625413269e761e35a59665\",\"title\":\"ADDIS ABABA UNIVERSITY COLLEGE OF NATURAL SCIENCES Real-time Shoplifting Detection from Surveillance Video\",\"url\":\"https://www.semanticscholar.org/paper/085316884c47d7bf61625413269e761e35a59665\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153104144\",\"name\":\"Xin-Yu Jin\"},{\"authorId\":\"47122584\",\"name\":\"Z. Zhao\"},{\"authorId\":\"50704081\",\"name\":\"Lanjuan Li\"}],\"doi\":\"10.1109/ITME.2019.00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b5f03da40f5cbfb44536e47511143d40bf46dfc\",\"title\":\"Classification of Abnormal Gait Based on Improved Two-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/8b5f03da40f5cbfb44536e47511143d40bf46dfc\",\"venue\":\"2019 10th International Conference on Information Technology in Medicine and Education (ITME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3073314\",\"name\":\"Yongqing Sun\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"1764762\",\"name\":\"H. Arai\"},{\"authorId\":\"31468482\",\"name\":\"Tetsuya Kinebuchi\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/2964284.2967199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"997b9ffe2f752ba84a66730cfd320d040e7ba2e2\",\"title\":\"Exploiting Objects with LSTMs for Video Categorization\",\"url\":\"https://www.semanticscholar.org/paper/997b9ffe2f752ba84a66730cfd320d040e7ba2e2\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1910.02533\",\"authors\":[{\"authorId\":\"1384812397\",\"name\":\"Haoyuan Cao\"},{\"authorId\":\"48932880\",\"name\":\"Shining Yu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"title\":\"Compressed Video Action Recognition with Refined Motion Vector\",\"url\":\"https://www.semanticscholar.org/paper/1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"}],\"doi\":\"10.1007/s11042-017-5017-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efe1ff6a4b2fe67c28be4c21d49641e51cefa599\",\"title\":\"Supervised spatio-temporal kernel descriptor for human action recognition from RGB-depth videos\",\"url\":\"https://www.semanticscholar.org/paper/efe1ff6a4b2fe67c28be4c21d49641e51cefa599\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.01432\",\"authors\":[{\"authorId\":\"13657788\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"8230405\",\"name\":\"Y. Tong\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"150270503\",\"name\":\"Qiyue Liu\"},{\"authorId\":\"48211752\",\"name\":\"Jun-Hui Liu\"}],\"doi\":\"10.1007/978-3-030-58604-1_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab87795177c3d53913cc91771162420ef75671e3\",\"title\":\"Boundary Content Graph Neural Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/ab87795177c3d53913cc91771162420ef75671e3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20772402\",\"name\":\"B. Gatto\"},{\"authorId\":\"9641567\",\"name\":\"L. S. Souza\"},{\"authorId\":\"1766202\",\"name\":\"E. Santos\"},{\"authorId\":\"1770128\",\"name\":\"K. Fukui\"},{\"authorId\":\"2417429\",\"name\":\"Waldir Sabino da Silva\"},{\"authorId\":\"31284899\",\"name\":\"K. Santos\"}],\"doi\":\"10.1186/s13640-020-00507-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a0c4082a4fab7b77497d9a9925954fe70e1b7a\",\"title\":\"A semi-supervised convolutional neural network based on subspace representation for image classification\",\"url\":\"https://www.semanticscholar.org/paper/a9a0c4082a4fab7b77497d9a9925954fe70e1b7a\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39893135\",\"name\":\"M. Yu\"},{\"authorId\":\"1712773\",\"name\":\"Weizhe Zhang\"},{\"authorId\":\"48411615\",\"name\":\"Qingxiang Zeng\"},{\"authorId\":\"47074418\",\"name\":\"C. Wang\"},{\"authorId\":\"38158055\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/ICAIIC.2019.8669069\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"title\":\"Human-Object Contour for Action Recognition with Attentional Multi-modal Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"venue\":\"2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780024\",\"name\":\"R. Polikar\"}],\"doi\":\"10.1007/978-3-030-12939-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b05362caf719e2161f04b035c54b3172d6749cdb\",\"title\":\"Pattern Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b05362caf719e2161f04b035c54b3172d6749cdb\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1708.00919\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f9ebd7c724c641d2eb5f5f8edb95a42436610e0\",\"title\":\"Learning Spherical Convolution for Fast Features from 360\\u00b0 Imagery\",\"url\":\"https://www.semanticscholar.org/paper/9f9ebd7c724c641d2eb5f5f8edb95a42436610e0\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47703700\",\"name\":\"Kun Hu\"},{\"authorId\":\"39532571\",\"name\":\"Zhiyong Wang\"},{\"authorId\":\"1745727\",\"name\":\"S. Mei\"},{\"authorId\":\"66155252\",\"name\":\"Kaylena A Ehgoetz Martens\"},{\"authorId\":\"145188375\",\"name\":\"Tingting Yao\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1109/JBHI.2019.2923209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf71cc460d0e857f5801410d10314f853380246d\",\"title\":\"Vision-Based Freezing of Gait Detection With Anatomic Directed Graph Representation\",\"url\":\"https://www.semanticscholar.org/paper/cf71cc460d0e857f5801410d10314f853380246d\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681148\",\"name\":\"L. Wang\"},{\"authorId\":\"3034546\",\"name\":\"Lianzheng Ge\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e378d5258615b542484fb519f2ca28b0ab1f1394\",\"title\":\"Three-stream CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e378d5258615b542484fb519f2ca28b0ab1f1394\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65773211\",\"name\":\"Carlos Ant\\u00f4nio Caetano J\\u00fanior\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"title\":\"Motion-based representations for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46572037\",\"name\":\"A. George\"},{\"authorId\":\"1978827882\",\"name\":\"Dighanchal Banerjee\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"37840630\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"145323795\",\"name\":\"P. Balamurali\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fcc63268caa9b8415517102e81fe1b2ae19aae7\",\"title\":\"A Reservoir-based Convolutional Spiking Neural Network for Gesture Recognition from DVS Input\",\"url\":\"https://www.semanticscholar.org/paper/8fcc63268caa9b8415517102e81fe1b2ae19aae7\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49989940\",\"name\":\"A. Jamal\"},{\"authorId\":\"2064509\",\"name\":\"Dipti Deodhare\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"145952735\",\"name\":\"K. Venkatesh\"}],\"doi\":\"10.1007/s11042-018-6179-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f86df492c45d5dbc28610c6de0fa5edcc06763de\",\"title\":\"Eclectic domain mixing for effective adaptation in action spaces\",\"url\":\"https://www.semanticscholar.org/paper/f86df492c45d5dbc28610c6de0fa5edcc06763de\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103887800\",\"name\":\"Rose Rustowicz\"},{\"authorId\":\"113983041\",\"name\":\"Robin Cheong\"},{\"authorId\":\"51471745\",\"name\":\"Lijing Wang\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"49240687\",\"name\":\"M. Burke\"},{\"authorId\":\"2465182\",\"name\":\"D. Lobell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f0cffad2d7527273a25a945736c1e813c08312\",\"title\":\"Semantic Segmentation of Crop Type in Africa: A Novel Dataset and Analysis of Deep Learning Methods\",\"url\":\"https://www.semanticscholar.org/paper/87f0cffad2d7527273a25a945736c1e813c08312\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22066021\",\"name\":\"Xishan Zhang\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"2069818\",\"name\":\"D. Zhang\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2017.662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b0b706fc94b35a1eddd830685e07870315b9565\",\"title\":\"Task-Driven Dynamic Fusion: Reducing Ambiguity in Video Description\",\"url\":\"https://www.semanticscholar.org/paper/3b0b706fc94b35a1eddd830685e07870315b9565\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423738380\",\"name\":\"Zakia Yahya\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"}],\"doi\":\"10.1109/HONET.2019.8908040\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"title\":\"Classification and Temporal Localization of Robbery Events in CCTV Videos through Multi-Stream Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"venue\":\"2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT and AI (HONET-ICT)\",\"year\":2019},{\"arxivId\":\"1709.06391\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07a9930c8bd1616b06bac1b9b68670dbc2dc136e\",\"title\":\"Human Action Forecasting by Learning Task Grammars\",\"url\":\"https://www.semanticscholar.org/paper/07a9930c8bd1616b06bac1b9b68670dbc2dc136e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"48902208\",\"name\":\"Zhaoqiang Wei\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"}],\"doi\":\"10.1007/978-3-319-77383-4_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"299e4d4c575fb684f7d234ac1a693f9c75dee9a2\",\"title\":\"Exploiting Sub-region Deep Features for Specific Action Recognition in Combat Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/299e4d4c575fb684f7d234ac1a693f9c75dee9a2\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1809.04096\",\"authors\":[{\"authorId\":\"49147616\",\"name\":\"Felix Gonda\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3557b92c64d17717253a3a6136fc85cf41ee3036\",\"title\":\"Parallel Separable 3D Convolution for Video and Volumetric Data Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3557b92c64d17717253a3a6136fc85cf41ee3036\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"title\":\"Watch, Think and Attend: End-to-End Video Classification via Dynamic Knowledge Evolution Modeling\",\"url\":\"https://www.semanticscholar.org/paper/eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"46246550\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f26caf22fd05659802db690c7e6c9db289be340\",\"title\":\"Modeling Temporal Concept Receptive Field Dynamically for Untrimmed Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1f26caf22fd05659802db690c7e6c9db289be340\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1962324382\",\"name\":\"Yongtao Zhang\"},{\"authorId\":\"97598583\",\"name\":\"Zhishuai Yin\"},{\"authorId\":\"66439545\",\"name\":\"Linzhen Nie\"},{\"authorId\":\"1747935\",\"name\":\"S. Huang\"}],\"doi\":\"10.1109/ACCESS.2020.3022623\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11391c1ac0978007935d36318be9b1e93183c627\",\"title\":\"Attention Based Multi-Layer Fusion of Multispectral Images for Pedestrian Detection\",\"url\":\"https://www.semanticscholar.org/paper/11391c1ac0978007935d36318be9b1e93183c627\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2272934\",\"name\":\"C. Li\"},{\"authorId\":\"145863017\",\"name\":\"X. Zhang\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"}],\"doi\":\"10.1109/ICCVW.2017.80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e2831ec15392050fefe7122f6ab603c2bea2363\",\"title\":\"LPSNet: A Novel Log Path Signature Feature Based Hand Gesture Recognition Framework\",\"url\":\"https://www.semanticscholar.org/paper/0e2831ec15392050fefe7122f6ab603c2bea2363\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"145375983\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1186/S13640-017-0235-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4a5ad6f1cc489427ac1021da7d7b70fa9a770f2\",\"title\":\"Gated spatio and temporal convolutional neural network for activity recognition: towards gated multimodal deep learning\",\"url\":\"https://www.semanticscholar.org/paper/a4a5ad6f1cc489427ac1021da7d7b70fa9a770f2\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2337936\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/FG.2018.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9077365c9486e54e251dd0b6f6edaeda30ae52b9\",\"title\":\"Convolutional Neural Network-Based Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9077365c9486e54e251dd0b6f6edaeda30ae52b9\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":\"1809.03258\",\"authors\":[{\"authorId\":\"9179750\",\"name\":\"Omar Hommos\"},{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-030-11024-6_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"23dbada22825613e7c616eb60af0c8a812372f3b\",\"title\":\"Using phase instead of optical flow for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/23dbada22825613e7c616eb60af0c8a812372f3b\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/ICIP.2018.8451255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad58b92ebc45e71e40ce68d4375441267549b054\",\"title\":\"DA-VLAD: Discriminative Action Vector of Locally Aggregated Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad58b92ebc45e71e40ce68d4375441267549b054\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1906.06496\",\"authors\":[{\"authorId\":\"50819719\",\"name\":\"Tian Wang\"},{\"authorId\":\"152384041\",\"name\":\"Shiye Lei\"},{\"authorId\":\"116503541\",\"name\":\"Youyou Jiang\"},{\"authorId\":\"97207595\",\"name\":\"Zihang Deng\"},{\"authorId\":\"50821858\",\"name\":\"Xin Su\"},{\"authorId\":\"2103629\",\"name\":\"Hichem Snoussi\"},{\"authorId\":\"145685544\",\"name\":\"Chang Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8041479e3018f7b0fa8e275beeda6998725ff7c3\",\"title\":\"Improving temporal action proposal generation by using high performance computing\",\"url\":\"https://www.semanticscholar.org/paper/8041479e3018f7b0fa8e275beeda6998725ff7c3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1706.07911\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"50152762\",\"name\":\"Sen Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"title\":\"Large-Scale Human Activity Mapping using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2019.01016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"title\":\"Time-Conditioned Action Anticipation in One Shot\",\"url\":\"https://www.semanticscholar.org/paper/3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33975342\",\"name\":\"Jiajun Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f31e2d67a479c44a9942b1cd6e4905b6b1972d37\",\"title\":\"Video Understanding : From Video Classification to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f31e2d67a479c44a9942b1cd6e4905b6b1972d37\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152460549\",\"name\":\"Antonia Breuer\"},{\"authorId\":\"153269740\",\"name\":\"Jana Kirschner\"},{\"authorId\":\"1694892\",\"name\":\"S. Homoceanu\"},{\"authorId\":\"1679795\",\"name\":\"T. Fingscheidt\"}],\"doi\":\"10.1109/IVS.2019.8813816\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"title\":\"Towards Tactical Maneuver Detection for Autonomous Driving Based on Vision Only\",\"url\":\"https://www.semanticscholar.org/paper/d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9355577\",\"name\":\"Shangqian Gao\"},{\"authorId\":\"145809539\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1748032\",\"name\":\"Heng Huang\"}],\"doi\":\"10.1109/CVPR.2019.00918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d80b8ddc5711a31a4ae82f6ad6d29e528d5e82c3\",\"title\":\"Cross Domain Model Compression by Structurally Weight Sharing\",\"url\":\"https://www.semanticscholar.org/paper/d80b8ddc5711a31a4ae82f6ad6d29e528d5e82c3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"title\":\"Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters\",\"url\":\"https://www.semanticscholar.org/paper/aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"venue\":\"AAAI 2017\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48599063\",\"name\":\"Ziqi Yang\"},{\"authorId\":\"46810102\",\"name\":\"X. Gong\"},{\"authorId\":\"46791330\",\"name\":\"Ying Guo\"},{\"authorId\":\"49663403\",\"name\":\"Wenbin Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2990683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"title\":\"A Temporal Sequence Dual-Branch Network for Classifying Hybrid Ultrasound Data of Breast Cancer\",\"url\":\"https://www.semanticscholar.org/paper/52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387702220\",\"name\":\"Wanqiang Zheng\"},{\"authorId\":\"1388235510\",\"name\":\"Punan Jing\"},{\"authorId\":\"67059706\",\"name\":\"Qingyang Xu\"}],\"doi\":\"10.1145/3331453.3361651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c33dc4d2af3c8b8fe28772e0ea9a4faef91b973\",\"title\":\"Action Recognition Based on Spatial Temporal Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/2c33dc4d2af3c8b8fe28772e0ea9a4faef91b973\",\"venue\":\"CSAE 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24559284\",\"name\":\"A. Patra\"},{\"authorId\":\"144872751\",\"name\":\"J. Noble\"}],\"doi\":\"10.1109/ISBI.2019.8759551\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2dd7131fbad6ca8adac904f7c3558aead6b008f8\",\"title\":\"Multi-anatomy localization in fetal echocardiography videos\",\"url\":\"https://www.semanticscholar.org/paper/2dd7131fbad6ca8adac904f7c3558aead6b008f8\",\"venue\":\"2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46433230\",\"name\":\"Y. Zhou\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"46275945\",\"name\":\"Jingyu Li\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1725421\",\"name\":\"Shi Qiu\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"}],\"doi\":\"10.1145/3134263.3134265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"title\":\"Video Classification via Relational Feature Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46395977\",\"name\":\"Yaohui Wang\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"},{\"authorId\":\"12565299\",\"name\":\"Jean-Claude Broutart\"},{\"authorId\":\"144805077\",\"name\":\"P. Robert\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"31474374\",\"name\":\"P. Bilinski\"}],\"doi\":\"10.1007/978-3-030-11024-6_10\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"6164a339b387b1964e62a490456c4e4b15696361\",\"title\":\"Comparing Methods for Assessment of Facial Dynamics in Patients with Major Neurocognitive Disorders\",\"url\":\"https://www.semanticscholar.org/paper/6164a339b387b1964e62a490456c4e4b15696361\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49831019\",\"name\":\"Pengcheng Wang\"},{\"authorId\":\"50341413\",\"name\":\"S. Li\"}],\"doi\":\"10.1117/12.2513868\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6f8e35dfcbd99269a38915f1b268452c9b5dab0\",\"title\":\"Structural-attentioned LSTM for action recognition based on skeleton\",\"url\":\"https://www.semanticscholar.org/paper/e6f8e35dfcbd99269a38915f1b268452c9b5dab0\",\"venue\":\"Other Conferences\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245665\",\"name\":\"H. F. M. Zaki\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1016/j.robot.2017.02.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"484ee36d9f6ca316a280319298159b3d968fd3e5\",\"title\":\"Learning a deeply supervised multi-modal RGB-D embedding for semantic scene and object category recognition\",\"url\":\"https://www.semanticscholar.org/paper/484ee36d9f6ca316a280319298159b3d968fd3e5\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389422664\",\"name\":\"Roshan Singh\"},{\"authorId\":\"3016430\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"1483623375\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1109/ISCON47742.2019.9036262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6466845f3bdc7e786ba1c519c512fc2edce274d9\",\"title\":\"Activity Recognition by Delving deeper using CNN and RNN\",\"url\":\"https://www.semanticscholar.org/paper/6466845f3bdc7e786ba1c519c512fc2edce274d9\",\"venue\":\"2019 4th International Conference on Information Systems and Computer Networks (ISCON)\",\"year\":2019},{\"arxivId\":\"1911.08511\",\"authors\":[{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"title\":\"Action Recognition Using Volumetric Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144199653\",\"name\":\"Fei Guo\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/ICIP.2018.8451260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d480a41e82ecad487d0a6c6f4a645c0f2459a4bd\",\"title\":\"Deep Camera Pose Regression Using Motion Vectors\",\"url\":\"https://www.semanticscholar.org/paper/d480a41e82ecad487d0a6c6f4a645c0f2459a4bd\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46652125\",\"name\":\"Chaobo Li\"},{\"authorId\":\"35579467\",\"name\":\"Yupeng Ding\"},{\"authorId\":\"119885907\",\"name\":\"Hongjun Li\"}],\"doi\":\"10.1007/978-3-030-36189-1_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40088dfb7b59fc2a1faa69d206b350904897682e\",\"title\":\"Sparse-Temporal Segment Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/40088dfb7b59fc2a1faa69d206b350904897682e\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9297958\",\"name\":\"C. Ranieri\"},{\"authorId\":\"143746261\",\"name\":\"P. Vargas\"},{\"authorId\":\"144050092\",\"name\":\"R. Romero\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e70f65ca216a7da13de5208659c12c64ab986cc\",\"title\":\"Uncovering Human Multimodal Activity Recognition with a Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/3e70f65ca216a7da13de5208659c12c64ab986cc\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1911.11462\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.01017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"title\":\"G-TAD: Sub-Graph Localization for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":\"10.1109/ICPR.2018.8545639\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"title\":\"Two-Stream Gated Fusion ConvNets for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35038524\",\"name\":\"R\\u00faben Geraldes\"},{\"authorId\":\"145568152\",\"name\":\"Artur Gon\\u00e7alves\"},{\"authorId\":\"121502726\",\"name\":\"Tin Lai\"},{\"authorId\":\"1395722933\",\"name\":\"Mathias Villerabel\"},{\"authorId\":\"13480585\",\"name\":\"Wenlong Deng\"},{\"authorId\":\"122560302\",\"name\":\"Ana Salta\"},{\"authorId\":\"1943224\",\"name\":\"K. Nakayama\"},{\"authorId\":\"145733486\",\"name\":\"Y. Matsuo\"},{\"authorId\":\"2356111\",\"name\":\"H. Prendinger\"}],\"doi\":\"10.1109/ACCESS.2019.2938249\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fb70b2ed97d255a870bedbda6758051173d7ce8a\",\"title\":\"UAV-Based Situational Awareness System Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/fb70b2ed97d255a870bedbda6758051173d7ce8a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2768467\",\"name\":\"Jennifer Vandoni\"},{\"authorId\":\"2486147\",\"name\":\"E. Aldea\"},{\"authorId\":\"1401005340\",\"name\":\"S. L. H\\u00e9garat-Mascle\"}],\"doi\":\"10.1016/j.ijar.2018.11.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d75e89dcebbeeb13671ddf7420523f9009c8f8c1\",\"title\":\"Evidential query-by-committee active learning for pedestrian detection in high-density crowds\",\"url\":\"https://www.semanticscholar.org/paper/d75e89dcebbeeb13671ddf7420523f9009c8f8c1\",\"venue\":\"Int. J. Approx. Reason.\",\"year\":2019},{\"arxivId\":\"2009.14635\",\"authors\":[{\"authorId\":\"2146623\",\"name\":\"Kourosh Meshgi\"},{\"authorId\":\"31095396\",\"name\":\"Maryam Sadat Mirzaei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"910a5ed98d7ac0a5015474d6a4c9cfd8d64ab4af\",\"title\":\"Adversarial Semi-Supervised Multi-Domain Tracking\",\"url\":\"https://www.semanticscholar.org/paper/910a5ed98d7ac0a5015474d6a4c9cfd8d64ab4af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134649559\",\"name\":\"R. Kiziltepe\"},{\"authorId\":\"3000774\",\"name\":\"J. Gan\"}],\"doi\":\"10.1007/978-3-030-62362-3_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e543b9710b3dba5d9f77b8f863067bd26422ab6\",\"title\":\"Simple Effective Methods for Decision-Level Fusion in Two-Stream Convolutional Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e543b9710b3dba5d9f77b8f863067bd26422ab6\",\"venue\":\"IDEAL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"},{\"authorId\":\"48805287\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1109/TKDE.2018.2872063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"63787b1fcf5add4b5e25376f7bee155a39e958c3\",\"title\":\"A Survey of Multi-View Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/63787b1fcf5add4b5e25376f7bee155a39e958c3\",\"venue\":\"IEEE Transactions on Knowledge and Data Engineering\",\"year\":2019},{\"arxivId\":\"1806.05653\",\"authors\":[{\"authorId\":\"50997909\",\"name\":\"Amirhossein Dadashzadeh\"},{\"authorId\":\"2310744\",\"name\":\"Alireza Tavakoli Targhi\"},{\"authorId\":\"46371133\",\"name\":\"Maryam Tahmasbi\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.1049/iet-cvi.2018.5796\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"531909281a0c92c738d9abfe7ad9a3630f9a2caf\",\"title\":\"HGR-Net: a fusion network for hand gesture segmentation and recognition\",\"url\":\"https://www.semanticscholar.org/paper/531909281a0c92c738d9abfe7ad9a3630f9a2caf\",\"venue\":\"IET Comput. Vis.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684884626\",\"name\":\"Qiuli Wang\"},{\"authorId\":\"144485153\",\"name\":\"D. Yang\"},{\"authorId\":\"1684790963\",\"name\":\"Zhihuan Li\"},{\"authorId\":\"1791962\",\"name\":\"X. Zhang\"},{\"authorId\":\"49046281\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2990423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eea79c7353416a8fa4675d7fe10f4975b5285291\",\"title\":\"Deep Regression via Multi-Channel Multi-Modal Learning for Pneumonia Screening\",\"url\":\"https://www.semanticscholar.org/paper/eea79c7353416a8fa4675d7fe10f4975b5285291\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1049/iet-cvi.2017.0005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"title\":\"Fully convolutional networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b73a0ce55cebe2c92b0ad38c7c1db466714ea0e8\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"50695792\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME.2019.00182\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdfcaf729fea332fc0a259143c406cee51303854\",\"title\":\"Recognizing Micro Actions in Videos: Learning Motion Details via Segment-Level Temporal Pyramid\",\"url\":\"https://www.semanticscholar.org/paper/fdfcaf729fea332fc0a259143c406cee51303854\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1810.01455\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2019.01018\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"title\":\"Representation Flow for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.07853\",\"authors\":[{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/CVPR.2019.00440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66c21a179824037becb94105cafea75c746ad89a\",\"title\":\"Learning Video Representations From Correspondence Proposals\",\"url\":\"https://www.semanticscholar.org/paper/66c21a179824037becb94105cafea75c746ad89a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1910.03579\",\"authors\":[{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2820254\",\"name\":\"Eirina Bourtsoulatze\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3023597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"title\":\"Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing\",\"url\":\"https://www.semanticscholar.org/paper/5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31634716\",\"name\":\"Huosheng Xie\"},{\"authorId\":\"2042838335\",\"name\":\"Hongwen Luo\"},{\"authorId\":\"11662913\",\"name\":\"J. Lin\"},{\"authorId\":\"37092569\",\"name\":\"Ning Yang\"}],\"doi\":\"10.1177/1748302620983661\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e170ec3e0ff8a5ccaaacda27f7820df7cd04529\",\"title\":\"A novel algorithm of fast CPR quality evaluation based on kinect\",\"url\":\"https://www.semanticscholar.org/paper/7e170ec3e0ff8a5ccaaacda27f7820df7cd04529\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d281b07ee152f6c1312297b71791d358f4dc88cb\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360$^{\\\\circ}$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/d281b07ee152f6c1312297b71791d358f4dc88cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8726117\",\"name\":\"Jen-Cheng Hou\"},{\"authorId\":\"2426246\",\"name\":\"S. Wang\"},{\"authorId\":\"145274549\",\"name\":\"Ying-Hui Lai\"},{\"authorId\":\"145403933\",\"name\":\"Y. Tsao\"},{\"authorId\":\"144600099\",\"name\":\"Hsiu-Wen Chang\"},{\"authorId\":\"1710199\",\"name\":\"H. Wang\"}],\"doi\":\"10.1109/TETCI.2017.2784878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddf1461979a5e39321b931cfe5b470999b5e4aab\",\"title\":\"Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ddf1461979a5e39321b931cfe5b470999b5e4aab\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"3040136\",\"name\":\"Yemin Shi\"},{\"authorId\":\"1576036690\",\"name\":\"Daochen Shi\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"3342777\",\"name\":\"Yongsheng Liang\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TMM.2020.2972128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94ebd897b1be9b15b547cff41a3aff2efbca2854\",\"title\":\"Adaptation-Oriented Feature Projection for One-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94ebd897b1be9b15b547cff41a3aff2efbca2854\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47558252\",\"name\":\"Y. Chen\"},{\"authorId\":\"27423107\",\"name\":\"Shanzhen Lan\"},{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"46461170\",\"name\":\"Yan Yang\"},{\"authorId\":null,\"name\":\"You Wang\"}],\"doi\":\"10.1109/ICCST50977.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"805233f3398deb9cc9dd616ebf3e51cb351fbd51\",\"title\":\"Boundary Sensitive and Confidence Fusion Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/805233f3398deb9cc9dd616ebf3e51cb351fbd51\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":\"1706.04508\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TMM.2018.2823900\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"title\":\"Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1906.03683\",\"authors\":[{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"1914418\",\"name\":\"Takaaki Tagawa\"},{\"authorId\":\"147128583\",\"name\":\"Jia-En M. Pan\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2674833\",\"name\":\"B. Douillard\"}],\"doi\":\"10.1109/IVS.2019.8814278\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7437cce0417848d1492f980daa8742e71131cdf\",\"title\":\"An Attention-based Recurrent Convolutional Network for Vehicle Taillight Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c7437cce0417848d1492f980daa8742e71131cdf\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":\"1812.01053\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"title\":\"MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.06.071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"title\":\"Action recognition using spatial-optical data organization and sequential learning framework\",\"url\":\"https://www.semanticscholar.org/paper/f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"}],\"doi\":\"10.1007/978-3-030-12177-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7f93e107e81125397652c5d2ae4535c5344612\",\"title\":\"Three-Stream Convolution Networks After Background Subtraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d7f93e107e81125397652c5d2ae4535c5344612\",\"venue\":\"FFER/DLPR@ICPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.07503\",\"authors\":[{\"authorId\":\"143749869\",\"name\":\"Y. Pan\"},{\"authorId\":\"1703302\",\"name\":\"J. Xu\"},{\"authorId\":\"50468674\",\"name\":\"M. Wang\"},{\"authorId\":\"7173620\",\"name\":\"Jinmian Ye\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":\"10.1609/aaai.v33i01.33014683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"title\":\"Compressing Recurrent Neural Networks with Tensor Ring for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"39952920\",\"name\":\"Q. Qin\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.patcog.2018.01.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa733992a236258adf36a41413b96707c8e9f4c\",\"title\":\"Multi-stream CNN: Learning representations based on human-related regions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/baa733992a236258adf36a41413b96707c8e9f4c\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"34765265\",\"name\":\"C. Yang\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2019.00013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dcdf68e007737ebae40e27239b3340b236337f03\",\"title\":\"Video Action Recognition With an Additional End-to-End Trained Temporal Stream\",\"url\":\"https://www.semanticscholar.org/paper/dcdf68e007737ebae40e27239b3340b236337f03\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7517b91073dc9ab5a1c7e73010ffa55e39a1f3c9\",\"title\":\"Automated Assessment of the Curliness of Collagen Fiber in Breast Cancer\",\"url\":\"https://www.semanticscholar.org/paper/7517b91073dc9ab5a1c7e73010ffa55e39a1f3c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b07546f26a99b61c5045e313bc024b0fe7de590a\",\"title\":\"Bilinear CNNs for Fine-grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b07546f26a99b61c5045e313bc024b0fe7de590a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1611.09078\",\"authors\":[{\"authorId\":\"2129493\",\"name\":\"Timur M. Bagautdinov\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"2721983\",\"name\":\"F. Fleuret\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/CVPR.2017.365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81ba5202424906f64b77f68afca063658139fbb2\",\"title\":\"Social Scene Understanding: End-to-End Multi-person Action Localization and Collective Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/81ba5202424906f64b77f68afca063658139fbb2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.08238\",\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"225fb9181545f8750061c7693661b62d715dc542\",\"title\":\"Multi-Level Recurrent Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/225fb9181545f8750061c7693661b62d715dc542\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"32281398\",\"name\":\"V. Q. Tran\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"}],\"doi\":\"10.1109/FG.2018.00076\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bb36c875754a2a8919f2f9b00a336c00006e453\",\"title\":\"Eigen-Evolution Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2bb36c875754a2a8919f2f9b00a336c00006e453\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"448c3a671ff66fd9184f2a8482dfbe223913035c\",\"title\":\"Boundary Sensitive Network : Submission to ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/448c3a671ff66fd9184f2a8482dfbe223913035c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2365404\",\"name\":\"N. Ghatwary\"},{\"authorId\":\"34040702\",\"name\":\"Xujiong Ye\"},{\"authorId\":\"2070333\",\"name\":\"M. Zolgharni\"}],\"doi\":\"10.1109/ACCESS.2019.2925585\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ed774fcf970f1ae96c2d0627cc1378886d27d81\",\"title\":\"Esophageal Abnormality Detection Using DenseNet Based Faster R-CNN With Gabor Features\",\"url\":\"https://www.semanticscholar.org/paper/4ed774fcf970f1ae96c2d0627cc1378886d27d81\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41173970\",\"name\":\"I. Li\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"37738947ef9d8f1f48a0e81321e813414235a396\",\"title\":\"Hierarchical Seq 2 Seq : Learning Representations of Online Spoken Speech\",\"url\":\"https://www.semanticscholar.org/paper/37738947ef9d8f1f48a0e81321e813414235a396\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151493680\",\"name\":\"Jingjun Chen\"},{\"authorId\":\"1682580\",\"name\":\"Y. Song\"},{\"authorId\":\"1591129121\",\"name\":\"Yuanlin Zhang\"}],\"doi\":\"10.1109/ICME.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"title\":\"Spatial Mask ConvLSTM Network and Intra-Class Joint Training Method for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144739475\",\"name\":\"Jian Xiong\"},{\"authorId\":\"97295020\",\"name\":\"Liguo Lu\"},{\"authorId\":\"51464961\",\"name\":\"Hengbing Wang\"},{\"authorId\":null,\"name\":\"Jie Yang\"},{\"authorId\":\"152593447\",\"name\":\"Guan Gui\"}],\"doi\":\"10.1109/ACCESS.2019.2931471\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9339c00617b803c2426ad37dffaaff981ad9396\",\"title\":\"Object-Level Trajectories Based Fine-Grained Action Recognition in Visual IoT Applications\",\"url\":\"https://www.semanticscholar.org/paper/e9339c00617b803c2426ad37dffaaff981ad9396\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/IJCNN.2019.8852090\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a525e9553fdbaec7648bb64e97d8865be07c526\",\"title\":\"Directional Attention based Video Frame Prediction using Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a525e9553fdbaec7648bb64e97d8865be07c526\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91999133\",\"name\":\"Ji-Hwan Kim\"},{\"authorId\":\"3247148\",\"name\":\"Jae-Pil Heo\"}],\"doi\":\"10.1109/ACCESS.2019.2946898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1db07ce91065594751cd51d31f086bc02d42968\",\"title\":\"Learning Coarse and Fine Features for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f1db07ce91065594751cd51d31f086bc02d42968\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1791201\",\"name\":\"Mingyang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c23d1fd3d9fc981a9d5919e905c765ccf149dc0\",\"title\":\"Shared model for multi-source speech generation tasks\",\"url\":\"https://www.semanticscholar.org/paper/3c23d1fd3d9fc981a9d5919e905c765ccf149dc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ICAICTA.2019.8904245\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"title\":\"Action Recognition by Composite Deep Learning Architecture I3D-DenseLSTM\",\"url\":\"https://www.semanticscholar.org/paper/6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"93233966\",\"name\":\"Chunping Hou\"},{\"authorId\":\"145874777\",\"name\":\"Y. Lang\"},{\"authorId\":\"144902595\",\"name\":\"T. Sakamoto\"},{\"authorId\":\"143605211\",\"name\":\"Yuan He\"},{\"authorId\":\"144455669\",\"name\":\"Wei Xiang\"}],\"doi\":\"10.1109/TGRS.2019.2958178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3b126f91b1a3f1f0c4664e2850f37419bb1121d\",\"title\":\"Omnidirectional Motion Classification With Monostatic Radar System Using Micro-Doppler Signatures\",\"url\":\"https://www.semanticscholar.org/paper/f3b126f91b1a3f1f0c4664e2850f37419bb1121d\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2566189\",\"name\":\"Suguo Zhu\"},{\"authorId\":\"51188296\",\"name\":\"Zhenying Fang\"},{\"authorId\":\"40013369\",\"name\":\"Y. Wang\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"}],\"doi\":\"10.1016/J.JVCIR.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"title\":\"Multimodal activity recognition with local block CNN and attention-based spatial weighted CNN\",\"url\":\"https://www.semanticscholar.org/paper/74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2024263545\",\"name\":\"Cai Yiheng\"},{\"authorId\":\"2024656841\",\"name\":\"Kong Xinran\"},{\"authorId\":\"2022577443\",\"name\":\"Wang Xueyan\"}],\"doi\":\"10.1145/3278198.3278224\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"412c640aee0c4f53bb2ad1746518a0fbf6220ae7\",\"title\":\"Temporal Action Detection with Long Action Seam Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/412c640aee0c4f53bb2ad1746518a0fbf6220ae7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101687783\",\"name\":\"O. Friberg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba018189673d883920111184040d307153346267\",\"title\":\"Recognizing Semantics in Human Actions with Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/ba018189673d883920111184040d307153346267\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2698334\",\"name\":\"Hatem A. Rashwan\"},{\"authorId\":\"1657429080\",\"name\":\"Miguel \\u00c1ngel Amor Garc\\u00eda\"},{\"authorId\":\"48067440\",\"name\":\"S. Abdulwahab\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1007/s11042-020-09194-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6e9ec78306f6c1a3bc1c6ce27618166bfb8c10c\",\"title\":\"Action representation and recognition through temporal co-occurrence of flow fields and convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d6e9ec78306f6c1a3bc1c6ce27618166bfb8c10c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1801.07388\",\"authors\":[{\"authorId\":\"118242229\",\"name\":\"D. Castro\"},{\"authorId\":\"2935619\",\"name\":\"Steven Hickson\"},{\"authorId\":\"3430745\",\"name\":\"Patsorn Sangkloy\"},{\"authorId\":\"145389008\",\"name\":\"Bhavishya Mittal\"},{\"authorId\":\"35459529\",\"name\":\"Sean Dai\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6e25cab2251a8ded43c44b28a87f4c62e3a548a\",\"title\":\"Let's Dance: Learning From Online Dance Videos\",\"url\":\"https://www.semanticscholar.org/paper/a6e25cab2251a8ded43c44b28a87f4c62e3a548a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16697766\",\"name\":\"S. Ma\"},{\"authorId\":\"144123438\",\"name\":\"Song Guo\"},{\"authorId\":\"144547971\",\"name\":\"Kun Wang\"},{\"authorId\":\"1697293\",\"name\":\"M. Guo\"}],\"doi\":\"10.1109/ICDCS.2019.00095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b1551b9cd4d5e3b5664d04a78e3f99f672e1f76\",\"title\":\"Service Demand Prediction with Incomplete Historical Data\",\"url\":\"https://www.semanticscholar.org/paper/9b1551b9cd4d5e3b5664d04a78e3f99f672e1f76\",\"venue\":\"2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120775311\",\"name\":\"D. Wu\"},{\"authorId\":\"49251523\",\"name\":\"Junjun Chen\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"2585415\",\"name\":\"Shirui Pan\"},{\"authorId\":\"97846126\",\"name\":\"Guodong Long\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN.2019.8851993\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cd307e67ac0bbcf2c2f4abc1bbc643067b57fb0\",\"title\":\"Adversarial Action Data Augmentation for Similar Gesture Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cd307e67ac0bbcf2c2f4abc1bbc643067b57fb0\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2480182\",\"name\":\"Earnest Paul Ijjina\"},{\"authorId\":\"31666069\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1016/j.patcog.2017.07.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6f58ac503c5a053ea30a1cf0d463646514992a9\",\"title\":\"Human action recognition in RGB-D videos using motion sequence information and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/b6f58ac503c5a053ea30a1cf0d463646514992a9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46895558\",\"name\":\"W. Song\"},{\"authorId\":\"38763335\",\"name\":\"Xinguo Yu\"}],\"doi\":\"10.1007/978-3-030-34879-3_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dd4965e33dbb9acbe22dd77bb9a7200b7b30134\",\"title\":\"Double Channel 3D Convolutional Neural Network for Exam Scene Classification of Invigilation Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dd4965e33dbb9acbe22dd77bb9a7200b7b30134\",\"venue\":\"PSIVT\",\"year\":2019},{\"arxivId\":\"1710.02310\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ad264201e0628723af373d17f8ed98408e8dda0\",\"title\":\"Detecting the Moment of Completion: Temporal Models for Localising Action Completion\",\"url\":\"https://www.semanticscholar.org/paper/2ad264201e0628723af373d17f8ed98408e8dda0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2011.00694\",\"authors\":[{\"authorId\":\"2845900\",\"name\":\"Lufei Gao\"},{\"authorId\":\"91391672\",\"name\":\"R. Zhou\"},{\"authorId\":\"8061954\",\"name\":\"Changfeng Dong\"},{\"authorId\":\"1399885883\",\"name\":\"Cheng Feng\"},{\"authorId\":\"49969637\",\"name\":\"Zhuguo Li\"},{\"authorId\":\"2005096276\",\"name\":\"Xiang Wan\"},{\"authorId\":\"2349140\",\"name\":\"Li Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31b16740b08fb32b42c2df8d91cb7f4b216bae11\",\"title\":\"Multi-Modal Active Learning for Automatic Liver Fibrosis Diagnosis based on Ultrasound Shear Wave Elastography\",\"url\":\"https://www.semanticscholar.org/paper/31b16740b08fb32b42c2df8d91cb7f4b216bae11\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/DICTA.2017.8227428\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b8b33481e92189044fd595ed9d177812017e0f3\",\"title\":\"Evaluation of Triple-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b8b33481e92189044fd595ed9d177812017e0f3\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patcog.2018.07.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bbee095fc18a34e6bce72c51cea8f06cb5f4da0\",\"title\":\"Pseudo low rank video representation\",\"url\":\"https://www.semanticscholar.org/paper/0bbee095fc18a34e6bce72c51cea8f06cb5f4da0\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1910.06540\",\"authors\":[{\"authorId\":\"34831857\",\"name\":\"Jasper S. Wijnands\"},{\"authorId\":\"145040690\",\"name\":\"J. Thompson\"},{\"authorId\":\"52351371\",\"name\":\"Kerry A. Nice\"},{\"authorId\":\"75058211\",\"name\":\"G. Aschwanden\"},{\"authorId\":\"144795096\",\"name\":\"M. Stevenson\"}],\"doi\":\"10.1007/s00521-019-04506-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82a9a9fde3c2c7acb2980506c15d323b338ad85b\",\"title\":\"Real-time monitoring of driver drowsiness on mobile platforms using 3D neural networks\",\"url\":\"https://www.semanticscholar.org/paper/82a9a9fde3c2c7acb2980506c15d323b338ad85b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"2011.00618\",\"authors\":[{\"authorId\":\"1845870613\",\"name\":\"Kapal Dev\"},{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"51135838\",\"name\":\"A. Jaiswal\"},{\"authorId\":\"2346704\",\"name\":\"A. Bist\"},{\"authorId\":\"144102699\",\"name\":\"Vaibhav Saini\"},{\"authorId\":\"3412034\",\"name\":\"S. Bhatia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cfdec7cd7f6412354bccdc1a85ac532af252ef0\",\"title\":\"Triage of Potential COVID-19 Patients from Chest X-ray Images using Hierarchical Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3cfdec7cd7f6412354bccdc1a85ac532af252ef0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.09616\",\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"},{\"authorId\":\"145087510\",\"name\":\"H. Krim\"}],\"doi\":\"10.1609/aaai.v34i07.6870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"title\":\"Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering Approach for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1711.08789\",\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f04d8a78cd33ac944353c55d3d40230ef504f449\",\"title\":\"Visual Speech Enhancement using Noise-Invariant Training\",\"url\":\"https://www.semanticscholar.org/paper/f04d8a78cd33ac944353c55d3d40230ef504f449\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27078642\",\"name\":\"Y. Miao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"46636537\",\"name\":\"Y. Gao\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/J.PATREC.2019.04.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cefb02f19879e1ea21dffb55faef7f7247f2d209\",\"title\":\"ST-CNN: Spatial-Temporal Convolutional Neural Network for crowd counting in videos\",\"url\":\"https://www.semanticscholar.org/paper/cefb02f19879e1ea21dffb55faef7f7247f2d209\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47916686\",\"name\":\"K. Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"}],\"doi\":\"10.1587/TRANSINF.2017EDL8049\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"title\":\"Trajectory-Set Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144713153\",\"name\":\"Dan Guo\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"}],\"doi\":\"10.1145/3152121\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2871cb56a9a8b0dfe882d16996defec0a0e0732b\",\"title\":\"Online Early-Late Fusion Based on Adaptive HMM for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2871cb56a9a8b0dfe882d16996defec0a0e0732b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"},{\"authorId\":\"49042243\",\"name\":\"Fengqing M Zhu\"},{\"authorId\":\"152921498\",\"name\":\"E. Cai\"},{\"authorId\":\"1720731758\",\"name\":\"Alain Chen\"},{\"authorId\":\"49025814\",\"name\":\"D. Chen\"},{\"authorId\":\"2809098\",\"name\":\"Q. Chen\"},{\"authorId\":\"50579821\",\"name\":\"Yuhao Chen\"},{\"authorId\":\"121954414\",\"name\":\"Jiaqi Guo\"},{\"authorId\":\"2318891\",\"name\":\"Mridul Gupta\"},{\"authorId\":\"1390542522\",\"name\":\"Shuo Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e542a578af706862dd99af178f31a9e0ea260dc9\",\"title\":\"THE PURDUE UNIVERSITY GRADUATE SCHOOL STATEMENT OF DISSERTATION APPROVAL\",\"url\":\"https://www.semanticscholar.org/paper/e542a578af706862dd99af178f31a9e0ea260dc9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40909443\",\"name\":\"Y. Hu\"},{\"authorId\":\"50655168\",\"name\":\"MingQi Lu\"},{\"authorId\":\"47415615\",\"name\":\"Chao Xie\"},{\"authorId\":\"153010660\",\"name\":\"Xiao-Bo Lu\"}],\"doi\":\"10.1109/TCSVT.2019.2958188\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fed50b6e4411a15bdec1dc85680fc0ddb60e107b\",\"title\":\"Driver Drowsiness Recognition via 3D Conditional GAN and Two-Level Attention Bi-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fed50b6e4411a15bdec1dc85680fc0ddb60e107b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2009.06902\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"1605763279\",\"name\":\"Dongliang Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"title\":\"Collaborative Distillation in the Parameter and Spectrum Domains for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02531\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3394171.3413694\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"title\":\"Self-supervised Video Representation Learning Using Inter-intra Contrastive Framework\",\"url\":\"https://www.semanticscholar.org/paper/de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.02632\",\"authors\":[{\"authorId\":\"52025559\",\"name\":\"Mahsa Ehsanpour\"},{\"authorId\":\"3447236\",\"name\":\"A. Abedin\"},{\"authorId\":\"19170799\",\"name\":\"F. Saleh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1007/978-3-030-58545-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81287e31f3e659aaedb5dce0646ba2b86377b282\",\"title\":\"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/81287e31f3e659aaedb5dce0646ba2b86377b282\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910166\",\"name\":\"Martin Gjoreski\"},{\"authorId\":\"3252158\",\"name\":\"Vito Janko\"},{\"authorId\":\"41154826\",\"name\":\"Gasper Slapnicar\"},{\"authorId\":\"2008234\",\"name\":\"Miha Mlakar\"},{\"authorId\":\"51882989\",\"name\":\"Nina Res\\u00e7i\\u00e7\"},{\"authorId\":\"8067132\",\"name\":\"J. Bizjak\"},{\"authorId\":\"51879710\",\"name\":\"Vid Drobnic\"},{\"authorId\":\"41154825\",\"name\":\"Matej Marinko\"},{\"authorId\":\"134522278\",\"name\":\"Nejc Mlakar\"},{\"authorId\":\"1723535\",\"name\":\"M. Lustrek\"},{\"authorId\":\"46778930\",\"name\":\"M. Gams\"}],\"doi\":\"10.1016/j.inffus.2020.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f668ac68e28a84f350e5837133e1938f5f60cd\",\"title\":\"Classical and deep learning methods for recognizing human activities and modes of transportation with smartphone sensors\",\"url\":\"https://www.semanticscholar.org/paper/b1f668ac68e28a84f350e5837133e1938f5f60cd\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2487235\",\"name\":\"Wen-Chia Tsai\"},{\"authorId\":\"153819312\",\"name\":\"Kuan-Chou. Chen\"},{\"authorId\":\"1878732094\",\"name\":\"Jhih-Sheng Lai\"},{\"authorId\":\"36027402\",\"name\":\"Jiun-In Guo\"}],\"doi\":\"10.1109/MWSCAS48704.2020.9184578\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97fb6c6d29246ceb5a70138ff1847f9cdeea1305\",\"title\":\"Front Moving Object Behavior Prediction System Exploiting Deep Learning Technology for ADAS Applications\",\"url\":\"https://www.semanticscholar.org/paper/97fb6c6d29246ceb5a70138ff1847f9cdeea1305\",\"venue\":\"2020 IEEE 63rd International Midwest Symposium on Circuits and Systems (MWSCAS)\",\"year\":2020},{\"arxivId\":\"1907.12023\",\"authors\":[{\"authorId\":\"51257987\",\"name\":\"Weisen Wang\"},{\"authorId\":\"47047780\",\"name\":\"Zhiyan Xu\"},{\"authorId\":\"48729616\",\"name\":\"Weihong Yu\"},{\"authorId\":\"10261852\",\"name\":\"Jianchun Zhao\"},{\"authorId\":\"51463706\",\"name\":\"Jingyuan Yang\"},{\"authorId\":\"144809303\",\"name\":\"Feng He\"},{\"authorId\":\"47087463\",\"name\":\"Z. Yang\"},{\"authorId\":\"1915664\",\"name\":\"Di Chen\"},{\"authorId\":\"50792192\",\"name\":\"Dayong Ding\"},{\"authorId\":\"50581019\",\"name\":\"You-xin Chen\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":\"10.1007/978-3-030-32239-7_18\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"39dab44bcfdfe1907e9b12282bce8c4cb7856cd0\",\"title\":\"Two-Stream CNN with Loose Pair Training for Multi-modal AMD Categorization\",\"url\":\"https://www.semanticscholar.org/paper/39dab44bcfdfe1907e9b12282bce8c4cb7856cd0\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1845915519\",\"name\":\"Eric Kasangu Lubamba\"},{\"authorId\":\"92581630\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3008848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c7c4556126f7219886cd28e4f33c85586f24955\",\"title\":\"Action Prediction Based on Partial Video Observation via Context and Temporal Sequential Network With Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/5c7c4556126f7219886cd28e4f33c85586f24955\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.11022\",\"authors\":[{\"authorId\":\"103603255\",\"name\":\"Yehui Tang\"},{\"authorId\":null,\"name\":\"Yunhe Wang\"},{\"authorId\":\"6898202\",\"name\":\"Yixing Xu\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"145194966\",\"name\":\"Chao Xu\"},{\"authorId\":\"1691522\",\"name\":\"Chunjing Xu\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"}],\"doi\":\"10.1609/AAAI.V34I04.6057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ba536d9f9b7d7118602e34931852900857f0149\",\"title\":\"Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6ba536d9f9b7d7118602e34931852900857f0149\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1812.10328\",\"authors\":[{\"authorId\":\"51264689\",\"name\":\"S. Azar\"},{\"authorId\":\"51443392\",\"name\":\"Mina Ghadimi Atigh\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fbd67c047fdcec3ec157173b4dd28b44cdb3589\",\"title\":\"A Multi-Stream Convolutional Neural Network Framework for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fbd67c047fdcec3ec157173b4dd28b44cdb3589\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.11731\",\"authors\":[{\"authorId\":\"1412518183\",\"name\":\"Marian K. Y. Boktor\"},{\"authorId\":\"1410429737\",\"name\":\"A. Al-Kabbany\"},{\"authorId\":\"46318863\",\"name\":\"Radwa Khalil\"},{\"authorId\":\"1398644693\",\"name\":\"S. El-Khamy\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"6044b30751c19b3231782fb0475c9ca438940690\",\"title\":\"Real-time Action Recognition with Dissimilarity-based Training of Specialized Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/6044b30751c19b3231782fb0475c9ca438940690\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1808.04063\",\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"2057809\",\"name\":\"G. Zhou\"},{\"authorId\":\"3004771\",\"name\":\"L. Bornn\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1751a191e76eb57b1e132cf3ed3bb5964b3ddfe7\",\"title\":\"Time Perception Machine: Temporal Point Processes for the When, Where and What of Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1751a191e76eb57b1e132cf3ed3bb5964b3ddfe7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"31802065\",\"name\":\"Zhaoxuan Fan\"}],\"doi\":\"10.1109/ICIP.2017.8296913\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"575db9fa61a9cb81a87859c20515806d55f66d27\",\"title\":\"Temporal action localization with two-stream segment-based RNN\",\"url\":\"https://www.semanticscholar.org/paper/575db9fa61a9cb81a87859c20515806d55f66d27\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1810.07212\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1007/978-3-030-01261-8_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"title\":\"Cross-Modal and Hierarchical Modeling of Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40909443\",\"name\":\"Y. Hu\"},{\"authorId\":\"50655168\",\"name\":\"MingQi Lu\"},{\"authorId\":\"144898651\",\"name\":\"Xiaobo Lu\"}],\"doi\":\"10.1007/s00138-018-0994-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f89974409e0064c3c739834e211eccd6f499e6b\",\"title\":\"Driving behaviour recognition from still images by using multi-stream fusion CNN\",\"url\":\"https://www.semanticscholar.org/paper/0f89974409e0064c3c739834e211eccd6f499e6b\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/DICTA.2018.8615804\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db86679d00baab8e21b436e05c17a661257ad8fd\",\"title\":\"Similar Gesture Recognition using Hierarchical Classification Approach in RGB Videos\",\"url\":\"https://www.semanticscholar.org/paper/db86679d00baab8e21b436e05c17a661257ad8fd\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"title\":\"Inertial-Vision: Cross-Domain Knowledge Transfer for Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/0d0868e5ea1fc07cd465f5d74f20cb05573eba6b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51498323\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"3016430\",\"name\":\"Alok Kumar Singh Kushwaha\"}],\"doi\":\"10.1109/ICSCCC.2018.8703295\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8354ae30ddbf9f4e7f6a92673ca5d1ee2a17d3b5\",\"title\":\"Deep Learning Approaches for Human Activity Recognition in Video Surveillance - A Survey\",\"url\":\"https://www.semanticscholar.org/paper/8354ae30ddbf9f4e7f6a92673ca5d1ee2a17d3b5\",\"venue\":\"2018 First International Conference on Secure Cyber Computing and Communication (ICSCCC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00807\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"title\":\"MARS: Motion-Augmented RGB Stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1810.03414\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1109/ICASSP.2019.8683898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97924ebc712b3739adfdadfd428247fce84af4b5\",\"title\":\"Dense Multimodal Fusion for Hierarchically Joint Representation\",\"url\":\"https://www.semanticscholar.org/paper/97924ebc712b3739adfdadfd428247fce84af4b5\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2004.06180\",\"authors\":[{\"authorId\":\"49296185\",\"name\":\"Neha Bhargava\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"054a27eb34260abfd51bc66b7d56e2d675aa9f85\",\"title\":\"Challenges and Opportunities for Computer Vision in Real-life Soccer Analytics\",\"url\":\"https://www.semanticscholar.org/paper/054a27eb34260abfd51bc66b7d56e2d675aa9f85\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.08178\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"48696416\",\"name\":\"Y. Cao\"},{\"authorId\":\"1761508\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803564\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"title\":\"Multi-Stream Single Shot Spatial-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145874475\",\"name\":\"Li Cheng\"},{\"authorId\":\"15132338\",\"name\":\"X. Jing\"},{\"authorId\":\"15318223\",\"name\":\"Xiao-ke Zhu\"},{\"authorId\":\"46499146\",\"name\":\"Fei Ma\"},{\"authorId\":\"144901835\",\"name\":\"Chang-Hui Hu\"},{\"authorId\":\"3397609\",\"name\":\"Ziyun Cai\"},{\"authorId\":\"2163054\",\"name\":\"Fumin Qi\"}],\"doi\":\"10.1007/s00521-020-04730-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05d2fae74ae656dfecc411b951dc4162d3442dd1\",\"title\":\"Scale-fusion framework for improving video-based person re-identification performance\",\"url\":\"https://www.semanticscholar.org/paper/05d2fae74ae656dfecc411b951dc4162d3442dd1\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9191972\",\"name\":\"Xin Men\"},{\"authorId\":\"50813206\",\"name\":\"F. Zhou\"},{\"authorId\":\"33899331\",\"name\":\"Xiaoyong Li\"}],\"doi\":\"10.2312/PG.20181287\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f19c5d8116fbd3e7f9a4e2b078d4a09de9fdcdc\",\"title\":\"A Deep Learned Method for Video Indexing and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7f19c5d8116fbd3e7f9a4e2b078d4a09de9fdcdc\",\"venue\":\"PG\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2009399\",\"name\":\"Igor L. O. Bastos\"},{\"authorId\":\"40658562\",\"name\":\"L. Soares\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1007/978-3-319-75193-1_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"467662cc7c78035f89405f50fd97398e194b5110\",\"title\":\"Pyramidal Zernike Over Time: A Spatiotemporal Feature Descriptor Based on Zernike Moments\",\"url\":\"https://www.semanticscholar.org/paper/467662cc7c78035f89405f50fd97398e194b5110\",\"venue\":\"CIARP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657264680\",\"name\":\"Cece Jin\"},{\"authorId\":\"1500522440\",\"name\":\"T. Zhang\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"title\":\"Regression Before Classification for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1803.11556\",\"authors\":[{\"authorId\":\"10805888\",\"name\":\"Zhongzheng Ren\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/978-3-030-01246-5_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211\",\"title\":\"Learning to Anonymize Faces for Privacy Preserving Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1912.08741\",\"authors\":[{\"authorId\":\"2531432\",\"name\":\"Diego Ortego\"},{\"authorId\":\"107621684\",\"name\":\"Eric Arazo\"},{\"authorId\":\"83107779\",\"name\":\"P. Albert\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d225b29a28b6154a90f29df8df74bed1614b2028\",\"title\":\"Towards Robust Learning with Different Label Noise Distributions\",\"url\":\"https://www.semanticscholar.org/paper/d225b29a28b6154a90f29df8df74bed1614b2028\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bd7b15c7ae060eb029490d5b18617977eb28812\",\"title\":\"Learnable Gated Temporal Shift Module for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/0bd7b15c7ae060eb029490d5b18617977eb28812\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.02665\",\"authors\":[{\"authorId\":\"49039823\",\"name\":\"Weixia Zhang\"},{\"authorId\":\"2233269\",\"name\":\"K. Ma\"},{\"authorId\":\"49780914\",\"name\":\"Jia Yan\"},{\"authorId\":\"1713678\",\"name\":\"D. Deng\"},{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"}],\"doi\":\"10.1109/TCSVT.2018.2886771\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"974ff86cdf8550cffde4d8048609baaac876b563\",\"title\":\"Blind Image Quality Assessment Using a Deep Bilinear Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/974ff86cdf8550cffde4d8048609baaac876b563\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"},{\"authorId\":\"143905686\",\"name\":\"J. R. Beveridge\"},{\"authorId\":\"1694404\",\"name\":\"B. Draper\"}],\"doi\":\"10.1109/IJCNN.2019.8851991\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"6b32068b26fafa8134ad1b90e094cfcbf2369a7a\",\"title\":\"Analyzing Multi-Channel Networks for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6b32068b26fafa8134ad1b90e094cfcbf2369a7a\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9363916\",\"name\":\"Zhao-qiang Wei\"},{\"authorId\":\"153075697\",\"name\":\"Yong-qiang Kong\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"120070034\",\"name\":\"Xiao-Long Zhang\"}],\"doi\":\"10.12783/DTCSE/CCNT2018/24746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de38f058527ef96ad9ee24442c87e6e68da5fc76\",\"title\":\"Temporal-scale Convolutional Networks for Human Action Recognition Based on Key-Frame Extraction\",\"url\":\"https://www.semanticscholar.org/paper/de38f058527ef96ad9ee24442c87e6e68da5fc76\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2269558\",\"name\":\"Q. Li\"},{\"authorId\":\"144854843\",\"name\":\"X. Zhao\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2923444\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ff61d933f95bab4d0390b0372b0e6f1829251c6\",\"title\":\"Recurrent Prediction With Spatio-Temporal Attention for Crowd Attribute Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ff61d933f95bab4d0390b0372b0e6f1829251c6\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"52217578\",\"name\":\"S. Alavi\"}],\"doi\":\"10.1109/ICWR49608.2020.9122304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"title\":\"Human Action Recognition in Video Using DB-LSTM and ResNet\",\"url\":\"https://www.semanticscholar.org/paper/e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"venue\":\"2020 6th International Conference on Web Research (ICWR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145977513\",\"name\":\"J. P. Howard\"},{\"authorId\":\"6426766\",\"name\":\"J. Tan\"},{\"authorId\":\"1398240397\",\"name\":\"Matthew J Shun-Shin\"},{\"authorId\":\"1492187763\",\"name\":\"Dina Mahdi\"},{\"authorId\":\"3537255\",\"name\":\"Alexandra N. Nowbar\"},{\"authorId\":\"8806860\",\"name\":\"A. Arnold\"},{\"authorId\":\"1380362507\",\"name\":\"Y. Ahmad\"},{\"authorId\":\"144062805\",\"name\":\"P. McCartney\"},{\"authorId\":\"2070333\",\"name\":\"M. Zolgharni\"},{\"authorId\":\"48615354\",\"name\":\"Nick W F Linton\"},{\"authorId\":\"1944624\",\"name\":\"N. Sutaria\"},{\"authorId\":\"2577168\",\"name\":\"B. Rana\"},{\"authorId\":\"3050053\",\"name\":\"J. Mayet\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"48633106\",\"name\":\"G. Cole\"},{\"authorId\":\"73404927\",\"name\":\"D. Francis\"}],\"doi\":\"10.21037/jmai.2019.10.03\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82b36e6baa75c700224eb39e9ac838d9adc5d27f\",\"title\":\"Improving ultrasound video classification: an evaluation of novel deep learning methods in echocardiography.\",\"url\":\"https://www.semanticscholar.org/paper/82b36e6baa75c700224eb39e9ac838d9adc5d27f\",\"venue\":\"Journal of medical artificial intelligence\",\"year\":2020},{\"arxivId\":\"1801.01415\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00818\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93a7b595757f0e37e59a7b24c6d08508c4177405\",\"title\":\"What have We Learned from Deep Representations for Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/93a7b595757f0e37e59a7b24c6d08508c4177405\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"47634649\",\"name\":\"Akshay Dudhane\"},{\"authorId\":\"1430720118\",\"name\":\"Prashant W. Patil\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/AVSS.2019.8909835\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cee3f7cb4e13944404d8e92c2ff205cb990e3dc2\",\"title\":\"Pose Guided Dynamic Image Network for Human Action Recognition in Person Centric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cee3f7cb4e13944404d8e92c2ff205cb990e3dc2\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62f1b47d94350ac17ec16e8569dcf6d9cf1ffcda\",\"title\":\"Activity Detection with Latent Sub-event Hierarchy Learning\",\"url\":\"https://www.semanticscholar.org/paper/62f1b47d94350ac17ec16e8569dcf6d9cf1ffcda\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"title\":\"Making Convolutional Networks Recurrent for Visual Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3362496\",\"name\":\"Qinghan Xue\"},{\"authorId\":\"1505621581\",\"name\":\"Abhishek Kolagunda\"},{\"authorId\":\"1911232\",\"name\":\"Steven Eliuk\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/BigData47090.2019.9006395\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa669635d056df7472db544e385b1c168e589bec\",\"title\":\"AWDF: An Adaptive Weighted Deep Fusion Architecture for Multi-modality Learning\",\"url\":\"https://www.semanticscholar.org/paper/fa669635d056df7472db544e385b1c168e589bec\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865403\",\"name\":\"Zhiyu Chen\"},{\"authorId\":\"1668787617\",\"name\":\"Yangwei Gu\"},{\"authorId\":\"50542782\",\"name\":\"Chunhua Deng\"},{\"authorId\":\"34611435\",\"name\":\"Ziqi Zhu\"}],\"doi\":\"10.1109/SPAC49953.2019.237869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"747cd60482560cc92a254eccc516cf8f230845d8\",\"title\":\"Adaptive Temporal Segmentation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/747cd60482560cc92a254eccc516cf8f230845d8\",\"venue\":\"2019 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)\",\"year\":2019},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2011.06958\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4545cdb909f2be23ce6542defef6091912729648\",\"title\":\"SALAD: Self-Assessment Learning for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/4545cdb909f2be23ce6542defef6091912729648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1906.01004\",\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"152284539\",\"name\":\"Qianli Ma\"},{\"authorId\":\"143627576\",\"name\":\"Heiko Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"title\":\"Frontal Low-rank Random Tensors for Fine-grained Action Segmentation.\",\"url\":\"https://www.semanticscholar.org/paper/8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.07641\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"title\":\"BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381737458\",\"name\":\"Bo Fu\"},{\"authorId\":\"8045693\",\"name\":\"Shilin Fu\"},{\"authorId\":\"49681151\",\"name\":\"Liyan Wang\"},{\"authorId\":\"1388030824\",\"name\":\"Yuhan Dong\"},{\"authorId\":\"51110571\",\"name\":\"Y. Ren\"}],\"doi\":\"10.1109/MMUL.2020.3021799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ef53db8150825f6f79fd84982fa8e2affd7df03\",\"title\":\"Deep Residual Split Directed Graph Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ef53db8150825f6f79fd84982fa8e2affd7df03\",\"venue\":\"IEEE MultiMedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3436875\",\"name\":\"Omar ElHarrouss\"},{\"authorId\":\"2380070\",\"name\":\"Noor Almaadeed\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-Maadeed\"}],\"doi\":\"10.1007/978-981-15-0637-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"title\":\"MHAD: Multi-Human Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"venue\":\"ICICT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3164119\",\"name\":\"O. Vynokurova\"},{\"authorId\":\"46713541\",\"name\":\"D. Peleshko\"},{\"authorId\":\"1965935863\",\"name\":\"Marta Peleshko\"}],\"doi\":\"10.1007/978-3-030-61656-4_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"613cd37d12f8756d0a3f1c2452f93ecff9fd369b\",\"title\":\"Hybrid Deep Convolutional Neural Network with Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/613cd37d12f8756d0a3f1c2452f93ecff9fd369b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.15831\",\"authors\":[{\"authorId\":\"51310352\",\"name\":\"Philipp V. Rouast\"},{\"authorId\":\"65980152\",\"name\":\"H. Heydarian\"},{\"authorId\":\"24235135\",\"name\":\"M. Adam\"},{\"authorId\":\"35164715\",\"name\":\"M. Rollo\"}],\"doi\":\"10.1109/ACCESS.2020.3026965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f851a707b673857f7e1e571072894d6893156421\",\"title\":\"OREBA: A Dataset for Objectively Recognizing Eating Behavior and Associated Intake\",\"url\":\"https://www.semanticscholar.org/paper/f851a707b673857f7e1e571072894d6893156421\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.04755\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"title\":\"Generalized Many-Way Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474464\",\"name\":\"Wei Hong Chin\"},{\"authorId\":\"2141400\",\"name\":\"Nuo Wi Noel Tay\"},{\"authorId\":\"145350352\",\"name\":\"N. Kubota\"},{\"authorId\":\"117831028\",\"name\":\"Chu Kiong Loo\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ff99740e33d92be0d18866661184e41085583ba\",\"title\":\"A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System\",\"url\":\"https://www.semanticscholar.org/paper/1ff99740e33d92be0d18866661184e41085583ba\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2004.00451\",\"authors\":[{\"authorId\":\"1573843594\",\"name\":\"Daniel Cores\"},{\"authorId\":\"1725529\",\"name\":\"V. Brea\"},{\"authorId\":\"1734140\",\"name\":\"M. Mucientes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"title\":\"Spatio-temporal Tubelet Feature Aggregation and Object Linking in Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICIP.2017.8296598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df2899462e04559c024a773d91f6e06c262e136b\",\"title\":\"Compressed-domain video classification with deep neural networks: \\u201cThere's way too much information to decode the matrix\\u201d\",\"url\":\"https://www.semanticscholar.org/paper/df2899462e04559c024a773d91f6e06c262e136b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143612376\",\"name\":\"Simon Fraser\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b2a2357b12cf0a5c99c8bc06ef7b46e40dd888e\",\"title\":\"Learning Person Trajectory Representations for Team Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3b2a2357b12cf0a5c99c8bc06ef7b46e40dd888e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1810.11794\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"}],\"doi\":\"10.1007/978-3-030-20890-5_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59795eab858174e34ce31e302f831d1a2243ddb1\",\"title\":\"Cascaded Pyramid Mining Network for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/59795eab858174e34ce31e302f831d1a2243ddb1\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235962\",\"name\":\"Juarez Monteiro\"},{\"authorId\":\"3045512\",\"name\":\"Roger Granada\"},{\"authorId\":\"10684139\",\"name\":\"Jo\\u00e3o Paulo Aires\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN.2018.8489297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eee24e29b1b73bbd1e75ad3cebe28c360f4aab84\",\"title\":\"Evaluating the Feasibility of Deep Learning for Action Recognition in Small Datasets\",\"url\":\"https://www.semanticscholar.org/paper/eee24e29b1b73bbd1e75ad3cebe28c360f4aab84\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":\"1811.08815\",\"authors\":[{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/ICCV.2019.00638\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"title\":\"Learning Motion in Feature Space: Locally-Consistent Deformable Convolution Networks for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.13072\",\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP.2018.8461792\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"title\":\"Cross-Modal Message Passing for Two-Stream Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"49682370\",\"name\":\"Alexander Keidel\"},{\"authorId\":\"73650373\",\"name\":\"Bappaditya Debnath\"}],\"doi\":\"10.1007/978-3-030-12939-2_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64abe70f02579fafc8b23b99700d625f1ca440a4\",\"title\":\"Context-driven Multi-stream LSTM (M-LSTM) for Recognizing Fine-Grained Activity of Drivers\",\"url\":\"https://www.semanticscholar.org/paper/64abe70f02579fafc8b23b99700d625f1ca440a4\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49436226\",\"name\":\"Xi Ouyang\"},{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"3194878\",\"name\":\"Chaoyun Zhang\"},{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"145376360\",\"name\":\"G. Liu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2906654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"title\":\"A 3D-CNN and LSTM Based Multi-Task Learning Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35573748\",\"name\":\"Matthieu Grard\"},{\"authorId\":\"34086868\",\"name\":\"Liming Chen\"},{\"authorId\":\"1718878\",\"name\":\"Emmanuel Dellandr\\u00e9a\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deac459941541cc4bdc8a79b45264d39a2633e1d\",\"title\":\"Bicameral Structuring and Synthetic Imagery for Jointly Predicting Instance Boundaries and Nearby Occlusions from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/deac459941541cc4bdc8a79b45264d39a2633e1d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990548\",\"name\":\"Go Irie\"},{\"authorId\":\"9211474\",\"name\":\"M. O\\u0161trek\"},{\"authorId\":\"48017277\",\"name\":\"Haochen Wang\"},{\"authorId\":\"1787190\",\"name\":\"H. Kameoka\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"}],\"doi\":\"10.1109/ICASSP.2019.8683142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"title\":\"Seeing through Sounds: Predicting Visual Semantic Segmentation Results from Multichannel Audio Signals\",\"url\":\"https://www.semanticscholar.org/paper/36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1908.04353\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"},{\"authorId\":null,\"name\":\"HaiBo Chen\"}],\"doi\":\"10.1007/978-3-030-41299-9_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2099f70cabf2a8efaa3c84ee4d3c59bcc7d1518f\",\"title\":\"Action Recognition in Untrimmed Videos with Composite Self-Attention Two-Stream Framework\",\"url\":\"https://www.semanticscholar.org/paper/2099f70cabf2a8efaa3c84ee4d3c59bcc7d1518f\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1911.11961\",\"authors\":[{\"authorId\":\"1391221756\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"49673319\",\"name\":\"Changsheng Li\"},{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"145924255\",\"name\":\"Peng Li\"},{\"authorId\":\"143689318\",\"name\":\"Jing Dong\"}],\"doi\":\"10.1109/tnnls.2019.2962815\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77e48bc788edc9870dd7c1bdfe7283a909a25b2f\",\"title\":\"AdapNet: Adaptability Decomposing Encoder-Decoder Network for Weakly Supervised Action Recognition and Localization\",\"url\":\"https://www.semanticscholar.org/paper/77e48bc788edc9870dd7c1bdfe7283a909a25b2f\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758964\",\"name\":\"Jie Yan\"},{\"authorId\":\"1783055\",\"name\":\"Guihe Qin\"},{\"authorId\":\"10431066\",\"name\":\"R. Zhao\"},{\"authorId\":\"46992126\",\"name\":\"Yan-hua Liang\"},{\"authorId\":\"150270946\",\"name\":\"Qianyi Xu\"}],\"doi\":\"10.1109/ACCESS.2019.2961383\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"title\":\"Mixpred: Video Prediction Beyond Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490672305\",\"name\":\"M. Suresha\"},{\"authorId\":\"98570196\",\"name\":\"S. Kuppa\"},{\"authorId\":\"1490675042\",\"name\":\"D. S. Raghukumar\"}],\"doi\":\"10.1007/s13735-019-00190-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac8f926b205bba37df42bab279c397a5eca07445\",\"title\":\"A study on deep learning spatiotemporal models and feature extraction techniques for video understanding\",\"url\":\"https://www.semanticscholar.org/paper/ac8f926b205bba37df42bab279c397a5eca07445\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134701532\",\"name\":\"Siddharth Buddhiraju\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef31237ffea3256c46db8a0227563f95c7c34721\",\"title\":\"Tennis Shot Recognition through Spatiotemporal Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ef31237ffea3256c46db8a0227563f95c7c34721\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48147932\",\"name\":\"Zhengyu Zhu\"},{\"authorId\":\"39241333\",\"name\":\"Bing Liu\"},{\"authorId\":\"145782887\",\"name\":\"Y. Rao\"},{\"authorId\":\"50383679\",\"name\":\"Qiao Liu\"},{\"authorId\":\"144142364\",\"name\":\"R. Zhang\"}],\"doi\":\"10.1109/ACCESS.2019.2903161\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"be2e3d014bb93d3ad17b10d8ccd665b69fc8afa4\",\"title\":\"STResNet_CF Tracker: The Deep Spatiotemporal Features Learning for Correlation Filter Based Robust Visual Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/be2e3d014bb93d3ad17b10d8ccd665b69fc8afa4\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":\"2937291\",\"name\":\"Zhikang Fu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"title\":\"Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map Based Feature Extraction for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2074878\",\"name\":\"Weixin Luo\"},{\"authorId\":\"48152297\",\"name\":\"W. Liu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/ICCV.2017.45\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99dff291f260b3cc3ff190106b0c2e3e685223a4\",\"title\":\"A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework\",\"url\":\"https://www.semanticscholar.org/paper/99dff291f260b3cc3ff190106b0c2e3e685223a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"35517688\",\"name\":\"Hugo Bertiche\"},{\"authorId\":\"145653560\",\"name\":\"Vicent Roig\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/ICCVW.2017.376\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"title\":\"Action Recognition from RGB-D Data: Comparison and Fusion of Spatio-Temporal Handcrafted Features and Deep Strategies\",\"url\":\"https://www.semanticscholar.org/paper/8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2970222\",\"name\":\"Zhongxu Hu\"},{\"authorId\":\"3285279\",\"name\":\"Youmin Hu\"},{\"authorId\":\"144397979\",\"name\":\"Bo Wu\"},{\"authorId\":\"49722516\",\"name\":\"Jie Liu\"}],\"doi\":\"10.1109/EECS.2017.91\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcd34203025441273ef29b5a174f4027a54d22fb\",\"title\":\"Hand Pose Estimation with CNN-RNN\",\"url\":\"https://www.semanticscholar.org/paper/bcd34203025441273ef29b5a174f4027a54d22fb\",\"venue\":\"2017 European Conference on Electrical Engineering and Computer Science (EECS)\",\"year\":2017},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1802.02522\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"title\":\"Joint Attention in Driver-Pedestrian Interaction: from Theory to Practice\",\"url\":\"https://www.semanticscholar.org/paper/a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.21437/Interspeech.2018-1955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f997d69d78af086dec4462e4319c6d241f42c0c1\",\"title\":\"Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/f997d69d78af086dec4462e4319c6d241f42c0c1\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720975\",\"name\":\"Jonas Vlasselaer\"},{\"authorId\":\"2527581\",\"name\":\"Carlos Fernando Crispim\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"1707364\",\"name\":\"A. Dries\"}],\"doi\":\"10.1109/ICCVW.2017.160\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e453713e7750995587c7fe5233f70cb63da8047\",\"title\":\"BEHAVE \\u2014 Behavioral Analysis of Visual Events for Assisted Living Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/9e453713e7750995587c7fe5233f70cb63da8047\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1811.08496\",\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"48467498\",\"name\":\"Rajeev Ranjan\"},{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"145668757\",\"name\":\"Carlos Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/WACV.2019.00021\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"title\":\"A Proposal-Based Solution to Spatio-Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367041\",\"name\":\"Himanshu Buckchash\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/978-3-030-34869-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0739a0b547ad3b50289b012d4e34bf44e577541f\",\"title\":\"Sustained Self-Supervised Pretraining for Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/0739a0b547ad3b50289b012d4e34bf44e577541f\",\"venue\":\"PReMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89417685\",\"name\":\"Snehashis Majhi\"},{\"authorId\":\"151182511\",\"name\":\"Ratnaka Dash\"},{\"authorId\":\"1715343\",\"name\":\"P. K. Sa\"}],\"doi\":\"10.1007/978-981-15-4018-9_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f855bc86ab1fb06d98f8a82d9ad930ae97a4ebbe\",\"title\":\"Two-Stream CNN Architecture for Anomalous Event Detection in Real World Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/f855bc86ab1fb06d98f8a82d9ad930ae97a4ebbe\",\"venue\":\"CVIP\",\"year\":2019},{\"arxivId\":\"1909.07725\",\"authors\":[{\"authorId\":\"40809222\",\"name\":\"Luxuan Li\"},{\"authorId\":\"145868988\",\"name\":\"Tao Kong\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-36718-3_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f27170bf174d81e646492173ba9e9c97753853c\",\"title\":\"Deep Point-wise Prediction for Action Temporal Proposal\",\"url\":\"https://www.semanticscholar.org/paper/8f27170bf174d81e646492173ba9e9c97753853c\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46554754\",\"name\":\"Lianping Yang\"},{\"authorId\":\"94362647\",\"name\":\"Y. Qin\"},{\"authorId\":\"3153945\",\"name\":\"Xiangde Zhang\"}],\"doi\":\"10.1007/s11554-020-01025-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9577332304d72f066aa821f0ba4f81fcaad667b0\",\"title\":\"Lightweight densely connected residual network for human pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/9577332304d72f066aa821f0ba4f81fcaad667b0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.03016\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2101cacd22060882e1ec6e787774e6b04f531e0\",\"title\":\"Online Action Detection in Streaming Videos with Time Buffers\",\"url\":\"https://www.semanticscholar.org/paper/a2101cacd22060882e1ec6e787774e6b04f531e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153490631\",\"name\":\"Y. Chang\"},{\"authorId\":\"100842298\",\"name\":\"C. S. Chan\"},{\"authorId\":\"1711669\",\"name\":\"Paolo Remagnino\"}],\"doi\":\"10.1007/s00521-020-04982-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7a88c44f85f9ed9ac27de55d1838ba3ce4d05a2\",\"title\":\"Action recognition on continuous video\",\"url\":\"https://www.semanticscholar.org/paper/a7a88c44f85f9ed9ac27de55d1838ba3ce4d05a2\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145625472\",\"name\":\"Qing Han\"},{\"authorId\":\"150129692\",\"name\":\"Haoyu Zhao\"},{\"authorId\":\"34924661\",\"name\":\"Weidong Min\"},{\"authorId\":\"144557888\",\"name\":\"H. Cui\"},{\"authorId\":\"1491232321\",\"name\":\"X. Zhou\"},{\"authorId\":\"1491243878\",\"name\":\"Ke Zuo\"},{\"authorId\":\"1389207398\",\"name\":\"Ruikang Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2962778\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa047afa0119449387fce48394d5071d42a99ff3\",\"title\":\"A Two-Stream Approach to Fall Detection With MobileVGG\",\"url\":\"https://www.semanticscholar.org/paper/aa047afa0119449387fce48394d5071d42a99ff3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.11306\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"50112704\",\"name\":\"Sumin Lee\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2019.2953187\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13aa627f35de78af64d1861fceb97c834a769b05\",\"title\":\"SRG: Snippet Relatedness-Based Temporal Action Proposal Generator\",\"url\":\"https://www.semanticscholar.org/paper/13aa627f35de78af64d1861fceb97c834a769b05\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1707.06119\",\"authors\":[{\"authorId\":\"2685285\",\"name\":\"P. Palasek\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e7dda4e54469969770f626c6abe3dcca1ecc6c3\",\"title\":\"Discriminative convolutional Fisher vector network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e7dda4e54469969770f626c6abe3dcca1ecc6c3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.07590\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.image.2017.11.005\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"1d6cd361b70a30a0ed8bd9c4bc65685e296647da\",\"title\":\"Hierarchical Multi-scale Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d6cd361b70a30a0ed8bd9c4bc65685e296647da\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICASSP.2018.8462612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88493c1952000cde64c3f2294d36fc76fd23bf3f\",\"title\":\"Mgn: Multi-Glimpse Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88493c1952000cde64c3f2294d36fc76fd23bf3f\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ICASSP.2018.8461988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"title\":\"A 203 FPS VLSI Architecture of Improved Dense Trajectories for Real-Time Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145470590\",\"name\":\"W. Lin\"},{\"authorId\":\"1517108051\",\"name\":\"Jie Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d0a1bdf67767b420fccb1d1847bfa6b65d11f5d\",\"title\":\"Beyond 2D: Fusion of Monocular 3D Pose, Motion and Appearance for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1bdf67767b420fccb1d1847bfa6b65d11f5d\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413954\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"title\":\"Towards More Explainability: Concept Knowledge Mining Network for Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.12432\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"117595877c1fca610f94c8d07009105092939ecc\",\"title\":\"All About Knowledge Graphs for Actions\",\"url\":\"https://www.semanticscholar.org/paper/117595877c1fca610f94c8d07009105092939ecc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153234114\",\"name\":\"Yunlei Sun\"},{\"authorId\":\"2679444\",\"name\":\"Dalin Zhang\"}],\"doi\":\"10.17559/tv-20190506101459\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9478073c3ec0a111e1d3d78508a40f985ecd216d\",\"title\":\"ATSN: Attention-Based Temporal Segment Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9478073c3ec0a111e1d3d78508a40f985ecd216d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.12970\",\"authors\":[{\"authorId\":\"51388208\",\"name\":\"Xuan Son Nguyen\"},{\"authorId\":\"145094363\",\"name\":\"L. Brun\"},{\"authorId\":\"2625077\",\"name\":\"O. L\\u00e9zoray\"},{\"authorId\":\"1738746\",\"name\":\"S\\u00e9bastien Bougleux\"}],\"doi\":\"10.1109/CVPR.2019.01231\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ece7f51e40856da3e52e62e1eaff9c9c5b1d4e8f\",\"title\":\"A Neural Network Based on SPD Manifold Learning for Skeleton-Based Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ece7f51e40856da3e52e62e1eaff9c9c5b1d4e8f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631782\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/S12652-019-01277-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f9337a88b22f0177727c20d3c8159b3e3af7392\",\"title\":\"An intelligent monitoring system for indoor safety of individuals suffering from Autism Spectrum Disorder (ASD)\",\"url\":\"https://www.semanticscholar.org/paper/8f9337a88b22f0177727c20d3c8159b3e3af7392\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"},{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"5810483\",\"name\":\"R. Bom\"}],\"doi\":\"10.1007/978-3-030-25590-9_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"title\":\"Human Activity Identification in Smart Daily Environments\",\"url\":\"https://www.semanticscholar.org/paper/0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1612.06703\",\"authors\":[{\"authorId\":\"7619850\",\"name\":\"Adhavan Jayabalan\"},{\"authorId\":\"7318780\",\"name\":\"Harish Karunakaran\"},{\"authorId\":\"8461792\",\"name\":\"Shravan Murlidharan\"},{\"authorId\":\"7227417\",\"name\":\"Tesia Shizume\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6350fcd05c9eea4240f3e58b9bbd0d2039935b3a\",\"title\":\"Dynamic Action Recognition: A convolutional neural network model for temporally organized joint location data\",\"url\":\"https://www.semanticscholar.org/paper/6350fcd05c9eea4240f3e58b9bbd0d2039935b3a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8897402\",\"name\":\"Feng-Ping An\"}],\"doi\":\"10.1007/s00500-020-04989-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4913e884be0a352f0cd04fe0d5f0cd11c09cd17f\",\"title\":\"Image classification algorithm based on stacked sparse coding deep learning model-optimized kernel function nonnegative sparse representation\",\"url\":\"https://www.semanticscholar.org/paper/4913e884be0a352f0cd04fe0d5f0cd11c09cd17f\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389422664\",\"name\":\"Roshan Singh\"},{\"authorId\":\"1483623375\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"30059439\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1080/21681163.2020.1805798\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"329ebf6e0edce89f5114f493b6d154c5841be639\",\"title\":\"A Dual Stream Model for Activity Recognition: Exploiting Residual- CNN with Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/329ebf6e0edce89f5114f493b6d154c5841be639\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389422664\",\"name\":\"Roshan Singh\"},{\"authorId\":\"1483623375\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"3016430\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00645-5\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"65925f1585c11107d99f8ef73e4802ce1ba86c1c\",\"title\":\"Combining CNN streams of dynamic image and depth data for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/65925f1585c11107d99f8ef73e4802ce1ba86c1c\",\"venue\":\"Multimedia Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49836180\",\"name\":\"Zhimin Bai\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e3baf29a555ca959f51b848fb21ee224835db9b\",\"title\":\"High-Order Graph Convolutional Network for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e3baf29a555ca959f51b848fb21ee224835db9b\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50393486\",\"name\":\"Avishek Majumder\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1007/978-981-13-0020-2_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b95cb0cf0b9697e0b87a86c317ae6d203c2273e\",\"title\":\"Deep Neural Network for Foreground Object Segmentation: An Unsupervised Approach\",\"url\":\"https://www.semanticscholar.org/paper/2b95cb0cf0b9697e0b87a86c317ae6d203c2273e\",\"venue\":\"NCVPRIPG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1145/3078971.3079002\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"34912edb1cf0576ff36ca9c4f651237f9115deed\",\"title\":\"Musical Instrument Recognition in User-generated Videos using a Multimodal Convolutional Neural Network Architecture\",\"url\":\"https://www.semanticscholar.org/paper/34912edb1cf0576ff36ca9c4f651237f9115deed\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713611\",\"name\":\"J. Filipe\"},{\"authorId\":\"17324395\",\"name\":\"A. Ghosh\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"71888255\",\"name\":\"Zhanjun Hao\"},{\"authorId\":\"70226424\",\"name\":\"X. Dang\"},{\"authorId\":\"49178133\",\"name\":\"Honghong Chen\"},{\"authorId\":\"24521940\",\"name\":\"Fenfang Li\"}],\"doi\":\"10.1007/978-981-33-4214-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c326ae12396c2a5c4efc123db4d8ddc1e375c32b\",\"title\":\"Wireless Sensor Networks: 14th China Conference, CWSN 2020, Dunhuang, China, September 18\\u201321, 2020, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/c326ae12396c2a5c4efc123db4d8ddc1e375c32b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49325258\",\"name\":\"Mingzhi Pang\"},{\"authorId\":\"8314653\",\"name\":\"X. Yang\"},{\"authorId\":\"49722131\",\"name\":\"J. Liu\"},{\"authorId\":\"10367284\",\"name\":\"Peihao Li\"},{\"authorId\":\"2028614762\",\"name\":\"Faren Yan\"},{\"authorId\":\"70173441\",\"name\":\"P. Chen\"}],\"doi\":\"10.1007/978-981-33-4214-9_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b150cc58f6972fc8f2497d6b6589ea70f00aba51\",\"title\":\"Device-Free Activity Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b150cc58f6972fc8f2497d6b6589ea70f00aba51\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72444453\",\"name\":\"Y. Su\"},{\"authorId\":\"152412578\",\"name\":\"Fei Tao\"},{\"authorId\":\"73658577\",\"name\":\"J. Jin\"},{\"authorId\":\"152987957\",\"name\":\"T. Wang\"},{\"authorId\":\"49110466\",\"name\":\"Q. Wang\"},{\"authorId\":\"40585259\",\"name\":\"L. Wang\"}],\"doi\":\"10.1115/1.4045445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"206350c97f4ade39ff86a8debb4a0d0c78c4d16e\",\"title\":\"Failure Prognosis of Complex Equipment With Multistream Deep Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/206350c97f4ade39ff86a8debb4a0d0c78c4d16e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47482879\",\"name\":\"W. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"861ba11c0de8efc8bca4320f59364080886cfbdb\",\"title\":\"Deep learning for human fall classification with application to e-healthcare\",\"url\":\"https://www.semanticscholar.org/paper/861ba11c0de8efc8bca4320f59364080886cfbdb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1708.04400\",\"authors\":[{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"}],\"doi\":\"10.1109/ICCV.2017.232\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dddfc10d9649a936cc440c1f3590b14e51a81daa\",\"title\":\"Bringing Background into the Foreground: Making All Classes Equal in Weakly-Supervised Video Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/dddfc10d9649a936cc440c1f3590b14e51a81daa\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114595746\",\"name\":\"Chong Chen\"},{\"authorId\":\"120731549\",\"name\":\"Bo He\"},{\"authorId\":\"9033105\",\"name\":\"Heng Zhang\"}],\"doi\":\"10.1109/ICCTEC.2017.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7892a4ba55f617a466e2b4403edfb05f501b93ba\",\"title\":\"Review on Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7892a4ba55f617a466e2b4403edfb05f501b93ba\",\"venue\":\"2017 International Conference on Computer Technology, Electronics and Communication (ICCTEC)\",\"year\":2017},{\"arxivId\":\"1802.09745\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Li\"},{\"authorId\":\"144811861\",\"name\":\"M. Chuah\"}],\"doi\":\"10.1109/WACV.2018.00046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"162148b5dcabd9354a722ad75e5390596f3ae4c3\",\"title\":\"ReHAR: Robust and Efficient Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/162148b5dcabd9354a722ad75e5390596f3ae4c3\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"}],\"doi\":\"10.1109/TMM.2017.2749159\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"title\":\"Two-Stream 3-D convNet Fusion for Action Recognition in Videos With Arbitrary Size and Length\",\"url\":\"https://www.semanticscholar.org/paper/93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"49308184\",\"name\":\"Y. Yang\"},{\"authorId\":\"143822920\",\"name\":\"He Jiang\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"2585506\",\"name\":\"G. Wang\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/RCAR.2018.8621829\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"title\":\"Action Recognition and Localization with Instance FCNN\",\"url\":\"https://www.semanticscholar.org/paper/ef62ed6fa1a1de1bbb6dc00b1da047a0391c3462\",\"venue\":\"2018 IEEE International Conference on Real-time Computing and Robotics (RCAR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"50469612\",\"name\":\"Guangyu Guo\"},{\"authorId\":null,\"name\":\"Dong Huang\"},{\"authorId\":\"145877494\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87e3a8c0429a2d8c4349f9b55fce4ff2c8540deb\",\"title\":\"presented a deep 3 D convolutional architecture that models the flow estimation problem as a \\u201c Voxel 2 Voxel \\u201d prediction problem\",\"url\":\"https://www.semanticscholar.org/paper/87e3a8c0429a2d8c4349f9b55fce4ff2c8540deb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674907\",\"name\":\"Lili Meng\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"115284322\",\"name\":\"W. Sun\"},{\"authorId\":\"1402348340\",\"name\":\"Frederich Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCVW.2019.00189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"title\":\"Interpretable Spatio-Temporal Attention for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1906.07052\",\"authors\":[{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"49543907\",\"name\":\"Xin-Xin Liu\"},{\"authorId\":\"49388002\",\"name\":\"Jianxin Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"title\":\"Towards Real-Time Action Recognition on Mobile Devices Using Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52554366\",\"name\":\"Mohammad Ahsanul\"},{\"authorId\":\"145345750\",\"name\":\"Braden Bautista\"},{\"authorId\":null,\"name\":\"Ole K\\u00e6seler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31527e16e0221361d6ce525881a72ed9107da69c\",\"title\":\"Aalborg Universitet Deep Multimodal Pain Recognition : A Database and Comparison of Spatio-Temporal Visual\",\"url\":\"https://www.semanticscholar.org/paper/31527e16e0221361d6ce525881a72ed9107da69c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84259605\",\"name\":\"Filip Granqvist\"},{\"authorId\":\"83191308\",\"name\":\"Oskar Holmberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16e445d470129a4fdb3c484216a368dc4a611bd2\",\"title\":\"A deep learning based tracking framework for passenger monitoring\",\"url\":\"https://www.semanticscholar.org/paper/16e445d470129a4fdb3c484216a368dc4a611bd2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"}],\"doi\":\"10.7275/WSCA-M707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b63b443885a5f2a54f58757481944f738d1e3092\",\"title\":\"Higher-Order Representations for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b63b443885a5f2a54f58757481944f738d1e3092\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheyuan Liu\"},{\"authorId\":\"9642011\",\"name\":\"Xiaoteng Zhang\"},{\"authorId\":\"33055674\",\"name\":\"L. Song\"},{\"authorId\":\"2261516\",\"name\":\"Zhengyan Ding\"},{\"authorId\":\"1730199\",\"name\":\"Huixian Duan\"}],\"doi\":\"10.1007/s10586-017-1309-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"title\":\"More efficient and effective tricks for deep action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153552006\",\"name\":\"A. Franco\"},{\"authorId\":\"31649620\",\"name\":\"A. Magnani\"},{\"authorId\":\"1747625\",\"name\":\"D. Maio\"}],\"doi\":\"10.1016/j.patrec.2020.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bebb0afdcc3e4c5a95e4b0b659569c096f2894c\",\"title\":\"A multimodal approach for human activity recognition based on skeleton and RGB data\",\"url\":\"https://www.semanticscholar.org/paper/2bebb0afdcc3e4c5a95e4b0b659569c096f2894c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"}],\"doi\":\"10.15496/PUBLIKATION-4524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d7ebfa0199d7d49f4ca95b80fa136aafb43b88\",\"title\":\"Towards Geometric Understanding of Motion\",\"url\":\"https://www.semanticscholar.org/paper/c3d7ebfa0199d7d49f4ca95b80fa136aafb43b88\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2365404\",\"name\":\"N. Ghatwary\"},{\"authorId\":\"2070333\",\"name\":\"M. Zolgharni\"},{\"authorId\":\"34040702\",\"name\":\"Xujiong Ye\"}],\"doi\":\"10.1007/978-3-030-32692-0_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"636eb9f311ef09bb2d93deaaac81cc94e206357c\",\"title\":\"GFD Faster R-CNN: Gabor Fractal DenseNet Faster R-CNN for Automatic Detection of Esophageal Abnormalities in Endoscopic Images\",\"url\":\"https://www.semanticscholar.org/paper/636eb9f311ef09bb2d93deaaac81cc94e206357c\",\"venue\":\"MLMI@MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"47557959\",\"name\":\"Y. Chen\"},{\"authorId\":\"47462870\",\"name\":\"Ruotao Xu\"},{\"authorId\":\"153172100\",\"name\":\"Hui Ji\"}],\"doi\":\"10.1016/J.CVIU.2019.102794\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"title\":\"Attention with structure regularization for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50096952\",\"name\":\"Chuanxu Wang\"},{\"authorId\":\"108019309\",\"name\":\"Hu Guofeng\"},{\"authorId\":\"47909724\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1088/1742-6596/1176/6/062015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3dd4cc2fdc41381510bf3d8f0e8eb8bf8a3039d\",\"title\":\"Multi-views Action Recognition on Deep Learning and K-SVD\",\"url\":\"https://www.semanticscholar.org/paper/f3dd4cc2fdc41381510bf3d8f0e8eb8bf8a3039d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":\"10.1109/WACV.2019.00128\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"db70e64fb69c64f174fd97ab86566373504fd702\",\"title\":\"Memory Warps for Long-Term Online Video Representations and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/db70e64fb69c64f174fd97ab86566373504fd702\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.09961\",\"authors\":[{\"authorId\":\"144865353\",\"name\":\"B. Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"3166067\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"145716219\",\"name\":\"C. Shi\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPR.2019.00051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"title\":\"Deep RNN Framework for Visual Sequential Applications\",\"url\":\"https://www.semanticscholar.org/paper/5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119404\",\"name\":\"G. Liang\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"},{\"authorId\":\"7214209\",\"name\":\"Hanbo Zhang\"},{\"authorId\":\"2200612\",\"name\":\"Xingyu Chen\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-65289-4_57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02989d1daaee8cff6064727a0688aec97c7444a3\",\"title\":\"Intention-Based Human Robot Collaboration\",\"url\":\"https://www.semanticscholar.org/paper/02989d1daaee8cff6064727a0688aec97c7444a3\",\"venue\":\"ICIRA\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6516435\",\"name\":\"Mengxi Lin\"},{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1145/3126686.3126755\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4097fef623185557bb1842501cfdc97f812fc66d\",\"title\":\"CTC Network with Statistical Language Modeling for Action Sequence Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4097fef623185557bb1842501cfdc97f812fc66d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1804.06498\",\"authors\":[{\"authorId\":\"3152993\",\"name\":\"Mahdi Abavisani\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/JSTSP.2018.2875385\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"738dcf73061ffdfc69d3101df78d51ec460ea8c1\",\"title\":\"Deep Multimodal Subspace Clustering Networks\",\"url\":\"https://www.semanticscholar.org/paper/738dcf73061ffdfc69d3101df78d51ec460ea8c1\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1809.06269\",\"authors\":[{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"3180441\",\"name\":\"L. Herranz\"},{\"authorId\":\"49751749\",\"name\":\"Chengpeng Chen\"}],\"doi\":\"10.1109/TIP.2018.2872629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ce1fc051a3629b4265d473d395b58154db4bf90\",\"title\":\"Learning Effective RGB-D Representations for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ce1fc051a3629b4265d473d395b58154db4bf90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393685151\",\"name\":\"Pratik Gujjar\"},{\"authorId\":\"31034396\",\"name\":\"R. Vaughan\"}],\"doi\":\"10.1109/ICRA.2019.8794278\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"efee2965990ce40ccb7b01231b0a1d2924afb97b\",\"title\":\"Classifying Pedestrian Actions In Advance Using Predicted Video Of Urban Driving Scenes\",\"url\":\"https://www.semanticscholar.org/paper/efee2965990ce40ccb7b01231b0a1d2924afb97b\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1889050\",\"name\":\"C. Ma\"},{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8774499\",\"name\":\"Anni Wang\"},{\"authorId\":\"47905379\",\"name\":\"Y. Wang\"},{\"authorId\":\"1752350\",\"name\":\"G. Chen\"}],\"doi\":\"10.3390/ijgi7010037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62f1bd2f6e48c78d19265d5f0d5f80d1ece5a05f\",\"title\":\"Traffic Command Gesture Recognition for Virtual Urban Scenes Based on a Spatiotemporal Convolution Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/62f1bd2f6e48c78d19265d5f0d5f80d1ece5a05f\",\"venue\":\"ISPRS Int. J. Geo Inf.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1901.10172\",\"authors\":[{\"authorId\":\"48981982\",\"name\":\"Peizhao Li\"},{\"authorId\":\"2428872\",\"name\":\"Y. Li\"},{\"authorId\":\"7325479\",\"name\":\"Xiaolong Jiang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"}],\"doi\":\"10.1109/ICIP.2019.8803394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c020ff7138c87f6e972e3974141d7cf6d902bf41\",\"title\":\"Two-Stream Multi-Task Network for Fashion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c020ff7138c87f6e972e3974141d7cf6d902bf41\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145723090\",\"name\":\"Z. Wang\"},{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"8670210\",\"name\":\"Peilin He\"},{\"authorId\":\"47906472\",\"name\":\"Yajie Wang\"},{\"authorId\":\"144180895\",\"name\":\"P. Zhu\"},{\"authorId\":\"71020733\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2019.02.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"931a49fc18b1cb1577e18812fbe1ffb7af135f17\",\"title\":\"Multi-scale aggregation network for temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/931a49fc18b1cb1577e18812fbe1ffb7af135f17\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825759635\",\"name\":\"Wafaa Shihab Ahmed\"},{\"authorId\":\"1825629798\",\"name\":\"Abdul Karim\"}],\"doi\":\"10.1109/CSASE48920.2020.9142089\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30a1cc192a510e846104d178fce2f409362f358d\",\"title\":\"The Impact of Filter Size and Number of Filters on Classification Accuracy in CNN\",\"url\":\"https://www.semanticscholar.org/paper/30a1cc192a510e846104d178fce2f409362f358d\",\"venue\":\"2020 International Conference on Computer Science and Software Engineering (CSASE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151471179\",\"name\":\"Nasim Khani\"},{\"authorId\":\"1917506\",\"name\":\"M. Rezaeian\"}],\"doi\":\"10.1109/PRIA.2019.8785989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"615f2ff53e297c753b323df4a1550a68953c0260\",\"title\":\"Three-stream Very Deep Neural Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/615f2ff53e297c753b323df4a1550a68953c0260\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46176327\",\"name\":\"A. Jahagirdar\"},{\"authorId\":\"9349710\",\"name\":\"M. Nagmode\"}],\"doi\":\"10.1007/978-981-10-7245-1_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caf5af49bacdb4e63852d1e395f0f056d4e06ff0\",\"title\":\"Silhouette-Based Human Action Recognition by Embedding HOG and PCA Features\",\"url\":\"https://www.semanticscholar.org/paper/caf5af49bacdb4e63852d1e395f0f056d4e06ff0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945620\",\"name\":\"Tejinderpal Singh\"},{\"authorId\":\"2454842\",\"name\":\"S. Rustagi\"},{\"authorId\":\"1452345079\",\"name\":\"Aakash Garg\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/BigMM.2019.00-19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7dc306f2cfa6da783dd89b47cf4d5419656936f\",\"title\":\"Deep Learning Framework for Single and Dyadic Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b7dc306f2cfa6da783dd89b47cf4d5419656936f\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":\"1911.08548\",\"authors\":[{\"authorId\":\"47792983\",\"name\":\"J. Ma\"},{\"authorId\":\"46227885\",\"name\":\"Satya Krishna Gorti\"},{\"authorId\":\"1765951\",\"name\":\"Maksims Volkovs\"},{\"authorId\":\"93169948\",\"name\":\"Ilya Stanevich\"},{\"authorId\":\"46546800\",\"name\":\"Guangwei Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8283f38f9e027a38c454957297d4a685b453575\",\"title\":\"Cross-Class Relevance Learning for Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/d8283f38f9e027a38c454957297d4a685b453575\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.02772\",\"authors\":[{\"authorId\":\"1709962\",\"name\":\"Christopher Xie\"},{\"authorId\":\"144863550\",\"name\":\"Y. Xiang\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"}],\"doi\":\"10.1109/CVPR.2019.01023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0672635f300663b7bce1d59475cf607141335e50\",\"title\":\"Object Discovery in Videos as Foreground Motion Clustering\",\"url\":\"https://www.semanticscholar.org/paper/0672635f300663b7bce1d59475cf607141335e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.13942\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"30017683\",\"name\":\"Haoye Cai\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"title\":\"Spatio-Temporal Graph for Video Captioning With Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"174d1b037e62ab7ae5f73b597b025d5faf0fadb4\",\"title\":\"Deep Reinforcement Sequence Learning for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/174d1b037e62ab7ae5f73b597b025d5faf0fadb4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.06689\",\"authors\":[{\"authorId\":\"37614515\",\"name\":\"J. Duan\"},{\"authorId\":\"145182505\",\"name\":\"Shuai Zhou\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"3315491\",\"name\":\"Xiaoyuan Guo\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee6cf6d7e5b034d1220518a3c9bcd0b08617cd65\",\"title\":\"Multi-Modality Fusion based on Consensus-Voting and 3D Convolution for Isolated Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee6cf6d7e5b034d1220518a3c9bcd0b08617cd65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2345721\",\"name\":\"S. Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1145/3139958.3140055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40dd736c803720890d6bfc1e083f6050e35d8f7a\",\"title\":\"Large-Scale Mapping of Human Activity using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/40dd736c803720890d6bfc1e083f6050e35d8f7a\",\"venue\":\"SIGSPATIAL/GIS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2799968\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"title\":\"Multi-Modality Multi-Task Recurrent Neural Network for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f08ee8d0351e39868d2ccb93f0c6e38c10bf85dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"1763134\",\"name\":\"Yeonho Kim\"},{\"authorId\":\"144499950\",\"name\":\"J. S. Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1016/j.patrec.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c81c88f74d466a65520ea9751970ff781352ec0a\",\"title\":\"First Person Action Recognition via Two-stream ConvNet with Long-term Fusion Pooling\",\"url\":\"https://www.semanticscholar.org/paper/c81c88f74d466a65520ea9751970ff781352ec0a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845377889\",\"name\":\"Rui Li\"},{\"authorId\":\"2029287167\",\"name\":\"Shourun Li\"}],\"doi\":\"10.1109/ICAIE50891.2020.00031\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f89e7bd91753dbf5b0e8c10b1352ece432a2e3b\",\"title\":\"Human behavior recognition based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/1f89e7bd91753dbf5b0e8c10b1352ece432a2e3b\",\"venue\":\"2020 International Conference on Artificial Intelligence and Education (ICAIE)\",\"year\":2020},{\"arxivId\":\"2012.01879\",\"authors\":[{\"authorId\":\"1596569179\",\"name\":\"W. Wang\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"47047780\",\"name\":\"Zhiyan Xu\"},{\"authorId\":\"1897758721\",\"name\":\"Weihong Yu\"},{\"authorId\":\"1596488705\",\"name\":\"Jianchun Zhao\"},{\"authorId\":\"1596613683\",\"name\":\"Dayong Ding\"},{\"authorId\":\"2510050\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2a11a0cdf22c454e87fa8d86e209d6127d2d8587\",\"title\":\"Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration Categorization\",\"url\":\"https://www.semanticscholar.org/paper/2a11a0cdf22c454e87fa8d86e209d6127d2d8587\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.13375\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Cao\"},{\"authorId\":\"1690418794\",\"name\":\"Jiarui Xu\"},{\"authorId\":\"48639986\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1825704806\",\"name\":\"Han Hu\"}],\"doi\":\"10.1109/TPAMI.2020.3047209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"title\":\"Global Context Networks.\",\"url\":\"https://www.semanticscholar.org/paper/e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404403\",\"name\":\"Longteng Kong\"},{\"authorId\":\"145022824\",\"name\":\"D. Huang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2893318\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef022983983d8b948ab27a686da4e76cf92d18b1\",\"title\":\"A Joint Framework for Athlete Tracking and Action Recognition in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ef022983983d8b948ab27a686da4e76cf92d18b1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.03428\",\"authors\":[{\"authorId\":\"3451384\",\"name\":\"Felix J\\u00e4remo Lawin\"},{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"},{\"authorId\":\"15791955\",\"name\":\"Patrik Tosteberg\"},{\"authorId\":\"49922196\",\"name\":\"Goutam Bhat\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":\"10.1007/978-3-319-64689-3_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c538865c619113cb82b54e74646c32a8cafd6063\",\"title\":\"Deep Projective 3D Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c538865c619113cb82b54e74646c32a8cafd6063\",\"venue\":\"CAIP\",\"year\":2017},{\"arxivId\":\"2007.06288\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"98256637\",\"name\":\"Zhou Yang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46946060\",\"name\":\"M. Jian\"},{\"authorId\":\"49217626\",\"name\":\"Boxuan Zhao\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.07.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50efde486726ae435c28211b6cd123c6b61e3a99\",\"title\":\"Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/50efde486726ae435c28211b6cd123c6b61e3a99\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1810.04047\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d94395882da6da17cee0a6ea6f1058314f091f05\",\"title\":\"Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video\",\"url\":\"https://www.semanticscholar.org/paper/d94395882da6da17cee0a6ea6f1058314f091f05\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1801.03983\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/WACV.2018.00178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"title\":\"Fully-Coupled Two-Stream Spatiotemporal Networks for Extremely Low Resolution Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3164119\",\"name\":\"O. Vynokurova\"},{\"authorId\":\"46713541\",\"name\":\"D. Peleshko\"}],\"doi\":\"10.1109/DSMP47368.2020.9204215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48d84f93829ee4bb99e39490f5e7d1cc71798fbe\",\"title\":\"Hybrid Multidimensional Deep Convolutional Neural Network for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/48d84f93829ee4bb99e39490f5e7d1cc71798fbe\",\"venue\":\"2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93589643\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s00521-020-05018-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d5ebb71384b8da236fd4ca903df1630bc62389c\",\"title\":\"A deeply coupled ConvNet for human activity recognition using dynamic and RGB images\",\"url\":\"https://www.semanticscholar.org/paper/9d5ebb71384b8da236fd4ca903df1630bc62389c\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"51174795\",\"name\":\"B. Zan\"},{\"authorId\":\"46332897\",\"name\":\"Min Jiang\"}],\"doi\":\"10.1117/1.JEI.27.3.033027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2b86797109bee4c0b95b7170379fa80c6aaadd8\",\"title\":\"Human action recognition using depth motion maps pyramid and discriminative collaborative representation classifier\",\"url\":\"https://www.semanticscholar.org/paper/e2b86797109bee4c0b95b7170379fa80c6aaadd8\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":\"2011.08014\",\"authors\":[{\"authorId\":\"1854884121\",\"name\":\"Sabrina Narimene Benassou\"},{\"authorId\":\"2635009\",\"name\":\"W. Shi\"},{\"authorId\":\"1768755563\",\"name\":\"Feng Jiang\"},{\"authorId\":\"8878512\",\"name\":\"Abdallah Benzine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b64209978e434fdc030a621148eb685d6bcd2e6\",\"title\":\"Hierarchical Complementary Learning for Weakly Supervised Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/1b64209978e434fdc030a621148eb685d6bcd2e6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1809.07697\",\"authors\":[{\"authorId\":\"40145256\",\"name\":\"J. Lee\"},{\"authorId\":\"1862090\",\"name\":\"Ryan A. Rossi\"},{\"authorId\":\"1833914\",\"name\":\"Xiangnan Kong\"},{\"authorId\":\"2939760\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"47652687\",\"name\":\"A. Rao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4eed4d77247eed4faa88c3ee7e03bc9d2594a02\",\"title\":\"Higher-order Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d4eed4d77247eed4faa88c3ee7e03bc9d2594a02\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31476320\",\"name\":\"Zhiqiang Liu\"},{\"authorId\":\"1678835\",\"name\":\"X. Shi\"},{\"authorId\":\"1683219\",\"name\":\"L. He\"},{\"authorId\":\"34707388\",\"name\":\"Dongxiao Yu\"},{\"authorId\":\"145914251\",\"name\":\"Hai Jin\"},{\"authorId\":\"144136729\",\"name\":\"Chen Yu\"},{\"authorId\":\"1503578591\",\"name\":\"Hulin Dai\"},{\"authorId\":\"1503936452\",\"name\":\"Zezhao Feng\"}],\"doi\":\"10.1007/s10619-020-07287-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"687ea17fe6f1307ca394c4dc75d4b95043a82083\",\"title\":\"A parameter-level parallel optimization algorithm for large-scale spatio-temporal data mining\",\"url\":\"https://www.semanticscholar.org/paper/687ea17fe6f1307ca394c4dc75d4b95043a82083\",\"venue\":\"Distributed and Parallel Databases\",\"year\":2020},{\"arxivId\":\"1701.07368\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/CVPRW.2017.161\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"title\":\"Deep Local Video Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"72399895\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"title\":\"Multi-kernel learning of deep convolutional features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1872087\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"2930187\",\"name\":\"Xiangyin Zhang\"},{\"authorId\":\"7824818\",\"name\":\"X. Li\"}],\"doi\":\"10.1117/1.JEI.27.5.053049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19ba3d8d9eb5e4c2304df5cb365d171fdb95dc6\",\"title\":\"Saliency-based foreground trajectory extraction using multiscale hybrid masks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c19ba3d8d9eb5e4c2304df5cb365d171fdb95dc6\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50201758\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"47785967\",\"name\":\"Jianmin Li\"},{\"authorId\":\"9563639\",\"name\":\"Mengqing Jiang\"},{\"authorId\":\"40275840\",\"name\":\"P. Yuan\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.1109/TCSVT.2017.2710345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"663eb30b98e84d67a7468b6a6a996fcca600bf0a\",\"title\":\"Scalable Discrete Supervised Multimedia Hash Learning With Clustering\",\"url\":\"https://www.semanticscholar.org/paper/663eb30b98e84d67a7468b6a6a996fcca600bf0a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1906.01028\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/TPAMI.2018.2884469\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25edae7a44dc4f26adc04693199595a12a3b1eec\",\"title\":\"A Hybrid RNN-HMM Approach for Weakly Supervised Temporal Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/25edae7a44dc4f26adc04693199595a12a3b1eec\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40956142\",\"name\":\"Van-Minh Khong\"},{\"authorId\":\"46602660\",\"name\":\"Thanh-Hai Tran\"}],\"doi\":\"10.1109/MAPR.2018.8337518\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"073e1cbacb3585b77181da4d0319be8218576932\",\"title\":\"Improving Human Action Recognition with Two-Stream 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/073e1cbacb3585b77181da4d0319be8218576932\",\"venue\":\"2018 1st International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38378646\",\"name\":\"S. Piramanayagam\"},{\"authorId\":\"1733172\",\"name\":\"E. Saber\"},{\"authorId\":\"1983805\",\"name\":\"W. Schwartzkopf\"},{\"authorId\":\"32230059\",\"name\":\"F. W. Koehler\"}],\"doi\":\"10.3390/rs10091429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9905cc8e2d60dd44b1880ac52440dee631671664\",\"title\":\"Supervised Classification of Multisensor Remotely Sensed Images Using a Deep Learning Framework\",\"url\":\"https://www.semanticscholar.org/paper/9905cc8e2d60dd44b1880ac52440dee631671664\",\"venue\":\"Remote. Sens.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2894025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"title\":\"Spatiotemporal Relation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410772490\",\"name\":\"R. Ogata\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1109/CVPRW.2019.00309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de7cbc5737177ff89913a916e9bd6417836f520e\",\"title\":\"Temporal Distance Matrices for Squat Classification\",\"url\":\"https://www.semanticscholar.org/paper/de7cbc5737177ff89913a916e9bd6417836f520e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"title\":\"Dribbling Basketball Shooting Basketball Dribbling Basketball Shooting Basketball Baking Cookies Peeling Potatos Baking Cookies Peeling Potatos Smoking Eating BurgerSmoking Eating\",\"url\":\"https://www.semanticscholar.org/paper/d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14516821\",\"name\":\"Ganesh Yaparla\"},{\"authorId\":\"32339189\",\"name\":\"Allaparthi Sriteja\"},{\"authorId\":\"9585601\",\"name\":\"Sai Krishna Munnangi\"},{\"authorId\":\"143674379\",\"name\":\"G. R. Murthy\"}],\"doi\":\"10.1007/978-3-030-20518-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1899d96326b67dc222500b0d8689ebad7c8dafd\",\"title\":\"A Novel Framework for Fine Grained Action Recognition in Soccer\",\"url\":\"https://www.semanticscholar.org/paper/b1899d96326b67dc222500b0d8689ebad7c8dafd\",\"venue\":\"IWANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153065698\",\"name\":\"Yinghan Long\"},{\"authorId\":\"153181248\",\"name\":\"G. Srinivasan\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"},{\"authorId\":\"39703133\",\"name\":\"K. Roy\"}],\"doi\":\"10.1109/JETCAS.2019.2935004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"212784b86f1bc4ddd43b621e35630579070a1b92\",\"title\":\"Structured Learning for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/212784b86f1bc4ddd43b621e35630579070a1b92\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35564381\",\"name\":\"Mahnaz Parian\"},{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"145717652\",\"name\":\"H. Schuldt\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.1145/3372278.3390723\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4da69e1cf5506637dd6c0cf23dc27a5c0b76b38e\",\"title\":\"Are You Watching Closely? Content-based Retrieval of Hand Gestures\",\"url\":\"https://www.semanticscholar.org/paper/4da69e1cf5506637dd6c0cf23dc27a5c0b76b38e\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09926ed62511c340f4540b5bc53cf2480e8063f8\",\"title\":\"Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/09926ed62511c340f4540b5bc53cf2480e8063f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38764391\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"50561740\",\"name\":\"J. Zhang\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2017.2758524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"title\":\"Discriminative Part Selection for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"2898447\",\"name\":\"Shanshan Huang\"}],\"doi\":\"10.1007/s11042-017-4979-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83ec3239253fa2d2247c2f4dc8ac89743dad2feb\",\"title\":\"Automatic analysis of complex athlete techniques in broadcast taekwondo video\",\"url\":\"https://www.semanticscholar.org/paper/83ec3239253fa2d2247c2f4dc8ac89743dad2feb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70573226\",\"name\":\"Chien-Cheng Lee\"},{\"authorId\":\"145947730\",\"name\":\"W. Gao\"},{\"authorId\":\"117788097\",\"name\":\"P. Lui\"}],\"doi\":\"10.1109/IPTA.2019.8936075\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"720a87fa17d19f9da26a112dd5b58dad17615c76\",\"title\":\"Rat Grooming Behavior Detection with Two-stream Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/720a87fa17d19f9da26a112dd5b58dad17615c76\",\"venue\":\"2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tian Wang\"},{\"authorId\":null,\"name\":\"Shiye Lei\"},{\"authorId\":\"116503541\",\"name\":\"Youyou Jiang\"},{\"authorId\":\"97207595\",\"name\":\"Zihang Deng\"},{\"authorId\":null,\"name\":\"Xin Su\"},{\"authorId\":\"102633245\",\"name\":\"Chang Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cc3947038142ccb82ff7c2e546d61c927371036\",\"title\":\"A high performance computing method for accelerating temporal action proposal generation\",\"url\":\"https://www.semanticscholar.org/paper/0cc3947038142ccb82ff7c2e546d61c927371036\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1710.03958\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb3948152788cfaf8a829aab2f02a6ec7de7c7d1\",\"title\":\"Detect to Track and Track to Detect\",\"url\":\"https://www.semanticscholar.org/paper/fb3948152788cfaf8a829aab2f02a6ec7de7c7d1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144130711\",\"name\":\"C. Lin\"},{\"authorId\":\"2003807524\",\"name\":\"Mengxiang Lin\"},{\"authorId\":\"2003808280\",\"name\":\"Suhui Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3032430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25db1ba302821f83040021e164e34d323354b154\",\"title\":\"SOPNet Method for the Fine-Grained Measurement and Prediction of Precipitation Intensity Using Outdoor Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/25db1ba302821f83040021e164e34d323354b154\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ACPR.2017.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08acfa0920abbac5c5046edcff01e41b12c98be7\",\"title\":\"Learning Principal Orientations Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08acfa0920abbac5c5046edcff01e41b12c98be7\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"47740566\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"title\":\"Action recognition with gradient boundary convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"1803391\",\"name\":\"Y. Lu\"},{\"authorId\":\"2378843\",\"name\":\"L. Lu\"},{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"}],\"doi\":\"10.1016/j.neucom.2019.01.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f05ef5fdb372509194d14de63a72dacd149635e\",\"title\":\"Refined video segmentation through global appearance regression\",\"url\":\"https://www.semanticscholar.org/paper/2f05ef5fdb372509194d14de63a72dacd149635e\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2954369\",\"name\":\"W. Zhao\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"2149156\",\"name\":\"Xunxun Chen\"},{\"authorId\":\"2289713\",\"name\":\"Yuanyan Tang\"},{\"authorId\":\"2333334\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/978-981-10-7302-1_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"797e5cc59a5d015545c51737f6c9da839d7f373f\",\"title\":\"Learning Deep Feature Fusion for Group Images Classification\",\"url\":\"https://www.semanticscholar.org/paper/797e5cc59a5d015545c51737f6c9da839d7f373f\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"34608228\",\"name\":\"Xu-dong Jiang\"},{\"authorId\":\"3108302\",\"name\":\"Wei-Long Zheng\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/TCSVT.2020.2976789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"title\":\"Early Action Recognition With Category Exclusion Using Policy-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":\"7296530\",\"name\":\"Hongyu Zhu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"title\":\"Reversing Two-Stream Networks with Decoding Discrepancy Penalty for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410229972\",\"name\":\"Guy Ben-Yosef\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"113363846\",\"name\":\"Shimon Ullman\"}],\"doi\":\"10.1016/j.cognition.2020.104263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"340edf9512e543655f7fa27f8498e0ad98ea2521\",\"title\":\"Minimal videos: Trade-off between spatial and temporal information in human and machine vision\",\"url\":\"https://www.semanticscholar.org/paper/340edf9512e543655f7fa27f8498e0ad98ea2521\",\"venue\":\"Cognition\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746387\",\"name\":\"Xin Jin\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"89187407\",\"name\":\"W. Li\"}],\"doi\":\"10.1016/j.patcog.2019.107143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc2c28f85fcc6380e759a92c6d85aab11b693e83\",\"title\":\"AI-GAN: Asynchronous interactive generative adversarial network for single image rain removal\",\"url\":\"https://www.semanticscholar.org/paper/cc2c28f85fcc6380e759a92c6d85aab11b693e83\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51936306\",\"name\":\"Swati Dewan\"},{\"authorId\":null,\"name\":\"Shubham Agarwal\"},{\"authorId\":\"2204983\",\"name\":\"N. Singh\"}],\"doi\":\"10.1109/ICPR.2018.8545251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e65de721e68f498b6e1c63373c6df60a12533cc0\",\"title\":\"Spatio-Temporal Laban Features for Dance Style Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e65de721e68f498b6e1c63373c6df60a12533cc0\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007457399\",\"name\":\"NooriFarzan Majeed\"},{\"authorId\":\"1643856801\",\"name\":\"RieglerMichael\"},{\"authorId\":\"1643957259\",\"name\":\"UddinMd. Zia\"},{\"authorId\":\"1643935061\",\"name\":\"TorresenJim\"}],\"doi\":\"10.1145/3377882\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1d991baa063983cc28c75f8a74809d91e88182a\",\"title\":\"Human Activity Recognition from Multiple Sensors Data Using Multi-fusion Representations and CNNs\",\"url\":\"https://www.semanticscholar.org/paper/f1d991baa063983cc28c75f8a74809d91e88182a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"title\":\"Improving gesture recognition through spatial focus of attention\",\"url\":\"https://www.semanticscholar.org/paper/a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.06203\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2019.00022\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"title\":\"TAN: Temporal Aggregation Network for Dense Multi-Label Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409383791\",\"name\":\"Chuan Ding\"},{\"authorId\":\"46204420\",\"name\":\"Y. Tie\"},{\"authorId\":\"50741817\",\"name\":\"Liu Qi\"}],\"doi\":\"10.1109/ISNE.2019.8896415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36d47b6a3333bb60b42e2a9c2d2021bdba4306e7\",\"title\":\"Multi-information Complementarity Neural Networks for Multi-Modal Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/36d47b6a3333bb60b42e2a9c2d2021bdba4306e7\",\"venue\":\"2019 8th International Symposium on Next Generation Electronics (ISNE)\",\"year\":2019},{\"arxivId\":\"1909.05165\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"title\":\"Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1515829486\",\"name\":\"Aditya Raj\"},{\"authorId\":\"1481712080\",\"name\":\"Pooja Consul\"},{\"authorId\":\"2000301595\",\"name\":\"Sakar K. Pal\"}],\"doi\":\"10.1007/978-3-030-55180-3_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"482cf0c7ffdbb13eb5a62cacafca2a253064ac75\",\"title\":\"Fast Neural Accumulator (NAC) Based Badminton Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/482cf0c7ffdbb13eb5a62cacafca2a253064ac75\",\"venue\":\"IntelliSys\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38397846\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"11675891\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1145/3343031.3350992\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a402ff486216270c38ee72f793e49e6f4b861e1\",\"title\":\"Stacked Memory Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/5a402ff486216270c38ee72f793e49e6f4b861e1\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1007/s10851-017-0766-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c61eaf172820fcafaabf39005bd4536f0c45f995\",\"title\":\"Spatio-Temporal Scale Selection in Video Data\",\"url\":\"https://www.semanticscholar.org/paper/c61eaf172820fcafaabf39005bd4536f0c45f995\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2017},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.03115\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00967\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3efaf9015e28e72cc511f94de5d33378a1364d64\",\"title\":\"Kernel Transformer Networks for Compact Spherical Convolution\",\"url\":\"https://www.semanticscholar.org/paper/3efaf9015e28e72cc511f94de5d33378a1364d64\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1016/j.patcog.2018.07.028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"756532d707209f13c44b96e6306ac0c96e6733a5\",\"title\":\"Asymmetric 3D Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/756532d707209f13c44b96e6306ac0c96e6733a5\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"2012.05342\",\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"title\":\"3D attention mechanism for fine-grained classification of table tennis strokes using a Twin Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2011.10759\",\"authors\":[{\"authorId\":\"2028192777\",\"name\":\"Faizaan Sakib\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f200eb3aae73c4626fd239fe15ab1fe5a1e957c3\",\"title\":\"Visual Recognition of Great Ape Behaviours in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f200eb3aae73c4626fd239fe15ab1fe5a1e957c3\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145886112\",\"name\":\"J. Guo\"},{\"authorId\":\"100681690\",\"name\":\"W. Xia\"},{\"authorId\":\"2095870\",\"name\":\"Hua-Wei Ma\"},{\"authorId\":\"47027389\",\"name\":\"Xiaoxuan Hu\"}],\"doi\":\"10.1007/s10846-020-01197-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b362d378851e7b7aae2a88c7d01d5d406d7fcf6\",\"title\":\"A Data-Driven Model for Evaluating the Survivability of Unmanned Aerial Vehicle Routes\",\"url\":\"https://www.semanticscholar.org/paper/9b362d378851e7b7aae2a88c7d01d5d406d7fcf6\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":\"2011.02356\",\"authors\":[{\"authorId\":\"50471900\",\"name\":\"Qi Kuang\"},{\"authorId\":\"145746387\",\"name\":\"Xin Jin\"},{\"authorId\":\"20658737\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1409962553\",\"name\":\"Bin Zhou\"}],\"doi\":\"10.1109/TMM.2019.2960656\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d3894167659f4be2208c0a28a4cf5954cca1350\",\"title\":\"Deep Multimodality Learning for UAV Video Aesthetic Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/8d3894167659f4be2208c0a28a4cf5954cca1350\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"48885685\",\"name\":\"Shihui Duan\"},{\"authorId\":\"50394327\",\"name\":\"F. Long\"},{\"authorId\":null,\"name\":\"Yongxing Wang\"},{\"authorId\":\"47673446\",\"name\":\"S. Wang\"},{\"authorId\":\"40177644\",\"name\":\"Q. Ling\"}],\"doi\":\"10.23919/CCC50068.2020.9188494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6b9ec747a1ce104810b89ee0947dcbf6b0a244a\",\"title\":\"Two-Stream Convolutional Neural Networks for Emergency Recognition in Images\",\"url\":\"https://www.semanticscholar.org/paper/f6b9ec747a1ce104810b89ee0947dcbf6b0a244a\",\"venue\":\"2020 39th Chinese Control Conference (CCC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145505204\",\"name\":\"J. Guo\"},{\"authorId\":\"2245433\",\"name\":\"Hao Bai\"},{\"authorId\":\"2238603\",\"name\":\"Z. Tang\"},{\"authorId\":\"47569011\",\"name\":\"P. Xu\"},{\"authorId\":\"1723390275\",\"name\":\"Daguang Gan\"},{\"authorId\":\"50677991\",\"name\":\"B. Liu\"}],\"doi\":\"10.1007/s11042-020-08998-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d45565c3dd515afdf7f90510a410e918b3c4d8\",\"title\":\"Multi modal human action recognition for video content matching\",\"url\":\"https://www.semanticscholar.org/paper/f3d45565c3dd515afdf7f90510a410e918b3c4d8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2001.11657\",\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/tip.2020.2967577\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"title\":\"Modality Compensation Network: Cross-Modal Adaptation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13480196\",\"name\":\"Shailendra Rathore\"},{\"authorId\":\"67269466\",\"name\":\"Byung Wook Kwon\"},{\"authorId\":\"143671650\",\"name\":\"J. Park\"}],\"doi\":\"10.1016/J.JNCA.2019.06.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3591055b6b5b0426d8962a116a330eb6e3e00332\",\"title\":\"BlockSecIoTNet: Blockchain-based decentralized security architecture for IoT network\",\"url\":\"https://www.semanticscholar.org/paper/3591055b6b5b0426d8962a116a330eb6e3e00332\",\"venue\":\"J. Netw. Comput. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145874475\",\"name\":\"Li Cheng\"},{\"authorId\":\"15132338\",\"name\":\"X. Jing\"},{\"authorId\":\"2802827\",\"name\":\"Xiaoke Zhu\"},{\"authorId\":\"2163054\",\"name\":\"Fumin Qi\"},{\"authorId\":\"145575776\",\"name\":\"Fei Ma\"},{\"authorId\":\"50556783\",\"name\":\"Xiaodong Jia\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"},{\"authorId\":\"47074775\",\"name\":\"Chunhe Wang\"}],\"doi\":\"10.1007/978-3-030-04167-0_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"701933be5a40d8737fedc604d46a1976f2906b83\",\"title\":\"A Hybrid 2D and 3D Convolution Based Recurrent Network for Video-Based Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/701933be5a40d8737fedc604d46a1976f2906b83\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49951778\",\"name\":\"Jianxin Feng\"},{\"authorId\":\"3310042\",\"name\":\"J. Liu\"},{\"authorId\":\"48441832\",\"name\":\"Chengsheng Pan\"}],\"doi\":\"10.1109/MSN.2018.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbc1d3e8e0a5cfa29e1fca4baed0b63337c38041\",\"title\":\"Complex Behavior Recognition Based on Convolutional Neural Network: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/bbc1d3e8e0a5cfa29e1fca4baed0b63337c38041\",\"venue\":\"2018 14th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1109/ICSP.2018.8652359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"494f3f390442c622fd47d3c75316c3f9737bfa97\",\"title\":\"Temporal Pyramid Pooling Based Relation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/494f3f390442c622fd47d3c75316c3f9737bfa97\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059230\",\"name\":\"L. Zhang\"},{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"}],\"doi\":\"10.1109/ICCVW.2017.369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"863ad2838b9b90d4461995f498a39bcd2fb87c73\",\"title\":\"Learning Spatiotemporal Features Using 3DCNN and Convolutional LSTM for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/863ad2838b9b90d4461995f498a39bcd2fb87c73\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1704.03615\",\"authors\":[{\"authorId\":\"2298523\",\"name\":\"Achal Dave\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2017.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08ed84f2cb8f4961dea6ba60c09cc36959921287\",\"title\":\"Predictive-Corrective Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/08ed84f2cb8f4961dea6ba60c09cc36959921287\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145905489\",\"name\":\"Y. Huang\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"},{\"authorId\":\"35392319\",\"name\":\"Shao-Heng Tai\"}],\"doi\":\"10.1007/978-3-030-11012-3_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8639c08322b30a456662e439b5bb7edd2e2551e6\",\"title\":\"Human Action Recognition Based on Temporal Pose CNN and Multi-dimensional Fusion\",\"url\":\"https://www.semanticscholar.org/paper/8639c08322b30a456662e439b5bb7edd2e2551e6\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"145468103\",\"name\":\"S. Gao\"},{\"authorId\":\"38836749\",\"name\":\"Wenran Liu\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/MMSP.2018.8547088\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c4761b47c3f259559740c90bd42ed8442249499d\",\"title\":\"3-Stream Convolutional Networks for Video Action Recognition with Hybrid Motion Field\",\"url\":\"https://www.semanticscholar.org/paper/c4761b47c3f259559740c90bd42ed8442249499d\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2003.07415\",\"authors\":[{\"authorId\":\"3001696\",\"name\":\"Parastoo Alinia\"},{\"authorId\":\"145156788\",\"name\":\"Seyed Iman Mirzadeh\"},{\"authorId\":\"144600887\",\"name\":\"H. Ghasemzadeh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2821a74d43675c573d48e523a16f63d7322dcc9\",\"title\":\"ActiLabel: A Combinatorial Transfer Learning Framework for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2821a74d43675c573d48e523a16f63d7322dcc9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.08291\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"50433510\",\"name\":\"Takio Kurita\"}],\"doi\":\"10.1016/j.image.2019.115731\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"title\":\"Correlation Net: Spatiotemporal multimodal deep learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2005.14324\",\"authors\":[{\"authorId\":\"11834740\",\"name\":\"P. Jahoda\"},{\"authorId\":\"1729513004\",\"name\":\"Igor Drozdovskiy\"},{\"authorId\":\"36806959\",\"name\":\"F. Sauro\"},{\"authorId\":\"1729512692\",\"name\":\"Leonardo Turchi\"},{\"authorId\":\"15922204\",\"name\":\"S. Payler\"},{\"authorId\":\"7685775\",\"name\":\"L. Bessone\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"963a0a2a63424eb5fea46517e46dd3dffcce1f7f\",\"title\":\"Machine Learning for recognition of minerals from multispectral data\",\"url\":\"https://www.semanticscholar.org/paper/963a0a2a63424eb5fea46517e46dd3dffcce1f7f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890940\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9276668\",\"name\":\"Kuangrong Hao\"},{\"authorId\":\"2269658\",\"name\":\"Xue-Song Tang\"},{\"authorId\":\"40190124\",\"name\":\"Bing Wei\"},{\"authorId\":\"36416361\",\"name\":\"Lihong Ren\"}],\"doi\":\"10.1109/ICAICA.2019.8873471\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89041a6a962fd68b23c29bb6e9c1516a82f6e5e3\",\"title\":\"Long-term 3D Convolutional Fusion Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89041a6a962fd68b23c29bb6e9c1516a82f6e5e3\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.07468\",\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1609/aaai.v33i01.33018618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"title\":\"Multi-scale 3D Convolution Network for Video Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787575\",\"name\":\"Ruibin Bai\"},{\"authorId\":\"1730925\",\"name\":\"Qing Zhao\"},{\"authorId\":\"3373601\",\"name\":\"Sanping Zhou\"},{\"authorId\":\"48514605\",\"name\":\"Y. Li\"},{\"authorId\":\"74491229\",\"name\":\"Xueji Zhao\"},{\"authorId\":\"32014778\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8462eea5a986ac4a38be9f19229bf70461dc262\",\"title\":\"Continuous Action Recognition and Segmentation in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/f8462eea5a986ac4a38be9f19229bf70461dc262\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123756463\",\"name\":\"Bibrat Ranjan Pradhan\"},{\"authorId\":\"121456805\",\"name\":\"Yeshwanth Bethi\"},{\"authorId\":\"119885109\",\"name\":\"Sathyaprakash Narayanan\"},{\"authorId\":\"37287044\",\"name\":\"A. Chakraborty\"},{\"authorId\":\"1807880\",\"name\":\"C. Thakur\"}],\"doi\":\"10.1109/ISCAS.2019.8702581\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b214d16c338dde0b626a34aa9509c248ba2efbdc\",\"title\":\"N-HAR: A Neuromorphic Event-Based Human Activity Recognition System using Memory Surfaces\",\"url\":\"https://www.semanticscholar.org/paper/b214d16c338dde0b626a34aa9509c248ba2efbdc\",\"venue\":\"2019 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742445396\",\"name\":\"Lin Wang\"},{\"authorId\":\"8417088\",\"name\":\"Xingfu Wang\"},{\"authorId\":\"3132704\",\"name\":\"Ammar Hawbani\"},{\"authorId\":\"38131633\",\"name\":\"Y. Xiong\"},{\"authorId\":\"89013155\",\"name\":\"Xu Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.3012154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d296dab7a1fd42ad30ed52d266c9faf1c63fab\",\"title\":\"Convolution Encoders for End-to-End Action Tracking With Space-Time Cubic Kernels\",\"url\":\"https://www.semanticscholar.org/paper/54d296dab7a1fd42ad30ed52d266c9faf1c63fab\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1612.02372\",\"authors\":[{\"authorId\":\"49692485\",\"name\":\"Jia Xue\"},{\"authorId\":\"46702541\",\"name\":\"H. Zhang\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"},{\"authorId\":\"153162213\",\"name\":\"Ko Nishino\"}],\"doi\":\"10.1109/CVPR.2017.734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f294cc63879f782f87d927a3649cea8e6a5406c1\",\"title\":\"Differential Angular Imaging for Material Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f294cc63879f782f87d927a3649cea8e6a5406c1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9462336\",\"name\":\"T. Subetha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"574ca8aeb7e9e9b338ba75c30d20b12adb245f7d\",\"title\":\"Dyadic Human Interaction Recognition from Videos using Multi-layer 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/574ca8aeb7e9e9b338ba75c30d20b12adb245f7d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.00421\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4ebf0a4f48275ecd8dbc2840b2a31cc07bd676d\",\"title\":\"A Fusion of Appearance based CNNs and Temporal evolution of Skeleton with LSTM for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4ebf0a4f48275ecd8dbc2840b2a31cc07bd676d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076846\",\"name\":\"Chandni\"},{\"authorId\":\"51498323\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"47556759\",\"name\":\"Alok K. Kushwaha\"}],\"doi\":\"10.1007/978-981-13-2685-1_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e425c71e2231f09530c6bb14fe1d02d74862c5\",\"title\":\"Delving Deeper with Dual-Stream CNN for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d7e425c71e2231f09530c6bb14fe1d02d74862c5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ICIP.2017.8296915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fb68bb0b02a16f3e55fc210d3342aeef4226e1f\",\"title\":\"Action recognition in RGB-D egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/8fb68bb0b02a16f3e55fc210d3342aeef4226e1f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38378646\",\"name\":\"S. Piramanayagam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b9877384f6375e68ffc7a6dd8a7f745b8162e59\",\"title\":\"Segmentation and Classification of Multimodal Imagery\",\"url\":\"https://www.semanticscholar.org/paper/6b9877384f6375e68ffc7a6dd8a7f745b8162e59\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.03964\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"},{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"}],\"doi\":\"10.1109/ICIP.2018.8451666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2761710\",\"name\":\"Dengdi Sun\"},{\"authorId\":\"46476972\",\"name\":\"Hanqing Wu\"},{\"authorId\":\"2430623\",\"name\":\"Zhuanlian Ding\"},{\"authorId\":\"144625999\",\"name\":\"B. Luo\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"}],\"doi\":\"10.1007/978-3-030-00776-8_78\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99cea5d749086408983e54e4ce7e27a5d35e9c9f\",\"title\":\"Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/99cea5d749086408983e54e4ce7e27a5d35e9c9f\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323047\",\"name\":\"Fengqian Pang\"},{\"authorId\":\"49404404\",\"name\":\"Heng Li\"},{\"authorId\":\"1855894\",\"name\":\"Yonggang Shi\"},{\"authorId\":\"7768957\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1089/cmb.2018.0023\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da522ad0a79b71f548a789e124f45d09b843dbfd\",\"title\":\"Computational Analysis of Cell Dynamics in Videos with Hierarchical-Pooled Deep-Convolutional Features\",\"url\":\"https://www.semanticscholar.org/paper/da522ad0a79b71f548a789e124f45d09b843dbfd\",\"venue\":\"J. Comput. Biol.\",\"year\":2018},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.09986\",\"authors\":[{\"authorId\":\"40618572\",\"name\":\"Shih-Yao Lin\"},{\"authorId\":\"1744044\",\"name\":\"Y. Lin\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"},{\"authorId\":\"145458451\",\"name\":\"Y. Hung\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed8a59edc7408f5583ad0639cf82193d828761dd\",\"title\":\"Learning Conditional Random Fields with Augmented Observations for Partially Observed Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed8a59edc7408f5583ad0639cf82193d828761dd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2018.2877936\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"title\":\"Toward Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"}],\"doi\":\"10.1109/TCSVT.2018.2883995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f430ae005d2514ef68fc018867369baf1d905b1\",\"title\":\"Hierarchical Integration of Rich Features for Video-Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/7f430ae005d2514ef68fc018867369baf1d905b1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1435354211\",\"name\":\"Shubin Dai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2dec8a3f3ee662d1297d2a31cef77eb9212a2f7\",\"title\":\"A segment-level classification solution to the 3 rd YouTube-8 M Video Understanding Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b2dec8a3f3ee662d1297d2a31cef77eb9212a2f7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7560130\",\"name\":\"L. Zhang\"},{\"authorId\":\"2238957\",\"name\":\"Xuezhi Xiang\"}],\"doi\":\"10.1007/s11042-019-08457-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"title\":\"Video event classification based on two-stage neural network\",\"url\":\"https://www.semanticscholar.org/paper/c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"title\":\"Two-Stage Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2751145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4289f9f727af39414537a97e5eef90b06115a5db\",\"title\":\"Global-Local Temporal Saliency Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4289f9f727af39414537a97e5eef90b06115a5db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144160585\",\"name\":\"Mohammad A. Haque\"},{\"authorId\":\"38817001\",\"name\":\"Ruben B. Bautista\"},{\"authorId\":\"4204765\",\"name\":\"F. Noroozi\"},{\"authorId\":\"145930781\",\"name\":\"Kaustubh Kulkarni\"},{\"authorId\":\"49218349\",\"name\":\"Christian B. Laursen\"},{\"authorId\":\"143973905\",\"name\":\"R. Irani\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"3087532\",\"name\":\"G. Anbarjafari\"},{\"authorId\":\"1803459\",\"name\":\"Kamal Nasrollahi\"},{\"authorId\":\"40137619\",\"name\":\"O. Andersen\"},{\"authorId\":\"2101741\",\"name\":\"E. Spaich\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/FG.2018.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"185ade6026c291166cbe4d36a444ee71fbe7f873\",\"title\":\"Deep Multimodal Pain Recognition: A Database and Comparison of Spatio-Temporal Visual Modalities\",\"url\":\"https://www.semanticscholar.org/paper/185ade6026c291166cbe4d36a444ee71fbe7f873\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893648\",\"name\":\"E. Efthimiou\"},{\"authorId\":\"2358968\",\"name\":\"Stavroula-Evita Fotinea\"},{\"authorId\":\"3214381\",\"name\":\"Theodore Goulas\"},{\"authorId\":\"2241666\",\"name\":\"Maria Koutsombogera\"},{\"authorId\":\"9036736\",\"name\":\"Panagiotis Karioris\"},{\"authorId\":\"2694568\",\"name\":\"Anna Vacalopoulou\"},{\"authorId\":\"1941827\",\"name\":\"I. Rodomagoulakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"},{\"authorId\":\"9355037\",\"name\":\"C. Tzafestas\"},{\"authorId\":\"1738119\",\"name\":\"Vassilis Pitsikalis\"},{\"authorId\":\"2929264\",\"name\":\"Y. Koumpouros\"},{\"authorId\":\"9038708\",\"name\":\"Alexandra Karavasili\"},{\"authorId\":\"9043401\",\"name\":\"Panagiotis Siavelis\"},{\"authorId\":\"9039224\",\"name\":\"Foteini Koureta\"},{\"authorId\":\"49239304\",\"name\":\"D. Alexopoulou\"}],\"doi\":\"10.1109/SSCI.2016.7850061\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df641f6d4f69bd014fbaf5e30b96beca50396abd\",\"title\":\"The MOBOT rollator human-robot interaction model and user evaluation process\",\"url\":\"https://www.semanticscholar.org/paper/df641f6d4f69bd014fbaf5e30b96beca50396abd\",\"venue\":\"2016 IEEE Symposium Series on Computational Intelligence (SSCI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49144000\",\"name\":\"A. Bastidas\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"}],\"doi\":\"10.1109/CVPRW.2019.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8a1b25826d1e798d886d9c3b28fad968353176b\",\"title\":\"Channel Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8a1b25826d1e798d886d9c3b28fad968353176b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70448265\",\"name\":\"Yi Cao\"},{\"authorId\":\"153172093\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"73312165\",\"name\":\"Wen-bo Zhang\"},{\"authorId\":\"48667875\",\"name\":\"Fei Xue\"}],\"doi\":\"10.1016/j.jvcir.2019.102635\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f33bb4d9af9234232aeb18a7d71831ace015943\",\"title\":\"Visual tracking via dynamic weighting with pyramid-redetection based Siamese networks\",\"url\":\"https://www.semanticscholar.org/paper/4f33bb4d9af9234232aeb18a7d71831ace015943\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1910.10056\",\"authors\":[{\"authorId\":\"1750502\",\"name\":\"X. Huang\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"}],\"doi\":\"10.1109/ICIP40778.2020.9190781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"title\":\"Predictive Coding Networks Meet Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1908.07625\",\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1109/ICCV.2019.00558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"title\":\"Action Recognition With Spatial-Temporal Discriminative Filter Banks\",\"url\":\"https://www.semanticscholar.org/paper/d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881632\",\"name\":\"Shuai Liao\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1145/3206025.3206057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac4747660bac003e3f96ab989eed8b9d5f55e3cd\",\"title\":\"Searching and Matching Texture-free 3D Shapes in Images\",\"url\":\"https://www.semanticscholar.org/paper/ac4747660bac003e3f96ab989eed8b9d5f55e3cd\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2970222\",\"name\":\"Zhongxu Hu\"},{\"authorId\":\"3285279\",\"name\":\"Youmin Hu\"},{\"authorId\":\"49722516\",\"name\":\"J. Liu\"},{\"authorId\":\"144397979\",\"name\":\"Bo Wu\"},{\"authorId\":\"51112167\",\"name\":\"Dongmin Han\"},{\"authorId\":\"144475497\",\"name\":\"Thomas R. Kurfess\"}],\"doi\":\"10.1016/j.neucom.2018.12.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19877bd17979cde9624eb3fe4515a32bb1be3c53\",\"title\":\"A CRNN module for hand pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/19877bd17979cde9624eb3fe4515a32bb1be3c53\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.08362\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1519286448\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"153552276\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/ICME46284.2020.9102724\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"title\":\"Multi-Task Learning of Generalizable Representations for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1709.09121\",\"authors\":[{\"authorId\":\"3401864\",\"name\":\"Ryota Hinami\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"}],\"doi\":\"10.1109/ICCV.2017.391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"094ac7510d1723cb9c2da01db47291322aa29025\",\"title\":\"Joint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/094ac7510d1723cb9c2da01db47291322aa29025\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.02463\",\"authors\":[{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"3325819\",\"name\":\"Shanxin Yuan\"},{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/CVPR.2018.00050\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"title\":\"First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations\",\"url\":\"https://www.semanticscholar.org/paper/e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144216791\",\"name\":\"Da Huo\"},{\"authorId\":\"1788719\",\"name\":\"Yufeng Chen\"},{\"authorId\":\"2255689\",\"name\":\"F. Li\"},{\"authorId\":\"40663936\",\"name\":\"Zhengchao Lei\"}],\"doi\":\"10.1109/ICCSE.2017.8085515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6c8d7e093788a8fdf0e0123d999f18c060d3557\",\"title\":\"Modality-convolutions: Multi-modal gesture recognition based on convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/b6c8d7e093788a8fdf0e0123d999f18c060d3557\",\"venue\":\"2017 12th International Conference on Computer Science and Education (ICCSE)\",\"year\":2017},{\"arxivId\":\"2006.15351\",\"authors\":[{\"authorId\":\"47058824\",\"name\":\"Lamei Zhang\"},{\"authorId\":\"10763777\",\"name\":\"Siyu Zhang\"},{\"authorId\":\"48931671\",\"name\":\"Bin Zou\"},{\"authorId\":\"1409413243\",\"name\":\"Hongwei Dong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43aa507e45b5b5c9077827adc7848eb53cbc840a\",\"title\":\"PCLNet: A Practical Way for Unsupervised Deep PolSAR Representations and Few-Shot Classification\",\"url\":\"https://www.semanticscholar.org/paper/43aa507e45b5b5c9077827adc7848eb53cbc840a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"153817519\",\"name\":\"S. E. Alavi\"}],\"doi\":\"10.22133/IJWR.2020.242723.1063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9064d8220c7fb8fde958d700b825bf03a757dc46\",\"title\":\"CoReHAR: A Hybrid Deep Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9064d8220c7fb8fde958d700b825bf03a757dc46\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.07744\",\"authors\":[{\"authorId\":\"1749326359\",\"name\":\"Adrian Sanchez-Caballero\"},{\"authorId\":\"1406742079\",\"name\":\"David Fuentes-Jim\\u00e9nez\"},{\"authorId\":\"1637432258\",\"name\":\"Cristina Losada-Guti\\u00e9rrez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"664d474f2bc27cd73e40bc5444c17427d1a0c10d\",\"title\":\"Exploiting the ConvLSTM: Human Action Recognition using Raw Depth Video-Based Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/664d474f2bc27cd73e40bc5444c17427d1a0c10d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042569583\",\"name\":\"Kensho Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2042706087\",\"name\":\"Masaki Inaba\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"2042698122\",\"name\":\"Ryusuke Hotta\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ITSC45102.2020.9294443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"title\":\"Predicting Vehicles Appearing from Blind Spots Based on Pedestrian Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"2002.12886\",\"authors\":[{\"authorId\":\"1965933798\",\"name\":\"Alban Main De Boissiere\"},{\"authorId\":\"2479033\",\"name\":\"Rita Noumeir\"}],\"doi\":\"10.1109/ACCESS.2020.3023599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"title\":\"Infrared and 3D Skeleton Feature Fusion for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"38905965\",\"name\":\"Arpit Chaudhary\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1109/WACV.2019.00015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"title\":\"Where to Focus on for Human Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1810.11868\",\"authors\":[{\"authorId\":\"24559284\",\"name\":\"A. Patra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"02d8e23eaee7efbd42313e53f935d24d3713ad2a\",\"title\":\"Sequential anatomy localization in fetal echocardiography videos\",\"url\":\"https://www.semanticscholar.org/paper/02d8e23eaee7efbd42313e53f935d24d3713ad2a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"49308434\",\"name\":\"Y. Yang\"},{\"authorId\":\"2092709\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.3390/jimaging5100082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"title\":\"Deep Learning of Fuzzy Weighted Multi-Resolution Depth Motion Maps with Spatial Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"venue\":\"J. Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"49605422\",\"name\":\"Jing Wang\"},{\"authorId\":\"4869835\",\"name\":\"T. Hassan\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.3390/fi11020042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"title\":\"3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39611894\",\"name\":\"Maria E. Presa-Reyes\"},{\"authorId\":\"1705664\",\"name\":\"Shu-Ching Chen\"}],\"doi\":\"10.1109/MIPR49039.2020.00017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9641953681f1c5e22c101970595b7fa42701dd8\",\"title\":\"Assessing Building Damage by Learning the Deep Feature Correspondence of Before and After Aerial Images\",\"url\":\"https://www.semanticscholar.org/paper/e9641953681f1c5e22c101970595b7fa42701dd8\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1599888295\",\"name\":\"Bin Yu\"},{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"79629177\",\"name\":\"Huangbin Wu\"},{\"authorId\":\"153061207\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1002/cpe.5910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"185239670a3709ec1dd14002229f73898c1403d6\",\"title\":\"Hand gesture recognition based on attentive feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/185239670a3709ec1dd14002229f73898c1403d6\",\"venue\":\"Concurr. Comput. Pract. Exp.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"1471440106\",\"name\":\"W. Meng\"},{\"authorId\":\"4169031\",\"name\":\"Hui-quan Li\"},{\"authorId\":\"8628276\",\"name\":\"Xuehong Cui\"}],\"doi\":\"10.1109/ACCESS.2019.2959206\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"430ee2f6b5a1d4c194e26088ca8e3b58ae571605\",\"title\":\"Multimodal Spatiotemporal Networks for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/430ee2f6b5a1d4c194e26088ca8e3b58ae571605\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3015832\",\"name\":\"Y. Kaneda\"},{\"authorId\":\"36972849\",\"name\":\"Shun Shibata\"},{\"authorId\":\"1714824\",\"name\":\"H. Mineno\"}],\"doi\":\"10.1016/j.knosys.2017.07.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a6fa8ec189bdf1ab1ce3a43fea0d92507b5fb01\",\"title\":\"Multi-modal sliding window-based support vector regression for predicting plant water stress\",\"url\":\"https://www.semanticscholar.org/paper/1a6fa8ec189bdf1ab1ce3a43fea0d92507b5fb01\",\"venue\":\"Knowl. Based Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557606546\",\"name\":\"Jose M. Rodriguez-Borbon\"},{\"authorId\":\"72445820\",\"name\":\"X. Ma\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1778860\",\"name\":\"W. Najjar\"}],\"doi\":\"10.1109/TCSVT.2019.2895304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"title\":\"Heterogeneous Acceleration of HAR Applications\",\"url\":\"https://www.semanticscholar.org/paper/62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819203\",\"name\":\"Zufan Zhang\"},{\"authorId\":\"2000399066\",\"name\":\"Zongming Lv\"},{\"authorId\":\"2901849\",\"name\":\"Chenquan Gan\"},{\"authorId\":\"145649216\",\"name\":\"Qingyi Zhu\"}],\"doi\":\"10.1016/j.neucom.2020.06.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"851edff1c8deded530836d0338ea6cbe50f30594\",\"title\":\"Human action recognition using convolutional LSTM and fully-connected LSTM with different attentions\",\"url\":\"https://www.semanticscholar.org/paper/851edff1c8deded530836d0338ea6cbe50f30594\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1907.01131\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"47781274\",\"name\":\"Z. Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"title\":\"Learnable Gated Temporal Shift Module for Free-form Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"},{\"authorId\":\"2452789\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.neucom.2017.07.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33fdaa747900d8952c0d371e8903c6531e357f93\",\"title\":\"Action recognition by Latent Duration Model\",\"url\":\"https://www.semanticscholar.org/paper/33fdaa747900d8952c0d371e8903c6531e357f93\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"2012.03457\",\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"3086596\",\"name\":\"Byeongho Heo\"},{\"authorId\":\"2086576\",\"name\":\"Dongyoon Han\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"title\":\"VideoMix: Rethinking Data Augmentation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71039664\",\"name\":\"Hiroaki Ishioka\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"48087997\",\"name\":\"Y. Man\"},{\"authorId\":\"1665822545\",\"name\":\"Kris Kitani\"}],\"doi\":\"10.22260/isarc2020/0092\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b116e130b3fa9ee7c007f02c3d19ed35180aec8d\",\"title\":\"Single Camera Worker Detection, Tracking and Action Recognition in Construction Site\",\"url\":\"https://www.semanticscholar.org/paper/b116e130b3fa9ee7c007f02c3d19ed35180aec8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/ACCESS.2019.2953455\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"title\":\"Spatio-Temporal Representation Matching-Based Open-Set Action Recognition by Joint Learning of Motion and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564581635\",\"name\":\"Bassel S. Chawkv\"},{\"authorId\":\"37370786\",\"name\":\"Mohammed Marey\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1109/ICICIS46948.2019.9014841\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"title\":\"OA18: A New Office Actions Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"venue\":\"2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS)\",\"year\":2019},{\"arxivId\":\"1805.04026\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2abaa1476fe1f00358f3eaa77dde2f348f58982\",\"title\":\"Towards an Unequivocal Representation of Actions\",\"url\":\"https://www.semanticscholar.org/paper/f2abaa1476fe1f00358f3eaa77dde2f348f58982\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1912.05003\",\"authors\":[{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"49621014\",\"name\":\"De-Cai Li\"},{\"authorId\":\"101084939\",\"name\":\"Y. He\"},{\"authorId\":\"3110318\",\"name\":\"Chunsheng Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4b09b78f20c62b32ceefd9675f307f03a048c0\",\"title\":\"SCR-Graph: Spatial-Causal Relationships based Graph Reasoning Network for Human Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd4b09b78f20c62b32ceefd9675f307f03a048c0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"}],\"doi\":\"10.1109/IPAS.2018.8708877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"title\":\"Learning to Represent Spatio-Temporal Features for Fine Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":\"1708.03280\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"title\":\"Exploring Temporal Preservation Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/58b3669cd4eed088f9a6b398aee583c5c3d8036f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1909.08453\",\"authors\":[{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"7533195\",\"name\":\"Desen Zhou\"},{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"2332078\",\"name\":\"Rongjie Li\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/ICCV.2019.00956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"title\":\"Pose-Aware Multi-Level Feature Network for Human Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143709258\",\"name\":\"Yangyang Xu\"},{\"authorId\":\"145131937\",\"name\":\"L. Wang\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"},{\"authorId\":\"39827902\",\"name\":\"H. Xia\"},{\"authorId\":\"1890165\",\"name\":\"J. Yin\"}],\"doi\":\"10.1109/COMPCOMM.2017.8322825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7a515d629dccddd413ffa9e395c3100d28f7f26\",\"title\":\"DTA: Double LSTM with temporal-wise attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f7a515d629dccddd413ffa9e395c3100d28f7f26\",\"venue\":\"2017 3rd IEEE International Conference on Computer and Communications (ICCC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":\"1810.06827\",\"authors\":[{\"authorId\":\"3415077\",\"name\":\"Sameera Ramasinghe\"},{\"authorId\":\"32548363\",\"name\":\"Jathushan Rajasegaran\"},{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"48430646\",\"name\":\"Kanchana Ranasinghe\"},{\"authorId\":\"144952844\",\"name\":\"R. Rodrigo\"},{\"authorId\":\"144224514\",\"name\":\"A. Pasqual\"}],\"doi\":\"10.1109/TCSVT.2017.2760858\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"title\":\"Combined Static and Motion Features for Deep-Networks-Based Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212639\",\"name\":\"Xiaomao Fan\"},{\"authorId\":\"40996180\",\"name\":\"Qihang Yao\"},{\"authorId\":\"37242953\",\"name\":\"Yunpeng Cai\"},{\"authorId\":\"2669075\",\"name\":\"Fen Miao\"},{\"authorId\":\"2017866\",\"name\":\"Fangmin Sun\"},{\"authorId\":\"1701468\",\"name\":\"Ye Li\"}],\"doi\":\"10.1109/JBHI.2018.2858789\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"95b3bd7452de875a7efd046534606a4ac51fedec\",\"title\":\"Multiscaled Fusion of Deep Convolutional Neural Networks for Screening Atrial Fibrillation From Single Lead Short ECG Recordings\",\"url\":\"https://www.semanticscholar.org/paper/95b3bd7452de875a7efd046534606a4ac51fedec\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2018},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":\"50841852\",\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1109/TIP.2019.2917283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"title\":\"Dense Dilated Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50699209\",\"name\":\"B. Yang\"},{\"authorId\":\"145313443\",\"name\":\"P. Zhou\"}],\"doi\":\"10.1117/12.2540276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bcea6e7382735bcac5c5675412003c75550ffac\",\"title\":\"Mixed 3D-(2+1)D convolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7bcea6e7382735bcac5c5675412003c75550ffac\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150965117\",\"name\":\"Daniel Alejandro Castro Chin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"title\":\"Understanding The Motion of A Human State In Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00052\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"title\":\"Improving a 3-D Convolutional Neural Network Model Reinvented from VGG16 with Batch Normalization\",\"url\":\"https://www.semanticscholar.org/paper/50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":\"2002.08219\",\"authors\":[{\"authorId\":\"1489467112\",\"name\":\"Yeji Kim\"},{\"authorId\":\"122808682\",\"name\":\"Dong-Gyu Lee\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107279\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"title\":\"Three-Stream Fusion Network for First-Person Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46844014\",\"name\":\"Yu-Min Huang\"},{\"authorId\":\"12931618\",\"name\":\"H. Tseng\"},{\"authorId\":\"145420218\",\"name\":\"Jen-Tzung Chien\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023327\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed957b9ca4d291e0f3a4150f097cb1bdb467fc5f\",\"title\":\"Stochastic Fusion for Multi-stream Neural Network in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ed957b9ca4d291e0f3a4150f097cb1bdb467fc5f\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152987957\",\"name\":\"Tian Wang\"},{\"authorId\":\"152384041\",\"name\":\"Shiye Lei\"},{\"authorId\":\"116503541\",\"name\":\"Youyou Jiang\"},{\"authorId\":\"122209497\",\"name\":\"Choi Chang\"},{\"authorId\":\"2103629\",\"name\":\"Hichem Snoussi\"},{\"authorId\":\"49021634\",\"name\":\"Guangcun Shan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7af61853fd6e536f347b3b69c3e1288db6401e36\",\"title\":\"Accelerating temporal action proposal generation via high performance computing.\",\"url\":\"https://www.semanticscholar.org/paper/7af61853fd6e536f347b3b69c3e1288db6401e36\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-319-69900-4_70\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"title\":\"Two-Stream Convolutional Network with Multi-level Feature Fusion for Categorization of Human Action from Videos\",\"url\":\"https://www.semanticscholar.org/paper/bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035597\",\"name\":\"Novanto Yudistira\"},{\"authorId\":\"145375983\",\"name\":\"Takio Kurita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e297f10a02580dfc74595ff8d7db34020002ec4\",\"title\":\"Correlation Net : spatio temporal multimodal deep learning\",\"url\":\"https://www.semanticscholar.org/paper/6e297f10a02580dfc74595ff8d7db34020002ec4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1708.06637\",\"authors\":[{\"authorId\":\"144289593\",\"name\":\"C. A. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/SIBGRAPI.2017.13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6c086748474dcda06d773891848aa1472de3560\",\"title\":\"Activity Recognition Based on a Magnitude-Orientation Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/c6c086748474dcda06d773891848aa1472de3560\",\"venue\":\"2017 30th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447347\",\"name\":\"H. Liu\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TPAMI.2017.2734779\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9dc41d3bc92e194c5a881ee9d741f898310ce9e\",\"title\":\"Two-Stream Transformer Networks for Video-Based Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/d9dc41d3bc92e194c5a881ee9d741f898310ce9e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1807.09715\",\"authors\":[{\"authorId\":\"31433785\",\"name\":\"Charles Ringer\"},{\"authorId\":\"1752913\",\"name\":\"Mihalis A. Nicolaou\"}],\"doi\":\"10.1145/3235765.3235781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f0fe020c9c181352b6f42f893c79dc02f178de5\",\"title\":\"Deep unsupervised multi-view detection of video game stream highlights\",\"url\":\"https://www.semanticscholar.org/paper/1f0fe020c9c181352b6f42f893c79dc02f178de5\",\"venue\":\"FDG\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46701988\",\"name\":\"Haimin Zhang\"},{\"authorId\":\"143679002\",\"name\":\"Min Xu\"}],\"doi\":\"10.1109/TMM.2018.2808760\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecd3975e55798972deb89708ebe9365f67b7eaf5\",\"title\":\"Recognition of Emotions in User-Generated Videos With Kernelized Features\",\"url\":\"https://www.semanticscholar.org/paper/ecd3975e55798972deb89708ebe9365f67b7eaf5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-3-030-01240-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2003d6e1de789b7fe60819257d8dfd54d267517\",\"title\":\"Dividing and Aggregating Network for Multi-view Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2003d6e1de789b7fe60819257d8dfd54d267517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12277476\",\"name\":\"Lifei Song\"},{\"authorId\":\"1779987\",\"name\":\"Liguo Weng\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"47715056\",\"name\":\"Min Xia\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2018.8451662\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"title\":\"Two-Stream Designed 2D/3D Residual Networks with Lstms for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092663\",\"name\":\"G. Yang\"}],\"doi\":\"10.1016/j.micpro.2020.103339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a955b40830b5d0602323eb4e56dac597a95d69b9\",\"title\":\"CLASSIFICATION ALGORITHM BASED ON SEMANTIC JUDGMENT AND ITS APPLICATION IN IMAGE CLASSIFICATION\",\"url\":\"https://www.semanticscholar.org/paper/a955b40830b5d0602323eb4e56dac597a95d69b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"title\":\"Representing Videos based on Scene Layouts for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097122\",\"name\":\"Y. Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"9359893\",\"name\":\"Shengrong Gong\"}],\"doi\":\"10.1145/3378026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e075864cdf19117f6b5f78db877347e2bca4f\",\"title\":\"Spatio-temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/083e075864cdf19117f6b5f78db877347e2bca4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47756385\",\"name\":\"J. Hu\"},{\"authorId\":\"36393738\",\"name\":\"Y. Chen\"},{\"authorId\":\"144191755\",\"name\":\"Jie Zhong\"},{\"authorId\":\"143978698\",\"name\":\"Rong Ju\"},{\"authorId\":\"40943004\",\"name\":\"Z. Yi\"}],\"doi\":\"10.1109/TMI.2018.2863562\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43121f7dc23c8dcaa5d802b1919d3f51c01e4615\",\"title\":\"Automated Analysis for Retinopathy of Prematurity by Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43121f7dc23c8dcaa5d802b1919d3f51c01e4615\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"},{\"authorId\":\"144934143\",\"name\":\"Dongdong Zhang\"}],\"doi\":\"10.1145/3371425.3371491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4273282e911323957c9b885231658ca592612bee\",\"title\":\"Cross-enhancement transform two-stream 3D ConvNets for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4273282e911323957c9b885231658ca592612bee\",\"venue\":\"AIIPCC '19\",\"year\":2019},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.00391\",\"authors\":[{\"authorId\":\"9739960\",\"name\":\"R. Gu\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"225a6c0409904ff7e5bd3bf4696cc7eadff4b4af\",\"title\":\"Temporal-Spatial Neural Filter: Direction Informed End-to-End Multi-channel Target Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/225a6c0409904ff7e5bd3bf4696cc7eadff4b4af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1708.09268\",\"authors\":[{\"authorId\":\"144603946\",\"name\":\"A. Tran\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"}],\"doi\":\"10.1109/ICCVW.2017.368\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdbfc8786f9ef0c1331f180398857347d29f901b\",\"title\":\"Two-Stream Flow-Guided Convolutional Attention Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdbfc8786f9ef0c1331f180398857347d29f901b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2017.8296542\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"title\":\"Cascaded temporal spatial features for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1708.04301\",\"authors\":[{\"authorId\":\"144909180\",\"name\":\"H. Hosseini\"},{\"authorId\":\"2797515\",\"name\":\"Baicen Xiao\"},{\"authorId\":\"145280190\",\"name\":\"A. Clark\"},{\"authorId\":\"144786412\",\"name\":\"R. Poovendran\"}],\"doi\":\"10.1145/3137616.3137618\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1832c646a98e4794e8408cb23593e8e049d9351\",\"title\":\"Attacking Automatic Video Analysis Algorithms: A Case Study of Google Cloud Video Intelligence API\",\"url\":\"https://www.semanticscholar.org/paper/a1832c646a98e4794e8408cb23593e8e049d9351\",\"venue\":\"MPS@CCS\",\"year\":2017},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.06316\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"title\":\"Temporal Gaussian Mixture Layer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2551813\",\"name\":\"R. Andri\"},{\"authorId\":\"1701257\",\"name\":\"L. Cavigelli\"},{\"authorId\":\"48307511\",\"name\":\"D. Rossi\"},{\"authorId\":\"1710649\",\"name\":\"L. Benini\"}],\"doi\":\"10.1109/JETCAS.2019.2905654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99da0b2d51618f5201c72f0f469212d2489612cd\",\"title\":\"Hyperdrive: A Multi-Chip Systolically Scalable Binary-Weight CNN Inference Engine\",\"url\":\"https://www.semanticscholar.org/paper/99da0b2d51618f5201c72f0f469212d2489612cd\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50884736\",\"name\":\"L. Wu\"},{\"authorId\":\"144367279\",\"name\":\"B. Lovell\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1007/978-3-030-13057-2_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5293e0a0cdc76688e7961c315e5d11b7667b9377\",\"title\":\"Deep Learning in Person Re-identification for Cyber-Physical Surveillance Systems\",\"url\":\"https://www.semanticscholar.org/paper/5293e0a0cdc76688e7961c315e5d11b7667b9377\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.06326\",\"authors\":[{\"authorId\":\"2994471\",\"name\":\"X. Zhang\"},{\"authorId\":\"40353974\",\"name\":\"K. Matzen\"},{\"authorId\":\"50393245\",\"name\":\"Vivien L. Nguyen\"},{\"authorId\":\"144210947\",\"name\":\"Dillon Yao\"},{\"authorId\":\"49890547\",\"name\":\"You Zhang\"},{\"authorId\":\"47383180\",\"name\":\"R. Ng\"}],\"doi\":\"10.1145/3306346.3323015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4150bde5405df091ad07e59e2480fd651758712f\",\"title\":\"Synthetic defocus and look-ahead autofocus for casual videography\",\"url\":\"https://www.semanticscholar.org/paper/4150bde5405df091ad07e59e2480fd651758712f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":\"1804.00623\",\"authors\":[{\"authorId\":\"2551813\",\"name\":\"R. Andri\"},{\"authorId\":\"1701257\",\"name\":\"L. Cavigelli\"},{\"authorId\":\"48307511\",\"name\":\"D. Rossi\"},{\"authorId\":\"1710649\",\"name\":\"L. Benini\"}],\"doi\":\"10.1109/ISVLSI.2018.00099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"061e24e08cf117f910b0a8a37a9118e251ee87e6\",\"title\":\"Hyperdrive: A Systolically Scalable Binary-Weight CNN Inference Engine for mW IoT End-Nodes\",\"url\":\"https://www.semanticscholar.org/paper/061e24e08cf117f910b0a8a37a9118e251ee87e6\",\"venue\":\"2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)\",\"year\":2018},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"144350546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1007/978-3-030-00776-8_57\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"title\":\"DT-3DResNet-LSTM: An Architecture for Temporal Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32062468\",\"name\":\"H. Ou\"},{\"authorId\":\"2994709\",\"name\":\"J. Sun\"}],\"doi\":\"10.1117/1.JEI.28.2.023009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"title\":\"Spatiotemporal information deep fusion network with frame attention mechanism for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"40546560\",\"name\":\"Qingquan Sun\"}],\"doi\":\"10.1016/j.neucom.2016.09.106\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"title\":\"Action recognition by saliency-based dense sampling\",\"url\":\"https://www.semanticscholar.org/paper/6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1905.02540\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"607048b431cea997ae9dd01f029a73c502d0273f\",\"title\":\"Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/607048b431cea997ae9dd01f029a73c502d0273f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1812.10222\",\"authors\":[{\"authorId\":\"16340457\",\"name\":\"L. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2891244\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"19992d925606520af56ea1b5d2ee7c3ff33e4dde\",\"title\":\"3-D PersonVLAD: Learning Deep Global Representations for Video-Based Person Reidentification\",\"url\":\"https://www.semanticscholar.org/paper/19992d925606520af56ea1b5d2ee7c3ff33e4dde\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1908.04013\",\"authors\":[{\"authorId\":\"145079398\",\"name\":\"Kun Cheng\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"},{\"authorId\":\"152131383\",\"name\":\"Lingyiqing Zhou\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01e7f4a72bb7b4747b171764c499f126317b45f2\",\"title\":\"Multi-Frame Content Integration with a Spatio-Temporal Attention Mechanism for Person Video Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/01e7f4a72bb7b4747b171764c499f126317b45f2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.05277\",\"authors\":[{\"authorId\":\"12010968\",\"name\":\"G. Borghi\"},{\"authorId\":\"41183949\",\"name\":\"M. Fabbri\"},{\"authorId\":\"1723285\",\"name\":\"R. Vezzani\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TPAMI.2018.2885472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef1ccd8ae90da6110320ffcc673501862e5cc337\",\"title\":\"Face-from-Depth for Head Pose Estimation on Depth Images\",\"url\":\"https://www.semanticscholar.org/paper/ef1ccd8ae90da6110320ffcc673501862e5cc337\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51936306\",\"name\":\"Swati Dewan\"},{\"authorId\":null,\"name\":\"Shubham Agarwal\"},{\"authorId\":\"2204983\",\"name\":\"N. Singh\"}],\"doi\":\"10.1007/978-3-030-04257-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9004e928e8818b23aafb14745ce9be6c384592f9\",\"title\":\"Automatic Labanotation Generation, Semi-automatic Semantic Annotation and Retrieval of Recorded Videos\",\"url\":\"https://www.semanticscholar.org/paper/9004e928e8818b23aafb14745ce9be6c384592f9\",\"venue\":\"ICADL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49989940\",\"name\":\"A. Jamal\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"2064509\",\"name\":\"Dipti Deodhare\"},{\"authorId\":\"145952735\",\"name\":\"K. Venkatesh\"}],\"doi\":\"10.1007/978-3-030-20893-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"883dc3e5b274412ff8fb0b4d291e7f3f935fb080\",\"title\":\"U-DADA: Unsupervised Deep Action Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/883dc3e5b274412ff8fb0b4d291e7f3f935fb080\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845611487\",\"name\":\"L. Chen\"},{\"authorId\":null,\"name\":\"Liu Rui\"},{\"authorId\":null,\"name\":\"Zhou Dongsheng\"},{\"authorId\":null,\"name\":\"Xin Yang\"},{\"authorId\":null,\"name\":\"Qiang Zhang\"},{\"authorId\":null,\"name\":\"Wei Xiaopeng\"}],\"doi\":\"10.1007/978-3-030-63426-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"title\":\"ESENet: A Human Behavior Recognition Model Based on Extended Squeeze-and-Excitation Network\",\"url\":\"https://www.semanticscholar.org/paper/62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752875656\",\"name\":\"Divya Meena Sundaram\"},{\"authorId\":\"1739138002\",\"name\":\"A. Loganathan\"}],\"doi\":\"10.1117/1.JRS.14.026521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e90c2ec3237f895b9e8ec204925b6a8f95379135\",\"title\":\"FSSCaps-DetCountNet: fuzzy soft sets and CapsNet-based detection and counting network for monitoring animals from aerial images\",\"url\":\"https://www.semanticscholar.org/paper/e90c2ec3237f895b9e8ec204925b6a8f95379135\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145634568\",\"name\":\"H. Hu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"}],\"doi\":\"10.1109/CVPRW.2017.272\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dee6609615b73b10540f32537a242baa3c9fca4d\",\"title\":\"Temporal Domain Neural Encoder for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/dee6609615b73b10540f32537a242baa3c9fca4d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832019\",\"name\":\"Fuhua Shang\"},{\"authorId\":\"145421603\",\"name\":\"Tao Han\"},{\"authorId\":\"152236895\",\"name\":\"Feng Tian\"},{\"authorId\":\"1884170385\",\"name\":\"Jun Tao\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.3014691\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"title\":\"A Multimodal Pairwise Discrimination Network for Cross-Domain Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.04462\",\"authors\":[{\"authorId\":\"3264239\",\"name\":\"Shi-Yuan Huang\"},{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"title\":\"Flow-Distilled IP Two-Stream Networks for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"145081305\",\"name\":\"L. Zhu\"},{\"authorId\":\"38079143\",\"name\":\"H. Zhang\"},{\"authorId\":\"38930487\",\"name\":\"Yinglong Wang\"}],\"doi\":\"10.1109/ACCESS.2018.2878313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"title\":\"Exploring the Cross-Domain Action Recognition Problem by Deep Feature Learning and Cross-Domain Learning\",\"url\":\"https://www.semanticscholar.org/paper/5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"40867966\",\"name\":\"Ermioni Mastora\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1007/978-3-030-03801-4_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5054a8082a0adea6008b16bdc1489b99f1853275\",\"title\":\"Robust Incremental Hidden Conditional Random Fields for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5054a8082a0adea6008b16bdc1489b99f1853275\",\"venue\":\"ISVC\",\"year\":2018},{\"arxivId\":\"1811.03879\",\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1007/978-3-030-12939-2_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"title\":\"Cross and Learn: Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.07179\",\"authors\":[{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd613000f7b2b6161548b1c1044ab46c7327a901\",\"title\":\"Attention-based Temporal Weighted Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd613000f7b2b6161548b1c1044ab46c7327a901\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"9297627\",\"name\":\"N. Balachandar\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3147852\",\"name\":\"Guido Pusiol\"},{\"authorId\":\"4421380\",\"name\":\"J. Luxenberg\"},{\"authorId\":\"49461537\",\"name\":\"Grace Li\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"3472674\",\"name\":\"A. Milstein\"},{\"authorId\":\"1435579960\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9628d7ae049ff763626f1f3a4f33ebcacd746b15\",\"title\":\"Vision-Based Descriptive Analytics of Seniors \\u2019 Daily Activities for Long-Term Health Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/9628d7ae049ff763626f1f3a4f33ebcacd746b15\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429079\",\"name\":\"Girmaw Abebe\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCVW.2017.159\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a671cb0d366ab895249349ca457673150ecc8ee2\",\"title\":\"A Long Short-Term Memory Convolutional Neural Network for First-Person Vision Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a671cb0d366ab895249349ca457673150ecc8ee2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1811.11875\",\"authors\":[{\"authorId\":\"52121635\",\"name\":\"Nathan Inkawhich\"},{\"authorId\":\"52117082\",\"name\":\"Matthew Inkawhich\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"},{\"authorId\":\"47892815\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"title\":\"Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.08069\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"207a1766a942be3f22534980f47916f6dc683095\",\"title\":\"S3D: Single Shot multi-Span Detector via Fully 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/207a1766a942be3f22534980f47916f6dc683095\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153008120\",\"name\":\"Zineng Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eee0fd08e8b33bf2affb355a6ecd3523860aa11\",\"title\":\"Action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6eee0fd08e8b33bf2affb355a6ecd3523860aa11\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"title\":\"Two-Stream Oriented Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e1b171fab52368f14f41955cdc7ca7775ded58\",\"title\":\"RGB TVL 1 Flow RGB + TVL 1 FlowMARS MARS + RGB MERS MERS + RGB Accuracy vs Time on MiniKinetics\",\"url\":\"https://www.semanticscholar.org/paper/47e1b171fab52368f14f41955cdc7ca7775ded58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"title\":\"Unified Egocentric Recognition of 3 D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9184016\",\"name\":\"J. Liu\"},{\"authorId\":\"8897402\",\"name\":\"Feng-Ping An\"}],\"doi\":\"10.1155/2020/7607612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f41a7ee9cac02f8a8f0ed7a76ea7503d29d34b37\",\"title\":\"Image Classification Algorithm Based on Deep Learning-Kernel Function\",\"url\":\"https://www.semanticscholar.org/paper/f41a7ee9cac02f8a8f0ed7a76ea7503d29d34b37\",\"venue\":\"Sci. Program.\",\"year\":2020},{\"arxivId\":\"2003.00385\",\"authors\":[{\"authorId\":\"47301772\",\"name\":\"Zhi-xin Jia\"},{\"authorId\":\"1954169\",\"name\":\"Mengxiang Lin\"},{\"authorId\":\"49864769\",\"name\":\"Zhixin Chen\"},{\"authorId\":\"1515540255\",\"name\":\"Shibo Jian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"710788e606d6c94608c9b1e925a34391d58ce801\",\"title\":\"Vision-based Robot Manipulation Learning via Human Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/710788e606d6c94608c9b1e925a34391d58ce801\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089367\",\"name\":\"P. Abreu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d5809d13e9de52ff113575533a029297f737468\",\"title\":\"Augmentation of Two-stream CNN architectures with context and attention for action detection and recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d5809d13e9de52ff113575533a029297f737468\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92599875\",\"name\":\"M. Nadeem\"},{\"authorId\":\"1828728\",\"name\":\"V. N. L. Franqueira\"},{\"authorId\":\"1881146\",\"name\":\"X. Zhai\"},{\"authorId\":\"1741168\",\"name\":\"F. Kurugollu\"}],\"doi\":\"10.1109/ACCESS.2019.2924733\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255485196a869c98aacce60a86074fccf07c01eb\",\"title\":\"A Survey of Deep Learning Solutions for Multimedia Visual Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/255485196a869c98aacce60a86074fccf07c01eb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"29438845\",\"name\":\"I. Haq\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1016/J.FUTURE.2019.01.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c40639b5a2be2ac13e2c982348b45e92584ad9c0\",\"title\":\"Action recognition using optimized deep autoencoder and CNN for surveillance data streams of non-stationary environments\",\"url\":\"https://www.semanticscholar.org/paper/c40639b5a2be2ac13e2c982348b45e92584ad9c0\",\"venue\":\"Future Gener. Comput. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651582\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1916963\",\"name\":\"Y. Shen\"},{\"authorId\":\"89080361\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ICMEW.2019.00034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"title\":\"Deep Key Clips-Video Feature Fusion Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICIP.2018.8451022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"158324e0eb67e48145d09c38e8fba50a7638678d\",\"title\":\"On the Fusion of RGB and Depth Information for Hand Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/158324e0eb67e48145d09c38e8fba50a7638678d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17772505\",\"name\":\"Chaojie Ou\"},{\"authorId\":\"3314892\",\"name\":\"Safaa M. Bedawi\"},{\"authorId\":\"40994204\",\"name\":\"Arief B. Koesdwiady\"},{\"authorId\":\"1696863\",\"name\":\"F. Karray\"}],\"doi\":\"10.1109/VTCFall.2018.8690657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c121f806f4996c74123cb360c0e89985454a821\",\"title\":\"Predicting Steering Actions for Self-Driving Cars Through Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/7c121f806f4996c74123cb360c0e89985454a821\",\"venue\":\"2018 IEEE 88th Vehicular Technology Conference (VTC-Fall)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83167758\",\"name\":\"Jie Zheng\"},{\"authorId\":\"11733729\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/CISP-BMEI48845.2019.8965930\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b0f6b8c475d1765629ec7d03ae479c6036ee90a\",\"title\":\"Non-Local Spatiaotemporal Two-Stream Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b0f6b8c475d1765629ec7d03ae479c6036ee90a\",\"venue\":\"2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150148817\",\"name\":\"Jin-Long Huang\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"7674045\",\"name\":\"J. Zheng\"},{\"authorId\":\"48448949\",\"name\":\"Xiao-Xiao Peng\"}],\"doi\":\"10.1007/978-3-030-26766-7_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97c37e7e3c6bd9bfa9ba72b5b65c7d8c7418ef36\",\"title\":\"Periodic Action Temporal Localization Method Based on Two-Path Architecture for Product Counting in Sewing Video\",\"url\":\"https://www.semanticscholar.org/paper/97c37e7e3c6bd9bfa9ba72b5b65c7d8c7418ef36\",\"venue\":\"ICIC\",\"year\":2019},{\"arxivId\":\"1912.01373\",\"authors\":[{\"authorId\":\"2633472\",\"name\":\"Sung-Kwon Choo\"},{\"authorId\":\"69411484\",\"name\":\"Won-Kyo Seo\"},{\"authorId\":\"1707645\",\"name\":\"N. I. Cho\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"147c0ce7d67bf1274e3ab48791f0502983368296\",\"title\":\"Automatic Video Object Segmentation via Motion-Appearance-Stream Fusion and Instance-aware Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/147c0ce7d67bf1274e3ab48791f0502983368296\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2025336100\",\"name\":\"Fladio Armandika\"},{\"authorId\":\"9292289\",\"name\":\"E. C. Djamal\"},{\"authorId\":\"100510864\",\"name\":\"F. Nugraha\"},{\"authorId\":\"72755241\",\"name\":\"Fatan Kasyidi\"}],\"doi\":\"10.23919/EECSI50503.2020.9251902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a83d32176cfe9ad778977a3dcbb7e75bec4696b\",\"title\":\"Dynamic Hand Gesture Recognition Using Temporal-Stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a83d32176cfe9ad778977a3dcbb7e75bec4696b\",\"venue\":\"2020 7th International Conference on Electrical Engineering, Computer Sciences and Informatics (EECSI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11834740\",\"name\":\"P. Jahoda\"},{\"authorId\":\"1729513004\",\"name\":\"Igor Drozdovskiy\"},{\"authorId\":\"15922204\",\"name\":\"S. Payler\"},{\"authorId\":\"1729512692\",\"name\":\"Leonardo Turchi\"},{\"authorId\":\"40047242\",\"name\":\"L. Bessone\"},{\"authorId\":\"2005730981\",\"name\":\"F. Sauro\"}],\"doi\":\"10.1039/d0an01483d\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0acbdfae598bb35b95b9ebbc93622c32c9b5b76\",\"title\":\"Machine learning for recognizing minerals from multispectral data.\",\"url\":\"https://www.semanticscholar.org/paper/b0acbdfae598bb35b95b9ebbc93622c32c9b5b76\",\"venue\":\"The Analyst\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29850862\",\"name\":\"He-Yen Hsieh\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190975\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d0a1105f231ffc200d7b299fb962d8b673369be\",\"title\":\"Temporal Action Proposal Generation Via Deep Feature Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1105f231ffc200d7b299fb962d8b673369be\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3215608\",\"name\":\"J. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/S11063-020-10349-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eac014f40c5601fdf1eab65b117250f6888e8799\",\"title\":\"Complementary Boundary Estimation Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/eac014f40c5601fdf1eab65b117250f6888e8799\",\"venue\":\"Neural Process. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/s00371-019-01725-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"812cfc1f88008476dc2ae90d0117065a4001a81b\",\"title\":\"Deep motion templates and extreme learning machine for sign language recognition\",\"url\":\"https://www.semanticscholar.org/paper/812cfc1f88008476dc2ae90d0117065a4001a81b\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04337\",\"authors\":[{\"authorId\":\"46480156\",\"name\":\"P. Gupta\"},{\"authorId\":\"8518293\",\"name\":\"Jyoti Maggu\"},{\"authorId\":\"144622883\",\"name\":\"A. Majumdar\"},{\"authorId\":\"102425592\",\"name\":\"\\u00c9. Chouzenoux\"},{\"authorId\":\"24284226\",\"name\":\"G. Chierchia\"}],\"doi\":\"10.1186/s13634-020-00684-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4915a3fb29769b0b7237e9a18c3f47f21c22235\",\"title\":\"DeConFuse: a deep convolutional transform-based unsupervised fusion framework\",\"url\":\"https://www.semanticscholar.org/paper/a4915a3fb29769b0b7237e9a18c3f47f21c22235\",\"venue\":\"EURASIP J. Adv. Signal Process.\",\"year\":2020},{\"arxivId\":\"1902.10796\",\"authors\":[{\"authorId\":\"3027229\",\"name\":\"Ashwini Tonge\"},{\"authorId\":\"1690656\",\"name\":\"Cornelia Caragea\"}],\"doi\":\"10.1145/3308558.3313691\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90f75bdafdca5505c5b0af510542bc90fe0a4e65\",\"title\":\"Dynamic Deep Multi-modal Fusion for Image Privacy Prediction\",\"url\":\"https://www.semanticscholar.org/paper/90f75bdafdca5505c5b0af510542bc90fe0a4e65\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2019.00400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"title\":\"Weakly Supervised Temporal Action Localization Through Contrast Based Evaluation Networks\",\"url\":\"https://www.semanticscholar.org/paper/87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"49984779\",\"name\":\"Chih-Chieh Yang\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"32168186\",\"name\":\"F. Zhou\"},{\"authorId\":\"1795283\",\"name\":\"B. Chen\"}],\"doi\":\"10.1016/j.jpdc.2019.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d0f0e835a46a7a7938f0eab4e2234a5d2c3bb15\",\"title\":\"Fast neural network training on a cluster of GPUs for action recognition with high accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1d0f0e835a46a7a7938f0eab4e2234a5d2c3bb15\",\"venue\":\"J. Parallel Distributed Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9227143\",\"name\":\"Yuanping Zhang\"},{\"authorId\":\"9227143\",\"name\":\"Yuanping Zhang\"},{\"authorId\":\"1687046\",\"name\":\"Y. Tang\"},{\"authorId\":\"1687046\",\"name\":\"Y. Tang\"},{\"authorId\":\"143762022\",\"name\":\"B. Fang\"},{\"authorId\":\"1883230\",\"name\":\"Zhaowei Shang\"}],\"doi\":\"10.1142/S0219691319500425\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42958a957d7f03a1ba95234361ca683766cfea8a\",\"title\":\"Multi-object tracking using deformable convolution networks with tracklets updating\",\"url\":\"https://www.semanticscholar.org/paper/42958a957d7f03a1ba95234361ca683766cfea8a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143926313\",\"name\":\"O-Yeon Kwon\"},{\"authorId\":\"81787330\",\"name\":\"M. Lee\"},{\"authorId\":\"145836900\",\"name\":\"Cuntai Guan\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1109/TNNLS.2019.2946869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4c3b59b4511c4de93cb681dd0add544d7f77feb\",\"title\":\"Subject-Independent Brain\\u2013Computer Interfaces Based on Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d4c3b59b4511c4de93cb681dd0add544d7f77feb\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3290745\",\"name\":\"M. T. Lorbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"865415145141268cfb47774523138797493afb5e\",\"title\":\"Automated Recognition of Rodent Social Behavior\",\"url\":\"https://www.semanticscholar.org/paper/865415145141268cfb47774523138797493afb5e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"title\":\"Learning to Recognize Actions with Weak Supervision. (Reconnaissance d'actions de mani\\u00e8re faiblement supervis\\u00e9e)\",\"url\":\"https://www.semanticscholar.org/paper/d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.05788\",\"authors\":[{\"authorId\":\"143876686\",\"name\":\"C. Ma\"},{\"authorId\":\"144423419\",\"name\":\"L. Chen\"},{\"authorId\":\"143865487\",\"name\":\"Jun-Hai Yong\"}],\"doi\":\"10.1016/j.neucom.2019.03.082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"105eb3731e66d7d143b98058b16bc551482a7b41\",\"title\":\"AU R-CNN: Encoding Expert Prior Knowledge into R-CNN for Action Unit Detection\",\"url\":\"https://www.semanticscholar.org/paper/105eb3731e66d7d143b98058b16bc551482a7b41\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035849222\",\"name\":\"Jianjia Zhang\"},{\"authorId\":\"2035849222\",\"name\":\"Jianjia Zhang\"},{\"authorId\":\"46660146\",\"name\":\"L. Wang\"},{\"authorId\":\"6578587\",\"name\":\"L. Zhou\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"}],\"doi\":\"10.1007/s11263-020-01376-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75cfd593297bae6eb3f3be21e8a58bbaa8d34ef0\",\"title\":\"Beyond Covariance: SICE and Kernel Based Visual Feature Representation\",\"url\":\"https://www.semanticscholar.org/paper/75cfd593297bae6eb3f3be21e8a58bbaa8d34ef0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.08505\",\"authors\":[{\"authorId\":\"65914312\",\"name\":\"Clebeson Canuto dos Santos\"},{\"authorId\":\"143622442\",\"name\":\"J. A. Samatelo\"},{\"authorId\":\"21859276\",\"name\":\"Raquel Frizera Vassallo\"}],\"doi\":\"10.1016/j.neucom.2020.03.038\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0b763e684aa26436efb8da8dad15d4fd555866e\",\"title\":\"Dynamic Gesture Recognition by Using CNNs and Star RGB: a Temporal Information Condensation\",\"url\":\"https://www.semanticscholar.org/paper/d0b763e684aa26436efb8da8dad15d4fd555866e\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51918162\",\"name\":\"Gledson Melotti\"},{\"authorId\":\"2097466\",\"name\":\"C. Premebida\"},{\"authorId\":\"144017996\",\"name\":\"N. Gon\\u00e7alves\"}],\"doi\":\"10.1109/ICARSC49921.2020.9096138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1234eff95b6f97d3df703d45adb9aaf413ad8be7\",\"title\":\"Multimodal Deep-Learning for Object Recognition Combining Camera and LIDAR Data\",\"url\":\"https://www.semanticscholar.org/paper/1234eff95b6f97d3df703d45adb9aaf413ad8be7\",\"venue\":\"2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1016/j.neucom.2018.05.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2cda38655d3f216430969b5b864b96c1b011c1\",\"title\":\"Detecting action tubes via spatial action estimation and temporal path inference\",\"url\":\"https://www.semanticscholar.org/paper/de2cda38655d3f216430969b5b864b96c1b011c1\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29779792\",\"name\":\"Kailun Zhong\"},{\"authorId\":\"31964291\",\"name\":\"Yi Li\"},{\"authorId\":\"144567629\",\"name\":\"L. Fang\"},{\"authorId\":\"145842268\",\"name\":\"P. Chen\"}],\"doi\":\"10.1007/978-3-030-31456-9_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dadd8e0d9bd106009d801a2fc96310943a38b6a\",\"title\":\"Cross-Dimension Transfer Learning for Video-Based Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0dadd8e0d9bd106009d801a2fc96310943a38b6a\",\"venue\":\"CCBR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144230956\",\"name\":\"Bo Huang\"},{\"authorId\":\"28899830\",\"name\":\"Hualong Huang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-319-70090-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89b279005e08a4936365eadbaea3bba1477188fb\",\"title\":\"Convolutional Gated Recurrent Units Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89b279005e08a4936365eadbaea3bba1477188fb\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71caf2f74e94cbb1c7fb3250e083a4d6924fb30e\",\"title\":\"PicSOM and EURECOM Experiments in TRECVID 2019 Pre-workshop draft \\u2013 Revision : 0 . 9\",\"url\":\"https://www.semanticscholar.org/paper/71caf2f74e94cbb1c7fb3250e083a4d6924fb30e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.09602\",\"authors\":[{\"authorId\":\"1388016741\",\"name\":\"Chris Careaga\"},{\"authorId\":\"144156036\",\"name\":\"Brian Hutchinson\"},{\"authorId\":\"47312946\",\"name\":\"Nathan Hodas\"},{\"authorId\":\"21785345\",\"name\":\"L. Phillips\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"title\":\"Metric-Based Few-Shot Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2698604\",\"name\":\"J. Miyao\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1007/978-981-15-4818-5_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b57e0f07d5752e30d8becd80d78dfeae3a1d62b2\",\"title\":\"Short-Term Action Recognition by 3D Convolutional Neural Network with Pixel-Wise Evidences\",\"url\":\"https://www.semanticscholar.org/paper/b57e0f07d5752e30d8becd80d78dfeae3a1d62b2\",\"venue\":\"IW-FCV\",\"year\":2020},{\"arxivId\":\"1910.12906\",\"authors\":[{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"3352747\",\"name\":\"Tanmay Randhavane\"},{\"authorId\":\"2718563\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1609/aaai.v34i02.5490\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23135a88c48de1b15bfdf2f4c09621385ae5d3de\",\"title\":\"STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits\",\"url\":\"https://www.semanticscholar.org/paper/23135a88c48de1b15bfdf2f4c09621385ae5d3de\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845267\",\"name\":\"Da Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00394\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daf161f0f763bf19246ad51338764c9f732d11f0\",\"title\":\"METAL: Minimum Effort Temporal Activity Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/daf161f0f763bf19246ad51338764c9f732d11f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2005.04366\",\"authors\":[{\"authorId\":\"1471722186\",\"name\":\"Miao Yin\"},{\"authorId\":\"145657535\",\"name\":\"Siyu Liao\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"48632004\",\"name\":\"X. Wang\"},{\"authorId\":\"1471729588\",\"name\":\"Bo Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"title\":\"Compressing Recurrent Neural Networks Using Hierarchical Tucker Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49047213\",\"name\":\"Congcong Liu\"},{\"authorId\":\"48410668\",\"name\":\"Jie Ying\"},{\"authorId\":\"3107530\",\"name\":\"Haima Yang\"},{\"authorId\":\"48539425\",\"name\":\"X. Hu\"},{\"authorId\":\"48211677\",\"name\":\"Jin Liu\"}],\"doi\":\"10.1007/s00371-020-01868-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6429d6188ed346c62792ff13cf36c1cb1a3e1205\",\"title\":\"Improved human action recognition approach based on two-stream convolutional neural network model\",\"url\":\"https://www.semanticscholar.org/paper/6429d6188ed346c62792ff13cf36c1cb1a3e1205\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"2002.03187\",\"authors\":[{\"authorId\":null,\"name\":\"Hao Zhou\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"24520518\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1609/AAAI.V34I07.7001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1e2665ac39dcb389e12f3f993004b4b4651826d\",\"title\":\"Spatial-Temporal Multi-Cue Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a1e2665ac39dcb389e12f3f993004b4b4651826d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47150103\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/WF-IoT48130.2020.9221355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d69bb85795e1ca9c6354c8537cc96a4361704c87\",\"title\":\"Multipath Event-Based Network for Low-Power Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d69bb85795e1ca9c6354c8537cc96a4361704c87\",\"venue\":\"2020 IEEE 6th World Forum on Internet of Things (WF-IoT)\",\"year\":2020},{\"arxivId\":\"2010.07524\",\"authors\":[{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"616e4fa9ac89ef99f073aabfcdb4cc05e4407520\",\"title\":\"Unsupervised Video Anomaly Detection via Flow-based Generative Modeling on Appearance and Motion Latent Features\",\"url\":\"https://www.semanticscholar.org/paper/616e4fa9ac89ef99f073aabfcdb4cc05e4407520\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/TBIOM.2020.2968216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c485bd63692f4aa68e54137ad237a431849017b9\",\"title\":\"Online Dynamic Hand Gesture Recognition Including Efficiency Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c485bd63692f4aa68e54137ad237a431849017b9\",\"venue\":\"IEEE Transactions on Biometrics, Behavior, and Identity Science\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49210768\",\"name\":\"Ling Guan\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"1403961741\",\"name\":\"Nour El-Din El-Madany\"},{\"authorId\":\"3337292\",\"name\":\"Chengwu Liang\"}],\"doi\":\"10.1109/MIPR.2018.00059\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"60462b981fda63c5f9d780528a37c46884fe0b54\",\"title\":\"Statistical Machine Learning vs Deep Learning in Information Fusion: Competition or Collaboration?\",\"url\":\"https://www.semanticscholar.org/paper/60462b981fda63c5f9d780528a37c46884fe0b54\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":null,\"name\":\"Qianli Ma\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3588725a4fb22db3a1506eaed75eb97fba09ecc3\",\"title\":\"Low-rank Random Tensor for Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/3588725a4fb22db3a1506eaed75eb97fba09ecc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1909523920\",\"name\":\"Jen-Kai Tsai\"},{\"authorId\":\"144926927\",\"name\":\"Chen-Chien Hsu\"},{\"authorId\":\"2653046\",\"name\":\"W. Wang\"},{\"authorId\":\"2814144\",\"name\":\"Shao-Kang Huang\"}],\"doi\":\"10.3390/s20174758\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9923da669485dfa56e69e4b8f4bb5620ea2161ba\",\"title\":\"Deep Learning-Based Real-Time Multiple-Person Action Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/9923da669485dfa56e69e4b8f4bb5620ea2161ba\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1924057490\",\"name\":\"Jinkue Lee\"},{\"authorId\":\"150123608\",\"name\":\"Hoeryong Jung\"}],\"doi\":\"10.3390/s20174871\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"696f993294597ba4657733d12a5f783ac58d1b80\",\"title\":\"TUHAD: Taekwondo Unit Technique Human Action Dataset with Key Frame-Based CNN Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/696f993294597ba4657733d12a5f783ac58d1b80\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123331898\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"title\":\"Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49750984\",\"name\":\"C. Chen\"},{\"authorId\":\"2800735\",\"name\":\"C. Zhang\"},{\"authorId\":\"1749704087\",\"name\":\"Tiannuo Wang\"},{\"authorId\":\"49620724\",\"name\":\"Dongnian Li\"},{\"authorId\":\"144794615\",\"name\":\"Y. Guo\"},{\"authorId\":\"24927259\",\"name\":\"Zhengxu Zhao\"},{\"authorId\":\"144705147\",\"name\":\"J. Hong\"}],\"doi\":\"10.3390/s20154208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"937b9594aa2359deddda346090d64bd874d8eb84\",\"title\":\"Monitoring of Assembly Process Using Deep Learning Technology\",\"url\":\"https://www.semanticscholar.org/paper/937b9594aa2359deddda346090d64bd874d8eb84\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2008.07819\",\"authors\":[{\"authorId\":\"72831997\",\"name\":\"T. Ma\"},{\"authorId\":\"101160956\",\"name\":\"L. Zhang\"},{\"authorId\":\"87641774\",\"name\":\"X. Diao\"},{\"authorId\":\"1411075691\",\"name\":\"O. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"title\":\"ConvGRU in Fine-grained Pitching Action Recognition for Action Outcome Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BENJAMIN NAOTO CHICHE\"},{\"authorId\":\"1702571\",\"name\":\"Amir H. Payberah\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f3e83d68b00051c115078ef25f9160cc3d4e26e9\",\"title\":\"Video classification with memory and computation-efficient convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/f3e83d68b00051c115078ef25f9160cc3d4e26e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1575585565\",\"name\":\"Xiyu Kong\"},{\"authorId\":\"3405204\",\"name\":\"Muming Zhao\"},{\"authorId\":\"49780826\",\"name\":\"Hao Zhou\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054258\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8eebfe0dcebffc1f93bb4fd7b51b9d0b925fab2b\",\"title\":\"Weakly Supervised Crowd-Wise Attention For Robust Crowd Counting\",\"url\":\"https://www.semanticscholar.org/paper/8eebfe0dcebffc1f93bb4fd7b51b9d0b925fab2b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/TIP.2017.2772904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a955ee69174fb97c7017f2e227a5fa26b900537\",\"title\":\"Egocentric Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/7a955ee69174fb97c7017f2e227a5fa26b900537\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24559284\",\"name\":\"A. Patra\"},{\"authorId\":\"1500544150\",\"name\":\"M. Ali\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"11189f87ae641a34b9628df7a9df0a8f45499865\",\"title\":\"Detection of spatiotemporal stochastic motion in echocardiography videos\",\"url\":\"https://www.semanticscholar.org/paper/11189f87ae641a34b9628df7a9df0a8f45499865\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92679c8cff92442f39de3405c21c8028162fe56a\",\"title\":\"Temporal 3D ConvNets Using Temporal Transition Layer\",\"url\":\"https://www.semanticscholar.org/paper/92679c8cff92442f39de3405c21c8028162fe56a\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-319-97909-0_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5549576809e8f9c3871c31285601f71d2d82ce5d\",\"title\":\"Residual Gating Fusion Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5549576809e8f9c3871c31285601f71d2d82ce5d\",\"venue\":\"CCBR\",\"year\":2018},{\"arxivId\":\"1705.08583\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"49733ccd65c087f3f0cf3d2235bed1b76f66e693\",\"title\":\"Sequence Summarization Using Order-constrained Kernelized Feature Subspaces\",\"url\":\"https://www.semanticscholar.org/paper/49733ccd65c087f3f0cf3d2235bed1b76f66e693\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":null,\"name\":\"Bicheng Xu\"},{\"authorId\":\"2057809\",\"name\":\"G. Zhou\"},{\"authorId\":\"3004771\",\"name\":\"L. Bornn\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"883e59ac3e386023d6ad8ef97d5c881a2009741c\",\"title\":\"Next : When , Where , What ? \\u201c Pass \\u201d \\u201c Receive \\u201d \\u201c Carry \\u201d \\u201c Dump \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/883e59ac3e386023d6ad8ef97d5c881a2009741c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f23b737af93469efc4b7438377a3cec2e9c8febb\",\"title\":\"Ju l 2 01 8 Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f23b737af93469efc4b7438377a3cec2e9c8febb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1907.11117\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b73ff5846772da8575262925aa7709b5e64079a0\",\"title\":\"Learning Visual Actions Using Multiple Verb-Only Labels\",\"url\":\"https://www.semanticscholar.org/paper/b73ff5846772da8575262925aa7709b5e64079a0\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46580562\",\"name\":\"Stefan Braun\"},{\"authorId\":\"145243593\",\"name\":\"D. Neil\"},{\"authorId\":\"24033690\",\"name\":\"Jithendar Anumula\"},{\"authorId\":\"9314936\",\"name\":\"Enea Ceolini\"},{\"authorId\":\"1704961\",\"name\":\"Shih-Chii Liu\"}],\"doi\":\"10.1109/IJCNN.2019.8852396\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7706104e1d3e1c5c18874350de6d35334fd8fed\",\"title\":\"Attention-driven Multi-sensor Selection\",\"url\":\"https://www.semanticscholar.org/paper/f7706104e1d3e1c5c18874350de6d35334fd8fed\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"15429809\",\"name\":\"Yangliu Hu\"}],\"doi\":\"10.1007/978-3-030-05716-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"title\":\"Soccer Video Event Detection Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"134883142\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2018.2887408\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification With Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000034\",\"name\":\"C. Huang\"},{\"authorId\":\"71422013\",\"name\":\"H. Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2890899\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d756afea68f322e9cd6509d148efec6c3e266772\",\"title\":\"A Novel Key-Frames Selection Framework for Comprehensive Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/d756afea68f322e9cd6509d148efec6c3e266772\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46602980\",\"name\":\"Thi Minh Hanh Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf203dc1119b32139653d5c72a6dc4d1bfb5dd8b\",\"title\":\"Anomaly detection in video\",\"url\":\"https://www.semanticscholar.org/paper/cf203dc1119b32139653d5c72a6dc4d1bfb5dd8b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18071979\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2588acc7a730d864f84d4e1a050070ff873b03d5\",\"title\":\"Action Recognition by an Attention-Aware Temporal Weighted Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2588acc7a730d864f84d4e1a050070ff873b03d5\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"2010.01343\",\"authors\":[{\"authorId\":\"153257128\",\"name\":\"A. Srivastava\"},{\"authorId\":\"83923404\",\"name\":\"O. Dutta\"},{\"authorId\":\"2988091\",\"name\":\"A. Prathosh\"},{\"authorId\":\"47208444\",\"name\":\"Sumeet Agarwal\"},{\"authorId\":\"66286585\",\"name\":\"J. Gupta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4a545203ed195f77bb2fa4fcb90199ff7784f74\",\"title\":\"A Variational Information Bottleneck Based Method to Compress Sequential Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4a545203ed195f77bb2fa4fcb90199ff7784f74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33455548\",\"name\":\"Jonathan Wu\"},{\"authorId\":\"1756038\",\"name\":\"P. Ishwar\"},{\"authorId\":\"48323468\",\"name\":\"J. Konrad\"}],\"doi\":\"10.1007/978-3-319-61657-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"548f44899d81babf02f3380763ac29da5c280e5a\",\"title\":\"Two-Stream CNNs for Gesture-Based Verification and Identification: Learning User Style\",\"url\":\"https://www.semanticscholar.org/paper/548f44899d81babf02f3380763ac29da5c280e5a\",\"venue\":\"CVPR 2016\",\"year\":2016},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.07209\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"49606697\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TPAMI.2017.2670560\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"title\":\"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3379055\",\"name\":\"M. Hossain\"},{\"authorId\":\"8112875\",\"name\":\"K. Cannons\"},{\"authorId\":\"40284986\",\"name\":\"D. Jang\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"47047818\",\"name\":\"Zhan Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"64c37e58d706ce429e379ed05097762ed737a87a\",\"title\":\"Video-Based Crowd Counting Using a Multi-Scale Optical Flow Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/64c37e58d706ce429e379ed05097762ed737a87a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.01083\",\"authors\":[{\"authorId\":\"51991145\",\"name\":\"Naina Dhingra\"},{\"authorId\":\"143717147\",\"name\":\"A. Kunz\"}],\"doi\":\"10.1109/3DV.2019.00061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"title\":\"Res3ATN - Deep 3D Residual Attention Network for Hand Gesture Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93385858\",\"name\":\"Z. Han\"},{\"authorId\":\"9260001\",\"name\":\"Yaling Liang\"},{\"authorId\":\"115023860\",\"name\":\"Zengqun Chen\"},{\"authorId\":\"6364267\",\"name\":\"Zhiheng Zhou\"}],\"doi\":\"10.3233/jifs-192067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eb45acc4f27fc47ed13249273cf5cb86476b154\",\"title\":\"A two-stream network with joint spatial-temporal distance for video-based person re-identification\",\"url\":\"https://www.semanticscholar.org/paper/1eb45acc4f27fc47ed13249273cf5cb86476b154\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72547325\",\"name\":\"Bassel S. Chawky\"},{\"authorId\":\"37370786\",\"name\":\"M. Marey\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1109/ICCES.2018.8639245\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46acae0f91d77eace6d425aa37d681004d28a157\",\"title\":\"Multi-Temporal-Resolution Technique for Action Recognition using C3D: Experimental Study\",\"url\":\"https://www.semanticscholar.org/paper/46acae0f91d77eace6d425aa37d681004d28a157\",\"venue\":\"2018 13th International Conference on Computer Engineering and Systems (ICCES)\",\"year\":2018},{\"arxivId\":\"1812.01922\",\"authors\":[{\"authorId\":\"48379459\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"7595315\",\"name\":\"Christian Jarvers\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1109/CVPR.2019.01228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428934f26e240aadeec86b40b23182455fb25c1a\",\"title\":\"Local Temporal Bilinear Pooling for Fine-Grained Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/428934f26e240aadeec86b40b23182455fb25c1a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240659\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecb4bab5296224bdedd389cf18748c2ff0050100\",\"title\":\"Online Action Tube Detection via Resolving the Spatio-temporal Context Pattern\",\"url\":\"https://www.semanticscholar.org/paper/ecb4bab5296224bdedd389cf18748c2ff0050100\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1803.05347\",\"authors\":[{\"authorId\":\"1718226\",\"name\":\"C. Li\"},{\"authorId\":\"143711380\",\"name\":\"D. Song\"},{\"authorId\":\"3128157\",\"name\":\"Ruofeng Tong\"},{\"authorId\":\"47605163\",\"name\":\"M. Tang\"}],\"doi\":\"10.1016/j.patcog.2018.08.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c1d748cf007531e59997eced96469a536842198\",\"title\":\"Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection\",\"url\":\"https://www.semanticscholar.org/paper/1c1d748cf007531e59997eced96469a536842198\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005271\",\"name\":\"Z. Li\"},{\"authorId\":\"1390685056\",\"name\":\"Yue Wu\"},{\"authorId\":\"1404588675\",\"name\":\"W. Abd-Almageed\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":\"10.1007/978-3-030-20873-8_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cb5780b87c44bde549420a93b2ae990d0d423b9\",\"title\":\"Weighted Feature Pooling Network in Template-Based Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cb5780b87c44bde549420a93b2ae990d0d423b9\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14542853\",\"name\":\"K. Hu\"},{\"authorId\":\"48708295\",\"name\":\"Z. Wang\"},{\"authorId\":\"153321393\",\"name\":\"K. E. Martens\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"}],\"doi\":\"10.1007/978-3-030-20887-5_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f40c2c3080f20a1c435e547f1020ab88352df9da\",\"title\":\"Vision-Based Freezing of Gait Detection with Anatomic Patch Based Representation\",\"url\":\"https://www.semanticscholar.org/paper/f40c2c3080f20a1c435e547f1020ab88352df9da\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"153585940\",\"name\":\"Hang Gao\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCVW.2019.00288\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3be602c7c3812397a29c64e544981a362de80f27\",\"title\":\"Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/3be602c7c3812397a29c64e544981a362de80f27\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50442701\",\"name\":\"Yu Jin\"},{\"authorId\":\"72336898\",\"name\":\"Y. Li\"}],\"doi\":\"10.1109/ICTAI.2019.00240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebcba87bc299735288579094f8479834ff3df6d4\",\"title\":\"Neural Network Approximation for Nonlinear Partial Differential Equations with Quasi-Newton Optimization and Piecewise Strategy\",\"url\":\"https://www.semanticscholar.org/paper/ebcba87bc299735288579094f8479834ff3df6d4\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50694843\",\"name\":\"S. Wang\"},{\"authorId\":\"1687384\",\"name\":\"Chiou-Ting Hsu\"}],\"doi\":\"10.5244/C.31.70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"733e24c33d50d6d3ff8755c30c92eb587a1fb3a3\",\"title\":\"AST-Net: An Attribute-based Siamese Temporal Network for Real-Time Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/733e24c33d50d6d3ff8755c30c92eb587a1fb3a3\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"2011.09216\",\"authors\":[{\"authorId\":\"30857985\",\"name\":\"Nishant Bhattacharya\"},{\"authorId\":\"2000307852\",\"name\":\"Suresh Sundaram\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06adf1a80e110f4c78c31f072824726aeeed1a1a\",\"title\":\"CGAP2: Context and gap aware predictive pose framework for early detection of gestures\",\"url\":\"https://www.semanticscholar.org/paper/06adf1a80e110f4c78c31f072824726aeeed1a1a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2900228\",\"name\":\"A. Masys\"},{\"authorId\":\"1388869398\",\"name\":\"Mamoun Alazab\"},{\"authorId\":\"50627760\",\"name\":\"Mingjian Tang\"}],\"doi\":\"10.1007/978-3-030-13057-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0267a77049e4dd02d61d032d061f29bd0e81b486\",\"title\":\"Deep Learning Applications for Cyber Security\",\"url\":\"https://www.semanticscholar.org/paper/0267a77049e4dd02d61d032d061f29bd0e81b486\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"50164924\",\"name\":\"Guanqun Ding\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"}],\"doi\":\"10.1109/TIP.2018.2885229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f2f48d03ed81c79b23ea68fced0ca1492036e98\",\"title\":\"Deep3DSaliency: Deep Stereoscopic Video Saliency Detection Model by 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/6f2f48d03ed81c79b23ea68fced0ca1492036e98\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"3145905\",\"name\":\"Jingqiu Zhang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11280-018-0530-0\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a304bea200da57e4a7ee3ca6ad36b5496763a6d0\",\"title\":\"Exploiting long-term temporal dynamics for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/a304bea200da57e4a7ee3ca6ad36b5496763a6d0\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1610.02237\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1016/j.cviu.2017.06.004\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3099b2c6a7a9771f3159d4934657ccf26e0f254d\",\"title\":\"Weakly supervised learning of actions from transcripts\",\"url\":\"https://www.semanticscholar.org/paper/3099b2c6a7a9771f3159d4934657ccf26e0f254d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"2007.12530\",\"authors\":[{\"authorId\":\"1832165240\",\"name\":\"Nikolas Adaloglou\"},{\"authorId\":\"1832364767\",\"name\":\"Theocharis Chatzis\"},{\"authorId\":\"1720774729\",\"name\":\"Ilias Papastratis\"},{\"authorId\":\"51919460\",\"name\":\"Andreas Stergioulas\"},{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1832359458\",\"name\":\"Vassia Zacharopoulou\"},{\"authorId\":\"2619600\",\"name\":\"George J. Xydopoulos\"},{\"authorId\":\"1832338213\",\"name\":\"Klimnis Atzakas\"},{\"authorId\":\"72239752\",\"name\":\"D. Papazachariou\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29e207f184213e521839f4686d6fc282fea97ef1\",\"title\":\"A Comprehensive Study on Sign Language Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/29e207f184213e521839f4686d6fc282fea97ef1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"13938108\",\"name\":\"Kaiming Cheng\"},{\"authorId\":\"9248073\",\"name\":\"Z. Li\"},{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"}],\"doi\":\"10.1016/J.PATREC.2018.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2aa6e399c3213513b3c9fee1963c38fd6552ac0d\",\"title\":\"Workflow recognition with structured two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/2aa6e399c3213513b3c9fee1963c38fd6552ac0d\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1804.01429\",\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2019.00135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9664f41b8e21125fed01fa3858ca40949fb73e01\",\"title\":\"Layout-Induced Video Representation for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/9664f41b8e21125fed01fa3858ca40949fb73e01\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1701.00193\",\"authors\":[{\"authorId\":\"38314901\",\"name\":\"H. Liu\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144807927\",\"name\":\"K. Jayashree\"},{\"authorId\":\"2188839\",\"name\":\"M. Qi\"},{\"authorId\":\"1731396\",\"name\":\"J. Jiang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TCSVT.2017.2715499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93288d536a90fbf7f78e09cbc164345bca0ec2c7\",\"title\":\"Video-Based Person Re-Identification With Accumulative Motion Context\",\"url\":\"https://www.semanticscholar.org/paper/93288d536a90fbf7f78e09cbc164345bca0ec2c7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/AVSS.2018.8639169\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d27dce9ac396f5b38d7eb9c50f8a6d7a34b43c10\",\"title\":\"Simultaneous Event Localization and Recognition in Surveillance Video\",\"url\":\"https://www.semanticscholar.org/paper/d27dce9ac396f5b38d7eb9c50f8a6d7a34b43c10\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1642174039\",\"name\":\"Dezhong Xu\"},{\"authorId\":\"1642213055\",\"name\":\"Heng Fu\"},{\"authorId\":\"8531710\",\"name\":\"L. Wu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"39267996\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2979742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35b91aa0115a4189ece2a365b59d42f21c186de8\",\"title\":\"Group Activity Recognition by Using Effective Multiple Modality Relation Representation With Temporal-Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/35b91aa0115a4189ece2a365b59d42f21c186de8\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40604885\",\"name\":\"Vachiraporn Ketsoi\"},{\"authorId\":\"7612072\",\"name\":\"M. Raza\"},{\"authorId\":\"40440163\",\"name\":\"H. Chen\"}],\"doi\":\"10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00163\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a57c9b55743e5b505811355569c3a3c8fcc06439\",\"title\":\"Hand Motion Based Human Computer Interaction Using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a57c9b55743e5b505811355569c3a3c8fcc06439\",\"venue\":\"2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83145882\",\"name\":\"J. You\"},{\"authorId\":\"144388019\",\"name\":\"P. Shi\"},{\"authorId\":\"29348697\",\"name\":\"Xiaojie Bao\"}],\"doi\":\"10.1109/ITOEC.2018.8740606\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f41e30a97b7ea505de56630755fde312d3752c5\",\"title\":\"Multi-stream I3D Network for Fine-grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f41e30a97b7ea505de56630755fde312d3752c5\",\"venue\":\"2018 IEEE 4th Information Technology and Mechatronics Engineering Conference (ITOEC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1007/978-3-030-04167-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caae04e73d362180f9586fabb224244200add105\",\"title\":\"Multi-stream with Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/caae04e73d362180f9586fabb224244200add105\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121569773\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"48586318\",\"name\":\"Chengrong Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"151495118\",\"name\":\"Cong Bai\"},{\"authorId\":\"48002027\",\"name\":\"X. Xue\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d54af916d7b813e798fa27327bfb0a909d816fd7\",\"title\":\"Embodied One-Shot Video Recognition: Learning from Actions of a Virtual Embodied Agent\",\"url\":\"https://www.semanticscholar.org/paper/d54af916d7b813e798fa27327bfb0a909d816fd7\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1803.07742\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":\"10.1007/978-3-030-11018-5_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4aac6f2dddf0f068f664b666a21a304275ebe0c\",\"title\":\"Fast Semantic Segmentation on Video Using Block Motion-Based Feature Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e4aac6f2dddf0f068f664b666a21a304275ebe0c\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1905.12708\",\"authors\":[{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"9427217\",\"name\":\"I. Dwivedi\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/ICRA.2019.8794137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07dd4a2c0c5d783206684eb8977a8a8d9e130a0a\",\"title\":\"Dynamic Traffic Scene Classification with Space-Time Coherence\",\"url\":\"https://www.semanticscholar.org/paper/07dd4a2c0c5d783206684eb8977a8a8d9e130a0a\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"40622450\",\"name\":\"S. Zhang\"},{\"authorId\":\"144159826\",\"name\":\"L. Wu\"},{\"authorId\":\"144738967\",\"name\":\"S. Zhang\"},{\"authorId\":\"47120636\",\"name\":\"Xiangdong Wang\"},{\"authorId\":\"2288520\",\"name\":\"Yonghao He\"}],\"doi\":\"10.1016/j.neucom.2018.03.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5628cd4895b80114ca8912374794fe5a4844af5d\",\"title\":\"Deep key frame extraction for sport training\",\"url\":\"https://www.semanticscholar.org/paper/5628cd4895b80114ca8912374794fe5a4844af5d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447537\",\"name\":\"Haijun Liu\"},{\"authorId\":\"2019481\",\"name\":\"S. Wang\"},{\"authorId\":\"97520398\",\"name\":\"Wen Wang\"},{\"authorId\":\"144569543\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/TMM.2019.2929923\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"title\":\"Multi-Scale Based Context-Aware Net for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51105591\",\"name\":\"D. Avola\"},{\"authorId\":\"1729018\",\"name\":\"L. Cinque\"},{\"authorId\":\"1491202046\",\"name\":\"Alberto Del Bimbo\"},{\"authorId\":\"40163123\",\"name\":\"Marco Raoul Marini\"}],\"doi\":\"10.1007/s11042-019-08590-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce5bf21882964d653cef0bfcdf9d814e30b4f90c\",\"title\":\"MIFTel: a multimodal interactive framework based on temporal logic rules\",\"url\":\"https://www.semanticscholar.org/paper/ce5bf21882964d653cef0bfcdf9d814e30b4f90c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.00157\",\"authors\":[{\"authorId\":\"38790746\",\"name\":\"Ana Paula G. S. de Almeida\"},{\"authorId\":\"2058288\",\"name\":\"F. Vidal\"}],\"doi\":\"10.1049/el.2019.2631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6df59ca0700aff6cf9597c5e2e6339819a900f34\",\"title\":\"L-CNN: A Lattice cross-fusion strategy for multistream convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/6df59ca0700aff6cf9597c5e2e6339819a900f34\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151492109\",\"name\":\"Wensong Chan\"},{\"authorId\":\"71506962\",\"name\":\"Zhiqiang Tian\"},{\"authorId\":\"51381728\",\"name\":\"S. Liu\"},{\"authorId\":\"145160620\",\"name\":\"J. Ren\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"}],\"doi\":\"10.1007/978-3-030-27535-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"title\":\"Select and Focus: Action Recognition with Spatial-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1612.03052\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"144660077\",\"name\":\"Jan Neumann\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"title\":\"ActionFlowNet: Learning Motion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31894181\",\"name\":\"M. Nandini\"},{\"authorId\":\"49852961\",\"name\":\"Nagappa U. Bhajantri\"},{\"authorId\":\"1723727\",\"name\":\"Trisiladevi C. Nagavi\"}],\"doi\":\"10.1007/978-981-15-3666-3_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4455f7265e2f66bb0ccb2cf0ecd785fa985827b5\",\"title\":\"Routine Statistical Framework to Speculate Kannada Lip Reading\",\"url\":\"https://www.semanticscholar.org/paper/4455f7265e2f66bb0ccb2cf0ecd785fa985827b5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2830923\",\"name\":\"Chunlei Yang\"},{\"authorId\":\"1882253\",\"name\":\"Jinlong Kang\"},{\"authorId\":\"50853050\",\"name\":\"Xiaoting Xue\"},{\"authorId\":\"49455294\",\"name\":\"Y. Zhou\"},{\"authorId\":\"4550108\",\"name\":\"H. Wang\"},{\"authorId\":\"1471395000\",\"name\":\"Zhaoxing Wan\"},{\"authorId\":\"5708929\",\"name\":\"Tongsheng Su\"},{\"authorId\":\"144578908\",\"name\":\"Fei Xie\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"}],\"doi\":\"10.1145/3364836.3364838\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a50a479aac9d5e8896453a3b95f573fd6f777c15\",\"title\":\"Automatic Degree Evaluation of Facial Nerve Paralysis Based on Triple-stream Long Short Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/a50a479aac9d5e8896453a3b95f573fd6f777c15\",\"venue\":\"ISICDM 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"145473096\",\"name\":\"Yu Zheng\"},{\"authorId\":\"145758664\",\"name\":\"J. Fan\"}],\"doi\":\"10.1109/TMM.2019.2907453\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56da037ea82b991caf206c07318f793dd0513c4a\",\"title\":\"Exploiting Mid-Level Semantics for Large-Scale Complex Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/56da037ea82b991caf206c07318f793dd0513c4a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.09818\",\"authors\":[{\"authorId\":\"145098776\",\"name\":\"Umar Asif\"},{\"authorId\":\"2363364\",\"name\":\"D. Mehta\"},{\"authorId\":\"2103918\",\"name\":\"Stefan von Cavallar\"},{\"authorId\":\"2328282\",\"name\":\"J. Tang\"},{\"authorId\":\"40639323\",\"name\":\"S. Harrer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f64c5330704d9d0909044fb653313c23e4a02ef\",\"title\":\"DeepActsNet: Spatial and Motion features from Face, Hands, and Body Combined with Convolutional and Graph Networks for Improved Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f64c5330704d9d0909044fb653313c23e4a02ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.06709\",\"authors\":[{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"},{\"authorId\":\"32484187\",\"name\":\"S. Adali\"}],\"doi\":\"10.1109/CVPRW.2017.44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94abe0f71c6270ce67ab74d296fa56e5a00ca965\",\"title\":\"Learning Spatiotemporal Features for Infrared Action Recognition with 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/94abe0f71c6270ce67ab74d296fa56e5a00ca965\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27097994\",\"name\":\"Qiule Sun\"},{\"authorId\":\"49110790\",\"name\":\"Qilong Wang\"},{\"authorId\":\"40210312\",\"name\":\"Jianxin Zhang\"},{\"authorId\":\"40426020\",\"name\":\"P. Li\"}],\"doi\":\"10.1016/j.neucom.2017.12.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d669921765e92708a14eaa9393d0e6a17d54561d\",\"title\":\"Hyperlayer Bilinear Pooling with application to fine-grained categorization and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d669921765e92708a14eaa9393d0e6a17d54561d\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"2767515\",\"name\":\"Izaro Goienetxea\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"}],\"doi\":\"10.3390/s20082436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"708ef686a14105ba5f1d75d1c5f4db9f96e46c93\",\"title\":\"Shedding Light on People Action Recognition in Social Robotics by Means of Common Spatial Patterns\",\"url\":\"https://www.semanticscholar.org/paper/708ef686a14105ba5f1d75d1c5f4db9f96e46c93\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1912.10405\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1609/AAAI.V34I07.6854\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"title\":\"Adversarial Cross-Domain Action Recognition with Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978810071\",\"name\":\"Konstantinos Bacharidis\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207397\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40f490936a81c89d0100c166c86f6ef0ec09fd64\",\"title\":\"Improving Deep Learning Approaches for Human Activity Recognition based on Natural Language Processing of Action Labels\",\"url\":\"https://www.semanticscholar.org/paper/40f490936a81c89d0100c166c86f6ef0ec09fd64\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144871013\",\"name\":\"Y. Pi\"},{\"authorId\":\"145737107\",\"name\":\"Zhen Zhao\"},{\"authorId\":\"66566247\",\"name\":\"Yongzhao Xiang\"},{\"authorId\":\"121703965\",\"name\":\"Yuhao Li\"},{\"authorId\":\"3742544\",\"name\":\"H. Cai\"},{\"authorId\":\"93701299\",\"name\":\"Zhang. Yi\"}],\"doi\":\"10.1016/j.media.2020.101784\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02aef3f3ae573b1ca44a59479950dbabb247bb68\",\"title\":\"Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/02aef3f3ae573b1ca44a59479950dbabb247bb68\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":\"2004.11623\",\"authors\":[{\"authorId\":\"10792639\",\"name\":\"Maarten Vandersteegen\"},{\"authorId\":\"1656709277\",\"name\":\"Wouter Reusen\"},{\"authorId\":\"2321568\",\"name\":\"Kristof Van Beeck\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1109/CVPRW50498.2020.00057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db922731bf1469a525f72bbc71eb229a853b0c93\",\"title\":\"Low-latency hand gesture recognition with a low resolution thermal imager\",\"url\":\"https://www.semanticscholar.org/paper/db922731bf1469a525f72bbc71eb229a853b0c93\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"40449507\",\"name\":\"Yang Yang\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/TMM.2018.2802648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"523038f4185228a3b55058dbc49924e587d5eb7c\",\"title\":\"Fusing Geometric Features for Skeleton-Based Action Recognition Using Multilayer LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/523038f4185228a3b55058dbc49924e587d5eb7c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed9b230a1629049656c62bf4434d1212faeacc1f\",\"title\":\"C V ] 9 N ov 2 01 8 Cross and Learn : Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/ed9b230a1629049656c62bf4434d1212faeacc1f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40380855\",\"name\":\"Fernando Moya Rueda\"},{\"authorId\":\"51173816\",\"name\":\"Ren\\u00e9 Grzeszick\"},{\"authorId\":\"1749475\",\"name\":\"G. Fink\"},{\"authorId\":\"2577935\",\"name\":\"Sascha Feldhorst\"},{\"authorId\":\"49438111\",\"name\":\"M. T. Hompel\"}],\"doi\":\"10.3390/informatics5020026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d90db527d890d3ecf0ef17e005743fe240973cec\",\"title\":\"Convolutional Neural Networks for Human Activity Recognition Using Body-Worn Sensors\",\"url\":\"https://www.semanticscholar.org/paper/d90db527d890d3ecf0ef17e005743fe240973cec\",\"venue\":\"Informatics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"144981720\",\"name\":\"Xue Bai\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"74806144\",\"name\":\"H. Tinega\"},{\"authorId\":\"1761058\",\"name\":\"Y. Ding\"}],\"doi\":\"10.1109/ACCESS.2019.2910604\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"title\":\"A Spatiotemporal Heterogeneous Two-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40896248\",\"name\":\"Samvit Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fd070be9327291e229d3149ec60388dd4dbf74b1\",\"title\":\"Fast Semantic Segmentation on Video Using Motion Vector-Based Feature Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/fd070be9327291e229d3149ec60388dd4dbf74b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143781496\",\"name\":\"Ke Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1893776\",\"name\":\"Shaohe Lv\"},{\"authorId\":\"143844357\",\"name\":\"Yong Dou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"title\":\"TPC: Temporal Preservation Convolutional Networks for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4adb97b096b700af9a58d00e45a2f980136fcbb5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30075877\",\"name\":\"W. Ye\"},{\"authorId\":\"120971374\",\"name\":\"J. Cheng\"},{\"authorId\":\"145976802\",\"name\":\"F. Yang\"},{\"authorId\":\"48615395\",\"name\":\"Y. Xu\"}],\"doi\":\"10.1109/access.2019.2918808\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"title\":\"Two-Stream Convolutional Network for Improving Activity Recognition Using Convolutional Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1905.13209\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"title\":\"AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures\",\"url\":\"https://www.semanticscholar.org/paper/a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"}],\"doi\":\"10.1016/J.PATCOG.2019.106989\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75e34c4d672344e76ec108aea21f93c04cacc314\",\"title\":\"Using temporal information for recognizing actions from still images\",\"url\":\"https://www.semanticscholar.org/paper/75e34c4d672344e76ec108aea21f93c04cacc314\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51300566\",\"name\":\"C. Reining\"},{\"authorId\":\"100599124\",\"name\":\"Friedrich Niemann\"},{\"authorId\":\"40380855\",\"name\":\"Fernando Moya Rueda\"},{\"authorId\":\"50128791\",\"name\":\"Gernot A. Fink\"},{\"authorId\":\"49438111\",\"name\":\"M. T. Hompel\"}],\"doi\":\"10.3390/INFO10080245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ec5d96b74cd96abd5c18aac762bc1243fd53242\",\"title\":\"Human Activity Recognition for Production and Logistics - A Systematic Literature Review\",\"url\":\"https://www.semanticscholar.org/paper/3ec5d96b74cd96abd5c18aac762bc1243fd53242\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":\"1812.01233\",\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"title\":\"Classifying Collisions with Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79755154\",\"name\":\"Hongje Seong\"},{\"authorId\":\"2246939\",\"name\":\"Junhyuk Hyun\"},{\"authorId\":\"70400973\",\"name\":\"Euntai Kim\"}],\"doi\":\"10.1109/ICCVW.2019.00194\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"title\":\"Video Multitask Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36751124\",\"name\":\"Amit Nagpal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5668835305efae2697844a053a3451e25f2b8e9\",\"title\":\"Fine grained action recognition in sports videos\",\"url\":\"https://www.semanticscholar.org/paper/d5668835305efae2697844a053a3451e25f2b8e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.07793\",\"authors\":[{\"authorId\":\"145724888\",\"name\":\"Ashraful Islam\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1109/WACV45572.2020.9093620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145c15e10967f9eb598b62ab547312571ec3ac3c\",\"title\":\"Weakly Supervised Temporal Action Localization Using Deep Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/145c15e10967f9eb598b62ab547312571ec3ac3c\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20398722\",\"name\":\"Edwin Jonathan Escobedo Cardenas\"},{\"authorId\":\"34560478\",\"name\":\"G. Ch\\u00e1vez\"}],\"doi\":\"10.1007/978-3-319-75193-1_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fad604ab6c0f7b9047e92e114004b63a990d6f3e\",\"title\":\"Fusion of Deep Learning Descriptors for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fad604ab6c0f7b9047e92e114004b63a990d6f3e\",\"venue\":\"CIARP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40909443\",\"name\":\"Y. Hu\"},{\"authorId\":\"50655168\",\"name\":\"MingQi Lu\"},{\"authorId\":\"144898651\",\"name\":\"Xiaobo Lu\"}],\"doi\":\"10.1016/j.image.2019.115697\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77bcecfb17db7937eca4744490f638c3032d376f\",\"title\":\"Feature refinement for image-based driver action recognition via multi-scale attention convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/77bcecfb17db7937eca4744490f638c3032d376f\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2011.02265\",\"authors\":[{\"authorId\":\"90724813\",\"name\":\"Y. Cheng\"},{\"authorId\":\"3566342\",\"name\":\"Yuchao Yang\"},{\"authorId\":\"50688512\",\"name\":\"Haibao Chen\"},{\"authorId\":\"1873081\",\"name\":\"N. Wong\"},{\"authorId\":\"37629830\",\"name\":\"H. Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"085e32367a143a829fd6c6adc8e28a552afcc191\",\"title\":\"S3-Net: A Fast and Lightweight Video Scene Understanding Network by Single-shot Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/085e32367a143a829fd6c6adc8e28a552afcc191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097295\",\"name\":\"Yue Li\"},{\"authorId\":\"31399226\",\"name\":\"Wenrui Ding\"},{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"46843692\",\"name\":\"Yuanjun Huang\"},{\"authorId\":\"9325297\",\"name\":\"Yalong Jiang\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9191306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"title\":\"Cam-Net: Compressed Attentive Multi-Granularity Network For Dynamic Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145236670\",\"name\":\"R. Lu\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/LSP.2018.2853566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2176fe5d53f69c26ae88c4ffe6607f7466ef33bc\",\"title\":\"Listen and Look: Audio\\u2013Visual Matching Assisted Speech Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/2176fe5d53f69c26ae88c4ffe6607f7466ef33bc\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2581044\",\"name\":\"Cemil Zalluhoglu\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.016\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fb4c91cbb55ab8f6ceea76f1812506df58bf634\",\"title\":\"Region based multi-stream convolutional neural networks for collective activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fb4c91cbb55ab8f6ceea76f1812506df58bf634\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978582908\",\"name\":\"Divina Govender\"},{\"authorId\":\"66491832\",\"name\":\"Jules-Raymond Tapamo\"}],\"doi\":\"10.3390/s20216380\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"85be850607b8d65c9b22082c7a20b06b11f6c2a6\",\"title\":\"Spatio-Temporal Scale Coded Bag-of-Words\",\"url\":\"https://www.semanticscholar.org/paper/85be850607b8d65c9b22082c7a20b06b11f6c2a6\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.05438\",\"authors\":[{\"authorId\":\"1846789641\",\"name\":\"Maxat Alibayev\"},{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"143971676\",\"name\":\"Y. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"title\":\"Developing Motion Code Embedding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48115601\",\"name\":\"W. Lee\"},{\"authorId\":\"2424770\",\"name\":\"J. Kim\"},{\"authorId\":\"144151151\",\"name\":\"Nam Kyung Lee\"}],\"doi\":\"10.1109/ICTC49870.2020.9289212\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c3085b26fa344c28f103764dbb3d3714aebea24\",\"title\":\"Pornographic Video Detection with Convolutional Two-Stream Network Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5c3085b26fa344c28f103764dbb3d3714aebea24\",\"venue\":\"2020 International Conference on Information and Communication Technology Convergence (ICTC)\",\"year\":2020},{\"arxivId\":\"2005.10439\",\"authors\":[{\"authorId\":\"50722486\",\"name\":\"Kelei He\"},{\"authorId\":\"34991744\",\"name\":\"C. Lian\"},{\"authorId\":\"121178487\",\"name\":\"B. Zhang\"},{\"authorId\":\"1820921\",\"name\":\"X. Zhang\"},{\"authorId\":\"1646534970\",\"name\":\"Xiaohuan Cao\"},{\"authorId\":\"2149862\",\"name\":\"Dong Nie\"},{\"authorId\":\"145644809\",\"name\":\"Yang Gao\"},{\"authorId\":\"40430887\",\"name\":\"J. Zhang\"},{\"authorId\":\"146549267\",\"name\":\"D. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7dc9d27df4336eee165a107820855ff996117ab\",\"title\":\"HF-UNet: Learning Hierarchically Inter-Task Relevance in Multi-Task U-Net for Accurate Prostate Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a7dc9d27df4336eee165a107820855ff996117ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14758\",\"authors\":[{\"authorId\":\"23980155\",\"name\":\"Veeru Talreja\"},{\"authorId\":\"1709360\",\"name\":\"M. Valenti\"},{\"authorId\":\"1722653\",\"name\":\"N. Nasrabadi\"}],\"doi\":\"10.1109/TIFS.2020.3033189\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f49fbeda26590772fe81b8bd8c3109b99fae0a\",\"title\":\"Deep Hashing for Secure Multimodal Biometrics\",\"url\":\"https://www.semanticscholar.org/paper/05f49fbeda26590772fe81b8bd8c3109b99fae0a\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144349170\",\"name\":\"Meet Pandya\"},{\"authorId\":\"1753967\",\"name\":\"A. Pillai\"},{\"authorId\":\"2007484554\",\"name\":\"Himanshu Rupani\"}],\"doi\":\"10.1007/978-981-15-3383-9_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb09c4472916a9385c67c62f82509da877d951b0\",\"title\":\"Segregating and Recognizing Human Actions from Video Footages Using LRCN Technique\",\"url\":\"https://www.semanticscholar.org/paper/fb09c4472916a9385c67c62f82509da877d951b0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaoqiang Li\"},{\"authorId\":null,\"name\":\"Miao Xie\"},{\"authorId\":null,\"name\":\"Yin Zhang\"},{\"authorId\":null,\"name\":\"Jide Li\"}],\"doi\":\"10.1117/1.JEI.29.6.063013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ff367b6e92953c0f0e72f5bee2f64f1c1d19f01\",\"title\":\"Multi-scale temporal feature-based dense convolutional network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ff367b6e92953c0f0e72f5bee2f64f1c1d19f01\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"2004.00945\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"151484848\",\"name\":\"Liang Xu\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"1409933106\",\"name\":\"Yue Xu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"48622851\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"title\":\"PaStaNet: Toward Human Activity Knowledge Engine\",\"url\":\"https://www.semanticscholar.org/paper/37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020}],\"corpusId\":12289712,\"doi\":\"10.1109/CVPR.2016.213\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":151,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"references\":[{\"arxivId\":\"1507.08750\",\"authors\":[{\"authorId\":\"2894414\",\"name\":\"Junhyuk Oh\"},{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4257bc131c36504a04382290cbc27ca8bb27813\",\"title\":\"Action-Conditional Video Prediction using Deep Networks in Atari Games\",\"url\":\"https://www.semanticscholar.org/paper/e4257bc131c36504a04382290cbc27ca8bb27813\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1503.03832\",\"authors\":[{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"}],\"doi\":\"10.1109/CVPR.2015.7298682\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aa26299435bdf7db874ef1640a6c3b5a4a2c394\",\"title\":\"FaceNet: A unified embedding for face recognition and clustering\",\"url\":\"https://www.semanticscholar.org/paper/5aa26299435bdf7db874ef1640a6c3b5a4a2c394\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.0035\",\"authors\":[{\"authorId\":\"32694028\",\"name\":\"Aravindh Mahendran\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPR.2015.7299155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d790c8fae40357d24813d085fa74a436847fb49\",\"title\":\"Understanding deep image representations by inverting them\",\"url\":\"https://www.semanticscholar.org/paper/4d790c8fae40357d24813d085fa74a436847fb49\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Garrote\"},{\"authorId\":null,\"name\":\"T. Poggio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Large - scale video classication with convolutional neural networks ImageNet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Srivastava\"},{\"authorId\":null,\"name\":\"E. Mansimov\"},{\"authorId\":null,\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A dataset of 101 human actions calsses from videos in the wild\",\"url\":\"\",\"venue\":\"Tech - nical Report CRCV - TR - 1201 , UCF Center for Research in Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4280\",\"authors\":[{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"2558463\",\"name\":\"R. Goroshin\"},{\"authorId\":\"36399635\",\"name\":\"Arjun Jain\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"1395143164\",\"name\":\"Christopher Bregler\"}],\"doi\":\"10.1109/CVPR.2015.7298664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebcea2d842d3d4e320500086aff0deb4cb4412ff\",\"title\":\"Efficient object localization using Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/ebcea2d842d3d4e320500086aff0deb4cb4412ff\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1412.4564\",\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"3257286\",\"name\":\"Karel Lenc\"}],\"doi\":\"10.1145/2733373.2807412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"title\":\"MatConvNet: Convolutional Neural Networks for MATLAB\",\"url\":\"https://www.semanticscholar.org/paper/0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"144489408\",\"name\":\"Rui Caseiro\"},{\"authorId\":\"2182210\",\"name\":\"Jorge P. Batista\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1007/978-3-642-33786-4_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28fa525ca1e101335e877bb1f6999b6ccf476959\",\"title\":\"Semantic Segmentation with Second-Order Pooling\",\"url\":\"https://www.semanticscholar.org/paper/28fa525ca1e101335e877bb1f6999b6ccf476959\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2543016\",\"name\":\"M. Cimpoi\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/cvpr.2015.7299007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aec822f56ff1794c32f5826cfb266f9b477f4df8\",\"title\":\"Deep filter banks for texture recognition and segmentation\",\"url\":\"https://www.semanticscholar.org/paper/aec822f56ff1794c32f5826cfb266f9b477f4df8\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Oh\"},{\"authorId\":null,\"name\":\"X. Guo\"},{\"authorId\":null,\"name\":\"H. Lee\"},{\"authorId\":null,\"name\":\"S. Singh\"},{\"authorId\":null,\"name\":\"R. Lewis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Actionconditional video prediction using deep networks in atari game\",\"url\":\"\",\"venue\":\"In NIPS,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Gorban\"},{\"authorId\":null,\"name\":\"H Indrees\"},{\"authorId\":null,\"name\":\"Y Jiang\"},{\"authorId\":null,\"name\":\"A R Zamir\"},{\"authorId\":null,\"name\":\"I Laptev\"},{\"authorId\":null,\"name\":\"M Shah\"},{\"authorId\":null,\"name\":\"R Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Thumos challenge: Action recognition with a large number of classes. http: //wwwthumos\",\"url\":\"\",\"venue\":\"Thumos challenge: Action recognition with a large number of classes. http: //wwwthumos\",\"year\":2015},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Gorban\"},{\"authorId\":null,\"name\":\"H. Indrees\"},{\"authorId\":null,\"name\":\"Y. Jiang\"},{\"authorId\":null,\"name\":\"A. R. Zamir\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Thumos challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"http: //wwwthumos.info/,\",\"year\":2015}],\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Vanish (computer science)\",\"topicId\":\"3779038\",\"url\":\"https://www.semanticscholar.org/topic/3779038\"},{\"topic\":\"Temporal logic\",\"topicId\":\"480\",\"url\":\"https://www.semanticscholar.org/topic/480\"},{\"topic\":\"Softmax function\",\"topicId\":\"966784\",\"url\":\"https://www.semanticscholar.org/topic/966784\"},{\"topic\":\"Interrupt descriptor table\",\"topicId\":\"1799979\",\"url\":\"https://www.semanticscholar.org/topic/1799979\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"