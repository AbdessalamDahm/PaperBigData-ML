"{\"abstract\":\"We propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image, and which can also comprehend or interpret such an expression to infer which object is being described. We show that our method outperforms previous methods that generate descriptions of objects without taking into account other potentially ambiguous objects in the scene. Our model is inspired by recent successes of deep learning methods for image captioning, but while image captioning is difficult to evaluate, our task allows for easy objective evaluation. We also present a new large-scale dataset for referring expressions, based on MSCOCO. We have released the dataset and a toolbox for visualization and evaluation, see https://github.com/ mjhucla/Google_Refexp_toolbox.\",\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\",\"url\":\"https://www.semanticscholar.org/author/36010601\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\",\"url\":\"https://www.semanticscholar.org/author/1808244\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\",\"url\":\"https://www.semanticscholar.org/author/1726415\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\",\"url\":\"https://www.semanticscholar.org/author/3317152\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\",\"url\":\"https://www.semanticscholar.org/author/145081362\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\",\"url\":\"https://www.semanticscholar.org/author/1702318\"}],\"citationVelocity\":99,\"citations\":[{\"arxivId\":\"2007.09877\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"title\":\"Graph Neural Network for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1612.01452\",\"authors\":[{\"authorId\":\"49675890\",\"name\":\"M. Simon\"},{\"authorId\":\"1679449\",\"name\":\"Erik Rodner\"},{\"authorId\":\"1728382\",\"name\":\"Joachim Denzler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d7f57f683be52ccf8d24ce21e72e2b44514511\",\"title\":\"ImageNet pre-trained models with batch normalization\",\"url\":\"https://www.semanticscholar.org/paper/a6d7f57f683be52ccf8d24ce21e72e2b44514511\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50818308\",\"name\":\"Tingxiao Yang\"},{\"authorId\":\"31786421\",\"name\":\"Yuichiro Yoshimura\"},{\"authorId\":\"150913063\",\"name\":\"Akira Morita\"},{\"authorId\":\"153169721\",\"name\":\"Takao Namiki\"},{\"authorId\":\"144397094\",\"name\":\"T. Nakaguchi\"}],\"doi\":\"10.1007/s10015-019-00547-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"263f0f7360a6b7542d90d23498ca4688217addbb\",\"title\":\"Synergistic attention U-Net for sublingual vein segmentation\",\"url\":\"https://www.semanticscholar.org/paper/263f0f7360a6b7542d90d23498ca4688217addbb\",\"venue\":\"Artificial Life and Robotics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36062926\",\"name\":\"Moshiko Raboh\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a481573eed17b33999fe22a367cd0b5095e40ea7\",\"title\":\"Learning Latent Scene-Graph Representations for Referring Relationships\",\"url\":\"https://www.semanticscholar.org/paper/a481573eed17b33999fe22a367cd0b5095e40ea7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.01629\",\"authors\":[{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"47417383\",\"name\":\"Dongyang Liu\"},{\"authorId\":\"144462039\",\"name\":\"H. Li\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413905\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3a08274632296de2f98d11180ce3e2b06776a3a0\",\"title\":\"Give Me Something to Eat: Referring Expression Comprehension with Commonsense Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3a08274632296de2f98d11180ce3e2b06776a3a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.09562\",\"authors\":[{\"authorId\":\"38107189\",\"name\":\"F. Baldassarre\"},{\"authorId\":\"117538614\",\"name\":\"K. Smith\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"2622491\",\"name\":\"H. Azizpour\"}],\"doi\":\"10.1007/978-3-030-58604-1_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18b2ad26b2859be7c4e00268f16514e4a723fdd1\",\"title\":\"Explanation-based Weakly-supervised Learning of Visual Relations with Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/18b2ad26b2859be7c4e00268f16514e4a723fdd1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1711.08664\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"49070447\",\"name\":\"Y. Chen\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cfbaa9af05f0eea03ac7c28cc0e588687cd8343\",\"title\":\"Self-view Grounding Given a Narrated 360{\\\\deg} Video\",\"url\":\"https://www.semanticscholar.org/paper/1cfbaa9af05f0eea03ac7c28cc0e588687cd8343\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112897627\",\"name\":\"Taichi Iki\"},{\"authorId\":\"1705519\",\"name\":\"A. Aizawa\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.420\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d94ebc1c92870d6d21a2ad4a2402be86ecf36309\",\"title\":\"Language-Conditioned Feature Pyramids for Visual Selection Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d94ebc1c92870d6d21a2ad4a2402be86ecf36309\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121433901\",\"name\":\"Xiaoqian Guo\"},{\"authorId\":\"50080038\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3394171.3413567\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1870b836377d41de6280f6291089d66ee8cf8e61\",\"title\":\"Expressional Region Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/1870b836377d41de6280f6291089d66ee8cf8e61\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144813679\",\"name\":\"L. Hao\"},{\"authorId\":\"48557329\",\"name\":\"L. Hou\"},{\"authorId\":\"9254183\",\"name\":\"Y. Song\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"143670111\",\"name\":\"J. Xue\"}],\"doi\":\"10.1145/3372278.3390712\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8631b8c4d14b42767deaeae0cad13d331d505e26\",\"title\":\"A Lightweight Gated Global Module for Global Context Modeling in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8631b8c4d14b42767deaeae0cad13d331d505e26\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1604.00562\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/D16-1125\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"92dbc1509b5641946cc8b524610cb6803d6ee5f6\",\"title\":\"Reasoning about Pragmatics with Neural Listeners and Speakers\",\"url\":\"https://www.semanticscholar.org/paper/92dbc1509b5641946cc8b524610cb6803d6ee5f6\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/W18-6906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9608e053896874d4f7d62f744057cf7105c5c90\",\"title\":\"Being data-driven is not enough: Revisiting interactive instruction giving as a challenge for NLG\",\"url\":\"https://www.semanticscholar.org/paper/b9608e053896874d4f7d62f744057cf7105c5c90\",\"venue\":\"HRI 2018\",\"year\":2018},{\"arxivId\":\"2009.03949\",\"authors\":[{\"authorId\":\"1699605396\",\"name\":\"Zeyu Wang\"},{\"authorId\":\"114200472\",\"name\":\"Berthy Feng\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":\"10.1007/978-3-030-58571-6_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81be56a5783552d5b32463b392ff0499dd86a5ab\",\"title\":\"Towards Unique and Informative Captioning of Images\",\"url\":\"https://www.semanticscholar.org/paper/81be56a5783552d5b32463b392ff0499dd86a5ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405506607\",\"name\":\"C. Hern\\u00e1ndez-Castro\"},{\"authorId\":\"33128766\",\"name\":\"S. Li\"},{\"authorId\":\"1398553629\",\"name\":\"M. Rodr\\u00edguez-Moreno\"}],\"doi\":\"10.1016/j.cose.2020.101758\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fef80df0bedfb0ce5f6bbd70862bf11ba84b3ea5\",\"title\":\"All about uncertainties and traps: Statistical oracle-based attacks on a new CAPTCHA protection against oracle attacks\",\"url\":\"https://www.semanticscholar.org/paper/fef80df0bedfb0ce5f6bbd70862bf11ba84b3ea5\",\"venue\":\"Comput. Secur.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150323937\",\"name\":\"Tapiwanashe Miranda Sanyanga\"},{\"authorId\":\"150205312\",\"name\":\"Munyaradzi Sydney Chinzvende\"},{\"authorId\":\"67213071\",\"name\":\"T. D. Kavu\"},{\"authorId\":\"123471961\",\"name\":\"J. Batani\"}],\"doi\":\"10.4018/IJICTRAME.2019070102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddc529c5d2d1c340907faf0724a2ec7843d54407\",\"title\":\"Searching Objects in a Video Footage: Dropping Frames and Object Detection Approach\",\"url\":\"https://www.semanticscholar.org/paper/ddc529c5d2d1c340907faf0724a2ec7843d54407\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1904.07318\",\"authors\":[{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/W19-0424\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d4dd7fe39504d9cfcab86038a9a1dceb9218368\",\"title\":\"Natural Language Semantics With Pictures: Some Language & Vision Datasets and Potential Uses for Computational Semantics\",\"url\":\"https://www.semanticscholar.org/paper/1d4dd7fe39504d9cfcab86038a9a1dceb9218368\",\"venue\":\"IWCS\",\"year\":2019},{\"arxivId\":\"2007.10736\",\"authors\":[{\"authorId\":\"50509045\",\"name\":\"F. Henkel\"},{\"authorId\":\"2135493\",\"name\":\"Rainer Kelz\"},{\"authorId\":\"145964711\",\"name\":\"G. Widmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"286b9a4f7b6f5ddc059e3f8d924de9bf48848e9d\",\"title\":\"Learning to Read and Follow Music in Complete Score Sheet Images\",\"url\":\"https://www.semanticscholar.org/paper/286b9a4f7b6f5ddc059e3f8d924de9bf48848e9d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"145042856\",\"name\":\"J. Xiong\"},{\"authorId\":\"143668320\",\"name\":\"W. Hwu\"},{\"authorId\":\"1793941\",\"name\":\"M. N. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fedae3bccf86052ed725e5925bb4ef47f9389c1\",\"title\":\"Word Prior Detection Segmentation Input \\\" The left guy \\\" Image : Query : a guy left the youth Energy\",\"url\":\"https://www.semanticscholar.org/paper/5fedae3bccf86052ed725e5925bb4ef47f9389c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P17-1023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709f43392b4a30519f5f87630a573b0a51d40537\",\"title\":\"Obtaining referential word meanings from visual and distributional information: Experiments on object naming\",\"url\":\"https://www.semanticscholar.org/paper/709f43392b4a30519f5f87630a573b0a51d40537\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.01045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1801.08186\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00142\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"title\":\"MAttNet: Modular Attention Network for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.04745\",\"authors\":[{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"143962643\",\"name\":\"Zhi Liu\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/CVPR.2019.01075\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69455376f5ad52cac5b72d5e8c6cf03fb466b55c\",\"title\":\"Cross-Modal Self-Attention Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/69455376f5ad52cac5b72d5e8c6cf03fb466b55c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.02559\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"153188107\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-01234-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8befcd91c24038e5c26df0238d26e2311b21719a\",\"title\":\"A Joint Sequence Fusion Model for Video Question Answering and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8befcd91c24038e5c26df0238d26e2311b21719a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2001.05994\",\"authors\":[{\"authorId\":\"48228222\",\"name\":\"Mycal Tucker\"},{\"authorId\":\"13086560\",\"name\":\"Y. Zhou\"},{\"authorId\":\"143873973\",\"name\":\"Julie Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0193b2fbceb581f5164d60731e775332cb8658f7\",\"title\":\"Adversarially Guided Self-Play for Adopting Social Conventions\",\"url\":\"https://www.semanticscholar.org/paper/0193b2fbceb581f5164d60731e775332cb8658f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.00515\",\"authors\":[{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1977587202\",\"name\":\"Sansi Yu\"},{\"authorId\":\"1977074324\",\"name\":\"Faxi Zhang\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"}],\"doi\":\"10.1007/978-3-030-58607-2_4\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b907a8d6c6fc5a0c3a8857a9db4225dc922397ad\",\"title\":\"Linguistic Structure Guided Context Modeling for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b907a8d6c6fc5a0c3a8857a9db4225dc922397ad\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.05049\",\"authors\":[{\"authorId\":\"2008154246\",\"name\":\"Zongheng Tang\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2103483\",\"name\":\"X. Jin\"},{\"authorId\":\"2292508\",\"name\":\"Hongxu Jiang\"},{\"authorId\":\"1410184682\",\"name\":\"Qian Yu\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"74c30c601d5de21af098389abf7be0f8261e6c13\",\"title\":\"Human-centric Spatio-Temporal Video Grounding With Visual Transformers\",\"url\":\"https://www.semanticscholar.org/paper/74c30c601d5de21af098389abf7be0f8261e6c13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.07280\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"12139064\",\"name\":\"Jake Bruce\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd9642470ff8c2089427f7a6392cd17d213a334\",\"title\":\"Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\",\"url\":\"https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"40894329\",\"name\":\"Stephan Alaniz\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-98131-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86de19e783d717c5db77f96f707613c27bde2915\",\"title\":\"Generating Post-Hoc Rationales of Deep Visual Classification Decisions\",\"url\":\"https://www.semanticscholar.org/paper/86de19e783d717c5db77f96f707613c27bde2915\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51177608\",\"name\":\"Lars Kunze\"},{\"authorId\":\"145729418\",\"name\":\"Tom Williams\"},{\"authorId\":\"143939898\",\"name\":\"Nick Hawes\"},{\"authorId\":\"1793014\",\"name\":\"Matthias Scheutz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40c194346a562e4a94ec57f4f380dd4cd39f5dc7\",\"title\":\"Spatial Referring Expression Generation for HRI: Algorithms and Evaluation Framework\",\"url\":\"https://www.semanticscholar.org/paper/40c194346a562e4a94ec57f4f380dd4cd39f5dc7\",\"venue\":\"AAAI Fall Symposia\",\"year\":2017},{\"arxivId\":\"1906.02497\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"}],\"doi\":\"10.1145/3331184.3331235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb53803897d3df3e1f43a43a753ee88a64517c47\",\"title\":\"Cross-Modal Interaction Networks for Query-Based Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb53803897d3df3e1f43a43a753ee88a64517c47\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4445312\",\"name\":\"Joshua T. Abbott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dab73c94a0d0958343ff68f023ecd47a61998c3e\",\"title\":\"Statistical models of learning and using semantic representations\",\"url\":\"https://www.semanticscholar.org/paper/dab73c94a0d0958343ff68f023ecd47a61998c3e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1903.07669\",\"authors\":[{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":\"10.1109/CVPR.2019.00430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e973b927ec80a6d7db9835a7378c7c9d25fd35e3\",\"title\":\"Neural Sequential Phrase Grounding (SeqGROUND)\",\"url\":\"https://www.semanticscholar.org/paper/e973b927ec80a6d7db9835a7378c7c9d25fd35e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152673712\",\"name\":\"Youming Gao\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"47362529\",\"name\":\"T. Xu\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-30508-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"title\":\"Referring Expression Comprehension via Co-attention and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100867099\",\"name\":\"N. Reamer\"}],\"doi\":\"10.1142/9789813231634_0003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a2d9da0e514341930edf457a3494f17bbce8452\",\"title\":\"For my parents\",\"url\":\"https://www.semanticscholar.org/paper/4a2d9da0e514341930edf457a3494f17bbce8452\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1608.00525\",\"authors\":[{\"authorId\":\"3081378\",\"name\":\"Varun K. Nagaraja\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46493-0_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"title\":\"Modeling Context Between Objects for Referring Expression Understanding\",\"url\":\"https://www.semanticscholar.org/paper/86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1907.04983\",\"authors\":[{\"authorId\":\"145746402\",\"name\":\"X. Jin\"},{\"authorId\":\"2688093\",\"name\":\"Le Wu\"},{\"authorId\":\"143681906\",\"name\":\"Geng Zhao\"},{\"authorId\":\"47057319\",\"name\":\"X. Li\"},{\"authorId\":\"1391223326\",\"name\":\"Xiaokun Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"145314008\",\"name\":\"Bin Zhou\"},{\"authorId\":\"51197465\",\"name\":\"Xinghui Zhou\"}],\"doi\":\"10.1145/3343031.3350970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e79423b5e216151ce0cdf615a7098666d9d9c07e\",\"title\":\"Aesthetic Attributes Assessment of Images\",\"url\":\"https://www.semanticscholar.org/paper/e79423b5e216151ce0cdf615a7098666d9d9c07e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49780999\",\"name\":\"Y. Zhu\"},{\"authorId\":\"82741945\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d5f6ca40afd27fd49c72930a87abd8b9fc4c0b1\",\"title\":\"TOWARDS ACTIVE AND INTERACTIVE VISUAL LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/5d5f6ca40afd27fd49c72930a87abd8b9fc4c0b1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"title\":\"Refer360$^\\\\circ$: A Referring Expression Recognition Dataset in 360$^\\\\circ$ Images\",\"url\":\"https://www.semanticscholar.org/paper/6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.03800\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/WACV.2018.00206\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d6a4a34829b3b55497210ddbe88ad63ff801faae\",\"title\":\"Object Referring in Visual Scene with Spoken Language\",\"url\":\"https://www.semanticscholar.org/paper/d6a4a34829b3b55497210ddbe88ad63ff801faae\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2005.01655\",\"authors\":[{\"authorId\":\"2947115\",\"name\":\"Arjun Reddy Akula\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1403907739\",\"name\":\"Yaser Al-Onaizan\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"}],\"doi\":\"10.18653/v1/2020.acl-main.586\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"title\":\"Words aren't enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"24068173\",\"name\":\"Mario Giulianelli\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"153915609\",\"name\":\"Arabella Sinclair\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35490092cd5295a4552a6b46b0ec8372beb87089\",\"title\":\"Refer, Reuse, Reduce: Grounding Subsequent References in Visual and Conversational Contexts\",\"url\":\"https://www.semanticscholar.org/paper/35490092cd5295a4552a6b46b0ec8372beb87089\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.02206\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"47621053\",\"name\":\"A. Gholami\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"title\":\"Scan2Cap: Context-aware Dense Captioning in RGB-D Scans\",\"url\":\"https://www.semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01496\",\"authors\":[{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dda3340edb94d30084315768934262f25026fed1\",\"title\":\"Explaining Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dda3340edb94d30084315768934262f25026fed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.08814\",\"authors\":[{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"72347323\",\"name\":\"X. Yang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-030-58539-6_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"13ee363f71e07112210ac2ff27d46625f6f8edab\",\"title\":\"Visual Relation Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/13ee363f71e07112210ac2ff27d46625f6f8edab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175864710def9b3e8b42e4613856d0b840c37615\",\"title\":\"Cross-modal Moment Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/175864710def9b3e8b42e4613856d0b840c37615\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1707.09593\",\"authors\":[{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"48596202\",\"name\":\"Hang Song\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2017.124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ed9de4de4aa3a0d4d50b844fa06cf12d522b53d\",\"title\":\"Discover and Learn New Objects from Documentaries\",\"url\":\"https://www.semanticscholar.org/paper/8ed9de4de4aa3a0d4d50b844fa06cf12d522b53d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1902.04213\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"49560222\",\"name\":\"Guanghui Xu\"},{\"authorId\":\"153009573\",\"name\":\"Z. Yu\"},{\"authorId\":null,\"name\":\"Yanwu Xu\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d8b54f188af9e71f5790f10c406d888ea006387d\",\"title\":\"You Only Look & Listen Once: Towards Fast and Accurate Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/d8b54f188af9e71f5790f10c406d888ea006387d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.10165\",\"authors\":[{\"authorId\":\"50981270\",\"name\":\"Nevan Wichers\"},{\"authorId\":\"1395813836\",\"name\":\"Dilek Z. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"}],\"doi\":\"10.1109/SLT.2018.8639518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ceb15dfe33884ac38fa9ec0abb1e19ab090679\",\"title\":\"Resolving Referring Expressions in Images with Labeled Elements\",\"url\":\"https://www.semanticscholar.org/paper/04ceb15dfe33884ac38fa9ec0abb1e19ab090679\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40284693\",\"name\":\"Poorvi Bhargava\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"46557005\",\"name\":\"Hiroyuki Udagawa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"249ae4363b8c57ed0911c7c9080093613fcca09f\",\"title\":\"A Character-Based Model for Pragmatic Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/249ae4363b8c57ed0911c7c9080093613fcca09f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"},{\"authorId\":\"1403865699\",\"name\":\"Tania Bedrax-Weiss\"},{\"authorId\":\"146514666\",\"name\":\"Daphne Luong\"},{\"authorId\":\"144928136\",\"name\":\"S. Narayanan\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"152639054\",\"name\":\"F. Pereira\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"3827070\",\"name\":\"M. Tseng\"},{\"authorId\":\"153533808\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.18653/v1/W18-1406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab743387bb3dad8ef541d43698372d2e98b05c7c\",\"title\":\"Points, Paths, and Playscapes: Large-scale Spatial Language Understanding Tasks Set in the Real World\",\"url\":\"https://www.semanticscholar.org/paper/ab743387bb3dad8ef541d43698372d2e98b05c7c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/CVPR.2018.00808\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"title\":\"Visual Grounding via Accumulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1590802267\",\"name\":\"J. Kim\"},{\"authorId\":\"1580654340\",\"name\":\"Hanbin Ko\"},{\"authorId\":\"9095876\",\"name\":\"Jipeng Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9480a1a403f3c3e0be22e08e63716ef4d5b38217\",\"title\":\"CoNAN: A Complementary Neighboring-based Attention Network for Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/9480a1a403f3c3e0be22e08e63716ef4d5b38217\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1904.07165\",\"authors\":[{\"authorId\":\"9074985\",\"name\":\"Fethiye Irmak Dogan\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"39799707\",\"name\":\"Iolanda Leite\"}],\"doi\":\"10.1109/IROS40897.2019.8968510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"728ba42165658b04986f5bba992b422874df4364\",\"title\":\"Learning to Generate Unambiguous Spatial Referring Expressions for Real-World Environments\",\"url\":\"https://www.semanticscholar.org/paper/728ba42165658b04986f5bba992b422874df4364\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121104319\",\"name\":\"Rehab Alahmadi\"},{\"authorId\":\"1695172\",\"name\":\"C. H. Park\"},{\"authorId\":\"36266636\",\"name\":\"J. Hahn\"}],\"doi\":\"10.1117/12.2523174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"title\":\"Sequence-to-sequence image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"venue\":\"International Conference on Machine Vision\",\"year\":2019},{\"arxivId\":\"1801.01582\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00434\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"title\":\"Object Referring in Videos with Language and Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9074985\",\"name\":\"Fethiye Irmak Dogan\"},{\"authorId\":\"1603546763\",\"name\":\"Sarah Gillet\"},{\"authorId\":\"1486057708\",\"name\":\"E. J. Carter\"},{\"authorId\":\"39799707\",\"name\":\"I. Leite\"}],\"doi\":\"10.1016/J.ROBOT.2020.103654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd1cd2de92afa6ddc8c122d3826091980454df4c\",\"title\":\"The impact of adding perspective-taking to spatial referencing during human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/dd1cd2de92afa6ddc8c122d3826091980454df4c\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2020},{\"arxivId\":\"1710.06280\",\"authors\":[{\"authorId\":\"1952555\",\"name\":\"J. Hatori\"},{\"authorId\":\"144142812\",\"name\":\"Yuta Kikuchi\"},{\"authorId\":\"3456592\",\"name\":\"S. Kobayashi\"},{\"authorId\":\"50608286\",\"name\":\"K. Takahashi\"},{\"authorId\":\"3229899\",\"name\":\"Yuta Tsuboi\"},{\"authorId\":\"40939427\",\"name\":\"Y. Unno\"},{\"authorId\":\"48617753\",\"name\":\"W. Ko\"},{\"authorId\":\"145924452\",\"name\":\"Jethro Tan\"}],\"doi\":\"10.1109/ICRA.2018.8460699\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f196a79c5e4b570013e4aa031cdd0fc0c98fc07d\",\"title\":\"Interactively Picking Real-World Objects with Unconstrained Spoken Language Instructions\",\"url\":\"https://www.semanticscholar.org/paper/f196a79c5e4b570013e4aa031cdd0fc0c98fc07d\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"1993659018\",\"name\":\"Xinjian Gao\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3394171.3413610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"title\":\"Weakly-Supervised Video Object Grounding by Exploring Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37438942\",\"name\":\"Masayasu Muraoka\"},{\"authorId\":\"2261082\",\"name\":\"Tetsuya Nasukawa\"},{\"authorId\":\"2993880\",\"name\":\"R. H. Putra\"},{\"authorId\":\"49223443\",\"name\":\"B. Bhattacharjee\"}],\"doi\":\"10.1145/3366423.3380006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b8aabbd65b77aa00db4ce208617441c9e1cd995\",\"title\":\"Visual Concept Naming: Discovering Well-Recognized Textual Expressions of Visual Concepts\",\"url\":\"https://www.semanticscholar.org/paper/5b8aabbd65b77aa00db4ce208617441c9e1cd995\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ca25b95fa13ece1d131c5a0df427e7c1c584da4\",\"title\":\"Following Formulaic Map Instructions in a Street Simulation Environment\",\"url\":\"https://www.semanticscholar.org/paper/8ca25b95fa13ece1d131c5a0df427e7c1c584da4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.00367\",\"authors\":[{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.7275/cprc-8x17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3e528eccb8a2452ac5fd1f9ccd8880fd965bbb5\",\"title\":\"An Incremental Iterated Response Model of Pragmatics\",\"url\":\"https://www.semanticscholar.org/paper/f3e528eccb8a2452ac5fd1f9ccd8880fd965bbb5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1707.05720\",\"authors\":[{\"authorId\":\"33516562\",\"name\":\"Mohit Shridhar\"},{\"authorId\":\"145463096\",\"name\":\"D. Hsu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff84ec1dab06135b2d8a99b441d04e15259090a1\",\"title\":\"Grounding Spatio-Semantic Referring Expressions for Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ff84ec1dab06135b2d8a99b441d04e15259090a1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453279481\",\"name\":\"Gonzalo Vaca Castano\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a851ad57feec3140b574c85851c436dacad8e70\",\"title\":\"Understanding images and videos using context\",\"url\":\"https://www.semanticscholar.org/paper/4a851ad57feec3140b574c85851c436dacad8e70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46671592\",\"name\":\"Y. Xian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e11ad2a6c18112c13e9e65d64ef85cb1ff4883d0\",\"title\":\"Exploring the Internal Statistics: Single Image Super-Resolution, Completion and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e11ad2a6c18112c13e9e65d64ef85cb1ff4883d0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2621738\",\"name\":\"Xuejian Rong\"},{\"authorId\":\"40263913\",\"name\":\"Chucai Yi\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/CVPR.2017.349\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e7b716a0e5e79b1888a3ff19b701aed34965282\",\"title\":\"Unambiguous Text Localization and Retrieval for Cluttered Scenes\",\"url\":\"https://www.semanticscholar.org/paper/2e7b716a0e5e79b1888a3ff19b701aed34965282\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1710.02534\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"83d66c1f808962536a68418587b691f30221c5a1\",\"title\":\"Contrastive Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/83d66c1f808962536a68418587b691f30221c5a1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1606.08777\",\"authors\":[{\"authorId\":\"1807810\",\"name\":\"Gemma Boleda\"},{\"authorId\":\"1708581\",\"name\":\"Sebastian Pad\\u00f3\"},{\"authorId\":\"152259557\",\"name\":\"Marco Baroni\"}],\"doi\":\"10.1007/978-3-319-77113-7_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f92791bc26449bddeaf9d72a9729562d8a24d63\",\"title\":\"\\\"Show me the cup\\\": Reference with Continuous Representations\",\"url\":\"https://www.semanticscholar.org/paper/2f92791bc26449bddeaf9d72a9729562d8a24d63\",\"venue\":\"CICLing\",\"year\":2017},{\"arxivId\":\"1903.11649\",\"authors\":[{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/ICCV.2019.00269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a89cd9056c0fb037d659215b121686ff3b454fd5\",\"title\":\"Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment\",\"url\":\"https://www.semanticscholar.org/paper/a89cd9056c0fb037d659215b121686ff3b454fd5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.08006\",\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-20870-7_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da30d00c9490768e7726725482e3ecbd102f18cd\",\"title\":\"Video Object Segmentation with Language Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/da30d00c9490768e7726725482e3ecbd102f18cd\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2003.08027\",\"authors\":[{\"authorId\":\"39024831\",\"name\":\"Shuai Wang\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40912079\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102714\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b65ffe7ada51e34a0a8e3e46b90d71099141a8e\",\"title\":\"Mutatt: Visual-Textual Mutual Guidance For Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3b65ffe7ada51e34a0a8e3e46b90d71099141a8e\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2001.11561\",\"authors\":[{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"143962644\",\"name\":\"Zhi Liu\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/TMM.2020.2971171\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"28bd4e070c12b421db0f7b32438142038b82af53\",\"title\":\"Dual Convolutional LSTM Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/28bd4e070c12b421db0f7b32438142038b82af53\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"},{\"authorId\":\"144538257\",\"name\":\"Y. Weiss\"}],\"doi\":\"10.1007/978-3-030-01258-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ecf589ab160976d283d751a8dc407b6cdaff67b0\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/ecf589ab160976d283d751a8dc407b6cdaff67b0\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.01542\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf8d0386cabafee915e579b54902d2418e0716ad\",\"title\":\"Natural Vocabulary Emerges from Free-Form Annotations\",\"url\":\"https://www.semanticscholar.org/paper/cf8d0386cabafee915e579b54902d2418e0716ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Vaswani\"},{\"authorId\":null,\"name\":\"Noam Shazeer\"},{\"authorId\":null,\"name\":\"Niki Parmar\"},{\"authorId\":null,\"name\":\"Jakob\"},{\"authorId\":null,\"name\":\"Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"title\":\"Words aren\\u2019t enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.02925\",\"authors\":[{\"authorId\":\"22199114\",\"name\":\"Panos Achlioptas\"},{\"authorId\":\"5586582\",\"name\":\"Judy Fan\"},{\"authorId\":\"8932668\",\"name\":\"Robert X. D. Hawkins\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1109/ICCV.2019.00903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9018a815a8a43ef8e27a9af55abdf6a270d7bc28\",\"title\":\"Shapeglot: Learning Language for Shape Differentiation\",\"url\":\"https://www.semanticscholar.org/paper/9018a815a8a43ef8e27a9af55abdf6a270d7bc28\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3031950\",\"name\":\"Cecilia Mauceri\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"},{\"authorId\":\"40517238\",\"name\":\"C. Heckman\"}],\"doi\":\"10.1109/ICCVW.2019.00236\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ffddf6accc2c9696d6dbdf02dcc939bc1f81d8d\",\"title\":\"SUN-Spot: An RGB-D Dataset With Spatial Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/4ffddf6accc2c9696d6dbdf02dcc939bc1f81d8d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34351565\",\"name\":\"Mingyang Qian\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"50081215\",\"name\":\"L. Zhang\"},{\"authorId\":\"40117581\",\"name\":\"Mengyang Feng\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b499dba91a612ae7bd28e77fa4230cd965e1f10\",\"title\":\"Language-aware weak supervision for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/3b499dba91a612ae7bd28e77fa4230cd965e1f10\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123386644\",\"name\":\"R. Manjunath\"},{\"authorId\":\"1646474224\",\"name\":\"B.N Chandrashekar\"},{\"authorId\":\"1646579981\",\"name\":\"B. N. Vinutha\"},{\"authorId\":\"1646599110\",\"name\":\"Rahul Arya\"},{\"authorId\":\"49926238\",\"name\":\"Arindam Chatterjee\"}],\"doi\":\"10.1109/GHCI47972.2019.9071811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26a3f8d7fce998fa150c016a57126f434ffb0e74\",\"title\":\"Unified framework of Explainable AI to enhance classifier performance\",\"url\":\"https://www.semanticscholar.org/paper/26a3f8d7fce998fa150c016a57126f434ffb0e74\",\"venue\":\"2019 Grace Hopper Celebration India (GHCI)\",\"year\":2019},{\"arxivId\":\"2011.02655\",\"authors\":[{\"authorId\":\"47297245\",\"name\":\"H. Zhu\"},{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"29962444\",\"name\":\"Zhao-Heng Zheng\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1cb961c8bea36d5faf3c6011f15dc23832a3e8fc\",\"title\":\"Utilizing Every Image Object for Semi-supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/1cb961c8bea36d5faf3c6011f15dc23832a3e8fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"46246806\",\"name\":\"Chia-Wen Lin\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414006\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"24f2a18c54ab017d00ce1f714600b6bede6c0820\",\"title\":\"Cascade Grouped Attention Network for Referring Expression Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/24f2a18c54ab017d00ce1f714600b6bede6c0820\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805489\",\"name\":\"Z. Zhang\"},{\"authorId\":\"50144812\",\"name\":\"Z. Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725989041b70ce21c5e20d90037691a59a483257\",\"title\":\"Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/725989041b70ce21c5e20d90037691a59a483257\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2008.08977\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"title\":\"Generating Adjacency Matrix for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.10200\",\"authors\":[{\"authorId\":\"36062926\",\"name\":\"Moshiko Raboh\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":\"10.1109/WACV45572.2020.9093297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c16855109b9b91999493cb61bb92f5d4bd944019\",\"title\":\"Differentiable Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/c16855109b9b91999493cb61bb92f5d4bd944019\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Elizabeth Coppock\"},{\"authorId\":null,\"name\":\"Danielle Dionne\"},{\"authorId\":\"1994754478\",\"name\":\"Nathanial Graham\"},{\"authorId\":\"1994755542\",\"name\":\"Elias Ganem\"},{\"authorId\":\"1957250044\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"35025843\",\"name\":\"S. Lin\"},{\"authorId\":\"49663231\",\"name\":\"Wenxing Liu\"},{\"authorId\":null,\"name\":\"Derry Wijaya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4769896d37963f4609c394736184e92b6d82fcb\",\"title\":\"Informativity in Image Captions vs. Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/d4769896d37963f4609c394736184e92b6d82fcb\",\"venue\":\"PAM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5301833\",\"name\":\"Sijia Chen\"},{\"authorId\":\"144977497\",\"name\":\"B. Song\"},{\"authorId\":\"51174778\",\"name\":\"L. Fan\"},{\"authorId\":\"144335971\",\"name\":\"Xiaojiang Du\"},{\"authorId\":\"145837053\",\"name\":\"M. Guizani\"}],\"doi\":\"10.1109/TCCN.2019.2893360\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bb220d21f029d786154ba61482c6f92ed8cbe29\",\"title\":\"Multi-Modal Data Semantic Localization With Relationship Dependencies for Efficient Signal Processing in EH CRNs\",\"url\":\"https://www.semanticscholar.org/paper/6bb220d21f029d786154ba61482c6f92ed8cbe29\",\"venue\":\"IEEE Transactions on Cognitive Communications and Networking\",\"year\":2019},{\"arxivId\":\"1808.10584\",\"authors\":[{\"authorId\":\"2006291\",\"name\":\"Harsh Jhamtani\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"}],\"doi\":\"10.18653/v1/D18-1436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7062b5de5fddb298823cf8969c7dfa6165ea933e\",\"title\":\"Learning to Describe Differences Between Pairs of Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/7062b5de5fddb298823cf8969c7dfa6165ea933e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48332333\",\"name\":\"Shuang Qiu\"},{\"authorId\":\"152621482\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/TMM.2019.2942480\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"863ce99910dad0efa42385e8a3bcbeb1f400acfb\",\"title\":\"Referring Image Segmentation by Generative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/863ce99910dad0efa42385e8a3bcbeb1f400acfb\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1811.12104\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"143973868\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"title\":\"Towards Human-Friendly Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2003.10606\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR42600.2020.01043\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"title\":\"Video Object Grounding Using Semantic Roles in Language Description\",\"url\":\"https://www.semanticscholar.org/paper/70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2003.12058\",\"authors\":[{\"authorId\":\"4055152\",\"name\":\"Sarah Pratt\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"20745881\",\"name\":\"Luca Weihs\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1007/978-3-030-58548-8_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc261c0efb5f9ce82581932d1440630b861fb85f\",\"title\":\"Grounded Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc261c0efb5f9ce82581932d1440630b861fb85f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.10796\",\"authors\":[{\"authorId\":\"4868335\",\"name\":\"J. Park\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1007/978-3-030-58558-7_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aacd623a46adc6a03c925fe3ac007c271c9c6ab\",\"title\":\"VisualCOMET: Reasoning About the Dynamic Context of a Still Image\",\"url\":\"https://www.semanticscholar.org/paper/4aacd623a46adc6a03c925fe3ac007c271c9c6ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.04554\",\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"24068173\",\"name\":\"Mario Giulianelli\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"153915609\",\"name\":\"Arabella Sinclair\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60eedf4faa04dd30f8c5769e0831268133549eb8\",\"title\":\"Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts\",\"url\":\"https://www.semanticscholar.org/paper/60eedf4faa04dd30f8c5769e0831268133549eb8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"48625377\",\"name\":\"Weiming Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"81436348\",\"name\":\"Q. Wang\"},{\"authorId\":\"46392484\",\"name\":\"Wooshik Kim\"},{\"authorId\":\"48836299\",\"name\":\"Sunghoon Hong\"}],\"doi\":\"10.1145/3343031.3351063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dbc17138e7b610214359bb1659a30e01d183482\",\"title\":\"Referring Expression Comprehension with Semantic Visual Relationship and Word Mapping\",\"url\":\"https://www.semanticscholar.org/paper/4dbc17138e7b610214359bb1659a30e01d183482\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2010.00514\",\"authors\":[{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"},{\"authorId\":\"1776665\",\"name\":\"Luoqi Liu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"}],\"doi\":\"10.1109/CVPR42600.2020.01050\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"66566337664bee69915d3a46e0c5b66b15a8f5b5\",\"title\":\"Referring Image Segmentation via Cross-Modal Progressive Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/66566337664bee69915d3a46e0c5b66b15a8f5b5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a645bcd029cc5ce21b973146f21a9655047cc96\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Linguistic Cues\",\"url\":\"https://www.semanticscholar.org/paper/1a645bcd029cc5ce21b973146f21a9655047cc96\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1909.05010\",\"authors\":[{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6897\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"title\":\"Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47988382\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1007/978-3-030-60633-6_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e64cbc4818b30e32f7068d2454a365a785919ab\",\"title\":\"Global Context Enhanced Multi-modal Fusion for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2e64cbc4818b30e32f7068d2454a365a785919ab\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"37414303\",\"name\":\"Cheolho Han\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"32849162\",\"name\":\"W. Kang\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.5626/JOK.2018.45.1.30\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"955e3ee03c846a364cae3c734cc55874c90ce94d\",\"title\":\"Analyzing and Solving GuessWhat\",\"url\":\"https://www.semanticscholar.org/paper/955e3ee03c846a364cae3c734cc55874c90ce94d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.04405\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2019.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dc698077cb178286c737484dcf67c5ab19314d0\",\"title\":\"Language-Conditioned Graph Networks for Relational Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2dc698077cb178286c737484dcf67c5ab19314d0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.07280\",\"authors\":[{\"authorId\":\"1472875852\",\"name\":\"Seanie Lee\"},{\"authorId\":\"4140588\",\"name\":\"D. Lee\"},{\"authorId\":\"35788904\",\"name\":\"Sung Ju Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e6756742dc2e0bac124801b5c65964abf652cf3\",\"title\":\"Contrastive Learning with Adversarial Perturbations for Conditional Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/0e6756742dc2e0bac124801b5c65964abf652cf3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.15124\",\"authors\":[{\"authorId\":\"83574123\",\"name\":\"Emanuele Bugliarello\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"title\":\"Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs\",\"url\":\"https://www.semanticscholar.org/paper/82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14451\",\"authors\":[{\"authorId\":\"21771052\",\"name\":\"Allen Nie\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c86523d500d636f453647385ddaa04085b5f1b\",\"title\":\"Pragmatic Issue-Sensitive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88c86523d500d636f453647385ddaa04085b5f1b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1701.03439\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2017.333\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b45e9a40313096abf530df3b98a1dfa1553f17b\",\"title\":\"Comprehension-Guided Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9b45e9a40313096abf530df3b98a1dfa1553f17b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"180d8e56484204c85477c93317b34f5352c40b76\",\"title\":\"Grounding, Justification, Adaptation: Towards Machines That Mean What They Say\",\"url\":\"https://www.semanticscholar.org/paper/180d8e56484204c85477c93317b34f5352c40b76\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1909.06273\",\"authors\":[{\"authorId\":\"153714898\",\"name\":\"M. Andrews\"},{\"authorId\":\"52214524\",\"name\":\"Y. K. Chia\"},{\"authorId\":\"115583560\",\"name\":\"Sam Witteveen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce7a6767ec5f99b8676c603ec24b3b65d47a9dd3\",\"title\":\"Scene Graph Parsing by Attention Graph\",\"url\":\"https://www.semanticscholar.org/paper/ce7a6767ec5f99b8676c603ec24b3b65d47a9dd3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.03478\",\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"51230543\",\"name\":\"G. Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"46246806\",\"name\":\"Chia-Wen Lin\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3165d8c9a3466ecac5f6e9dc7e61b65c62c1decb\",\"title\":\"A Real-time Global Inference Network for One-stage Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3165d8c9a3466ecac5f6e9dc7e61b65c62c1decb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.08813\",\"authors\":[{\"authorId\":\"51230543\",\"name\":\"G. Luo\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"2867893\",\"name\":\"Cheng-Lin Wu\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/cvpr42600.2020.01005\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d1bc83cc65d30e4619c49f53115012a209fd8c9\",\"title\":\"Multi-Task Collaborative Network for Joint Referring Expression Comprehension and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8d1bc83cc65d30e4619c49f53115012a209fd8c9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2913681\",\"name\":\"Stefanie Tellex\"},{\"authorId\":\"2646714\",\"name\":\"Nakul Gopalan\"},{\"authorId\":\"1387890355\",\"name\":\"H. Kress-Gazit\"},{\"authorId\":\"2674440\",\"name\":\"Cynthia Matuszek\"}],\"doi\":\"10.1146/annurev-control-101119-071628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc23dfb70e109dbe666b979f995e2779b96e1073\",\"title\":\"Robots That Use Language\",\"url\":\"https://www.semanticscholar.org/paper/bc23dfb70e109dbe666b979f995e2779b96e1073\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1510.02125\",\"authors\":[{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"2061232\",\"name\":\"C. Kennington\"}],\"doi\":\"10.18653/v1/P16-1115\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13a721dc8a7c774ca3feec3710212c809a28dd1d\",\"title\":\"Resolving References to Objects in Photographs using the Words-As-Classifiers Model\",\"url\":\"https://www.semanticscholar.org/paper/13a721dc8a7c774ca3feec3710212c809a28dd1d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1909.08164\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/ICCV.2019.00474\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6c8b8a2d61cdd9592faebb6aca262ec3a64e6d43\",\"title\":\"Dynamic Graph Attention for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/6c8b8a2d61cdd9592faebb6aca262ec3a64e6d43\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02225\",\"authors\":[{\"authorId\":\"27572284\",\"name\":\"E. Conser\"},{\"authorId\":\"32714395\",\"name\":\"Kennedy Hahn\"},{\"authorId\":\"94239933\",\"name\":\"Chandler M. Watson\"},{\"authorId\":\"144380037\",\"name\":\"Melanie Mitchell\"}],\"doi\":\"10.18653/v1/W19-1804\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7da62fe123c4a3c77b22c92b011285ec42dcba5c\",\"title\":\"Revisiting Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7da62fe123c4a3c77b22c92b011285ec42dcba5c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.08824\",\"authors\":[{\"authorId\":\"2419744\",\"name\":\"Aaron Walsman\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"119902504\",\"name\":\"Saadia Gabriel\"},{\"authorId\":\"31498163\",\"name\":\"Dipendra Kumar Misra\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"}],\"doi\":\"10.1109/IROS40897.2019.8968165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"299ab255f3d940a20891128dfa9e0736d74a936c\",\"title\":\"EARLY FUSION for Goal Directed Robotic Vision\",\"url\":\"https://www.semanticscholar.org/paper/299ab255f3d940a20891128dfa9e0736d74a936c\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"1901.00850\",\"authors\":[{\"authorId\":\"9326827\",\"name\":\"Runtao Liu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00431\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9695676deace8c05d4e95274b92f20ed1e97470c\",\"title\":\"CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9695676deace8c05d4e95274b92f20ed1e97470c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.11544\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"145587210\",\"name\":\"Nassir Navab\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1109/CVPR.2018.00892\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a334442b493501bb60a53dc3e689fc569965ad81\",\"title\":\"Guide Me: Interacting with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/a334442b493501bb60a53dc3e689fc569965ad81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438473\",\"name\":\"Max H. Quinn\"},{\"authorId\":\"27572284\",\"name\":\"E. Conser\"},{\"authorId\":\"38388831\",\"name\":\"J. M. Witte\"},{\"authorId\":\"144380037\",\"name\":\"Melanie Mitchell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58628e64e61bd2776a2a7258012eabe3c79ca90c\",\"title\":\"Active Grounding of Visual Situations\",\"url\":\"https://www.semanticscholar.org/paper/58628e64e61bd2776a2a7258012eabe3c79ca90c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1704.03162\",\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"2544590\",\"name\":\"Ali Elqursh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d674b540dcd968bc302ea4360df3f4e85e994b55\",\"title\":\"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d674b540dcd968bc302ea4360df3f4e85e994b55\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2461040\",\"name\":\"Roger P. G. van Gompel\"},{\"authorId\":\"47753345\",\"name\":\"Kees van Deemter\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"88729045\",\"name\":\"Rick Snoeren\"},{\"authorId\":\"1743666\",\"name\":\"E. Krahmer\"}],\"doi\":\"10.1037/rev0000138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0467d0798d3387675903a15cc94ece359daaab5e\",\"title\":\"Conceptualization in Reference Production: Probabilistic Modeling and Experimental Testing\",\"url\":\"https://www.semanticscholar.org/paper/0467d0798d3387675903a15cc94ece359daaab5e\",\"venue\":\"Psychological review\",\"year\":2019},{\"arxivId\":\"1712.01892\",\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2018.00437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"69d576ffe624f11fe4e84a03d4063856a5af838f\",\"title\":\"Grounding Referring Expressions in Images by Variational Context\",\"url\":\"https://www.semanticscholar.org/paper/69d576ffe624f11fe4e84a03d4063856a5af838f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.07939\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2017.143\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"title\":\"Recurrent Multimodal Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.09542\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2017.375\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a5b64709c677c131ec8b7846d3493df53987fa6f\",\"title\":\"A Joint Speaker-Listener-Reinforcer Model for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a5b64709c677c131ec8b7846d3493df53987fa6f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11263-017-1033-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"828ac57f755db989e2886042a85278ae4823297c\",\"title\":\"Uncovering the Temporal Context for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/828ac57f755db989e2886042a85278ae4823297c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900432330\",\"name\":\"Ke Ning\"},{\"authorId\":\"1811534\",\"name\":\"M. Cai\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TMM.2019.2957854\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9f2837b150eab8a1aa2e74a1a528700e1e6d8b8\",\"title\":\"An Attentive Sequence to Sequence Translator for Localizing Video Clips by Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/f9f2837b150eab8a1aa2e74a1a528700e1e6d8b8\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Asi Sheffer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"99de392582d3bd6d1e55cdafcd362ef8d57575d9\",\"title\":\"Natural Language Object Retrieval with Cross Domain Normalization\",\"url\":\"https://www.semanticscholar.org/paper/99de392582d3bd6d1e55cdafcd362ef8d57575d9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1608.08305\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a20403b74e8fd1d56233d2f1a3a805410573e0a8\",\"title\":\"Utilizing Large Scale Vision and Text Datasets for Image Segmentation from Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a20403b74e8fd1d56233d2f1a3a805410573e0a8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581032846\",\"name\":\"Neha Supe\"},{\"authorId\":\"69865365\",\"name\":\"D. Patil\"},{\"authorId\":\"1579332377\",\"name\":\"Revathi Mahadevan\"},{\"authorId\":\"1581054675\",\"name\":\"Tanvi Pandhre\"},{\"authorId\":\"49675497\",\"name\":\"B. Joshi\"}],\"doi\":\"10.1007/978-981-15-0146-3_121\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fcf85f3adcf0476fc99f8b38a45a0f7031db1c6\",\"title\":\"Image Description Generation Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1fcf85f3adcf0476fc99f8b38a45a0f7031db1c6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1603.06180\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46448-0_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b133e361e2f8af22b823d25060b2e7c47f690985\",\"title\":\"Segmentation from Natural Language Expressions\",\"url\":\"https://www.semanticscholar.org/paper/b133e361e2f8af22b823d25060b2e7c47f690985\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1912.03098\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-030-58558-7_38\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"title\":\"Connecting Vision and Language with Localized Narratives\",\"url\":\"https://www.semanticscholar.org/paper/439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145747299\",\"name\":\"Shaonan Wei\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"}],\"doi\":\"10.1007/978-3-030-31726-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f13152e19d8381b2df13bbd8d4b0718c57635d3d\",\"title\":\"Scenario Referring Expression Comprehension via Attributes of Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/f13152e19d8381b2df13bbd8d4b0718c57635d3d\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3090299\",\"name\":\"Sungmin Eum\"},{\"authorId\":\"2757702\",\"name\":\"David K. Han\"},{\"authorId\":\"50134060\",\"name\":\"G. Briggs\"}],\"doi\":\"10.1109/CVPRW50498.2020.00198\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"971ed1ca33f7e5bcc2f33e490b1ceb7d2a190d9e\",\"title\":\"SomethingFinder: Localizing undefined regions using referring expressions\",\"url\":\"https://www.semanticscholar.org/paper/971ed1ca33f7e5bcc2f33e490b1ceb7d2a190d9e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2011.07660\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"2008198436\",\"name\":\"Abhaysinh Zala\"},{\"authorId\":\"2008207270\",\"name\":\"Graham Burri\"},{\"authorId\":\"1725438390\",\"name\":\"H. Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8a95123dfd60ed5424cb669b7f4336127c6770f\",\"title\":\"ArraMon: A Joint Navigation-Assembly Instruction Interpretation Task in Dynamic Environments\",\"url\":\"https://www.semanticscholar.org/paper/d8a95123dfd60ed5424cb669b7f4336127c6770f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1903.02728\",\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"145159522\",\"name\":\"Ahmed Elgammal\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"debca9b7eccca1c1b704df0fbe187f56cd869842\",\"title\":\"Graphical Contrastive Losses for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/debca9b7eccca1c1b704df0fbe187f56cd869842\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.00786\",\"authors\":[{\"authorId\":\"50720410\",\"name\":\"Dipendra Misra\"},{\"authorId\":\"143885573\",\"name\":\"Andrew Bennett\"},{\"authorId\":\"32481910\",\"name\":\"Valts Blukis\"},{\"authorId\":\"51440033\",\"name\":\"Eyvind Niklasson\"},{\"authorId\":\"51438964\",\"name\":\"Max Shatkhin\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/D18-1287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae09e1df06d7fdf7bece8c454085ddbf5fedec2a\",\"title\":\"Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ae09e1df06d7fdf7bece8c454085ddbf5fedec2a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3401864\",\"name\":\"Ryota Hinami\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a1a1fcfd30232165b9691fb568885c3aef46c8b\",\"title\":\"Query-Adaptive R-CNN for Open-Vocabulary Object Detection and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8a1a1fcfd30232165b9691fb568885c3aef46c8b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-319-69005-6_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"title\":\"Topic-Specific Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"venue\":\"CCL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46391221\",\"name\":\"Hendricks\"},{\"authorId\":\"101014571\",\"name\":\"Miles Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"145809650\",\"name\":\"Yael Weiss\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e57ca8cfc00de06f4a5baf555c42b80964c5529b\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Grounding Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/e57ca8cfc00de06f4a5baf555c42b80964c5529b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645680\",\"name\":\"Ting Han\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"}],\"doi\":\"10.18653/v1/W19-8618\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d11e75a34408ccfa0852949270ee7784eaeb217\",\"title\":\"Sketch Me if You Can: Towards Generating Detailed Descriptions of Object Shape by Grounding in Images and Drawings\",\"url\":\"https://www.semanticscholar.org/paper/3d11e75a34408ccfa0852949270ee7784eaeb217\",\"venue\":\"INLG\",\"year\":2019},{\"arxivId\":\"1906.05928\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/ICCV.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"title\":\"Unsupervised Video Interpolation Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51118891\",\"name\":\"Enjie Cui\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1007/978-3-319-97289-3_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f014ed75aebbf3a6bc3c0833bda870673e43c26c\",\"title\":\"Selective Comprehension for Referring Expression by Prebuilt Entity Dictionary with Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/f014ed75aebbf3a6bc3c0833bda870673e43c26c\",\"venue\":\"PKAW\",\"year\":2018},{\"arxivId\":\"1803.06152\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":\"10.1109/ICCVW.2019.00316\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"83d72d7e512b1ab65b9590581418594da21c946e\",\"title\":\"Object Captioning and Retrieval with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/83d72d7e512b1ab65b9590581418594da21c946e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"},{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aa1045859089567dd65f69499d01aaaf701da70\",\"title\":\"Visual Dialogue Needs Symmetry , Goals , and Dynamics : The Example of the MeetUp Task\",\"url\":\"https://www.semanticscholar.org/paper/2aa1045859089567dd65f69499d01aaaf701da70\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"1798489\",\"name\":\"Yichen Li\"},{\"authorId\":\"144968844\",\"name\":\"K. Xu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"155dbe88e444b18ad1fd78dc9b655eb9b9d7fd43\",\"title\":\"Open-vocabulary Phrase Detection\",\"url\":\"https://www.semanticscholar.org/paper/155dbe88e444b18ad1fd78dc9b655eb9b9d7fd43\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72650914\",\"name\":\"Timothy Brinkley\"}],\"doi\":\"10.4018/978-1-5225-3041-1.CH005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e3cd4a56dcd94cba905eea552256efb1b891cdc\",\"title\":\"Technology for Gifted Students in Mixed-Ability Classrooms\",\"url\":\"https://www.semanticscholar.org/paper/1e3cd4a56dcd94cba905eea552256efb1b891cdc\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.01301\",\"authors\":[{\"authorId\":\"2191455\",\"name\":\"Sheng Shen\"},{\"authorId\":\"47070750\",\"name\":\"Daniel Fried\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N19-1410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"743d1aae44a12fb37b743ec947fad41cba9831b8\",\"title\":\"Pragmatically Informative Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/743d1aae44a12fb37b743ec947fad41cba9831b8\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2006.03776\",\"authors\":[{\"authorId\":\"3456962\",\"name\":\"Amar Shrestha\"},{\"authorId\":\"9091383\",\"name\":\"Krittaphat Pugdeethosapol\"},{\"authorId\":\"122851204\",\"name\":\"Haowen Fang\"},{\"authorId\":\"1862322\",\"name\":\"Q. Qiu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032a517f0c7e27a5fa95522c49de423633036b5f\",\"title\":\"MAGNet: Multi-Region Attention-Assisted Grounding of Natural Language Queries at Phrase Level\",\"url\":\"https://www.semanticscholar.org/paper/032a517f0c7e27a5fa95522c49de423633036b5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10092\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"title\":\"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74597299\",\"name\":\"Ran Wensheng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e35789e253de531fce485f096c71c1bfac1cad31\",\"title\":\"Modeling Relationships between Objects for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/e35789e253de531fce485f096c71c1bfac1cad31\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.11209\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"143668320\",\"name\":\"W. Hwu\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e81df94c24c08963c7d338d601bb030a8d919720\",\"title\":\"Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/e81df94c24c08963c7d338d601bb030a8d919720\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"12086460\",\"name\":\"Xiaoyu Mo\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b31d3016349c164d7cad574b64f2bcb74eb2490\",\"title\":\"Recursive Grounding Pruning Input Language the skis of the man in the red jacket skis of man in red jacket RvG-Tree Constructor\",\"url\":\"https://www.semanticscholar.org/paper/8b31d3016349c164d7cad574b64f2bcb74eb2490\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.01530\",\"authors\":[{\"authorId\":\"134167565\",\"name\":\"J. Haber\"},{\"authorId\":\"51190347\",\"name\":\"Tim Baumg\\u00e4rtner\"},{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"2552871\",\"name\":\"Elia Bruni\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/P19-1184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76cb048a3571f71e191c9731c69644eec16eb1ed\",\"title\":\"The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/76cb048a3571f71e191c9731c69644eec16eb1ed\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1908.07129\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2019.00479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"666d9a766de11c22d9fd7d8e3c36a80ecd6f0bd0\",\"title\":\"Zero-Shot Grounding of Objects From Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/666d9a766de11c22d9fd7d8e3c36a80ecd6f0bd0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66125335\",\"name\":\"Heqian Qiu\"},{\"authorId\":\"30548955\",\"name\":\"Hongliang Li\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"1706784\",\"name\":\"Fanman Meng\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"},{\"authorId\":\"1993661016\",\"name\":\"Taijin Zhao\"},{\"authorId\":\"1684869\",\"name\":\"K. N. Ngan\"}],\"doi\":\"10.1145/3394171.3413850\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ee97b258b907a8859a67014d1bdb8bf3fcc4894\",\"title\":\"Language-Aware Fine-Grained Object Representation for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7ee97b258b907a8859a67014d1bdb8bf3fcc4894\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2441498\",\"name\":\"Kar-Han Tan\"},{\"authorId\":\"1910217\",\"name\":\"B. P. Lim\"}],\"doi\":\"10.1017/ATSIP.2018.6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3264428bc54b63c49968e499996abb986acc47b\",\"title\":\"The artificial intelligence renaissance: deep learning and the road to human-Level machine intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a3264428bc54b63c49968e499996abb986acc47b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2101328\",\"name\":\"Xue-Jing Liu\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"2797676\",\"name\":\"Dechao Meng\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413677\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0767d8241f959f42e2e747cf17813c78cacc79e1\",\"title\":\"Transferrable Referring Expression Grounding with Concept Transfer and Context Inheritance\",\"url\":\"https://www.semanticscholar.org/paper/0767d8241f959f42e2e747cf17813c78cacc79e1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681393\",\"name\":\"C. Wang\"},{\"authorId\":\"3757443\",\"name\":\"A. Rimner\"},{\"authorId\":\"2915726\",\"name\":\"Y. Hu\"},{\"authorId\":\"1955294\",\"name\":\"N. Tyagi\"},{\"authorId\":\"46401067\",\"name\":\"J. Jiang\"},{\"authorId\":\"3059059\",\"name\":\"E. Yorke\"},{\"authorId\":\"8072782\",\"name\":\"S. Riyahi\"},{\"authorId\":\"2013813\",\"name\":\"G. Mageras\"},{\"authorId\":\"1769439\",\"name\":\"J. Deasy\"},{\"authorId\":\"2165338\",\"name\":\"P. Zhang\"}],\"doi\":\"10.1002/mp.13765\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37436947ad172f78a75d9edb4481ddb13ccfe7d2\",\"title\":\"Towards Predicting the Evolution of Lung Tumors During Radiotherapy Observed on a Longitudinal MR Imaging Study Via a Deep Learning Algorithm.\",\"url\":\"https://www.semanticscholar.org/paper/37436947ad172f78a75d9edb4481ddb13ccfe7d2\",\"venue\":\"Medical physics\",\"year\":2019},{\"arxivId\":\"1811.12354\",\"authors\":[{\"authorId\":\"27936309\",\"name\":\"Howard Chen\"},{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"31498163\",\"name\":\"Dipendra Kumar Misra\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.1109/CVPR.2019.01282\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5cc6634724b2238c88bcc324ec01a2c91c1b909\",\"title\":\"TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments\",\"url\":\"https://www.semanticscholar.org/paper/b5cc6634724b2238c88bcc324ec01a2c91c1b909\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144770458\",\"name\":\"F. Zhao\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"39001620\",\"name\":\"T. Xu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3123266.3123439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b0134725e7400f2211207fbe9bfb402b9fcacf3\",\"title\":\"Deep Attribute-preserving Metric Learning for Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2b0134725e7400f2211207fbe9bfb402b9fcacf3\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50704161\",\"name\":\"Lingxuan Li\"},{\"authorId\":\"11232438\",\"name\":\"Yihong Zhao\"},{\"authorId\":\"96515479\",\"name\":\"Zhaorui Zhang\"},{\"authorId\":\"1733076573\",\"name\":\"Tianrui Niu\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"48631332\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-60457-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c0d407899b7c535ce90fa798309214902ae0cba\",\"title\":\"Referring Expression Generation via Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0c0d407899b7c535ce90fa798309214902ae0cba\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.07290\",\"authors\":[{\"authorId\":\"5315428\",\"name\":\"Benjamin J. Newman\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"673c1512aeb604c9070605ef097d6dfd5e4cd0ba\",\"title\":\"Communication-based Evaluation for Natural Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/673c1512aeb604c9070605ef097d6dfd5e4cd0ba\",\"venue\":\"SCIL\",\"year\":2020},{\"arxivId\":\"1810.00333\",\"authors\":[{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"81911935\",\"name\":\"Nicol\\u00e1s Mar\\u00edn\"},{\"authorId\":\"1405030818\",\"name\":\"Gustavo Rivas-Gervilla\"},{\"authorId\":\"123730887\",\"name\":\"D. S\\u00e1nchez\"}],\"doi\":\"10.18653/v1/W18-6562\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ef9b5a791a9d4d2392a03d6c606b3316555c76\",\"title\":\"Specificity measures and reference\",\"url\":\"https://www.semanticscholar.org/paper/75ef9b5a791a9d4d2392a03d6c606b3316555c76\",\"venue\":\"INLG\",\"year\":2018},{\"arxivId\":\"1712.03463\",\"authors\":[{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"302ae0d991d62dee82b63530b487a50469810af4\",\"title\":\"Learning Interpretable Spatial Operations in a Rich 3D Blocks World\",\"url\":\"https://www.semanticscholar.org/paper/302ae0d991d62dee82b63530b487a50469810af4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1908.10568\",\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"143931909\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"958f102ce7fdaa9f2467f0c2f6b3071b824394af\",\"title\":\"Adaptive Reconstruction Network for Weakly Supervised Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/958f102ce7fdaa9f2467f0c2f6b3071b824394af\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1805.10547\",\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b658b8a9fbe1d35cdf1942e5c1bdc546a4c39029\",\"title\":\"Using Syntax to Ground Referring Expressions in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/b658b8a9fbe1d35cdf1942e5c1bdc546a4c39029\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"38218215\",\"name\":\"Xin Wang\"},{\"authorId\":\"49336516\",\"name\":\"W. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/cvpr42600.2020.01000\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd8ad5cc71f8108177206fa4844c8d06dd57cdc0\",\"title\":\"REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments\",\"url\":\"https://www.semanticscholar.org/paper/fd8ad5cc71f8108177206fa4844c8d06dd57cdc0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.05060\",\"authors\":[{\"authorId\":\"2155555\",\"name\":\"Y. Pu\"},{\"authorId\":\"145594432\",\"name\":\"K. Ellis\"},{\"authorId\":\"1878563\",\"name\":\"Marta Kryven\"},{\"authorId\":\"114497499\",\"name\":\"Josh Tenenbaum\"},{\"authorId\":\"1389870240\",\"name\":\"Armando Solar-Lezama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0035c48f78039dd362a9dc25a31a676e815701f\",\"title\":\"Program Synthesis with Pragmatic Communication\",\"url\":\"https://www.semanticscholar.org/paper/b0035c48f78039dd362a9dc25a31a676e815701f\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1703.02521\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.116\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35f1bcff4552632419742bbb6e1927ef5e998eb4\",\"title\":\"Unsupervised Visual-Linguistic Reference Resolution in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/35f1bcff4552632419742bbb6e1927ef5e998eb4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"32273391\",\"name\":\"L. Dery\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00623\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeac614f10cb2a5dc000fdee30d857bbe5456ce5\",\"title\":\"Finding \\\"It\\\": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/aeac614f10cb2a5dc000fdee30d857bbe5456ce5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1807.09685\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":\"10.1007/978-3-030-01216-8_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"887027f0aaa2644c29bb9f4c42dcb19ea94c2763\",\"title\":\"Grounding Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/887027f0aaa2644c29bb9f4c42dcb19ea94c2763\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"143677598\",\"name\":\"R. Tao\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2017.777\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"736657bd62e6e8a1e29fd2bdb49910ee6da9b8c7\",\"title\":\"Tracking by Natural Language Specification\",\"url\":\"https://www.semanticscholar.org/paper/736657bd62e6e8a1e29fd2bdb49910ee6da9b8c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2010.00263\",\"authors\":[{\"authorId\":\"37923017\",\"name\":\"Miriam Bellver\"},{\"authorId\":\"38478804\",\"name\":\"C. Ventura\"},{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"40954941\",\"name\":\"Ioannis Kazakos\"},{\"authorId\":\"144345280\",\"name\":\"J. Torres\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"574cfdc454a6b44026fcbc5539127ca507ca3045\",\"title\":\"RefVOS: A Closer Look at Referring Expressions for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/574cfdc454a6b44026fcbc5539127ca507ca3045\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05816\",\"authors\":[{\"authorId\":\"32609381\",\"name\":\"Hyunwoo Kim\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"70308241\",\"name\":\"G. Kim\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.65\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcfacdd0b5b42e97e7e38cb2dd323510822f5d46\",\"title\":\"Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness\",\"url\":\"https://www.semanticscholar.org/paper/fcfacdd0b5b42e97e7e38cb2dd323510822f5d46\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1703.09902\",\"authors\":[{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":\"10.1613/jair.5477\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d13bb317e87f3f6da10da11059ebf4350b754814\",\"title\":\"Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d13bb317e87f3f6da10da11059ebf4350b754814\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2018},{\"arxivId\":\"2008.01180\",\"authors\":[{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"143903550\",\"name\":\"M. Timm\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1007/978-3-030-58452-8_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86f0fb3791761cdb5e9108721a536d752641d4bf\",\"title\":\"Describing Textures using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/86f0fb3791761cdb5e9108721a536d752641d4bf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"},{\"authorId\":\"1741866\",\"name\":\"H. Li\"},{\"authorId\":\"1706784\",\"name\":\"Fanman Meng\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-01231-1_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"title\":\"Key-Word-Aware Network for Referring Expression Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3269302\",\"name\":\"H. Lu\"},{\"authorId\":\"2476949\",\"name\":\"Q. Liu\"},{\"authorId\":\"117701202\",\"name\":\"Nicholas Ichien\"},{\"authorId\":\"145081360\",\"name\":\"A. Yuille\"},{\"authorId\":\"2009767\",\"name\":\"K. Holyoak\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f186350c101af1eecdd1cbe62ca02501ba8140d\",\"title\":\"Seeing the Meaning: Vision Meets Semantics in Solving Pictorial Analogy Problems\",\"url\":\"https://www.semanticscholar.org/paper/0f186350c101af1eecdd1cbe62ca02501ba8140d\",\"venue\":\"CogSci\",\"year\":2019},{\"arxivId\":\"1904.07826\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":null,\"name\":\"Lillian Lee\"},{\"authorId\":\"38917723\",\"name\":\"David Mimno\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d97b53c661bfca4fe8f4ce253c13a45645a44b\",\"title\":\"Training Time : Document-level Co-occurrence Testing Time : Image / Sentence Link Prediction Great day at the park !\",\"url\":\"https://www.semanticscholar.org/paper/76d97b53c661bfca4fe8f4ce253c13a45645a44b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.05786\",\"authors\":[{\"authorId\":\"30572523\",\"name\":\"H. Wang\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"},{\"authorId\":\"80158488\",\"name\":\"SingBing Kang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56bb6fbf51905151f3147d674fea45219e6a6f35\",\"title\":\"Learning to Globally Edit Images with Textual Description\",\"url\":\"https://www.semanticscholar.org/paper/56bb6fbf51905151f3147d674fea45219e6a6f35\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.02448\",\"authors\":[{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1855095179\",\"name\":\"Pengwei Tang\"},{\"authorId\":\"3008849\",\"name\":\"Zhikang Zhou\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":\"10.1145/3394171.3414053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"title\":\"Fine-grained Iterative Attention Network for Temporal Language Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.08792\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"83754395\",\"name\":\"Simon Vandenhende\"},{\"authorId\":\"1388019229\",\"name\":\"Dusan Grujicic\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1758219\",\"name\":\"Matthew B. Blaschko\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a43ed50d4ae027cfd29ab3fdbb731f8439c49c5\",\"title\":\"Commands 4 Autonomous Vehicles (C4AV) Workshop Summary\",\"url\":\"https://www.semanticscholar.org/paper/9a43ed50d4ae027cfd29ab3fdbb731f8439c49c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08717\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"144481186\",\"name\":\"Guillem Collell\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bc42a9ebf099b84c02feac5b99e81ce5777eb07\",\"title\":\"Giving Commands to a Self-driving Car: A Multimodal Reasoner for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2bc42a9ebf099b84c02feac5b99e81ce5777eb07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.04284\",\"authors\":[{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d81b0a79558cabaaf3db22caf89454f4e012f21b\",\"title\":\"iParaphrasing: Extracting Visually Grounded Paraphrases via an Image\",\"url\":\"https://www.semanticscholar.org/paper/d81b0a79558cabaaf3db22caf89454f4e012f21b\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46748462\",\"name\":\"E. Blasch\"},{\"authorId\":\"1847092\",\"name\":\"L. Grewe\"},{\"authorId\":\"1743503219\",\"name\":\"Edward L. Waltz\"},{\"authorId\":\"3292083\",\"name\":\"Paul Bendich\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"},{\"authorId\":\"3158478\",\"name\":\"I. Kadar\"},{\"authorId\":\"143732554\",\"name\":\"C. Chong\"}],\"doi\":\"10.1117/12.2559416\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"156f00ea76be4e0e79749a70c157bce2c5b51d21\",\"title\":\"Machine learning in/with information fusion for infrastructure understanding, panel summary\",\"url\":\"https://www.semanticscholar.org/paper/156f00ea76be4e0e79749a70c157bce2c5b51d21\",\"venue\":\"Defense + Commercial Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1807810\",\"name\":\"Gemma Boleda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0434b16a363d88e27a1b36fc68e04451cc3725b9\",\"title\":\"Object Naming in Language and Vision: A Survey and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0434b16a363d88e27a1b36fc68e04451cc3725b9\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1711.00088\",\"authors\":[{\"authorId\":\"3438473\",\"name\":\"Max H. Quinn\"},{\"authorId\":\"27572284\",\"name\":\"E. Conser\"},{\"authorId\":\"38388831\",\"name\":\"J. M. Witte\"},{\"authorId\":\"144380037\",\"name\":\"Melanie Mitchell\"}],\"doi\":\"10.1109/ICSC.2018.00032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25894be540936562953f37fbbcff69e5ac17a494\",\"title\":\"Semantic Image Retrieval via Active Grounding of Visual Situations\",\"url\":\"https://www.semanticscholar.org/paper/25894be540936562953f37fbbcff69e5ac17a494\",\"venue\":\"2018 IEEE 12th International Conference on Semantic Computing (ICSC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.18653/v1/D18-1282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a15f4e3adb56dbbdd6f922489efef48fc5efa003\",\"title\":\"Grounding Semantic Roles in Images\",\"url\":\"https://www.semanticscholar.org/paper/a15f4e3adb56dbbdd6f922489efef48fc5efa003\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714708\",\"name\":\"S. Lee\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"975af82c9ce82a1fad760d58ba0a661217689aa9\",\"title\":\"Answerer in Questioner's Mind for Goal-Oriented Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/975af82c9ce82a1fad760d58ba0a661217689aa9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.00839\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"50218594\",\"name\":\"Z. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/CVPR.2019.00205\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"title\":\"Improving Referring Expression Grounding With Cross-Modal Attention-Guided Erasing\",\"url\":\"https://www.semanticscholar.org/paper/cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.09936\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"title\":\"Tripping through time: Efficient Localization of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2011.10364\",\"authors\":[{\"authorId\":\"31213065\",\"name\":\"Mohamadreza Faridghasemnia\"},{\"authorId\":\"144143747\",\"name\":\"D. Nardi\"},{\"authorId\":\"1815138\",\"name\":\"A. Saffiotti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebb8de3ec8aec2134a77545bcdaae552484e4340\",\"title\":\"Towards Abstract Relational Learning in Human Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ebb8de3ec8aec2134a77545bcdaae552484e4340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35137594\",\"name\":\"Jinpeng Mi\"},{\"authorId\":\"1939598\",\"name\":\"Jian-Zhi Lyu\"},{\"authorId\":\"1739175813\",\"name\":\"Song Tang\"},{\"authorId\":\"153082688\",\"name\":\"Qingdu Li\"},{\"authorId\":\"50561627\",\"name\":\"J. Zhang\"}],\"doi\":\"10.3389/fnbot.2020.00043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ceb666a47c683b0555f8976e7d2a0f15f9cf8be2\",\"title\":\"Interactive Natural Language Grounding via Referring Expression Comprehension and Scene Graph Parsing\",\"url\":\"https://www.semanticscholar.org/paper/ceb666a47c683b0555f8976e7d2a0f15f9cf8be2\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"}],\"doi\":\"10.1109/CVPR.2018.00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2115fe369b3a6b859c6992ba023d5c11b1689801\",\"title\":\"GroupCap: Group-Based Image Captioning with Structured Relevance and Diversity Constraints\",\"url\":\"https://www.semanticscholar.org/paper/2115fe369b3a6b859c6992ba023d5c11b1689801\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.03885\",\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.18653/v1/W19-1802\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e164e75632e23a7fba6a46d2ee2dc328720601af\",\"title\":\"Referring to Objects in Videos using Spatio-Temporal Identifying Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e164e75632e23a7fba6a46d2ee2dc328720601af\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.06193\",\"authors\":[{\"authorId\":\"10774714\",\"name\":\"Rajat Koner\"},{\"authorId\":\"98755209\",\"name\":\"Poulami Sinhamahapatra\"},{\"authorId\":\"1700754\",\"name\":\"Volker Tresp\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fc60ce53d8fb9711c5c2cd9206f7578ebc5d9df\",\"title\":\"Relation Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/1fc60ce53d8fb9711c5c2cd9206f7578ebc5d9df\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405709193\",\"name\":\"Gonzalo Vaca-Castano\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/J.CVIU.2019.02.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0efecabff90401ea60cc5bca791d00f5113fa73\",\"title\":\"Holistic object detection and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0efecabff90401ea60cc5bca791d00f5113fa73\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1711.09509\",\"authors\":[{\"authorId\":\"3401864\",\"name\":\"Ryota Hinami\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"}],\"doi\":\"10.18653/v1/D18-1281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca24289cefdee010a4700a6dd2ffac2a0cf05d09\",\"title\":\"Discriminative Learning of Open-Vocabulary Object Retrieval and Localization by Negative Phrase Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/ca24289cefdee010a4700a6dd2ffac2a0cf05d09\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1802.03881\",\"authors\":[{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f593265377f98b458e5f34fc595ab032de3c1922\",\"title\":\"Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f593265377f98b458e5f34fc595ab032de3c1922\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1909.07072\",\"authors\":[{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"9296457\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"47557603\",\"name\":\"Yanjie Chen\"},{\"authorId\":null,\"name\":\"Chen Qian\"},{\"authorId\":\"33980717\",\"name\":\"B. Li\"}],\"doi\":\"10.1109/CVPR42600.2020.01089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1588b47c51cf719bcfdf1889349164d541fb3825\",\"title\":\"A Real-Time Cross-Modality Correlation Filtering Method for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/1588b47c51cf719bcfdf1889349164d541fb3825\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.00421\",\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"97885771\",\"name\":\"Hongming Zhang\"},{\"authorId\":\"95882703\",\"name\":\"Y. Song\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.18653/v1/D19-1516\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64f8fe204cd130035749c0ff110746580f04d7c3\",\"title\":\"What You See is What You Get: Visual Pronoun Coreference Resolution in Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/64f8fe204cd130035749c0ff110746580f04d7c3\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029315929\",\"name\":\"Nikolaos Panagiaris\"},{\"authorId\":\"144988281\",\"name\":\"E. Hart\"},{\"authorId\":\"2921637\",\"name\":\"Dimitra Gkatzia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9915eb6475247e72a084eb8d6a89d602ee1c27a0\",\"title\":\"Improving the Naturalness and Diversity of Referring Expression Generation models using Minimum Risk Training\",\"url\":\"https://www.semanticscholar.org/paper/9915eb6475247e72a084eb8d6a89d602ee1c27a0\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.00260\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2017.452\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"title\":\"Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1701.02870\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/CVPR.2017.120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e782437503f2a24fd1a836a434da395bf15c88c2\",\"title\":\"Context-Aware Captions from Context-Agnostic Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e782437503f2a24fd1a836a434da395bf15c88c2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.06641\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues\",\"url\":\"https://www.semanticscholar.org/paper/d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34692779\",\"name\":\"K. Chang\"},{\"authorId\":\"10421443\",\"name\":\"Kung-Hung Lu\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"}],\"doi\":\"10.1109/ICCV.2017.380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"title\":\"Aesthetic Critiques Generation for Photos\",\"url\":\"https://www.semanticscholar.org/paper/c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.03561\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"title\":\"Joint Visual Grounding with Language Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1807.02257\",\"authors\":[{\"authorId\":\"1414497291\",\"name\":\"Edgar Margffoy-Tuay\"},{\"authorId\":\"152978592\",\"name\":\"Juan C. P\\u00e9rez\"},{\"authorId\":\"51049657\",\"name\":\"E. Botero\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"}],\"doi\":\"10.1007/978-3-030-01252-6_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"title\":\"Dynamic Multimodal Instance Segmentation guided by natural language queries\",\"url\":\"https://www.semanticscholar.org/paper/810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.04748\",\"authors\":[{\"authorId\":\"12650171\",\"name\":\"Yi-Wen Chen\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0096ee35502910ef560fc554b2980010aa1947b5\",\"title\":\"Referring Expression Object Segmentation with Caption-Aware Consistency\",\"url\":\"https://www.semanticscholar.org/paper/0096ee35502910ef560fc554b2980010aa1947b5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1812.03426\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"title\":\"Real-Time Referring Expression Comprehension by Single-Stage Grounding Network\",\"url\":\"https://www.semanticscholar.org/paper/e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"143931909\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e59f4cd2651ffb36a6009231dead1cae16d5987\",\"title\":\"Language Attention Proposal Attention + Training Inference man in white on the left holding a bat Subject Location Context Input query Input image\",\"url\":\"https://www.semanticscholar.org/paper/8e59f4cd2651ffb36a6009231dead1cae16d5987\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"153500661\",\"name\":\"S. Cohen\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/CVPR42600.2020.01023\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a1ebc58f6c055eac8555d9850cb849a38c22c67d\",\"title\":\"PhraseCut: Language-Based Image Segmentation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/a1ebc58f6c055eac8555d9850cb849a38c22c67d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.01678\",\"authors\":[{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"1388323535\",\"name\":\"Hadar Averbuch-Elor\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/2020.acl-main.234\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ff80f56fe0977836fdb232a058fbebc1c2d5bbac\",\"title\":\"What is Learned in Visually Grounded Neural Syntax Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/ff80f56fe0977836fdb232a058fbebc1c2d5bbac\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1904.04166\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TIP.2020.2967584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866908141e1db5d6b278984072303a0e14423bcc\",\"title\":\"Revisiting EmbodiedQA: A Simple Baseline and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/866908141e1db5d6b278984072303a0e14423bcc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.08814\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/cvpr42600.2020.00997\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"434bccb2743fbb918b5666000c839b390cb209ae\",\"title\":\"Graph-Structured Referring Expression Reasoning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/434bccb2743fbb918b5666000c839b390cb209ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.11185\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"021b08b823700f8053afc54356e8d0ce57a3df71\",\"title\":\"Unsupervised Textual Grounding: Linking Words to Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/021b08b823700f8053afc54356e8d0ce57a3df71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51287527\",\"name\":\"W. Veltroni\"},{\"authorId\":\"3359378\",\"name\":\"Helena de Medeiros Caseli\"}],\"doi\":\"10.1007/978-3-319-99722-3_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"129c4b70435316fe03ea5d4ceae3dd7522295614\",\"title\":\"Text-Image Alignment in Portuguese News Using LinkPICS\",\"url\":\"https://www.semanticscholar.org/paper/129c4b70435316fe03ea5d4ceae3dd7522295614\",\"venue\":\"PROPOR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"2462591\",\"name\":\"Ruifan Li\"}],\"doi\":\"10.24963/ijcai.2018/592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"555e65623326de1b9c32bd22d482071920a6e4f1\",\"title\":\"Show and Tell More: Topic-Oriented Multi-Sentence Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/555e65623326de1b9c32bd22d482071920a6e4f1\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf2f9f9ebe16b2574ad6de69f5806e5d44c14217\",\"title\":\"Explainability by Parsing: Neural Module Tree Networks for Natural Language Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/bf2f9f9ebe16b2574ad6de69f5806e5d44c14217\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.03409\",\"authors\":[{\"authorId\":\"79953458\",\"name\":\"Haoshuo Huang\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"18138802\",\"name\":\"Harsh Mehta\"},{\"authorId\":\"31702389\",\"name\":\"Alexander Ku\"},{\"authorId\":\"145181836\",\"name\":\"Gabriel Magalh\\u00e3es\"},{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"}],\"doi\":\"10.1109/ICCV.2019.00750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c351e405660f09ded4ba2bd05a2362be292a3da3\",\"title\":\"Transferable Representation Learning in Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c351e405660f09ded4ba2bd05a2362be292a3da3\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.03299\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1109/ICCV.2019.00477\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e504843bfd3ca81b859895439bbe19efc1f3dc61\",\"title\":\"Learning to Assemble Neural Module Tree Networks for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/e504843bfd3ca81b859895439bbe19efc1f3dc61\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.10890\",\"authors\":[{\"authorId\":\"2018700866\",\"name\":\"Chao Yang\"},{\"authorId\":\"50248868\",\"name\":\"Guoqing Wang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"2476503\",\"name\":\"H. Shen\"},{\"authorId\":\"145030306\",\"name\":\"S. Feng\"},{\"authorId\":\"1796274181\",\"name\":\"Bin Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1275efae4f9f749b876c1f9dd527302de63a88c3\",\"title\":\"PPGN: Phrase-Guided Proposal Generation Network For Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/1275efae4f9f749b876c1f9dd527302de63a88c3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.03609\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/TPAMI.2019.2926266\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"title\":\"Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"2002.10340\",\"authors\":[{\"authorId\":\"144052839\",\"name\":\"Wei Pang\"},{\"authorId\":\"50142157\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-58517-4_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7ba12958cb670442236accd5e0579728821ad7d\",\"title\":\"Guessing State Tracking for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/b7ba12958cb670442236accd5e0579728821ad7d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.06354\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00478\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"title\":\"A Fast and Accurate One-Stage Approach to Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100818163\",\"name\":\"Chen-chen Jing\"},{\"authorId\":\"145558278\",\"name\":\"Y. Wu\"},{\"authorId\":\"144315453\",\"name\":\"Mingtao Pei\"},{\"authorId\":\"46972595\",\"name\":\"Yao Hu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413902\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc24a5a8d6629eec5c8d87d48ab891bc17e862ff\",\"title\":\"Visual-Semantic Graph Matching for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/cc24a5a8d6629eec5c8d87d48ab891bc17e862ff\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36854588\",\"name\":\"Jacob Arkin\"},{\"authorId\":\"2037963\",\"name\":\"Daehyung Park\"},{\"authorId\":\"2248453\",\"name\":\"Subhro Roy\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"},{\"authorId\":\"153676642\",\"name\":\"N. Roy\"},{\"authorId\":\"35452905\",\"name\":\"T. M. Howard\"},{\"authorId\":\"3619154\",\"name\":\"R. Paul\"}],\"doi\":\"10.1177/0278364920917755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b0c78644069b231b9f2421086f21a17644b9726\",\"title\":\"Multimodal estimation and communication of latent semantic knowledge for robust execution of robot instructions\",\"url\":\"https://www.semanticscholar.org/paper/1b0c78644069b231b9f2421086f21a17644b9726\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.01784\",\"authors\":[{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"12086460\",\"name\":\"Xiaoyu Mo\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/TPAMI.2019.2911066\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2db3da6c2279c5a7e8238a63d5e79681e25c97cb\",\"title\":\"Learning to Compose and Reason with Language Tree Structures for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2db3da6c2279c5a7e8238a63d5e79681e25c97cb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1703.07579\",\"authors\":[{\"authorId\":\"145391148\",\"name\":\"F. Wu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fbea83f1d3eaac2bfe94a2aee9d1d6093b4de70\",\"title\":\"An End-to-End Approach to Natural Language Object Retrieval via Context-Aware Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/7fbea83f1d3eaac2bfe94a2aee9d1d6093b4de70\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144230956\",\"name\":\"Bo Huang\"},{\"authorId\":\"144645740\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1736727\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1145/3301506.3301538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"befc8b8ee539df950bbbab06d09c89d5b83eaa34\",\"title\":\"MLN: Moment localization Network and Samples Selection for Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/befc8b8ee539df950bbbab06d09c89d5b83eaa34\",\"venue\":\"ICVIP\",\"year\":2018},{\"arxivId\":\"1608.07068\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-46475-6_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"title\":\"Title Generation for User Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41a809153d43dadd285e587f9a166c6175b6db64\",\"title\":\"A Modular Interface for Multimodal Data Annotation and Visualization with Applications to Conversational AI and Commonsense Grounding\",\"url\":\"https://www.semanticscholar.org/paper/41a809153d43dadd285e587f9a166c6175b6db64\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921534\",\"name\":\"Philip Kinghorn\"},{\"authorId\":\"41204462\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.neucom.2017.07.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"title\":\"A region-based image caption generator with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1909.02860\",\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"73596205\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47809582\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3343031.3351074\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"28691804ea6e9bb00249d864be36354f6c548ba5\",\"title\":\"Knowledge-guided Pairwise Reconstruction Network for Weakly Supervised Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/28691804ea6e9bb00249d864be36354f6c548ba5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"152599661\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2019.00589\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"949959250e487617faa3035b05b52aa03a8e9895\",\"title\":\"Generating Easy-to-Understand Referring Expressions for Target Identifications\",\"url\":\"https://www.semanticscholar.org/paper/949959250e487617faa3035b05b52aa03a8e9895\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3725761\",\"name\":\"XiaoQing Bu\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"}],\"doi\":\"10.1007/978-3-030-31723-2_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb92398ee4ecf17963bc2b261ca6e5c69128f63c\",\"title\":\"One-Shot Video Object Segmentation Initialized with Referring Expression\",\"url\":\"https://www.semanticscholar.org/paper/eb92398ee4ecf17963bc2b261ca6e5c69128f63c\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92041675\",\"name\":\"X. Liu\"},{\"authorId\":\"49594421\",\"name\":\"M. Gan\"}],\"doi\":\"10.1016/j.knosys.2020.106142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d00e0540415702d789b5f1701e181720dbf4bbc8\",\"title\":\"RDBN: Visual relationship detection with inaccurate RGB-D images\",\"url\":\"https://www.semanticscholar.org/paper/d00e0540415702d789b5f1701e181720dbf4bbc8\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"1704.07945\",\"authors\":[{\"authorId\":\"3369734\",\"name\":\"M. Yamaguchi\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2017.162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06184106c9a5dc602cac98f162b991707aaa4a80\",\"title\":\"Spatio-Temporal Person Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/06184106c9a5dc602cac98f162b991707aaa4a80\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2621738\",\"name\":\"Xuejian Rong\"},{\"authorId\":\"40263913\",\"name\":\"Chucai Yi\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2930176\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"257bac97982d95f290f1a67ad23f0654b716693c\",\"title\":\"Unambiguous Scene Text Segmentation With Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/257bac97982d95f290f1a67ad23f0654b716693c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1908.11310\",\"authors\":[{\"authorId\":\"19444389\",\"name\":\"Koustav Ghosal\"},{\"authorId\":\"36809068\",\"name\":\"Aakanksha Rana\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d204156022f65e34706d4211e05bcb578940939\",\"title\":\"Aesthetic Image Captioning From Weakly-Labelled Photographs\",\"url\":\"https://www.semanticscholar.org/paper/5d204156022f65e34706d4211e05bcb578940939\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P16-1058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06d7968ced2bdeba0d7dc58fb8e12406a3ccb3c8\",\"title\":\"Easy Things First: Installments Improve Referring Expression Generation for Objects in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/06d7968ced2bdeba0d7dc58fb8e12406a3ccb3c8\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1808.08803\",\"authors\":[{\"authorId\":\"1819984\",\"name\":\"K. Ning\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"47118295\",\"name\":\"Ming Cai\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20da5315cfe5eab69d99bbda270e73ab488a49ba\",\"title\":\"Attentive Sequence to Sequence Translation for Localizing Clips of Interest by Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/20da5315cfe5eab69d99bbda270e73ab488a49ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24874138\",\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":null,\"name\":\"Xiaohui Zeng\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1d4c49e764a200bc90113b0ba9c34664d0f9462\",\"title\":\"Memo No . 082 May 10 , 2018 Scene Graph Parsing as Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/d1d4c49e764a200bc90113b0ba9c34664d0f9462\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"}],\"doi\":\"10.3929/ethz-b-000359170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6cbafe557680d52d32df8a7af600a6adcbfcc2c\",\"title\":\"Automatic Alignment Methods for Visual and Textual Data with Narrative Content\",\"url\":\"https://www.semanticscholar.org/paper/b6cbafe557680d52d32df8a7af600a6adcbfcc2c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2018.2811621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a17310abb249ce8fce8f409709b5395da32e0a6\",\"title\":\"Bundled Object Context for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/8a17310abb249ce8fce8f409709b5395da32e0a6\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"145159522\",\"name\":\"Ahmed Elgammal\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/CVPR.2019.01180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a4a62cccc182c3602ea0c604a21b8d91b99867a\",\"title\":\"Graphical Contrastive Losses for Scene Graph Parsing\",\"url\":\"https://www.semanticscholar.org/paper/0a4a62cccc182c3602ea0c604a21b8d91b99867a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"46270526\",\"name\":\"Z. Liu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dd133c6baed0b080687da0954754ea23abc8ba1\",\"title\":\"Video Question Generation via Semantic Rich Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dd133c6baed0b080687da0954754ea23abc8ba1\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.05417\",\"authors\":[{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.18653/v1/N18-2070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"025f852b227766c3a5dc914ded6f6c0ae137c617\",\"title\":\"Pragmatically Informative Image Captioning with Character-Level Reference\",\"url\":\"https://www.semanticscholar.org/paper/025f852b227766c3a5dc914ded6f6c0ae137c617\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1906.05518\",\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P19-1063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4e26768300d94850418de10484067707fec34ec\",\"title\":\"Know What You Don't Know: Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories\",\"url\":\"https://www.semanticscholar.org/paper/d4e26768300d94850418de10484067707fec34ec\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1704.01518\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2017.447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db2fecc8b1bd175d39687eb471360707a5fddb03\",\"title\":\"Generating Descriptions with Grounded and Co-referenced People\",\"url\":\"https://www.semanticscholar.org/paper/db2fecc8b1bd175d39687eb471360707a5fddb03\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.08481\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/CVPR.2017.475\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bed7834ae7d371171977a590872f60d137c2f951\",\"title\":\"GuessWhat?! Visual Object Discovery through Multi-modal Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/bed7834ae7d371171977a590872f60d137c2f951\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1007/s11263-017-1018-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44855e53801d09763c1fb5f90ab73e5c3758a728\",\"title\":\"Sentence Directed Video Object Codiscovery\",\"url\":\"https://www.semanticscholar.org/paper/44855e53801d09763c1fb5f90ab73e5c3758a728\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1906.07689\",\"authors\":[{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eb2e2b9c22cb1da8561044ca0dc8fc0b13e3157\",\"title\":\"Expressing Visual Relationships via Language\",\"url\":\"https://www.semanticscholar.org/paper/4eb2e2b9c22cb1da8561044ca0dc8fc0b13e3157\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1612.07360\",\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f83380fe193ae8475e660c1c6b12b60521a29f\",\"title\":\"Top-Down Visual Saliency Guided by Captions\",\"url\":\"https://www.semanticscholar.org/paper/76f83380fe193ae8475e660c1c6b12b60521a29f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2011.08277\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"51050450\",\"name\":\"Jacob Krantz\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dab94f11874acdd5ffe63cfb22c5f93723dc519f\",\"title\":\"Where Are You? Localization from Embodied Dialog\",\"url\":\"https://www.semanticscholar.org/paper/dab94f11874acdd5ffe63cfb22c5f93723dc519f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"}],\"doi\":\"10.1007/978-981-10-7299-4_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"title\":\"Automatic Image Description Generation with Emotional Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1806.02724\",\"authors\":[{\"authorId\":\"47070750\",\"name\":\"Daniel Fried\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ede8ba65c4db10d357d9c3bf8e75b092f536fc84\",\"title\":\"Speaker-Follower Models for Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/ede8ba65c4db10d357d9c3bf8e75b092f536fc84\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1809.04560\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D18-1012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"title\":\"Game-Based Video-Context Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1804.00112\",\"authors\":[{\"authorId\":\"50357985\",\"name\":\"S. Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3a0240a2dde30e3c7b977358843a5013b3f4d42\",\"title\":\"Compare and Contrast: Learning Prominent Visual Differences\",\"url\":\"https://www.semanticscholar.org/paper/d3a0240a2dde30e3c7b977358843a5013b3f4d42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1907.05084\",\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e854ee8a8eda42858e8b1fc050f6cae98f54be6\",\"title\":\"MeetUp! A Corpus of Joint Activity Dialogues in a Visual Environment\",\"url\":\"https://www.semanticscholar.org/paper/3e854ee8a8eda42858e8b1fc050f6cae98f54be6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.06426\",\"authors\":[{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"143979421\",\"name\":\"F. Xu\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"title\":\"Tell-the-difference: Fine-grained Visual Descriptor via a Discriminating Referee\",\"url\":\"https://www.semanticscholar.org/paper/dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.01449\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"144735552\",\"name\":\"Wenbo Ma\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8382e838ffba7a940b80679d9724710fd0143215\",\"title\":\"Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/8382e838ffba7a940b80679d9724710fd0143215\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32609381\",\"name\":\"Hyunwoo Kim\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"70308241\",\"name\":\"G. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7f0b2bcdf8f6448c2fdd51e715cee5713f4af72\",\"title\":\"Public Self-consciousness for Endowing Dialogue Agents with Consistent Persona\",\"url\":\"https://www.semanticscholar.org/paper/c7f0b2bcdf8f6448c2fdd51e715cee5713f4af72\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.10362\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"3442125\",\"name\":\"Ines Chami\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2018.00718\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"08a4022e30f93cac2e55cf6b034a09a40550df45\",\"title\":\"Referring Relationships\",\"url\":\"https://www.semanticscholar.org/paper/08a4022e30f93cac2e55cf6b034a09a40550df45\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1803.09189\",\"authors\":[{\"authorId\":\"24874138\",\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"1751476\",\"name\":\"Xiaohui Zeng\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.18653/v1/N18-1037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c3c6197037ec92de044b3068c57e26815dd6c76\",\"title\":\"Scene Graph Parsing as Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/0c3c6197037ec92de044b3068c57e26815dd6c76\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/W18-6563\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5350ef1d45574e33f5b0f1c013a5bb00e1b1c55\",\"title\":\"Decoding Strategies for Neural Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/f5350ef1d45574e33f5b0f1c013a5bb00e1b1c55\",\"venue\":\"INLG\",\"year\":2018},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BiGRU BiGRU\"},{\"authorId\":null,\"name\":\"BiGRU\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"title\":\"Multi-Stage Cross-modal Interaction Module d ) Moment Retrieval Module q \\\" q # q $ q ) Query\",\"url\":\"https://www.semanticscholar.org/paper/dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"48985581\",\"name\":\"Manli Zhang\"},{\"authorId\":\"1684276\",\"name\":\"Jianhong Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"2259699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14644cc31aec3b9aa7d785e3c1a007bda0c7824d\",\"title\":\"Recursive Visual Attention Algorithm 1 Recursive Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/14644cc31aec3b9aa7d785e3c1a007bda0c7824d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1603.08507\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46493-0_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"title\":\"Generating Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1605.09553\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"title\":\"Attention Correctness in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1806.03831\",\"authors\":[{\"authorId\":\"33516562\",\"name\":\"Mohit Shridhar\"},{\"authorId\":\"145463096\",\"name\":\"D. Hsu\"}],\"doi\":\"10.15607/RSS.2018.XIV.028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f22372af67e563c609c98ab05c0c73d0b90e6dc\",\"title\":\"Interactive Visual Grounding of Referring Expressions for Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4f22372af67e563c609c98ab05c0c73d0b90e6dc\",\"venue\":\"Robotics: Science and Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2007.09554\",\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/tmm.2020.3042066\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d8398d9c36d25ad1363d9a5dd922dbbfa7be3be\",\"title\":\"Referring Expression Comprehension: A Survey of Methods and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/9d8398d9c36d25ad1363d9a5dd922dbbfa7be3be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2248453\",\"name\":\"Subhro Roy\"},{\"authorId\":\"38107789\",\"name\":\"Michael Noseworthy\"},{\"authorId\":\"3619154\",\"name\":\"R. Paul\"},{\"authorId\":\"2037963\",\"name\":\"Daehyung Park\"},{\"authorId\":\"143724999\",\"name\":\"N. Roy\"}],\"doi\":\"10.18653/v1/K19-1040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b897b2478dae27ed7e6175436257bad0ef968796\",\"title\":\"Leveraging Past References for Robust Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b897b2478dae27ed7e6175436257bad0ef968796\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1908.01189\",\"authors\":[{\"authorId\":\"1387996941\",\"name\":\"Hazan Anayurt\"},{\"authorId\":\"1387996951\",\"name\":\"Sezai Artun Ozyegin\"},{\"authorId\":\"1387997004\",\"name\":\"Ulfet Cetin\"},{\"authorId\":\"153160880\",\"name\":\"Utku Akta\\u015f\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"669c4c85770f13a2ff5508aef8ef62c9208948f1\",\"title\":\"Searching for Ambiguous Objects in Videos using Relational Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/669c4c85770f13a2ff5508aef8ef62c9208948f1\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":\"51208710\",\"name\":\"Haoran Mo\"},{\"authorId\":\"2971945\",\"name\":\"Chengying Gao\"},{\"authorId\":\"152272089\",\"name\":\"R. Du\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"}],\"doi\":\"10.1145/3355089.3356561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98c1715b17db5a992b4e2e99f55957e70f3e51b7\",\"title\":\"Language-based colorization of scene sketches\",\"url\":\"https://www.semanticscholar.org/paper/98c1715b17db5a992b4e2e99f55957e70f3e51b7\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1694585\",\"name\":\"Fanglin Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"title\":\"Referring Expression Grounding by Marginalizing Scene Graph Likelihood\",\"url\":\"https://www.semanticscholar.org/paper/4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.08389\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"8440041\",\"name\":\"Paige Kordas\"},{\"authorId\":\"1772294\",\"name\":\"M. Kiapour\"},{\"authorId\":\"144147900\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"3221010\",\"name\":\"Robinson Piramuthu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-030-01258-8_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5bfebd3774c44580463cda8e611487ae3639cd7\",\"title\":\"Conditional Image-Text Embedding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e5bfebd3774c44580463cda8e611487ae3639cd7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.07553\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1109/ICCV.2019.00476\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a056153541c21f519b27717fbfe31e4ac565f9a1\",\"title\":\"Phrase Localization Without Paired Training Examples\",\"url\":\"https://www.semanticscholar.org/paper/a056153541c21f519b27717fbfe31e4ac565f9a1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.00403\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"97992296\",\"name\":\"P. Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01010\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"title\":\"Cops-Ref: A New Dataset and Task on Compositional Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1812.04794\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00206\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ca91ad7763be4da05238aa17a9e5628f619dc0b\",\"title\":\"Neighbourhood Watch: Referring Expression Comprehension via Language-Guided Graph Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/8ca91ad7763be4da05238aa17a9e5628f619dc0b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.10838\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"83754395\",\"name\":\"Simon Vandenhende\"},{\"authorId\":\"1388019229\",\"name\":\"Dusan Grujicic\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.18653/v1/D19-1215\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"61ac1603c0ad5268b202506bb2cddbfe10c45d9f\",\"title\":\"Talk2Car: Taking Control of Your Self-Driving Car\",\"url\":\"https://www.semanticscholar.org/paper/61ac1603c0ad5268b202506bb2cddbfe10c45d9f\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9f931f3c70487e86c475fe18cfe16caf4f65d4e\",\"title\":\"Learning under Ambiguity through Multiple Predictions\",\"url\":\"https://www.semanticscholar.org/paper/d9f931f3c70487e86c475fe18cfe16caf4f65d4e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37414303\",\"name\":\"Cheolho Han\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"32849162\",\"name\":\"W. Kang\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"68c6df1249e1ee56835f79e1877506a16d8418f4\",\"title\":\"Criteria for Human-Compatible AI in Two-Player Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/68c6df1249e1ee56835f79e1877506a16d8418f4\",\"venue\":\"LaCATODA@IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47336681\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a6bba2e81d5fb3c0fd0e6b757cf50ba7bf8e924\",\"title\":\"Compare and Contrast : Learning Prominent Differences in Relative Attributes by\",\"url\":\"https://www.semanticscholar.org/paper/2a6bba2e81d5fb3c0fd0e6b757cf50ba7bf8e924\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"145855898\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"title\":\"Supplementary Material : Referring to Object in Video using Spatio-Temporal Identifying Description\",\"url\":\"https://www.semanticscholar.org/paper/ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.11818\",\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"}],\"doi\":\"10.18653/v1/N18-2123\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72d7c465ef199a9670b3da7a318b0227f5cc3229\",\"title\":\"Visual Referring Expression Recognition: What Do Systems Actually Learn?\",\"url\":\"https://www.semanticscholar.org/paper/72d7c465ef199a9670b3da7a318b0227f5cc3229\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"2011.07398\",\"authors\":[{\"authorId\":\"48390820\",\"name\":\"Guanyi Chen\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"dd9c03517b5652da2efa18a31e3315bf71437706\",\"title\":\"Lessons from Computational Modelling of Reference Production in Mandarin and English\",\"url\":\"https://www.semanticscholar.org/paper/dd9c03517b5652da2efa18a31e3315bf71437706\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.02664\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"48985581\",\"name\":\"Manli Zhang\"},{\"authorId\":\"47538869\",\"name\":\"J. Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"2259699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":\"10.1109/CVPR.2019.00684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41db31c451cd819d22f9c0b90be110edc4424911\",\"title\":\"Recursive Visual Attention in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/41db31c451cd819d22f9c0b90be110edc4424911\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.11683\",\"authors\":[{\"authorId\":\"145559125\",\"name\":\"H. Akbari\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"1754397\",\"name\":\"Surabhi Bhargava\"},{\"authorId\":\"143852868\",\"name\":\"B. Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.01276\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"title\":\"Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1604.03249\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-319-50077-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"title\":\"Attributes as Semantic Units between Natural Language and Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2003.12739\",\"authors\":[{\"authorId\":\"33299173\",\"name\":\"Ozan Arkan Can\"},{\"authorId\":\"116865200\",\"name\":\"Ilker Kesen\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a84a38a190b90d161bcdd5585ab7a87f5b8c974d\",\"title\":\"BiLingUNet: Image Segmentation by Modulating Top-Down and Bottom-Up Visual Processing with Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a84a38a190b90d161bcdd5585ab7a87f5b8c974d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2965987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"title\":\"Moment Retrieval via Cross-Modal Interaction Networks With Query Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33516562\",\"name\":\"Mohit Shridhar\"},{\"authorId\":\"1498050435\",\"name\":\"Dixant Mittal\"},{\"authorId\":\"1384318941\",\"name\":\"David Hsu\"}],\"doi\":\"10.1177/0278364919897133\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30432eb1deae9c35ff855e8d1422e14361fb123c\",\"title\":\"INGRESS: Interactive visual grounding of referring expressions\",\"url\":\"https://www.semanticscholar.org/paper/30432eb1deae9c35ff855e8d1422e14361fb123c\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645680\",\"name\":\"Ting Han\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"145179848\",\"name\":\"Kazunori Komatani\"},{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76d6db0986ac0d68f21960835c3da9ab38367e07\",\"title\":\"Learning to Describe Multimodally from Parallel Unimodal Data ? A Pilot Study on Verbal and Sketched Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/76d6db0986ac0d68f21960835c3da9ab38367e07\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/D17-1100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f0d4f791df586308656fd1a81e61dc8018ca730\",\"title\":\"Deriving continous grounded meaning representations from referentially structured multimodal contexts\",\"url\":\"https://www.semanticscholar.org/paper/4f0d4f791df586308656fd1a81e61dc8018ca730\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1902.09514\",\"authors\":[{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"}],\"doi\":\"10.18653/v1/N19-1042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed7c3eececad3915c865b7b11d88c338b0e0cbe1\",\"title\":\"Lost in Machine Translation: A Method to Reduce Meaning Loss\",\"url\":\"https://www.semanticscholar.org/paper/ed7c3eececad3915c865b7b11d88c338b0e0cbe1\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1809.02079\",\"authors\":[{\"authorId\":\"144412704\",\"name\":\"Tong Niu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/K18-1047\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3de72d2b1ead0b9c7af5804252024128312b9cfe\",\"title\":\"Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models\",\"url\":\"https://www.semanticscholar.org/paper/3de72d2b1ead0b9c7af5804252024128312b9cfe\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87784907\",\"name\":\"X. Li\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"2168639\",\"name\":\"Kaiping Xu\"},{\"authorId\":\"50144856\",\"name\":\"Zhehuan Zhao\"},{\"authorId\":\"153318657\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9191285\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6553ee7945543eb47f239fd7150a6d6a266130fe\",\"title\":\"A Context-Based Network For Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6553ee7945543eb47f239fd7150a6d6a266130fe\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1904.02794\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"93155387\",\"name\":\"Karan Jariwala\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/N19-1194\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f17f7590a6b4488921f046112bc8fdb82d513914\",\"title\":\"VQD: Visual Query Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/f17f7590a6b4488921f046112bc8fdb82d513914\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2004.01894\",\"authors\":[{\"authorId\":\"1715983\",\"name\":\"Oier Lopez de Lacalle\"},{\"authorId\":\"1612386066\",\"name\":\"Ander Salaberria\"},{\"authorId\":\"1786084\",\"name\":\"A. Soroa\"},{\"authorId\":\"2481918\",\"name\":\"Gorka Azkune\"},{\"authorId\":\"1733049\",\"name\":\"Eneko Agirre\"}],\"doi\":\"10.3233/FAIA200319\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b792296bfe5a3b25c5b15d6dd73f5e68314208de\",\"title\":\"Evaluating Multimodal Representations on Visual Semantic Textual Similarity\",\"url\":\"https://www.semanticscholar.org/paper/b792296bfe5a3b25c5b15d6dd73f5e68314208de\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2004.10796\",\"authors\":[{\"authorId\":\"4868335\",\"name\":\"J. Park\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6966b0018daffa49eb2c38e68eb8964d56440233\",\"title\":\"Visual Commonsense Graphs: Reasoning about the Dynamic Context of a Still Image\",\"url\":\"https://www.semanticscholar.org/paper/6966b0018daffa49eb2c38e68eb8964d56440233\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30710736\",\"name\":\"Nico Chaves\"},{\"authorId\":\"40915072\",\"name\":\"Reuben Cohn-Gordon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e99e2fbc61b99e6ef3ef29d0ebb69739705c8ce\",\"title\":\"Image Captioning with Pragmatics\",\"url\":\"https://www.semanticscholar.org/paper/5e99e2fbc61b99e6ef3ef29d0ebb69739705c8ce\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.07826\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"145810617\",\"name\":\"Lillian Lee\"},{\"authorId\":\"38917723\",\"name\":\"D. Mimno\"}],\"doi\":\"10.18653/v1/D19-1210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d97b53c661bfca4fe8f4ce253c13a45645a44b\",\"title\":\"Unsupervised Discovery of Multimodal Links in Multi-Image, Multi-Sentence Documents\",\"url\":\"https://www.semanticscholar.org/paper/76d97b53c661bfca4fe8f4ce253c13a45645a44b\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394481858\",\"name\":\"Miltiadis Marios Katsakioris\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"2000174289\",\"name\":\"Pierre Yves Mignotte\"},{\"authorId\":\"49763748\",\"name\":\"H. Hastie\"}],\"doi\":\"10.1145/3382507.3418861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d6f886961c0d53ebe0ae42423dfa1a151c21db\",\"title\":\"ROSMI: A Multimodal Corpus for Map-based Instruction-Giving\",\"url\":\"https://www.semanticscholar.org/paper/f3d6f886961c0d53ebe0ae42423dfa1a151c21db\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"1812.07119\",\"authors\":[{\"authorId\":\"2221563\",\"name\":\"N. Vo\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2019.00660\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d\",\"title\":\"Composing Text and Image for Image Retrieval - an Empirical Odyssey\",\"url\":\"https://www.semanticscholar.org/paper/fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2008.01059\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58568-6_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3be9acba7b1f847e6d091c540536753ec66669c\",\"title\":\"Improving One-stage Visual Grounding by Recursive Sub-query Construction\",\"url\":\"https://www.semanticscholar.org/paper/a3be9acba7b1f847e6d091c540536753ec66669c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"2809150\",\"name\":\"Songhao Jia\"},{\"authorId\":\"2849249\",\"name\":\"Yi-Chen Lo\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICCV.2019.00755\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"661d82c26fad099f28a8da02d2c9d1cfee32cff4\",\"title\":\"See-Through-Text Grouping for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/661d82c26fad099f28a8da02d2c9d1cfee32cff4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1708.08874\",\"authors\":[{\"authorId\":\"3393384\",\"name\":\"Jong-Chyi Su\"},{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2017.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"title\":\"Reasoning About Fine-Grained Attribute Phrases Using Reference Games\",\"url\":\"https://www.semanticscholar.org/paper/956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"2706315\",\"name\":\"Ya\\u011fmur G\\u00fc\\u00e7l\\u00fct\\u00fcrk\"},{\"authorId\":\"80777440\",\"name\":\"U. G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"103366015\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.1007/978-3-319-98131-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a217389b365d06ae323fee744304067c8f62be7\",\"title\":\"Explainable and Interpretable Models in Computer Vision and Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/8a217389b365d06ae323fee744304067c8f62be7\",\"venue\":\"The Springer Series on Challenges in Machine Learning\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443432976\",\"name\":\"Zhenxiong Tan\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"1584278646\",\"name\":\"Jinyu Chen\"},{\"authorId\":\"47179923\",\"name\":\"S. Liu\"}],\"doi\":\"10.1007/978-3-030-60633-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99a02592befa3741ebeefd8d02fbe2960817b6fa\",\"title\":\"Multi-granularity Multimodal Feature Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/99a02592befa3741ebeefd8d02fbe2960817b6fa\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1016/j.neucom.2020.06.091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26f46dec34e640b6a6ccb69cc28eda3c1eaac0d\",\"title\":\"vtGraphNet: Learning weakly-supervised scene graph for complex visual grounding\",\"url\":\"https://www.semanticscholar.org/paper/a26f46dec34e640b6a6ccb69cc28eda3c1eaac0d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2005.07310\",\"authors\":[{\"authorId\":\"1701219797\",\"name\":\"Jize Cao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"46700583\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1007/978-3-030-58539-6_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26cfb57a9722599b361858d454ec816420723e36\",\"title\":\"Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models\",\"url\":\"https://www.semanticscholar.org/paper/26cfb57a9722599b361858d454ec816420723e36\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3725761\",\"name\":\"XiaoQing Bu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"1519272531\",\"name\":\"Jianming Wang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"1709000\",\"name\":\"T. Chung\"}],\"doi\":\"10.1016/j.neucom.2020.06.129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e24b67d8fe5780f8685ee791cba8518c4174529d\",\"title\":\"Weakly supervised video object segmentation initialized with referring expression\",\"url\":\"https://www.semanticscholar.org/paper/e24b67d8fe5780f8685ee791cba8518c4174529d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.acl-main.644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4887113b68c6b9dfda201019c99bcb99b18d642e\",\"title\":\"Refer360\\u2218: A Referring Expression Recognition Dataset in 360: A Referring Expression Recognition Dataset in 360\\u2218 Images Images\",\"url\":\"https://www.semanticscholar.org/paper/4887113b68c6b9dfda201019c99bcb99b18d642e\",\"venue\":\"ACL 2020\",\"year\":2020},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba7890a5e9e51bf6181cc3c03144796cb3e5e254\",\"title\":\"Query : \\\" A man in a red sweatshirt performing breakdance \\\"\",\"url\":\"https://www.semanticscholar.org/paper/ba7890a5e9e51bf6181cc3c03144796cb3e5e254\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"2175130\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"66663648\",\"name\":\"Heeseung Yun\"},{\"authorId\":\"2004821977\",\"name\":\"Jiwan Chung\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-58558-7_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afcf32596398c04bd734ee6469506522e224e52\",\"title\":\"Character Grounding and Re-identification in Story of Videos and Text Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/3afcf32596398c04bd734ee6469506522e224e52\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1611.06949\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"title\":\"Dense Captioning with Joint Inference and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.09472\",\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2017.554\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"title\":\"Weakly-Supervised Learning of Visual Relations\",\"url\":\"https://www.semanticscholar.org/paper/5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145919381\",\"name\":\"J. Hu\"},{\"authorId\":\"9582936\",\"name\":\"Desai Fan\"},{\"authorId\":\"3467427\",\"name\":\"S. Yao\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0074ccd17382bf077bf08d649a97541ad64478fd\",\"title\":\"Answer-Aware Attention on Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/0074ccd17382bf077bf08d649a97541ad64478fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.04987\",\"authors\":[{\"authorId\":\"47070750\",\"name\":\"Daniel Fried\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N18-1177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baf47cd0b471a9bb7b2230fec0b680fc9b3c4783\",\"title\":\"Unified Pragmatic Models for Generating and Following Instructions\",\"url\":\"https://www.semanticscholar.org/paper/baf47cd0b471a9bb7b2230fec0b680fc9b3c4783\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143677598\",\"name\":\"Ran Tao\"},{\"authorId\":\"2304222\",\"name\":\"Efstratios Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"970e0a18fe46aeb94647be19842d2f800147b95e\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Tracking by Natural Language Specification\",\"url\":\"https://www.semanticscholar.org/paper/970e0a18fe46aeb94647be19842d2f800147b95e\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1704.03944\",\"authors\":[{\"authorId\":\"145489055\",\"name\":\"Y. Zhang\"},{\"authorId\":\"27257564\",\"name\":\"Luyao Yuan\"},{\"authorId\":\"1857914\",\"name\":\"Yijie Guo\"},{\"authorId\":\"1755497\",\"name\":\"Zhiyuan He\"},{\"authorId\":\"38648777\",\"name\":\"Ian Huang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/CVPR.2017.122\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"title\":\"Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19343873\",\"name\":\"Zonghan Yang\"},{\"authorId\":\"145161800\",\"name\":\"Yong Cheng\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"9390452\",\"name\":\"Maosong Sun\"}],\"doi\":\"10.18653/v1/P19-1623\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ec5f3b55a90c1b32ad74dbe4423019d006b6bd3\",\"title\":\"Reducing Word Omission Errors in Neural Machine Translation: A Contrastive Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/1ec5f3b55a90c1b32ad74dbe4423019d006b6bd3\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"3249631\",\"name\":\"Kai-Can Li\"},{\"authorId\":\"2144249\",\"name\":\"Yi-Chun Kuo\"},{\"authorId\":\"38826848\",\"name\":\"Michelle Shu\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":\"10.1109/CVPR.2018.00602\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f44799620bf22f6efa01c35497de7dda3e5d4ab\",\"title\":\"Referring Image Segmentation via Recurrent Refinement Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f44799620bf22f6efa01c35497de7dda3e5d4ab\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19204816\",\"name\":\"Shuxiong Ye\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"},{\"authorId\":\"2168639\",\"name\":\"Kaiping Xu\"},{\"authorId\":\"145489794\",\"name\":\"K. Huang\"},{\"authorId\":\"1886528\",\"name\":\"Guolong Wang\"}],\"doi\":\"10.1007/978-3-319-77383-4_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f146e172205c6a1b9706dc0d6b9e39be35389b3\",\"title\":\"Semantic R-CNN for Natural Language Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/8f146e172205c6a1b9706dc0d6b9e39be35389b3\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1608.00272\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"3451188\",\"name\":\"Patrick Poirson\"},{\"authorId\":\"144947353\",\"name\":\"S. Yang\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46475-6_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"title\":\"Modeling Context in Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"49070447\",\"name\":\"Y. Chen\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f54252274514e8eb54adb6b9af7594f6189ec63a\",\"title\":\"Self-view Grounding Given a Narrated 360\\u00b0 Video\",\"url\":\"https://www.semanticscholar.org/paper/f54252274514e8eb54adb6b9af7594f6189ec63a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.07212\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"121704643\",\"name\":\"Yichen Li\"},{\"authorId\":\"145031845\",\"name\":\"Ke Xu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2020.3029008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"title\":\"Revisiting Image-Language Networks for Open-ended Phrase Detection.\",\"url\":\"https://www.semanticscholar.org/paper/0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941780\",\"name\":\"Zhiwei Hu\"},{\"authorId\":\"49081953\",\"name\":\"Guang Feng\"},{\"authorId\":\"1491083353\",\"name\":\"Jiayu Sun\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00448\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"31422b7cbcabe22d24975129fafe9a3258051b2d\",\"title\":\"Bi-Directional Relationship Inferring Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/31422b7cbcabe22d24975129fafe9a3258051b2d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":8745888,\"doi\":\"10.1109/CVPR.2016.9\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":89,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Zheng\"},{\"authorId\":null,\"name\":\"V. Vineet\"},{\"authorId\":null,\"name\":\"P. Sturgess\"},{\"authorId\":null,\"name\":\"N. Crook\"},{\"authorId\":null,\"name\":\"N. J. Mitra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Verbal guided image parsing\",\"url\":\"\",\"venue\":\"ACM Trans . Graphics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803066\",\"name\":\"A. Sadovnik\"},{\"authorId\":\"3437467\",\"name\":\"Yi-I Chiu\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"2331213\",\"name\":\"S. Edelman\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/CVPR.2012.6248003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d632b8ca64f804a02e9bcf4b3bd9cf3caba0fa9\",\"title\":\"Image description with a goal: Building efficient discriminating expressions for images\",\"url\":\"https://www.semanticscholar.org/paper/9d632b8ca64f804a02e9bcf4b3bd9cf3caba0fa9\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. L. Berg\"},{\"authorId\":null,\"name\":\"A. C. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"posing simple image descriptions using webscale ngrams\",\"url\":\"\",\"venue\":\"CoNLL , pages\",\"year\":2007},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921637\",\"name\":\"Dimitra Gkatzia\"},{\"authorId\":\"1681799\",\"name\":\"Verena Rieser\"},{\"authorId\":\"2002085\",\"name\":\"Phil J. Bartie\"},{\"authorId\":\"2428370\",\"name\":\"W. Mackaness\"}],\"doi\":\"10.18653/v1/D15-1224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e7f99c718e46c7515049ed3d1361a7d1658c8c\",\"title\":\"From the Virtual to the RealWorld: Referring to Objects in Real-World Spatial Scenes\",\"url\":\"https://www.semanticscholar.org/paper/e4e7f99c718e46c7515049ed3d1361a7d1658c8c\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1310.4389\",\"authors\":[{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"144147900\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"1730822\",\"name\":\"Wen-Yan Lin\"},{\"authorId\":\"1734784\",\"name\":\"J. Warrell\"},{\"authorId\":\"143729959\",\"name\":\"Vibhav Vineet\"},{\"authorId\":\"108557258\",\"name\":\"P. Sturgess\"},{\"authorId\":\"143902644\",\"name\":\"N. Crook\"},{\"authorId\":\"152908887\",\"name\":\"Niloy Mitra\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1145/2682628\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8c30d4cb0ef7966c9230fae0ad837c9de5a3ce9\",\"title\":\"ImageSpirit: Verbal Guided Image Parsing\",\"url\":\"https://www.semanticscholar.org/paper/d8c30d4cb0ef7966c9230fae0ad837c9de5a3ce9\",\"venue\":\"TOGS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ms coco captioning challenge. http://mscoco.org/ dataset/#captions-challenge2015\",\"url\":\"\",\"venue\":\"Ms coco captioning challenge. http://mscoco.org/ dataset/#captions-challenge2015\",\"year\":null},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O. Vinyals\"},{\"authorId\":null,\"name\":\"A. Toshev\"},{\"authorId\":null,\"name\":\"S. Bengio\"},{\"authorId\":null,\"name\":\"D. Erhan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Show and tell : A neural image caption generator Understanding natural language\",\"url\":\"\",\"venue\":\"Cognitive psychology\",\"year\":2008},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1383223659\",\"name\":\"Carlos A. Hern\\u00e1ndez\"},{\"authorId\":\"145876100\",\"name\":\"J. A. Gonzalez\"},{\"authorId\":\"83445446\",\"name\":\"A. L\\u00f3pez-L\\u00f3pez\"},{\"authorId\":\"1389780530\",\"name\":\"M. Montes-y-G\\u00f3mez\"},{\"authorId\":\"34970419\",\"name\":\"E. Morales\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"},{\"authorId\":\"1710020\",\"name\":\"L. Pineda\"},{\"authorId\":\"2426894\",\"name\":\"Michael Grubinger\"}],\"doi\":\"10.1016/j.cviu.2009.03.008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50a331a2adb66ecfd98052ede37be1799a671585\",\"title\":\"The segmented and annotated IAPR TC-12 benchmark\",\"url\":\"https://www.semanticscholar.org/paper/50a331a2adb66ecfd98052ede37be1799a671585\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143883142\",\"name\":\"Nicholas FitzGerald\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccbe74c9cef10571f3e0bfdde8c9af064b923531\",\"title\":\"Learning Distributions over Logical Forms for Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/ccbe74c9cef10571f3e0bfdde8c9af064b923531\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391682125\",\"name\":\"T. Winograd\"}],\"doi\":\"10.2307/1572810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb20f121c979b535bbeade5ac06676d627d4ad7d\",\"title\":\"Understanding Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/bb20f121c979b535bbeade5ac06676d627d4ad7d\",\"venue\":\"\",\"year\":1972},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. V. de Souza\"},{\"authorId\":null,\"name\":\"R. Mercer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ms coco captioning challenge\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2293129\",\"name\":\"Jette Viethen\"},{\"authorId\":\"144301565\",\"name\":\"R. Dale\"}],\"doi\":\"10.3115/1708322.1708334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50c1fd9658d2fc58eee72ed7b043b3f7cb735c87\",\"title\":\"The Use of Spatial Relations in Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/50c1fd9658d2fc58eee72ed7b043b3f7cb735c87\",\"venue\":\"INLG\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"},{\"authorId\":\"1742430\",\"name\":\"M. Theune\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43a31675d528d348106d9ebd615007234d3b7def\",\"title\":\"Efficient context-sensitive generation of referring expressions\",\"url\":\"https://www.semanticscholar.org/paper/43a31675d528d348106d9ebd615007234d3b7def\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2855180\",\"name\":\"Dave Golland\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"615f70728d7176acf83e310cdbcd763bbf6d5633\",\"title\":\"A Game-Theoretic Approach to Generating Spatial Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/615f70728d7176acf83e310cdbcd763bbf6d5633\",\"venue\":\"EMNLP\",\"year\":2010},{\"arxivId\":\"1508.06161\",\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"2464284\",\"name\":\"Scott Alan Bronikowski\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52a71d99e5f69b5702734333708ef1bbea8c89ec\",\"title\":\"Robot Language Learning, Generation, and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/52a71d99e5f69b5702734333708ef1bbea8c89ec\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1312.2249\",\"authors\":[{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"}],\"doi\":\"10.1109/CVPR.2014.276\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67fc0ec1d26f334b05fe66d2b7e0767b60fb73b6\",\"title\":\"Scalable Object Detection Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/67fc0ec1d26f334b05fe66d2b7e0767b60fb73b6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1503.04069\",\"authors\":[{\"authorId\":\"3035541\",\"name\":\"Klaus Greff\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"2865775\",\"name\":\"J. Koutn\\u00edk\"},{\"authorId\":\"71009239\",\"name\":\"Bastiaan Steunebrink\"},{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1109/tnnls.2016.2582924\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7976c2bacfbb194ddbe7fd10c2e50a545cf4081\",\"title\":\"LSTM: A Search Space Odyssey\",\"url\":\"https://www.semanticscholar.org/paper/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Hu\"},{\"authorId\":null,\"name\":\"H Xu\"},{\"authorId\":null,\"name\":\"M Rohrbach\"},{\"authorId\":null,\"name\":\"J Feng\"},{\"authorId\":null,\"name\":\"K Saenko\"},{\"authorId\":null,\"name\":\"T Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Natural language object retrieval. CVPR\",\"url\":\"\",\"venue\":\"Natural language object retrieval. CVPR\",\"year\":2016},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"},{\"authorId\":\"144568312\",\"name\":\"Ehud Reiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29dba003ef1c3f6242a9ab9d0ff26ec9bd68d059\",\"title\":\"Natural Reference to Objects in a Visual Domain\",\"url\":\"https://www.semanticscholar.org/paper/29dba003ef1c3f6242a9ab9d0ff26ec9bd68d059\",\"venue\":\"INLG\",\"year\":2010},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2696176\",\"name\":\"L. R. Bahl\"},{\"authorId\":\"32538203\",\"name\":\"Peter F. Brown\"},{\"authorId\":\"144856857\",\"name\":\"P. D. Souza\"},{\"authorId\":\"2474650\",\"name\":\"R. Mercer\"}],\"doi\":\"10.1109/ICASSP.1986.1169179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5f09ce0dd760857e0d0e4879f6e2543f04c5d33\",\"title\":\"Maximum mutual information estimation of hidden Markov model parameters for speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5f09ce0dd760857e0d0e4879f6e2543f04c5d33\",\"venue\":\"ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing\",\"year\":1986},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"},{\"authorId\":\"144568312\",\"name\":\"Ehud Reiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c40e743d12ae387cf844bdfd2e8a2c7c11add28a\",\"title\":\"Generating Expressions that Refer to Visible Objects\",\"url\":\"https://www.semanticscholar.org/paper/c40e743d12ae387cf844bdfd2e8a2c7c11add28a\",\"venue\":\"HLT-NAACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"},{\"authorId\":\"2512058\",\"name\":\"R. Kibble\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca9ab569017e38bff676c6c4359f25be9a068b8d\",\"title\":\"Information sharing - reference and presupposition in language generation and interpretation\",\"url\":\"https://www.semanticscholar.org/paper/ca9ab569017e38bff676c6c4359f25be9a068b8d\",\"venue\":\"CSLI lecture notes series\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"145388103\",\"name\":\"Daniel Lassiter\"}],\"doi\":\"10.1002/9781118882139.CH21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b86c2baf8bbff63c79a47797ac82778b75b72e03\",\"title\":\"Probabilistic Semantics and Pragmatics: Uncertainty in Language and Thought\",\"url\":\"https://www.semanticscholar.org/paper/b86c2baf8bbff63c79a47797ac82778b75b72e03\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48221821\",\"name\":\"S. Chapman\"}],\"doi\":\"10.1057/9780230005853_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b25e5bca74d74abb1687315fa3c637bb9911554d\",\"title\":\"Logic and Conversation\",\"url\":\"https://www.semanticscholar.org/paper/b25e5bca74d74abb1687315fa3c637bb9911554d\",\"venue\":\"\",\"year\":2005},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e6f47c4b2109e7824cd475336c3676faf9b113e\",\"title\":\"Baby Talk : Understanding and Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6e6f47c4b2109e7824cd475336c3676faf9b113e\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"},{\"authorId\":\"1699960\",\"name\":\"I. V. D. Sluis\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"}],\"doi\":\"10.3115/1706269.1706296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a611c1097a3e9c1cb762f156965d8ca23277f42e\",\"title\":\"Building a Semantically Transparent Corpus for the Generation of Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a611c1097a3e9c1cb762f156965d8ca23277f42e\",\"venue\":\"INLG\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Kulkarni V. Ordonez\"},{\"authorId\":null,\"name\":\"L. T.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Berg . Im 2 text : Describing images using 1 million captioned photographs\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Antol\"},{\"authorId\":null,\"name\":\"A Agrawal\"},{\"authorId\":null,\"name\":\"J Lu\"},{\"authorId\":null,\"name\":\"M Mitchell\"},{\"authorId\":null,\"name\":\"D Batra\"},{\"authorId\":null,\"name\":\"C L Zitnick\"},{\"authorId\":null,\"name\":\"D Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Vqa: Visual question answering. arXiv\",\"url\":\"\",\"venue\":\"Vqa: Visual question answering. arXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"},{\"authorId\":\"3766304\",\"name\":\"Abhaya Agarwal\"}],\"doi\":\"10.3115/1626355.1626389\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34d7a07c493ca6336c92156806a2947e115caadc\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/34d7a07c493ca6336c92156806a2947e115caadc\",\"venue\":\"WMT@ACL\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H P Grice\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Logic and conversation. na\",\"url\":\"\",\"venue\":\"Logic and conversation. na\",\"year\":1970},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2011.5995711\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec97294c1e5974c6b827f8fda67f2e96cf1d8339\",\"title\":\"Recognition using visual phrases\",\"url\":\"https://www.semanticscholar.org/paper/ec97294c1e5974c6b827f8fda67f2e96cf1d8339\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"}],\"doi\":\"10.1162/COLI_a_00088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee4fe11884eca58a76ea797f102bbd5c3c67137b\",\"title\":\"Computational Generation of Referring Expressions: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/ee4fe11884eca58a76ea797f102bbd5c3c67137b\",\"venue\":\"Computational Linguistics\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015}],\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"topics\":[{\"topic\":\"List comprehension\",\"topicId\":\"263264\",\"url\":\"https://www.semanticscholar.org/topic/263264\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Regular expression\",\"topicId\":\"48721\",\"url\":\"https://www.semanticscholar.org/topic/48721\"},{\"topic\":\"Sergio Verd\\u00fa\",\"topicId\":\"1663975\",\"url\":\"https://www.semanticscholar.org/topic/1663975\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Berg connector\",\"topicId\":\"2642300\",\"url\":\"https://www.semanticscholar.org/topic/2642300\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Minds and Machines\",\"topicId\":\"1003374\",\"url\":\"https://www.semanticscholar.org/topic/1003374\"}],\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"