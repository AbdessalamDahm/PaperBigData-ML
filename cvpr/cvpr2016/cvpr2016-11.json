"{\"abstract\":\"Anticipating actions and objects before they start or appear is a difficult problem in computer vision with several real-world applications. This task is challenging partly because it requires leveraging extensive knowledge of the world that is difficult to write down. We believe that a promising resource for efficiently learning this knowledge is through readily available unlabeled video. We present a framework that capitalizes on temporal structure in unlabeled video to learn to anticipate human actions and objects. The key idea behind our approach is that we can train deep networks to predict the visual representation of images in the future. Visual representations are a promising prediction target because they encode images at a higher semantic level than pixels yet are automatic to compute. We then apply recognition algorithms on our predicted representation to anticipate objects and actions. We experimentally validate this idea on two datasets, anticipating actions one second in the future and objects five seconds in the future.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\",\"url\":\"https://www.semanticscholar.org/author/1856025\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\",\"url\":\"https://www.semanticscholar.org/author/2367683\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805211\"}],\"citationVelocity\":74,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"145817168\",\"name\":\"D. Scott\"},{\"authorId\":\"1707342\",\"name\":\"J. Breslin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c31819c917981b6946accaa9be9399b810c624c\",\"title\":\"EMNLP 2016 Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods\",\"url\":\"https://www.semanticscholar.org/paper/4c31819c917981b6946accaa9be9399b810c624c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Tgt . ( a ) GT sequence ( b ) ImagineFlow ( c ) Backward warping Before After\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108323879\",\"name\":\"Timothy Lewis\"},{\"authorId\":\"2674440\",\"name\":\"Cynthia Matuszek\"},{\"authorId\":\"47505369\",\"name\":\"A. Hurst\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":\"10.18653/v1/W16-6011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d60dbd0c08a7e2a1fbacf58f37023060e8cbc69\",\"title\":\"Using Language Groundings for Context-Sensitive Text Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6d60dbd0c08a7e2a1fbacf58f37023060e8cbc69\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2003.03530\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"150352016\",\"name\":\"Yanzhou Su\"},{\"authorId\":\"144941515\",\"name\":\"Y. Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2de59074948bca0c0a4919bba03229477f65e821\",\"title\":\"TTPP: Temporal Transformer with Progressive Prediction for Efficient Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2de59074948bca0c0a4919bba03229477f65e821\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"47839088\",\"name\":\"K. Kim\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.5626/KTCP.2018.24.3.138\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"265e1fee7452c346d5d14fad5ddfd6d2dfdd25de\",\"title\":\"ViStoryNet: Neural Networks with Successive Event Order Embedding and BiLSTMs for Video Story Regeneration\",\"url\":\"https://www.semanticscholar.org/paper/265e1fee7452c346d5d14fad5ddfd6d2dfdd25de\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1807.06980\",\"authors\":[{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33240704f9efc39f75b4229983c2e10a56ca609f\",\"title\":\"Video Time: Properties, Encoders and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/33240704f9efc39f75b4229983c2e10a56ca609f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1705.07328\",\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"46664397\",\"name\":\"Jangwon Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3a8f40af25b5b4a23639f18f9daefd39757a4f67\",\"title\":\"Forecasting Hand and Object Locations in Future Frames\",\"url\":\"https://www.semanticscholar.org/paper/3a8f40af25b5b4a23639f18f9daefd39757a4f67\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2018.2882805\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02c293bc06c580305c8b62a8ed90f37a75608493\",\"title\":\"Adversarial Action Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/02c293bc06c580305c8b62a8ed90f37a75608493\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1807.09245\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/TPAMI.2018.2854726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a217bebb97cb94968f2d476bdf00612019d08be2\",\"title\":\"Visual Dynamics: Stochastic Future Generation via Layered Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/a217bebb97cb94968f2d476bdf00612019d08be2\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"2998590\",\"name\":\"Paul Vernaza\"}],\"doi\":\"10.1007/978-3-030-01261-8_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a36530e30b34f4f057b097dfbb952c794ec52f41\",\"title\":\"r2p2: A ReparameteRized Pushforward Policy for Diverse, Precise Generative Path Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/a36530e30b34f4f057b097dfbb952c794ec52f41\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2006.04700\",\"authors\":[{\"authorId\":\"22221620\",\"name\":\"Osama Makansi\"},{\"authorId\":\"3422575\",\"name\":\"\\u00d6zg\\u00fcn \\u00c7i\\u00e7ek\"},{\"authorId\":\"1739646797\",\"name\":\"Kevin Buchicchio\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/cvpr42600.2020.00441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"609407e2087f1ab4cfa4172ac070db91540d0118\",\"title\":\"Multimodal Future Localization and Emergence Prediction for Objects in Egocentric View With a Reachability Prior\",\"url\":\"https://www.semanticscholar.org/paper/609407e2087f1ab4cfa4172ac070db91540d0118\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143727953\",\"name\":\"A. Wu\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/s11263-019-01238-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"879a6970d46e6a22f45875f404e067148dcd326c\",\"title\":\"Model-Based Robot Imitation with Future Image Similarity\",\"url\":\"https://www.semanticscholar.org/paper/879a6970d46e6a22f45875f404e067148dcd326c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35494343\",\"name\":\"Pranjal Sahu\"},{\"authorId\":\"33830021\",\"name\":\"D. Yu\"},{\"authorId\":\"1780708\",\"name\":\"K. Yager\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"145199626\",\"name\":\"H. Qin\"}],\"doi\":\"10.1145/3217197.3217204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc4b1a6ac94d3af019d4a0db089cafa6b5c701cb\",\"title\":\"In-Operando Tracking and Prediction of Transition in Material System using LSTM\",\"url\":\"https://www.semanticscholar.org/paper/dc4b1a6ac94d3af019d4a0db089cafa6b5c701cb\",\"venue\":\"AI-Science@HPDC\",\"year\":2018},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1907.01172\",\"authors\":[{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-58621-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71992656ff50c56adcbe6e99fca7eecac446d70a\",\"title\":\"Procedure Planning in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/71992656ff50c56adcbe6e99fca7eecac446d70a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/CVPR.2017.390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa3e3f4f1159e3af45a32eb0b3e206204d201721\",\"title\":\"Deep Sequential Context Networks for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa3e3f4f1159e3af45a32eb0b3e206204d201721\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267f3674d02ab3b53e0ac58e082380547b0bbf1c\",\"title\":\"Beyond Labels and Captions: Contextualizing Grounded Semantics for Explainable Visual Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/267f3674d02ab3b53e0ac58e082380547b0bbf1c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144882773\",\"name\":\"Arnau Bar\\u00f3\"},{\"authorId\":\"40420775\",\"name\":\"Pau Riba\"},{\"authorId\":\"1388521984\",\"name\":\"Jorge Calvo-Zaragoza\"},{\"authorId\":\"1686569\",\"name\":\"A. Forn\\u00e9s\"}],\"doi\":\"10.1007/978-3-030-02284-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3c337a1b48086ea8df89edecf58592527fdf40e\",\"title\":\"Optical Music Recognition by Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/d3c337a1b48086ea8df89edecf58592527fdf40e\",\"venue\":\"GREC\",\"year\":2017},{\"arxivId\":\"1908.09540\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00151\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae19f940eed7521339078dd4ab5a01f371039e2a\",\"title\":\"Uncertainty-Aware Anticipation of Activities\",\"url\":\"https://www.semanticscholar.org/paper/ae19f940eed7521339078dd4ab5a01f371039e2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9400214\",\"name\":\"Guangxing Han\"},{\"authorId\":\"37735027\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"3244057\",\"name\":\"Chongrong Li\"}],\"doi\":\"10.1145/3240508.3240693\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5bacb5489537012805e88ad7f4f70c96a438f88\",\"title\":\"Semi-Supervised DFF: Decoupling Detection and Feature Flow for Video Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/c5bacb5489537012805e88ad7f4f70c96a438f88\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2007.00548\",\"authors\":[{\"authorId\":\"1388594887\",\"name\":\"Dominik Rivoir\"},{\"authorId\":\"2462340\",\"name\":\"S. Bodenstedt\"},{\"authorId\":\"40917135\",\"name\":\"Isabel Funke\"},{\"authorId\":\"150996210\",\"name\":\"F. Bechtolsheim\"},{\"authorId\":\"113945674\",\"name\":\"M. Distler\"},{\"authorId\":\"143997715\",\"name\":\"J. Weitz\"},{\"authorId\":\"47515221\",\"name\":\"S. Speidel\"}],\"doi\":\"10.1007/978-3-030-59716-0_72\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"084577134a1e5a8e21355a1217c29c44976a07da\",\"title\":\"Rethinking Anticipation Tasks: Uncertainty-aware Anticipation of Sparse Surgical Instrument Usage for Context-aware Assistance\",\"url\":\"https://www.semanticscholar.org/paper/084577134a1e5a8e21355a1217c29c44976a07da\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"1904.10666\",\"authors\":[{\"authorId\":\"3306760\",\"name\":\"Hsu-Kuang Chiu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/LRA.2020.2992184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73c28cef6c0d58b101204609137af39c3e94c047\",\"title\":\"Segmenting the Future\",\"url\":\"https://www.semanticscholar.org/paper/73c28cef6c0d58b101204609137af39c3e94c047\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26923471\",\"name\":\"T. Chalen\"},{\"authorId\":\"3164610\",\"name\":\"B. Vintimilla\"}],\"doi\":\"10.1109/LA-CCI47412.2019.9037051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d98987f6ccada446e6dc50b02446e2027c06eec\",\"title\":\"Towards Action Prediction Applying Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2d98987f6ccada446e6dc50b02446e2027c06eec\",\"venue\":\"2019 IEEE Latin American Conference on Computational Intelligence (LA-CCI)\",\"year\":2019},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.02634\",\"authors\":[{\"authorId\":\"3319373\",\"name\":\"Dirk Weissenborn\"},{\"authorId\":\"2556289\",\"name\":\"Oscar T\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e763fdc9ae56826ff799163ea035b29bffd8ea6f\",\"title\":\"Scaling Autoregressive Video Models\",\"url\":\"https://www.semanticscholar.org/paper/e763fdc9ae56826ff799163ea035b29bffd8ea6f\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1801.04134\",\"authors\":[{\"authorId\":\"35309584\",\"name\":\"Jonas Rothfuss\"},{\"authorId\":\"145839029\",\"name\":\"F. Ferreira\"},{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"46432716\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/LRA.2018.2860057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"970a8f1655ab329cba5fe26edf543e62fe354376\",\"title\":\"Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution\",\"url\":\"https://www.semanticscholar.org/paper/970a8f1655ab329cba5fe26edf543e62fe354376\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":\"1906.06521\",\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfdd73269882b6d512786f64118a305aea18e43b\",\"title\":\"Delving into 3D Action Anticipation from Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/bfdd73269882b6d512786f64118a305aea18e43b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.12699\",\"authors\":[{\"authorId\":\"8792285\",\"name\":\"Olivia Wiles\"},{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCVW.2019.00364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc5b45133858b7a182efb665836fbcf7d7e19194\",\"title\":\"Self-Supervised Learning of Class Embeddings from Video\",\"url\":\"https://www.semanticscholar.org/paper/bc5b45133858b7a182efb665836fbcf7d7e19194\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1803.10861\",\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"title\":\"Memory Warps for Learning Long-Term Online Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.01040\",\"authors\":[{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2017.63\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6c95b567701f38fe3d87bbd56e3da9ad5ee35ca\",\"title\":\"Learning Robot Activities from First-Person Human Videos Using Convolutional Future Regression\",\"url\":\"https://www.semanticscholar.org/paper/b6c95b567701f38fe3d87bbd56e3da9ad5ee35ca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1909.04656\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCVW.2019.00186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"title\":\"Video Representation Learning by Dense Predictive Coding\",\"url\":\"https://www.semanticscholar.org/paper/0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1906.05261\",\"authors\":[{\"authorId\":\"1398347979\",\"name\":\"M. Mar\\u00edn-Jim\\u00e9nez\"},{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"1417336005\",\"name\":\"Pablo Medina-Suarez\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ede2b6e05c06c218fcc10a54bee93fe35568a72c\",\"title\":\"LAEO-Net: Revisiting People Looking at Each Other in Videos\",\"url\":\"https://www.semanticscholar.org/paper/ede2b6e05c06c218fcc10a54bee93fe35568a72c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41c853eebc563cc6dde2df32fbaca816ce0bab3e\",\"title\":\"Perceptual Prediction Error Detection Learning Signal Learning Signal\",\"url\":\"https://www.semanticscholar.org/paper/41c853eebc563cc6dde2df32fbaca816ce0bab3e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"134686414\",\"name\":\"Riccardo Volpi\"},{\"authorId\":\"1389596256\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/s11263-019-01234-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2734eeef756657296857068d386521c58228ef5b\",\"title\":\"Predicting Intentions from Motion: The Subject-Adversarial Adaptation Approach\",\"url\":\"https://www.semanticscholar.org/paper/2734eeef756657296857068d386521c58228ef5b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1808.04063\",\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"2057809\",\"name\":\"G. Zhou\"},{\"authorId\":\"3004771\",\"name\":\"L. Bornn\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1751a191e76eb57b1e132cf3ed3bb5964b3ddfe7\",\"title\":\"Time Perception Machine: Temporal Point Processes for the When, Where and What of Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1751a191e76eb57b1e132cf3ed3bb5964b3ddfe7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.07796\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2017.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"title\":\"First-Person Activity Forecasting with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643866905\",\"name\":\"Rogfel Thompson Martinez\"},{\"authorId\":\"2752591\",\"name\":\"S. C. Alfaro\"}],\"doi\":\"10.5772/INTECHOPEN.91184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b7f05fd5e64b1baaacc40101d6e73de5038dc66\",\"title\":\"Data Analysis and Modeling Techniques of Welding Processes: The State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/2b7f05fd5e64b1baaacc40101d6e73de5038dc66\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1606.07839\",\"authors\":[{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"37824829\",\"name\":\"M. Cogswell\"},{\"authorId\":\"2673180\",\"name\":\"Viresh Ranjan\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c659f4ca9b7e75abf77133c54ad830ed4ebc0ff0\",\"title\":\"Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles\",\"url\":\"https://www.semanticscholar.org/paper/c659f4ca9b7e75abf77133c54ad830ed4ebc0ff0\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"34465973\",\"name\":\"A. Koul\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"db40065a98378b417cf68871a0081944310cb83f\",\"title\":\"Predicting Human Intentions from Motion Only: A 2D+3D Fusion Approach\",\"url\":\"https://www.semanticscholar.org/paper/db40065a98378b417cf68871a0081944310cb83f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1702.08626\",\"authors\":[{\"authorId\":\"1711521\",\"name\":\"A. H. Qureshi\"},{\"authorId\":\"38035941\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"2836701\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"1687808\",\"name\":\"H. Ishiguro\"}],\"doi\":\"10.1109/ICRA.2017.7989193\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36295388bce75619b7184560833aeb5ae0cd0a91\",\"title\":\"Show, attend and interact: Perceivable human-robot social interaction through neural attention Q-network\",\"url\":\"https://www.semanticscholar.org/paper/36295388bce75619b7184560833aeb5ae0cd0a91\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1007/s11263-016-0982-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"048169db1243b6d4bd8c4d9bdccfd2526dcfe568\",\"title\":\"Max-Margin Heterogeneous Information Machine for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048169db1243b6d4bd8c4d9bdccfd2526dcfe568\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.05869\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"47988509\",\"name\":\"J. Yang\"},{\"authorId\":\"47707394\",\"name\":\"Shenghao Zhou\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7da0a3dabdc9b9633432d94c085e06476ab1bae9\",\"title\":\"Keyframing the Future: Keyframe Discovery for Visual Prediction and Planning\",\"url\":\"https://www.semanticscholar.org/paper/7da0a3dabdc9b9633432d94c085e06476ab1bae9\",\"venue\":\"L4DC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"49728738\",\"name\":\"T. Serre\"}],\"doi\":\"10.1111/nyas.14320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"title\":\"Beyond the feedforward sweep: feedback computations in the visual cortex\",\"url\":\"https://www.semanticscholar.org/paper/83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"venue\":\"Annals of the New York Academy of Sciences\",\"year\":2020},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144371270\",\"name\":\"M. Kumar\"},{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46573521\",\"name\":\"Laurent Dinh\"},{\"authorId\":\"70429380\",\"name\":\"Durk Kingma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c740302dddf0e54c50c43110716f987edd73329b\",\"title\":\"VideoFlow: A Flow-Based Generative Model for Video\",\"url\":\"https://www.semanticscholar.org/paper/c740302dddf0e54c50c43110716f987edd73329b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1906.12340\",\"authors\":[{\"authorId\":\"3422872\",\"name\":\"Dan Hendrycks\"},{\"authorId\":\"16787428\",\"name\":\"Mantas Mazeika\"},{\"authorId\":\"148070327\",\"name\":\"Saurav Kadavath\"},{\"authorId\":\"153801801\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"db787640c9b42416ff8d7015546e667e58267177\",\"title\":\"Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/db787640c9b42416ff8d7015546e667e58267177\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/IROS.2017.8205953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312\",\"title\":\"Learning robot activities from first-person human videos using convolutional future regression\",\"url\":\"https://www.semanticscholar.org/paper/e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1705.08918\",\"authors\":[{\"authorId\":null,\"name\":\"Liang Zhao\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aafebe09b9d7fe12afbcb0e6d701459f950554c9\",\"title\":\"Unsupervised Learning Layers for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/aafebe09b9d7fe12afbcb0e6d701459f950554c9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2318546\",\"name\":\"Shiping Wen\"},{\"authorId\":\"49663634\",\"name\":\"W. Liu\"},{\"authorId\":\"46286125\",\"name\":\"Y. Yang\"},{\"authorId\":\"145582475\",\"name\":\"T. Huang\"},{\"authorId\":\"145043786\",\"name\":\"Z. Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2867934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84e5e611baa362ccce571eef737c98de7a5331b5\",\"title\":\"Generating Realistic Videos From Keyframes With Concatenated GANs\",\"url\":\"https://www.semanticscholar.org/paper/84e5e611baa362ccce571eef737c98de7a5331b5\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144221742\",\"name\":\"Yifang Yin\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.1145/3240508.3240631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed6d21801ab632f771828ca76d08184e021b48e9\",\"title\":\"Learning and Fusing Multimodal Deep Features for Acoustic Scene Categorization\",\"url\":\"https://www.semanticscholar.org/paper/ed6d21801ab632f771828ca76d08184e021b48e9\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.194\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1808.05561\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1145/3240508.3240578\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540831094fd9b80469c8dacb9320b7e342b50e03\",\"title\":\"Emotion Recognition in Speech using Cross-Modal Transfer in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/540831094fd9b80469c8dacb9320b7e342b50e03\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"143880942\",\"name\":\"Q. Nguyen\"},{\"authorId\":\"7641415\",\"name\":\"Stephen Hammer\"},{\"authorId\":\"143836309\",\"name\":\"J. Kent\"},{\"authorId\":null,\"name\":\"John R. Smith\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1145/3123266.3127924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dceee8e3ce2ec5aaafd6915ffc4439e136f1abc2\",\"title\":\"IBM High-Five: Highlights From Intelligent Video Engine\",\"url\":\"https://www.semanticscholar.org/paper/dceee8e3ce2ec5aaafd6915ffc4439e136f1abc2\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2312486\",\"name\":\"Chaochao Lu\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":\"10.1109/CVPR.2017.230\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e52f73c77c7eaece6f2d8fdd0f15327f9f007261\",\"title\":\"Flexible Spatio-Temporal Networks for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e52f73c77c7eaece6f2d8fdd0f15327f9f007261\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.04818\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.92\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"title\":\"RED: Reinforced Encoder-Decoder Networks for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"15702255\",\"name\":\"M. Billah\"},{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc2aa32e5ee30ba71bd6fb708cd70bdea0cedbe8\",\"title\":\"Captioning Near-Future Activity Sequences\",\"url\":\"https://www.semanticscholar.org/paper/dc2aa32e5ee30ba71bd6fb708cd70bdea0cedbe8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.08317\",\"authors\":[{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47b0e2fde37b3d1810a5b5a19597765fd76c691e\",\"title\":\"Temporal Interpolation as an Unsupervised Pretraining Task for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/47b0e2fde37b3d1810a5b5a19597765fd76c691e\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727999\",\"name\":\"Gierad Laput\"},{\"authorId\":\"3451315\",\"name\":\"K. Ahuja\"},{\"authorId\":\"4646339\",\"name\":\"Mayank Goel\"},{\"authorId\":\"145078227\",\"name\":\"C. Harrison\"}],\"doi\":\"10.1145/3242587.3242609\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"122bb67c7f04892bd2ce22848e7c4270070a3a09\",\"title\":\"Ubicoustics: Plug-and-Play Acoustic Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/122bb67c7f04892bd2ce22848e7c4270070a3a09\",\"venue\":\"UIST\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145222076\",\"name\":\"Tianyu Zhang\"},{\"authorId\":\"2366119\",\"name\":\"Weiqing Min\"},{\"authorId\":\"27730334\",\"name\":\"Ying Zhu\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3394171.3413964\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10066d89b96b8baac518c994f23278b817994a12\",\"title\":\"An Egocentric Action Anticipation Framework via Fusing Intuition and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/10066d89b96b8baac518c994f23278b817994a12\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1907.11475\",\"authors\":[{\"authorId\":\"101947437\",\"name\":\"J. Saric\"},{\"authorId\":\"3009751\",\"name\":\"M. Orsic\"},{\"authorId\":\"2111962\",\"name\":\"Tonci Antunovic\"},{\"authorId\":\"3237756\",\"name\":\"Sacha Vrazic\"},{\"authorId\":\"3166278\",\"name\":\"Sinisa Segvic\"}],\"doi\":\"10.1007/978-3-030-33676-9_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cceeaf0deec726961dc1627e786943f3cbdcbe1c\",\"title\":\"Single Level Feature-to-Feature Forecasting with Deformable Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/cceeaf0deec726961dc1627e786943f3cbdcbe1c\",\"venue\":\"GCPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":null,\"name\":\"Bicheng Xu\"},{\"authorId\":\"2057809\",\"name\":\"G. Zhou\"},{\"authorId\":\"3004771\",\"name\":\"L. Bornn\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"883e59ac3e386023d6ad8ef97d5c881a2009741c\",\"title\":\"Next : When , Where , What ? \\u201c Pass \\u201d \\u201c Receive \\u201d \\u201c Carry \\u201d \\u201c Dump \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/883e59ac3e386023d6ad8ef97d5c881a2009741c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.02675\",\"authors\":[{\"authorId\":\"40290798\",\"name\":\"T. Suzuki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00371\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7aa69b348701f8efb7bc04f36e93ef85ec8a017\",\"title\":\"Anticipating Traffic Accidents with Adaptive Loss and Large-Scale Incident DB\",\"url\":\"https://www.semanticscholar.org/paper/a7aa69b348701f8efb7bc04f36e93ef85ec8a017\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3221527\",\"name\":\"Z. Kilimci\"},{\"authorId\":\"73494793\",\"name\":\"Aykut G\\u00fcven\"},{\"authorId\":\"2750036\",\"name\":\"M. Uysal\"},{\"authorId\":\"3249050\",\"name\":\"S. Akyoku\\u015f\"}],\"doi\":\"10.1155/2019/6434578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a09382d790eb85a9163b839292ac6690b9854b92\",\"title\":\"Mood Detection from Physical and Neurophysical Data Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/a09382d790eb85a9163b839292ac6690b9854b92\",\"venue\":\"Complex.\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICCV.2017.616\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"25403c52a7c3092866773b0e765ab55841d3cb67\",\"title\":\"Joint Prediction of Activity Labels and Starting Times in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/25403c52a7c3092866773b0e765ab55841d3cb67\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9384558\",\"name\":\"Runsheng Yu\"},{\"authorId\":\"46451107\",\"name\":\"Zhenyu Shi\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8d8501595f38974e001a66752dc7098db13dfec\",\"title\":\"Unsupervised Learning aids Prediction: Using Future Representation Learning Variantial Autoencoder for Human Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8d8501595f38974e001a66752dc7098db13dfec\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.09760\",\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69f7045d901dab5e949948a16beb89a4b0b38c15\",\"title\":\"Predicting the Future with Transformational States\",\"url\":\"https://www.semanticscholar.org/paper/69f7045d901dab5e949948a16beb89a4b0b38c15\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144575264\",\"name\":\"H. Chen\"},{\"authorId\":\"152141369\",\"name\":\"Yifan Deng\"},{\"authorId\":\"2998493\",\"name\":\"Shiwen Cheng\"},{\"authorId\":null,\"name\":\"Yixuan Wang\"},{\"authorId\":\"48219791\",\"name\":\"Dongmei Jiang\"},{\"authorId\":\"151486921\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1145/3347320.3357690\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d9ff2905896fa52fd9296d75e2de27ffa59f9f1\",\"title\":\"Efficient Spatial Temporal Convolutional Features for Audiovisual Continuous Affect Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d9ff2905896fa52fd9296d75e2de27ffa59f9f1\",\"venue\":\"AVEC@MM\",\"year\":2019},{\"arxivId\":\"2004.02753\",\"authors\":[{\"authorId\":\"1612061859\",\"name\":\"Joshua Knights\"},{\"authorId\":\"1612351216\",\"name\":\"Anthony Vanderkop\"},{\"authorId\":\"143679553\",\"name\":\"D. Ward\"},{\"authorId\":\"1612210724\",\"name\":\"Olivia Mackenzie-Ross\"},{\"authorId\":\"145136889\",\"name\":\"P. Moghadam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"195a51f9e4be3537f930d87f5200e63a51b9a226\",\"title\":\"Temporally Coherent Embeddings for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/195a51f9e4be3537f930d87f5200e63a51b9a226\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.03631\",\"authors\":[{\"authorId\":\"22221620\",\"name\":\"Osama Makansi\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"3422575\",\"name\":\"\\u00d6zg\\u00fcn \\u00c7i\\u00e7ek\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2019.00731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39d7613f13526852e2330a11686d17d94df41c33\",\"title\":\"Overcoming Limitations of Mixture Density Networks: A Sampling and Fitting Framework for Multimodal Future Prediction\",\"url\":\"https://www.semanticscholar.org/paper/39d7613f13526852e2330a11686d17d94df41c33\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.03705\",\"authors\":[{\"authorId\":\"1410629683\",\"name\":\"Xiaoxiao Du\"},{\"authorId\":\"145386932\",\"name\":\"R. Vasudevan\"},{\"authorId\":\"1389944402\",\"name\":\"M. Johnson-Roberson\"}],\"doi\":\"10.1109/LRA.2019.2895266\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f8944eb08c103f395485e9ee976fa898342ce2f\",\"title\":\"Bio-LSTM: A Biomechanically Inspired Recurrent Neural Network for 3-D Pedestrian Pose and Gait Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6f8944eb08c103f395485e9ee976fa898342ce2f\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.01191\",\"authors\":[{\"authorId\":\"3334896\",\"name\":\"Timo Milbich\"},{\"authorId\":\"144258123\",\"name\":\"Miguel \\u00c1ngel Bautista\"},{\"authorId\":\"38486173\",\"name\":\"E. Sutter\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1109/ICCV.2017.471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95deb62b82ede5c6732c5c498d3f9452866eaba7\",\"title\":\"Unsupervised Video Understanding by Reconciliation of Posture Similarities\",\"url\":\"https://www.semanticscholar.org/paper/95deb62b82ede5c6732c5c498d3f9452866eaba7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720818\",\"name\":\"Sebastian Agethen\"},{\"authorId\":\"3245101\",\"name\":\"Hu-Cheng Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/CVPRW.2019.00357\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"73a006022a64a7de18cd99ba7c7cb570e0566e38\",\"title\":\"Anticipation of Human Actions With Pose-Based Fine-Grained Representations\",\"url\":\"https://www.semanticscholar.org/paper/73a006022a64a7de18cd99ba7c7cb570e0566e38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICIP.2019.8803534\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee5eac18cb8f201c44d7aa5fa3ca677b8d4d3da5\",\"title\":\"Egocentric Action Anticipation by Disentangling Encoding and Inference\",\"url\":\"https://www.semanticscholar.org/paper/ee5eac18cb8f201c44d7aa5fa3ca677b8d4d3da5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"103356373\",\"name\":\"Kunyi Lu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TPAMI.2019.2951667\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64dadf96304f65af96fc6b4f82c11bc69589f547\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/64dadf96304f65af96fc6b4f82c11bc69589f547\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1804.00892\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00560\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"title\":\"When will you do what? - Anticipating Temporal Occurrences of Activities\",\"url\":\"https://www.semanticscholar.org/paper/33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.02735\",\"authors\":[{\"authorId\":\"2067767\",\"name\":\"A. Canziani\"},{\"authorId\":\"2889774\",\"name\":\"E. Culurciello\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709cc149b7e17d03b8b92c181a98d6e44ad782e6\",\"title\":\"CortexNet: a Generic Network Family for Robust Visual Temporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/709cc149b7e17d03b8b92c181a98d6e44ad782e6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2007.04687\",\"authors\":[{\"authorId\":\"2678268\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"9754502\",\"name\":\"Yujia Shi\"},{\"authorId\":\"5264927\",\"name\":\"Yujia Sun\"},{\"authorId\":\"1802542506\",\"name\":\"Fangtao Shao\"},{\"authorId\":\"48551946\",\"name\":\"Zhaoyang Wu\"},{\"authorId\":\"40615725\",\"name\":\"Zhiwei Yang\"}],\"doi\":\"10.1007/978-3-030-58577-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f28873be3601c5a2736996eba543cf51950a381\",\"title\":\"Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/8f28873be3601c5a2736996eba543cf51950a381\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152978200\",\"name\":\"X. Guo\"},{\"authorId\":\"47896751\",\"name\":\"W. Zhong\"},{\"authorId\":\"46269770\",\"name\":\"L. Ye\"},{\"authorId\":\"145683627\",\"name\":\"L. Fang\"},{\"authorId\":\"20481570\",\"name\":\"Y. Heng\"},{\"authorId\":\"145711569\",\"name\":\"Qin Zhang\"}],\"doi\":\"10.1007/978-3-030-37734-2_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8fa715d9ba6078583be1249e8ceb8db0cfa6960\",\"title\":\"Global Affective Video Content Regression Based on Complementary Audio-Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/d8fa715d9ba6078583be1249e8ceb8db0cfa6960\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1904.12165\",\"authors\":[{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2019.00770\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08a80e33fc646482b9fedc9f153238d960d670e5\",\"title\":\"Improved Conditional VRNNs for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/08a80e33fc646482b9fedc9f153238d960d670e5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.03157\",\"authors\":[{\"authorId\":\"46840646\",\"name\":\"A. Wu\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e35eb21a69178aba00205073d34ec9b2ee499c\",\"title\":\"Model-based Behavioral Cloning with Future Image Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8e35eb21a69178aba00205073d34ec9b2ee499c\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1007/978-3-030-01225-0_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"title\":\"Scaling Egocentric Vision: The Dataset\",\"url\":\"https://www.semanticscholar.org/paper/443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1806.04422\",\"authors\":[{\"authorId\":\"49732389\",\"name\":\"D. Feng\"},{\"authorId\":\"40560919\",\"name\":\"Kele Xu\"},{\"authorId\":\"40565983\",\"name\":\"Haibo Mi\"},{\"authorId\":\"51019727\",\"name\":\"Feifan Liao\"},{\"authorId\":\"1692274\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1007/978-3-319-97289-3_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b67d3e20f8f3aff16367c298c35f0df59db9099e\",\"title\":\"Sample Dropout for Audio Scene Classification Using Multi-Scale Dense Connected Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b67d3e20f8f3aff16367c298c35f0df59db9099e\",\"venue\":\"PKAW\",\"year\":2018},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34238057\",\"name\":\"SeungJin Lee\"},{\"authorId\":\"40984270\",\"name\":\"Dongil Shin\"},{\"authorId\":\"1742563\",\"name\":\"Dongkyoo Shin\"}],\"doi\":\"10.1145/3368926.3369661\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f911cbc1e59a4f3e48b99033ac595a98a7b9e2af\",\"title\":\"Sensor-based Abnormal Behavior Detection Using Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/f911cbc1e59a4f3e48b99033ac595a98a7b9e2af\",\"venue\":\"SoICT 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22803355\",\"name\":\"Beibei Jin\"},{\"authorId\":\"144985887\",\"name\":\"Y. Hu\"},{\"authorId\":\"145492828\",\"name\":\"Y. Zeng\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"32758259\",\"name\":\"Shice Liu\"},{\"authorId\":\"144030865\",\"name\":\"Jing Ye\"}],\"doi\":\"10.1109/IROS.2018.8594264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9431e81519d16c87859a55bb1735f61a9e013f7e\",\"title\":\"VarNet: Exploring Variations for Unsupervised Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9431e81519d16c87859a55bb1735f61a9e013f7e\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"2008.09154\",\"authors\":[{\"authorId\":\"3468426\",\"name\":\"Athanasios Vlontzos\"},{\"authorId\":\"10757438\",\"name\":\"Henrique Bergallo Rocha\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"2015193\",\"name\":\"Bernhard Kainz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef9f35af432109c1f9bb5f428ea13d65ae1aeb94\",\"title\":\"Causal Future Prediction in a Minkowski Space-Time\",\"url\":\"https://www.semanticscholar.org/paper/ef9f35af432109c1f9bb5f428ea13d65ae1aeb94\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbe18855b85bc6f218c53993cf289e2607518b1\",\"title\":\"Learning Policies to Forecast Agent Behavior with Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/6dbe18855b85bc6f218c53993cf289e2607518b1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.14620\",\"authors\":[{\"authorId\":\"3027512\",\"name\":\"M. Zieba\"},{\"authorId\":\"147572870\",\"name\":\"Marcin Przewiezlikowski\"},{\"authorId\":\"49688210\",\"name\":\"M. Smieja\"},{\"authorId\":\"145541197\",\"name\":\"J. Tabor\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"},{\"authorId\":\"153673689\",\"name\":\"Przemys\\u0142aw Spurek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4836cad4b69b09e6002ddb1921df173d31c91dcb\",\"title\":\"RegFlow: Probabilistic Flow-based Regression for Future Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4836cad4b69b09e6002ddb1921df173d31c91dcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47535981\",\"name\":\"Chuanhe Liu\"},{\"authorId\":\"2342818\",\"name\":\"T. Tang\"},{\"authorId\":\"47734596\",\"name\":\"K. Lv\"},{\"authorId\":\"47447148\",\"name\":\"Minghao Wang\"}],\"doi\":\"10.1145/3242969.3264989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"389266c1cb73a7918d599be659d91e7fb7f431df\",\"title\":\"Multi-Feature Based Emotion Recognition for Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/389266c1cb73a7918d599be659d91e7fb7f431df\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":\"1609.06377\",\"authors\":[{\"authorId\":\"2071658\",\"name\":\"R. Mahjourian\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1109/IVS.2017.7995953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"905214ad6874bbd462a2d58089abef5e43ab857e\",\"title\":\"Geometry-based next frame prediction from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/905214ad6874bbd462a2d58089abef5e43ab857e\",\"venue\":\"2017 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643682004\",\"name\":\"He Zhao\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-58526-6_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd941a3cb2664715269cbbd30a4df6828799ac01\",\"title\":\"On Diverse Asynchronous Activity Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/bd941a3cb2664715269cbbd30a4df6828799ac01\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.05553\",\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-20873-8_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"title\":\"On Learning Associations of Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500415699\",\"name\":\"Prathmesh Sambrekar\"},{\"authorId\":\"2635735\",\"name\":\"Satyadhyan Chickerur\"}],\"doi\":\"10.1109/ICICICT46008.2019.8993289\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"454550613466f1882821b155e4c1e9cbf2bb18ae\",\"title\":\"Movie Frame Prediction Using Convolutional Long Short Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/454550613466f1882821b155e4c1e9cbf2bb18ae\",\"venue\":\"2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)\",\"year\":2019},{\"arxivId\":\"1810.09044\",\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1007/978-3-030-20887-5_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"title\":\"VIENA2: A Driving Anticipation Dataset\",\"url\":\"https://www.semanticscholar.org/paper/44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1811.04869\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/CVPR.2019.00129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063ba2f8f6f1624f42de4e9bee0ac5ae6ce06032\",\"title\":\"A Perceptual Prediction Framework for Self Supervised Event Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/063ba2f8f6f1624f42de4e9bee0ac5ae6ce06032\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.07711\",\"authors\":[{\"authorId\":\"1637242169\",\"name\":\"Guglielmo Camporese\"},{\"authorId\":\"29776698\",\"name\":\"Pasquale Coscia\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc24772bf84d9ff92166d8f228284c4079619ed0\",\"title\":\"Knowledge Distillation for Action Anticipation via Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/dc24772bf84d9ff92166d8f228284c4079619ed0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.04394\",\"authors\":[{\"authorId\":\"2702448\",\"name\":\"N. Lee\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"2998590\",\"name\":\"Paul Vernaza\"},{\"authorId\":\"15239369\",\"name\":\"Christopher B. Choy\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":\"10.1109/CVPR.2017.233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"864ad6b8f2778bf7238e8a983551edc2072f08a9\",\"title\":\"DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents\",\"url\":\"https://www.semanticscholar.org/paper/864ad6b8f2778bf7238e8a983551edc2072f08a9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"145235303\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1109/BigMM.2018.8499470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee15b67b606ff49cd17467b062c11441e3b2dd70\",\"title\":\"Deep Residual Feature Learning for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ee15b67b606ff49cd17467b062c11441e3b2dd70\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1912.07148\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICCV.2019.00566\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2b4960bb3997105073779651a54255b2c129d3d6\",\"title\":\"Predicting the Future: A Jointly Learnt Model for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2b4960bb3997105073779651a54255b2c129d3d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.04486\",\"authors\":[{\"authorId\":\"145450400\",\"name\":\"Thibault Sellam\"},{\"authorId\":\"48085802\",\"name\":\"Kevin Lin\"},{\"authorId\":\"48612187\",\"name\":\"I. Huang\"},{\"authorId\":\"47345429\",\"name\":\"M. Yang\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"48144872\",\"name\":\"E. Wu\"}],\"doi\":\"10.1145/3299869.3300073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d913f05044382ddc1fea170a739fffa189c9c88\",\"title\":\"DeepBase: Deep Inspection of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d913f05044382ddc1fea170a739fffa189c9c88\",\"venue\":\"SIGMOD Conference\",\"year\":2019},{\"arxivId\":\"1808.07784\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"2011.09192\",\"authors\":[{\"authorId\":\"103368444\",\"name\":\"K. Tuyls\"},{\"authorId\":\"2008186335\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"2008186474\",\"name\":\"Paul Muller\"},{\"authorId\":\"47197505\",\"name\":\"Zhe Wang\"},{\"authorId\":\"2007915382\",\"name\":\"Jerome Connor\"},{\"authorId\":\"2008182142\",\"name\":\"Daniel Hennes\"},{\"authorId\":\"145253240\",\"name\":\"I. Graham\"},{\"authorId\":\"52462738\",\"name\":\"W. Spearman\"},{\"authorId\":\"2026325301\",\"name\":\"Tim Waskett\"},{\"authorId\":\"2026283770\",\"name\":\"Dafydd Steele\"},{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"51980959\",\"name\":\"Alexandre Galashov\"},{\"authorId\":\"2005813\",\"name\":\"G. Thornton\"},{\"authorId\":\"47431108\",\"name\":\"R. Elie\"},{\"authorId\":\"2905900\",\"name\":\"P. Sprechmann\"},{\"authorId\":\"50713166\",\"name\":\"P. Moreno\"},{\"authorId\":\"3421987\",\"name\":\"Kris Cao\"},{\"authorId\":\"3468254\",\"name\":\"Marta Garnelo\"},{\"authorId\":\"9076891\",\"name\":\"P. Dutta\"},{\"authorId\":\"1806291\",\"name\":\"Michal Valko\"},{\"authorId\":\"1599360864\",\"name\":\"Nicolas Heess\"},{\"authorId\":\"1392692054\",\"name\":\"Alex Bridgland\"},{\"authorId\":\"3422031\",\"name\":\"Julien P\\u00e9rolat\"},{\"authorId\":\"1419267454\",\"name\":\"Bart De Vylder\"},{\"authorId\":\"49961426\",\"name\":\"A. Eslami\"},{\"authorId\":\"144845452\",\"name\":\"M. Rowland\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"49274028\",\"name\":\"R. Munos\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"2026327929\",\"name\":\"Razia Ahamed\"},{\"authorId\":\"1404756328\",\"name\":\"Simon Bouton\"},{\"authorId\":\"2026355587\",\"name\":\"Nathalie Beauguerlange\"},{\"authorId\":\"2026325402\",\"name\":\"Jackson Broshear\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"1838779\",\"name\":\"D. Hassabis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66240545b56959cec31b4187d93e71884365d1f7\",\"title\":\"Game Plan: What AI can do for Football, and What Football can do for AI\",\"url\":\"https://www.semanticscholar.org/paper/66240545b56959cec31b4187d93e71884365d1f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"144530691\",\"name\":\"Lili Wan\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1145/3343031.3351073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13bf8def0af5ce1883d3d046b4c48ee6153d6241\",\"title\":\"Prediction-CGAN: Human Action Prediction with Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/13bf8def0af5ce1883d3d046b4c48ee6153d6241\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36124320\",\"name\":\"Yan Zhang\"},{\"authorId\":\"2949115\",\"name\":\"Georg Layher\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1109/IPTA.2017.8310114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5e5d391fbf80cd65a5e2b09924945c1ce341601\",\"title\":\"Continuous activity understanding based on accumulative pose-context visual patterns\",\"url\":\"https://www.semanticscholar.org/paper/f5e5d391fbf80cd65a5e2b09924945c1ce341601\",\"venue\":\"2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46429010\",\"name\":\"Fang Wang\"}],\"doi\":\"10.25911/5d6cf9fcdf586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1f257f38dc11023cf3e8c52e4268e2d6962e2d\",\"title\":\"From Line Drawings to Human Actions: Deep Neural Networks for Visual Data Representation\",\"url\":\"https://www.semanticscholar.org/paper/6c1f257f38dc11023cf3e8c52e4268e2d6962e2d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1912.04608\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":\"10.1109/TIP.2020.3021497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08bf24e179aff7971ba95aed185c8e13da9f8ce4\",\"title\":\"Forecasting Future Action Sequences With Attention: A New Approach to Weakly Supervised Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/08bf24e179aff7971ba95aed185c8e13da9f8ce4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.01766\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"49588480\",\"name\":\"A. Myers\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2019.00756\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c41a11c0e9b8b92b4faaf97749841170b760760a\",\"title\":\"VideoBERT: A Joint Model for Video and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/c41a11c0e9b8b92b4faaf97749841170b760760a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.04781\",\"authors\":[{\"authorId\":\"49050667\",\"name\":\"Jason Y. Zhang\"},{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2019.00721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20ac7634e9b406c37b0867ea8e6c0e37ae0794ae\",\"title\":\"Predicting 3D Human Dynamics From Video\",\"url\":\"https://www.semanticscholar.org/paper/20ac7634e9b406c37b0867ea8e6c0e37ae0794ae\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67235476\",\"name\":\"S. Wang\"},{\"authorId\":\"144364920\",\"name\":\"J. Gao\"},{\"authorId\":\"121504236\",\"name\":\"Hanping Lin\"},{\"authorId\":\"69976531\",\"name\":\"Mayur Shitole\"},{\"authorId\":\"1383481739\",\"name\":\"Layla Reza\"},{\"authorId\":\"108770252\",\"name\":\"S. Zhou\"}],\"doi\":\"10.1109/BigDataService.2019.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd546d016f73de49ef5cd02f4d4de75db64c2bbf\",\"title\":\"Dynamic Human Behavior Pattern Detection and Classification\",\"url\":\"https://www.semanticscholar.org/paper/dd546d016f73de49ef5cd02f4d4de75db64c2bbf\",\"venue\":\"2019 IEEE Fifth International Conference on Big Data Computing Service and Applications (BigDataService)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9433002\",\"name\":\"M. Saremi\"},{\"authorId\":\"1914793\",\"name\":\"F. Yaghmaee\"}],\"doi\":\"10.1007/s13735-019-00182-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db337468c459fc100780e396c39750fb5aebf05e\",\"title\":\"Probabilistic selection of frames for early action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/db337468c459fc100780e396c39750fb5aebf05e\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2003.12185\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1007/978-3-030-58568-6_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61b166040abff8309e23d804551fc3d3acc833f6\",\"title\":\"Action Localization through Continual Predictive Learning\",\"url\":\"https://www.semanticscholar.org/paper/61b166040abff8309e23d804551fc3d3acc833f6\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19188327\",\"name\":\"Nghia Pham Trong\"},{\"authorId\":\"144715435\",\"name\":\"H. Nguyen\"},{\"authorId\":\"1791753\",\"name\":\"K. Kotani\"},{\"authorId\":\"145344657\",\"name\":\"H. Le\"}],\"doi\":\"10.1007/978-3-319-62392-4_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50a31ac7866c2cba2b5f580973bfbbbd92569142\",\"title\":\"A Comprehensive Survey on Human Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/50a31ac7866c2cba2b5f580973bfbbbd92569142\",\"venue\":\"ICCSA\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.06987\",\"authors\":[{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"1710493\",\"name\":\"F. Castaldo\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"39229524\",\"name\":\"F. Palmieri\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1007/978-3-319-46448-0_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19dd12ccc9c6997c9cecdaf12f937812066827aa\",\"title\":\"Knowledge Transfer for Scene-Specific Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/19dd12ccc9c6997c9cecdaf12f937812066827aa\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.00141\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1007/978-3-030-11015-4_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"title\":\"Action Anticipation By Predicting Future Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2009.09439\",\"authors\":[{\"authorId\":\"1955206198\",\"name\":\"Hlynur Dav'idh Hlynsson\"},{\"authorId\":\"1955222754\",\"name\":\"Merlin Schuler\"},{\"authorId\":\"1581658184\",\"name\":\"Robin Schiewer\"},{\"authorId\":\"1756710\",\"name\":\"T. Glasmachers\"},{\"authorId\":\"1736245\",\"name\":\"Laurenz Wiskott\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11592fccfa953ce36e26a7702672d42cebc2e3c6\",\"title\":\"Latent Representation Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/11592fccfa953ce36e26a7702672d42cebc2e3c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.09412\",\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c970f99e844f774236511a40bf43b8950dde339f\",\"title\":\"Cubic LSTMs for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c970f99e844f774236511a40bf43b8950dde339f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1904.05869\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"47988509\",\"name\":\"J. Yang\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"145979389\",\"name\":\"Joseph Lim\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36cddcdafdcbfe830a644777befa4a707839053c\",\"title\":\"KeyIn: Discovering Subgoal Structure with Keyframe-based Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/36cddcdafdcbfe830a644777befa4a707839053c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40529032\",\"name\":\"C. Shen\"},{\"authorId\":\"5346056\",\"name\":\"E. Laloy\"},{\"authorId\":\"39221195\",\"name\":\"A. Elshorbagy\"},{\"authorId\":\"10294024\",\"name\":\"Adrian Albert\"},{\"authorId\":\"1824103\",\"name\":\"J. Bales\"},{\"authorId\":\"93576630\",\"name\":\"F. J. Chang\"},{\"authorId\":\"3000700\",\"name\":\"S. Ganguly\"},{\"authorId\":\"19450115\",\"name\":\"K. Hsu\"},{\"authorId\":\"1852261\",\"name\":\"D. Kifer\"},{\"authorId\":\"145636412\",\"name\":\"Z. Fang\"},{\"authorId\":\"1815501\",\"name\":\"K. Fang\"},{\"authorId\":\"46599300\",\"name\":\"D. Li\"},{\"authorId\":\"47057319\",\"name\":\"X. Li\"},{\"authorId\":\"4865710\",\"name\":\"W. Tsai\"}],\"doi\":\"10.5194/HESS-22-5639-2018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f43507936dd71d7b91e473737de5fbee23c1b5c8\",\"title\":\"HESS Opinions: Incubating deep-learning-powered hydrologic science advances as a community\",\"url\":\"https://www.semanticscholar.org/paper/f43507936dd71d7b91e473737de5fbee23c1b5c8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.05743\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"title\":\"Contrastive Bidirectional Transformer for Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1845915519\",\"name\":\"Eric Kasangu Lubamba\"},{\"authorId\":\"92581630\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3008848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c7c4556126f7219886cd28e4f33c85586f24955\",\"title\":\"Action Prediction Based on Partial Video Observation via Context and Temporal Sequential Network With Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/5c7c4556126f7219886cd28e4f33c85586f24955\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"title\":\"Recognition Prediction ? ? ? ? ? ? ? ? Gap fi lling\",\"url\":\"https://www.semanticscholar.org/paper/5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152978200\",\"name\":\"X. Guo\"},{\"authorId\":\"47896751\",\"name\":\"W. Zhong\"},{\"authorId\":\"46269770\",\"name\":\"L. Ye\"},{\"authorId\":\"145683627\",\"name\":\"L. Fang\"},{\"authorId\":\"2356305\",\"name\":\"Q. Zhang\"}],\"doi\":\"10.1007/978-981-15-3341-9_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c4e59fad40a04415f13db0304821d168d68d233\",\"title\":\"Affective Video Content Analysis Based on Two Compact Audio-Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/2c4e59fad40a04415f13db0304821d168d68d233\",\"venue\":\"IFTC\",\"year\":2019},{\"arxivId\":\"1711.09265\",\"authors\":[{\"authorId\":\"51281239\",\"name\":\"Yu Runsheng\"},{\"authorId\":\"47134922\",\"name\":\"Shi Zhen-yu\"},{\"authorId\":\"51284306\",\"name\":\"Ma Qiongxiong\"},{\"authorId\":\"51281188\",\"name\":\"Qing Laiyun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a02a6ce130ad3d6c78a5f573fd7badca41c7227\",\"title\":\"Predictive Learning: Using Future Representation Learning Variantial Autoencoder for Human Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6a02a6ce130ad3d6c78a5f573fd7badca41c7227\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.04231\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"title\":\"Relational Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.02230\",\"authors\":[{\"authorId\":\"50316200\",\"name\":\"Zhichao Zhang\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"150323459\",\"name\":\"T. Qiao\"},{\"authorId\":\"1730880\",\"name\":\"Shunqing Zhang\"},{\"authorId\":\"144613170\",\"name\":\"S. Cao\"}],\"doi\":\"10.1007/978-3-030-31654-9_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffac573c42c3d6826c60cb76a101727cbc784822\",\"title\":\"Attention based Convolutional Recurrent Neural Network for Environmental Sound Classification\",\"url\":\"https://www.semanticscholar.org/paper/ffac573c42c3d6826c60cb76a101727cbc784822\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1607.06854\",\"authors\":[{\"authorId\":\"3213262\",\"name\":\"F. Piekniewski\"},{\"authorId\":\"2626554\",\"name\":\"P. A. Laurent\"},{\"authorId\":\"35138001\",\"name\":\"C. Petre\"},{\"authorId\":\"145868716\",\"name\":\"Micah Richert\"},{\"authorId\":\"3432563\",\"name\":\"D. Fisher\"},{\"authorId\":\"32020006\",\"name\":\"T. Hylton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50457c55b318dde8c9024851fdf7e5ce3a936f65\",\"title\":\"Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/50457c55b318dde8c9024851fdf7e5ce3a936f65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1806.06003\",\"authors\":[{\"authorId\":\"3331786\",\"name\":\"Markus Wulfmeier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51cb2116c5a32d076f54b1a192cf4e850390f665\",\"title\":\"On Machine Learning and Structure for Mobile Robots\",\"url\":\"https://www.semanticscholar.org/paper/51cb2116c5a32d076f54b1a192cf4e850390f665\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.00913\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Unsupervised Bi-directional Flow-based Video Generation from one Snapshot\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c19373d455d22d23461c3202d2fbb4f791ec5c9\",\"title\":\"Exploiting visual motion to understand our visual world\",\"url\":\"https://www.semanticscholar.org/paper/5c19373d455d22d23461c3202d2fbb4f791ec5c9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3370510\",\"name\":\"Martin Garbade\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.5244/C.31.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d11dd78cac143fc898b2e41f32a7bc141701f44\",\"title\":\"Thinking Outside the Box: Spatial Anticipation of Semantic Categories\",\"url\":\"https://www.semanticscholar.org/paper/7d11dd78cac143fc898b2e41f32a7bc141701f44\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1904.10666\",\"authors\":[{\"authorId\":\"3306760\",\"name\":\"Hsu-Kuang Chiu\"},{\"authorId\":\"46408185\",\"name\":\"Ehsan Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"119131638\",\"name\":\"Stanford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73c28cef6c0d58b101204609137af39c3e94c047\",\"title\":\"Video Frames Output : Future Semantic Segmentation Semantic Segmentation Forecasting Input : Past Video Frames Output : Future Semantic Segmentation Semantic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/73c28cef6c0d58b101204609137af39c3e94c047\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28575711\",\"name\":\"J. Koch\"},{\"authorId\":\"2663734\",\"name\":\"Antti Oulasvirta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaee0d86da94d14c5d07dbe607d7d3bb9ec09810\",\"title\":\"Chapter 15 Group Cognition and Collaborative AI\",\"url\":\"https://www.semanticscholar.org/paper/aaee0d86da94d14c5d07dbe607d7d3bb9ec09810\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92917823\",\"name\":\"Kookjin Kim\"},{\"authorId\":\"2800874\",\"name\":\"Seungjin Lee\"},{\"authorId\":\"50203956\",\"name\":\"Sungjoong Kim\"},{\"authorId\":\"87105817\",\"name\":\"Jaekeun Kim\"},{\"authorId\":\"4728322\",\"name\":\"D. Shin\"},{\"authorId\":\"1742563\",\"name\":\"Dongkyoo Shin\"}],\"doi\":\"10.1109/ACCESS.2020.3011654\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ccdba2743a2831f114743f5e0fe5fb853172b93\",\"title\":\"Sensor-Based Deviant Behavior Detection System Using Deep Learning to Help Dementia Caregivers\",\"url\":\"https://www.semanticscholar.org/paper/7ccdba2743a2831f114743f5e0fe5fb853172b93\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1610.00759\",\"authors\":[{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"7572514\",\"name\":\"Fang Wang\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"3234252\",\"name\":\"Konstantinos Zampogiannis\"},{\"authorId\":null,\"name\":\"Yi Zhang\"},{\"authorId\":\"144484799\",\"name\":\"F. Barranco\"},{\"authorId\":\"144578436\",\"name\":\"M. Pfeiffer\"}],\"doi\":\"10.1007/s11263-017-0992-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6275aa21331a2712222b7ab2116e9589e21ae82c\",\"title\":\"Prediction of Manipulation Actions\",\"url\":\"https://www.semanticscholar.org/paper/6275aa21331a2712222b7ab2116e9589e21ae82c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"2007.14937\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"title\":\"Learning Video Representations from Textual Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28575711\",\"name\":\"J. Koch\"},{\"authorId\":\"2663734\",\"name\":\"Antti Oulasvirta\"}],\"doi\":\"10.1007/978-3-319-90403-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3558b9ea9e9ef409f0ba2bd1ecfe96b929a32a91\",\"title\":\"Group Cognition and Collaborative AI\",\"url\":\"https://www.semanticscholar.org/paper/3558b9ea9e9ef409f0ba2bd1ecfe96b929a32a91\",\"venue\":\"Human and Machine Learning\",\"year\":2018},{\"arxivId\":\"2005.00343\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1109/TPAMI.2020.2991965\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1badccbe4a3cbf8662b924a97bbeea14fe2f1ac7\",\"title\":\"The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1badccbe4a3cbf8662b924a97bbeea14fe2f1ac7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1912.02155\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"20745881\",\"name\":\"Luca Weihs\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/cvpr42600.2020.01159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6d7734a35d5e20f2c0cf75b9c01683cbe8b5675\",\"title\":\"Visual Reaction: Learning to Play Catch With Your Drone\",\"url\":\"https://www.semanticscholar.org/paper/d6d7734a35d5e20f2c0cf75b9c01683cbe8b5675\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1809.08318\",\"authors\":[{\"authorId\":\"15995259\",\"name\":\"Adam W. Terwilliger\"},{\"authorId\":\"47604355\",\"name\":\"G. Brazil\"},{\"authorId\":\"38284381\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/WACV.2019.00186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7919088b12e861fd449c47dd8622db9f584af9e\",\"title\":\"Recurrent Flow-Guided Semantic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/d7919088b12e861fd449c47dd8622db9f584af9e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1902.09641\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144338675\",\"name\":\"P. Karlsson\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"906c03e6e188d301b85ca6521955a8584f9babe7\",\"title\":\"Stochastic Prediction of Multi-Agent Interactions from Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/906c03e6e188d301b85ca6521955a8584f9babe7\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"34465973\",\"name\":\"A. Koul\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1145/3123266.3123298\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"217aa3aa0b3d9f6f394b5d26f03418187d775596\",\"title\":\"Predicting Human Intentions from Motion Cues Only: A 2D+3D Fusion Approach\",\"url\":\"https://www.semanticscholar.org/paper/217aa3aa0b3d9f6f394b5d26f03418187d775596\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"2006.12480\",\"authors\":[{\"authorId\":\"35703530\",\"name\":\"Fangrui Zhu\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1c2c47df98554d787927618b54fdb406338a4fd\",\"title\":\"Self-supervised Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e1c2c47df98554d787927618b54fdb406338a4fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143693859\",\"name\":\"Yiming Gan\"},{\"authorId\":\"67155695\",\"name\":\"Yuxian Qiu\"},{\"authorId\":\"152875073\",\"name\":\"Lele Chen\"},{\"authorId\":\"1831521\",\"name\":\"Jingwen Leng\"},{\"authorId\":\"2124167\",\"name\":\"Yuhao Zhu\"}],\"doi\":\"10.1145/3410463.3414650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9aff614238739620573e45cb41931b6868a6fed\",\"title\":\"Low-Latency Proactive Continuous Vision\",\"url\":\"https://www.semanticscholar.org/paper/d9aff614238739620573e45cb41931b6868a6fed\",\"venue\":\"PACT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001407\",\"name\":\"S. Cappallo\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1145/3123266.3123437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06b94b47b70c9bfcddbe277a61a9a802acd20096\",\"title\":\"Future-Supervised Retrieval of Unseen Queries for Live Video\",\"url\":\"https://www.semanticscholar.org/paper/06b94b47b70c9bfcddbe277a61a9a802acd20096\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1702.07492\",\"authors\":[{\"authorId\":\"1711521\",\"name\":\"A. H. Qureshi\"},{\"authorId\":\"38035941\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"2836701\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"1687808\",\"name\":\"H. Ishiguro\"}],\"doi\":\"10.1109/HUMANOIDS.2016.7803357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac891a856277a55c0ad30a03718859a210c9df25\",\"title\":\"Robot gains social intelligence through multimodal deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/ac891a856277a55c0ad30a03718859a210c9df25\",\"venue\":\"2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/TPAMI.2018.2873794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"title\":\"First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1705.06560\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"2601489\",\"name\":\"Fu-Hsiang Chan\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1debc9cd258a8c66045f01bbb50b6c9d15883256\",\"title\":\"Agent-Centric Risk Assessment: Accident Anticipation and Risky Region Localization\",\"url\":\"https://www.semanticscholar.org/paper/1debc9cd258a8c66045f01bbb50b6c9d15883256\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"2173143\",\"name\":\"C. Zhang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"48707717\",\"name\":\"Z. Wang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-11024-6_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"title\":\"Visually Indicated Sound Generation by Perceptually Optimized Classification\",\"url\":\"https://www.semanticscholar.org/paper/d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1911.11206\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1109/cvpr42600.2020.00100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"title\":\"Oops! Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1805.00833\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"title\":\"Learnable PINs: Cross-Modal Embeddings for Person Identity\",\"url\":\"https://www.semanticscholar.org/paper/a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48044229\",\"name\":\"F. Qi\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dae315b084b9164ac68da26aaa73de877f73f75c\",\"title\":\"A Unified Framework for Multimodal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/dae315b084b9164ac68da26aaa73de877f73f75c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50118603\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"7179962\",\"name\":\"Yan-qi Yang\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2020.3040521\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acfa6fcd7343c14e3f150c0541cc94e672cf1a73\",\"title\":\"Learning to Anticipate Egocentric Actions by Imagination\",\"url\":\"https://www.semanticscholar.org/paper/acfa6fcd7343c14e3f150c0541cc94e672cf1a73\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.11261\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"title\":\"Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1612.04468\",\"authors\":[{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dc02c317afbd922ae21fd9af8222a65274456ab\",\"title\":\"Sparse Factorization Layers for Neural Networks with Limited Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6dc02c317afbd922ae21fd9af8222a65274456ab\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"},{\"authorId\":\"1701928\",\"name\":\"Jixiang Du\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"47416429\",\"name\":\"Shuang Ye\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19194129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"title\":\"A Survey of Vision-Based Human Action Evaluation Methods\",\"url\":\"https://www.semanticscholar.org/paper/fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2019.01016\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"title\":\"Time-Conditioned Action Anticipation in One Shot\",\"url\":\"https://www.semanticscholar.org/paper/3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.00308\",\"authors\":[{\"authorId\":\"121310313\",\"name\":\"Yiyi Zhang\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"13944031\",\"name\":\"Ziqi Pan\"},{\"authorId\":\"1438947172\",\"name\":\"Meichao Luo\"},{\"authorId\":\"49051251\",\"name\":\"Jianfu Zhang\"},{\"authorId\":\"2476347\",\"name\":\"Dawei Cheng\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6990\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"223eba328e72650eda1cc85817f4d396cc116eb4\",\"title\":\"Exploiting Motion Information from Unlabeled Videos for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/223eba328e72650eda1cc85817f4d396cc116eb4\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1904.06250\",\"authors\":[{\"authorId\":\"47625239\",\"name\":\"Jiaqi Guan\"},{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":\"10.1109/cvpr42600.2020.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e81711be35d918d1bc5c987f25e0eaa9cfb7170\",\"title\":\"Generative Hybrid Representations for Activity Forecasting With No-Regret Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e81711be35d918d1bc5c987f25e0eaa9cfb7170\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581606067\",\"name\":\"Amey Arvind Bhile\"},{\"authorId\":\"144088162\",\"name\":\"V. Hole\"}],\"doi\":\"10.1007/978-3-030-37051-0_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"065544f24bcf2094042355193364cb9d951ef065\",\"title\":\"Real-Time Environment Description Application for Visually Challenged People\",\"url\":\"https://www.semanticscholar.org/paper/065544f24bcf2094042355193364cb9d951ef065\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"1808.02668\",\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"2504258\",\"name\":\"Alexis Lechervy\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1145/3242969.3264980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be09418dec0cb334eab6094f04f3cd57c1f26cbf\",\"title\":\"An Occam's Razor View on Learning Audiovisual Emotion Recognition with Small Training Sets\",\"url\":\"https://www.semanticscholar.org/paper/be09418dec0cb334eab6094f04f3cd57c1f26cbf\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":\"1808.08405\",\"authors\":[{\"authorId\":\"48806245\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"1730880\",\"name\":\"Shunqing Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24e1a9eabec4adb37a46eae5ff51198e6e758a44\",\"title\":\"Deep Convolutional Neural Network with Mixup for Environmental Sound Classification\",\"url\":\"https://www.semanticscholar.org/paper/24e1a9eabec4adb37a46eae5ff51198e6e758a44\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724176\",\"name\":\"M. Rovatsos\"}],\"doi\":\"10.1007/978-3-319-31737-3_45-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73325b69edc948ba82ac2b626997d3a049bf644d\",\"title\":\"Anticipatory Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/73325b69edc948ba82ac2b626997d3a049bf644d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1911.07806\",\"authors\":[{\"authorId\":\"11519650\",\"name\":\"Yuge Shi\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1007/978-3-030-01249-6_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3200539538eca54a85223bf0ec4f3ed132d0493\",\"title\":\"Action Anticipation with RBF Kernelized Feature Mapping RNN\",\"url\":\"https://www.semanticscholar.org/paper/b3200539538eca54a85223bf0ec4f3ed132d0493\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"83895120\",\"name\":\"Ruichen Li\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1145/3266302.3266313\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1ff567d7400ed7663d662c0b1e0ec6a9b900e70\",\"title\":\"Multi-modal Multi-cultural Dimensional Continues Emotion Recognition in Dyadic Interactions\",\"url\":\"https://www.semanticscholar.org/paper/f1ff567d7400ed7663d662c0b1e0ec6a9b900e70\",\"venue\":\"AVEC@MM\",\"year\":2018},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997924\",\"name\":\"Samira Pouyanfar\"},{\"authorId\":\"2868174\",\"name\":\"Yudong Tao\"},{\"authorId\":\"2229900\",\"name\":\"Haiman Tian\"},{\"authorId\":\"1705664\",\"name\":\"Shu-Ching Chen\"},{\"authorId\":\"144987531\",\"name\":\"M. Shyu\"}],\"doi\":\"10.1007/s11280-018-0636-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2c92968ebbe9ddedcd8b0d03a7cffe98c1c3909\",\"title\":\"Multimodal deep learning based on multiple correspondence analysis for disaster management\",\"url\":\"https://www.semanticscholar.org/paper/c2c92968ebbe9ddedcd8b0d03a7cffe98c1c3909\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1704.03615\",\"authors\":[{\"authorId\":\"2298523\",\"name\":\"Achal Dave\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2017.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08ed84f2cb8f4961dea6ba60c09cc36959921287\",\"title\":\"Predictive-Corrective Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/08ed84f2cb8f4961dea6ba60c09cc36959921287\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2011.06037\",\"authors\":[{\"authorId\":\"1581475970\",\"name\":\"Nadine Behrmann\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11cd3fc5561dd372f8fd03dd1c4d23d93f2e746e\",\"title\":\"Unsupervised Video Representation Learning by Bidirectional Feature Prediction\",\"url\":\"https://www.semanticscholar.org/paper/11cd3fc5561dd372f8fd03dd1c4d23d93f2e746e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.11727\",\"authors\":[{\"authorId\":\"50510090\",\"name\":\"S. Kannan\"},{\"authorId\":\"31618054\",\"name\":\"Gaurav Yengera\"},{\"authorId\":\"2055499\",\"name\":\"D. Mutter\"},{\"authorId\":\"144688664\",\"name\":\"J. Marescaux\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":\"10.1109/TMI.2019.2931158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"384458985d2e3c58995ab5098012a1e5e699676c\",\"title\":\"Future-State Predicting LSTM for Early Surgery Type Recognition\",\"url\":\"https://www.semanticscholar.org/paper/384458985d2e3c58995ab5098012a1e5e699676c\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144816684\",\"name\":\"K. Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"title\":\"Learning Video Representations using Contrastive Bidirectional Transformer\",\"url\":\"https://www.semanticscholar.org/paper/025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"4a250bf0e10e23de16200cb33d5977d09848c80a\",\"title\":\"Online Semantic Activity Forecasting with DARKO\",\"url\":\"https://www.semanticscholar.org/paper/4a250bf0e10e23de16200cb33d5977d09848c80a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb38a07cdb12ded42c19bea27a01574f2b06b02e\",\"title\":\"DESIRE : Deep Stochastic IOC RNN Encoder-decoder for Distant Future Prediction in Dynamic Scenes with Multiple Interacting Agents\",\"url\":\"https://www.semanticscholar.org/paper/eb38a07cdb12ded42c19bea27a01574f2b06b02e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4fa0b4e518de397fafa3fe8c9d925bcd4a3438e\",\"title\":\"Online action detection\",\"url\":\"https://www.semanticscholar.org/paper/f4fa0b4e518de397fafa3fe8c9d925bcd4a3438e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5967915\",\"name\":\"Fuqiang Zhou\"},{\"authorId\":\"95266241\",\"name\":\"L. Wang\"},{\"authorId\":\"13676327\",\"name\":\"Zuoxin Li\"},{\"authorId\":\"51263696\",\"name\":\"Wangxia Zuo\"},{\"authorId\":\"3022594\",\"name\":\"Haishu Tan\"}],\"doi\":\"10.1007/s11063-019-10113-w\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3da6084f6610d57ecae2d51575c4171045e9ea90\",\"title\":\"Unsupervised Learning Approach for Abnormal Event Detection in Surveillance Video by Hybrid Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/3da6084f6610d57ecae2d51575c4171045e9ea90\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144378416\",\"name\":\"Y. Zhong\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/ICIP.2018.8451428\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"430134bf1805c075ae21b499430f27c483d04f65\",\"title\":\"Unsupervised Learning for Forecasting Action Representations\",\"url\":\"https://www.semanticscholar.org/paper/430134bf1805c075ae21b499430f27c483d04f65\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2058516\",\"name\":\"O. Oshin\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"3033982\",\"name\":\"B. Nair\"},{\"authorId\":\"1443749549\",\"name\":\"Jerry Ding\"},{\"authorId\":\"1443782889\",\"name\":\"Richa Varma\"},{\"authorId\":\"33177662\",\"name\":\"Richard W. Osborne\"},{\"authorId\":\"1443783806\",\"name\":\"Eddie Tunstel\"},{\"authorId\":\"1443782661\",\"name\":\"Francesca Stramandinoli\"}],\"doi\":\"10.1109/SMC.2019.8913974\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e63c2528d640d8746c9b2b1029eb17c3efd6d288\",\"title\":\"Coupling Deep Discriminative and Generative Models for Reactive Robot Planning in Human-Robot Collaboration\",\"url\":\"https://www.semanticscholar.org/paper/e63c2528d640d8746c9b2b1029eb17c3efd6d288\",\"venue\":\"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)\",\"year\":2019},{\"arxivId\":\"2007.11984\",\"authors\":[{\"authorId\":\"144041170\",\"name\":\"Ning Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"2255687\",\"name\":\"Yibing Song\"},{\"authorId\":\"1409866378\",\"name\":\"Chao Ma\"},{\"authorId\":\"39922753\",\"name\":\"Wei Liu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1007/S11263-020-01357-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b29eef7a4b8597ab4fc90579e1326980d6d16b51\",\"title\":\"Unsupervised Deep Representation Learning for Real-Time Tracking\",\"url\":\"https://www.semanticscholar.org/paper/b29eef7a4b8597ab4fc90579e1326980d6d16b51\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1809.02560\",\"authors\":[{\"authorId\":\"3393384\",\"name\":\"Jong-Chyi Su\"},{\"authorId\":\"48644686\",\"name\":\"Matheus Gadelha\"},{\"authorId\":\"46885957\",\"name\":\"R. Wang\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1007/978-3-030-11015-4_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a90fd410a6e52c67b897ecddbc130e1351846b01\",\"title\":\"A Deeper Look at 3D Shape Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/a90fd410a6e52c67b897ecddbc130e1351846b01\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152598568\",\"name\":\"Cuiwei Liu\"},{\"authorId\":\"1455839106\",\"name\":\"Yaguang Lu\"},{\"authorId\":\"3085797\",\"name\":\"Xiangbin Shi\"},{\"authorId\":\"31176242\",\"name\":\"C. Du\"},{\"authorId\":\"9248201\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2956538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d61922db7bfd01a11fb1c1310b6b3b5f26ee24e0\",\"title\":\"A Novel Double-Layer Framework for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d61922db7bfd01a11fb1c1310b6b3b5f26ee24e0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1901.03728\",\"authors\":[{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"66572445\",\"name\":\"Mahdieh Izadpanahkakhk\"},{\"authorId\":\"66760000\",\"name\":\"E. Omrani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"37fd19e135c065659875e2e824a455ad56689507\",\"title\":\"Anticipation and next action forecasting in video: an end-to-end model with memory\",\"url\":\"https://www.semanticscholar.org/paper/37fd19e135c065659875e2e824a455ad56689507\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102693700\",\"name\":\"J\\u00f6rg Wagner\"},{\"authorId\":\"47092548\",\"name\":\"Volker Fischer\"},{\"authorId\":\"47205733\",\"name\":\"S. Herman\"},{\"authorId\":\"1699019\",\"name\":\"Sven Behnke\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15383ae2d86eb8c5e172168f94ef915a7a238b72\",\"title\":\"Learning Semantic Prediction using Pretrained Deep Feedforward Networks\",\"url\":\"https://www.semanticscholar.org/paper/15383ae2d86eb8c5e172168f94ef915a7a238b72\",\"venue\":\"ESANN\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053210\",\"name\":\"Vibekananda Dutta\"},{\"authorId\":\"1684960\",\"name\":\"T. Zielinska\"}],\"doi\":\"10.1007/s10846-018-0815-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbc40a84bcfeeba9611ea58f9ae56c60c0b67713\",\"title\":\"Predicting Human Actions Taking into Account Object Affordances\",\"url\":\"https://www.semanticscholar.org/paper/cbc40a84bcfeeba9611ea58f9ae56c60c0b67713\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153920582\",\"name\":\"Luk\\u00e1s Neumann\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPRW.2019.00354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"title\":\"Future Event Prediction: If and When\",\"url\":\"https://www.semanticscholar.org/paper/4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2751145\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4289f9f727af39414537a97e5eef90b06115a5db\",\"title\":\"Global-Local Temporal Saliency Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4289f9f727af39414537a97e5eef90b06115a5db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"47430935\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1007/s11042-019-7675-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b04b5503532a69428841548e32c1847f4cd24021\",\"title\":\"Action prediction via deep residual feature learning and weighted loss\",\"url\":\"https://www.semanticscholar.org/paper/b04b5503532a69428841548e32c1847f4cd24021\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1704.00717\",\"authors\":[{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5539585e0b3831e1b14219cd9a9ac07810220765\",\"title\":\"It Takes Two to Tango: Towards Theory of AI's Mind\",\"url\":\"https://www.semanticscholar.org/paper/5539585e0b3831e1b14219cd9a9ac07810220765\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"50695076\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3133944.3133949\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c15e172032404df48ef685d6b1a5536843a7bd4\",\"title\":\"Multimodal Multi-task Learning for Dimensional and Continuous Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c15e172032404df48ef685d6b1a5536843a7bd4\",\"venue\":\"AVEC@ACM Multimedia\",\"year\":2017},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.01065\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58580-8_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"202c79bbb45ab6524141feacc81caacc4ba00401\",\"title\":\"Memory-augmented Dense Predictive Coding for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/202c79bbb45ab6524141feacc81caacc4ba00401\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1605.09526\",\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"34465973\",\"name\":\"A. Koul\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"ceca53c79ee54db9df526553e5cb045fad10c05e\",\"title\":\"Intention from Motion\",\"url\":\"https://www.semanticscholar.org/paper/ceca53c79ee54db9df526553e5cb045fad10c05e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1812.02501\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":\"10.1109/ICCV.2019.00095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15a36f9639f608c4567302de65355543fdcee910\",\"title\":\"Zero-Shot Anticipation for Instructional Activities\",\"url\":\"https://www.semanticscholar.org/paper/15a36f9639f608c4567302de65355543fdcee910\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.01142\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"title\":\"Long-Term Anticipation of Activities with Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1007/978-3-030-00776-8_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98186acc8121da00da8683d4cb014641340898c4\",\"title\":\"Multimodal Dimensional and Continuous Emotion Recognition in Dyadic Video Interactions\",\"url\":\"https://www.semanticscholar.org/paper/98186acc8121da00da8683d4cb014641340898c4\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1710.01692\",\"authors\":[{\"authorId\":\"27583154\",\"name\":\"Dokhyam Hoshen\"},{\"authorId\":\"27379268\",\"name\":\"M. Werman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7273d0d3ea253fd522f0afe04d2d9c7dc45cbd\",\"title\":\"IQ of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/bd7273d0d3ea253fd522f0afe04d2d9c7dc45cbd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7040e2a78bdb6ed01c237e52f0ace6c4f8608ba2\",\"title\":\"Unsupervised Learning of Sensorimotor Affordances by Stochastic Future Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7040e2a78bdb6ed01c237e52f0ace6c4f8608ba2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1708.05827\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"41187419\",\"name\":\"Bokui (William) Shen\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.326\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"9c5cbbdaa76e10106c4ea12a17826bec88e5efc3\",\"title\":\"Visual Forecasting by Imitating Dynamics in Natural Sequences\",\"url\":\"https://www.semanticscholar.org/paper/9c5cbbdaa76e10106c4ea12a17826bec88e5efc3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1809.10352\",\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"15702255\",\"name\":\"M. Billah\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/GlobalSIP.2018.8646380\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b04ee4e92e990519cf0a554862fa111cabf83e3\",\"title\":\"MULTI-VIEW FRAME RECONSTRUCTION WITH CONDITIONAL GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b04ee4e92e990519cf0a554862fa111cabf83e3\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":\"1807.07946\",\"authors\":[{\"authorId\":\"51134474\",\"name\":\"S. S. Nabavi\"},{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ba5e820f160dfd02544120ab6c1678421fb2c3b\",\"title\":\"Future Semantic Segmentation with Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/3ba5e820f160dfd02544120ab6c1678421fb2c3b\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1725011\",\"name\":\"P. Foggia\"},{\"authorId\":\"1729314\",\"name\":\"Alessia Saggese\"},{\"authorId\":\"1742086\",\"name\":\"Nicola Strisciuglio\"},{\"authorId\":\"1687627\",\"name\":\"M. Vento\"},{\"authorId\":\"40790370\",\"name\":\"Vincenzo Vigilante\"}],\"doi\":\"10.1007/978-3-030-30645-8_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1ad9e55f0388953233463664ae21add0918f9b2\",\"title\":\"Detecting Sounds of Interest in Roads with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/b1ad9e55f0388953233463664ae21add0918f9b2\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":\"2010.14810\",\"authors\":[{\"authorId\":\"1557386872\",\"name\":\"Quan Kong\"},{\"authorId\":\"31713260\",\"name\":\"W. Wei\"},{\"authorId\":\"90812043\",\"name\":\"Z. Deng\"},{\"authorId\":\"32710145\",\"name\":\"Tomoaki Yoshinaga\"},{\"authorId\":\"2668511\",\"name\":\"T. Murakami\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81b6c5b86ff596876078dc7eab4c0f093832056a\",\"title\":\"Cycle-Contrast for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/81b6c5b86ff596876078dc7eab4c0f093832056a\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1810.05057\",\"authors\":[{\"authorId\":\"51040359\",\"name\":\"Nicolas Le Hir\"},{\"authorId\":\"3211142\",\"name\":\"Olivier Sigaud\"},{\"authorId\":\"1687839\",\"name\":\"A. Laflaqui\\u00e8re\"}],\"doi\":\"10.3389/frobt.2018.00070\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af1422b23ff73839c83c8e9ca4e08afba9f40339\",\"title\":\"Identification of Invariant Sensorimotor Structures as a Prerequisite for the Discovery of Objects\",\"url\":\"https://www.semanticscholar.org/paper/af1422b23ff73839c83c8e9ca4e08afba9f40339\",\"venue\":\"Front. Robot. AI\",\"year\":2018},{\"arxivId\":\"1904.04868\",\"authors\":[{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97f1676e20d232d106d71b6007e4b4284a22699d\",\"title\":\"Back to the Future: Knowledge Distillation for Human Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/97f1676e20d232d106d71b6007e4b4284a22699d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1580178816\",\"name\":\"Roghayeh Pazoki\"},{\"authorId\":\"2671497\",\"name\":\"Parvin Razzaghi\"}],\"doi\":\"10.1007/978-3-030-37309-2_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45c9a8728610ab1a178029a7b22de3ae7c062685\",\"title\":\"Next Frame Prediction Using Flow Fields\",\"url\":\"https://www.semanticscholar.org/paper/45c9a8728610ab1a178029a7b22de3ae7c062685\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993709019\",\"name\":\"Chon Hou Sio\"},{\"authorId\":\"1993630593\",\"name\":\"Yu-Jen Ma\"},{\"authorId\":\"2426757\",\"name\":\"Hong-Han Shuai\"},{\"authorId\":\"49252128\",\"name\":\"J. Chen\"},{\"authorId\":\"1711298\",\"name\":\"W. Cheng\"}],\"doi\":\"10.1145/3394171.3413611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a0e78d0bc50c4437c0d533468894c3ca6fab38f\",\"title\":\"S2SiamFC: Self-supervised Fully Convolutional Siamese Network for Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/4a0e78d0bc50c4437c0d533468894c3ca6fab38f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/978-3-030-11015-4_12\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"bd7731912be9691f74f1898d02c5a6844dcb3920\",\"title\":\"Forecasting Hands and Objects in Future Frames\",\"url\":\"https://www.semanticscholar.org/paper/bd7731912be9691f74f1898d02c5a6844dcb3920\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195829\",\"name\":\"Pengjie Wang\"},{\"authorId\":\"138861973\",\"name\":\"Shao-Fu Lien\"},{\"authorId\":\"3288949\",\"name\":\"Ming-Sui Lee\"}],\"doi\":\"10.1109/ICIP.2019.8803820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf9aa6c509a74b038437629d550660929ac2e548\",\"title\":\"A Learning-Based Prediction Model for Baby Accidents\",\"url\":\"https://www.semanticscholar.org/paper/cf9aa6c509a74b038437629d550660929ac2e548\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279549\",\"name\":\"Xiao Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"title\":\"Leveraging Multimodal Perspectives to Learn Common Sense for Vision and Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"29be236bb68e503a6df6bb4932984fbca5452669\",\"title\":\"Learning, Moving, And Predicting With Global Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/29be236bb68e503a6df6bb4932984fbca5452669\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742086\",\"name\":\"Nicola Strisciuglio\"},{\"authorId\":\"145919705\",\"name\":\"N. Petkov\"}],\"doi\":\"10.1007/978-3-030-33904-3_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bef3b122698e5066ab56258b383593b72116243\",\"title\":\"Trainable COPE Features for Sound Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/0bef3b122698e5066ab56258b383593b72116243\",\"venue\":\"CIARP\",\"year\":2019},{\"arxivId\":\"1911.09989\",\"authors\":[{\"authorId\":\"1429191721\",\"name\":\"Menatallh Hammad\"},{\"authorId\":\"1429191719\",\"name\":\"May Hammad\"},{\"authorId\":\"31358369\",\"name\":\"M. ElShenawy\"}],\"doi\":\"10.1007/978-3-030-59830-3_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86ac173f03a5dbfb1d64a84759aa920ed6c1aec1\",\"title\":\"Characterizing the impact of using features extracted from pre-trained models on the quality of video captioning sequence-to-sequence models\",\"url\":\"https://www.semanticscholar.org/paper/86ac173f03a5dbfb1d64a84759aa920ed6c1aec1\",\"venue\":\"ICPRAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144623952\",\"name\":\"S. Bhattacharya\"},{\"authorId\":\"41073684\",\"name\":\"Dionysis Manousakas\"},{\"authorId\":\"104424199\",\"name\":\"A. Ramos\"},{\"authorId\":\"2867986\",\"name\":\"Stylianos I. Venieris\"},{\"authorId\":\"144948031\",\"name\":\"N. Lane\"},{\"authorId\":\"1733840\",\"name\":\"C. Mascolo\"}],\"doi\":\"10.17863/CAM.51962\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"110e83ac016b8d8c8764e3422392c1522d88bec8\",\"title\":\"Countering Acoustic Adversarial Attacks in Microphone-equipped Smart Home Devices\",\"url\":\"https://www.semanticscholar.org/paper/110e83ac016b8d8c8764e3422392c1522d88bec8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48266060\",\"name\":\"K. Man\"},{\"authorId\":\"2656777\",\"name\":\"A. Damasio\"}],\"doi\":\"10.1038/s42256-019-0103-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40b5e503ca03da59f36bd632b9f5c125f3a14ff2\",\"title\":\"Homeostasis and soft robotics in the design of feeling machines\",\"url\":\"https://www.semanticscholar.org/paper/40b5e503ca03da59f36bd632b9f5c125f3a14ff2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1806.09655\",\"authors\":[{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a53874f5c63b31468ad2fe3f5dea558a6ce35820\",\"title\":\"Learning what you can do before doing anything\",\"url\":\"https://www.semanticscholar.org/paper/a53874f5c63b31468ad2fe3f5dea558a6ce35820\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":\"10.1109/WACV.2019.00128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db70e64fb69c64f174fd97ab86566373504fd702\",\"title\":\"Memory Warps for Long-Term Online Video Representations and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/db70e64fb69c64f174fd97ab86566373504fd702\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.08449\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"48568841\",\"name\":\"Xuhong Li\"},{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"36352940\",\"name\":\"P. Jin\"},{\"authorId\":\"144230587\",\"name\":\"D. Chen\"},{\"authorId\":\"104530500\",\"name\":\"L. Jing\"},{\"authorId\":\"1761972\",\"name\":\"X. Zhu\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":\"10.1007/978-3-030-58586-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fabb1ef96d2840834cfaf384408309bafc588d5\",\"title\":\"Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7fabb1ef96d2840834cfaf384408309bafc588d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.06843\",\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1109/lra.2020.3010742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39716ff3e1d5a464f42c6b55366fcc8ddb712f7b\",\"title\":\"Socially and Contextually Aware Human Motion and Pose Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/39716ff3e1d5a464f42c6b55366fcc8ddb712f7b\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1612.03777\",\"authors\":[{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f42dca4a4426e5873a981712102aa961be34539a\",\"title\":\"Next-Flow: Hybrid Multi-Tasking with Next-Frame Prediction to Boost Optical-Flow Estimation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f42dca4a4426e5873a981712102aa961be34539a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.08539\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"152462956\",\"name\":\"D. Gordon\"},{\"authorId\":\"151492449\",\"name\":\"T. Nguyen\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d27eca39a42d1bf618c827f5472d58a8423c5568\",\"title\":\"What Can You Learn from Your Muscles? Learning Visual Representation from Human Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d27eca39a42d1bf618c827f5472d58a8423c5568\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96140284\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3144f39f473e238374dd4005c8b83e19764ae9e\",\"title\":\"Hybrid Learning of Optical Flow and Next Frame Prediction to Boost Optical Flow in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/e3144f39f473e238374dd4005c8b83e19764ae9e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04608\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b99ef13af9802bc77fb1b51dc68538ef7a01a5e1\",\"title\":\"Forecasting Future Sequence of Actions to Complete an Activity\",\"url\":\"https://www.semanticscholar.org/paper/b99ef13af9802bc77fb1b51dc68538ef7a01a5e1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056868\",\"name\":\"Xingguang Li\"},{\"authorId\":\"153539287\",\"name\":\"Wenjun Song\"},{\"authorId\":\"2038034798\",\"name\":\"Zonglin Liang\"}],\"doi\":\"10.3233/JIFS-191129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6c99f021512eac39162bcaf3dd4966523f09ae4\",\"title\":\"Emotion recognition from speech using deep learning on spectrograms\",\"url\":\"https://www.semanticscholar.org/paper/a6c99f021512eac39162bcaf3dd4966523f09ae4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40069761\",\"name\":\"Auston Sterling\"},{\"authorId\":\"46939093\",\"name\":\"J. Wilson\"},{\"authorId\":\"40623145\",\"name\":\"S. Lowe\"},{\"authorId\":\"144247566\",\"name\":\"M. Lin\"}],\"doi\":\"10.1007/978-3-030-01267-0_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d95d29db6778c6a2c6c6415f22814864348708e\",\"title\":\"ISNN: Impact Sound Neural Network for Audio-Visual Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/4d95d29db6778c6a2c6c6415f22814864348708e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31372985\",\"name\":\"Shafina Bibi\"},{\"authorId\":\"1969896\",\"name\":\"Nadeem Anjum\"},{\"authorId\":\"1742471\",\"name\":\"T. Amjad\"},{\"authorId\":\"50122854\",\"name\":\"G. McRobbie\"},{\"authorId\":\"1728223\",\"name\":\"N. Ramzan\"}],\"doi\":\"10.1109/access.2020.3012557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c557611948b7235b080feca5bce5856b86d61c7f\",\"title\":\"Human Interaction Anticipation by Combining Deep Features and Transformed Optical Flow Components\",\"url\":\"https://www.semanticscholar.org/paper/c557611948b7235b080feca5bce5856b86d61c7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.11474\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58539-6_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c47ef056ac57e83405f9ee63c32c6a185011d187\",\"title\":\"SoundSpaces: Audio-Visual Navigation in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/c47ef056ac57e83405f9ee63c32c6a185011d187\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.07528\",\"authors\":[{\"authorId\":\"2121780\",\"name\":\"D. Gunning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"727f114602eeae6e83563e46390ea8d6b6c76a0e\",\"title\":\"Machine Common Sense Concept Paper\",\"url\":\"https://www.semanticscholar.org/paper/727f114602eeae6e83563e46390ea8d6b6c76a0e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2770888\",\"name\":\"W. Coleman\"},{\"authorId\":\"103076474\",\"name\":\"C. Cullen\"},{\"authorId\":\"1406163037\",\"name\":\"Ming Yan\"},{\"authorId\":\"2366069\",\"name\":\"Sarah Jane Delany\"}],\"doi\":\"10.1007/978-3-030-57321-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73cf44902fcf7f7de15f3c44ee40a7bfefa25dc6\",\"title\":\"Active Learning for Auditory Hierarchy\",\"url\":\"https://www.semanticscholar.org/paper/73cf44902fcf7f7de15f3c44ee40a7bfefa25dc6\",\"venue\":\"CD-MAKE\",\"year\":2020},{\"arxivId\":\"2008.02441\",\"authors\":[{\"authorId\":\"1391202645\",\"name\":\"Junwen Chen\"},{\"authorId\":\"2342453\",\"name\":\"Wentao Bao\"},{\"authorId\":\"1798119797\",\"name\":\"Yu Kong\"}],\"doi\":\"10.1007/978-3-030-58589-1_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4830393aa75613a29c256078b89f85a02171bbfb\",\"title\":\"Group Activity Prediction with Sequential Relational Anticipation Model\",\"url\":\"https://www.semanticscholar.org/paper/4830393aa75613a29c256078b89f85a02171bbfb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32553939\",\"name\":\"S. Pini\"},{\"authorId\":\"3314152\",\"name\":\"O. Ahmed\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"}],\"doi\":\"10.1145/3136755.3143006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1d00801743ec8ed512aa3008dc871a59839bfca\",\"title\":\"Modeling multimodal cues in a deep learning-based framework for emotion recognition in the wild\",\"url\":\"https://www.semanticscholar.org/paper/e1d00801743ec8ed512aa3008dc871a59839bfca\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46736172\",\"name\":\"Ning Wang\"},{\"authorId\":\"2255687\",\"name\":\"Yibing Song\"},{\"authorId\":\"144905350\",\"name\":\"Chao Ma\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f90f1f3a74cd12073610f8cf8713ef3d9049e2f\",\"title\":\"Correlation Filter Correlation Filter ( a ) Unsupervised Learning Motivation Template Patch Search Patch Search Patch Template Patch Forward Tracking using Initial Label Backward Tracking using Pseudo Label Consistency\",\"url\":\"https://www.semanticscholar.org/paper/7f90f1f3a74cd12073610f8cf8713ef3d9049e2f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1612.00132\",\"authors\":[{\"authorId\":\"5291972\",\"name\":\"Jiajun Lu\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f8fa634a2f0fbb6ce03d245854957d44ff15afa\",\"title\":\"CDVAE: Co-embedding Deep Variational Auto Encoder for Conditional Variational Generation\",\"url\":\"https://www.semanticscholar.org/paper/3f8fa634a2f0fbb6ce03d245854957d44ff15afa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.06314\",\"authors\":[{\"authorId\":\"35497458\",\"name\":\"M. H. Baig\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d13f0a196752eb795182b3df2150322dde05ab01\",\"title\":\"Colorization for Image Compression\",\"url\":\"https://www.semanticscholar.org/paper/d13f0a196752eb795182b3df2150322dde05ab01\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64ab7408ea3e78b7319ff062a5c9df0faf741d0d\",\"title\":\"CSCI 699 ML4Know: Midterm Report\",\"url\":\"https://www.semanticscholar.org/paper/64ab7408ea3e78b7319ff062a5c9df0faf741d0d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144396280\",\"name\":\"Yongjin Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"9637828\",\"name\":\"Junho Jin\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"}],\"doi\":\"10.1016/j.eswa.2017.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f6720bd97d74b57fd297dce197c680aed009e05\",\"title\":\"Hierarchically linked infinite hidden Markov model based trajectory analysis and semantic region retrieval in a trajectory dataset\",\"url\":\"https://www.semanticscholar.org/paper/5f6720bd97d74b57fd297dce197c680aed009e05\",\"venue\":\"Expert Syst. Appl.\",\"year\":2017},{\"arxivId\":\"1612.00197\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"33452695\",\"name\":\"R. DiPietro\"},{\"authorId\":\"1816169\",\"name\":\"Maximilian Baust\"}],\"doi\":\"10.1109/ICCV.2017.388\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"162d2b37d39ca9824800c0bc482d14a239f11a8c\",\"title\":\"Learning in an Uncertain World: Representing Ambiguity Through Multiple Hypotheses\",\"url\":\"https://www.semanticscholar.org/paper/162d2b37d39ca9824800c0bc482d14a239f11a8c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"title\":\"ops Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093957\",\"name\":\"Jingya Wang\"},{\"authorId\":\"34963860\",\"name\":\"M. Korayem\"},{\"authorId\":\"144635079\",\"name\":\"Sa\\u00fal A. Blanco\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1145/2964284.2984067\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f87565f92d0d8da7e667e890e748512ab1c4456\",\"title\":\"Tracking Natural Events through Social Media and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/4f87565f92d0d8da7e667e890e748512ab1c4456\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1803.10827\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"2456400\",\"name\":\"Hessam Bagherinezhad\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00426\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a63b8429ebeef316a65a94b021ef9a214c705f83\",\"title\":\"Who Let the Dogs Out? Modeling Dog Behavior from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/a63b8429ebeef316a65a94b021ef9a214c705f83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.03201\",\"authors\":[{\"authorId\":\"51230038\",\"name\":\"Eadom Dessalene\"},{\"authorId\":\"2739186\",\"name\":\"Michael Maynord\"},{\"authorId\":\"39685196\",\"name\":\"Chinmaya Devaraj\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50f9b0fb3448435f569e702aacc02bac4298d314\",\"title\":\"Egocentric Object Manipulation Graphs\",\"url\":\"https://www.semanticscholar.org/paper/50f9b0fb3448435f569e702aacc02bac4298d314\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102022969\",\"name\":\"ArielRosenfeld\"},{\"authorId\":\"101963919\",\"name\":\"SaritKraus\"}],\"doi\":\"10.2200/S00820ED1V01Y201712AIM036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42d1be2272c31d288ba385ae93092252295d9ad9\",\"title\":\"Predicting Human Decision-Making: From Prediction to Action\",\"url\":\"https://www.semanticscholar.org/paper/42d1be2272c31d288ba385ae93092252295d9ad9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.01828\",\"authors\":[{\"authorId\":\"144041170\",\"name\":\"Ning Wang\"},{\"authorId\":\"2255687\",\"name\":\"Yibing Song\"},{\"authorId\":\"144905350\",\"name\":\"Chao Ma\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2019.00140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b6555c46a2d02e713dbd339e7ac7230ace5193f\",\"title\":\"Unsupervised Deep Tracking\",\"url\":\"https://www.semanticscholar.org/paper/8b6555c46a2d02e713dbd339e7ac7230ace5193f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145532503\",\"name\":\"Marco Leo\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11024-6_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"title\":\"Deep Learning for Assistive Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2007.00095\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"title\":\"Deep Learning for Vision-based Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":10533233,\"doi\":\"10.1109/CVPR.2016.18\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":28,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"references\":[{\"arxivId\":\"1505.00687\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2015.320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"title\":\"Unsupervised Learning of Visual Representations Using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2410191\",\"name\":\"L. Pickup\"},{\"authorId\":\"145683519\",\"name\":\"Z. Pan\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"34872975\",\"name\":\"Yi-Chang Shih\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2014.262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ad97ae1e861c21472a29dd2b7037e629f522d7d\",\"title\":\"Seeing the Arrow of Time\",\"url\":\"https://www.semanticscholar.org/paper/9ad97ae1e861c21472a29dd2b7037e629f522d7d\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-642-15552-9_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed01c2706c1dd05de8664bee1e42a628a49480ad\",\"title\":\"A Data-Driven Approach for Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ed01c2706c1dd05de8664bee1e42a628a49480ad\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1403.6382\",\"authors\":[{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"},{\"authorId\":\"2622491\",\"name\":\"H. Azizpour\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPRW.2014.131\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6270baedeba28001cd1b563a199335720d6e0fe0\",\"title\":\"CNN Features Off-the-Shelf: An Astounding Baseline for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6270baedeba28001cd1b563a199335720d6e0fe0\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144315453\",\"name\":\"Mingtao Pei\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2011.6126279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"054e8684578eb6f85cabcfb31ada42a9b7ec8fd6\",\"title\":\"Parsing video events with goal inference and intent prediction\",\"url\":\"https://www.semanticscholar.org/paper/054e8684578eb6f85cabcfb31ada42a9b7ec8fd6\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2011.6126349\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76be79c45335db6d08efcde7843ae298765d4d63\",\"title\":\"Human activity prediction: Early recognition of ongoing activities from streaming videos\",\"url\":\"https://www.semanticscholar.org/paper/76be79c45335db6d08efcde7843ae298765d4d63\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48700486\",\"name\":\"J. Lezama\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2011.6044588\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d43af56f3d107515f32f070432257bc45eb78a\",\"title\":\"Track to the future: Spatio-temporal video segmentation with long-range motion cues\",\"url\":\"https://www.semanticscholar.org/paper/00d43af56f3d107515f32f070432257bc45eb78a\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"2608414\",\"name\":\"C. Olsson\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/978-3-319-10602-1_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8797e45db52d3a59a64bd7ea8f43789cf6ee4fc\",\"title\":\"Predicting Actions from Static Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b8797e45db52d3a59a64bd7ea8f43789cf6ee4fc\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Srivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsupervised learning of video representations using lstm. arXiv\",\"url\":\"\",\"venue\":\"Unsupervised learning of video representations using lstm. arXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1505.05192\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2015.167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"title\":\"Unsupervised Visual Representation Learning by Context Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/TPAMI.2015.2430335\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50a00d4fa9bf2e7bff37bc944ac48b403f5eb097\",\"title\":\"Anticipating Human Activities Using Object Affordances for Reactive Robotic Response\",\"url\":\"https://www.semanticscholar.org/paper/50a00d4fa9bf2e7bff37bc944ac48b403f5eb097\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/CVPR.2014.496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ac54216a10aa4a888b3ba90e7ec87540d3d2d22\",\"title\":\"Reconstructing Storyline Graphs for Image Recommendation from Web Community Photos\",\"url\":\"https://www.semanticscholar.org/paper/7ac54216a10aa4a888b3ba90e7ec87540d3d2d22\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1310.1531\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8de958fead0d8a9619b55c7299df3257c624a96\",\"title\":\"DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8de958fead0d8a9619b55c7299df3257c624a96\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1112.6209\",\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"145834163\",\"name\":\"Kai Chen\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1109/ICASSP.2013.6639343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72e93aa6767ee683de7f001fa72f1314e40a8f35\",\"title\":\"Building high-level features using large scale unsupervised learning\",\"url\":\"https://www.semanticscholar.org/paper/72e93aa6767ee683de7f001fa72f1314e40a8f35\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"144695232\",\"name\":\"Sham M. Kakade\"}],\"doi\":\"10.1109/ICCV.2007.4409012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06a1382a0fc63fb173fe570e7b6a84158d4e06a5\",\"title\":\"Leveraging archival video for building face datasets\",\"url\":\"https://www.semanticscholar.org/paper/06a1382a0fc63fb173fe570e7b6a84158d4e06a5\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2009.5459368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17b1193c0236d36fe369d4982a81cb09fb28cdbf\",\"title\":\"Learning actions from the Web\",\"url\":\"https://www.semanticscholar.org/paper/17b1193c0236d36fe369d4982a81cb09fb28cdbf\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403818358\",\"name\":\"Alonso Patron-Perez\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.5244/C.24.50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b1287ef7fb7cc88ac5353804c7cb8ee264153f9\",\"title\":\"High Five: Recognising human interactions in TV shows\",\"url\":\"https://www.semanticscholar.org/paper/3b1287ef7fb7cc88ac5353804c7cb8ee264153f9\",\"venue\":\"BMVC\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.1109/CVPR.2014.412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0ab8aa7a5b684532b4ff30f8d34b35a99759a46\",\"title\":\"Learning Everything about Anything: Webly-Supervised Visual Concept Learning\",\"url\":\"https://www.semanticscholar.org/paper/b0ab8aa7a5b684532b4ff30f8d34b35a99759a46\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1007/978-3-319-10584-0_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdfedec1341bdd2f0df6cc6f987d867f7173191c\",\"title\":\"Action-Reaction: Forecasting the Dynamics of Human Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fdfedec1341bdd2f0df6cc6f987d867f7173191c\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"title\":\"Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots\",\"url\":\"https://www.semanticscholar.org/paper/db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1406.5362\",\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"}],\"doi\":\"10.1109/CVPR.2015.7298696\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13cf671988172562817cdeb1cc80a87c07a7f1cd\",\"title\":\"Predicting the future behavior of a time-varying probability distribution\",\"url\":\"https://www.semanticscholar.org/paper/13cf671988172562817cdeb1cc80a87c07a7f1cd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2013.178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53e4ab9730e983242a3409c7bf1af945041a6563\",\"title\":\"NEIL: Extracting Visual Knowledge from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/53e4ab9730e983242a3409c7bf1af945041a6563\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1505.00295\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2015.281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"title\":\"Dense Optical Flow Prediction from a Static Image\",\"url\":\"https://www.semanticscholar.org/paper/098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-642-33765-9_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8a5addbd17d2c7c8043d8877234675da19938a\",\"title\":\"Activity Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/0d8a5addbd17d2c7c8043d8877234675da19938a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1503.04144\",\"authors\":[{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"1689313\",\"name\":\"Florian Luisier\"},{\"authorId\":\"144941335\",\"name\":\"Walter Andrews\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.5244/C.29.60\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"title\":\"Exploiting Image-trained CNN Architectures for Unconstrained Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2014.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"title\":\"Patch to the Future: Unsupervised Visual Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3232655\",\"name\":\"H. Mobahi\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2c477de72bb7718f5304c6f38457fda9c8334b1\",\"title\":\"Deep learning from temporal coherence in video\",\"url\":\"https://www.semanticscholar.org/paper/e2c477de72bb7718f5304c6f38457fda9c8334b1\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1760137\",\"name\":\"Haifeng Gong\"},{\"authorId\":\"1978562\",\"name\":\"Jack Sim\"},{\"authorId\":\"145371551\",\"name\":\"M. Likhachev\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICCV.2011.6126296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73f84bfad5d3d6cd548ac43702802e2d244ad38d\",\"title\":\"Multi-hypothesis motion planning for visual object tracking\",\"url\":\"https://www.semanticscholar.org/paper/73f84bfad5d3d6cd548ac43702802e2d244ad38d\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1007/s11263-013-0683-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b72756c4d4237a857e1a764c876e82a82edd128c\",\"title\":\"Max-Margin Early Event Detectors\",\"url\":\"https://www.semanticscholar.org/paper/b72756c4d4237a857e1a764c876e82a82edd128c\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948848\",\"name\":\"S. Sadanand\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247806\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"title\":\"Action bank: A high-level representation of activity in video\",\"url\":\"https://www.semanticscholar.org/paper/d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Gorban\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"THUMOS challenge: Action recognition with a large number of classes\",\"year\":2015},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34846285\",\"name\":\"Julian F. P. Kooij\"},{\"authorId\":\"2892316\",\"name\":\"Nicolas Schneider\"},{\"authorId\":\"2869660\",\"name\":\"F. Flohr\"},{\"authorId\":\"144854796\",\"name\":\"D. Gavrila\"}],\"doi\":\"10.1007/978-3-319-10599-4_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90dab18196c20d37b4da55a3ea58c3b4aa231e6d\",\"title\":\"Context-Based Pedestrian Path Prediction\",\"url\":\"https://www.semanticscholar.org/paper/90dab18196c20d37b4da55a3ea58c3b4aa231e6d\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2014.260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c99798fce885b41ab1de66bbacf04b7de7274f85\",\"title\":\"Predicting Object Dynamics in Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c99798fce885b41ab1de66bbacf04b7de7274f85\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/TPAMI.2008.128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d2b5c64a67f65c5dd812b89e07973f97699552\",\"title\":\"80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/54d2b5c64a67f65c5dd812b89e07973f97699552\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1145/2185520.2185597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d913b9d742b99119d96ad2b661f3e7e7c2fa5e2b\",\"title\":\"What makes Paris look like Paris?\",\"url\":\"https://www.semanticscholar.org/paper/d913b9d742b99119d96ad2b661f3e7e7c2fa5e2b\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"2708745\",\"name\":\"Tsung-Chuan Chen\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1007/978-3-319-10578-9_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2edc655b678da8fac7db70c3389070eba8727c5\",\"title\":\"A Hierarchical Representation for Future Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e2edc655b678da8fac7db70c3389070eba8727c5\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48811777\",\"name\":\"Dan Xie\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2013.277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4a3be1de7ea7b07cf6ac98398e8b9bea6cb2dfe\",\"title\":\"Inferring \\\"Dark Matter\\\" and \\\"Dark Energy\\\" from Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4a3be1de7ea7b07cf6ac98398e8b9bea6cb2dfe\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Ikizler-Cinbis\"},{\"authorId\":null,\"name\":\"R G Cinbis\"},{\"authorId\":null,\"name\":\"S Sclaroff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning actions from the web. ICCV\",\"url\":\"\",\"venue\":\"Learning actions from the web. ICCV\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D F Fouhey\"},{\"authorId\":null,\"name\":\"C L Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Predicting object dynamics in scenes. CVPR\",\"url\":\"\",\"venue\":\"Predicting object dynamics in scenes. CVPR\",\"year\":2014}],\"title\":\"Anticipating Visual Representations from Unlabeled Video\",\"topics\":[{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Computer cluster\",\"topicId\":\"8927\",\"url\":\"https://www.semanticscholar.org/topic/8927\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Test set\",\"topicId\":\"24168\",\"url\":\"https://www.semanticscholar.org/topic/24168\"},{\"topic\":\"Tesla (microarchitecture)\",\"topicId\":\"45589\",\"url\":\"https://www.semanticscholar.org/topic/45589\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Computer data storage\",\"topicId\":\"1283\",\"url\":\"https://www.semanticscholar.org/topic/1283\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"