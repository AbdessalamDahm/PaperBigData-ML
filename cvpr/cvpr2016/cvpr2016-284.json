"{\"abstract\":\"What defines an action like \\\"kicking ball\\\"? We argue that the true meaning of an action lies in the change or transformation an action brings to the environment. In this paper, we propose a novel representation for actions by modeling an action as a transformation which changes the state of the environment before the action happens (precondition) to the state after the action (effect). Motivated by recent advancements of video representation using deep learning, we design a Siamese network which models the action as a transformation on a high-level feature space. We show that our model gives improvements on standard action recognition datasets including UCF101 and HMDB51. More importantly, our approach is able to generalize beyond learned action categories and shows significant performance improvement on cross-category generalization on our new ACT dataset.\",\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\",\"url\":\"https://www.semanticscholar.org/author/39849136\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\",\"url\":\"https://www.semanticscholar.org/author/143787583\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\",\"url\":\"https://www.semanticscholar.org/author/1737809\"}],\"citationVelocity\":39,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.01.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"title\":\"Video you only look once: Overall temporal convolutions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"title\":\"Mining Spatial and Spatio-Temporal ROIs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2964284.2964328\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"899be93e14d991017b1f8a4afdf907cbc03cf300\",\"title\":\"Multi-Stream Multi-Class Fusion of Deep Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/899be93e14d991017b1f8a4afdf907cbc03cf300\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"47569745\",\"name\":\"Shaohua Yang\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.18653/v1/P18-1086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b6afc9557dc0670bf2792bde4c4389ac52c707f\",\"title\":\"What Action Causes This? Towards Naive Physical Action-Effect Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6b6afc9557dc0670bf2792bde4c4389ac52c707f\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6323911\",\"name\":\"Jacob Westerberg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9626bcb3fc7c7df2c5a423ae8d0a046b2f69180c\",\"title\":\"A deep learning approach for action classification in American football video sequences\",\"url\":\"https://www.semanticscholar.org/paper/9626bcb3fc7c7df2c5a423ae8d0a046b2f69180c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.09026\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/iccv.2017.314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"title\":\"Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"},{\"authorId\":\"50656755\",\"name\":\"Qing Yuan Zhou\"},{\"authorId\":\"50424096\",\"name\":\"Nicolas Christou\"},{\"authorId\":\"145081360\",\"name\":\"Alan Loddon Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"title\":\"Electronic Theses and Dissertations Title Mining Spatial and Spatio-Temporal ROIs for Action Recognition Permalink\",\"url\":\"https://www.semanticscholar.org/paper/4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"414c85e333a24456a3bb5b194d97e95e69175dea\",\"title\":\"Jointly Recognizing Object Fluents and Tasks in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/414c85e333a24456a3bb5b194d97e95e69175dea\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1804.04810\",\"authors\":[{\"authorId\":\"143758901\",\"name\":\"Jungbeom Lee\"},{\"authorId\":\"2808551\",\"name\":\"Jangho Lee\"},{\"authorId\":\"47090426\",\"name\":\"Sungmin Lee\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3497be24bcecb698a700b02c12e23b305ea0c24c\",\"title\":\"MSnet: Mutual Suppression Network for Disentangled Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/3497be24bcecb698a700b02c12e23b305ea0c24c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.07784\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"title\":\"RECOGNITIONWITH GRADIENT BOUNDARY CONVOLUTIONAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TCSVT.2017.2746092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20970f0db883b76b56bbf080da79f7fc4c4fc805\",\"title\":\"Cross-Agent Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/20970f0db883b76b56bbf080da79f7fc4c4fc805\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"47628927\",\"name\":\"Mingyang Li\"},{\"authorId\":null,\"name\":\"He Bai\"},{\"authorId\":\"88502672\",\"name\":\"L. Ma\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"}],\"doi\":\"10.1007/s00521-019-04030-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"title\":\"DKD\\u2013DAD: a novel framework with discriminative kinematic descriptor and deep attention-pooled descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.5244/C.30.142\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bf7ce197b9311f698e7c9e44e4b7ca2871674a36\",\"title\":\"Beyond Action Recognition: Action Completion in RGB-D Data\",\"url\":\"https://www.semanticscholar.org/paper/bf7ce197b9311f698e7c9e44e4b7ca2871674a36\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1612.00881\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1109/CVPR.2017.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f31de384bee955d8faffa1efe5f7b51cb299381\",\"title\":\"Procedural Generation of Videos to Train Deep Action Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f31de384bee955d8faffa1efe5f7b51cb299381\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1605.04988\",\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.imavis.2017.01.010\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"title\":\"Going deeper into action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":\"1808.04545\",\"authors\":[{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"51114494\",\"name\":\"Akash Rastogi\"},{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1733732\",\"name\":\"Sunil Hadap\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1007/978-3-030-01228-1_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ce852f1e9b6d8d97787127d43dcbec1cdeeda09\",\"title\":\"MT-VAE: Learning Motion Transformations to Generate Multimodal Human Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/2ce852f1e9b6d8d97787127d43dcbec1cdeeda09\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1706.04508\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TMM.2018.2823900\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"title\":\"Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/36ab143da8b6f6d49811afaaa7bcbf81c22a210e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1805.11223\",\"authors\":[{\"authorId\":\"9102201\",\"name\":\"Yaxiang Fan\"},{\"authorId\":\"144334479\",\"name\":\"Gongjian Wen\"},{\"authorId\":\"143638182\",\"name\":\"D. Li\"},{\"authorId\":\"3437649\",\"name\":\"Shaohua Qiu\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"}],\"doi\":\"10.1016/j.cviu.2020.102920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d880d303ee0bfdbc80fc34df0978088cd15ce861\",\"title\":\"Video Anomaly Detection and Localization via Gaussian Mixture Fully Convolutional Variational Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/d880d303ee0bfdbc80fc34df0978088cd15ce861\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1909.09422\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"title\":\"Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos\",\"url\":\"https://www.semanticscholar.org/paper/3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1701.07368\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/CVPRW.2017.161\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"title\":\"Deep Local Video Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23124669\",\"name\":\"Jiewan Zheng\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"7883602\",\"name\":\"Xiangbo Su\"}],\"doi\":\"10.1109/TNNLS.2018.2844464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc95fb644c12ee9caa989390af29c969b4c1d646\",\"title\":\"Deep Ensemble Machine for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc95fb644c12ee9caa989390af29c969b4c1d646\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576171686\",\"name\":\"Denys Volodymyrovych Soldatov\"}],\"doi\":\"10.20535/2617-0965.2019.2.3.164709\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"949981340608476488f5e287f9828546c64d9132\",\"title\":\"Action and movements recognition methods\",\"url\":\"https://www.semanticscholar.org/paper/949981340608476488f5e287f9828546c64d9132\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9400214\",\"name\":\"Guangxing Han\"},{\"authorId\":\"37735027\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"3244057\",\"name\":\"Chongrong Li\"}],\"doi\":\"10.1145/3240508.3240693\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5bacb5489537012805e88ad7f4f70c96a438f88\",\"title\":\"Semi-Supervised DFF: Decoupling Detection and Feature Flow for Video Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/c5bacb5489537012805e88ad7f4f70c96a438f88\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1609.05420\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a69099ad60804816d1c2d884d4844105b0480082\",\"title\":\"Pose from Action: Unsupervised Learning of Pose Features based on Motion\",\"url\":\"https://www.semanticscholar.org/paper/a69099ad60804816d1c2d884d4844105b0480082\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"35517688\",\"name\":\"Hugo Bertiche\"},{\"authorId\":\"145653560\",\"name\":\"Vicent Roig\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/ICCVW.2017.376\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"title\":\"Action Recognition from RGB-D Data: Comparison and Fusion of Spatio-Temporal Handcrafted Features and Deep Strategies\",\"url\":\"https://www.semanticscholar.org/paper/8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1708.02191\",\"authors\":[{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"39168231\",\"name\":\"Guangyu Zhong\"},{\"authorId\":\"143880075\",\"name\":\"X. Yu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":\"10.1109/ICCV.2017.630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"052f994898c79529955917f3dfc5181586282cf8\",\"title\":\"Unsupervised Domain Adaptation for Face Recognition in Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/052f994898c79529955917f3dfc5181586282cf8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296302\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"title\":\"SCNN: Sequential convolutional neural network for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/CVPR.2017.604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ICAICTA.2019.8904245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"title\":\"Action Recognition by Composite Deep Learning Architecture I3D-DenseLSTM\",\"url\":\"https://www.semanticscholar.org/paper/6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13916641\",\"name\":\"Jiarong Song\"},{\"authorId\":\"48599025\",\"name\":\"Zhong Yang\"},{\"authorId\":\"49347069\",\"name\":\"Qiuyan Zhang\"},{\"authorId\":\"49363806\",\"name\":\"Ting Fang\"},{\"authorId\":\"49433951\",\"name\":\"Guoxiong Hu\"},{\"authorId\":\"4945374\",\"name\":\"Jiaming Han\"},{\"authorId\":\"46729542\",\"name\":\"C. Chen\"}],\"doi\":\"10.1007/978-3-030-04167-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ff10c914e6905a9ab78da6a001650625451b52e\",\"title\":\"Human Action Recognition with 3D Convolution Skip-Connections and RNNs\",\"url\":\"https://www.semanticscholar.org/paper/3ff10c914e6905a9ab78da6a001650625451b52e\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"}],\"doi\":\"10.1109/TMM.2017.2749159\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"title\":\"Two-Stream 3-D convNet Fusion for Action Recognition in Videos With Arbitrary Size and Length\",\"url\":\"https://www.semanticscholar.org/paper/93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"}],\"doi\":\"10.1109/ICIP.2018.8451226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c6655ab00cf3fbcb412949e85204b608937c881\",\"title\":\"Action Recognition Based on Discriminative Embedding of Actions Using Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6655ab00cf3fbcb412949e85204b608937c881\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"137c394dc72f7a0dda9200dff4579c78a96a998f\",\"title\":\"Geometric + Kinematic Priors and Part-based Graph Convolutional Network for Skeleton-based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/137c394dc72f7a0dda9200dff4579c78a96a998f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1705.08080\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"3386570\",\"name\":\"Eric Kolve\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"51230553\",\"name\":\"A. Gupta\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/ICCV.2017.60\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4558b932075a862c72bb98bbce5f08590f563b14\",\"title\":\"Visual Semantic Planning Using Deep Successor Representations\",\"url\":\"https://www.semanticscholar.org/paper/4558b932075a862c72bb98bbce5f08590f563b14\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"}],\"doi\":\"10.1007/s11042-017-5017-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efe1ff6a4b2fe67c28be4c21d49641e51cefa599\",\"title\":\"Supervised spatio-temporal kernel descriptor for human action recognition from RGB-depth videos\",\"url\":\"https://www.semanticscholar.org/paper/efe1ff6a4b2fe67c28be4c21d49641e51cefa599\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1608.04339\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-319-46604-0_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9abd35b37a49ee1295e8197aac59bde802a934f3\",\"title\":\"Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9abd35b37a49ee1295e8197aac59bde802a934f3\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1811.05014\",\"authors\":[{\"authorId\":\"47244850\",\"name\":\"Rongcheng Lin\"},{\"authorId\":\"144033366\",\"name\":\"J. Xiao\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1007/978-3-030-11018-5_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"919548553251d5cf92a2cb50e87d29b862613bb5\",\"title\":\"NeXtVLAD: An Efficient Neural Network to Aggregate Frame-level Features for Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/919548553251d5cf92a2cb50e87d29b862613bb5\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"47557959\",\"name\":\"Y. Chen\"},{\"authorId\":\"47462870\",\"name\":\"Ruotao Xu\"},{\"authorId\":\"153172100\",\"name\":\"Hui Ji\"}],\"doi\":\"10.1016/J.CVIU.2019.102794\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"title\":\"Attention with structure regularization for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"title\":\"Diversity encouraging ensemble of convolutional networks for high performance action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.07230\",\"authors\":[{\"authorId\":\"2308598\",\"name\":\"U. Ahsan\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f6d6c99fe5011d925d892725ff0c8cbbd7db3ba\",\"title\":\"DiscrimNet: Semi-Supervised Action Recognition from Videos using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5f6d6c99fe5011d925d892725ff0c8cbbd7db3ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.02522\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"title\":\"Joint Attention in Driver-Pedestrian Interaction: from Theory to Practice\",\"url\":\"https://www.semanticscholar.org/paper/a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.06749\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89d7aa10ad97251089d0204916f784f137f3a1ec\",\"title\":\"Action Completion: A Temporal Model for Moment Detection\",\"url\":\"https://www.semanticscholar.org/paper/89d7aa10ad97251089d0204916f784f137f3a1ec\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1906.06813\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/WACV.2018.00045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"title\":\"A Temporal Sequence Learning for Action Recognition and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1702.02738\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":\"10.1109/ICCV.2017.234\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"993f0793ca7217e03afbd29346d03c01109acc49\",\"title\":\"Joint Discovery of Object States and Manipulation Actions\",\"url\":\"https://www.semanticscholar.org/paper/993f0793ca7217e03afbd29346d03c01109acc49\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"},{\"authorId\":\"144538257\",\"name\":\"Y. Weiss\"}],\"doi\":\"10.1007/978-3-030-01228-1\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"474c8f4e31a51e2cb3c1e9fed83202b4483efb35\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/474c8f4e31a51e2cb3c1e9fed83202b4483efb35\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"144466591\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2018.2882061\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5a9167cd2914b9c19315cfca9162e0d4c90621b\",\"title\":\"Predicting Diverse Future Frames With Local Transformation-Guided Masking\",\"url\":\"https://www.semanticscholar.org/paper/d5a9167cd2914b9c19315cfca9162e0d4c90621b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd000f4a7a64db5e00b200b93cc3f13c9e313c01\",\"title\":\"Attributes as Operators\",\"url\":\"https://www.semanticscholar.org/paper/cd000f4a7a64db5e00b200b93cc3f13c9e313c01\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.05928\",\"authors\":[{\"authorId\":\"12229916\",\"name\":\"Z. Wang\"},{\"authorId\":\"145895122\",\"name\":\"S. Rosa\"},{\"authorId\":\"11246861\",\"name\":\"Linhai Xie\"},{\"authorId\":\"143787134\",\"name\":\"Bo Yang\"},{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"3641238\",\"name\":\"A. Trigoni\"},{\"authorId\":\"34401562\",\"name\":\"A. Markham\"}],\"doi\":\"10.1109/ICRA.2018.8462832\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aae7bde6972328de6c23a510fe59254854163308\",\"title\":\"DEFO-NET: Learning Body Deformation Using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/aae7bde6972328de6c23a510fe59254854163308\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":\"1705.09894\",\"authors\":[{\"authorId\":\"38689120\",\"name\":\"Brandon Victor\"},{\"authorId\":\"1787185\",\"name\":\"Z. He\"},{\"authorId\":\"31548192\",\"name\":\"S. Morgan\"},{\"authorId\":\"2874225\",\"name\":\"D. Miniutti\"}],\"doi\":\"10.1109/CVPRW.2017.21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8820d1d3fa73cde623662d92ecf2e3faf1e3f328\",\"title\":\"Continuous Video to Simple Signals for Swimming Stroke Detection with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8820d1d3fa73cde623662d92ecf2e3faf1e3f328\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3073314\",\"name\":\"Yongqing Sun\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"1764762\",\"name\":\"H. Arai\"},{\"authorId\":\"31468482\",\"name\":\"Tetsuya Kinebuchi\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/2964284.2967199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"997b9ffe2f752ba84a66730cfd320d040e7ba2e2\",\"title\":\"Exploiting Objects with LSTMs for Video Categorization\",\"url\":\"https://www.semanticscholar.org/paper/997b9ffe2f752ba84a66730cfd320d040e7ba2e2\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120775311\",\"name\":\"D. Wu\"},{\"authorId\":\"49251523\",\"name\":\"Junjun Chen\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"2585415\",\"name\":\"Shirui Pan\"},{\"authorId\":\"97846126\",\"name\":\"Guodong Long\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN.2019.8851993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cd307e67ac0bbcf2c2f4abc1bbc643067b57fb0\",\"title\":\"Adversarial Action Data Augmentation for Similar Gesture Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cd307e67ac0bbcf2c2f4abc1bbc643067b57fb0\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1804.08758\",\"authors\":[{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"39168231\",\"name\":\"Guangyu Zhong\"},{\"authorId\":\"24817039\",\"name\":\"Shalini De Mello\"},{\"authorId\":\"143785523\",\"name\":\"Jinwei Gu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1007/978-3-030-01234-2_6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e6a5008be4e26ae34ba7528ddc752e40532988a\",\"title\":\"Switchable Temporal Propagation Network\",\"url\":\"https://www.semanticscholar.org/paper/9e6a5008be4e26ae34ba7528ddc752e40532988a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1708.01246\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"144688398\",\"name\":\"Maneesh Kumar Singh\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.79\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de40803a3d17dd406e25922695266d6ed580e371\",\"title\":\"Unsupervised Representation Learning by Sorting Sequences\",\"url\":\"https://www.semanticscholar.org/paper/de40803a3d17dd406e25922695266d6ed580e371\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930831020\",\"name\":\"Lorxayxang Kai\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"},{\"authorId\":\"3017565\",\"name\":\"Xiaodong Dai\"},{\"authorId\":\"81498564\",\"name\":\"M. Ma\"}],\"doi\":\"10.1007/978-3-030-57884-8_71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"title\":\"Fast Video Classification with CNNs in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35258643\",\"name\":\"S. Jothi\"},{\"authorId\":null,\"name\":\"Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.35940/ijitee.i7914.078919\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"611dc0fa4b0beb0ac8fa0bf3bbf24f089adf3fe5\",\"title\":\"Anomaly Detection in Video Events using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/611dc0fa4b0beb0ac8fa0bf3bbf24f089adf3fe5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1016/j.patcog.2018.07.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"756532d707209f13c44b96e6306ac0c96e6733a5\",\"title\":\"Asymmetric 3D Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/756532d707209f13c44b96e6306ac0c96e6733a5\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9102201\",\"name\":\"Yaxiang Fan\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"},{\"authorId\":\"144334479\",\"name\":\"Gongjian Wen\"},{\"authorId\":\"3437649\",\"name\":\"Shaohua Qiu\"}],\"doi\":\"10.1016/j.neucom.2017.02.082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fe7239546e34ede6579fad5d7f36317c850fefd\",\"title\":\"A deep neural network for real-time detection of falling humans in naturally occurring scenes\",\"url\":\"https://www.semanticscholar.org/paper/9fe7239546e34ede6579fad5d7f36317c850fefd\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.786\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"title\":\"Temporal Residual Networks for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713611\",\"name\":\"J. Filipe\"},{\"authorId\":\"17324395\",\"name\":\"A. Ghosh\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"71888255\",\"name\":\"Zhanjun Hao\"},{\"authorId\":\"70226424\",\"name\":\"X. Dang\"},{\"authorId\":\"49178133\",\"name\":\"Honghong Chen\"},{\"authorId\":\"24521940\",\"name\":\"Fenfang Li\"}],\"doi\":\"10.1007/978-981-33-4214-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c326ae12396c2a5c4efc123db4d8ddc1e375c32b\",\"title\":\"Wireless Sensor Networks: 14th China Conference, CWSN 2020, Dunhuang, China, September 18\\u201321, 2020, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/c326ae12396c2a5c4efc123db4d8ddc1e375c32b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1604.08826\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2859204\",\"name\":\"Masatoshi Hidaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"title\":\"Improved Dense Trajectory with Cross Streams\",\"url\":\"https://www.semanticscholar.org/paper/da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403194286\",\"name\":\"Omar Costilla-Reyes\"},{\"authorId\":\"1402712530\",\"name\":\"R. Vera-Rodr\\u00edguez\"},{\"authorId\":\"151379036\",\"name\":\"Abdullah S. Alharthi\"},{\"authorId\":\"103667326\",\"name\":\"S. U. Yunas\"},{\"authorId\":\"3038893\",\"name\":\"K. Ozanyan\"}],\"doi\":\"10.1007/978-3-030-31760-7_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5d1ecd5378254a48c38a7c786efb23b9ad5feec\",\"title\":\"Deep learning in gait analysis for security and healthcare\",\"url\":\"https://www.semanticscholar.org/paper/d5d1ecd5378254a48c38a7c786efb23b9ad5feec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.03879\",\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1007/978-3-030-12939-2_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"title\":\"Cross and Learn: Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"146761298\",\"name\":\"Fu Xiaoc\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TCSVT.2019.2918591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"title\":\"Discriminative Multi-View Subspace Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004905657\",\"name\":\"Rihem Mahmoud\"},{\"authorId\":\"1757886\",\"name\":\"S. Belgacem\"},{\"authorId\":\"3169159\",\"name\":\"M. Omri\"}],\"doi\":\"10.1016/j.jksuci.2020.08.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"title\":\"Deep Signature-based Isolated and Large Scale Continuous Gesture Recognition Approach\",\"url\":\"https://www.semanticscholar.org/paper/52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"15223978\",\"name\":\"Xingming Sun\"},{\"authorId\":\"46583977\",\"name\":\"J. Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-981-15-8083-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"title\":\"Artificial Intelligence and Security: 6th International Conference, ICAIS 2020, Hohhot, China, July 17\\u201320, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33124583\",\"name\":\"Yixiao Yun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cc8f79365b9e6e0e12f83ee305fefc9b3089bbf\",\"title\":\"Riemannian Manifold-Based Modeling and Classification Methods for Video Activities with Applications to Assisted Living and Smart Home\",\"url\":\"https://www.semanticscholar.org/paper/7cc8f79365b9e6e0e12f83ee305fefc9b3089bbf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2902676\",\"name\":\"Menghua Zhai\"}],\"doi\":\"10.13023/etd.2018.458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"850043221fa1466185c8826480096bb691dd6dd5\",\"title\":\"Deep Probabilistic Models for Camera Geo-Calibration\",\"url\":\"https://www.semanticscholar.org/paper/850043221fa1466185c8826480096bb691dd6dd5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780024\",\"name\":\"R. Polikar\"}],\"doi\":\"10.1007/978-3-030-12939-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b05362caf719e2161f04b035c54b3172d6749cdb\",\"title\":\"Pattern Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b05362caf719e2161f04b035c54b3172d6749cdb\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1612.03052\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"144660077\",\"name\":\"Jan Neumann\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"title\":\"ActionFlowNet: Learning Motion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":null,\"name\":\"Gedas Bertasius\"},{\"authorId\":null,\"name\":\"Tae-Hyun Oh\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39796129\",\"name\":\"Hayden Faulkner\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":\"10.1109/DICTA.2017.8227494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"title\":\"TenniSet: A Dataset for Dense Fine-Grained Event Recognition, Localisation and Description\",\"url\":\"https://www.semanticscholar.org/paper/4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1910.12295\",\"authors\":[{\"authorId\":\"47244850\",\"name\":\"Rongcheng Lin\"},{\"authorId\":\"46852065\",\"name\":\"J. Xiao\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaca4be112f752d9aa6fa68412a5bb609b1642a0\",\"title\":\"MOD: A Deep Mixture Model with Online Knowledge Distillation for Large Scale Video Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/eaca4be112f752d9aa6fa68412a5bb609b1642a0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1611.05520\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"title\":\"Deep Action- and Context-Aware Sequence Learning for Activity Recognition and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/b98d69f8e9f37a5d8622579caa308378f5b5f8dd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1109/ICSP.2018.8652359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"494f3f390442c622fd47d3c75316c3f9737bfa97\",\"title\":\"Temporal Pyramid Pooling Based Relation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/494f3f390442c622fd47d3c75316c3f9737bfa97\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"47740566\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"title\":\"Action recognition with gradient boundary convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143758901\",\"name\":\"Jungbeom Lee\"},{\"authorId\":\"3300485\",\"name\":\"J. Lee\"},{\"authorId\":\"153310690\",\"name\":\"Sungmin Lee\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca39fe1518cd12fcbc9c653fcf6c79949be236ef\",\"title\":\"Mutual Suppression Network for Video Prediction using Disentangled Features\",\"url\":\"https://www.semanticscholar.org/paper/ca39fe1518cd12fcbc9c653fcf6c79949be236ef\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49308892\",\"name\":\"Mahlagha Afrasiabi\"},{\"authorId\":\"2264128\",\"name\":\"H. Khotanlou\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"}],\"doi\":\"10.1007/s11042-020-08845-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"233fde55a797ac4fcd018bb2e7e967e51731c341\",\"title\":\"Spatial-temporal dual-actor CNN for human interaction prediction in video\",\"url\":\"https://www.semanticscholar.org/paper/233fde55a797ac4fcd018bb2e7e967e51731c341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/ICCVW.2017.46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73598ca47948fa18e051ce5173d7556e0f485489\",\"title\":\"Adaptive Pooling in Multi-instance Learning for Web Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/73598ca47948fa18e051ce5173d7556e0f485489\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.06964\",\"authors\":[{\"authorId\":\"145116380\",\"name\":\"Eric Jang\"},{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6d8ebfd88ee333deccce32b09ee41d271af6dc4\",\"title\":\"Grasp2Vec: Learning Object Representations from Self-Supervised Grasping\",\"url\":\"https://www.semanticscholar.org/paper/e6d8ebfd88ee333deccce32b09ee41d271af6dc4\",\"venue\":\"CoRL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed9b230a1629049656c62bf4434d1212faeacc1f\",\"title\":\"C V ] 9 N ov 2 01 8 Cross and Learn : Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/ed9b230a1629049656c62bf4434d1212faeacc1f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cc4618ce3811d2d14f23ec28ee462fa040f469c9\",\"title\":\"Interpretable representation learning for visual intelligence\",\"url\":\"https://www.semanticscholar.org/paper/cc4618ce3811d2d14f23ec28ee462fa040f469c9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144195544\",\"name\":\"S. Shri\"},{\"authorId\":\"30990524\",\"name\":\"S. Jothilakshmi\"}],\"doi\":\"10.1016/J.COMCOM.2019.07.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d10ce66a13a6e2d270329f47aae1761cf4389\",\"title\":\"Crowd Video Event Classification using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/476d10ce66a13a6e2d270329f47aae1761cf4389\",\"venue\":\"Comput. Commun.\",\"year\":2019},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-59126-1_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81ede08b36f3abd423424804da8ff240606b3a5d\",\"title\":\"Top-Down Deep Appearance Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/81ede08b36f3abd423424804da8ff240606b3a5d\",\"venue\":\"SCIA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631862\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/s11042-019-7700-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad6493b57050955d9686b3c1fc84a19195852f8c\",\"title\":\"Computer vision based working environment monitoring to analyze Generalized Anxiety Disorder (GAD)\",\"url\":\"https://www.semanticscholar.org/paper/ad6493b57050955d9686b3c1fc84a19195852f8c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1710.02310\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2ad264201e0628723af373d17f8ed98408e8dda0\",\"title\":\"Detecting the Moment of Completion: Temporal Models for Localising Action Completion\",\"url\":\"https://www.semanticscholar.org/paper/2ad264201e0628723af373d17f8ed98408e8dda0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"2007.04515\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":\"10.1007/978-3-030-58574-7_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e3a6c70799ee375e4b6035f59236677439c41a5\",\"title\":\"Aligning Videos in Space and Time\",\"url\":\"https://www.semanticscholar.org/paper/9e3a6c70799ee375e4b6035f59236677439c41a5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-319-69900-4_70\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"title\":\"Two-Stream Convolutional Network with Multi-level Feature Fusion for Categorization of Human Action from Videos\",\"url\":\"https://www.semanticscholar.org/paper/bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"1713084\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/tpami.2020.2976971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaccf98302c256f49c7691dd906716ff50e3a44b\",\"title\":\"A Generalized Earley Parser for Human Activity Parsing and Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/aaccf98302c256f49c7691dd906716ff50e3a44b\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10700\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"144585402\",\"name\":\"Peng Zhang\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3343031.3351040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"title\":\"Explainable Video Action Reasoning via Prior Knowledge and State Transitions\",\"url\":\"https://www.semanticscholar.org/paper/7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.09851\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01246-5_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a34e5c66bd553d8a75e13084fb7a81217c21e33b\",\"title\":\"Attributes as Operators: Factorizing Unseen Attribute-Object Compositions\",\"url\":\"https://www.semanticscholar.org/paper/a34e5c66bd553d8a75e13084fb7a81217c21e33b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2011.13160\",\"authors\":[{\"authorId\":\"145251354\",\"name\":\"Xin Hong\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"70414094\",\"name\":\"J. Guo\"},{\"authorId\":\"30857876\",\"name\":\"Xueqi Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"825363a518902f3e44d61bd9a10262d0e527be60\",\"title\":\"Transformation Driven Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/825363a518902f3e44d61bd9a10262d0e527be60\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":5651336,\"doi\":\"10.1109/CVPR.2016.291\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":23,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3de050d1707524512eeab99780df3cbdee09670c\",\"title\":\"DevNet: A Deep Event Network for multimedia event detection and evidence recounting\",\"url\":\"https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1412.6622\",\"authors\":[{\"authorId\":\"40555034\",\"name\":\"E. Hoffer\"},{\"authorId\":\"2048494\",\"name\":\"Nir Ailon\"}],\"doi\":\"10.1007/978-3-319-24261-3_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca\",\"title\":\"Deep Metric Learning Using Triplet Network\",\"url\":\"https://www.semanticscholar.org/paper/3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca\",\"venue\":\"SIMBAD\",\"year\":2015},{\"arxivId\":\"1202.1694\",\"authors\":[{\"authorId\":\"50262304\",\"name\":\"Yun Jiang\"},{\"authorId\":\"143940975\",\"name\":\"Marcus Lim\"},{\"authorId\":\"39294084\",\"name\":\"C. Zheng\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1177/0278364912438781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7402411d86b724a3f7851795ecd801f8b9da48d4\",\"title\":\"Learning to place new objects in a scene\",\"url\":\"https://www.semanticscholar.org/paper/7402411d86b724a3f7851795ecd801f8b9da48d4\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2012},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1312.6034\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71\",\"title\":\"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2315504\",\"name\":\"Raia Hadsell\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/CVPR.2005.202\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfaae9b6857b834043606df3342d8dc97524aa9d\",\"title\":\"Learning a similarity metric discriminatively, with application to face verification\",\"url\":\"https://www.semanticscholar.org/paper/cfaae9b6857b834043606df3342d8dc97524aa9d\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1412.6537\",\"authors\":[{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"1995333\",\"name\":\"Eduard Trulls\"},{\"authorId\":\"147306748\",\"name\":\"Luis Ferraz\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"205e985af9fed380a68b1dd581fa23aaa6b3b3ef\",\"title\":\"Fracking Deep Convolutional Image Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/205e985af9fed380a68b1dd581fa23aaa6b3b3ef\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Modeling actions through state changes\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2013},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/CVPR.2015.7298616\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Ji\"},{\"authorId\":null,\"name\":\"W Xu\"},{\"authorId\":null,\"name\":\"M Yang\"},{\"authorId\":null,\"name\":\"K Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tional neural networks for human action recognition\",\"url\":\"\",\"venue\":\"TPAMI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-642-33765-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40493e58880b5bc51e38d2831f0a4e6c1b01bde8\",\"title\":\"Recognizing Complex Events Using Large Margin Joint Low-Level Event Model\",\"url\":\"https://www.semanticscholar.org/paper/40493e58880b5bc51e38d2831f0a4e6c1b01bde8\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1504.00983\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1145/2733373.2806226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3634b4dd263c0f330245c086ce646c9bb748cd6b\",\"title\":\"Temporal Localization of Fine-Grained Actions in Videos by Domain Transfer from Web Images\",\"url\":\"https://www.semanticscholar.org/paper/3634b4dd263c0f330245c086ce646c9bb748cd6b\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1505.00687\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2015.320\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"title\":\"Unsupervised Learning of Visual Representations Using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPR.2014.330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48ce52c12e15300be979807ecf49978ad7f2f861\",\"title\":\"Towards Good Practices for Action Video Encoding\",\"url\":\"https://www.semanticscholar.org/paper/48ce52c12e15300be979807ecf49978ad7f2f861\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Klaser\"},{\"authorId\":null,\"name\":\"C. Schmid\"},{\"authorId\":null,\"name\":\"L. Cheng-Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Action recognition by dense trajectories Action recognition with improved trajectories\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-642-33718-5_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"title\":\"Script Data for Attribute-Based Recognition of Composite Activities\",\"url\":\"https://www.semanticscholar.org/paper/8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2013.333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f55af5a0c774d5140df601b39167f94062ad6a\",\"title\":\"Modeling Actions through State Changes\",\"url\":\"https://www.semanticscholar.org/paper/42f55af5a0c774d5140df601b39167f94062ad6a\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Hebert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing hierarchical invariant spatio - temporal features for action recognition with independent subspace analy\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2315504\",\"name\":\"Raia Hadsell\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/CVPR.2006.100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46f30e94dd3d5902141c5fbe58d0bc9189545c76\",\"title\":\"Dimensionality Reduction by Learning an Invariant Mapping\",\"url\":\"https://www.semanticscholar.org/paper/46f30e94dd3d5902141c5fbe58d0bc9189545c76\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"50678963\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/CVPR.2012.6247808\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6acdddc36ea57ec84581e9e196665f246e8157ab\",\"title\":\"Learning latent temporal structure for complex event detection\",\"url\":\"https://www.semanticscholar.org/paper/6acdddc36ea57ec84581e9e196665f246e8157ab\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1411.4006\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"title\":\"A discriminative CNN video representation for event detection\",\"url\":\"https://www.semanticscholar.org/paper/10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Y. Yeung\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing hierarchical invariant spatio - temporal features for action recognition with independent subspace analy\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1508.07654\",\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2015.517\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f1674f7dd14d8450fca5f336f5f53e811dfd574\",\"title\":\"Action Recognition by Hierarchical Mid-Level Action Elements\",\"url\":\"https://www.semanticscholar.org/paper/0f1674f7dd14d8450fca5f336f5f53e811dfd574\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.imavis.2009.11.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d984b580e02da76cd4d991953e6d430fadf3d578\",\"title\":\"A survey on vision-based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d984b580e02da76cd4d991953e6d430fadf3d578\",\"venue\":\"Image Vis. Comput.\",\"year\":2010},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Y. Zou\"},{\"authorId\":null,\"name\":\"S. Y. Yeung\"},{\"authorId\":null,\"name\":\"A. Y. Ng.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing hierarchical invariant spatio - temporal features for action recognition with independent subspace analy\",\"url\":\"\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"31064779\",\"name\":\"W. Zhang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/ICCV.2013.442\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21e8f3344170a8f133b69308c178518df8a27274\",\"title\":\"Action Recognition with Actons\",\"url\":\"https://www.semanticscholar.org/paper/21e8f3344170a8f133b69308c178518df8a27274\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1505.02206\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2015.166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c426ba865e9158a0f7962a86a50575aa943051b1\",\"title\":\"Learning Image Representations Tied to Ego-Motion\",\"url\":\"https://www.semanticscholar.org/paper/c426ba865e9158a0f7962a86a50575aa943051b1\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/TPAMI.2010.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ccb0f7f869068b11d9a96efe5565d203677c417\",\"title\":\"Hidden Part Models for Human Action Recognition: Probabilistic versus Max Margin\",\"url\":\"https://www.semanticscholar.org/paper/0ccb0f7f869068b11d9a96efe5565d203677c417\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1007/978-3-642-33715-4_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b071b910f8dc0c64c26730da144cddbedc29ed07\",\"title\":\"Trajectory-Based Modeling of Human Actions with Motion Reference Points\",\"url\":\"https://www.semanticscholar.org/paper/b071b910f8dc0c64c26730da144cddbedc29ed07\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.1109/CVPR.2013.330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"title\":\"Better Exploiting Motion for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"2860351\",\"name\":\"Will Y. Zou\"},{\"authorId\":\"32408341\",\"name\":\"Serena Y. Yeung\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1109/CVPR.2011.5995496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42269d0438c0ae4ca892334946ed779999691074\",\"title\":\"Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis\",\"url\":\"https://www.semanticscholar.org/paper/42269d0438c0ae4ca892334946ed779999691074\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E Simo-Serra\"},{\"authorId\":null,\"name\":\"E Trulls\"},{\"authorId\":null,\"name\":\"L Ferraz\"},{\"authorId\":null,\"name\":\"I Kokkinos\"},{\"authorId\":null,\"name\":\"F Moreno-Noguer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fracking deep convolutional image descriptors. CoRR, /abs/1412\",\"url\":\"\",\"venue\":\"Fracking deep convolutional image descriptors. CoRR, /abs/1412\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35561551\",\"name\":\"Arpit Jain\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"144113391\",\"name\":\"Mikel Rodriguez\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2013.332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eece43a4680e80e9dfba7027927b5e4ecae70eb2\",\"title\":\"Representing Videos Using Mid-level Discriminative Patches\",\"url\":\"https://www.semanticscholar.org/paper/eece43a4680e80e9dfba7027927b5e4ecae70eb2\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2013.453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d934149644f048e176630c9ee3daed7fbe16c72\",\"title\":\"ACTIVE: Activity Concept Transitions in Video Event Classification\",\"url\":\"https://www.semanticscholar.org/paper/6d934149644f048e176630c9ee3daed7fbe16c72\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q. V. Le\"},{\"authorId\":null,\"name\":\"W. Y. Zou\"},{\"authorId\":null,\"name\":\"S. Y. Yeung\"},{\"authorId\":null,\"name\":\"A. Y. Ng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing hierarchical invariant spatio - temporal features for action recognition with independent subspace analy\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34651153\",\"name\":\"J. Hu\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"1689805\",\"name\":\"Y. Tan\"}],\"doi\":\"10.1109/CVPR.2014.242\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6438f4fc1b0e89d1319f2de1ca663255b8ee190\",\"title\":\"Discriminative Deep Metric Learning for Face Verification in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/b6438f4fc1b0e89d1319f2de1ca663255b8ee190\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Modeling actions through state changes\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143983346\",\"name\":\"R. Davis\"}],\"doi\":\"10.1109/CVPR.2013.457\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"530b9939c077bab5c8d7e9bae01d1b5251cb769f\",\"title\":\"Action Recognition by Hierarchical Sequence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/530b9939c077bab5c8d7e9bae01d1b5251cb769f\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1504.01561\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2733373.2806222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fd06a73e7970181bfd87fa4d6c340bc99373069\",\"title\":\"Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/2fd06a73e7970181bfd87fa4d6c340bc99373069\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. R. Zamir\"},{\"authorId\":null,\"name\":\"G. Toderici\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Thumos challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"http://crcv.ucf.edu/THUMOS14/,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983582\",\"name\":\"J. Bromley\"},{\"authorId\":\"152862874\",\"name\":\"J. Bentz\"},{\"authorId\":\"119267979\",\"name\":\"L. Bottou\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"49015421\",\"name\":\"C. Moore\"},{\"authorId\":\"1776424\",\"name\":\"Eduard S\\u00e4ckinger\"},{\"authorId\":\"2098454\",\"name\":\"R. Shah\"}],\"doi\":\"10.1142/S0218001493000339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"997dc5d9a058753f034422afe7bd0cc0b8ad808b\",\"title\":\"Signature Verification Using A \\\"Siamese\\\" Time Delay Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/997dc5d9a058753f034422afe7bd0cc0b8ad808b\",\"venue\":\"Int. J. Pattern Recognit. Artif. Intell.\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930329\",\"name\":\"P. Matikainen\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/ICCVW.2009.5457659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b155538a9079e4d8476e11afe09a7ebf5543fd50\",\"title\":\"Trajectons: Action recognition through the motion analysis of tracked features\",\"url\":\"https://www.semanticscholar.org/paper/b155538a9079e4d8476e11afe09a7ebf5543fd50\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948848\",\"name\":\"S. Sadanand\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"title\":\"Action bank: A high-level representation of activity in video\",\"url\":\"https://www.semanticscholar.org/paper/d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"35984288\",\"name\":\"Guangnan Ye\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"144677796\",\"name\":\"A. Loui\"}],\"doi\":\"10.1145/1991996.1992025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8359e3a7cf20fde8eda51c0ad1a17917f675105\",\"title\":\"Consumer video understanding: a benchmark database and an evaluation of human and machine performance\",\"url\":\"https://www.semanticscholar.org/paper/a8359e3a7cf20fde8eda51c0ad1a17917f675105\",\"venue\":\"ICMR '11\",\"year\":2011},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"Actions ~ Transformations\",\"topics\":[{\"topic\":\"Precondition\",\"topicId\":\"1279\",\"url\":\"https://www.semanticscholar.org/topic/1279\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Cartesian closed category\",\"topicId\":\"119207\",\"url\":\"https://www.semanticscholar.org/topic/119207\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"}],\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"