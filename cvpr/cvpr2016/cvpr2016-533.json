"{\"abstract\":\"We have seen great progress in basic perceptual tasks such as object recognition and detection. However, AI models still fail to match humans in high-level vision tasks due to the lack of capacities for deeper reasoning. Recently the new task of visual question answering (QA) has been proposed to evaluate a model's capacity for deep image understanding. Previous works have established a loose, global association between QA sentences and images. However, many questions and answers, in practice, relate to local regions in the images. We establish a semantic link between textual descriptions and image regions by object-level grounding. It enables a new type of QA with visual answers, in addition to textual answers used in previous work. We study the visual QA tasks in a grounded setting with a large collection of 7W multiple-choice QA pairs. Furthermore, we evaluate human performance and several baseline models on the QA tasks. Finally, we propose a novel LSTM model with spatial attention to tackle the 7W QA tasks.\",\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\",\"url\":\"https://www.semanticscholar.org/author/2117748\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\",\"url\":\"https://www.semanticscholar.org/author/50499889\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\",\"url\":\"https://www.semanticscholar.org/author/145879842\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\",\"url\":\"https://www.semanticscholar.org/author/48004138\"}],\"citationVelocity\":115,\"citations\":[{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eeff23d6e0127cfbbd0374a83341173a418ba7f\",\"title\":\"Dual Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6eeff23d6e0127cfbbd0374a83341173a418ba7f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f55deed4fa5d6d806790610dad9cf7505c1adde8\",\"title\":\"Goal Driven Detection in Natural Scenes Anonymous\",\"url\":\"https://www.semanticscholar.org/paper/f55deed4fa5d6d806790610dad9cf7505c1adde8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66671751\",\"name\":\"Vineet Edupuganti\"},{\"authorId\":\"7929147\",\"name\":\"Mihir T. Garimella\"},{\"authorId\":null,\"name\":\"Ben Kotopka\"},{\"authorId\":\"40236124\",\"name\":\"P. Naidu\"},{\"authorId\":\"1739519868\",\"name\":\"Rohan Suri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74697f08ac6b4f7a421c18c3ec8309a31ded72f8\",\"title\":\"Tutorial 9: Introduction to Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/74697f08ac6b4f7a421c18c3ec8309a31ded72f8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.06273\",\"authors\":[{\"authorId\":\"153714898\",\"name\":\"M. Andrews\"},{\"authorId\":\"52214524\",\"name\":\"Y. K. Chia\"},{\"authorId\":\"115583560\",\"name\":\"Sam Witteveen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce7a6767ec5f99b8676c603ec24b3b65d47a9dd3\",\"title\":\"Scene Graph Parsing by Attention Graph\",\"url\":\"https://www.semanticscholar.org/paper/ce7a6767ec5f99b8676c603ec24b3b65d47a9dd3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"36620933\",\"name\":\"S. Wang\"},{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b2d224c8b69191c02dce750257c39d46b1c4a7b\",\"title\":\"A Reinforcement Learning Framework for Natural Question Generation using Bi-discriminators\",\"url\":\"https://www.semanticscholar.org/paper/8b2d224c8b69191c02dce750257c39d46b1c4a7b\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1612.08843\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"8539304\",\"name\":\"Shiyi Lan\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"2695115\",\"name\":\"Zhimin Cao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2017.245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"410043f2d7d6f1a46b0c4f64d5bcc48bb1e48282\",\"title\":\"FastMask: Segment Multi-scale Object Candidates in One Shot\",\"url\":\"https://www.semanticscholar.org/paper/410043f2d7d6f1a46b0c4f64d5bcc48bb1e48282\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.07191\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5075fa79da6cd7b81e5d3dc24161217ef86368\",\"title\":\"ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/da5075fa79da6cd7b81e5d3dc24161217ef86368\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.02951\",\"authors\":[{\"authorId\":\"1935410\",\"name\":\"M. Rahnemoonfar\"},{\"authorId\":\"39734189\",\"name\":\"Tashnim J. S. Chowdhury\"},{\"authorId\":\"1381535116\",\"name\":\"Argho Sarkar\"},{\"authorId\":\"1411385478\",\"name\":\"D. Varshney\"},{\"authorId\":\"1505798397\",\"name\":\"Masoud Yari\"},{\"authorId\":\"1789429\",\"name\":\"R. Murphy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"title\":\"FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.18653/v1/P18-1079\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"472644c5f4155635cf9e9e37540bfa53c20e7610\",\"title\":\"Semantically Equivalent Adversarial Rules for Debugging NLP models\",\"url\":\"https://www.semanticscholar.org/paper/472644c5f4155635cf9e9e37540bfa53c20e7610\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49530191\",\"name\":\"S. Bhattacharya\"},{\"authorId\":\"2757153\",\"name\":\"Rajeev Agrawal\"},{\"authorId\":\"1812598\",\"name\":\"Neal Wagner\"}],\"doi\":\"10.1145/3281375.3281405\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a84b972b385109fc9eb76522de8344a5d495763\",\"title\":\"Application of deep learning and geo-knowledge bases to scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/7a84b972b385109fc9eb76522de8344a5d495763\",\"venue\":\"MEDES\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TIP.2020.3013142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"635b37afc27d628e0a2f0044a66a6f6d7940f53c\",\"title\":\"ORDNet: Capturing Omni-Range Dependencies for Scene Parsing\",\"url\":\"https://www.semanticscholar.org/paper/635b37afc27d628e0a2f0044a66a6f6d7940f53c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2003.10606\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR42600.2020.01043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"title\":\"Video Object Grounding Using Semantic Roles in Language Description\",\"url\":\"https://www.semanticscholar.org/paper/70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"49982480\",\"name\":\"Yuanyuan Ge\"},{\"authorId\":\"47909272\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s11042-018-5868-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"title\":\"Remember and forget: video and text fusion for video question answering\",\"url\":\"https://www.semanticscholar.org/paper/ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1904.02865\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00204\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51932dc1148566040fdb0df6ed66d8d2a0712933\",\"title\":\"Actively Seeking and Learning From Live Data\",\"url\":\"https://www.semanticscholar.org/paper/51932dc1148566040fdb0df6ed66d8d2a0712933\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.11207\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"49624560\",\"name\":\"M. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2019.00211\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6258cb5ae8d15870e65c363efea319e012fb249\",\"title\":\"Information Maximizing Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/e6258cb5ae8d15870e65c363efea319e012fb249\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.06409\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"title\":\"Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47897687\",\"name\":\"H. Tan\"},{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"1786343\",\"name\":\"Q. Xu\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"2998031\",\"name\":\"F. Fang\"},{\"authorId\":\"2000269838\",\"name\":\"Yi Cheng\"},{\"authorId\":\"152765071\",\"name\":\"N. Gauthier\"},{\"authorId\":\"2000311149\",\"name\":\"Ying Sun\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"}],\"doi\":\"10.1109/ICIP40778.2020.9190659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"title\":\"Task-Oriented Multi-Modal Question Answering For Collaborative Applications\",\"url\":\"https://www.semanticscholar.org/paper/cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1608.03410\",\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.5244/C.30.77\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"title\":\"Solving VIsual Madlibs with Multiple Cues\",\"url\":\"https://www.semanticscholar.org/paper/95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1610.04062\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"title\":\"Video Fill in the Blank with Merging LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1811.10561\",\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"38655449\",\"name\":\"G. Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6bb8fda39f104a95332b5dbca9b1a1c071de539\",\"title\":\"CLEAR: A Dataset for Compositional Language and Elementary Acoustic Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a6bb8fda39f104a95332b5dbca9b1a1c071de539\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49066069\",\"name\":\"Fabian Frank\"},{\"authorId\":\"31199200\",\"name\":\"Lars Jebe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e2873a2ea525507f5cd08e54ba363b06bc10e0a\",\"title\":\"Multi-Modal Information Extraction in a Question-Answer Framework\",\"url\":\"https://www.semanticscholar.org/paper/4e2873a2ea525507f5cd08e54ba363b06bc10e0a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"46264522\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICCV.2019.00470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"title\":\"From Strings to Things: Knowledge-Enabled VQA Model That Can Read and Reason\",\"url\":\"https://www.semanticscholar.org/paper/ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31696860\",\"name\":\"Shurong Sheng\"},{\"authorId\":\"35301620\",\"name\":\"Katrien Laenen\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1007/978-3-030-15719-7_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d75b686c7d32680f5e5aeeefaffff6dab06d31ee\",\"title\":\"Can Image Captioning Help Passage Retrieval in Multimodal Question Answering?\",\"url\":\"https://www.semanticscholar.org/paper/d75b686c7d32680f5e5aeeefaffff6dab06d31ee\",\"venue\":\"ECIR\",\"year\":2019},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2006.03776\",\"authors\":[{\"authorId\":\"3456962\",\"name\":\"Amar Shrestha\"},{\"authorId\":\"9091383\",\"name\":\"Krittaphat Pugdeethosapol\"},{\"authorId\":\"122851204\",\"name\":\"Haowen Fang\"},{\"authorId\":\"1862322\",\"name\":\"Q. Qiu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032a517f0c7e27a5fa95522c49de423633036b5f\",\"title\":\"MAGNet: Multi-Region Attention-Assisted Grounding of Natural Language Queries at Phrase Level\",\"url\":\"https://www.semanticscholar.org/paper/032a517f0c7e27a5fa95522c49de423633036b5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.05268\",\"authors\":[{\"authorId\":\"3296335\",\"name\":\"D. Mascharka\"},{\"authorId\":\"46450184\",\"name\":\"Philip Tran\"},{\"authorId\":\"49902902\",\"name\":\"Ryan Soklaski\"},{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"}],\"doi\":\"10.1109/CVPR.2018.00519\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd0a7c58964905ccfddbad1614165320ccc56393\",\"title\":\"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cd0a7c58964905ccfddbad1614165320ccc56393\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"48873415\",\"name\":\"Na Rong\"},{\"authorId\":\"145414551\",\"name\":\"Takashi Miyazaki\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"98025d3d44e9379736adb1228919272ded9298ae\",\"title\":\"Visual Question Answering Dataset for Bilingual Image Understanding: A Study of Cross-Lingual Transfer Using Attention Maps\",\"url\":\"https://www.semanticscholar.org/paper/98025d3d44e9379736adb1228919272ded9298ae\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40791626\",\"name\":\"Reham Abobeah\"},{\"authorId\":\"1864588\",\"name\":\"Marwan Torki\"},{\"authorId\":\"39781659\",\"name\":\"A. Shoukry\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.5220/0007524505830589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd6ca05440395195c3092c0717d58f4410143fb0\",\"title\":\"Bi-Directional Attention Flow for Video Alignment\",\"url\":\"https://www.semanticscholar.org/paper/fd6ca05440395195c3092c0717d58f4410143fb0\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24328497\",\"name\":\"Avraam Tsantekidis\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"2910979\",\"name\":\"J. Kanniainen\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"},{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"}],\"doi\":\"10.23919/EUSIPCO.2017.8081663\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a36eb02c398c6225e8afe122619ac3c0bc251bf\",\"title\":\"Using deep learning to detect price change indications in financial markets\",\"url\":\"https://www.semanticscholar.org/paper/8a36eb02c398c6225e8afe122619ac3c0bc251bf\",\"venue\":\"2017 25th European Signal Processing Conference (EUSIPCO)\",\"year\":2017},{\"arxivId\":\"1809.03707\",\"authors\":[{\"authorId\":\"51929143\",\"name\":\"M. Wagner\"},{\"authorId\":\"7005920\",\"name\":\"H. Basevi\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"}],\"doi\":\"10.1007/978-3-030-11009-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918f122b385c5de709d076063527e850c2666c78\",\"title\":\"Answering Visual What-If Questions: From Actions to Predicted Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/918f122b385c5de709d076063527e850c2666c78\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"7476726\",\"name\":\"Eshan Verma\"},{\"authorId\":\"7747740\",\"name\":\"Parag Goel\"},{\"authorId\":\"1412708076\",\"name\":\"Anisha Cherodian\"},{\"authorId\":\"1794486\",\"name\":\"M. Savvides\"}],\"doi\":\"10.1109/CVPRW.2016.24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5720c765f38e6a98d79b889f3f3534b7e6f4bfa\",\"title\":\"DeepGender: Occlusion and Low Resolution Robust Facial Gender Classification via Progressively Trained Convolutional Neural Networks with Attention\",\"url\":\"https://www.semanticscholar.org/paper/e5720c765f38e6a98d79b889f3f3534b7e6f4bfa\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46174228\",\"name\":\"Sidra Shabir\"},{\"authorId\":\"49854677\",\"name\":\"Syed Yasser Arafat\"}],\"doi\":\"10.1109/ICPESG.2018.8384519\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"title\":\"An image conveys a message: A brief survey on image description generation\",\"url\":\"https://www.semanticscholar.org/paper/4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"venue\":\"2018 1st International Conference on Power, Energy and Smart Grid (ICPESG)\",\"year\":2018},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964003\",\"name\":\"C. Lee\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"2208161\",\"name\":\"Szu-Lin Wu\"},{\"authorId\":\"117660020\",\"name\":\"Chi-Liang Liu\"},{\"authorId\":\"145359071\",\"name\":\"Wei Fang\"},{\"authorId\":\"3451540\",\"name\":\"Juei-Yang Hsu\"},{\"authorId\":\"33870107\",\"name\":\"Bo-Hsiang Tseng\"}],\"doi\":\"10.1109/TASLP.2019.2913499\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"title\":\"Machine Comprehension of Spoken Content: TOEFL Listening Test and Spoken SQuAD\",\"url\":\"https://www.semanticscholar.org/paper/76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47121309\",\"name\":\"Wenping Ma\"},{\"authorId\":\"47492162\",\"name\":\"Qifan Yang\"},{\"authorId\":\"46220633\",\"name\":\"Yue Wu\"},{\"authorId\":\"145675285\",\"name\":\"W. Zhao\"},{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"}],\"doi\":\"10.3390/RS11111307\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0565198f6b8ca7117616b05fb2d6409693b526e9\",\"title\":\"Double-Branch Multi-Attention Mechanism Network for Hyperspectral Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/0565198f6b8ca7117616b05fb2d6409693b526e9\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"1906.09844\",\"authors\":[{\"authorId\":\"2052119\",\"name\":\"Zhaoquan Yuan\"},{\"authorId\":\"47393013\",\"name\":\"Siyuan Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"116155759\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48258806\",\"name\":\"Changsheng Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"title\":\"Adversarial Multimodal Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98727476\",\"name\":\"Tsan-Hwei Huang\"},{\"authorId\":\"2024357948\",\"name\":\"Hunter Hsieh\"},{\"authorId\":\"2025282857\",\"name\":\"Jiaqi Qin\"},{\"authorId\":\"2024727250\",\"name\":\"Hsien-Fung Liu\"},{\"authorId\":\"2377003\",\"name\":\"M. Eirinaki\"}],\"doi\":\"10.1109/TransAI49837.2020.00008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"title\":\"Play it again IMuCo! Music Composition to Match your Mood\",\"url\":\"https://www.semanticscholar.org/paper/30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"venue\":\"2020 Second International Conference on Transdisciplinary AI (TransAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"}],\"doi\":\"10.1016/B978-0-12-809276-7.00014-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef42dd8253dc2de6be45af130d96348edd8b1313\",\"title\":\"Activity Forecasting: An Invitation to Predictive Perception\",\"url\":\"https://www.semanticscholar.org/paper/ef42dd8253dc2de6be45af130d96348edd8b1313\",\"venue\":\"Group and Crowd Behavior for Computer Vision\",\"year\":2017},{\"arxivId\":\"2007.00145\",\"authors\":[{\"authorId\":\"3381900\",\"name\":\"E. Dodds\"},{\"authorId\":\"31922487\",\"name\":\"J. Culpepper\"},{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e09df55b9aaf6e81b210815106d5ea075e3aaad0\",\"title\":\"Modality-Agnostic Attention Fusion for visual search with text feedback\",\"url\":\"https://www.semanticscholar.org/paper/e09df55b9aaf6e81b210815106d5ea075e3aaad0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711219\",\"name\":\"Juzheng Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"47672848\",\"name\":\"Siyu Wang\"},{\"authorId\":\"145803573\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f783d93b983841804a9633a37dfbc624bf5d9bfb\",\"title\":\"Textbook Question Answering Under Instructor Guidance with Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/f783d93b983841804a9633a37dfbc624bf5d9bfb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2918814\",\"name\":\"Z. Bai\"},{\"authorId\":\"47002010\",\"name\":\"Y. Li\"},{\"authorId\":\"3309410\",\"name\":\"Meili Zhou\"},{\"authorId\":\"1409646866\",\"name\":\"Di Li\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"1734496\",\"name\":\"Dawid Po\\u0142ap\"},{\"authorId\":\"144433006\",\"name\":\"M. Wo\\u017aniak\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206964\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07e8b56bc2f996c269d6550c8ff0195171cd7215\",\"title\":\"Bilinear Semi-Tensor Product Attention (BSTPA) model for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/07e8b56bc2f996c269d6550c8ff0195171cd7215\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145406475\",\"name\":\"R. Ma\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"48094184\",\"name\":\"Jiawen Wang\"},{\"authorId\":\"1732687\",\"name\":\"L. Cui\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.1145/3209978.3210026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50f3587a6316ae59493f4c408eadefe3bbf891fe\",\"title\":\"Mention Recommendation for Multimodal Microblog with Cross-attention Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/50f3587a6316ae59493f4c408eadefe3bbf891fe\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":\"2001.11673\",\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1745798\",\"name\":\"B. D. Eugenio\"}],\"doi\":\"10.1109/ICSC.2020.00013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ee926c62a30a40727529fd6be129a6f942d4722\",\"title\":\"Augmenting Visual Question Answering with Semantic Frame Information in a Multitask Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/8ee926c62a30a40727529fd6be129a6f942d4722\",\"venue\":\"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46812189\",\"name\":\"K. Gao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-3-319-77383-4_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23de896c1b3487803ec6989b1ec1c3bd0c0f8136\",\"title\":\"Spatio-Temporal Context Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/23de896c1b3487803ec6989b1ec1c3bd0c0f8136\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"49298718\",\"name\":\"Jie Li\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3321505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"title\":\"Video Question Answering via Knowledge-based Progressive Spatial-Temporal Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3164185\",\"name\":\"Fadwa Yahya\"},{\"authorId\":\"2973443\",\"name\":\"Khouloud Boukadi\"},{\"authorId\":\"1398586755\",\"name\":\"H. Ben-Abdallah\"}],\"doi\":\"10.1108/BPMJ-11-2017-0327\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9eed96b0eea44261421c544ec0adfc8950d65f61\",\"title\":\"Improving the quality of Business Process Models: Lesson learned from the State of the Art\",\"url\":\"https://www.semanticscholar.org/paper/9eed96b0eea44261421c544ec0adfc8950d65f61\",\"venue\":\"Bus. Process. Manag. J.\",\"year\":2019},{\"arxivId\":\"1803.09189\",\"authors\":[{\"authorId\":\"24874138\",\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"1751476\",\"name\":\"Xiaohui Zeng\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.18653/v1/N18-1037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c3c6197037ec92de044b3068c57e26815dd6c76\",\"title\":\"Scene Graph Parsing as Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/0c3c6197037ec92de044b3068c57e26815dd6c76\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1902.11280\",\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"38655449\",\"name\":\"G. Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b90f978dae910f0662041ca44fdad7009d2a006\",\"title\":\"From Visual to Acoustic Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b90f978dae910f0662041ca44fdad7009d2a006\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.11649\",\"authors\":[{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/ICCV.2019.00269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a89cd9056c0fb037d659215b121686ff3b454fd5\",\"title\":\"Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment\",\"url\":\"https://www.semanticscholar.org/paper/a89cd9056c0fb037d659215b121686ff3b454fd5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2005.01655\",\"authors\":[{\"authorId\":\"2947115\",\"name\":\"Arjun Reddy Akula\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1403907739\",\"name\":\"Yaser Al-Onaizan\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"}],\"doi\":\"10.18653/v1/2020.acl-main.586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"title\":\"Words aren't enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"49725227\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.04.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"title\":\"Stimulus-driven and concept-driven analysis for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1810.00912\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03625172605e0721db44ef107bc75e6ececdee25\",\"title\":\"Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/03625172605e0721db44ef107bc75e6ececdee25\",\"venue\":\"CoRL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.06092\",\"authors\":[{\"authorId\":\"47125062\",\"name\":\"G. Yang\"},{\"authorId\":\"2204671\",\"name\":\"Igor Ganichev\"},{\"authorId\":\"2146534\",\"name\":\"X. Wang\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"3089810\",\"name\":\"David Sussillo\"}],\"doi\":\"10.1007/978-3-030-01249-6_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4efd4b08999758a3a80085fb674eb99f7c6f2e1\",\"title\":\"A dataset and architecture for visual reasoning with a working memory\",\"url\":\"https://www.semanticscholar.org/paper/d4efd4b08999758a3a80085fb674eb99f7c6f2e1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.02234\",\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"},{\"authorId\":\"1924996\",\"name\":\"S. Herbin\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-20890-5_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"title\":\"Semantic bottleneck for computer vision tasks\",\"url\":\"https://www.semanticscholar.org/paper/ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1705.02315\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"3774191\",\"name\":\"M. Bagheri\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2017.369\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"05e882679d61f4c64a68ebe21826251a39f87e98\",\"title\":\"ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\",\"url\":\"https://www.semanticscholar.org/paper/05e882679d61f4c64a68ebe21826251a39f87e98\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.04968\",\"authors\":[{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00729\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"title\":\"Visual Question Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2011.13160\",\"authors\":[{\"authorId\":\"145251354\",\"name\":\"Xin Hong\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"48537499\",\"name\":\"Liang Pang\"},{\"authorId\":\"70414094\",\"name\":\"J. Guo\"},{\"authorId\":\"30857876\",\"name\":\"Xueqi Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"825363a518902f3e44d61bd9a10262d0e527be60\",\"title\":\"Transformation Driven Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/825363a518902f3e44d61bd9a10262d0e527be60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2016.538\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"7187373\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"49112842\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-20887-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"title\":\"Answer Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1709.08203\",\"authors\":[{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"2462516\",\"name\":\"Shagun Sodhani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e23229289b1fbea14bc425718bc0a227d100b8e\",\"title\":\"Survey of Recent Advances in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0e23229289b1fbea14bc425718bc0a227d100b8e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3126686.3126695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"title\":\"Generative Attention Model with Adversarial Self-learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2310836\",\"name\":\"Bashar Talafha\"},{\"authorId\":\"1398466553\",\"name\":\"Mahmoud Al-Ayyoub\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"title\":\"JUST at VQA-Med: A VGG-Seq2Seq Model\",\"url\":\"https://www.semanticscholar.org/paper/4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":\"1711.04323\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799537fa855caf53a6a3a7cf20301a81e90da127\",\"title\":\"High-Order Attention Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/799537fa855caf53a6a3a7cf20301a81e90da127\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.02358\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"1837923\",\"name\":\"Taehoon Kim\"},{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b80f128830114896df94999b4104cb75408e657e\",\"title\":\"Transfer Learning via Unsupervised Task Discovery for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b80f128830114896df94999b4104cb75408e657e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1805.06549\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-2069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8629c779581a0f46452bc4ca45b571bfbd3cd063\",\"title\":\"Defoiling Foiled Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8629c779581a0f46452bc4ca45b571bfbd3cd063\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367790\",\"name\":\"Seong Jae Hwang\"},{\"authorId\":\"3023295\",\"name\":\"S. Ravi\"},{\"authorId\":\"46641029\",\"name\":\"Zirui Tao\"},{\"authorId\":\"40147719\",\"name\":\"H. Kim\"},{\"authorId\":\"31604982\",\"name\":\"Maxwell D. Collins\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2018.00112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b6d41795de1fd9a0da4227c83dc4dd038a229ec\",\"title\":\"Tensorize, Factorize and Regularize: Robust Visual Relationship Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b6d41795de1fd9a0da4227c83dc4dd038a229ec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.08949\",\"authors\":[{\"authorId\":\"3470231\",\"name\":\"Liangming Pan\"},{\"authorId\":\"39165620\",\"name\":\"Wenqiang Lei\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"37596605\",\"name\":\"Min-Yen Kan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bda4156a2a62c99073ceabcfe4ac5092f1a38157\",\"title\":\"Recent Advances in Neural Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/bda4156a2a62c99073ceabcfe4ac5092f1a38157\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2006.09073\",\"authors\":[{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"46394401\",\"name\":\"Yujing Wang\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.24963/ijcai.2020/153\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b13065b4050800e30bb74e010b8aaba3355525d\",\"title\":\"Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6b13065b4050800e30bb74e010b8aaba3355525d\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2009.03793\",\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1397911258\",\"name\":\"Ali Movaghar-Rahimabadi\"}],\"doi\":\"10.36227/techrxiv.12928544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f097e32ea304a14c8e26648b05f944d530b016\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/46f097e32ea304a14c8e26648b05f944d530b016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.05492\",\"authors\":[{\"authorId\":\"2235894\",\"name\":\"Pramod Kaushik Mudrakarta\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"30740726\",\"name\":\"M. Sundararajan\"},{\"authorId\":\"1696833\",\"name\":\"K. Dhamdhere\"}],\"doi\":\"10.18653/v1/P18-1176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a9831e5fec549edee454709048a51997ef60fb7\",\"title\":\"Did the Model Understand the Question?\",\"url\":\"https://www.semanticscholar.org/paper/4a9831e5fec549edee454709048a51997ef60fb7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40791626\",\"name\":\"Reham Abobeah\"},{\"authorId\":\"39781659\",\"name\":\"A. Shoukry\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/ACCESS.2020.2967750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15c795b754f44f5f1c8664a5adb18e01e33eb8e5\",\"title\":\"Video Alignment Using Bi-Directional Attention Flow in a Multi-Stage Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/15c795b754f44f5f1c8664a5adb18e01e33eb8e5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.12520\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"82729121\",\"name\":\"Chentao Ye\"},{\"authorId\":\"9071958\",\"name\":\"Zihua Liu\"},{\"authorId\":\"32104754\",\"name\":\"Qingtao Hu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"title\":\"A Dataset and Baselines for Visual Question Answering on Art\",\"url\":\"https://www.semanticscholar.org/paper/fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48539596\",\"name\":\"U. Sharma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b715977048c3e112cab5bbae2265012890db7fe\",\"title\":\"Interpreting Decision-Making in Interactive Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/9b715977048c3e112cab5bbae2265012890db7fe\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153825264\",\"name\":\"Tao Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e38114f470f09fadeac4e9e403fb3b1a9e9e940\",\"title\":\"A Cognition Platform for Joint Inference of 3D Geometry, Object States, and Human Belief\",\"url\":\"https://www.semanticscholar.org/paper/4e38114f470f09fadeac4e9e403fb3b1a9e9e940\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"68978364\",\"name\":\"Demetres Kostas\"},{\"authorId\":\"2839925\",\"name\":\"E. Pang\"},{\"authorId\":\"2479037\",\"name\":\"F. Rudzicz\"}],\"doi\":\"10.1038/s41598-019-38612-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e43cd9092510dc3a29d4b902a5a6e066e970b81\",\"title\":\"Machine learning for MEG during speech tasks\",\"url\":\"https://www.semanticscholar.org/paper/3e43cd9092510dc3a29d4b902a5a6e066e970b81\",\"venue\":\"Scientific Reports\",\"year\":2019},{\"arxivId\":\"1909.03409\",\"authors\":[{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"151260226\",\"name\":\"Y. Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Y. Sun\"},{\"authorId\":\"2256618\",\"name\":\"Z. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"title\":\"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"79927338\",\"name\":\"L. Wang\"},{\"authorId\":\"37233332\",\"name\":\"J. Gou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"title\":\"Affective question answering on video\",\"url\":\"https://www.semanticscholar.org/paper/1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"}],\"doi\":\"10.1051/JNWPU/20183630522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a49e34cf529989963a7a2d64dd92798621e1a748\",\"title\":\"Image Caption Description of Traffic Scene Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a49e34cf529989963a7a2d64dd92798621e1a748\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2003.11844\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"145491338\",\"name\":\"S. Palacio\"},{\"authorId\":\"144553243\",\"name\":\"J. Folz\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"120996558\",\"name\":\"J. Hees\"},{\"authorId\":\"1384499125\",\"name\":\"Andreas Dengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"title\":\"P $\\\\approx$ NP, at least in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.02833\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"title\":\"Eliminating Catastrophic Interference with Biased Competition\",\"url\":\"https://www.semanticscholar.org/paper/07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1603.07396\",\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"153778850\",\"name\":\"M. Salvato\"},{\"authorId\":\"3386570\",\"name\":\"Eric Kolve\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1007/978-3-319-46493-0_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"title\":\"A Diagram is Worth a Dozen Images\",\"url\":\"https://www.semanticscholar.org/paper/e18ec2c9f0b4a817b8cf0435822bbc879d7db698\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b02dba59a087f16d8286aec5e6481d5952a37df5\",\"title\":\"CMU Sinbad\\u2019s Submission for the DSTC7 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b02dba59a087f16d8286aec5e6481d5952a37df5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d8f4f76ac6534627ef8a1c24b9937d8ab2a5c5f\",\"title\":\"Anchors: High-Precision Model-Agnostic Explanations\",\"url\":\"https://www.semanticscholar.org/paper/1d8f4f76ac6534627ef8a1c24b9937d8ab2a5c5f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123865\",\"name\":\"F. Tung\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/TPAMI.2018.2886192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"610d0b290f0f1c22b03f220d6ba332627a5f6f3e\",\"title\":\"Deep Neural Network Compression by In-Parallel Pruning-Quantization\",\"url\":\"https://www.semanticscholar.org/paper/610d0b290f0f1c22b03f220d6ba332627a5f6f3e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1907.12133\",\"authors\":[{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"113737386\",\"name\":\"D. Xuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"title\":\"An Empirical Study on Leveraging Scene Graphs for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20506582\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"49167156\",\"name\":\"B. Liu\"},{\"authorId\":\"2607732\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11390-017-1755-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0801d539bacc3e3bc42e2e96bdb8f5d9bec67b41\",\"title\":\"Deep Multimodal Reinforcement Network with Contextually Guided Recurrent Attention for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0801d539bacc3e3bc42e2e96bdb8f5d9bec67b41\",\"venue\":\"Journal of Computer Science and Technology\",\"year\":2017},{\"arxivId\":\"1909.01860\",\"authors\":[{\"authorId\":\"66275275\",\"name\":\"Yash Srivastava\"},{\"authorId\":\"152967610\",\"name\":\"Vaishnav Murali\"},{\"authorId\":\"34992579\",\"name\":\"S. Dubey\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"title\":\"Visual Question Answering using Deep Learning: A Survey and Performance Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1612.06543\",\"authors\":[{\"authorId\":\"1736750\",\"name\":\"N. Martinel\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"1708507\",\"name\":\"C. Micheloni\"}],\"doi\":\"10.1109/WACV.2018.00068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeda0531681764381b4c8b9c139ade3200e7f5cf\",\"title\":\"Wide-Slice Residual Networks for Food Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aeda0531681764381b4c8b9c139ade3200e7f5cf\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1810.09965\",\"authors\":[{\"authorId\":\"24328497\",\"name\":\"Avraam Tsantekidis\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"2910979\",\"name\":\"J. Kanniainen\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"},{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"}],\"doi\":\"10.1016/j.asoc.2020.106401\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b7b9cd48228d186e668345749b492cc51b9b421\",\"title\":\"Using Deep Learning for price prediction by exploiting stationary limit order book features\",\"url\":\"https://www.semanticscholar.org/paper/6b7b9cd48228d186e668345749b492cc51b9b421\",\"venue\":\"Appl. Soft Comput.\",\"year\":2020},{\"arxivId\":\"1907.12861\",\"authors\":[{\"authorId\":\"13726384\",\"name\":\"Ritwick Chaudhry\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"},{\"authorId\":\"2681580\",\"name\":\"Utkarsh Gupta\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"153841978\",\"name\":\"Prann Bansal\"},{\"authorId\":\"33901930\",\"name\":\"A. Joshi\"}],\"doi\":\"10.1109/WACV45572.2020.9093269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d47f20de7195fea82e48315fea52ccf06dc301d3\",\"title\":\"LEAF-QA: Locate, Encode & Attend for Figure Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d47f20de7195fea82e48315fea52ccf06dc301d3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2005.00619\",\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"title\":\"Probing Contextual Language Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Vaswani\"},{\"authorId\":null,\"name\":\"Noam Shazeer\"},{\"authorId\":null,\"name\":\"Niki Parmar\"},{\"authorId\":null,\"name\":\"Jakob\"},{\"authorId\":null,\"name\":\"Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"title\":\"Words aren\\u2019t enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":\"1705.08923\",\"authors\":[{\"authorId\":\"144137447\",\"name\":\"Tao Zhou\"},{\"authorId\":\"1998918\",\"name\":\"Muhao Chen\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"},{\"authorId\":\"1750924\",\"name\":\"Demetri Terzopoulos\"}],\"doi\":\"10.1109/CVPRW.2017.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92d5fd4ef31cf86a650c7b01c26f0ac93304f98a\",\"title\":\"Attention-Based Natural Language Person Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/92d5fd4ef31cf86a650c7b01c26f0ac93304f98a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1745798\",\"name\":\"B. D. Eugenio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91412f8e920ed226b44b5fad195c2b8bd080e837\",\"title\":\"A Corpus for Visual Question Answering Annotated with Frame Semantic Information\",\"url\":\"https://www.semanticscholar.org/paper/91412f8e920ed226b44b5fad195c2b8bd080e837\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2860490\",\"name\":\"K. Acheampong\"},{\"authorId\":\"39720104\",\"name\":\"W. Tian\"},{\"authorId\":\"38986009\",\"name\":\"Emmanuel Boateng Sifah\"},{\"authorId\":\"1800405536\",\"name\":\"Kwame Obour-Agyekum Opuni Boachie\"}],\"doi\":\"10.1007/978-3-030-52246-9_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c35d5ef467d7248fea71ad8a9edfb33a288c5ac\",\"title\":\"The Emergence, Advancement and Future of Textual Answer Triggering\",\"url\":\"https://www.semanticscholar.org/paper/3c35d5ef467d7248fea71ad8a9edfb33a288c5ac\",\"venue\":\"SAI\",\"year\":2020},{\"arxivId\":\"2012.04293\",\"authors\":[{\"authorId\":\"32856839\",\"name\":\"T. Ates\"},{\"authorId\":\"2033380403\",\"name\":\"Muhammed Samil Atesoglu\"},{\"authorId\":\"2033381520\",\"name\":\"Cagatay Yigit\"},{\"authorId\":\"116865200\",\"name\":\"Ilker Kesen\"},{\"authorId\":\"2033382593\",\"name\":\"Mert Kobas\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"81703837\",\"name\":\"T. Goksun\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b2397185ef6315ce346180d505df00550d6b08d\",\"title\":\"CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions\",\"url\":\"https://www.semanticscholar.org/paper/9b2397185ef6315ce346180d505df00550d6b08d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.08896\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c41d7cfadcdaa5a66694bd57fa5eaf807043ef9\",\"title\":\"Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c41d7cfadcdaa5a66694bd57fa5eaf807043ef9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"8214376\",\"name\":\"J. Zhang\"},{\"authorId\":\"2810571\",\"name\":\"Yueyang Chen\"},{\"authorId\":\"47893083\",\"name\":\"Huangcan Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"},{\"authorId\":\"1945606\",\"name\":\"R. Burd\"}],\"doi\":\"10.1145/3123266.3123365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c18a0389bacc1b9e5539b9bc9c6b3aba5073a7e\",\"title\":\"Region-based Activity Recognition Using Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/8c18a0389bacc1b9e5539b9bc9c6b3aba5073a7e\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"32113652\",\"name\":\"G. Gandolfi\"},{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.248\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"title\":\"Be Different to Be Better! A Benchmark to Leverage the Complementarity of Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.02218\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"2061528\",\"name\":\"Wenqing Chu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2018.2859820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96f0908cc138aceb2d5e0180c440e5adc711d855\",\"title\":\"A Better Way to Attend: Attention With Trees for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/96f0908cc138aceb2d5e0180c440e5adc711d855\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.15124\",\"authors\":[{\"authorId\":\"83574123\",\"name\":\"Emanuele Bugliarello\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"title\":\"Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs\",\"url\":\"https://www.semanticscholar.org/paper/82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.07771\",\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"1703003796\",\"name\":\"Anish Madan\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"152253423\",\"name\":\"Y. Yu\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3949fff9e84261dee6e856faf4b04a27dfa460cd\",\"title\":\"C3VQG: Category Consistent Cyclic Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/3949fff9e84261dee6e856faf4b04a27dfa460cd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.07853\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"48032659\",\"name\":\"Xiaoyi Liu\"},{\"authorId\":\"49330599\",\"name\":\"Liangjian Chen\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":\"10.1109/WACV.2018.00209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"title\":\"Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec3621e900cc50afd067584bb1246a8b4e338fa8\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2220994\",\"name\":\"A. Guha\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1409929082\",\"name\":\"Jordan L. Boyd-Graber\"}],\"doi\":\"10.18653/v1/W16-0107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13b674bb3078623608045a18570b47f6e49a8358\",\"title\":\"\\u201cA Distorted Skull Lies in the Bottom Center...\\u201d Identifying Paintings from Text Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/13b674bb3078623608045a18570b47f6e49a8358\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51118891\",\"name\":\"Enjie Cui\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1007/978-3-319-97289-3_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f014ed75aebbf3a6bc3c0833bda870673e43c26c\",\"title\":\"Selective Comprehension for Referring Expression by Prebuilt Entity Dictionary with Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/f014ed75aebbf3a6bc3c0833bda870673e43c26c\",\"venue\":\"PKAW\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/s11263-018-1096-0\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"title\":\"Combining Multiple Cues for Visual Madlibs Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"92790579\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-13969-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50d8da795bd50ebd14c4635116c159354409c9c\",\"title\":\"Automatic Classification and Reporting of Multiple Common Thorax Diseases Using Chest Radiographs\",\"url\":\"https://www.semanticscholar.org/paper/d50d8da795bd50ebd14c4635116c159354409c9c\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":\"1711.08105\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-01267-0_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a742c64f14b145b9e653ef30819520c5ce5e0123\",\"title\":\"Visual Question Answering as a Meta Learning Task\",\"url\":\"https://www.semanticscholar.org/paper/a742c64f14b145b9e653ef30819520c5ce5e0123\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.07939\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2017.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"title\":\"Recurrent Multimodal Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2907492\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"7476726\",\"name\":\"Eshan Verma\"},{\"authorId\":\"1794486\",\"name\":\"M. Savvides\"}],\"doi\":\"10.1007/978-3-319-61657-5_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2308649d960a41bca916390d6d041dd534f5c26\",\"title\":\"DeepGender2: A Generative Approach Toward Occlusion and Low-Resolution Robust Facial Gender Classification via Progressively Trained Attention Shift Convolutional Neural Networks (PTAS-CNN) and Deep Convolutional Generative Adversarial Networks (DCGAN)\",\"url\":\"https://www.semanticscholar.org/paper/b2308649d960a41bca916390d6d041dd534f5c26\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1703.08120\",\"authors\":[{\"authorId\":\"2321160\",\"name\":\"Abhijit Sharang\"},{\"authorId\":\"143756813\",\"name\":\"Eric Lau\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c0c611ebc538662023c7e5e51654a47e8063c2e\",\"title\":\"Recurrent and Contextual Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c0c611ebc538662023c7e5e51654a47e8063c2e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1903.09950\",\"authors\":[{\"authorId\":\"27678837\",\"name\":\"Y. Xia\"},{\"authorId\":\"2569534\",\"name\":\"J. Kim\"},{\"authorId\":\"1729041\",\"name\":\"J. Canny\"},{\"authorId\":\"2769532\",\"name\":\"K. Zipser\"},{\"authorId\":\"143659729\",\"name\":\"D. Whitney\"}],\"doi\":\"10.1109/WACV45572.2020.9093524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a17dc7457a6c13641a4f2a2dbf33203fa382d12a\",\"title\":\"Periphery-Fovea Multi-Resolution Driving Model Guided by Human Attention\",\"url\":\"https://www.semanticscholar.org/paper/a17dc7457a6c13641a4f2a2dbf33203fa382d12a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8193c52c32b7620c6b12dfe2643ff8c1360e38dd\",\"title\":\"A Bayesian approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8193c52c32b7620c6b12dfe2643ff8c1360e38dd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47935745\",\"name\":\"Hang Qi\"},{\"authorId\":\"2762640\",\"name\":\"Yuanlu Xu\"},{\"authorId\":\"48580157\",\"name\":\"T. Yuan\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d75d644fcce8d2d4576e149febade5c5b8259a95\",\"title\":\"Scene-Centric Joint Parsing of Cross-View Videos\",\"url\":\"https://www.semanticscholar.org/paper/d75d644fcce8d2d4576e149febade5c5b8259a95\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1712.00733\",\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"23ed7f18100717ba814b2859196e10c5d4fed216\",\"title\":\"Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/23ed7f18100717ba814b2859196e10c5d4fed216\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"144889898\",\"name\":\"Mengqi Jiang\"},{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"46351963\",\"name\":\"Weixin Zhou\"},{\"authorId\":\"2181606\",\"name\":\"K. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2908035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0734fd670605a578b9e4b908e58b63e4142625e\",\"title\":\"Co-Attention Network With Question Type for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f0734fd670605a578b9e4b908e58b63e4142625e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1910.06315\",\"authors\":[{\"authorId\":\"153636852\",\"name\":\"Soumik Ranjan Dasgupta\"},{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"title\":\"Dynamic Attention Networks for Task Oriented Grounding\",\"url\":\"https://www.semanticscholar.org/paper/361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.00076\",\"authors\":[{\"authorId\":\"27678755\",\"name\":\"Zicong Fan\"},{\"authorId\":\"118126099\",\"name\":\"S. Meng\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ab0f44736311b677cb131ce40ed0a381c2ac9c4\",\"title\":\"OptiBox: Breaking the Limits of Proposals for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/5ab0f44736311b677cb131ce40ed0a381c2ac9c4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1901.06706\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"1868193\",\"name\":\"Farley Lai\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c54b796cc10cb530f77caa4d18e1c80ac863822\",\"title\":\"Visual Entailment: A Novel Task for Fine-Grained Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3c54b796cc10cb530f77caa4d18e1c80ac863822\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1713128\",\"name\":\"Quan Z. Sheng\"},{\"authorId\":\"65966956\",\"name\":\"A. Alhazmi\"},{\"authorId\":\"2829009\",\"name\":\"Chenliang Li\"}],\"doi\":\"10.1145/3374217\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"652107ea8161f607e3bdabc89199e9ff2fdfd015\",\"title\":\"Adversarial Attacks on Deep-learning Models in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/652107ea8161f607e3bdabc89199e9ff2fdfd015\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2020},{\"arxivId\":\"1811.11903\",\"authors\":[{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00648\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"title\":\"Visual Question Answering as Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1612.06530\",\"authors\":[{\"authorId\":\"144738967\",\"name\":\"S. Zhang\"},{\"authorId\":\"14564042\",\"name\":\"Lizhen Qu\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"2881049\",\"name\":\"Zhenglu Yang\"},{\"authorId\":\"8214269\",\"name\":\"Jiawan Zhang\"}],\"doi\":\"10.24963/ijcai.2017/592\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0f61fa2ae931eb001214b60c6391966ddb41123\",\"title\":\"Automatic Generation of Grounded Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/b0f61fa2ae931eb001214b60c6391966ddb41123\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1704.04224\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.440\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"title\":\"Spatial Memory for Context Reasoning in Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002278\",\"name\":\"Yikuan Li\"},{\"authorId\":\"51464971\",\"name\":\"Hanyin Wang\"},{\"authorId\":\"1830568527\",\"name\":\"Yuan Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"title\":\"A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports\",\"url\":\"https://www.semanticscholar.org/paper/ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06637\",\"authors\":[{\"authorId\":\"1742328079\",\"name\":\"Shaunak Halbe\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"title\":\"Exploring Weaknesses of VQA Models through Attribution Driven Insights\",\"url\":\"https://www.semanticscholar.org/paper/274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":\"1808.00300\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"}],\"doi\":\"10.1007/978-3-030-01231-1_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afe3a0d463e2f099305c745ddbf943844583795d\",\"title\":\"Learning Visual Question Answering by Bootstrapping Hard Attention\",\"url\":\"https://www.semanticscholar.org/paper/afe3a0d463e2f099305c745ddbf943844583795d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1911.03897\",\"authors\":[{\"authorId\":\"19677945\",\"name\":\"Yaoyiran Li\"},{\"authorId\":\"144924128\",\"name\":\"Jing Jiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"863bc093e87a2963a0f6b5fc6c2d8b7451b8a7b2\",\"title\":\"Two-Headed Monster And Crossed Co-Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/863bc093e87a2963a0f6b5fc6c2d8b7451b8a7b2\",\"venue\":\"AACL\",\"year\":2020},{\"arxivId\":\"1906.06216\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1351\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8501712706efa6f314438143de18507471781060\",\"title\":\"Improving Visual Question Answering by Referring to Generated Paragraph Captions\",\"url\":\"https://www.semanticscholar.org/paper/8501712706efa6f314438143de18507471781060\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367790\",\"name\":\"Seong Jae Hwang\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"152894252\",\"name\":\"A. Gordon\"},{\"authorId\":\"144755346\",\"name\":\"Zheng Xu\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"}],\"doi\":\"10.1145/3292500.3330653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f811e87c0e50dcd1e494be69afbd23f1fae73c5e\",\"title\":\"Large-Scale Training Framework for Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/f811e87c0e50dcd1e494be69afbd23f1fae73c5e\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":\"1804.00105\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708223\",\"name\":\"B. Li\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"title\":\"Visual Question Reasoning on General Dependency Tree\",\"url\":\"https://www.semanticscholar.org/paper/eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997954506\",\"name\":\"Yevhen Romaniak\"},{\"authorId\":\"1997944494\",\"name\":\"Anastasiia Smielova\"},{\"authorId\":\"1380224734\",\"name\":\"Yevhenii Yakishyn\"},{\"authorId\":\"1380224706\",\"name\":\"Valerii Dziubliuk\"},{\"authorId\":\"1380224713\",\"name\":\"Mykhailo Zlotnyk\"},{\"authorId\":\"1380224917\",\"name\":\"Oleksandr Viatchaninov\"}],\"doi\":\"10.1145/3379350.3416153\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7444f34dd62067823dcf58b1ffdf03a7047e1a96\",\"title\":\"Nimble: Mobile Interface for a Visual Question Answering Augmented by Gestures\",\"url\":\"https://www.semanticscholar.org/paper/7444f34dd62067823dcf58b1ffdf03a7047e1a96\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arne J. Supp\\u00e9\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a92b610d2eed67b934ef2075264e243e6e1ea91\",\"title\":\"Learning Multi-Modal Navigation for Unmanned Ground Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/2a92b610d2eed67b934ef2075264e243e6e1ea91\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1fa9c5af78b3ca04476f4ee6910684dc19008f5e\",\"title\":\"Supplementary Material : Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1fa9c5af78b3ca04476f4ee6910684dc19008f5e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103567595\",\"name\":\"Shayan Hassantabar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"880760777e3671593ba50b7a17b0d30b655fc86d\",\"title\":\"Visual Question Answering : Datasets , Methods , Challenges and Oppurtunities\",\"url\":\"https://www.semanticscholar.org/paper/880760777e3671593ba50b7a17b0d30b655fc86d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24874138\",\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":null,\"name\":\"Xiaohui Zeng\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1d4c49e764a200bc90113b0ba9c34664d0f9462\",\"title\":\"Memo No . 082 May 10 , 2018 Scene Graph Parsing as Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/d1d4c49e764a200bc90113b0ba9c34664d0f9462\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"title\":\"Preserved Knowledge Embedding Question : Why does the person have an umbrella ? Answer : It is raining . Knowledge Incorporated Open-Domain VQA Candidate Knowledge Retrieval Dynamic Memory Network Memory Updating Attention Machanisim Query\",\"url\":\"https://www.semanticscholar.org/paper/db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1909.10128\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cede1c63336de84344922876e6ee23617e2afb3\",\"title\":\"Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network\",\"url\":\"https://www.semanticscholar.org/paper/4cede1c63336de84344922876e6ee23617e2afb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398541225\",\"name\":\"Neha Tilak\"},{\"authorId\":\"145674268\",\"name\":\"S. Gandhi\"},{\"authorId\":\"143979239\",\"name\":\"T. Oates\"}],\"doi\":\"10.1109/IJCNN.2017.7965916\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea665686400e9094a83c149e4924571bf3df30b8\",\"title\":\"Visual entity linking\",\"url\":\"https://www.semanticscholar.org/paper/ea665686400e9094a83c149e4924571bf3df30b8\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"}],\"doi\":\"10.1109/CCDC.2017.7979342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7926df884c677ecbd2f44402f33024ccd942a6b\",\"title\":\"Visual attention based on long-short term memory model for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/f7926df884c677ecbd2f44402f33024ccd942a6b\",\"venue\":\"2017 29th Chinese Control And Decision Conference (CCDC)\",\"year\":2017},{\"arxivId\":\"1903.02741\",\"authors\":[{\"authorId\":\"145657495\",\"name\":\"Chi Zhang\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00546\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d0bfd3cb732471a0843a39d2d047caf60a844466\",\"title\":\"RAVEN: A Dataset for Relational and Analogical Visual REasoNing\",\"url\":\"https://www.semanticscholar.org/paper/d0bfd3cb732471a0843a39d2d047caf60a844466\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"2809150\",\"name\":\"Songhao Jia\"},{\"authorId\":\"2849249\",\"name\":\"Yi-Chen Lo\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICCV.2019.00755\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"661d82c26fad099f28a8da02d2c9d1cfee32cff4\",\"title\":\"See-Through-Text Grouping for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/661d82c26fad099f28a8da02d2c9d1cfee32cff4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12153206\",\"name\":\"Shengyan Liu\"},{\"authorId\":\"2025671\",\"name\":\"Haiyan Ding\"},{\"authorId\":\"47155070\",\"name\":\"Xiaobing Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5d250b1d69d36131e4848969f1ff9dd69486c44\",\"title\":\"Shengyan at VQA-Med 2020: An Encoder-Decoder Model for Medical Domain Visual Question Answering Task\",\"url\":\"https://www.semanticscholar.org/paper/e5d250b1d69d36131e4848969f1ff9dd69486c44\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145691225\",\"name\":\"Santiago Castro\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"1724416445\",\"name\":\"Cristina Noujaim\"},{\"authorId\":\"30646659\",\"name\":\"R. Wang\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"title\":\"LifeQA: A Real-life Dataset for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"39698901\",\"name\":\"H. Wang\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1109/TIP.2020.2992888\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de847c41c0b6c52e5fc770f364a19fed04a7b3ae\",\"title\":\"Textual-Visual Reference-Aware Attention Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/de847c41c0b6c52e5fc770f364a19fed04a7b3ae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"66658845\",\"name\":\"B. D. Eugenio\"}],\"doi\":\"10.1142/S1793351X20400085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eca1e3a8ecfd39026d3f7de4717ad0429d406602\",\"title\":\"Incorporating Verb Semantic Information in Visual Question Answering Through Multitask Learning Paradigm\",\"url\":\"https://www.semanticscholar.org/paper/eca1e3a8ecfd39026d3f7de4717ad0429d406602\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49780826\",\"name\":\"Hao Zhou\"},{\"authorId\":\"2056289\",\"name\":\"C. Hu\"},{\"authorId\":\"50445655\",\"name\":\"C. Zhang\"},{\"authorId\":\"113682165\",\"name\":\"Shengyang Shen\"}],\"doi\":\"10.1109/ICASSP.2019.8683464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f7df23240e9fe8bedc916942ce3b60e2ff37ef3\",\"title\":\"Visual Relationship Recognition via Language and Position Guided Attention\",\"url\":\"https://www.semanticscholar.org/paper/8f7df23240e9fe8bedc916942ce3b60e2ff37ef3\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1806.00857\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"31408089\",\"name\":\"Aron Szanto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a9135976912d4169a4490c641561ed0867a306c\",\"title\":\"On the Flip Side: Identifying Counterexamples in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2a9135976912d4169a4490c641561ed0867a306c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1709.05436\",\"authors\":[{\"authorId\":\"47935745\",\"name\":\"Hang Qi\"},{\"authorId\":\"2762640\",\"name\":\"Yuanlu Xu\"},{\"authorId\":\"48580157\",\"name\":\"Tao Yuan\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"145380991\",\"name\":\"Song-Chun Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39e7ac344b17d97267ec80681aeded17e3e6d786\",\"title\":\"Joint Parsing of Cross-view Scenes with Spatio-temporal Semantic Parse Graphs\",\"url\":\"https://www.semanticscholar.org/paper/39e7ac344b17d97267ec80681aeded17e3e6d786\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":null,\"name\":\"James Storer Brandeis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f95ef25dc7f87c6f1224e6e46ff4b86df1a16e\",\"title\":\"Highway Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/39f95ef25dc7f87c6f1224e6e46ff4b86df1a16e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1807.02257\",\"authors\":[{\"authorId\":\"1414497291\",\"name\":\"Edgar Margffoy-Tuay\"},{\"authorId\":\"152978592\",\"name\":\"Juan C. P\\u00e9rez\"},{\"authorId\":\"51049657\",\"name\":\"E. Botero\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"}],\"doi\":\"10.1007/978-3-030-01252-6_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"title\":\"Dynamic Multimodal Instance Segmentation guided by natural language queries\",\"url\":\"https://www.semanticscholar.org/paper/810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.05728\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"title\":\"Granular Multimodal Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.5244/C.31.131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d814981606fe5954148e45c737f1debe7b5b36c4\",\"title\":\"Visual Textbook Network: Watch Carefully before Answering Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/d814981606fe5954148e45c737f1debe7b5b36c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22225752\",\"name\":\"F. Brad\"}],\"doi\":\"10.1109/ICCVW.2019.00560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"title\":\"Scene Graph Contextualization in Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1604.04279\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46454-1_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"title\":\"Learning Visual Storylines with Skipping Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123335\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b44999bb2e23cf8ca0a413a2d006cc9800794650\",\"title\":\"More Than An Answer: Neural Pivot Network for Visual Qestion Answering\",\"url\":\"https://www.semanticscholar.org/paper/b44999bb2e23cf8ca0a413a2d006cc9800794650\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-319-75928-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51280870657c72400b5de46ba56ee18b9891ab40\",\"title\":\"Multimodal Attention Agents in Visual Conversation\",\"url\":\"https://www.semanticscholar.org/paper/51280870657c72400b5de46ba56ee18b9891ab40\",\"venue\":\"EIDWT\",\"year\":2018},{\"arxivId\":\"1711.07373\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"title\":\"Attentive Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1905.09400\",\"authors\":[{\"authorId\":\"8804979\",\"name\":\"Siddhesh Khandelwal\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3805f0058ac3b320016ca518a98de358aca9823\",\"title\":\"AttentionRNN: A Structured Spatial Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/f3805f0058ac3b320016ca518a98de358aca9823\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144318278\",\"name\":\"Abhishek Sinha\"},{\"authorId\":\"2566197\",\"name\":\"K. Ayush\"}],\"doi\":\"10.1109/ICIP.2018.8451353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1f6f1f2f3c732eb986f604f6056c23bd9e25c7c\",\"title\":\"Towards Mathematical Reasoning: A Multimodal Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/f1f6f1f2f3c732eb986f604f6056c23bd9e25c7c\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2010.11701\",\"authors\":[{\"authorId\":\"84039136\",\"name\":\"P. Sadler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60d6e35891baa34282433546df0449d7422ce98\",\"title\":\"Spatial Attention as an Interface for Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b60d6e35891baa34282433546df0449d7422ce98\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717592\",\"name\":\"W. Zhang\"},{\"authorId\":\"1792246\",\"name\":\"C. Zhang\"},{\"authorId\":\"3114205\",\"name\":\"P. Liu\"},{\"authorId\":\"2035942\",\"name\":\"Zhiqiang Zhan\"},{\"authorId\":\"34985964\",\"name\":\"Xiaofeng Qiu\"}],\"doi\":\"10.1109/BIGCOM.2017.17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f24a03b9b55327704fba3aed182323137113c2\",\"title\":\"Two-Step Joint Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a3f24a03b9b55327704fba3aed182323137113c2\",\"venue\":\"2017 3rd International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e464187b1cee23117a0b1b1b86a479bee011d991\",\"title\":\"Project on Visual Commonsense Reasoning Anonymous ACL submission\",\"url\":\"https://www.semanticscholar.org/paper/e464187b1cee23117a0b1b1b86a479bee011d991\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.01172\",\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1832b749528755dfcbe462717f4f5afc07243b8\",\"title\":\"Commonsense Reasoning for Natural Language Understanding: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b1832b749528755dfcbe462717f4f5afc07243b8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10582\",\"authors\":[{\"authorId\":\"38907975\",\"name\":\"Ning Xie\"},{\"authorId\":\"1868193\",\"name\":\"Farley Lai\"},{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0955252cd57db8503a2ed9e56f195fa44b1bc0d4\",\"title\":\"Visual Entailment Task for Visually-Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/0955252cd57db8503a2ed9e56f195fa44b1bc0d4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.06994\",\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"7573997\",\"name\":\"Huayi Zhan\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"67250414\",\"name\":\"B. Sinha\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2019.00855\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"title\":\"Visual Query Answering by Entity-Attribute Graph Matching and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"1478185914\",\"name\":\"Zehan Song\"},{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/TIP.2020.2963950\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"title\":\"Open-Ended Video Question Answering via Multi-Modal Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969948\",\"name\":\"Zhihui Li\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"2585415\",\"name\":\"Shirui Pan\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"},{\"authorId\":\"46702510\",\"name\":\"Hua-Xiang Zhang\"}],\"doi\":\"10.1145/3394486.3403072\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c2dbeb0edfd63241c5c902f5bded78e42d6d1ef\",\"title\":\"Grounding Visual Concepts for Zero-Shot Event Detection and Event Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c2dbeb0edfd63241c5c902f5bded78e42d6d1ef\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1858438\",\"name\":\"Zhengyi Liu\"},{\"authorId\":\"122560994\",\"name\":\"Quntao Duan\"},{\"authorId\":\"1492200471\",\"name\":\"Song Shi\"},{\"authorId\":\"145344370\",\"name\":\"Peng Zhao\"}],\"doi\":\"10.1007/s00371-020-01821-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4e7389f4a68a51375dee8f914fbfcefa0fbea3\",\"title\":\"Multi-level progressive parallel attention guided salient object detection for RGB-D images\",\"url\":\"https://www.semanticscholar.org/paper/9a4e7389f4a68a51375dee8f914fbfcefa0fbea3\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.00623\",\"authors\":[{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"7236400\",\"name\":\"S. Choi\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"7951400\",\"name\":\"J. Kim\"},{\"authorId\":\"89496405\",\"name\":\"Jeh-Kwang Ryu\"},{\"authorId\":\"39171461\",\"name\":\"B. Bae\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b27b6df500b4fc50092f22727a90111b2010a588\",\"title\":\"Constructing Hierarchical Q&A Datasets for Video Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b27b6df500b4fc50092f22727a90111b2010a588\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51479145\",\"name\":\"Shailaja Keyur Sampat\"},{\"authorId\":\"70248997\",\"name\":\"J. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f756bcefdb0b1050a6f892b34f01048bbc64bfb8\",\"title\":\"A Model-Based Approach to Visual Reasoning on CNLVR Dataset\",\"url\":\"https://www.semanticscholar.org/paper/f756bcefdb0b1050a6f892b34f01048bbc64bfb8\",\"venue\":\"KR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240687\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"title\":\"Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA\",\"url\":\"https://www.semanticscholar.org/paper/97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1806.03960\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"2619658\",\"name\":\"Zhuode Liu\"},{\"authorId\":\"13800723\",\"name\":\"L. Zhang\"},{\"authorId\":\"51002225\",\"name\":\"Jake A. Whritner\"},{\"authorId\":\"47136793\",\"name\":\"K. Muller\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1007/978-3-030-01252-6_41\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"170643ea1794c4285a491bcea7dede2d35806726\",\"title\":\"AGIL: Learning Attention from Human for Visuomotor Tasks\",\"url\":\"https://www.semanticscholar.org/paper/170643ea1794c4285a491bcea7dede2d35806726\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"34711141\",\"name\":\"Ankita Bishnu\"},{\"authorId\":\"22267101\",\"name\":\"L. Patel\"}],\"doi\":\"10.18653/v1/P17-3008\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e8691980eeb827b10cdfb4cc402b3f43f020bc6a\",\"title\":\"Segmentation Guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e8691980eeb827b10cdfb4cc402b3f43f020bc6a\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145919381\",\"name\":\"J. Hu\"},{\"authorId\":\"9582936\",\"name\":\"Desai Fan\"},{\"authorId\":\"3467427\",\"name\":\"S. Yao\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0074ccd17382bf077bf08d649a97541ad64478fd\",\"title\":\"Answer-Aware Attention on Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/0074ccd17382bf077bf08d649a97541ad64478fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2154334\",\"name\":\"Ruizhen Hu\"},{\"authorId\":\"3276873\",\"name\":\"O. V. Kaick\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"2295141\",\"name\":\"M. Savva\"}],\"doi\":\"10.1145/2988458.2988469\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a043d23d07ffd2590308fcab3a137c44927093b9\",\"title\":\"SIGGRAPH Asia 2016: course notes directions in shape analysis towards functionality\",\"url\":\"https://www.semanticscholar.org/paper/a043d23d07ffd2590308fcab3a137c44927093b9\",\"venue\":\"SIGGRAPH ASIA Courses\",\"year\":2016},{\"arxivId\":\"1912.03098\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-030-58558-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"title\":\"Connecting Vision and Language with Localized Narratives\",\"url\":\"https://www.semanticscholar.org/paper/439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"51431789\",\"name\":\"Dan Shiebler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"title\":\"Learning what and where to attend\",\"url\":\"https://www.semanticscholar.org/paper/136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1712.01238\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/CVPR.2018.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f355634fac2b445a475ee81b8d16bf768188ec\",\"title\":\"Learning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/83f355634fac2b445a475ee81b8d16bf768188ec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11263-017-1033-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"828ac57f755db989e2886042a85278ae4823297c\",\"title\":\"Uncovering the Temporal Context for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/828ac57f755db989e2886042a85278ae4823297c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1912.11861\",\"authors\":[{\"authorId\":\"1696018\",\"name\":\"Filippos Gouidis\"},{\"authorId\":\"1471858890\",\"name\":\"Alexandros Vassiliades\"},{\"authorId\":\"151470761\",\"name\":\"Theodore Patkos\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"},{\"authorId\":\"143804820\",\"name\":\"Nick Bassiliades\"},{\"authorId\":\"69853580\",\"name\":\"Dimitris Plexousakis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"487ca1670a7fd97ff33be6f7d85455d00cea63ea\",\"title\":\"A Review on Intelligent Object Perception Methods Combining Knowledge-based Reasoning and Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/487ca1670a7fd97ff33be6f7d85455d00cea63ea\",\"venue\":\"AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.01801\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"46328947\",\"name\":\"B. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/WACV45572.2020.9093494\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"title\":\"Answering Questions about Data Visualizations using Efficient Bimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1804.00298\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/CVPR.2018.00801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"title\":\"Differential Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1611.01603\",\"authors\":[{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a7b63b50c64f4ec3358477790e84cbd6be2a0b4\",\"title\":\"Bidirectional Attention Flow for Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145654605\",\"name\":\"Correia Ribeiro\"},{\"authorId\":\"51281748\",\"name\":\"M. T\\u00falio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9ade1cb5278876e2ee6cf4adf1adadabf8ca40ca\",\"title\":\"Model-Agnostic Explanations and Evaluation of Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ade1cb5278876e2ee6cf4adf1adadabf8ca40ca\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739898\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d7f60e41dd9cb84ac5754d59e5a8b418fc7a685\",\"title\":\"Generator Based On Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d7f60e41dd9cb84ac5754d59e5a8b418fc7a685\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145952554\",\"name\":\"Michael Chan\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2019.00901\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"title\":\"Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.06306\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/ICCV.2019.00754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"title\":\"U-CAM: Visual Explanation Using Uncertainty Based Class Activation Maps\",\"url\":\"https://www.semanticscholar.org/paper/5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.01780\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1b8ffe938f706a9416c319a34793a2389866773\",\"title\":\"Visual Question Answering as a Multi-Task Problem\",\"url\":\"https://www.semanticscholar.org/paper/b1b8ffe938f706a9416c319a34793a2389866773\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/978-981-15-5788-0_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"title\":\"Optimal Image Feature Ranking and Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"venue\":\"FICTA\",\"year\":2020},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"2193560\",\"name\":\"Piji Li\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.24963/ijcai.2018/563\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9328898f9e04e4ddfbc377701ecf3d4da2e44652\",\"title\":\"A Question Type Driven Framework to Diversify Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9328898f9e04e4ddfbc377701ecf3d4da2e44652\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1610.06620\",\"authors\":[{\"authorId\":\"1814319\",\"name\":\"Omid Bakhshandeh\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"145907577\",\"name\":\"W. Chang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4bb5fc80767bc3ef3810546428c0c4b93ebdf16\",\"title\":\"Proposing Plausible Answers for Open-ended Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d4bb5fc80767bc3ef3810546428c0c4b93ebdf16\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1704.04859\",\"authors\":[{\"authorId\":\"2155134\",\"name\":\"Frederick Liu\"},{\"authorId\":\"145830316\",\"name\":\"H. Lu\"},{\"authorId\":\"144645869\",\"name\":\"Chieh Lo\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.18653/v1/P17-1188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db253b17043b6a86e02173b6aa597664b0c7f256\",\"title\":\"Learning Character-level Compositionality with Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/db253b17043b6a86e02173b6aa597664b0c7f256\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1905.01984\",\"authors\":[{\"authorId\":\"49346714\",\"name\":\"Q. Zhang\"},{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":\"49528142\",\"name\":\"H. Wang\"},{\"authorId\":\"1710232\",\"name\":\"Yunji Liang\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"50077884\",\"name\":\"Zhiwen Yu\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c60f184112ead2648f4ec9875b20035631c0c512\",\"title\":\"AI-Powered Text Generation for Harmonious Human-Machine Interaction: Current State and Future Directions\",\"url\":\"https://www.semanticscholar.org/paper/c60f184112ead2648f4ec9875b20035631c0c512\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.02794\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"93155387\",\"name\":\"Karan Jariwala\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/N19-1194\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f17f7590a6b4488921f046112bc8fdb82d513914\",\"title\":\"VQD: Visual Query Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/f17f7590a6b4488921f046112bc8fdb82d513914\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2009.00145\",\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":null,\"name\":\"Yujing Wang\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":\"10.1016/j.patcog.2020.107563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e526624783b3b5687da54b8cd4a7190a26a0b5e8\",\"title\":\"Cross-modal Knowledge Reasoning for Knowledge-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e526624783b3b5687da54b8cd4a7190a26a0b5e8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1911.04058\",\"authors\":[{\"authorId\":\"48615049\",\"name\":\"Y. Xu\"},{\"authorId\":\"46308159\",\"name\":\"L. Chen\"},{\"authorId\":\"120235436\",\"name\":\"Zhongwei Cheng\"},{\"authorId\":\"71138167\",\"name\":\"Lixin Duan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.34\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"title\":\"Open-Ended Visual Question Answering by Multi-Modal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.01810\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708631\",\"name\":\"Bailin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tpami.2019.2943456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"title\":\"Interpretable Visual Question Answering by Reasoning on Dependency Trees\",\"url\":\"https://www.semanticscholar.org/paper/97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1704.02516\",\"authors\":[{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/CVPR.2017.773\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"title\":\"An Empirical Evaluation of Visual Question Answering for Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"1691826\",\"name\":\"Y. Li\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532764\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"940c42892bc5b012be2b2ac7421ccb15005781e6\",\"title\":\"Simple and effective visual question answering in a single modality\",\"url\":\"https://www.semanticscholar.org/paper/940c42892bc5b012be2b2ac7421ccb15005781e6\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1610.02692\",\"authors\":[{\"authorId\":\"8136555\",\"name\":\"Issey Masuda\"},{\"authorId\":\"7816749\",\"name\":\"Santiago Pascual de la Puente\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f01ad151706d8fb2d2c3e5e134e609e8664f30be\",\"title\":\"Open-Ended Visual Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/f01ad151706d8fb2d2c3e5e134e609e8664f30be\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145066124\",\"name\":\"Bin Guo\"},{\"authorId\":\"46506266\",\"name\":\"Haiying Wang\"},{\"authorId\":\"151260226\",\"name\":\"Yasan Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Yueqi Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"title\":\"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8804979\",\"name\":\"Siddhesh Khandelwal\"}],\"doi\":\"10.14288/1.0384602\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0217b35a52d1e6b29ab734fe8b637ddad66cbe89\",\"title\":\"Enforcing structure in visual attention\",\"url\":\"https://www.semanticscholar.org/paper/0217b35a52d1e6b29ab734fe8b637ddad66cbe89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.11185\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"021b08b823700f8053afc54356e8d0ce57a3df71\",\"title\":\"Unsupervised Textual Grounding: Linking Words to Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/021b08b823700f8053afc54356e8d0ce57a3df71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112995179\",\"name\":\"L. Chen\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCVW.2019.00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"347748443be69ffceb2fb345df9b41448f2974ad\",\"title\":\"Object Grounding via Iterative Context Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/347748443be69ffceb2fb345df9b41448f2974ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1911.09655\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":\"10.1109/TASLP.2020.3010650\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bfa437129daef8533708924c395c3fd0c5c3bf81\",\"title\":\"Temporal Reasoning via Audio Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bfa437129daef8533708924c395c3fd0c5c3bf81\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144690460\",\"name\":\"Di Lu\"},{\"authorId\":\"152842060\",\"name\":\"Leonardo Neves\"},{\"authorId\":\"144714820\",\"name\":\"V. Carvalho\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"144016781\",\"name\":\"Heng Ji\"}],\"doi\":\"10.18653/v1/P18-1185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f81602b157899a785f49ca58ab99494a06c84bb9\",\"title\":\"Visual Attention Model for Name Tagging in Multimodal Social Media\",\"url\":\"https://www.semanticscholar.org/paper/f81602b157899a785f49ca58ab99494a06c84bb9\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"L. Wang\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1109/MIPR.2018.00038\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"883800c16fd5250d43a195dfa8b4eeca0b7f7e0b\",\"title\":\"Affective Visual Question Answering Network\",\"url\":\"https://www.semanticscholar.org/paper/883800c16fd5250d43a195dfa8b4eeca0b7f7e0b\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2017.766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"401cb8e62b915a7af0bd18776548896559566ce0\",\"title\":\"ViP-CNN: Visual Phrase Guided Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/401cb8e62b915a7af0bd18776548896559566ce0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1901.00850\",\"authors\":[{\"authorId\":\"9326827\",\"name\":\"Runtao Liu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00431\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9695676deace8c05d4e95274b92f20ed1e97470c\",\"title\":\"CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9695676deace8c05d4e95274b92f20ed1e97470c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.12352\",\"authors\":[{\"authorId\":\"1845867134\",\"name\":\"Letitia Parcalabescu\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"143876555\",\"name\":\"A. Frank\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"title\":\"Seeing past words: Testing the cross-modal capabilities of pretrained V&L models\",\"url\":\"https://www.semanticscholar.org/paper/1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.06666\",\"authors\":[{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1932edb4e5b2aae30ec1e7344b16d6110f52ef4\",\"title\":\"VirTex: Learning Visual Representations from Textual Annotations\",\"url\":\"https://www.semanticscholar.org/paper/b1932edb4e5b2aae30ec1e7344b16d6110f52ef4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3269206.3271765\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c67d62592ff24a25764e489a8a68672d40f50da7\",\"title\":\"Adversarial Learning of Answer-Related Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c67d62592ff24a25764e489a8a68672d40f50da7\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47111044\",\"name\":\"Mingqin Chen\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"145675052\",\"name\":\"Shan Chen\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"}],\"doi\":\"10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"title\":\"Counting Attention Based on Classification Confidence for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"venue\":\"2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"287c5be2610e1c61798851feb32b88c424acfbf9\",\"title\":\"Hierarchical Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/287c5be2610e1c61798851feb32b88c424acfbf9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31696860\",\"name\":\"Shurong Sheng\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10be82098017fc2d60b0572cea8032afabad5d1a\",\"title\":\"A Dataset for Multimodal Question Answering in the Cultural Heritage Domain\",\"url\":\"https://www.semanticscholar.org/paper/10be82098017fc2d60b0572cea8032afabad5d1a\",\"venue\":\"LT4DH@COLING\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.09134\",\"authors\":[{\"authorId\":\"2674321\",\"name\":\"Jiaying Lu\"},{\"authorId\":\"153031206\",\"name\":\"Xin Ye\"},{\"authorId\":\"71048893\",\"name\":\"Yi Ren\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f78833c64750122ad21f79f2f53db37141237d\",\"title\":\"Good, Better, Best: Textual Distractors Generation for Multi-Choice VQA via Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/58f78833c64750122ad21f79f2f53db37141237d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.09468\",\"authors\":[{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"9694054\",\"name\":\"Ming-Li Song\"}],\"doi\":\"10.1007/978-3-030-04167-0_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b06c13335774f9cadab50b172d7fa9085374566\",\"title\":\"DeepSIC: Deep Semantic Image Compression\",\"url\":\"https://www.semanticscholar.org/paper/4b06c13335774f9cadab50b172d7fa9085374566\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"51252244\",\"name\":\"Elinda Kajo Me\\u00e7e\"}],\"doi\":\"10.1145/3230467.3230476\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f3efd4cc31527d5d8fc27aad27b140042f5f7561\",\"title\":\"Visual Question Answering Agent with Visual and Textual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f3efd4cc31527d5d8fc27aad27b140042f5f7561\",\"venue\":\"ICEMC '18\",\"year\":2018},{\"arxivId\":\"1701.02870\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/CVPR.2017.120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e782437503f2a24fd1a836a434da395bf15c88c2\",\"title\":\"Context-Aware Captions from Context-Agnostic Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e782437503f2a24fd1a836a434da395bf15c88c2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20600120\",\"name\":\"Mihael Cudic\"},{\"authorId\":\"40269075\",\"name\":\"R. Burt\"},{\"authorId\":\"145805087\",\"name\":\"Eder Santana\"},{\"authorId\":\"143961030\",\"name\":\"J. Pr\\u00edncipe\"}],\"doi\":\"10.1016/j.neucom.2018.02.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7d0325e3a012cae26b3d0861e878d60e97d0035\",\"title\":\"A flexible testing environment for visual question answering with performance evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7d0325e3a012cae26b3d0861e878d60e97d0035\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82117909\",\"name\":\"Sanket Shah\"},{\"authorId\":\"39719398\",\"name\":\"Anand Mishra\"},{\"authorId\":\"46202814\",\"name\":\"N. Yadati\"},{\"authorId\":\"2408872\",\"name\":\"P. Talukdar\"}],\"doi\":\"10.1609/aaai.v33i01.33018876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0818dac77eee5b970736e57a478bcedfb1b15fe\",\"title\":\"KVQA: Knowledge-Aware Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d0818dac77eee5b970736e57a478bcedfb1b15fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":\"10.18653/v1/2020.acl-main.643\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e600553fe2f21630f2a272c80de4ce0e0363cb9c\",\"title\":\"Multimodal Neural Graph Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e600553fe2f21630f2a272c80de4ce0e0363cb9c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1906.07689\",\"authors\":[{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eb2e2b9c22cb1da8561044ca0dc8fc0b13e3157\",\"title\":\"Expressing Visual Relationships via Language\",\"url\":\"https://www.semanticscholar.org/paper/4eb2e2b9c22cb1da8561044ca0dc8fc0b13e3157\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2012.12871\",\"authors\":[{\"authorId\":\"1751661088\",\"name\":\"Phillip Lippe\"},{\"authorId\":\"1661217828\",\"name\":\"Nithin Holla\"},{\"authorId\":\"1879340965\",\"name\":\"Shantanu Chandra\"},{\"authorId\":\"1723418777\",\"name\":\"Santhosh Rajamanickam\"},{\"authorId\":\"33537528\",\"name\":\"G. Antoniou\"},{\"authorId\":\"2362276\",\"name\":\"Ekaterina Shutova\"},{\"authorId\":\"2169553\",\"name\":\"H. Yannakoudakis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"76e266d5220f963886cf30ae747d72fdf8c84378\",\"title\":\"A Multimodal Framework for the Detection of Hateful Memes\",\"url\":\"https://www.semanticscholar.org/paper/76e266d5220f963886cf30ae747d72fdf8c84378\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1702.06700\",\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2385007824daaf9eac9476fccb1501b7ac166ceb\",\"title\":\"Task-driven Visual Saliency and Attention-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2385007824daaf9eac9476fccb1501b7ac166ceb\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9330502\",\"name\":\"Navneet Sinha\"},{\"authorId\":\"1841118\",\"name\":\"Ifeoma Nwogu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20289282fedfd60d9d4a7153f460f5c8e0a502b8\",\"title\":\"Goal Driven Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/20289282fedfd60d9d4a7153f460f5c8e0a502b8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8d37d9522d57df506a6eda88953bd97c009ea29\",\"title\":\"Characterizing how Visual Question Answering models scale with the world\",\"url\":\"https://www.semanticscholar.org/paper/e8d37d9522d57df506a6eda88953bd97c009ea29\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"title\":\"A Simple Baseline for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2252963\",\"name\":\"X. Li\"}],\"doi\":\"10.7282/T3CF9TJH\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a6bc21051679bded51b0e9463083cf910d0d93b\",\"title\":\"Process progress estimation and activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a6bc21051679bded51b0e9463083cf910d0d93b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7c75b16563d07069505cd07dd6466d86f6958f9\",\"title\":\"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/e7c75b16563d07069505cd07dd6466d86f6958f9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"144780837\",\"name\":\"Li He\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1109/ICME.2018.8486475\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"title\":\"Dual Learning for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3470231\",\"name\":\"Liangming Pan\"},{\"authorId\":\"39165620\",\"name\":\"Wenqiang Lei\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a98cf0d3416951db233110959e16081b2f86f82\",\"title\":\"C L ] 2 7 M ay 2 01 9 Recent Advances in Neural Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/1a98cf0d3416951db233110959e16081b2f86f82\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2009.11278\",\"authors\":[{\"authorId\":\"2706729\",\"name\":\"Jaemin Cho\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"title\":\"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/e5fb7a72807af36a7d39049346b3feb422a50c3c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40474403\",\"name\":\"J. J. Lau\"},{\"authorId\":\"29948554\",\"name\":\"Soumya Gayen\"},{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":\"10.1038/sdata.2018.251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"title\":\"A dataset of clinically generated visual questions and answers about radiology images\",\"url\":\"https://www.semanticscholar.org/paper/18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"venue\":\"Scientific Data\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2017.2746267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"title\":\"Unifying the Video and Question Attentions for Open-Ended Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1801.04334\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2018.00943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1b2402dcd85b81381fde40d0b971b510471ef23\",\"title\":\"TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays\",\"url\":\"https://www.semanticscholar.org/paper/b1b2402dcd85b81381fde40d0b971b510471ef23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb4fc76dc335f89d258f38676ea6e92c9ddf66c6\",\"title\":\"Multimodal Learning and Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb4fc76dc335f89d258f38676ea6e92c9ddf66c6\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"14898006\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"145947071\",\"name\":\"Jing Qin\"}],\"doi\":\"10.1109/TNNLS.2019.2933439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"title\":\"Exploring Duality in Visual Question-Driven Top-Down Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1811.05013\",\"authors\":[{\"authorId\":\"12679121\",\"name\":\"Ankesh Anand\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"},{\"authorId\":\"2182706\",\"name\":\"Kyle Kastner\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96ec628fc3608f88fdef998bf68eb37f7ae17359\",\"title\":\"Blindfold Baselines for Embodied QA\",\"url\":\"https://www.semanticscholar.org/paper/96ec628fc3608f88fdef998bf68eb37f7ae17359\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.06796\",\"authors\":[{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1713128\",\"name\":\"Quan Z. Sheng\"},{\"authorId\":\"65966956\",\"name\":\"A. Alhazmi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42d6727d6db5440a87d223a474b3dc6ecc271aeb\",\"title\":\"Generating Textual Adversarial Examples for Deep Learning Models: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/42d6727d6db5440a87d223a474b3dc6ecc271aeb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.10255\",\"authors\":[{\"authorId\":\"8809422\",\"name\":\"Vishwanath Sindagi\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/TIP.2019.2928634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f8a1d07216259a87fe8968feb9379c14629ad9f\",\"title\":\"HA-CCN: Hierarchical Attention-Based Crowd Counting Network\",\"url\":\"https://www.semanticscholar.org/paper/8f8a1d07216259a87fe8968feb9379c14629ad9f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1908.10028\",\"authors\":[{\"authorId\":\"3338475\",\"name\":\"Junsuk Choe\"},{\"authorId\":\"2081318\",\"name\":\"Hyunjung Shim\"}],\"doi\":\"10.1109/CVPR.2019.00232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb337033885ff9e34f48d6ae0c810ef5b709efbb\",\"title\":\"Attention-Based Dropout Layer for Weakly Supervised Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/eb337033885ff9e34f48d6ae0c810ef5b709efbb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1016/j.csl.2020.101093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"title\":\"Transfer learning for multimodal dialog\",\"url\":\"https://www.semanticscholar.org/paper/9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743434\",\"name\":\"W. Cheng\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fa1076a98a15cec083fb474f238237f1b3a341a\",\"title\":\"Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-based Method\",\"url\":\"https://www.semanticscholar.org/paper/6fa1076a98a15cec083fb474f238237f1b3a341a\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1145/3009906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e60536c847ac25dba4c1c071e0355e5537fe061\",\"title\":\"Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061\",\"venue\":\"ACM Comput. Surv.\",\"year\":2017},{\"arxivId\":\"1609.05600\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.344\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7d007ba376faddf0046930ea7375ed59600cee9\",\"title\":\"Graph-Structured Representations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c7d007ba376faddf0046930ea7375ed59600cee9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.06059\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.18653/v1/P16-1170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"title\":\"Generating Natural Questions About an Image\",\"url\":\"https://www.semanticscholar.org/paper/8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2002.06289\",\"authors\":[{\"authorId\":\"73775105\",\"name\":\"Antoni Rosinol\"},{\"authorId\":\"48668934\",\"name\":\"Arjun Gupta\"},{\"authorId\":\"1381693514\",\"name\":\"M. Abate\"},{\"authorId\":\"95677827\",\"name\":\"J. Shi\"},{\"authorId\":\"1710879\",\"name\":\"L. Carlone\"}],\"doi\":\"10.15607/rss.2020.xvi.079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44cca25d51d2614d0e32cd1b314748e32cf91770\",\"title\":\"3D Dynamic Scene Graphs: Actionable Spatial Perception with Places, Objects, and Humans\",\"url\":\"https://www.semanticscholar.org/paper/44cca25d51d2614d0e32cd1b314748e32cf91770\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993611266\",\"name\":\"Guohao Li\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413943\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"title\":\"Boosting Visual Question Answering with Context-aware Knowledge Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"27563697\",\"name\":\"Pabitra Lenka\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"title\":\"A Unified Framework for Multilingual and Code-Mixed Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.04166\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TIP.2020.2967584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866908141e1db5d6b278984072303a0e14423bcc\",\"title\":\"Revisiting EmbodiedQA: A Simple Baseline and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/866908141e1db5d6b278984072303a0e14423bcc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1605.09553\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"title\":\"Attention Correctness in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1703.06492\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"title\":\"VQABQ: Visual Question Answering by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-030-11018-5_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8173e63aa2db962b9807bdbab66538afb3caf929\",\"title\":\"MoQA - A Multi-modal Question Answering Architecture\",\"url\":\"https://www.semanticscholar.org/paper/8173e63aa2db962b9807bdbab66538afb3caf929\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145268319\",\"name\":\"Qiang Sun\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":\"10.1145/3323873.3325044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33c6f05eac12622146fec4868735daa78f79f80a\",\"title\":\"Stacked Self-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33c6f05eac12622146fec4868735daa78f79f80a\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144905355\",\"name\":\"Chao Ma\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145950894\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"title\":\"Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52004465\",\"name\":\"J. Abdelnour\"},{\"authorId\":\"145709285\",\"name\":\"Giampiero Salvi\"},{\"authorId\":\"1680808\",\"name\":\"J. Rouat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1df4414f38e524db344d868938fdd8ddecde23b1\",\"title\":\"L G ] 2 8 Fe b 20 19 FROM VISUAL TO ACOUSTIC QUESTION ANSWERING\",\"url\":\"https://www.semanticscholar.org/paper/1df4414f38e524db344d868938fdd8ddecde23b1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1612.05386\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.416\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"title\":\"The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions\",\"url\":\"https://www.semanticscholar.org/paper/7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1802.08129\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2018.00915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"title\":\"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724431\",\"name\":\"D. Amanatidis\"},{\"authorId\":\"2283824\",\"name\":\"Michael F. Dossis\"},{\"authorId\":\"2139316\",\"name\":\"I. Mylona\"}],\"doi\":\"10.1109/SEEDA-CECNSM.2019.8908466\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4bc184acb290aaf43dc93b81570d9cbf6ba4481\",\"title\":\"A Convolutional Neural Network for Sentiment Analysis of TripAdvisor reviews\",\"url\":\"https://www.semanticscholar.org/paper/c4bc184acb290aaf43dc93b81570d9cbf6ba4481\",\"venue\":\"2019 4th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)\",\"year\":2019},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410229972\",\"name\":\"Guy Ben-Yosef\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1098/rsfs.2018.0020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e81149da6e06bfd48386bf5cbcabf850e2875d3\",\"title\":\"Image interpretation above and below the object level\",\"url\":\"https://www.semanticscholar.org/paper/4e81149da6e06bfd48386bf5cbcabf850e2875d3\",\"venue\":\"Interface Focus\",\"year\":2018},{\"arxivId\":\"1805.08819\",\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"46242703\",\"name\":\"Dan Scheibler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.32470/CCN.2018.1113-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"title\":\"Global-and-local attention networks for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2001.07059\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"title\":\"Accuracy vs. Complexity: A Trade-off in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.08779\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":null,\"name\":\"Sandeep Kumar\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e4720942ff8b02d2822aea5d024628139551723\",\"title\":\"Deep Bayesian Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/8e4720942ff8b02d2822aea5d024628139551723\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39630692\",\"name\":\"Chenyue Meng\"},{\"authorId\":\"1728915\",\"name\":\"Y. Wang\"},{\"authorId\":\"3911164\",\"name\":\"S. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"433c16d0be2caa7bd5672282bea1368da087f824\",\"title\":\"Image-Question-Linguistic Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/433c16d0be2caa7bd5672282bea1368da087f824\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.03986\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"49596229\",\"name\":\"S. Kumar\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.18653/v1/D18-1434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"title\":\"Multimodal Differential Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146987905\",\"name\":\"Issey Masuda Mora\"},{\"authorId\":\"7816749\",\"name\":\"Santiago Pascual de la Puente\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"983534325c649e391fefe87025337187021b9830\",\"title\":\"Towards Automatic Generation of Question Answer Pairs from Images\",\"url\":\"https://www.semanticscholar.org/paper/983534325c649e391fefe87025337187021b9830\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1705.03865\",\"authors\":[{\"authorId\":\"50178628\",\"name\":\"Akshay Kumar Gupta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"637648198f9e91654ce27eaaa40512f2dc870fc1\",\"title\":\"Survey of Visual Question Answering: Datasets and Techniques\",\"url\":\"https://www.semanticscholar.org/paper/637648198f9e91654ce27eaaa40512f2dc870fc1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151411658\",\"name\":\"Xutao Qu\"},{\"authorId\":\"2127844\",\"name\":\"Dongye Zhuang\"},{\"authorId\":\"152962135\",\"name\":\"Haibin Xie\"}],\"doi\":\"10.1007/978-3-030-27532-7_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02a582e88eff56adc643b4d5404ae78a06524470\",\"title\":\"Semantic Situation Extraction from Satellite Image Based on Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/02a582e88eff56adc643b4d5404ae78a06524470\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1611.02145\",\"authors\":[{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1561/0600000073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c95a8db377c25d4280f188e9477569ab57281b\",\"title\":\"Crowdsourcing in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/84c95a8db377c25d4280f188e9477569ab57281b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2011.13681\",\"authors\":[{\"authorId\":\"20657367\",\"name\":\"A. Mani\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"},{\"authorId\":\"2029244392\",\"name\":\"Nobline Yoo\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"title\":\"Point and Ask: Incorporating Pointing into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1612.07833\",\"authors\":[{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"title\":\"Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task\",\"url\":\"https://www.semanticscholar.org/paper/6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1712.08697\",\"authors\":[{\"authorId\":\"3545259\",\"name\":\"A. Trott\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"title\":\"Interpretable Counting for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145865760\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3240508.3240527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81b3cfd55ca84802cdcc971410e633ed40e04980\",\"title\":\"Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/81b3cfd55ca84802cdcc971410e633ed40e04980\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24328497\",\"name\":\"Avraam Tsantekidis\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"2910979\",\"name\":\"J. Kanniainen\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"},{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"}],\"doi\":\"10.1109/CBI.2017.23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1d33d85efc0f9e3de8686bd12e9250cebd5fcda\",\"title\":\"Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f1d33d85efc0f9e3de8686bd12e9250cebd5fcda\",\"venue\":\"2017 IEEE 19th Conference on Business Informatics (CBI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1904.08920\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00851\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af1f7739283bdbd2b7a94903041f6d6afd991907\",\"title\":\"Towards VQA Models That Can Read\",\"url\":\"https://www.semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-030-01174-1_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"title\":\"Multimodal Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.05078\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"title\":\"Visual Grounding in Video for Unsupervised Word Translation\",\"url\":\"https://www.semanticscholar.org/paper/a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3814221\",\"name\":\"Vasileios Lioutas\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"}],\"doi\":\"10.1109/ISCAS.2018.8351158\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"36cdb5d188398fd5d84fcc0b8959edee69a54f58\",\"title\":\"Visual Question Answering using Explicit Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/36cdb5d188398fd5d84fcc0b8959edee69a54f58\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3814221\",\"name\":\"Vasileios Lioutas\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"}],\"doi\":\"10.1016/j.patrec.2018.04.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17984591f8b6fba05d950458220b0450f8753b84\",\"title\":\"Explicit ensemble attention learning for improving visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/17984591f8b6fba05d950458220b0450f8753b84\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1705.01253\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1016/j.neucom.2018.06.069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"783e48629dfbb44697b15a3bc0cb2aa3eea490eb\",\"title\":\"The Forgettable-Watcher Model for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/783e48629dfbb44697b15a3bc0cb2aa3eea490eb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1909.02097\",\"authors\":[{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"144865339\",\"name\":\"Bo Pang\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/D19-1155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b6e6822eabe2f64192a1965c23e38043866319c\",\"title\":\"Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic Labels Improve Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3b6e6822eabe2f64192a1965c23e38043866319c\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008177645\",\"name\":\"Hisashi Kamezawa\"},{\"authorId\":\"8058716\",\"name\":\"Noriki Nishida\"},{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"47615106\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88288c5ebea5da91bb699ec0cd2d9806f06955c1\",\"title\":\"A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses\",\"url\":\"https://www.semanticscholar.org/paper/88288c5ebea5da91bb699ec0cd2d9806f06955c1\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.08730\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1490642986\",\"name\":\"Shivansh Pate\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a487065408c44d387aa1cf7836cd58405f945983\",\"title\":\"Robust Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a487065408c44d387aa1cf7836cd58405f945983\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2019.00203\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bb60b737b53b23f5eb1f56cd145153d4581330\",\"title\":\"It's Not About the Journey; It's About the Destination: Following Soft Paths Under Question-Guidance for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/80bb60b737b53b23f5eb1f56cd145153d4581330\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2110665\",\"name\":\"A. Padmakumar\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"title\":\"Visual Question Answering using Natural Language Object Retrieval and Saliency Cues\",\"url\":\"https://www.semanticscholar.org/paper/aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412806873\",\"name\":\"Mandar Bhalerao\"},{\"authorId\":\"1491238382\",\"name\":\"Shlok Gujar\"},{\"authorId\":\"144555055\",\"name\":\"A. Bhave\"},{\"authorId\":\"2702152\",\"name\":\"Anant V. Nimkar\"}],\"doi\":\"10.1109/IBSSC47189.2019.8973090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"title\":\"Visual Question Answering Using Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"venue\":\"2019 IEEE Bombay Section Signature Conference (IBSSC)\",\"year\":2019},{\"arxivId\":\"2004.12238\",\"authors\":[{\"authorId\":\"1424748326\",\"name\":\"A. Kumar\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"title\":\"MCQA: Multimodal Co-attention Based Network for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.05558\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68773df340498768e88487abe8f7fbac5fcb52d\",\"title\":\"CoDraw: Visual Dialog for Collaborative Drawing\",\"url\":\"https://www.semanticscholar.org/paper/b68773df340498768e88487abe8f7fbac5fcb52d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1911.08618\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1609/AAAI.V34I07.6858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"title\":\"Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA\",\"url\":\"https://www.semanticscholar.org/paper/dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":\"1805.09786\",\"authors\":[{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"143653164\",\"name\":\"Ali Razavi\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"2910877\",\"name\":\"K. Hermann\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"2603033\",\"name\":\"V. Bapst\"},{\"authorId\":\"143724694\",\"name\":\"D. Raposo\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebff4eb2f94dcf38171a5ca6a24ee95bc8e88c10\",\"title\":\"Hyperbolic Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/ebff4eb2f94dcf38171a5ca6a24ee95bc8e88c10\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"39083167\",\"name\":\"A. Dutta\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"143826881\",\"name\":\"J. Llad\\u00f3s\"},{\"authorId\":\"144167309\",\"name\":\"U. Pal\"}],\"doi\":\"10.1007/978-3-030-20890-5_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaee9f15fcc7590b2f463bf9bc66745e797fd5f3\",\"title\":\"Aligning Salient Objects to Queries: A Multi-modal and Multi-object Image Retrieval Framework\",\"url\":\"https://www.semanticscholar.org/paper/eaee9f15fcc7590b2f463bf9bc66745e797fd5f3\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffedfc08fb9059cd06c65961b9a84e6cbcfaf27\",\"title\":\"Unconstrained Periocular Face Recognition: From Reconstructive Dictionary Learning to Generative Deep Learning and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/cffedfc08fb9059cd06c65961b9a84e6cbcfaf27\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.03230\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"152876475\",\"name\":\"William W. J. Wang\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0bbae624efbfeee01bd38185c6d754c08417de7\",\"title\":\"Meta Module Network for Compositional Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/d0bbae624efbfeee01bd38185c6d754c08417de7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66801160\",\"name\":\"Ge Yuan-yuan\"},{\"authorId\":\"1441325232\",\"name\":\"Xu Youjiang\"},{\"authorId\":\"1391375173\",\"name\":\"Han Ya-hong\"}],\"doi\":\"10.1007/978-981-10-7299-4_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"489baaf7ca4b6ed0ff3cef48a8b078ca09b4c080\",\"title\":\"Video Question Answering Using a Forget Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/489baaf7ca4b6ed0ff3cef48a8b078ca09b4c080\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46812189\",\"name\":\"K. Gao\"},{\"authorId\":\"15318113\",\"name\":\"Xianglei Zhu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-981-10-8530-7_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"333ff6c4544ea083581476e4dc70548aff7fb365\",\"title\":\"Initialized Frame Attention Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/333ff6c4544ea083581476e4dc70548aff7fb365\",\"venue\":\"ICIMCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48332333\",\"name\":\"Shuang Qiu\"},{\"authorId\":\"152621482\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/TMM.2019.2942480\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"863ce99910dad0efa42385e8a3bcbeb1f400acfb\",\"title\":\"Referring Image Segmentation by Generative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/863ce99910dad0efa42385e8a3bcbeb1f400acfb\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1806.03724\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00569\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"title\":\"Learning Answer Embeddings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"467ac47b2e01ce6ae74e8d70561ca0f8f66c7b8c\",\"title\":\"Probing Text Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/467ac47b2e01ce6ae74e8d70561ca0f8f66c7b8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.1109/CVPR.2017.571\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"title\":\"Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1908.06354\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"title\":\"A Fast and Accurate One-Stage Approach to Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.651\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"173a38768848cfe57a6b20b5ae019ce613e58781\",\"title\":\"Knowledge Acquisition for Visual Question Answering via Iterative Querying\",\"url\":\"https://www.semanticscholar.org/paper/173a38768848cfe57a6b20b5ae019ce613e58781\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tarfah Alrashid\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70327c8228b508388f96bd70d7dbdf3943c8437e\",\"title\":\"Annotating and Recognising Visually Descriptive Language\",\"url\":\"https://www.semanticscholar.org/paper/70327c8228b508388f96bd70d7dbdf3943c8437e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.07212\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1007/978-3-030-01261-8_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"title\":\"Cross-Modal and Hierarchical Modeling of Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12153206\",\"name\":\"Shengyan Liu\"},{\"authorId\":\"151257983\",\"name\":\"Xiaozhi Ou\"},{\"authorId\":\"90628610\",\"name\":\"Jiao Che\"},{\"authorId\":\"47155070\",\"name\":\"Xiaobing Zhou\"},{\"authorId\":\"2025671\",\"name\":\"Haiyan Ding\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"deb8fac1239d88df5e1ffd6bff52a767a1007628\",\"title\":\"An Xception-GRU Model for Visual Question Answering in the Medical Domain\",\"url\":\"https://www.semanticscholar.org/paper/deb8fac1239d88df5e1ffd6bff52a767a1007628\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"1910.02527\",\"authors\":[{\"authorId\":\"1798372\",\"name\":\"Iro Armeni\"},{\"authorId\":\"51243129\",\"name\":\"Zhi-Yang He\"},{\"authorId\":\"39813007\",\"name\":\"JunYoung Gwak\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"50359401\",\"name\":\"M. Fischer\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2019.00576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77b4f542ea56b02804672790b6482df400428c95\",\"title\":\"3D Scene Graph: A Structure for Unified Semantics, 3D Space, and Camera\",\"url\":\"https://www.semanticscholar.org/paper/77b4f542ea56b02804672790b6482df400428c95\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"1466481870\",\"name\":\"Bencheng Yan\"}],\"doi\":\"10.1007/978-3-030-36718-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77465a0ae333a9ce4cf3969b93e756772714fc63\",\"title\":\"Watch and Ask: Video Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/77465a0ae333a9ce4cf3969b93e756772714fc63\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068917\",\"name\":\"Ruoqian Liu\"},{\"authorId\":\"3019232\",\"name\":\"Diana Palsetia\"},{\"authorId\":\"47415634\",\"name\":\"A. Paul\"},{\"authorId\":\"1406516125\",\"name\":\"Reda Al-Bahrani\"},{\"authorId\":\"49942521\",\"name\":\"D. Jha\"},{\"authorId\":\"1847672\",\"name\":\"W. Liao\"},{\"authorId\":\"1725914\",\"name\":\"A. Agrawal\"},{\"authorId\":\"143975793\",\"name\":\"A. Choudhary\"}],\"doi\":\"10.1109/BigData.2016.7840868\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f201b4226d62bf449a68ebcc159acf8b95289be\",\"title\":\"PinterNet: A thematic label curation tool for large image datasets\",\"url\":\"https://www.semanticscholar.org/paper/7f201b4226d62bf449a68ebcc159acf8b95289be\",\"venue\":\"2016 IEEE International Conference on Big Data (Big Data)\",\"year\":2016},{\"arxivId\":\"1708.01988\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47718789\",\"name\":\"Wei Yang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f222282574666658dc0408176805cbe21348477d\",\"title\":\"Identity-Aware Textual-Visual Matching with Latent Co-attention\",\"url\":\"https://www.semanticscholar.org/paper/f222282574666658dc0408176805cbe21348477d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1903.00857\",\"authors\":[{\"authorId\":\"2525270\",\"name\":\"Gongjie Zhang\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/TGRS.2019.2930982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69034a8f0329b6cb749e02ccee5ce199e9e06096\",\"title\":\"CAD-Net: A Context-Aware Detection Network for Objects in Remote Sensing Imagery\",\"url\":\"https://www.semanticscholar.org/paper/69034a8f0329b6cb749e02ccee5ce199e9e06096\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2019},{\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.01045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3390891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb9fb10f604a196515e48ad90f217d33794f5991\",\"title\":\"Recurrent Attention Network with Reinforced Generator for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cb9fb10f604a196515e48ad90f217d33794f5991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35514628\",\"name\":\"Sanyi Zhang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"39389412\",\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TCSVT.2019.2902268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf71e9e41ccdf0fcf4c1809e94a1de920913bfff\",\"title\":\"Task-Aware Attention Model for Clothing Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cf71e9e41ccdf0fcf4c1809e94a1de920913bfff\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2002.10309\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"title\":\"Uncertainty based Class Activation Maps for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01fffd4fcd33d83602f7bc5a600ce87317e72763\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":5714907,\"doi\":\"10.1109/CVPR.2016.540\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":72,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"references\":[{\"arxivId\":\"1406.5472\",\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.21236/ada612444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfe448d6297ea0a3d4deba21fbf1006bc35877d7\",\"title\":\"Inferring the Why in Images\",\"url\":\"https://www.semanticscholar.org/paper/dfe448d6297ea0a3d4deba21fbf1006bc35877d7\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1409929082\",\"name\":\"Jordan L. Boyd-Graber\"},{\"authorId\":\"3357514\",\"name\":\"Leonardo Claudino\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":\"10.3115/v1/D14-1070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af44f5db5b4396e1670cda07eff5ad84145ba843\",\"title\":\"A Neural Network for Factoid Question Answering over Paragraphs\",\"url\":\"https://www.semanticscholar.org/paper/af44f5db5b4396e1670cda07eff5ad84145ba843\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1308.6628\",\"authors\":[{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"143764552\",\"name\":\"M. Meng\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"2194804\",\"name\":\"T. E. Choe\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/MMUL.2014.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2935d8071583e46c5a895730c65d2bd213757c07\",\"title\":\"Joint Video and Text Parsing for Understanding Events and Answering Queries\",\"url\":\"https://www.semanticscholar.org/paper/2935d8071583e46c5a895730c65d2bd213757c07\",\"venue\":\"IEEE MultiMedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143937776\",\"name\":\"R. Kuhn\"},{\"authorId\":\"103044842\",\"name\":\"\\u00c9. Neveu\"}],\"doi\":\"10.4324/9780203167564\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd2e54adcc7375cfecc5e783609be5da8f2cd563\",\"title\":\"Political Journalism: New Challenges, New Practices\",\"url\":\"https://www.semanticscholar.org/paper/cd2e54adcc7375cfecc5e783609be5da8f2cd563\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31533291\",\"name\":\"Frank Palermo\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-642-33783-3_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa78e6180549d72110a05e62420fd7037f2b2720\",\"title\":\"Dating Historical Color Images\",\"url\":\"https://www.semanticscholar.org/paper/fa78e6180549d72110a05e62420fd7037f2b2720\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2410191\",\"name\":\"L. Pickup\"},{\"authorId\":\"145683519\",\"name\":\"Z. Pan\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"34872975\",\"name\":\"Yi-Chang Shih\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2014.262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ad97ae1e861c21472a29dd2b7037e629f522d7d\",\"title\":\"Seeing the Arrow of Time\",\"url\":\"https://www.semanticscholar.org/paper/9ad97ae1e861c21472a29dd2b7037e629f522d7d\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"2925245\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1866029.1866080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"venue\":\"UIST '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Antol\"},{\"authorId\":null,\"name\":\"A Agrawal\"},{\"authorId\":null,\"name\":\"J Lu\"},{\"authorId\":null,\"name\":\"M Mitchell\"},{\"authorId\":null,\"name\":\"D Batra\"},{\"authorId\":null,\"name\":\"C L Zitnick\"},{\"authorId\":null,\"name\":\"D Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"VQA: Visual question answering. ICCV\",\"url\":\"\",\"venue\":\"VQA: Visual question answering. ICCV\",\"year\":2015},{\"arxivId\":\"1502.04623\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"title\":\"DRAW: A Recurrent Neural Network For Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Ramanathan\"},{\"authorId\":null,\"name\":\"A. Joulin\"},{\"authorId\":null,\"name\":\"P. Liang\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Linking people with \\u201dtheir\\u201d names using coreference resolution\",\"url\":\"\",\"venue\":\"In ECCV,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295799\",\"name\":\"D. Ferrucci\"},{\"authorId\":\"1793454\",\"name\":\"E. W. Brown\"},{\"authorId\":\"1684353\",\"name\":\"Jennifer Chu-Carroll\"},{\"authorId\":\"32653281\",\"name\":\"J. Fan\"},{\"authorId\":\"2771137\",\"name\":\"David Gondek\"},{\"authorId\":\"1973186\",\"name\":\"A. Kalyanpur\"},{\"authorId\":\"144071952\",\"name\":\"Adam Lally\"},{\"authorId\":\"145412011\",\"name\":\"J. William Murdock\"},{\"authorId\":\"144287919\",\"name\":\"Eric Nyberg\"},{\"authorId\":\"30210546\",\"name\":\"J. M. Prager\"},{\"authorId\":\"2807334\",\"name\":\"Nico Schlaefer\"},{\"authorId\":\"143778120\",\"name\":\"Chris Welty\"}],\"doi\":\"10.1609/AIMAG.V31I3.2303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec\",\"title\":\"Building Watson: An Overview of the DeepQA Project\",\"url\":\"https://www.semanticscholar.org/paper/3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec\",\"venue\":\"AI Mag.\",\"year\":2010},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772294\",\"name\":\"M. Kiapour\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.382\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cf785868dd412736f7008e2bdb51f62c173c292\",\"title\":\"Where to Buy It: Matching Street Clothing Photos in Online Shops\",\"url\":\"https://www.semanticscholar.org/paper/2cf785868dd412736f7008e2bdb51f62c173c292\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"50355189\",\"name\":\"Yin Cui\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2015.7299135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b26d4407cd9a479b87a1cf5c7ce3e197b63ad2f6\",\"title\":\"Learning deep representations for ground-to-aerial geolocalization\",\"url\":\"https://www.semanticscholar.org/paper/b26d4407cd9a479b87a1cf5c7ce3e197b63ad2f6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. W. Lee\"},{\"authorId\":null,\"name\":\"T. E. Choe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Szegedy . Deeppose : Human pose estimation via deep neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"4781463\",\"name\":\"Deniz Oktay\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.327\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03c48850373b40f32b2bc0b1fbf7c13ccf0c8063\",\"title\":\"Predicting Motivations of Actions by Leveraging Text\",\"url\":\"https://www.semanticscholar.org/paper/03c48850373b40f32b2bc0b1fbf7c13ccf0c8063\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2014.455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"title\":\"What Are You Talking About? Text-to-Image Coreference\",\"url\":\"https://www.semanticscholar.org/paper/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"},{\"authorId\":\"1748758\",\"name\":\"H. Nickisch\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPRW.2009.5206594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"title\":\"Learning to detect unseen object classes by between-class attribute transfer\",\"url\":\"https://www.semanticscholar.org/paper/0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145602732\",\"name\":\"Kobus Barnard\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"},{\"authorId\":\"1796335\",\"name\":\"D. Blei\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":\"10.1162/153244303322533214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e\",\"title\":\"Matching Words and Pictures\",\"url\":\"https://www.semanticscholar.org/paper/6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2003},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Szegedy . Deeppose : Human pose estimation via deep neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-10605-2_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea8fe33cc1596b2e493ddd87f22cd21f563664e8\",\"title\":\"Reasoning about Object Affordances in a Knowledge Base Representation\",\"url\":\"https://www.semanticscholar.org/paper/ea8fe33cc1596b2e493ddd87f22cd21f563664e8\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1312.4659\",\"authors\":[{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":\"10.1109/CVPR.2014.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"title\":\"DeepPose: Human Pose Estimation via Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.1109/ICCV.2013.211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"title\":\"Learning the Visual Interpretation of Sentences\",\"url\":\"https://www.semanticscholar.org/paper/6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50827772\",\"name\":\"G. Patterson\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2012.6247998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"add89dbbd15b82d8275d712f7f969f1b511f96fd\",\"title\":\"SUN attribute database: Discovering, annotating, and recognizing scene attributes\",\"url\":\"https://www.semanticscholar.org/paper/add89dbbd15b82d8275d712f7f969f1b511f96fd\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"Visual7W: Grounded Question Answering in Images\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Link relation\",\"topicId\":\"816617\",\"url\":\"https://www.semanticscholar.org/topic/816617\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Outline of object recognition\",\"topicId\":\"34569\",\"url\":\"https://www.semanticscholar.org/topic/34569\"},{\"topic\":\"Commonsense knowledge (artificial intelligence)\",\"topicId\":\"326287\",\"url\":\"https://www.semanticscholar.org/topic/326287\"},{\"topic\":\"Google Questions and Answers\",\"topicId\":\"2898125\",\"url\":\"https://www.semanticscholar.org/topic/2898125\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"OLGA (technology)\",\"topicId\":\"352116\",\"url\":\"https://www.semanticscholar.org/topic/352116\"},{\"topic\":\"Justin (robot)\",\"topicId\":\"65789\",\"url\":\"https://www.semanticscholar.org/topic/65789\"}],\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"