"{\"abstract\":\"We introduce the novel problem of automatically generating animated GIFs from video. GIFs are short looping video with no sound, and a perfect combination between image and video that really capture our attention. GIFs tell a story, express emotion, turn events into humorous moments, and are the new wave of photojournalism. We pose the question: Can we automate the entirely manual and elaborate process of GIF creation by leveraging the plethora of user generated GIF content? We propose a Robust Deep RankNet that, given a video, generates a ranked list of its segments according to their suitability as GIF. We train our model to learn what visual content is often selected for GIFs by using over 100K user generated GIFs and their corresponding video sources. We effectively deal with the noisy web data by proposing a novel adaptive Huber loss in the ranking formulation. We show that our approach is robust to outliers and picks up several patterns that are frequently present in popular animated GIFs. On our new large-scale benchmark dataset, we show the advantage of our approach over several state-of-the-art methods.\",\"arxivId\":\"1605.04850\",\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\",\"url\":\"https://www.semanticscholar.org/author/3037160\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\",\"url\":\"https://www.semanticscholar.org/author/2317183\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\",\"url\":\"https://www.semanticscholar.org/author/48749954\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"80491208\",\"name\":\"Vinay Rajpoot\"},{\"authorId\":\"2232488\",\"name\":\"S. Girase\"}],\"doi\":\"10.1109/ICECA.2018.8474699\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9bec3ecd6451b8c891bfbb85a3d39b3bda7ea14\",\"title\":\"A Study on Application Scenario of Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/c9bec3ecd6451b8c891bfbb85a3d39b3bda7ea14\",\"venue\":\"2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)\",\"year\":2018},{\"arxivId\":\"1904.12201\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"48379469\",\"name\":\"Yixuan Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICME.2019.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbdd08a1f2896f6f304cfa9befef2400f22e0f67\",\"title\":\"Human-Centered Emotion Recognition in Animated GIFs\",\"url\":\"https://www.semanticscholar.org/paper/cbdd08a1f2896f6f304cfa9befef2400f22e0f67\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101756846\",\"name\":\"Atip Nurharini\"},{\"authorId\":\"103446902\",\"name\":\"Sumilah\"},{\"authorId\":\"114166109\",\"name\":\"Yuyarti\"}],\"doi\":\"10.1109/ICET48172.2019.8987223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ec73ddf1a0d366747abfb25732a92c37ac49601\",\"title\":\"Animated Video Media: Motoric Skills In Dance Lesson\",\"url\":\"https://www.semanticscholar.org/paper/7ec73ddf1a0d366747abfb25732a92c37ac49601\",\"venue\":\"2019 5th International Conference on Education and Technology (ICET)\",\"year\":2019},{\"arxivId\":\"1804.06604\",\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.1145/3240508.3240599\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"916218b7fd637d75f644c5ef5f7590c05fabca75\",\"title\":\"PHD-GIFs: Personalized Highlight Detection for Automatic GIF Creation\",\"url\":\"https://www.semanticscholar.org/paper/916218b7fd637d75f644c5ef5f7590c05fabca75\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7779922\",\"name\":\"G. Erdogan\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75858f816a5abd01965df82127cc03304203ca7c\",\"title\":\"HUCVL at MediaEval 2016: Predicting Interesting Key Frames with Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/75858f816a5abd01965df82127cc03304203ca7c\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2733735\",\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22245219e3ccda4026f103e5112329703c3439f1\",\"title\":\"For Your Eyes Only: Learning to Summarize First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/22245219e3ccda4026f103e5112329703c3439f1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2f9b96c88d929b58d08cd2b2ec431555a018f8b\",\"title\":\"Contextually Customized Video Summaries Via Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/f2f9b96c88d929b58d08cd2b2ec431555a018f8b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.04318\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd286954bba554035ea98946afdd02262b9bca45\",\"title\":\"Cross-Modal Retrieval with Implicit Concept Association\",\"url\":\"https://www.semanticscholar.org/paper/cd286954bba554035ea98946afdd02262b9bca45\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000438408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53e77b526587b3c3bf7bb359590692a081b53260\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/53e77b526587b3c3bf7bb359590692a081b53260\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.11724\",\"authors\":[{\"authorId\":\"47767796\",\"name\":\"L. Wu\"},{\"authorId\":\"46285799\",\"name\":\"Y. Yang\"},{\"authorId\":\"3619088\",\"name\":\"Lei Chen\"},{\"authorId\":\"1862782\",\"name\":\"Defu Lian\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3397271.3401145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb473dc961acb1fccc85693ffa55791151cb0220\",\"title\":\"Learning to Transfer Graph Embeddings for Inductive Graph based Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/fb473dc961acb1fccc85693ffa55791151cb0220\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"1704.01466\",\"authors\":[{\"authorId\":\"10710354\",\"name\":\"Anurag Sahoo\"},{\"authorId\":\"3333118\",\"name\":\"Vishal Kaushal\"},{\"authorId\":\"40224337\",\"name\":\"Khoshrav Doctor\"},{\"authorId\":\"33911191\",\"name\":\"Suyash Shetty\"},{\"authorId\":\"145074006\",\"name\":\"R. Iyer\"},{\"authorId\":\"145799547\",\"name\":\"Ganesh Ramakrishnan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ef9046cc26946acedda3f515d9149a76e19cd6e\",\"title\":\"A Unified Multi-Faceted Video Summarization System\",\"url\":\"https://www.semanticscholar.org/paper/9ef9046cc26946acedda3f515d9149a76e19cd6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1703.02437\",\"authors\":[{\"authorId\":\"2414059\",\"name\":\"S. Manen\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICCV.2017.40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ae84b0adc5054db47814a5c475f732e6c1c9098\",\"title\":\"PathTrack: Fast Trajectory Annotation with Path Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6ae84b0adc5054db47814a5c475f732e6c1c9098\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1901.01153\",\"authors\":[{\"authorId\":\"3333118\",\"name\":\"Vishal Kaushal\"},{\"authorId\":\"145074006\",\"name\":\"R. Iyer\"},{\"authorId\":\"40224337\",\"name\":\"Khoshrav Doctor\"},{\"authorId\":\"10710354\",\"name\":\"Anurag Sahoo\"},{\"authorId\":\"46175439\",\"name\":\"P. Dubal\"},{\"authorId\":\"9745898\",\"name\":\"S. Kothawade\"},{\"authorId\":\"22549601\",\"name\":\"Rohan Mahadev\"},{\"authorId\":\"46208440\",\"name\":\"Kunal Dargan\"},{\"authorId\":\"145799547\",\"name\":\"Ganesh Ramakrishnan\"}],\"doi\":\"10.1109/WACV.2019.00054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ddb9dc22a78ca9c06c8982ecf0608a789b4122b\",\"title\":\"Demystifying Multi-Faceted Video Summarization: Tradeoff Between Diversity, Representation, Coverage and Importance\",\"url\":\"https://www.semanticscholar.org/paper/0ddb9dc22a78ca9c06c8982ecf0608a789b4122b\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":null,\"name\":\"Mohammad Soleymani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"890935379e6fc3a724d2ef5bb22775bdcfd0888b\",\"title\":\"Supplementary Material for Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/890935379e6fc3a724d2ef5bb22775bdcfd0888b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050705\",\"name\":\"J. Zhang\"},{\"authorId\":\"48081557\",\"name\":\"Yue Shi\"},{\"authorId\":\"2989256\",\"name\":\"Peiguang Jing\"},{\"authorId\":\"46701354\",\"name\":\"J. Liu\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1007/s11042-018-6841-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0719f1d9c42eed4ec7f4752dd6dfa9e933b1750\",\"title\":\"A structure-transfer-driven temporal subspace clustering for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/a0719f1d9c42eed4ec7f4752dd6dfa9e933b1750\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1702.01528\",\"authors\":[{\"authorId\":\"1751687\",\"name\":\"J. Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f28e2bb46e49799589787e466c3ca966a0897bf7\",\"title\":\"Textually Customized Video Summaries\",\"url\":\"https://www.semanticscholar.org/paper/f28e2bb46e49799589787e466c3ca966a0897bf7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47126776\",\"name\":\"E. Elhamifar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"497cb565caa9e9e12b8dedf55ad12e6680f505da\",\"title\":\"Summarization via Submodular and Convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/497cb565caa9e9e12b8dedf55ad12e6680f505da\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1609.09761\",\"authors\":[{\"authorId\":\"152714397\",\"name\":\"Mohammad Soleymani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab029fdee5a3097ce3bbce986f802103b622064d\",\"title\":\"Detecting Cognitive Appraisals from Facial Expressions for Interest Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab029fdee5a3097ce3bbce986f802103b622064d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1901.10713\",\"authors\":[{\"authorId\":\"1965545\",\"name\":\"Chih-Yuan Yang\"},{\"authorId\":\"66663648\",\"name\":\"Heeseung Yun\"},{\"authorId\":\"1717095\",\"name\":\"J. Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0d59dedba3b38c1c2d0fb997dc2fcf901c353d0\",\"title\":\"Video Summarization through Human Detection on a Social Robot\",\"url\":\"https://www.semanticscholar.org/paper/f0d59dedba3b38c1c2d0fb997dc2fcf901c353d0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1996351\",\"name\":\"Claire-H\\u00e9l\\u00e8ne Demarty\"},{\"authorId\":\"1766204\",\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":\"51244018\",\"name\":\"Mihai Gabriel Constantin\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1007/978-3-319-57687-9_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb1e82cf7005591a47e3174b59443e38feee9f35\",\"title\":\"Predicting Interestingness of Visual Content\",\"url\":\"https://www.semanticscholar.org/paper/bb1e82cf7005591a47e3174b59443e38feee9f35\",\"venue\":\"Visual Content Indexing and Retrieval with Psycho-Visual Models\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8442576\",\"name\":\"X. Zhang\"},{\"authorId\":\"1885338345\",\"name\":\"Yiyang Ou\"},{\"authorId\":\"1665956472\",\"name\":\"Siddhartha Sen\"},{\"authorId\":\"1727978\",\"name\":\"J. Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ce7178d23b560fac6eb26a499acfac31547db2f\",\"title\":\"SENSEI: Aligning Video Streaming Quality with Dynamic User Sensitivity\",\"url\":\"https://www.semanticscholar.org/paper/9ce7178d23b560fac6eb26a499acfac31547db2f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920099\",\"name\":\"S. Cai\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"36685537\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1007/978-3-030-01264-9_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"817a781e26c2eabb068973d3cc0bab9220fa401d\",\"title\":\"Weakly-Supervised Video Summarization Using Variational Encoder-Decoder and Web Prior\",\"url\":\"https://www.semanticscholar.org/paper/817a781e26c2eabb068973d3cc0bab9220fa401d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40396836\",\"name\":\"Ke Niu\"},{\"authorId\":null,\"name\":\"Han Wang\"}],\"doi\":\"10.1007/s11042-019-7442-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb011e242a4eb0b9b4e7c5fc3f84dbcb5197aafd\",\"title\":\"Video highlight extraction via content-aware deep transfer\",\"url\":\"https://www.semanticscholar.org/paper/fb011e242a4eb0b9b4e7c5fc3f84dbcb5197aafd\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1801.10312\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"35272603\",\"name\":\"Joonil Na\"},{\"authorId\":\"35365676\",\"name\":\"J. Kang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f14cdd95870baa38582f5d0022356cb241ea86f\",\"title\":\"A Deep Ranking Model for Spatio-Temporal Highlight Detection from a 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/9f14cdd95870baa38582f5d0022356cb241ea86f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40794636\",\"name\":\"Antti E. Ainasoja\"},{\"authorId\":\"15486133\",\"name\":\"Antti Hietanen\"},{\"authorId\":\"2451794\",\"name\":\"Jukka Lankinen\"},{\"authorId\":\"145196370\",\"name\":\"J. K\\u00e4m\\u00e4r\\u00e4inen\"}],\"doi\":\"10.5220/0006619202870296\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b8623ed0f268050e6b78a23542884038637639d\",\"title\":\"Keyframe-based Video Summarization with Human in the Loop\",\"url\":\"https://www.semanticscholar.org/paper/6b8623ed0f268050e6b78a23542884038637639d\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":\"1611.08780\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cead74e154c14913c2b73d5c7dba91dcd114726f\",\"title\":\"Real-Time Video Highlights for Yahoo Esports\",\"url\":\"https://www.semanticscholar.org/paper/cead74e154c14913c2b73d5c7dba91dcd114726f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.3929/ethz-b-000204633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ef504d7e5c94b9f9b8bfd3d1c44c6aa0d0515f2\",\"title\":\"Interest-Based Video Summarization via Subset Selection\",\"url\":\"https://www.semanticscholar.org/paper/8ef504d7e5c94b9f9b8bfd3d1c44c6aa0d0515f2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31868671\",\"name\":\"W. Chen\"},{\"authorId\":\"1729713\",\"name\":\"Ognjen Rudovic\"},{\"authorId\":\"1719389\",\"name\":\"Rosalind W. Picard\"}],\"doi\":\"10.1109/ACII.2017.8273647\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3dce3bb30f0c19121a71e0bfe1d418f855cb13ce\",\"title\":\"GIFGIF+: Collecting emotional animated GIFs with clustered multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/3dce3bb30f0c19121a71e0bfe1d418f855cb13ce\",\"venue\":\"2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation in Cities\",\"url\":\"https://www.semanticscholar.org/paper/392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144020384\",\"name\":\"Hoseong Kim\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"}],\"doi\":\"10.1109/TMM.2018.2806224\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f27eb66e4aec7fda25ffcbd3cdd0fb4b285c6f67\",\"title\":\"Exploiting Web Images for Video Highlight Detection With Triplet Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/f27eb66e4aec7fda25ffcbd3cdd0fb4b285c6f67\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024839\",\"name\":\"Yujie Li\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"},{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":\"10.1109/ICME.2017.8019352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf789e3770488c2690d1cca37366a79a5df99b0\",\"title\":\"Key frame extraction from first-person video with multi-sensor integration\",\"url\":\"https://www.semanticscholar.org/paper/aaf789e3770488c2690d1cca37366a79a5df99b0\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.06858\",\"authors\":[{\"authorId\":\"2340572\",\"name\":\"Haojian Jin\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"3260704\",\"name\":\"K. Yatani\"}],\"doi\":\"10.1145/3123266.3123393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78742a59b81a97efbdfaf093de81b1422c01a4be\",\"title\":\"ElasticPlay: Interactive Video Summarization with Dynamic Time Budgets\",\"url\":\"https://www.semanticscholar.org/paper/78742a59b81a97efbdfaf093de81b1422c01a4be\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799538\",\"name\":\"Costas Panagiotakis\"},{\"authorId\":\"2542688\",\"name\":\"H. Papadakis\"},{\"authorId\":\"3099265\",\"name\":\"P. Fragopoulou\"}],\"doi\":\"10.1007/978-3-030-45442-5_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91f345861ffc505dba0ff2d10d7b90967855ce3b\",\"title\":\"Personalized Video Summarization Based Exclusively on User Preferences\",\"url\":\"https://www.semanticscholar.org/paper/91f345861ffc505dba0ff2d10d7b90967855ce3b\",\"venue\":\"ECIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453353986\",\"name\":\"Kim EunYul\"},{\"authorId\":\"72372373\",\"name\":\"Gyemin Lee\"}],\"doi\":\"10.5909/JBE.2018.23.2.218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd8306527e5e08402555fa404abdc5570d268e40\",\"title\":\"Highlight Detection in Personal Broadcasting by Analysing Chat Traffic : Game Contests as a Test Case\",\"url\":\"https://www.semanticscholar.org/paper/cd8306527e5e08402555fa404abdc5570d268e40\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47126776\",\"name\":\"E. Elhamifar\"},{\"authorId\":\"144826656\",\"name\":\"M. Clara De Paolis Kaluza\"}],\"doi\":\"10.1109/CVPR.2017.197\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71d803b327652f2c9945fa35126b4dad3152289f\",\"title\":\"Online Summarization via Submodular and Convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/71d803b327652f2c9945fa35126b4dad3152289f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2007.09833\",\"authors\":[{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"1823519002\",\"name\":\"Xuanteng Huang\"},{\"authorId\":\"50135134\",\"name\":\"Weihong Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1007/978-3-030-58601-0_21\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"4079558004efd97ddb20ea160909f7fa97d689c2\",\"title\":\"MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection\",\"url\":\"https://www.semanticscholar.org/paper/4079558004efd97ddb20ea160909f7fa97d689c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1609.01388\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"2109913\",\"name\":\"Miriam Redi\"},{\"authorId\":\"2757535\",\"name\":\"Jordi Vallmitjana\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1145/2983323.2983349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"152cf1c319f17d7d66c3c38317f2c3488d33528b\",\"title\":\"To Click or Not To Click: Automatic Selection of Beautiful Thumbnails from Videos\",\"url\":\"https://www.semanticscholar.org/paper/152cf1c319f17d7d66c3c38317f2c3488d33528b\",\"venue\":\"CIKM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\"},{\"authorId\":\"143864954\",\"name\":\"Y. Cao\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1145/3197517.3201355\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f595e03f93640d25650b34b35c39156e42c1052\",\"title\":\"What characterizes personalities of graphic designs?\",\"url\":\"https://www.semanticscholar.org/paper/8f595e03f93640d25650b34b35c39156e42c1052\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58523-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b26d5d20b073828898087f99b81736c0629c1798\",\"title\":\"Learning Trailer Moments in Full-Length Movies with Co-Contrastive Attention\",\"url\":\"https://www.semanticscholar.org/paper/b26d5d20b073828898087f99b81736c0629c1798\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.04052\",\"authors\":[{\"authorId\":\"152338671\",\"name\":\"Yiitan Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350985\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"745242c746b6f379048f6dbdfc009181d9027a60\",\"title\":\"Sentence Specified Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/745242c746b6f379048f6dbdfc009181d9027a60\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2008.08502\",\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76e71fe84643b72ffb61afe54c9034be824604e3\",\"title\":\"Learning Trailer Moments in Full-Length Movies\",\"url\":\"https://www.semanticscholar.org/paper/76e71fe84643b72ffb61afe54c9034be824604e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47282782\",\"name\":\"D. Miki\"},{\"authorId\":\"98498116\",\"name\":\"S. Chen\"},{\"authorId\":\"2357866\",\"name\":\"K. Demachi\"}],\"doi\":\"10.1109/WACV45572.2020.9093551\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5625a113457bfba7a1ad242a808277cda9c160e0\",\"title\":\"Weakly Supervised Graph Convolutional Neural Network for Human Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/5625a113457bfba7a1ad242a808277cda9c160e0\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2008.13362\",\"authors\":[{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"1491322959\",\"name\":\"Mahesh Kumar Krishna Reddy\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8aa1bf7c6b1505538903c57472e5fa0ed45b303d\",\"title\":\"Sentence Guided Temporal Modulation for Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/8aa1bf7c6b1505538903c57472e5fa0ed45b303d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.04402\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/CVPR.2019.00208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a39d5919531a56de0e36f6b76142041b5d508213\",\"title\":\"Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"}],\"doi\":\"10.15781/T2QR4P68H\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"title\":\"Natural Language Video Description using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/191d4ba0825ff83afe91e94dafe27df8eb0202b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1705.00581\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1145/3123266.3123297\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48031e454325487b5fa7972280d1a2400bdef1d4\",\"title\":\"Query-adaptive Video Summarization via Quality-aware Relevance Estimation\",\"url\":\"https://www.semanticscholar.org/paper/48031e454325487b5fa7972280d1a2400bdef1d4\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1901.02840\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2019.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"title\":\"GIF2Video: Color Dequantization and Temporal Interpolation of GIF Images\",\"url\":\"https://www.semanticscholar.org/paper/75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1701.00599\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TMM.2017.2751969\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1da240dd35a4923b623b7bae66b1b7f074890852\",\"title\":\"AENet: Learning Deep Audio Features for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1da240dd35a4923b623b7bae66b1b7f074890852\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1708.02970\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"36400073\",\"name\":\"Kyungdon Joo\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/ICCV.2017.552\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4661d57e381bee9f9eda7c7a33592ad4e605f27c\",\"title\":\"Personalized Cinemagraphs Using Semantic Understanding and Collaborative Learning\",\"url\":\"https://www.semanticscholar.org/paper/4661d57e381bee9f9eda7c7a33592ad4e605f27c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8598253\",\"name\":\"Wang-Li Hao\"},{\"authorId\":\"1500387021\",\"name\":\"Ruixian Zhang\"},{\"authorId\":\"47319226\",\"name\":\"Shancang Li\"},{\"authorId\":\"1492111607\",\"name\":\"Junyu Li\"},{\"authorId\":\"49515557\",\"name\":\"F. Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"3103971\",\"name\":\"Wuping Zhang\"}],\"doi\":\"10.1155/2020/8876056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"title\":\"Anomaly Event Detection in Security Surveillance Using Two-Stream Based Model\",\"url\":\"https://www.semanticscholar.org/paper/d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0147ac7e824936ccedf547743c7b5c272fb2b8ac\",\"title\":\"ETH-CVL @ MediaEval 2016: Textual-Visual Embeddings and Video2GIF for Video Interestingness\",\"url\":\"https://www.semanticscholar.org/paper/0147ac7e824936ccedf547743c7b5c272fb2b8ac\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1145/2964284.2967195\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fbc97fa87acb767434b21d8d796caf3c3ed7f01\",\"title\":\"Analyzing and Predicting GIF Interestingness\",\"url\":\"https://www.semanticscholar.org/paper/9fbc97fa87acb767434b21d8d796caf3c3ed7f01\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1801.04264\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2018.00678\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"598fe25743f9492c5c1ba30274ea446f65426d85\",\"title\":\"Real-World Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/598fe25743f9492c5c1ba30274ea446f65426d85\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.08922\",\"authors\":[{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"350fc542f1a6a93b74d74aee14d83bed8782afcd\",\"title\":\"Summarizing First-Person Videos from Third Persons' Points of Views\",\"url\":\"https://www.semanticscholar.org/paper/350fc542f1a6a93b74d74aee14d83bed8782afcd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1903.00859\",\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00135\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"title\":\"Less Is More: Learning Highlight Detection From Video Duration\",\"url\":\"https://www.semanticscholar.org/paper/85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.02029\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-020-01374-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.02838\",\"authors\":[{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"41051080\",\"name\":\"Jinyoung Sung\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2018.00153\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e68c133947bbf14834f5353126ae85cc048642db\",\"title\":\"A Memory Network Approach for Story-Based Temporal Summarization of 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/e68c133947bbf14834f5353126ae85cc048642db\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"},{\"authorId\":\"37837552\",\"name\":\"M. Mortillaro\"}],\"doi\":\"10.3389/fict.2018.00017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b2b68a46dfd47444193f4f62cb95b628dc5c90f\",\"title\":\"Behavioral and Physiological Responses to Visual Interest and Appraisals: Multimodal Analysis and Automatic Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b2b68a46dfd47444193f4f62cb95b628dc5c90f\",\"venue\":\"Front. ICT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528629\",\"name\":\"H. Wang\"},{\"authorId\":\"52144028\",\"name\":\"Huangyue Yu\"},{\"authorId\":\"143685287\",\"name\":\"Pei Chen\"},{\"authorId\":\"144722239\",\"name\":\"Rui Hua\"},{\"authorId\":\"52195887\",\"name\":\"Chuyi Yan\"},{\"authorId\":\"143972418\",\"name\":\"L. Zou\"}],\"doi\":\"10.1109/ICPR.2018.8545808\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7071c41a024acb83cec869a2d9ae524965bf82c8\",\"title\":\"Unsupervised Video Highlight Extraction via Query-related Deep Transfer\",\"url\":\"https://www.semanticscholar.org/paper/7071c41a024acb83cec869a2d9ae524965bf82c8\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/TIP.2017.2666039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0696b633404183479bf57bc337de2e2121cf0a5e\",\"title\":\"Semantic Highlight Retrieval and Term Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0696b633404183479bf57bc337de2e2121cf0a5e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1910.06189\",\"authors\":[{\"authorId\":\"1739538\",\"name\":\"L. Wang\"},{\"authorId\":\"21072153\",\"name\":\"Zixun Sun\"},{\"authorId\":\"3315113\",\"name\":\"Wentao Yao\"},{\"authorId\":\"47940636\",\"name\":\"Hui Zhan\"},{\"authorId\":\"3252265\",\"name\":\"Chengwei Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d760fc5d63705bd33d33b759fe727149f8e47e67\",\"title\":\"Unsupervised Multi-stream Highlight detection for the Game \\\"Honor of Kings\\\"\",\"url\":\"https://www.semanticscholar.org/paper/d760fc5d63705bd33d33b759fe727149f8e47e67\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2097156\",\"name\":\"M. Fei\"},{\"authorId\":\"152889332\",\"name\":\"Wei Jiang\"},{\"authorId\":\"39721136\",\"name\":\"Weijie Mao\"}],\"doi\":\"10.1016/J.ESWA.2020.114036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef76b3d6c7095c6e86eeb2d3a574c42859a7d406\",\"title\":\"Learning user interest with improved triplet deep ranking and web-image priors for topic-related video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ef76b3d6c7095c6e86eeb2d3a574c42859a7d406\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143972418\",\"name\":\"L. Zou\"},{\"authorId\":null,\"name\":\"Han Wang\"},{\"authorId\":\"143685287\",\"name\":\"Pei Chen\"},{\"authorId\":\"145923855\",\"name\":\"Bo Wei\"}],\"doi\":\"10.1007/978-3-030-04946-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d99571d37f519666d572f4f17447c82d7ef25a86\",\"title\":\"A Method of Film Clips Retrieval Using Image Queries Based on User Interests\",\"url\":\"https://www.semanticscholar.org/paper/d99571d37f519666d572f4f17447c82d7ef25a86\",\"venue\":\"Cognitive Internet of Things\",\"year\":2019},{\"arxivId\":\"1809.08846\",\"authors\":[{\"authorId\":\"145074006\",\"name\":\"R. Iyer\"},{\"authorId\":\"46175439\",\"name\":\"P. Dubal\"},{\"authorId\":\"46208440\",\"name\":\"Kunal Dargan\"},{\"authorId\":\"9745898\",\"name\":\"S. Kothawade\"},{\"authorId\":\"22549601\",\"name\":\"Rohan Mahadev\"},{\"authorId\":\"3333118\",\"name\":\"Vishal Kaushal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bf209be1e61531bc0b8c6e618af6e9591e4431f\",\"title\":\"Vis-DSS: An Open-Source toolkit for Visual Data Selection and Summarization\",\"url\":\"https://www.semanticscholar.org/paper/6bf209be1e61531bc0b8c6e618af6e9591e4431f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2007.09598\",\"authors\":[{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"1491322959\",\"name\":\"Mahesh Kumar Krishna Reddy\"},{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1007/978-3-030-58589-1_16\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d402204bd400df352c733ea232708d50d59b3be4\",\"title\":\"Adaptive Video Highlight Detection by Learning from User History\",\"url\":\"https://www.semanticscholar.org/paper/d402204bd400df352c733ea232708d50d59b3be4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.12948\",\"authors\":[{\"authorId\":\"1405222115\",\"name\":\"K. VivekrajV.\"},{\"authorId\":\"144789994\",\"name\":\"D. Sen\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3347712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"title\":\"Video Skimming\",\"url\":\"https://www.semanticscholar.org/paper/8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019}],\"corpusId\":10268887,\"doi\":\"10.1109/CVPR.2016.114\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":11,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"28f0e0d3783659bc9adb2cec56f19b1f90cdd2be\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995467\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53e74f8319dea6561ca110d8e22c20283a9bea28\",\"title\":\"High level describable attributes for predicting aesthetics and interestingness\",\"url\":\"https://www.semanticscholar.org/paper/53e74f8319dea6561ca110d8e22c20283a9bea28\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680188\",\"name\":\"T. Joachims\"}],\"doi\":\"10.1145/775047.775067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfd4259d305a00f13d5f08841230389f61322422\",\"title\":\"Optimizing search engines using clickthrough data\",\"url\":\"https://www.semanticscholar.org/paper/cfd4259d305a00f13d5f08841230389f61322422\",\"venue\":\"KDD '02\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00016-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"title\":\"P\",\"url\":\"https://www.semanticscholar.org/paper/db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47080432\",\"name\":\"C. Zauner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"635e1b5261ad1545aab7acde48efa267ae428fc3\",\"title\":\"Implementation and Benchmarking of Perceptual Image Hash Functions\",\"url\":\"https://www.semanticscholar.org/paper/635e1b5261ad1545aab7acde48efa267ae428fc3\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265058\",\"name\":\"J. Oh\"}],\"doi\":\"10.1007/978-0-387-39940-9_3930\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a83503e3b4bb789a77ca122636fd0536a5740160\",\"title\":\"Video Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/a83503e3b4bb789a77ca122636fd0536a5740160\",\"venue\":\"Encyclopedia of Database Systems\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681887\",\"name\":\"D. Rumelhart\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1038/323533a0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"052b1d8ce63b07fec3de9dbb583772d860b7c769\",\"title\":\"Learning representations by back-propagating errors\",\"url\":\"https://www.semanticscholar.org/paper/052b1d8ce63b07fec3de9dbb583772d860b7c769\",\"venue\":\"Nature\",\"year\":1986},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70510241\",\"name\":\"Frederick R. Forst\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c87d57da3b1f2b467ef4995d30df832ee2281107\",\"title\":\"On robust estimation of the location parameter\",\"url\":\"https://www.semanticscholar.org/paper/c87d57da3b1f2b467ef4995d30df832ee2281107\",\"venue\":\"\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2015.7298928\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"title\":\"Video summarization by learning submodular mixtures of objectives\",\"url\":\"https://www.semanticscholar.org/paper/cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143979267\",\"name\":\"R. Hamid\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"},{\"authorId\":\"145507437\",\"name\":\"N. Sundaresan\"}],\"doi\":\"10.1109/CVPR.2013.348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4b1fd34dabc3bc37aad39279bae9fa06b4a9dac\",\"title\":\"Large-Scale Video Summarization Using Web-Image Priors\",\"url\":\"https://www.semanticscholar.org/paper/e4b1fd34dabc3bc37aad39279bae9fa06b4a9dac\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2955704\",\"name\":\"B. T. Truong\"},{\"authorId\":\"49337894\",\"name\":\"S. Venkatesh\"}],\"doi\":\"10.1145/1198302.1198305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37e084cdf8b8704b497b2d8e7547380c09468c7b\",\"title\":\"Video abstraction: A systematic review and classification\",\"url\":\"https://www.semanticscholar.org/paper/37e084cdf8b8704b497b2d8e7547380c09468c7b\",\"venue\":\"TOMCCAP\",\"year\":2007},{\"arxivId\":\"1312.4894\",\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"145266091\",\"name\":\"Thomas Leung\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b049d8cfea6c3bed377090e0e7fa677d282a361\",\"title\":\"Deep Convolutional Ranking for Multilabel Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/3b049d8cfea6c3bed377090e0e7fa677d282a361\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648354\",\"name\":\"Ching-Pei Lee\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"}],\"doi\":\"10.1162/NECO_a_00571\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccdf6ff1d27d20bb478e302e0f2689d8a71d3c2a\",\"title\":\"Large-Scale Linear RankSVM\",\"url\":\"https://www.semanticscholar.org/paper/ccdf6ff1d27d20bb478e302e0f2689d8a71d3c2a\",\"venue\":\"Neural Computation\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Jiang\"},{\"authorId\":null,\"name\":\"Y Wang\"},{\"authorId\":null,\"name\":\"R Feng\"},{\"authorId\":null,\"name\":\"X Xue\"},{\"authorId\":null,\"name\":\"Y Zheng\"},{\"authorId\":null,\"name\":\"H Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Understanding and Predicting Interestingness of Videos. AAAI\",\"url\":\"\",\"venue\":\"Understanding and Predicting Interestingness of Videos. AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"2055335\",\"name\":\"Fabian Nater\"},{\"authorId\":\"2437544\",\"name\":\"M. Druey\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1145/2502081.2502109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e04526b0ce5a2c9114418269909f18256e6bdd3e\",\"title\":\"Visual interestingness in image sequences\",\"url\":\"https://www.semanticscholar.org/paper/e04526b0ce5a2c9114418269909f18256e6bdd3e\",\"venue\":\"MM '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40490812\",\"name\":\"R. Datta\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"40116905\",\"name\":\"Jia Li\"},{\"authorId\":\"48094094\",\"name\":\"James Ze Wang\"}],\"doi\":\"10.1007/11744078_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8772877ceb40d6d8685655145034740f3df7baad\",\"title\":\"Studying Aesthetics in Photographic Images Using a Computational Approach\",\"url\":\"https://www.semanticscholar.org/paper/8772877ceb40d6d8685655145034740f3df7baad\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1504.03410\",\"authors\":[{\"authorId\":\"2356867\",\"name\":\"Hanjiang Lai\"},{\"authorId\":\"145829235\",\"name\":\"Y. Pan\"},{\"authorId\":\"49420392\",\"name\":\"Y. Liu\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/CVPR.2015.7298947\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73543e2f04bc496930e5d5e9790559d4510e7596\",\"title\":\"Simultaneous feature learning and hash coding with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/73543e2f04bc496930e5d5e9790559d4510e7596\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-10584-0_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"title\":\"Creating Summaries from User Videos\",\"url\":\"https://www.semanticscholar.org/paper/799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"3038150\",\"name\":\"Cherry Che\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2015.7298994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"title\":\"Multi-task deep visual-semantic embedding for video thumbnail selection\",\"url\":\"https://www.semanticscholar.org/paper/562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1719780\",\"name\":\"Yan Ke\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"144745185\",\"name\":\"Feng Jing\"}],\"doi\":\"10.1109/CVPR.2006.303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6989f866a445bb880ed8663a05dc4cd71c87b1b7\",\"title\":\"The Design of High-Level Features for Photo Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/6989f866a445bb880ed8663a05dc4cd71c87b1b7\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":\"1501.06272\",\"authors\":[{\"authorId\":\"145246817\",\"name\":\"F. Zhao\"},{\"authorId\":\"145501833\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/CVPR.2015.7298763\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b48c2bccc3ae0d4fc0839ac0ffdc8eefa100ac7c\",\"title\":\"Deep semantic ranking based hashing for multi-label image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b48c2bccc3ae0d4fc0839ac0ffdc8eefa100ac7c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"title\":\"Unsupervised Learning of Visual Representations using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"title\":\"Diverse Sequential Subset Selection for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1212.0901\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1395619597\",\"name\":\"Nicolas Boulanger-Lewandowski\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"}],\"doi\":\"10.1109/ICASSP.2013.6639349\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ded103d0613e1a8f51f586cc1678aee3ff26e811\",\"title\":\"Advances in optimizing recurrent networks\",\"url\":\"https://www.semanticscholar.org/paper/ded103d0613e1a8f51f586cc1678aee3ff26e811\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":\"1510.01442\",\"authors\":[{\"authorId\":\"46402216\",\"name\":\"Huan Yang\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2242717\",\"name\":\"D. Wipf\"},{\"authorId\":\"1697293\",\"name\":\"M. Guo\"},{\"authorId\":\"143632999\",\"name\":\"B. Guo\"}],\"doi\":\"10.1109/ICCV.2015.526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faafe2a76dbb9a5a1468b1a02b1f0f09ced8587e\",\"title\":\"Unsupervised Extraction of Video Highlights via Robust Recurrent Auto-Encoders\",\"url\":\"https://www.semanticscholar.org/paper/faafe2a76dbb9a5a1468b1a02b1f0f09ced8587e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1404.4661\",\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"145266091\",\"name\":\"Thomas Leung\"},{\"authorId\":\"17027818\",\"name\":\"C. Rosenberg\"},{\"authorId\":\"120465907\",\"name\":\"J. Wang\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2014.180\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6df192c9b654bc5cc371c55012cf99d85cb61df\",\"title\":\"Learning Fine-Grained Image Similarity with Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/e6df192c9b654bc5cc371c55012cf99d85cb61df\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"2055335\",\"name\":\"Fabian Nater\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICCV.2013.205\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbec6f6e3c1493a403e8b66134977e0c93743733\",\"title\":\"The Interestingness of Images\",\"url\":\"https://www.semanticscholar.org/paper/cbec6f6e3c1493a403e8b66134977e0c93743733\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2618874\",\"name\":\"Michael Heilman\"},{\"authorId\":\"123527342\",\"name\":\"J. Kelly\"},{\"authorId\":\"48561735\",\"name\":\"Martin Thoma\"},{\"authorId\":\"4565995\",\"name\":\"K. Rasul\"},{\"authorId\":\"5697774\",\"name\":\"Eric Battenberg\"},{\"authorId\":\"1403986113\",\"name\":\"Hendrik Weideman\"},{\"authorId\":\"1388358166\",\"name\":\"S\\u00f8ren Kaae S\\u00f8nderby\"},{\"authorId\":\"1403986095\",\"name\":\"instagibbs\"},{\"authorId\":\"1403986098\",\"name\":\"Britefury\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"3110620\",\"name\":\"J. Degrave\"},{\"authorId\":\"1403986089\",\"name\":\"peterderivaz\"},{\"authorId\":\"30158197\",\"name\":\"Jon\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"70015865\",\"name\":\"Diogo\"},{\"authorId\":\"51235216\",\"name\":\"Daniel Nouri\"},{\"authorId\":\"1382154289\",\"name\":\"Jan Schl\\u00fcter\"},{\"authorId\":\"50231436\",\"name\":\"Daniel Maturana\"},{\"authorId\":\"70092325\",\"name\":\"CongLiu\"},{\"authorId\":\"47701834\",\"name\":\"Eben M. Olson\"},{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"1403986057\",\"name\":\"takacsg\"}],\"doi\":\"10.5281/ZENODO.27878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ef5e2fa01f1b3b512786bf9f8e2c98f7557f4f9\",\"title\":\"Lasagne: First release.\",\"url\":\"https://www.semanticscholar.org/paper/5ef5e2fa01f1b3b512786bf9f8e2c98f7557f4f9\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39554008\",\"name\":\"Saeideh Bakhshi\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"144557123\",\"name\":\"L. Kennedy\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1893882\",\"name\":\"Paloma de Juan\"},{\"authorId\":\"143782217\",\"name\":\"J. Kaye\"}],\"doi\":\"10.1145/2858036.2858532\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"345413ede3e5743645d95140e74a73a86a96d7f8\",\"title\":\"Fast, Cheap, and Good: Why Animated GIFs Engage Us\",\"url\":\"https://www.semanticscholar.org/paper/345413ede3e5743645d95140e74a73a86a96d7f8\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"2637241\",\"name\":\"Yanran Wang\"},{\"authorId\":\"145951245\",\"name\":\"R. Feng\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":\"3035364\",\"name\":\"Hanfang Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"472500bb0fc49354445b25f851905dda621a42d0\",\"title\":\"Understanding and Predicting Interestingness of Videos\",\"url\":\"https://www.semanticscholar.org/paper/472500bb0fc49354445b25f851905dda621a42d0\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1760870\",\"name\":\"Y. Lin\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/ICCVW.2015.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"806d9616e10020f069e604c4c828ae992b694c7d\",\"title\":\"Summarizing While Recording: Context-Based Highlight Detection for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/806d9616e10020f069e604c4c828ae992b694c7d\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/CVPR.2014.538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2743180fa8b87b313f32a3ad37e9771da2234a1\",\"title\":\"Joint Summarization of Large-Scale Collections of Web Images and Videos for Storyline Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/e2743180fa8b87b313f32a3ad37e9771da2234a1\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M Redi\"},{\"authorId\":null,\"name\":\"N O Hare\"},{\"authorId\":null,\"name\":\"R Schifanella\"},{\"authorId\":null,\"name\":\"M Trevisiol\"},{\"authorId\":null,\"name\":\"A Jaimes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Seconds of Sound and Vision : Creativity in Micro-Videos. CVPR\",\"url\":\"\",\"venue\":\"Seconds of Sound and Vision : Creativity in Micro-Videos. CVPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H Grabner\"},{\"authorId\":null,\"name\":\"F Nater\"},{\"authorId\":null,\"name\":\"L Van\"},{\"authorId\":null,\"name\":\"Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visual Interestingness in Image Sequences. ACM MM\",\"url\":\"\",\"venue\":\"Visual Interestingness in Image Sequences. ACM MM\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Bergstra\"},{\"authorId\":null,\"name\":\"O Breuleux\"},{\"authorId\":null,\"name\":\"F Bastien\"},{\"authorId\":null,\"name\":\"P Lamblin\"},{\"authorId\":null,\"name\":\"R Pascanu\"},{\"authorId\":null,\"name\":\"G Desjardins\"},{\"authorId\":null,\"name\":\"J Turian\"},{\"authorId\":null,\"name\":\"D Warde-Farley\"},{\"authorId\":null,\"name\":\"Y Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Theano: a CPU and GPU math expression compiler\",\"url\":\"\",\"venue\":\"Proceedings of SciPy\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-319-10590-1_51\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c7adde982efb24c3786fa2d1f65f40a64e2afbf\",\"title\":\"Ranking Domain-Specific Highlights by Analyzing Edited Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c7adde982efb24c3786fa2d1f65f40a64e2afbf\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"2757535\",\"name\":\"Jordi Vallmitjana\"},{\"authorId\":\"1690152\",\"name\":\"Amanda Stent\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1109/CVPR.2015.7299154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"title\":\"TVSum: Summarizing web videos using titles\",\"url\":\"https://www.semanticscholar.org/paper/cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10599-4_35\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"title\":\"Category-Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M Gygli\"},{\"authorId\":null,\"name\":\"H Grabner\"},{\"authorId\":null,\"name\":\"H Riemenschneider\"},{\"authorId\":null,\"name\":\"F Nater\"},{\"authorId\":null,\"name\":\"L Van Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The Interestingness Of Images. ICCV\",\"url\":\"\",\"venue\":\"The Interestingness Of Images. ICCV\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"}],\"doi\":\"10.1007/978-3-319-10605-2_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b0a7d26ee7c2cc5cad25d47c21da72c6e7d036\",\"title\":\"Interestingness Prediction by Robust Learning to Rank\",\"url\":\"https://www.semanticscholar.org/paper/54b0a7d26ee7c2cc5cad25d47c21da72c6e7d036\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.4080\",\"authors\":[{\"authorId\":\"2109913\",\"name\":\"Miriam Redi\"},{\"authorId\":\"1401255262\",\"name\":\"N. O'Hare\"},{\"authorId\":\"2251027\",\"name\":\"R. Schifanella\"},{\"authorId\":\"2203900\",\"name\":\"Michele Trevisiol\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1109/CVPR.2014.544\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36aa1a04aab6780cf8c4f9b03855c45b9c5d9c29\",\"title\":\"6 Seconds of Sound and Vision: Creativity in Micro-videos\",\"url\":\"https://www.semanticscholar.org/paper/36aa1a04aab6780cf8c4f9b03855c45b9c5d9c29\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014}],\"title\":\"Video2GIF: Automatic Generation of Animated GIFs from Video\",\"topics\":[{\"topic\":\"GIF\",\"topicId\":\"84786\",\"url\":\"https://www.semanticscholar.org/topic/84786\"},{\"topic\":\"Computer animation\",\"topicId\":\"102448\",\"url\":\"https://www.semanticscholar.org/topic/102448\"},{\"topic\":\"Huber loss\",\"topicId\":\"45062\",\"url\":\"https://www.semanticscholar.org/topic/45062\"},{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"}],\"url\":\"https://www.semanticscholar.org/paper/28f0e0d3783659bc9adb2cec56f19b1f90cdd2be\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"