"{\"abstract\":\"Automatically generating a natural language description of an image has attracted interests recently both because of its importance in practical applications and because it connects two major artificial intelligence fields: computer vision and natural language processing. Existing approaches are either top-down, which start from a gist of an image and convert it into words, or bottom-up, which come up with words describing various aspects of an image and then combine them. In this paper, we propose a new algorithm that combines both approaches through a model of semantic attention. Our algorithm learns to selectively attend to semantic concept proposals and fuse them into hidden states and outputs of recurrent neural networks. The selection and fusion form a feedback connecting the top-down and bottom-up computation. We evaluate our algorithm on two public benchmarks: Microsoft COCO and Flickr30K. Experimental results show that our algorithm significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics.\",\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\",\"url\":\"https://www.semanticscholar.org/author/36610242\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\",\"url\":\"https://www.semanticscholar.org/author/41151701\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\",\"url\":\"https://www.semanticscholar.org/author/8056043\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\",\"url\":\"https://www.semanticscholar.org/author/144823841\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"}],\"citationVelocity\":256,\"citations\":[{\"arxivId\":\"1909.05003\",\"authors\":[{\"authorId\":\"1388070721\",\"name\":\"Alexander Makrigiorgos\"},{\"authorId\":\"2216790\",\"name\":\"A. Shafti\"},{\"authorId\":\"46178426\",\"name\":\"Alex Harston\"},{\"authorId\":\"35619011\",\"name\":\"Julien G\\u00e9rard\"},{\"authorId\":\"144683767\",\"name\":\"A. Faisal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ff88fd6991de2dd9a9254548ccddbd894da5336\",\"title\":\"Human Visual Attention Prediction Boosts Learning & Performance of Autonomous Driving Agents\",\"url\":\"https://www.semanticscholar.org/paper/3ff88fd6991de2dd9a9254548ccddbd894da5336\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.08070\",\"authors\":[{\"authorId\":\"51163002\",\"name\":\"Alasdair Tran\"},{\"authorId\":\"46953477\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"}],\"doi\":\"10.1109/CVPR42600.2020.01305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"title\":\"Transform and Tell: Entity-Aware News Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3123266.3123391\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"39836fbbcd2a664edb31119e88870c38b83df352\",\"title\":\"Adaptively Attending to Visual Attributes and Linguistic Knowledge for Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39836fbbcd2a664edb31119e88870c38b83df352\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2012.12109\",\"authors\":[{\"authorId\":\"2904307\",\"name\":\"Menghan Xia\"},{\"authorId\":\"50350340\",\"name\":\"Tien-Tsin Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"482320e7b777133a34952ccde19d91337d071544\",\"title\":\"Noise-Equipped Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/482320e7b777133a34952ccde19d91337d071544\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.06972\",\"authors\":[{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1109/CVPR.2017.780\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1de837d76d6513aa664f2d032d49ef12c938bbbb\",\"title\":\"Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/1de837d76d6513aa664f2d032d49ef12c938bbbb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686788\",\"name\":\"R. Miikkulainen\"},{\"authorId\":\"9560397\",\"name\":\"J. Liang\"},{\"authorId\":\"2978740\",\"name\":\"Elliot Meyerson\"},{\"authorId\":\"33365929\",\"name\":\"A. Rawal\"},{\"authorId\":\"2038570172\",\"name\":\"E. FinkDaniel\"},{\"authorId\":\"9965138\",\"name\":\"Olivier Francon\"},{\"authorId\":\"39806498\",\"name\":\"B. Raju\"},{\"authorId\":\"2481407\",\"name\":\"Hormoz Shahrzad\"},{\"authorId\":\"1632432987\",\"name\":\"Arshak Navruzyan\"},{\"authorId\":\"143857271\",\"name\":\"Nigel Duffy\"},{\"authorId\":\"3024670\",\"name\":\"B. Hodjat\"}],\"doi\":\"10.1016/B978-0-12-815480-9.00015-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd7c02cab3ec4e59150657bd6660eab97def9a3a\",\"title\":\"Evolving Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cd7c02cab3ec4e59150657bd6660eab97def9a3a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1109/CVPRW.2018.00260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2bd5fceb1f885f690f63a58c289607c85069be3d\",\"title\":\"Image Caption Generation with Hierarchical Contextual Visual Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bd5fceb1f885f690f63a58c289607c85069be3d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292515\",\"name\":\"Z. Liu\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":null,\"name\":\"Chen Shen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"}],\"doi\":\"10.1007/978-3-319-97304-3_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe3af3e0e06c1d0adf5173adea06c268692be10d\",\"title\":\"Topic-Guided Automatical Human-Simulated Tweeting System\",\"url\":\"https://www.semanticscholar.org/paper/fe3af3e0e06c1d0adf5173adea06c268692be10d\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":\"1909.03169\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"67001969\",\"name\":\"Mahmoud Elsayed\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7af5c94fedc32f3104a08301a46c62f51b044a81\",\"title\":\"Look and Modify: Modification Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7af5c94fedc32f3104a08301a46c62f51b044a81\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/ICCV.2019.00434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"title\":\"Generating Diverse and Descriptive Image Captions Using Visual Paraphrases\",\"url\":\"https://www.semanticscholar.org/paper/b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38091504\",\"name\":\"Yuele Zhang\"},{\"authorId\":\"48605138\",\"name\":\"Jie Michael Guo\"},{\"authorId\":\"4126481\",\"name\":\"Zheng Huang\"},{\"authorId\":\"47846658\",\"name\":\"Weidong Qiu\"},{\"authorId\":\"121491325\",\"name\":\"Hexiaohui Fan\"}],\"doi\":\"10.1051/MATECCONF/201927702025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f483ddc9a640220f89d8a7327382e9d6e86da33d\",\"title\":\"Multi-layer attention for person re-identification\",\"url\":\"https://www.semanticscholar.org/paper/f483ddc9a640220f89d8a7327382e9d6e86da33d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.07770\",\"authors\":[{\"authorId\":\"47482125\",\"name\":\"E. Nowara\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"93554569\",\"name\":\"A. Veeraraghavan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6c00cd9b39e435775519033d737d82c5ad6dfad\",\"title\":\"The Benefit of Distraction: Denoising Remote Vitals Measurements using Inverse Attention\",\"url\":\"https://www.semanticscholar.org/paper/c6c00cd9b39e435775519033d737d82c5ad6dfad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144454693\",\"name\":\"Pei Li\"},{\"authorId\":\"26659900\",\"name\":\"Xinde Li\"},{\"authorId\":\"102266003\",\"name\":\"H. Pan\"},{\"authorId\":\"51071590\",\"name\":\"M. O. Khyam\"},{\"authorId\":\"1398730731\",\"name\":\"Md. Noor-A.-Rahim\"}],\"doi\":\"10.1016/j.neucom.2019.02.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff64b129c42442e08aed3138bdd67afabd7b59b3\",\"title\":\"Text-based indoor place recognition with deep neural network\",\"url\":\"https://www.semanticscholar.org/paper/ff64b129c42442e08aed3138bdd67afabd7b59b3\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.11832\",\"authors\":[{\"authorId\":\"3450321\",\"name\":\"Binghui Chen\"},{\"authorId\":\"1774956\",\"name\":\"W. Deng\"}],\"doi\":\"10.1109/CVPR.2019.00286\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd58ca00535abbeab012c27128c459ad875db95f\",\"title\":\"Hybrid-Attention Based Decoupled Metric Learning for Zero-Shot Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/fd58ca00535abbeab012c27128c459ad875db95f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39210448\",\"name\":\"Syed Haseeb\"},{\"authorId\":\"150235080\",\"name\":\"M. SrushtiG\"},{\"authorId\":\"150042973\",\"name\":\"B. Haripriya\"},{\"authorId\":\"144516989\",\"name\":\"M. Prakash\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b091b2211da71b515b013477d4961848e3988b64\",\"title\":\"Image Captioning using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/b091b2211da71b515b013477d4961848e3988b64\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"2598444\",\"name\":\"Chengjun Zhang\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3319921.3319934\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1da9da475a471eacdb47a7f71d81cc3517188054\",\"title\":\"Reconstructing Attention with Dynamic Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1da9da475a471eacdb47a7f71d81cc3517188054\",\"venue\":\"ICIAI 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051436\",\"name\":\"Jianxin Zhang\"},{\"authorId\":\"48093480\",\"name\":\"Junyou Wang\"},{\"authorId\":\"27097994\",\"name\":\"Qiule Sun\"},{\"authorId\":\"2441706\",\"name\":\"Cunhua Li\"},{\"authorId\":\"50678046\",\"name\":\"B. Liu\"},{\"authorId\":\"48327323\",\"name\":\"Qiang Zhang\"},{\"authorId\":\"1706625\",\"name\":\"X. Wei\"}],\"doi\":\"10.1109/ACCESS.2019.2936446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c77c9df0d947e328edbc094e43460723c6a730e\",\"title\":\"Second-Order Response Transform Attention Network for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/7c77c9df0d947e328edbc094e43460723c6a730e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97667801\",\"name\":\"Matthew John Marter\"}],\"doi\":\"10.15126/THESIS.00850052\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0f45a806a38bf38511a9f2fd774d7a18d0fc3b3\",\"title\":\"Learning to recognise visual content from textual annotation\",\"url\":\"https://www.semanticscholar.org/paper/a0f45a806a38bf38511a9f2fd774d7a18d0fc3b3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1478822269\",\"name\":\"Jian Ke\"},{\"authorId\":\"46372566\",\"name\":\"Jianbo Xu\"},{\"authorId\":\"144164185\",\"name\":\"Xiangwei Meng\"},{\"authorId\":\"2031492283\",\"name\":\"Qixiong Huang\"}],\"doi\":\"10.1109/ICDSBA48748.2019.00020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"709503d5fa9c418eb30428efcbf8731bbabe3771\",\"title\":\"Hybrid Collaborative Filtering with Attention CNN for Web Service Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/709503d5fa9c418eb30428efcbf8731bbabe3771\",\"venue\":\"2019 3rd International Conference on Data Science and Business Analytics (ICDSBA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144951859\",\"name\":\"O. Scharenborg\"},{\"authorId\":\"2167829\",\"name\":\"Lucas Ondel\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"144332819\",\"name\":\"Philip Arthur\"},{\"authorId\":\"35426982\",\"name\":\"Francesco Ciannella\"},{\"authorId\":\"33868757\",\"name\":\"Mingxing Du\"},{\"authorId\":\"40651102\",\"name\":\"Elin Larsen\"},{\"authorId\":\"35833790\",\"name\":\"Danny Merkx\"},{\"authorId\":\"40425637\",\"name\":\"Rachid Riad\"},{\"authorId\":\"51471760\",\"name\":\"L. Wang\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"1693321\",\"name\":\"S. St\\u00fcker\"},{\"authorId\":\"47267872\",\"name\":\"P. Godard\"},{\"authorId\":\"152250250\",\"name\":\"M. M\\u00fcller\"}],\"doi\":\"10.1109/TASLP.2020.2973896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec6499842d3e51b7dda94f5d0620d6df5c1a1b6d\",\"title\":\"Speech Technology for Unwritten Languages\",\"url\":\"https://www.semanticscholar.org/paper/ec6499842d3e51b7dda94f5d0620d6df5c1a1b6d\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144276007\",\"name\":\"C. J. Wang\"},{\"authorId\":\"65804087\",\"name\":\"C. A. Hamm\"},{\"authorId\":\"4364779\",\"name\":\"B. Letzen\"},{\"authorId\":\"145947161\",\"name\":\"J. Duncan\"}],\"doi\":\"10.1117/12.2512473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd822f59526448bc28ee2c9639aa7bff266a5f1d\",\"title\":\"A probabilistic approach for interpretable deep learning in liver cancer diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/fd822f59526448bc28ee2c9639aa7bff266a5f1d\",\"venue\":\"Medical Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"title\":\"Think and Tell: Preview Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39771170\",\"name\":\"Andeep S. Toor\"},{\"authorId\":\"143979395\",\"name\":\"H. Wechsler\"},{\"authorId\":\"144759484\",\"name\":\"M. Nappi\"}],\"doi\":\"10.1007/s11042-018-6097-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bddf7da5a21a5d1915cc9ee784223adadbe0aec4\",\"title\":\"Question action relevance and editing for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/bddf7da5a21a5d1915cc9ee784223adadbe0aec4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-019-10005-z\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"2cf83b5d0c02cfdf877edc5547737ef3501e5deb\",\"title\":\"Image Captioning Using Region-Based Attention Joint with Time-Varying Attention\",\"url\":\"https://www.semanticscholar.org/paper/2cf83b5d0c02cfdf877edc5547737ef3501e5deb\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1903.09761\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af4df89ad28580d98113fa6a816195137f7d1a1d\",\"title\":\"Scene Understanding for Autonomous Manipulation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/af4df89ad28580d98113fa6a816195137f7d1a1d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27048932\",\"name\":\"Massimo Giordano\"},{\"authorId\":\"81048340\",\"name\":\"Giorgio Cristiano\"},{\"authorId\":\"2703972\",\"name\":\"K. Ishibashi\"},{\"authorId\":\"46301541\",\"name\":\"S. Ambrogio\"},{\"authorId\":\"13030074\",\"name\":\"H. Tsai\"},{\"authorId\":\"34730407\",\"name\":\"G. Burr\"},{\"authorId\":\"32967358\",\"name\":\"P. Narayanan\"}],\"doi\":\"10.1109/JETCAS.2019.2911537\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2977fa01d2287d4d471f9cdbaf164ca48cf5af35\",\"title\":\"Analog-to-Digital Conversion With Reconfigurable Function Mapping for Neural Networks Activation Function Acceleration\",\"url\":\"https://www.semanticscholar.org/paper/2977fa01d2287d4d471f9cdbaf164ca48cf5af35\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TMM.2019.2896515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5f79ee6c9b3e5951e4267d4624d2d7669a72cb3\",\"title\":\"Generating Video Descriptions With Latent Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/e5f79ee6c9b3e5951e4267d4624d2d7669a72cb3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8633454\",\"name\":\"Yingqing Peng\"},{\"authorId\":\"1700880\",\"name\":\"Zhi Jin\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"100715052\",\"name\":\"Yi Tang\"},{\"authorId\":\"1502881409\",\"name\":\"Xia Li\"}],\"doi\":\"10.1007/978-3-030-34113-8_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"161f104b8379589e3d906552bfcd8730ccb26bd5\",\"title\":\"An Efficient Quality Enhancement Solution for Stereo Images\",\"url\":\"https://www.semanticscholar.org/paper/161f104b8379589e3d906552bfcd8730ccb26bd5\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1805.08819\",\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"46242703\",\"name\":\"Dan Scheibler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.32470/CCN.2018.1113-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"title\":\"Global-and-local attention networks for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390412671\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"46223195\",\"name\":\"Shuchen Weng\"},{\"authorId\":\"49889486\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35580784\",\"name\":\"Boxin Shi\"},{\"authorId\":\"80266964\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2968054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"title\":\"Context-Aware Cross-Attention for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49388776\",\"name\":\"Huanhuan Ji\"},{\"authorId\":\"47781560\",\"name\":\"Z. Liu\"},{\"authorId\":\"40370973\",\"name\":\"Wei Qi Yan\"},{\"authorId\":\"1729664\",\"name\":\"R. Klette\"}],\"doi\":\"10.1007/978-3-030-41299-9_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be49c7c68106f5c5e5c5cb02208188237375da25\",\"title\":\"Early Diagnosis of Alzheimer's Disease Based on Selective Kernel Network with Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/be49c7c68106f5c5e5c5cb02208188237375da25\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/TPAMI.2018.2852750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69adf188e4c7d863edd3a4c0b300d2e9f35ae8e9\",\"title\":\"Deep Collaborative Embedding for Social Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/69adf188e4c7d863edd3a4c0b300d2e9f35ae8e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1905.13302\",\"authors\":[{\"authorId\":\"116567136\",\"name\":\"Vasiliki Kougia\"},{\"authorId\":\"2332587\",\"name\":\"John Pavlopoulos\"},{\"authorId\":\"1752430\",\"name\":\"Ion Androutsopoulos\"}],\"doi\":\"10.18653/v1/W19-1803\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e7f91e3bcc86360c6eaad7c3bdb3dafbde2bb1e\",\"title\":\"A Survey on Biomedical Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3e7f91e3bcc86360c6eaad7c3bdb3dafbde2bb1e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.00484\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"49915485\",\"name\":\"Andrew Silva\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"title\":\"Action2Vec: A Crossmodal Embedding Approach to Action Learning\",\"url\":\"https://www.semanticscholar.org/paper/797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.08113\",\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2910007\",\"name\":\"J. Guo\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0694beaf14f558a75f2dc32f64d151e505dbee17\",\"title\":\"Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/0694beaf14f558a75f2dc32f64d151e505dbee17\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1909.11760\",\"authors\":[{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"50126210\",\"name\":\"Yanan Xu\"},{\"authorId\":\"153514206\",\"name\":\"Yanmin Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa54eec434f5d7360d72a8dfb0e702cbf77c5a15\",\"title\":\"ALCNN: Attention-based Model for Fine-grained Demand Inference of Dock-less Shared Bike in New Cities\",\"url\":\"https://www.semanticscholar.org/paper/aa54eec434f5d7360d72a8dfb0e702cbf77c5a15\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144636064\",\"name\":\"M. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c15057f734781ee29f6569c87c48b97fa347cfb0\",\"title\":\"Optimization for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c15057f734781ee29f6569c87c48b97fa347cfb0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.01410\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00640\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"title\":\"Context and Attribute Grounded Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"49725227\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.04.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"title\":\"Stimulus-driven and concept-driven analysis for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2734498\",\"name\":\"N. Laokulrat\"},{\"authorId\":\"1764004\",\"name\":\"N. Okazaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8972dc1f5e59042c6ce111dc7591e8b5eed9737d\",\"title\":\"Incorporating Semantic Attention in Video Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/8972dc1f5e59042c6ce111dc7591e8b5eed9737d\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50811366\",\"name\":\"Haojie Pan\"},{\"authorId\":null,\"name\":\"Junpei Zhou\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49420788\",\"name\":\"Y. Liu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b0846692857eee0a1029adb5782c1136ae3f1c9\",\"title\":\"C L ] 1 N ov 2 01 8 Dial 2 Desc : End-to-end Dialogue Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/9b0846692857eee0a1029adb5782c1136ae3f1c9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5482750\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72f9116a04e584081635500e9f0789fa26e4d15f\",\"title\":\"Hierarchical Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72f9116a04e584081635500e9f0789fa26e4d15f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1805.00314\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-1198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"title\":\"Object Counts! Bringing Explicit Detections Back into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3180110\",\"name\":\"Renyu Zhang\"},{\"authorId\":\"145533896\",\"name\":\"C. Weber\"},{\"authorId\":\"153660172\",\"name\":\"R. Grossman\"},{\"authorId\":\"1794512\",\"name\":\"A. Khan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"629b93eaf76a445ae5672b30a13a6815c6242c42\",\"title\":\"Evaluating and interpreting caption prediction for histopathology images\",\"url\":\"https://www.semanticscholar.org/paper/629b93eaf76a445ae5672b30a13a6815c6242c42\",\"venue\":\"MLHC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"3374688\",\"name\":\"M. Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":null,\"name\":\"Heng Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"}],\"doi\":\"10.1016/J.PATREC.2019.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749f376d0addb83569fcc7536e46308abbb232d4\",\"title\":\"How much do cross-modal related semantics benefit image captioning by weighting attributes and re-ranking sentences?\",\"url\":\"https://www.semanticscholar.org/paper/749f376d0addb83569fcc7536e46308abbb232d4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"title\":\"A Semi-supervised Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fa6a688f350831503d158f8f618c58d1e06bc5d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.03107\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"1411260673\",\"name\":\"Luke Melas-Kyriazi\"}],\"doi\":\"10.1109/cvpr42600.2020.00486\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9419436682726232e1b37a04c53bba919b12025\",\"title\":\"Show, Edit and Tell: A Framework for Editing Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/e9419436682726232e1b37a04c53bba919b12025\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50e9aabc46ea2d1ee80aacfcade14746776a6761\",\"title\":\"Woman BrownPerson BluePerson Boy Counterfactual Phrase Grounding : woman in brown Result N / A\",\"url\":\"https://www.semanticscholar.org/paper/50e9aabc46ea2d1ee80aacfcade14746776a6761\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"31126576\",\"name\":\"Zheng Xiong\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"9245443\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.3390/app10010391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"945ffeb90e538214e3063407db8e094469ec877a\",\"title\":\"Panoptic Segmentation-Based Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/945ffeb90e538214e3063407db8e094469ec877a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46842113\",\"name\":\"S. Muralidharan\"},{\"authorId\":null,\"name\":\"smuralid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04d46aa5f75b7bee55f173cc76610643d755e154\",\"title\":\"Memory Augmented Recurrent Neural Networks for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04d46aa5f75b7bee55f173cc76610643d755e154\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2006.15406\",\"authors\":[{\"authorId\":\"1417133896\",\"name\":\"Sergi Perez-Castanos\"},{\"authorId\":\"1419458795\",\"name\":\"Javier Naranjo-Alcazar\"},{\"authorId\":\"2450434\",\"name\":\"P. Zuccarello\"},{\"authorId\":\"2432536\",\"name\":\"M. Cobos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b789ac73566e685839fdb610cbcd9cd43ca899a\",\"title\":\"Listen carefully and tell: an audio captioning system based on residual learning and gammatone audio representation\",\"url\":\"https://www.semanticscholar.org/paper/6b789ac73566e685839fdb610cbcd9cd43ca899a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"1716595\",\"name\":\"Chengjun Zhan\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1117/1.JEI.28.2.023022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e21b716ee953230b0261d05db9664cf50e6f906\",\"title\":\"Long short-term memory network with external memories for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/3e21b716ee953230b0261d05db9664cf50e6f906\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1905.10521\",\"authors\":[{\"authorId\":\"2490092\",\"name\":\"Kyungwoo Song\"},{\"authorId\":\"91586945\",\"name\":\"Joonho Jang\"},{\"authorId\":\"120296402\",\"name\":\"Seung-Jae Shin\"},{\"authorId\":\"1729306\",\"name\":\"I. Moon\"}],\"doi\":\"10.1609/AAAI.V34I04.6039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61bb0b9bf5aba11ab06e2a578ba32b21c4bd6611\",\"title\":\"Bivariate Beta LSTM\",\"url\":\"https://www.semanticscholar.org/paper/61bb0b9bf5aba11ab06e2a578ba32b21c4bd6611\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1808.09648\",\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"title\":\"From VQA to Multimodal CQA: Adapting Visual QA Models for Community QA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7843061\",\"name\":\"Gamaleldin F. Elsayed\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f302ce6172125f55b8efc5cdef2be2b36ddf9ba4\",\"title\":\"Soft attention is popular in models used for natural language tasks\",\"url\":\"https://www.semanticscholar.org/paper/f302ce6172125f55b8efc5cdef2be2b36ddf9ba4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438407\",\"name\":\"Mina Naghshnejad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7094888371de5f79d01d2733e8d4e689da41f2cf\",\"title\":\"Scheduling, Characterization and Prediction of HPC Workloads for Distributed Computing Environments\",\"url\":\"https://www.semanticscholar.org/paper/7094888371de5f79d01d2733e8d4e689da41f2cf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50826972\",\"name\":\"Wei Huang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1109/lgrs.2020.2980933\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca66b05a647e85426def722931e6b7ff79c672c8\",\"title\":\"Denoising-Based Multiscale Feature Fusion for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ca66b05a647e85426def722931e6b7ff79c672c8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.35940/ijrte.b1472.0982s1119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d23256c631bde5d1c88a5f6ed139a458c45c6b54\",\"title\":\"Prediction of Caption and Emoji of an Image using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d23256c631bde5d1c88a5f6ed139a458c45c6b54\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.04732\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/WACV45572.2020.9093373\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"title\":\"Fine-grained Image Classification and Retrieval by Combining Visual and Locally Pooled Textual Features\",\"url\":\"https://www.semanticscholar.org/paper/871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/978-3-319-51811-4_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"title\":\"What Convnets Make for Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":\"1706.09601\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"title\":\"Actor-Critic Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.05490\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2017.443\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"title\":\"Semantic Regularisation for Recurrent Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39603708\",\"name\":\"Q. Truong\"},{\"authorId\":\"3309003\",\"name\":\"Hady W. Lauw\"}],\"doi\":\"10.1145/3308558.3313463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17c07ee62b55b6ab2c5340460aed2b802dd31023\",\"title\":\"Multimodal Review Generation for Recommender Systems\",\"url\":\"https://www.semanticscholar.org/paper/17c07ee62b55b6ab2c5340460aed2b802dd31023\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.18653/v1/P18-3003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"954a39752ca5ebc19eb7563c28a5773f70bff452\",\"title\":\"Learning-based Composite Metrics for Improved Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/954a39752ca5ebc19eb7563c28a5773f70bff452\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1702.07432\",\"authors\":[{\"authorId\":\"145982988\",\"name\":\"Xiao Chu\"},{\"authorId\":null,\"name\":\"Wei Yang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"144970602\",\"name\":\"Cheng Ma\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2017.601\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9e671c01163c9ce0ea5699ff81b5173dd03730cf\",\"title\":\"Multi-context Attention for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/9e671c01163c9ce0ea5699ff81b5173dd03730cf\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.02735\",\"authors\":[{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145262833\",\"name\":\"Cara Jones\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc72b2bb34f6a8216767df80ae13e09d1ef0ebda\",\"title\":\"Combating Human Trafficking with Multimodal Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/fc72b2bb34f6a8216767df80ae13e09d1ef0ebda\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362315\",\"name\":\"J. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"},{\"authorId\":\"47789939\",\"name\":\"J. Lu\"}],\"doi\":\"10.1109/ICC40277.2020.9149264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a5a6c759925570ab178c45340d34174fc8760f3\",\"title\":\"Local-to-Global Semantic Supervised Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3a5a6c759925570ab178c45340d34174fc8760f3\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.03589\",\"authors\":[{\"authorId\":\"6818270\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1109/CVPR.2019.00654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92366e3c446c30e4c783c61dcf420edd17695c73\",\"title\":\"Modularized Textual Grounding for Counterfactual Resilience\",\"url\":\"https://www.semanticscholar.org/paper/92366e3c446c30e4c783c61dcf420edd17695c73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.13136\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"46641911\",\"name\":\"W. Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":\"10.1007/s11263-019-01206-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47286105575aacaed5ef74af9ae007e258abc60a\",\"title\":\"LCEval: Learned Composite Metric for Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/47286105575aacaed5ef74af9ae007e258abc60a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7644453\",\"name\":\"Hanqi Wang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"46867455\",\"name\":\"Yin Sheng Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3126686.3126715\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"70f7bcfe2ce3789e62846c73e98feeaa319135e5\",\"title\":\"Learning Deep Contextual Attention Network for Narrative Photo Stream Captioning\",\"url\":\"https://www.semanticscholar.org/paper/70f7bcfe2ce3789e62846c73e98feeaa319135e5\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"40222538\",\"name\":\"N. Lord\"},{\"authorId\":\"2702448\",\"name\":\"N. Lee\"},{\"authorId\":\"1730268\",\"name\":\"P. H. S. Torr\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c6f58adf4a5ee8499cbc9b9bc1e6f1c39f1f8eae\",\"title\":\"Earn to P Ay a Ttention\",\"url\":\"https://www.semanticscholar.org/paper/c6f58adf4a5ee8499cbc9b9bc1e6f1c39f1f8eae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1901.08942\",\"authors\":[{\"authorId\":\"143959713\",\"name\":\"Yimin Zhou\"},{\"authorId\":\"3156408\",\"name\":\"Y. Sun\"},{\"authorId\":\"145513516\",\"name\":\"Vasant G Honavar\"}],\"doi\":\"10.1109/WACV.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4c45108cb41051010d8a5175b8da23eb246c967\",\"title\":\"Improving Image Captioning by Leveraging Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/f4c45108cb41051010d8a5175b8da23eb246c967\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"title\":\"Attentive Models in Vision 3 Input Image Human Fixation Map Loss Function Final Convolutional Layers Learned Prior Low , Medium and High Level Features Predicted Saliency Map Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2001.09876\",\"authors\":[{\"authorId\":\"3362324\",\"name\":\"Binny Mathew\"},{\"authorId\":\"2632448\",\"name\":\"Sandipan Sikdar\"},{\"authorId\":\"2101037\",\"name\":\"Florian Lemmerich\"},{\"authorId\":\"1743043\",\"name\":\"M. Strohmaier\"}],\"doi\":\"10.1145/3366423.3380227\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"259e58c2555742982358a8df3dcf33c0843a5a70\",\"title\":\"The POLAR Framework: Polar Opposites Enable Interpretability of Pre-Trained Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/259e58c2555742982358a8df3dcf33c0843a5a70\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70535751\",\"name\":\"Siying Wu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.24963/ijcai.2019/137\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b004fca907431d3c11e1ac8d1fde710af5fd60d7\",\"title\":\"Densely Supervised Hierarchical Policy-Value Network for Image Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/b004fca907431d3c11e1ac8d1fde710af5fd60d7\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a347342b770635de4a837223562f4bc704d32ccd\",\"title\":\"Metadata of the chapter that will be visualized in SpringerLink\",\"url\":\"https://www.semanticscholar.org/paper/a347342b770635de4a837223562f4bc704d32ccd\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386080\",\"name\":\"Shifu Hou\"},{\"authorId\":\"2549310\",\"name\":\"Yujie Fan\"},{\"authorId\":\"49890762\",\"name\":\"Yiming Zhang\"},{\"authorId\":\"7873409\",\"name\":\"Yanfang Ye\"},{\"authorId\":\"30896646\",\"name\":\"Jingwei Lei\"},{\"authorId\":\"73667947\",\"name\":\"Wenqiang Wan\"},{\"authorId\":\"1519286480\",\"name\":\"Jiabin Wang\"},{\"authorId\":\"145099487\",\"name\":\"Qi Xiong\"},{\"authorId\":\"46726063\",\"name\":\"Fudong Shao\"}],\"doi\":\"10.1145/3357384.3357875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d7efe798ee9465e846c1e0d62263a8e72d75994\",\"title\":\"\\u03b1Cyber: Enhancing Robustness of Android Malware Detection System against Adversarial Attacks on Heterogeneous Graph based Model\",\"url\":\"https://www.semanticscholar.org/paper/1d7efe798ee9465e846c1e0d62263a8e72d75994\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1909.05693\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"101377061\",\"name\":\"Zizhou Jia\"},{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"2091623\",\"name\":\"L. Li\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1145/3343031.3351062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12c258108ab59ef0189a6deb47222a99269da212\",\"title\":\"PDANet: Polarity-consistent Deep Attention Network for Fine-grained Visual Emotion Regression\",\"url\":\"https://www.semanticscholar.org/paper/12c258108ab59ef0189a6deb47222a99269da212\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116740128\",\"name\":\"Hongchen Tan\"},{\"authorId\":\"48033092\",\"name\":\"X. Liu\"},{\"authorId\":\"3223020\",\"name\":\"Xin Li\"},{\"authorId\":\"48379553\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2207938\",\"name\":\"B. Yin\"}],\"doi\":\"10.1109/ICCV.2019.01060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"129e2359e072ba20029e48545f4acefa618d748a\",\"title\":\"Semantics-Enhanced Adversarial Nets for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/129e2359e072ba20029e48545f4acefa618d748a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00850\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2017.2729019\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"51b2c1e750b1d3b893072829d012f2352d6bd373\",\"title\":\"Video Captioning With Attention-Based LSTM and Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/51b2c1e750b1d3b893072829d012f2352d6bd373\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"39083167\",\"name\":\"A. Dutta\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"143826881\",\"name\":\"J. Llad\\u00f3s\"},{\"authorId\":\"144167309\",\"name\":\"U. Pal\"}],\"doi\":\"10.1007/978-3-030-20890-5_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaee9f15fcc7590b2f463bf9bc66745e797fd5f3\",\"title\":\"Aligning Salient Objects to Queries: A Multi-modal and Multi-object Image Retrieval Framework\",\"url\":\"https://www.semanticscholar.org/paper/eaee9f15fcc7590b2f463bf9bc66745e797fd5f3\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1591412916\",\"name\":\"Jiajie Su\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1007/s11042-020-08832-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"title\":\"Tell and guess: cooperative learning for natural image caption generation with hierarchical refined attention\",\"url\":\"https://www.semanticscholar.org/paper/814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143715692\",\"name\":\"X. Hao\"},{\"authorId\":\"46468475\",\"name\":\"F. Zhou\"},{\"authorId\":\"33899331\",\"name\":\"Xiaoyong Li\"}],\"doi\":\"10.1109/ITNEC48623.2020.9084781\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"653de101370307afc2eba27d4e4c574441eb06da\",\"title\":\"Scene-Edge GRU for Video Caption\",\"url\":\"https://www.semanticscholar.org/paper/653de101370307afc2eba27d4e4c574441eb06da\",\"venue\":\"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67010907\",\"name\":\"Martina Toshevska\"},{\"authorId\":\"67275493\",\"name\":\"Frosina Stojanovska\"},{\"authorId\":\"2269444\",\"name\":\"Eftim Zdravevski\"},{\"authorId\":\"1769456\",\"name\":\"Petre Lameski\"},{\"authorId\":\"144293427\",\"name\":\"S. Gievska\"}],\"doi\":\"10.15439/2020F57\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a8becc75e050e9ea52a1e4bb4faf9c1e39e5d599\",\"title\":\"Exploration into Deep Learning Text Generation Architectures for Dense Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a8becc75e050e9ea52a1e4bb4faf9c1e39e5d599\",\"venue\":\"2020 15th Conference on Computer Science and Information Systems (FedCSIS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712278660\",\"name\":\"Rishi Khajuria\"},{\"authorId\":\"9223439\",\"name\":\"Abdul Quyoom\"},{\"authorId\":\"1447070282\",\"name\":\"Abid Sarwar\"}],\"doi\":\"10.33851/jmis.2020.7.1.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b1dce21333f38dcadc2e8f8422aeaee1be5dd47\",\"title\":\"A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4b1dce21333f38dcadc2e8f8422aeaee1be5dd47\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":null,\"name\":\"Rui Wang\"},{\"authorId\":\"144241178\",\"name\":\"B. Lyu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/BigMM.2018.8499066\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"title\":\"Image Captioning Based on Adaptive Balancing Loss\",\"url\":\"https://www.semanticscholar.org/paper/9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398421283\",\"name\":\"U. Markowska-Kaczmar\"},{\"authorId\":\"153318273\",\"name\":\"H. Kwasnicka\"}],\"doi\":\"10.1007/978-3-319-73891-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"title\":\"Deep Learning\\u2014A New Era in Bridging the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.11701\",\"authors\":[{\"authorId\":\"84039136\",\"name\":\"P. Sadler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60d6e35891baa34282433546df0449d7422ce98\",\"title\":\"Spatial Attention as an Interface for Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b60d6e35891baa34282433546df0449d7422ce98\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46440341\",\"name\":\"Kaikai Song\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"40177644\",\"name\":\"Q. Ling\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1016/j.neucom.2018.05.104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24522165803afefd43f95d5c79a0449f248e7718\",\"title\":\"Boosting image sentiment analysis with visual attention\",\"url\":\"https://www.semanticscholar.org/paper/24522165803afefd43f95d5c79a0449f248e7718\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37310105\",\"name\":\"L. Zhao\"},{\"authorId\":\"47423527\",\"name\":\"Chunxia Zhang\"},{\"authorId\":null,\"name\":\"Xi Zhang\"},{\"authorId\":\"3034224\",\"name\":\"Yating Hu\"},{\"authorId\":\"8253080\",\"name\":\"Z. Niu\"}],\"doi\":\"10.1007/978-3-319-97304-3_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f472524ad1a5989aa1d66634a477041cd6ec9b64\",\"title\":\"A Deep Reinforced Training Method for Location-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f472524ad1a5989aa1d66634a477041cd6ec9b64\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116740128\",\"name\":\"Hongchen Tan\"},{\"authorId\":\"48033092\",\"name\":\"X. Liu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"2207938\",\"name\":\"B. Yin\"},{\"authorId\":\"3223020\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TIP.2020.3026728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f90326d1d032ce3ce1ce54fe762318781c173bb\",\"title\":\"KT-GAN: Knowledge-Transfer Generative Adversarial Network for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/4f90326d1d032ce3ce1ce54fe762318781c173bb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038515405\",\"name\":\"Yazid Bounab\"},{\"authorId\":\"1471224685\",\"name\":\"Mourad Oussalah\"},{\"authorId\":\"2038543683\",\"name\":\"Ahlam Ferdenache\"}],\"doi\":\"10.1109/IPTA50016.2020.9286602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"title\":\"Reconciling Image Captioning and User\\u2019s Comments for Urban Tourism\",\"url\":\"https://www.semanticscholar.org/paper/12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/cvpr42600.2020.01098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"title\":\"X-Linear Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7785915\",\"name\":\"Horea-Ioan Ioanas\"},{\"authorId\":\"4038972\",\"name\":\"Bechara John Saab\"},{\"authorId\":\"1707489\",\"name\":\"M. Rudin\"}],\"doi\":\"10.25080/SHINMA-7F4C6E7-004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"388bc7b000969262f816299c7424572622cbbf8d\",\"title\":\"LabbookDB: A Wet-Work-Tracking Database Application Framework\",\"url\":\"https://www.semanticscholar.org/paper/388bc7b000969262f816299c7424572622cbbf8d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692269\",\"name\":\"Jiancheng Ni\"},{\"authorId\":\"1557381789\",\"name\":\"Susu Zhang\"},{\"authorId\":null,\"name\":\"Zili Zhou\"},{\"authorId\":\"47287130\",\"name\":\"J. Hou\"},{\"authorId\":\"152174467\",\"name\":\"Feng Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2975841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7cddb9d7709cebcc615611930bedf93cd6caef3\",\"title\":\"Instance Mask Embedding and Attribute-Adaptive Generative Adversarial Network for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/b7cddb9d7709cebcc615611930bedf93cd6caef3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"3348635\",\"name\":\"Haoran Wang\"}],\"doi\":\"10.1109/BigMM.2018.8499098\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eaf2eaf8ffd056799ae6bbe44f5939eb562fd8d9\",\"title\":\"Reference Based on Adaptive Attention Mechanism for Image Captioning*\",\"url\":\"https://www.semanticscholar.org/paper/eaf2eaf8ffd056799ae6bbe44f5939eb562fd8d9\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.02391\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"40222538\",\"name\":\"N. Lord\"},{\"authorId\":\"2702448\",\"name\":\"N. Lee\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c70218603f0af1be5d063056cbe629e042141a86\",\"title\":\"Learn To Pay Attention\",\"url\":\"https://www.semanticscholar.org/paper/c70218603f0af1be5d063056cbe629e042141a86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.03853\",\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1382537904\",\"name\":\"Chengpeng Dai\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"46246806\",\"name\":\"Chia-Wen Lin\"},{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7755545e3ed52ac13db79a844d631f4f435f4cf7\",\"title\":\"Semantic-aware Image Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/7755545e3ed52ac13db79a844d631f4f435f4cf7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.00794\",\"authors\":[{\"authorId\":\"2514295\",\"name\":\"Derek Doran\"},{\"authorId\":\"48144261\",\"name\":\"Sarah Schulz\"},{\"authorId\":\"143862012\",\"name\":\"Tarek R. Besold\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0ba972791a530641cec11a7b8de18a3dcaa45fb\",\"title\":\"What Does Explainable AI Really Mean? A New Conceptualization of Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/a0ba972791a530641cec11a7b8de18a3dcaa45fb\",\"venue\":\"CEx@AI*IA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26994223\",\"name\":\"Yunbin Tu\"},{\"authorId\":\"22066021\",\"name\":\"Xishan Zhang\"},{\"authorId\":\"50678151\",\"name\":\"Bingtao Liu\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"}],\"doi\":\"10.1145/3123266.3123354\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c2cf74ba6f107aa9508e7ef1bad93916d944cb4c\",\"title\":\"Video Description with Spatial-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/c2cf74ba6f107aa9508e7ef1bad93916d944cb4c\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350881\",\"name\":\"Y. Tian\"},{\"authorId\":\"47120369\",\"name\":\"X. Wang\"},{\"authorId\":\"13013695\",\"name\":\"Jiachen Wu\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"7324474\",\"name\":\"Bailin Yang\"}],\"doi\":\"10.1613/jair.1.11338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfeda236987b04250a218b688e32b6b35c617ba4\",\"title\":\"Multi-scale Hierarchical Residual Network for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cfeda236987b04250a218b688e32b6b35c617ba4\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49537438\",\"name\":\"Xing Fan\"},{\"authorId\":\"3181908\",\"name\":\"Huijune Luo\"},{\"authorId\":\"1391222888\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"144486617\",\"name\":\"Lingxiao He\"},{\"authorId\":\"47897373\",\"name\":\"Wei Jiang\"}],\"doi\":\"10.1007/978-3-030-20890-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d336e2e536de51c287e04d95737ff62eeebb536\",\"title\":\"Computer Vision \\u2013 ACCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/2d336e2e536de51c287e04d95737ff62eeebb536\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73435945\",\"name\":\"C. Yan\"},{\"authorId\":\"102636815\",\"name\":\"Chengfei Cai\"},{\"authorId\":\"144945345\",\"name\":\"J. Xie\"},{\"authorId\":\"143785074\",\"name\":\"Yao Fu\"},{\"authorId\":\"35572013\",\"name\":\"Hui Shuai\"},{\"authorId\":\"5084670\",\"name\":\"X. Fan\"},{\"authorId\":\"145971173\",\"name\":\"J. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71e9cb9f4783452ccb6a36aa71b2a7f20e494e33\",\"title\":\"Prior Consistent CNN with Multi-Task Learning for Colon Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/71e9cb9f4783452ccb6a36aa71b2a7f20e494e33\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388141138\",\"name\":\"L B.\"},{\"authorId\":\"1381486649\",\"name\":\"G. V.\"}],\"doi\":\"10.1109/ICECCT.2019.8869370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac91986d1f63267874fe901d8f2a0856e50ec11c\",\"title\":\"Review based on Image Understanding Approaches\",\"url\":\"https://www.semanticscholar.org/paper/ac91986d1f63267874fe901d8f2a0856e50ec11c\",\"venue\":\"2019 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)\",\"year\":2019},{\"arxivId\":\"1901.06283\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"Bai Li\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"717daba98eb57b898687fc013b705f763eb2916b\",\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/717daba98eb57b898687fc013b705f763eb2916b\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672743\",\"name\":\"C. Li\"},{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"}],\"doi\":\"10.1007/978-3-319-71607-7_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"title\":\"Combining Object-Based Attention and Attributes for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97042343\",\"name\":\"Y. Chen\"},{\"authorId\":\"1596798793\",\"name\":\"Jingwei Zheng\"},{\"authorId\":\"48108760\",\"name\":\"Dagang Li\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206595\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76cca006995bc457bc9f69af7891afe5ddc94017\",\"title\":\"Sparse Attributed Network Embedding via Adaptively Aggregating Neighborhood Information\",\"url\":\"https://www.semanticscholar.org/paper/76cca006995bc457bc9f69af7891afe5ddc94017\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47396548\",\"name\":\"Chao Huang\"},{\"authorId\":\"3407809\",\"name\":\"Chuxu Zhang\"},{\"authorId\":\"48501208\",\"name\":\"P. Dai\"},{\"authorId\":\"144651486\",\"name\":\"L. Bo\"}],\"doi\":\"10.1145/3357384.3357829\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39d552539bc4dd65a75ffe04f28bf2b32ddf917\",\"title\":\"Deep Dynamic Fusion Network for Traffic Accident Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/d39d552539bc4dd65a75ffe04f28bf2b32ddf917\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47284770\",\"name\":\"Utkarsh Ojha\"},{\"authorId\":\"40772377\",\"name\":\"U. Adhikari\"},{\"authorId\":\"40406614\",\"name\":\"D. K. Singh\"}],\"doi\":\"10.1109/I2C2.2017.8321819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b262f1ddb26e8f8c7cfd9267f9a4f8a315c013a3\",\"title\":\"Image annotation using deep learning: A review\",\"url\":\"https://www.semanticscholar.org/paper/b262f1ddb26e8f8c7cfd9267f9a4f8a315c013a3\",\"venue\":\"2017 International Conference on Intelligent Computing and Control (I2C2)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32324177\",\"name\":\"C. Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.neucom.2018.07.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fc4a590d1859ba43c1303927c86c64b34e43287\",\"title\":\"Hierarchical attention-based multimodal fusion for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fc4a590d1859ba43c1303927c86c64b34e43287\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005221\",\"name\":\"Zhishen Yang\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1dc881bd497d4466897c1ab9111674d87dda9d0\",\"title\":\"Image Caption Generation for News Articles\",\"url\":\"https://www.semanticscholar.org/paper/b1dc881bd497d4466897c1ab9111674d87dda9d0\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41078388\",\"name\":\"Mark Bugeja\"},{\"authorId\":\"1804046\",\"name\":\"Alexiei Dingli\"},{\"authorId\":\"145221463\",\"name\":\"Maria Attard\"},{\"authorId\":\"1793044\",\"name\":\"Dylan Seychell\"}],\"doi\":\"10.1145/3349622.3355448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84e2fbee5cb7b3492d7c1a628bde744f697d330d\",\"title\":\"A Framework for Queryable Video Analysis: A Case-Study on Transport Modelling\",\"url\":\"https://www.semanticscholar.org/paper/84e2fbee5cb7b3492d7c1a628bde744f697d330d\",\"venue\":\"SMAS@MobiCom\",\"year\":2019},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1905.02963\",\"authors\":[{\"authorId\":\"145114776\",\"name\":\"L. Sun\"},{\"authorId\":\"143721383\",\"name\":\"Bing Li\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICME.2019.00226\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"title\":\"Multimodal Semantic Attention Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b8218640e95bb2d925a617b1c3012eed7d209351\",\"title\":\"Show, Reward and Tell: Automatic Generation of Narrative Paragraph From Photo Stream by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/b8218640e95bb2d925a617b1c3012eed7d209351\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1908.00047\",\"authors\":[{\"authorId\":\"9424554\",\"name\":\"Berkan Demirel\"},{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d617b8cbf10b3fe776c16fa498e6420def3e000\",\"title\":\"Image Captioning with Unseen Objects\",\"url\":\"https://www.semanticscholar.org/paper/3d617b8cbf10b3fe776c16fa498e6420def3e000\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2019.2921655\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"title\":\"Sports Video Captioning via Attentive Motion Representation and Group Relationship Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1809.07257\",\"authors\":[{\"authorId\":\"2662002\",\"name\":\"Oliver Nina\"},{\"authorId\":\"47238599\",\"name\":\"W. Garcia\"},{\"authorId\":\"47637016\",\"name\":\"Scott Clouse\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81e31899aa9f0f54db069f0f4c2a29ed9587fe89\",\"title\":\"MTLE: A Multitask Learning Encoder of Visual Feature Representations for Video and Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/81e31899aa9f0f54db069f0f4c2a29ed9587fe89\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508437\",\"name\":\"J. Moon\"},{\"authorId\":\"152840733\",\"name\":\"B. Lee\"}],\"doi\":\"10.1109/ICRA40945.2020.9196563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdccef464720bd47e16de8bebdd5df9bc3281c5b\",\"title\":\"Object-oriented Semantic Graph Based Natural Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/cdccef464720bd47e16de8bebdd5df9bc3281c5b\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2341978\",\"name\":\"Anjali Singh\"},{\"authorId\":\"41051307\",\"name\":\"Ruhi Sharma Mittal\"},{\"authorId\":\"47033576\",\"name\":\"Shubham Atreja\"},{\"authorId\":\"51253421\",\"name\":\"Mourvi Sharma\"},{\"authorId\":\"145620983\",\"name\":\"Seema Nagar\"},{\"authorId\":\"35346960\",\"name\":\"P. Dey\"},{\"authorId\":\"145367571\",\"name\":\"Mohit Jain\"}],\"doi\":\"10.1609/aaai.v33i01.33019713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94976360e7ea07b6d67c13d2e4aa90591183bcbd\",\"title\":\"Automatic Generation of Leveled Visual Assessments for Young Learners\",\"url\":\"https://www.semanticscholar.org/paper/94976360e7ea07b6d67c13d2e4aa90591183bcbd\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52201852\",\"name\":\"Eleftherios Daskalakis\"},{\"authorId\":\"2817419\",\"name\":\"Maria Tzelepi\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"}],\"doi\":\"10.1016/j.patrec.2018.09.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc1332023c370dc55fabb1b6c895af1a5f48f889\",\"title\":\"Learning deep spatiotemporal features for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/fc1332023c370dc55fabb1b6c895af1a5f48f889\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1908.07644\",\"authors\":[{\"authorId\":\"7843061\",\"name\":\"Gamaleldin F. Elsayed\"},{\"authorId\":\"40464924\",\"name\":\"Simon Kornblith\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ceddc94e4539763185003b924b6178dd8beef73\",\"title\":\"Saccader: Improving Accuracy of Hard Attention Models for Vision\",\"url\":\"https://www.semanticscholar.org/paper/7ceddc94e4539763185003b924b6178dd8beef73\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1812.02869\",\"authors\":[{\"authorId\":\"143876686\",\"name\":\"C. Ma\"},{\"authorId\":\"145619011\",\"name\":\"Peng Kang\"},{\"authorId\":\"1699037\",\"name\":\"Bin Wu\"},{\"authorId\":\"40326664\",\"name\":\"Qinglong Wang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"}],\"doi\":\"10.1145/3289600.3290977\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5e365fe2d3134ae03987beccdb81c1c39adc11d\",\"title\":\"Gated Attentive-Autoencoder for Content-Aware Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/d5e365fe2d3134ae03987beccdb81c1c39adc11d\",\"venue\":\"WSDM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1906.08089\",\"authors\":[{\"authorId\":\"50695615\",\"name\":\"Shiyin Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60cb01b81c1d3daa31308b95ad670705b5ed7504\",\"title\":\"Predicting Drug Responses by Propagating Interactions through Text-Enhanced Drug-Gene Networks\",\"url\":\"https://www.semanticscholar.org/paper/60cb01b81c1d3daa31308b95ad670705b5ed7504\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22603654\",\"name\":\"Xuecheng Ning\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1007/978-3-030-37734-2_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"120b849abbfcaefe0e212c38141e86958118d1d7\",\"title\":\"Multi-hop Interactive Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/120b849abbfcaefe0e212c38141e86958118d1d7\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10798523\",\"name\":\"C. C. Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/TPAMI.2018.2824816\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"title\":\"Towards Personalized Image Captioning via Multimodal Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410712200\",\"name\":\"B. Lalitha\"},{\"authorId\":\"1396873549\",\"name\":\"Gomathi\"}],\"doi\":\"10.1109/ICECCT.2019.8869370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69b2b219282546e2b51b65e55e189102e9f7ec0e\",\"title\":\"Review based on Image Understanding Approaches\",\"url\":\"https://www.semanticscholar.org/paper/69b2b219282546e2b51b65e55e189102e9f7ec0e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2654246\",\"name\":\"A. Ashfaq\"},{\"authorId\":\"1401602035\",\"name\":\"A. Sant'Anna\"},{\"authorId\":\"13839814\",\"name\":\"Markus Lingman\"},{\"authorId\":\"51895059\",\"name\":\"S\\u0142awomir Nowaczyk\"}],\"doi\":\"10.1016/j.jbi.2019.103256\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e201dbf90c649fa1ba0ec842e7df0e5bb4e1cc9\",\"title\":\"Readmission prediction using deep learning on electronic health records\",\"url\":\"https://www.semanticscholar.org/paper/9e201dbf90c649fa1ba0ec842e7df0e5bb4e1cc9\",\"venue\":\"J. Biomed. Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52423203\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3985dbf7616c7d2c6178eaa262389815f95290e6\",\"title\":\"Cross-view learning\",\"url\":\"https://www.semanticscholar.org/paper/3985dbf7616c7d2c6178eaa262389815f95290e6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1016/j.neucom.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"title\":\"Phrase-based image caption generator with hierarchical LSTM network\",\"url\":\"https://www.semanticscholar.org/paper/760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1812.03426\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"title\":\"Real-Time Referring Expression Comprehension by Single-Stage Grounding Network\",\"url\":\"https://www.semanticscholar.org/paper/e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W17-4752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"title\":\"Sheffield MultiMT: Using Object Posterior Predictions for Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ecb6b37ed067b2f16dbb6f476d449f113fae534\",\"title\":\"Video Captioning and Retrieval Models with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/1ecb6b37ed067b2f16dbb6f476d449f113fae534\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1903.01072\",\"authors\":[{\"authorId\":\"47060391\",\"name\":\"J. Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"38900275\",\"name\":\"Joon Huang Chuah\"}],\"doi\":\"10.1109/TMM.2019.2904878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"title\":\"COMIC: Toward A Compact Image Captioning Model With Attention\",\"url\":\"https://www.semanticscholar.org/paper/9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1906.05963\",\"authors\":[{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"40441990\",\"name\":\"Armin Kappeler\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"},{\"authorId\":\"145730823\",\"name\":\"J. Soares\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b499228aa74b59be32711c3926e44de208d6b636\",\"title\":\"Image Captioning: Transforming Objects into Words\",\"url\":\"https://www.semanticscholar.org/paper/b499228aa74b59be32711c3926e44de208d6b636\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5947095\",\"name\":\"Byeong Jo Kim\"},{\"authorId\":\"47634928\",\"name\":\"Yong Hoon Choi\"}],\"doi\":\"10.1145/3341105.3374063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"title\":\"Automatic baseball commentary generation using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2008.02918\",\"authors\":[{\"authorId\":\"1864097171\",\"name\":\"Xubin Zhong\"},{\"authorId\":\"144116132\",\"name\":\"Changxing Ding\"},{\"authorId\":\"50123957\",\"name\":\"Xian Qu\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"title\":\"Polysemy Deciphering Network for Robust Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2002.05637\",\"authors\":[{\"authorId\":\"9546292\",\"name\":\"Justin Sybrandt\"},{\"authorId\":\"2926850\",\"name\":\"Ilya Safro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c754f1b71591f5ec0a75c041f9cc231c1cc939ac\",\"title\":\"CBAG: Conditional Biomedical Abstract Generation\",\"url\":\"https://www.semanticscholar.org/paper/c754f1b71591f5ec0a75c041f9cc231c1cc939ac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.11639\",\"authors\":[{\"authorId\":\"3214992\",\"name\":\"A. Ortis\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"104159140\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1049/iet-ipr.2019.1270\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60fb1f219236c010c151632a46f0f175cf50b781\",\"title\":\"A Survey on Visual Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/60fb1f219236c010c151632a46f0f175cf50b781\",\"venue\":\"IET Image Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1016/j.neucom.2020.03.087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1c830d89069401945c430c6ddccc3ea4b3bd924\",\"title\":\"Evolutionary recurrent neural network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1c830d89069401945c430c6ddccc3ea4b3bd924\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145960537\",\"name\":\"W. Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1007/978-981-10-7299-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"title\":\"Relevance and Coherence Based Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83816065\",\"name\":\"P. Jenkins\"},{\"authorId\":\"120246332\",\"name\":\"J. Zhao\"},{\"authorId\":\"3016225\",\"name\":\"Heath Vinicombe\"},{\"authorId\":\"1410580599\",\"name\":\"Anant Subramanian\"},{\"authorId\":\"143718136\",\"name\":\"A. Prasad\"},{\"authorId\":\"1678196014\",\"name\":\"Atillia Dobi\"},{\"authorId\":\"33413117\",\"name\":\"E. Li\"},{\"authorId\":\"2447423\",\"name\":\"Yunsong Guo\"}],\"doi\":\"10.1145/3366423.3380049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be48c3941305cc52df61332a0927a4b773a84169\",\"title\":\"Natural Language Annotations for Search Engine Optimization\",\"url\":\"https://www.semanticscholar.org/paper/be48c3941305cc52df61332a0927a4b773a84169\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1704.06485\",\"authors\":[{\"authorId\":\"47465525\",\"name\":\"Cesc Chunseong Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.681\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"title\":\"Attend to You: Personalized Image Captioning with Context Sequence Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410455580\",\"name\":\"Viet-Khoa Vo-Ho\"},{\"authorId\":\"51172821\",\"name\":\"Quoc-An Luong\"},{\"authorId\":\"123547177\",\"name\":\"Duy-Tam Nguyen\"},{\"authorId\":\"35505989\",\"name\":\"Mai-Khiem Tran\"},{\"authorId\":\"1780348\",\"name\":\"M. Tran\"}],\"doi\":\"10.1145/3287921.3287955\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58e82b6035b5893cb50df9ef39481a0eebfbeec3\",\"title\":\"Personal Diary Generation from Wearable Cameras with Concept Augmented Image Captioning and Wide Trail Strategy\",\"url\":\"https://www.semanticscholar.org/paper/58e82b6035b5893cb50df9ef39481a0eebfbeec3\",\"venue\":\"SoICT 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70034802\",\"name\":\"D. Z. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f4d64227d6694ab8cb426792022cfaeb6589ff9\",\"title\":\"Understanding and Predicting the Usefulness of Yelp Reviews\",\"url\":\"https://www.semanticscholar.org/paper/6f4d64227d6694ab8cb426792022cfaeb6589ff9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"title\":\"IGURE QA : A N A NNOTATED F IGURE D ATASET FOR V ISUAL R EASONING\",\"url\":\"https://www.semanticscholar.org/paper/cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"36158244\",\"name\":\"Maaike H. T. de Boer\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1109/ICME.2018.8486491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d27272027cd84341070fd4b7eb7e03dcb514d93f\",\"title\":\"A Dual Prediction Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d27272027cd84341070fd4b7eb7e03dcb514d93f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9382626\",\"name\":\"M. Amaresh\"},{\"authorId\":\"144902122\",\"name\":\"S. Chitrakala\"}],\"doi\":\"10.1109/ICCSP.2019.8698097\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aad4525b28b18fde9c793ab387ac327802ef71d2\",\"title\":\"Video Captioning using Deep Learning: An Overview of Methods, Datasets and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/aad4525b28b18fde9c793ab387ac327802ef71d2\",\"venue\":\"2019 International Conference on Communication and Signal Processing (ICCSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9db873fb85ad9e3f19d2462a724e6f169a79328a\",\"title\":\"Optimization for Networks and Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9db873fb85ad9e3f19d2462a724e6f169a79328a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15281603\",\"name\":\"Zerui Chen\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2019.8802975\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"title\":\"Augmented Visual-Semantic Embeddings for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1431726865\",\"name\":\"R. SreelaS.\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.3390/info10110354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"title\":\"Dense Model for Automatic Image Description Generation with Game Theoretic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39970828\",\"name\":\"J. Jacob\"},{\"authorId\":\"2457110\",\"name\":\"M. S. Elayidom\"},{\"authorId\":\"3109670\",\"name\":\"V. P. Devassia\"}],\"doi\":\"10.11591/IJECE.V10I6.PP6019-6025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de96c55acc706c4a02307a5e572753ffab6853d2\",\"title\":\"Video content analysis and retrieval system using video storytelling and indexing techniques\",\"url\":\"https://www.semanticscholar.org/paper/de96c55acc706c4a02307a5e572753ffab6853d2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145441561\",\"name\":\"W. Cui\"},{\"authorId\":\"49451360\",\"name\":\"Fei Wang\"},{\"authorId\":\"144258396\",\"name\":\"X. He\"},{\"authorId\":\"29090447\",\"name\":\"D. Zhang\"},{\"authorId\":\"122135929\",\"name\":\"Xuxiang Xu\"},{\"authorId\":\"144817588\",\"name\":\"Meng Yao\"},{\"authorId\":\"72682876\",\"name\":\"Z. Wang\"},{\"authorId\":\"1955707\",\"name\":\"Jiejun Huang\"}],\"doi\":\"10.3390/RS11091044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75b0a1264b5ba0202ee3e81b89d7e9f0042c3744\",\"title\":\"Multi-Scale Semantic Segmentation and Spatial Relationship Recognition of Remote Sensing Images Based on an Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/75b0a1264b5ba0202ee3e81b89d7e9f0042c3744\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"145819866\",\"name\":\"J. Liang\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1016/j.neucom.2018.03.078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"title\":\"Image captioning by incorporating affective concepts learned from both visual and textual components\",\"url\":\"https://www.semanticscholar.org/paper/adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"2806202\",\"name\":\"Soonmin Hwang\"},{\"authorId\":\"72682056\",\"name\":\"Ho-Deok Jang\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1007/s00138-019-01017-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae5d5e5c40b208e21f6f0c18bc453310bf9cb297\",\"title\":\"Gated bidirectional feature pyramid network for accurate one-shot detection\",\"url\":\"https://www.semanticscholar.org/paper/ae5d5e5c40b208e21f6f0c18bc453310bf9cb297\",\"venue\":\"Machine Vision and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150016295\",\"name\":\"A. Hocking\"}],\"doi\":\"10.18745/th.21281\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec4e829879c136d9ef36c99183ea1498cd95a2e9\",\"title\":\"Automatic Object Detection and Categorisation in Deep Astronomical Imaging Surveys Using Unsupervised Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/ec4e829879c136d9ef36c99183ea1498cd95a2e9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89766800\",\"name\":\"Zhenru Li\"},{\"authorId\":\"121704343\",\"name\":\"Yaoyi Li\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-36802-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"title\":\"Improve Image Captioning by Self-attention\",\"url\":\"https://www.semanticscholar.org/paper/c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.07022\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"1682058\",\"name\":\"H. Zhang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.364\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"428818a9edfb547431be6d7ec165c6af576c83d5\",\"title\":\"Recurrent Topic-Transition GAN for Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/428818a9edfb547431be6d7ec165c6af576c83d5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115698465\",\"name\":\"Xianhao He\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"}],\"doi\":\"10.1007/978-3-030-30484-3_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd443c7b72c78608e101c85dc76ffacc05064317\",\"title\":\"Spatial Attention Network for Few-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/fd443c7b72c78608e101c85dc76ffacc05064317\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"1812.10025\",\"authors\":[{\"authorId\":\"46362682\",\"name\":\"H. Fukui\"},{\"authorId\":\"8295964\",\"name\":\"Tsubasa Hirakawa\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"1687968\",\"name\":\"H. Fujiyoshi\"}],\"doi\":\"10.1109/CVPR.2019.01096\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e8874d7d585ae1c355e186efdcc9f704b3d43b49\",\"title\":\"Attention Branch Network: Learning of Attention Mechanism for Visual Explanation\",\"url\":\"https://www.semanticscholar.org/paper/e8874d7d585ae1c355e186efdcc9f704b3d43b49\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780348\",\"name\":\"M. Tran\"},{\"authorId\":\"35659935\",\"name\":\"Thanh-Dat Truong\"},{\"authorId\":\"46195787\",\"name\":\"Tung Dinh Duy\"},{\"authorId\":\"1410455580\",\"name\":\"Viet-Khoa Vo-Ho\"},{\"authorId\":\"51172821\",\"name\":\"Q. Luong\"},{\"authorId\":\"34453615\",\"name\":\"V. Nguyen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f3580317c9c8e7a5066ce57aba0a22781dd84cc\",\"title\":\"Lifelog Moment Retrieval with Visual Concept Fusion and Text-based Query Expansion\",\"url\":\"https://www.semanticscholar.org/paper/0f3580317c9c8e7a5066ce57aba0a22781dd84cc\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":\"1908.00120\",\"authors\":[{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"102574232\",\"name\":\"C. Chen\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"}],\"doi\":\"10.1145/3394171.3413889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e87d0adf7df03fdd74e6dfea81f21aa03afab0\",\"title\":\"ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences\",\"url\":\"https://www.semanticscholar.org/paper/66e87d0adf7df03fdd74e6dfea81f21aa03afab0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"153017460\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":null,\"name\":\"Yan Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"title\":\"Variational Structured Semantic Inference for Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-019-09978-8\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"9651480574afedb770e645871484b07fa6fc60c3\",\"title\":\"Deep Captioning with Attention-Based Visual Concept Transfer Mechanism for Enriching Description\",\"url\":\"https://www.semanticscholar.org/paper/9651480574afedb770e645871484b07fa6fc60c3\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161800\",\"name\":\"Yong Cheng\"},{\"authorId\":\"143857288\",\"name\":\"Fei Huang\"},{\"authorId\":\"144913277\",\"name\":\"Lian Zhou\"},{\"authorId\":\"145020730\",\"name\":\"C. Jin\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"40953577\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1145/3077136.3080671\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39a20428734b1b38b8e93c1c23283f4c85ff27f4\",\"title\":\"A Hierarchical Multimodal Attention-based Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39a20428734b1b38b8e93c1c23283f4c85ff27f4\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":\"1706.10006\",\"authors\":[{\"authorId\":\"3193584\",\"name\":\"Konstantinos Drossos\"},{\"authorId\":\"9918923\",\"name\":\"Sharath Adavanne\"},{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"}],\"doi\":\"10.1109/WASPAA.2017.8170058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1368b0001e454381eafc35324740c928cb2ad1e\",\"title\":\"Automated audio captioning with recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/f1368b0001e454381eafc35324740c928cb2ad1e\",\"venue\":\"2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)\",\"year\":2017},{\"arxivId\":\"1811.00696\",\"authors\":[{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"2900282\",\"name\":\"W. Wang\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"261783ef9c98986652ee11c4df20173edafae826\",\"title\":\"Sequence Generation with Guider Network\",\"url\":\"https://www.semanticscholar.org/paper/261783ef9c98986652ee11c4df20173edafae826\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5829939\",\"name\":\"Suo Qiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e16b1752767ef3c23456107bc1cfc69edb8ad97\",\"title\":\"Global Weighted Average Pooling Bridges Pixel-level Localization and Image-level Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e16b1752767ef3c23456107bc1cfc69edb8ad97\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3470080\",\"name\":\"Puzhao Zhang\"},{\"authorId\":\"144605807\",\"name\":\"Maoguo Gong\"},{\"authorId\":\"48213361\",\"name\":\"Hui Bin Zhang\"},{\"authorId\":\"48210927\",\"name\":\"Jia Liu\"}],\"doi\":\"10.24963/ijcai.2017/477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a258d421200b2e41588a2f08fd352d6bfe0d144\",\"title\":\"DRLnet: Deep Difference Representation Learning Network and An Unsupervised Optimization Framework\",\"url\":\"https://www.semanticscholar.org/paper/9a258d421200b2e41588a2f08fd352d6bfe0d144\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"66628761\",\"name\":\"Wenbo Nie\"},{\"authorId\":\"50079235\",\"name\":\"X. Li\"},{\"authorId\":\"1704871\",\"name\":\"Yao Yu\"}],\"doi\":\"10.1109/YAC.2019.8787715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e46bfa93fb5874069b4bcdd6e887e96308babb2b\",\"title\":\"Image Caption Generation With Adaptive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/e46bfa93fb5874069b4bcdd6e887e96308babb2b\",\"venue\":\"2019 34rd Youth Academic Annual Conference of Chinese Association of Automation (YAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2343931\",\"name\":\"Miao Ma\"},{\"authorId\":\"93119174\",\"name\":\"Ziang Gao\"}],\"doi\":\"10.1109/CCHI.2019.8901917\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddcfc8f4aab75a96ba76f1275056f39f5595f2bc\",\"title\":\"Examinee Behavior Description Method Based on Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ddcfc8f4aab75a96ba76f1275056f39f5595f2bc\",\"venue\":\"2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"46651452\",\"name\":\"Cong Li\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8803108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff24050374748529fa2a1fee6941af08296449f8\",\"title\":\"Image Captioning with Attribute Refinement\",\"url\":\"https://www.semanticscholar.org/paper/ff24050374748529fa2a1fee6941af08296449f8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7cc8e0430de6b9f1a2970e7f4f7596be0a0716e\",\"title\":\"CLARA: Dynamic Doctor Representation Learning for Clinical Trial Recruitment\",\"url\":\"https://www.semanticscholar.org/paper/e7cc8e0430de6b9f1a2970e7f4f7596be0a0716e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"3097765\",\"name\":\"A. K. Sangaiah\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.PATREC.2019.03.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96829c628b8db61c67f3e72dd3f25035bff2d985\",\"title\":\"Image caption generation with high-level image features\",\"url\":\"https://www.semanticscholar.org/paper/96829c628b8db61c67f3e72dd3f25035bff2d985\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1804.03867\",\"authors\":[{\"authorId\":\"39012223\",\"name\":\"Ameya Prabhu\"},{\"authorId\":\"41018721\",\"name\":\"Vishal Batchu\"},{\"authorId\":\"41019538\",\"name\":\"Rohit Gajawada\"},{\"authorId\":\"41020217\",\"name\":\"Sri Aurobindo Munagala\"},{\"authorId\":\"3185334\",\"name\":\"A. Namboodiri\"}],\"doi\":\"10.1109/WACV.2018.00095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69cd9ab8d0e9006d40e370a1b1fb006ae07f7bfe\",\"title\":\"Hybrid Binary Networks: Optimizing for Accuracy, Efficiency and Memory\",\"url\":\"https://www.semanticscholar.org/paper/69cd9ab8d0e9006d40e370a1b1fb006ae07f7bfe\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"3141085\",\"name\":\"V. K\\u0131l\\u0131\\u00e7\"}],\"doi\":\"10.23919/ELECO47770.2019.8990395\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2c04709cafc945deaa13b6a92c092416188d8bf9\",\"title\":\"Smartphone-based Image Captioning for Visually and Hearing Impaired\",\"url\":\"https://www.semanticscholar.org/paper/2c04709cafc945deaa13b6a92c092416188d8bf9\",\"venue\":\"2019 11th International Conference on Electrical and Electronics Engineering (ELECO)\",\"year\":2019},{\"arxivId\":\"2008.12470\",\"authors\":[{\"authorId\":\"1688272723\",\"name\":\"Guangshuai Gao\"},{\"authorId\":\"150270468\",\"name\":\"Qingjie Liu\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"}],\"doi\":\"10.1109/tgrs.2020.3020555\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4584520ebf18e0415d3531257cc57c731cae06d8\",\"title\":\"Counting from Sky: A Large-scale Dataset for Remote Sensing Object Counting and A Benchmark Method\",\"url\":\"https://www.semanticscholar.org/paper/4584520ebf18e0415d3531257cc57c731cae06d8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"2896799\",\"name\":\"Ye Zhao\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/BigMM.2018.8499172\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96418bb981ac738468340c7836a8362fa08cc1f2\",\"title\":\"Enhanced Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96418bb981ac738468340c7836a8362fa08cc1f2\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"2010.14709\",\"authors\":[{\"authorId\":\"50581334\",\"name\":\"Y. Chen\"},{\"authorId\":\"1882886\",\"name\":\"Alexander Lerch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a468c22aff082e24366f926c1099984520b9086\",\"title\":\"Melody-Conditioned Lyrics Generation with SeqGANs\",\"url\":\"https://www.semanticscholar.org/paper/7a468c22aff082e24366f926c1099984520b9086\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932765\",\"name\":\"N. Nguyen\"},{\"authorId\":\"50582171\",\"name\":\"R. Thawonmas\"},{\"authorId\":\"144263221\",\"name\":\"Pujana Paliyawan\"},{\"authorId\":\"35221020\",\"name\":\"H. Pham\"}],\"doi\":\"10.1109/CoG47356.2020.9231771\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0518b4777a7acfcd41fffbcc60e474d12bf60c96\",\"title\":\"JUSTIN: An Audience Participation Game With A Purpose for Collecting Descriptions for Artwork Images\",\"url\":\"https://www.semanticscholar.org/paper/0518b4777a7acfcd41fffbcc60e474d12bf60c96\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2018.8486437\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0f0076476fc81a344b8bdec771802a8584dd10f\",\"title\":\"Refining Attention: A Sequential Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0f0076476fc81a344b8bdec771802a8584dd10f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1905.09400\",\"authors\":[{\"authorId\":\"8804979\",\"name\":\"Siddhesh Khandelwal\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3805f0058ac3b320016ca518a98de358aca9823\",\"title\":\"AttentionRNN: A Structured Spatial Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/f3805f0058ac3b320016ca518a98de358aca9823\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.18653/v1/P18-5004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"532837c431617d37c03361ba5a7d5fdb082c55f4\",\"title\":\"Connecting Language and Vision to Actions\",\"url\":\"https://www.semanticscholar.org/paper/532837c431617d37c03361ba5a7d5fdb082c55f4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"30889568\",\"name\":\"Abdulmotaleb El Saddik\"}],\"doi\":\"10.1145/3279952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"title\":\"Deep Learning\\u2013Based Multimedia Analytics\",\"url\":\"https://www.semanticscholar.org/paper/bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510760875\",\"name\":\"Kripesh Adhikari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"308e4aa36906dbb92f325c9c7ce7166ce1da1534\",\"title\":\"Computer vision based posture estimation and fall detection.\",\"url\":\"https://www.semanticscholar.org/paper/308e4aa36906dbb92f325c9c7ce7166ce1da1534\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/978-3-030-31756-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"title\":\"The Encoder-Decoder Framework and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1805.09701\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"29943965\",\"name\":\"Nan Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"}],\"doi\":\"10.1145/3219819.3220036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"title\":\"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"1812.06587\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171a027fc6c7f4194569170accc48187c8bb5aaa\",\"title\":\"Grounded Video Description\",\"url\":\"https://www.semanticscholar.org/paper/171a027fc6c7f4194569170accc48187c8bb5aaa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/978-3-030-00776-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee34a697bc114a5284025648fb9b49f9cdf5e343\",\"title\":\"Video Captioning Based on the Spatial-Temporal Saliency Tracing\",\"url\":\"https://www.semanticscholar.org/paper/ee34a697bc114a5284025648fb9b49f9cdf5e343\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.05764\",\"authors\":[{\"authorId\":\"2988239\",\"name\":\"Fenglong Ma\"},{\"authorId\":\"1776163\",\"name\":\"Radha Chitta\"},{\"authorId\":\"143860023\",\"name\":\"J. Zhou\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"48789476\",\"name\":\"T. Sun\"},{\"authorId\":\"144407304\",\"name\":\"Jing Gao\"}],\"doi\":\"10.1145/3097983.3098088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9b89f35b55c7c75114f532dd9350265dfc5baab\",\"title\":\"Dipole: Diagnosis Prediction in Healthcare via Attention-based Bidirectional Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b9b89f35b55c7c75114f532dd9350265dfc5baab\",\"venue\":\"KDD\",\"year\":2017},{\"arxivId\":\"2012.02128\",\"authors\":[{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"49892954\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"8139616\",\"name\":\"F. Guerin\"},{\"authorId\":\"1510708415\",\"name\":\"Mian Zhou\"}],\"doi\":\"10.1016/j.csl.2020.101169\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1a435ffd06c26f9f4273b11efed10bce2138d08\",\"title\":\"BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/c1a435ffd06c26f9f4273b11efed10bce2138d08\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"1790251284\",\"name\":\"Lin Li\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"9594118\",\"name\":\"C. Gu\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/s11063-020-10352-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"title\":\"Adaptively Converting Auxiliary Attributes and Textual Embedding for Video Captioning Based on BiLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3f1619990d5b61b84bfe268d2e1e7e60de43788e\",\"venue\":\"Neural Process. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2547721\",\"name\":\"M. Fourati\"},{\"authorId\":\"2245992\",\"name\":\"A. Jedidi\"},{\"authorId\":\"9395641\",\"name\":\"F. Gargouri\"}],\"doi\":\"10.1007/s11042-020-09589-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1adfd46f461de181edc64bb783eedee45f55ed7\",\"title\":\"A survey on description and modeling of audiovisual documents\",\"url\":\"https://www.semanticscholar.org/paper/c1adfd46f461de181edc64bb783eedee45f55ed7\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1905.03922\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19659297ac67a29d7524fba60062558f2235f8a\",\"title\":\"Spatio-Temporal Video Re-Localization by Warp LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"47655360\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1445303213\",\"name\":\"Jiaqi Zhao\"},{\"authorId\":\"49353948\",\"name\":\"Mingming Liu\"}],\"doi\":\"10.1016/j.knosys.2020.105920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"title\":\"Remote sensing image captioning via Variational Autoencoder and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"1907.00664\",\"authors\":[{\"authorId\":\"3163480\",\"name\":\"W. Shang\"},{\"authorId\":\"89859445\",\"name\":\"Alex Trott\"},{\"authorId\":\"3393918\",\"name\":\"Stephan Zheng\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66605b6ceae9847156526e46ca9fe467804fca54\",\"title\":\"Learning World Graphs to Accelerate Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/66605b6ceae9847156526e46ca9fe467804fca54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.03949\",\"authors\":[{\"authorId\":\"1699605396\",\"name\":\"Zeyu Wang\"},{\"authorId\":\"114200472\",\"name\":\"Berthy Feng\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":\"10.1007/978-3-030-58571-6_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81be56a5783552d5b32463b392ff0499dd86a5ab\",\"title\":\"Towards Unique and Informative Captioning of Images\",\"url\":\"https://www.semanticscholar.org/paper/81be56a5783552d5b32463b392ff0499dd86a5ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1905.03540\",\"authors\":[{\"authorId\":\"117174671\",\"name\":\"Masahiro Mitsuhara\"},{\"authorId\":\"46362682\",\"name\":\"H. Fukui\"},{\"authorId\":\"27585768\",\"name\":\"Yusuke Sakashita\"},{\"authorId\":\"145404286\",\"name\":\"T. Ogata\"},{\"authorId\":\"8295964\",\"name\":\"Tsubasa Hirakawa\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"1687968\",\"name\":\"H. Fujiyoshi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5393ccde31e38b1f278bc70af0c5b0a9cc758b96\",\"title\":\"Embedding Human Knowledge in Deep Neural Network via Attention Map\",\"url\":\"https://www.semanticscholar.org/paper/5393ccde31e38b1f278bc70af0c5b0a9cc758b96\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"48873711\",\"name\":\"Q. Liu\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"910eb7a8c3f175a9b71680f70303751726bebd30\",\"title\":\"Reference Based LSTM for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/910eb7a8c3f175a9b71680f70303751726bebd30\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1897130\",\"name\":\"X. He\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"49663627\",\"name\":\"W. Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3077136.3080797\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"43c0ff1070def3d98f548b7cbf523fdd4a83827a\",\"title\":\"Attentive Collaborative Filtering: Multimedia Recommendation with Item- and Component-Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/43c0ff1070def3d98f548b7cbf523fdd4a83827a\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sunny Katiyar\"},{\"authorId\":\"88294723\",\"name\":\"M. Wakode\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0881b665590ac2aba58a5b3b7db93c1c4f6af15\",\"title\":\"A Survey On Visual Questioning Answering : Datasets, Approaches And Models\",\"url\":\"https://www.semanticscholar.org/paper/a0881b665590ac2aba58a5b3b7db93c1c4f6af15\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1612.04949\",\"authors\":[{\"authorId\":\"38314901\",\"name\":\"H. Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5793958cd1654b4817ebb57f5484dfd8861f916\",\"title\":\"Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering\",\"url\":\"https://www.semanticscholar.org/paper/b5793958cd1654b4817ebb57f5484dfd8861f916\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d5bb9b38c44448512973e5bbacb5f7468aee2b6\",\"title\":\"Asking Friendly Strangers: Non-Semantic Attribute Transfer\",\"url\":\"https://www.semanticscholar.org/paper/3d5bb9b38c44448512973e5bbacb5f7468aee2b6\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35641549\",\"name\":\"Rucai Zhou\"},{\"authorId\":\"49245946\",\"name\":\"Kuojian Lu\"},{\"authorId\":\"47341671\",\"name\":\"Yi Long\"},{\"authorId\":\"2674321\",\"name\":\"Jiaying Lu\"},{\"authorId\":\"144925373\",\"name\":\"Xinghua Cheng\"},{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"2168143\",\"name\":\"Y. Gu\"}],\"doi\":\"10.1109/BESC.2017.8256394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9146b314812231d09587e3a9f622dda65d3cc40\",\"title\":\"A survey on social image understanding\",\"url\":\"https://www.semanticscholar.org/paper/b9146b314812231d09587e3a9f622dda65d3cc40\",\"venue\":\"2017 International Conference on Behavioral, Economic, Socio-cultural Computing (BESC)\",\"year\":2017},{\"arxivId\":\"1904.04329\",\"authors\":[{\"authorId\":\"38139853\",\"name\":\"Xiaowei Jia\"},{\"authorId\":\"2533995\",\"name\":\"Ankush Khandelwal\"},{\"authorId\":\"40574362\",\"name\":\"Vipin Kumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaed85d6e1ede71eb9b0056b2d53cb19bc4a0bbd\",\"title\":\"Automated Monitoring Cropland Using Remote Sensing Data: Challenges and Opportunities for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/eaed85d6e1ede71eb9b0056b2d53cb19bc4a0bbd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40974715\",\"name\":\"Bhargav Kanuparthi\"},{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"51922896\",\"name\":\"Giancarlo Kerg\"},{\"authorId\":\"145604319\",\"name\":\"Nan Rosemary Ke\"},{\"authorId\":null,\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d17baa369d635c817875dbe32b5e5264926a15f\",\"title\":\"WARDS BETTER OPTIMIZATION\",\"url\":\"https://www.semanticscholar.org/paper/1d17baa369d635c817875dbe32b5e5264926a15f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.01193\",\"authors\":[{\"authorId\":\"8809422\",\"name\":\"Vishwanath Sindagi\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/AVSS.2019.8909889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ae585d4ca4581a5ee218a8d55c22a14d6dfe901\",\"title\":\"Inverse Attention Guided Deep Crowd Counting Network\",\"url\":\"https://www.semanticscholar.org/paper/6ae585d4ca4581a5ee218a8d55c22a14d6dfe901\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ICASSP.2018.8461507\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54969341ec539ddaaf7537b7353e3cea84790eac\",\"title\":\"A Novel Semantic Attribute-Based Feature for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/54969341ec539ddaaf7537b7353e3cea84790eac\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73698428\",\"name\":\"Manan Shah\"},{\"authorId\":\"144494232\",\"name\":\"K. Viswanathan\"},{\"authorId\":\"2828701\",\"name\":\"Chun-Ta Lu\"},{\"authorId\":\"2326719\",\"name\":\"A. Fuxman\"},{\"authorId\":\"49969893\",\"name\":\"Z. Li\"},{\"authorId\":\"50408671\",\"name\":\"A. Timofeev\"},{\"authorId\":\"144711699\",\"name\":\"C. Jia\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"}],\"doi\":\"10.1145/3357384.3357987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eccff2a2fd7b99a4597ec4cb12895a99f1b036db\",\"title\":\"Inferring Context from Pixels for Multimodal Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/eccff2a2fd7b99a4597ec4cb12895a99f1b036db\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71787436\",\"name\":\"F. Xiao\"},{\"authorId\":\"144838968\",\"name\":\"Xue Gong\"},{\"authorId\":\"49890762\",\"name\":\"Yiming Zhang\"},{\"authorId\":\"2879323\",\"name\":\"Yanqing Shen\"},{\"authorId\":\"46276957\",\"name\":\"J. Li\"},{\"authorId\":\"1705421\",\"name\":\"Xieping Gao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f5ec7bdce1acf0415e3c3370b4f634ca3d474cb\",\"title\":\"DAA: Dual LSTMs with adaptive attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f5ec7bdce1acf0415e3c3370b4f634ca3d474cb\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1807.09434\",\"authors\":[{\"authorId\":\"2183432\",\"name\":\"Boeun Kim\"},{\"authorId\":\"49380412\",\"name\":\"Y. Lee\"},{\"authorId\":\"3011724\",\"name\":\"Hyedong Jung\"},{\"authorId\":\"2529532\",\"name\":\"C. S. Cho\"}],\"doi\":\"10.1007/978-3-030-11018-5_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"239a38663967140e026385f6625a913a3e7b1cd7\",\"title\":\"Distinctive-attribute Extraction for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/239a38663967140e026385f6625a913a3e7b1cd7\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2012.05545\",\"authors\":[{\"authorId\":\"67333377\",\"name\":\"Zeliang Song\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"title\":\"Image Captioning with Context-Aware Auxiliary Guidance\",\"url\":\"https://www.semanticscholar.org/paper/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/3292058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"title\":\"Image Captioning With Visual-Semantic Double Attention\",\"url\":\"https://www.semanticscholar.org/paper/1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":\"46908536\",\"name\":\"Jun Yue\"},{\"authorId\":\"7137861\",\"name\":\"Jianzhuang Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1007/978-3-030-58607-2_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"062a6f27a48374d1b53e272747cd9f5c389e768f\",\"title\":\"Large-Scale Few-Shot Learning via Multi-modal Knowledge Discovery\",\"url\":\"https://www.semanticscholar.org/paper/062a6f27a48374d1b53e272747cd9f5c389e768f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387016\",\"name\":\"Ziwei Yang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3123266.3127904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a736b7347fc5ea93c196ddfe0630ecddc17d324\",\"title\":\"Multirate Multimodal Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7a736b7347fc5ea93c196ddfe0630ecddc17d324\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48187964\",\"name\":\"Binbin Hu\"},{\"authorId\":\"40630836\",\"name\":\"Z. Zhang\"},{\"authorId\":\"144123161\",\"name\":\"Chuan Shi\"},{\"authorId\":\"49640379\",\"name\":\"J. Zhou\"},{\"authorId\":\"47057000\",\"name\":\"X. Li\"},{\"authorId\":\"40612590\",\"name\":\"Yuan Qi\"}],\"doi\":\"10.1609/AAAI.V33I01.3301946\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e96899777544e9494ccae0536f77e693bb8ace2a\",\"title\":\"Cash-Out User Detection Based on Attributed Heterogeneous Information Network with a Hierarchical Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e96899777544e9494ccae0536f77e693bb8ace2a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"}],\"doi\":\"10.1007/978-981-10-7299-4_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"title\":\"Automatic Image Description Generation with Emotional Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/89352b9c8114017b9d99d964b4c57203b1f14ebd\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1145/2983563.2983571\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6d6edce271935feec96484d0e1f16dcc24973fd\",\"title\":\"Exploiting Scene Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d6d6edce271935feec96484d0e1f16dcc24973fd\",\"venue\":\"iV&L-MM@MM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50017230\",\"name\":\"Xiaotian Han\"},{\"authorId\":\"143698377\",\"name\":\"C. Shi\"},{\"authorId\":\"3210262\",\"name\":\"Senzhang Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"144157700\",\"name\":\"L. Song\"}],\"doi\":\"10.24963/ijcai.2018/471\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"015395cd36b17f30050c8f2449db669de172200c\",\"title\":\"Aspect-Level Deep Collaborative Filtering via Heterogeneous Information Networks\",\"url\":\"https://www.semanticscholar.org/paper/015395cd36b17f30050c8f2449db669de172200c\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2312163\",\"name\":\"Jirui Yuan\"},{\"authorId\":\"3408277\",\"name\":\"Wenya Ma\"},{\"authorId\":null,\"name\":\"Pengfei Zhu\"},{\"authorId\":\"1683084\",\"name\":\"K. Egiazarian\"}],\"doi\":\"10.1007/978-3-319-70096-0_61\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb22980c53e97539ed5bf64ef2b2afd541e8b0e8\",\"title\":\"Robust Deep Face Recognition with Label Noise\",\"url\":\"https://www.semanticscholar.org/paper/cb22980c53e97539ed5bf64ef2b2afd541e8b0e8\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":\"1901.03729\",\"authors\":[{\"authorId\":\"9553105\",\"name\":\"Upol Ehsan\"},{\"authorId\":\"2018910\",\"name\":\"Pradyumna Tambwekar\"},{\"authorId\":\"152869653\",\"name\":\"L. Chan\"},{\"authorId\":\"35066258\",\"name\":\"B. Harrison\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.1145/3301275.3302316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7df5eae54107c013885231eb7af4431f2e6158\",\"title\":\"Automated rationale generation: a technique for explainable AI and its effects on human perceptions\",\"url\":\"https://www.semanticscholar.org/paper/ef7df5eae54107c013885231eb7af4431f2e6158\",\"venue\":\"IUI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"144474380\",\"name\":\"X. Tang\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"},{\"authorId\":\"33161908\",\"name\":\"C. Li\"}],\"doi\":\"10.3390/rs11060612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"944e93e74379afedced307ca30fc6d31365dc96e\",\"title\":\"Description Generation for Remote Sensing Images Using Attribute Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/944e93e74379afedced307ca30fc6d31365dc96e\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144364295\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"title\":\"TVT: Two-View Transformer Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":\"2007.09903\",\"authors\":[{\"authorId\":\"151257945\",\"name\":\"Xiangyang Mou\"},{\"authorId\":\"1824292863\",\"name\":\"Brandyn Sigouin\"},{\"authorId\":\"1824242400\",\"name\":\"Ian Steenstra\"},{\"authorId\":\"1563539653\",\"name\":\"Hui Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cb2782f61c964e9b207f34c5dd1cb367b0fc561\",\"title\":\"Multimodal Dialogue State Tracking By QA Approach with Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/8cb2782f61c964e9b207f34c5dd1cb367b0fc561\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3123266.3127901\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3609c92bbcad4eaa6e239112fc2cadbf87bb3c33\",\"title\":\"Knowing Yourself: Improving Video Caption via In-depth Recap\",\"url\":\"https://www.semanticscholar.org/paper/3609c92bbcad4eaa6e239112fc2cadbf87bb3c33\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1811.05253\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"Fangyu Wu\"},{\"authorId\":\"33830793\",\"name\":\"Jeremy S. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"Bailing Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"title\":\"Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8353931\",\"name\":\"Jiahe Shi\"},{\"authorId\":\"5550675\",\"name\":\"Y. Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"}],\"doi\":\"10.1109/ICIP.2019.8803149\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8c054cda5375018e902daab0b0875773a854d035\",\"title\":\"Cascade Attention: Multiple Feature Based Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c054cda5375018e902daab0b0875773a854d035\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1438623667\",\"name\":\"Khaled Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afa8032f794011884be0b06f808540f36b404c0b\",\"title\":\"A Short Review on Image Caption Generation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/afa8032f794011884be0b06f808540f36b404c0b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1145/3293353.3293391\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"title\":\"A Bottom-Up and Top-Down Approach for Image Captioning using Transformer\",\"url\":\"https://www.semanticscholar.org/paper/acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685820\",\"name\":\"Jianming Lv\"},{\"authorId\":\"3156477\",\"name\":\"Qinghui Sun\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"},{\"authorId\":\"1409365064\",\"name\":\"Lu\\u00eds Moreira-Matias\"}],\"doi\":\"10.1109/TITS.2019.2924903\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57427a27386f0d8bc9377dc4eee82382b1b9605a\",\"title\":\"Multi-Scale and Multi-Scope Convolutional Neural Networks for Destination Prediction of Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/57427a27386f0d8bc9377dc4eee82382b1b9605a\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"50025928\",\"name\":\"Yuqian Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"}],\"doi\":\"10.1007/s11063-019-09997-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"title\":\"Hierarchical Deep Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1812.05917\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s11263-020-01295-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e50c32f7244e3556eb879f24b7de8410f3177f6\",\"title\":\"Visual Social Relationship Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e50c32f7244e3556eb879f24b7de8410f3177f6\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/CVPR.2018.00808\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"title\":\"Visual Grounding via Accumulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICPR.2018.8545049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c6272a095d6601acf683d9f94c8683009cd1e5c\",\"title\":\"Image Captioning using Adversarial Networks and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3c6272a095d6601acf683d9f94c8683009cd1e5c\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1908.03266\",\"authors\":[{\"authorId\":\"91337137\",\"name\":\"B. Zhang\"},{\"authorId\":\"1805285\",\"name\":\"A. Davoodi\"},{\"authorId\":\"1943030\",\"name\":\"Y. Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a69fdb58224eab55e980c183624497268ad2c43\",\"title\":\"Efficient Inference of CNNs via Channel Pruning\",\"url\":\"https://www.semanticscholar.org/paper/4a69fdb58224eab55e980c183624497268ad2c43\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"51431789\",\"name\":\"Dan Shiebler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"title\":\"Learning what and where to attend\",\"url\":\"https://www.semanticscholar.org/paper/136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peng Zhou\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"40057270\",\"name\":\"Z. Qi\"},{\"authorId\":\"2682574\",\"name\":\"Hongyun Bao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"49821282\",\"name\":\"Bo Xu\"}],\"doi\":\"10.1016/j.neunet.2018.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99f8fe805f276f1cad76339e0e7cb21d34c5d05\",\"title\":\"Distant supervision for relation extraction with hierarchical selective attention\",\"url\":\"https://www.semanticscholar.org/paper/e99f8fe805f276f1cad76339e0e7cb21d34c5d05\",\"venue\":\"Neural Networks\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4421716\",\"name\":\"F. Wang\"},{\"authorId\":\"21776508\",\"name\":\"X. Gong\"},{\"authorId\":\"1754542\",\"name\":\"Linpeng Huang\"}],\"doi\":\"10.1109/ICPR.2018.8545355\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"title\":\"Time-Dependent Pre-attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1702.05658\",\"authors\":[{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"39369840\",\"name\":\"Feng Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.24963/ijcai.2017/563\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2498124e6466ccde28c95477c923e7cd5843f4c0\",\"title\":\"MAT: A Multimodal Attentive Translator for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2498124e6466ccde28c95477c923e7cd5843f4c0\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.09818\",\"authors\":[{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"},{\"authorId\":\"145109280\",\"name\":\"S. Walsh\"},{\"authorId\":\"49051223\",\"name\":\"Junting Zhang\"},{\"authorId\":\"38791445\",\"name\":\"J. Zhang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"title\":\"Generative Visual Dialogue System via Adaptive Reasoning and Weighted Likelihood Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51934339\",\"name\":\"Nuzhat Naqvi\"},{\"authorId\":\"83256875\",\"name\":\"Z. Ye\"}],\"doi\":\"10.1007/s11042-020-09128-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12b53d372b723e201a234786792c6de002244386\",\"title\":\"Image captions: global-local and joint signals attention model (GL-JSAM)\",\"url\":\"https://www.semanticscholar.org/paper/12b53d372b723e201a234786792c6de002244386\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77537913\",\"name\":\"J. Lee\"}],\"doi\":\"10.1007/s11042-019-08011-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2623c1b4aee3f043da30d05f3e2c0f62fca5d5e\",\"title\":\"Deep multimodal embedding for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/c2623c1b4aee3f043da30d05f3e2c0f62fca5d5e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145207212\",\"name\":\"T. Davenport\"},{\"authorId\":\"49609718\",\"name\":\"Abhijit Guha\"},{\"authorId\":\"39957592\",\"name\":\"D. Grewal\"},{\"authorId\":\"1481726023\",\"name\":\"Timna Bressgott\"}],\"doi\":\"10.1007/s11747-019-00696-0\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7\",\"title\":\"How artificial intelligence will change the future of marketing\",\"url\":\"https://www.semanticscholar.org/paper/1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005279478\",\"name\":\"Sreela Sreekumaran Pillai Remadevi Amma\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.25046/aj050447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1226eeb9787b7555e810ee289c4593cb2da04775\",\"title\":\"Keyword Driven Image Description Generation System\",\"url\":\"https://www.semanticscholar.org/paper/1226eeb9787b7555e810ee289c4593cb2da04775\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"1626610869\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1692580\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/TMM.2020.2976552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"title\":\"Integrating Part of Speech Guidance for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02923\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":\"10.1613/jair.1.12025\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"title\":\"Image Captioning using Facial Expression and Attention\",\"url\":\"https://www.semanticscholar.org/paper/29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144063214\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"96363850\",\"name\":\"Mohd Fairuz Shiratuddin\"},{\"authorId\":\"48540238\",\"name\":\"Hamid Laga\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/DICTA47822.2019.8946003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"098833985221f9f30d547dadf24ae7b0f1433ef5\",\"title\":\"Bi-SAN-CAP: Bi-Directional Self-Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/098833985221f9f30d547dadf24ae7b0f1433ef5\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123563\",\"name\":\"Shihao Wang\"},{\"authorId\":\"81983870\",\"name\":\"Hong Mo\"},{\"authorId\":\"1749615\",\"name\":\"Yue Xu\"},{\"authorId\":\"145717893\",\"name\":\"W. Wu\"},{\"authorId\":\"144812501\",\"name\":\"Zhong Zhou\"}],\"doi\":\"10.1007/978-3-030-00764-5_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c48633735a10c2e509374ba7fad8e267f322e1\",\"title\":\"Intra-Image Region Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51c48633735a10c2e509374ba7fad8e267f322e1\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39786961\",\"name\":\"Jingqiang Chen\"},{\"authorId\":\"143632630\",\"name\":\"H. Zhuge\"}],\"doi\":\"10.1109/SKG49510.2019.00029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b85498b500ad86f8114f58a93f3eb344fa354172\",\"title\":\"News Image Captioning Based on Text Summarization Using Image as Query\",\"url\":\"https://www.semanticscholar.org/paper/b85498b500ad86f8114f58a93f3eb344fa354172\",\"venue\":\"2019 15th International Conference on Semantics, Knowledge and Grids (SKG)\",\"year\":2019},{\"arxivId\":\"1611.06492\",\"authors\":[{\"authorId\":\"7284555\",\"name\":\"A. Jain\"},{\"authorId\":\"34762956\",\"name\":\"Abhinav Agarwalla\"},{\"authorId\":\"6565766\",\"name\":\"Kumar Krishna Agrawal\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1109/CVPRW.2017.273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53a41c711b40e7fe3dc2b12e0790933d9c99a6e0\",\"title\":\"Recurrent Memory Addressing for Describing Videos\",\"url\":\"https://www.semanticscholar.org/paper/53a41c711b40e7fe3dc2b12e0790933d9c99a6e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145262833\",\"name\":\"Cara Jones\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61c411c22d21299e46b9477d45ccf188e7d4d396\",\"title\":\"Combating Human Trafficking with Deep Multimodal Models.\",\"url\":\"https://www.semanticscholar.org/paper/61c411c22d21299e46b9477d45ccf188e7d4d396\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581606067\",\"name\":\"Amey Arvind Bhile\"},{\"authorId\":\"144088162\",\"name\":\"V. Hole\"}],\"doi\":\"10.1007/978-3-030-37051-0_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"065544f24bcf2094042355193364cb9d951ef065\",\"title\":\"Real-Time Environment Description Application for Visually Challenged People\",\"url\":\"https://www.semanticscholar.org/paper/065544f24bcf2094042355193364cb9d951ef065\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.09284\",\"authors\":[{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"51055456\",\"name\":\"R. Chen\"},{\"authorId\":\"48443459\",\"name\":\"Lin Nie\"},{\"authorId\":\"144361019\",\"name\":\"Xiaonan Luo\"},{\"authorId\":\"144799773\",\"name\":\"Xiaobai Liu\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/TMM.2018.2870062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9de38f78b3859e3155a7d7fdc3eee362152b4e61\",\"title\":\"Neural Task Planning With AND\\u2013OR Graph Representations\",\"url\":\"https://www.semanticscholar.org/paper/9de38f78b3859e3155a7d7fdc3eee362152b4e61\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746022\",\"name\":\"S. Yin\"},{\"authorId\":\"12263637\",\"name\":\"P. Ouyang\"},{\"authorId\":\"3151232\",\"name\":\"J. Yang\"},{\"authorId\":\"3491203\",\"name\":\"Tianyi Lu\"},{\"authorId\":\"15524575\",\"name\":\"Xiudong Li\"},{\"authorId\":\"1743798\",\"name\":\"L. Liu\"},{\"authorId\":\"1803672\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/JSSC.2018.2881913\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c6bec79e3287b756f0cefa77424097ab8b515e7\",\"title\":\"An Energy-Efficient Reconfigurable Processor for Binary-and Ternary-Weight Neural Networks With Flexible Data Bit Width\",\"url\":\"https://www.semanticscholar.org/paper/6c6bec79e3287b756f0cefa77424097ab8b515e7\",\"venue\":\"IEEE Journal of Solid-State Circuits\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2675822\",\"name\":\"Tushar Karayil\"},{\"authorId\":\"67063678\",\"name\":\"A. Irfan\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"33884920\",\"name\":\"J. Hees\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1007/978-3-030-30490-4_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52941a210e543707b530aa6daf32c18561d8ecc3\",\"title\":\"Conditional GANs for Image Captioning with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/52941a210e543707b530aa6daf32c18561d8ecc3\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"1801.10304\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICPR.2018.8546012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"title\":\"Action Recognition with Visual Attention on Skeleton Images\",\"url\":\"https://www.semanticscholar.org/paper/e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143698008\",\"name\":\"Chang Su\"},{\"authorId\":\"2072772\",\"name\":\"Junchao Li\"},{\"authorId\":\"50747550\",\"name\":\"Ying Peng\"},{\"authorId\":\"49069672\",\"name\":\"Yijiang Chen\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64b9e1f7da77c6dac0444205cb34c085eeef7918\",\"title\":\"Chinese metaphor sentiment computing via considering culture\",\"url\":\"https://www.semanticscholar.org/paper/64b9e1f7da77c6dac0444205cb34c085eeef7918\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11474124\",\"name\":\"Sanjukta Mishra\"},{\"authorId\":\"3094150\",\"name\":\"M. Banerjee\"}],\"doi\":\"10.1007/978-981-15-2930-6_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee22142fb6788e2bb3b695e73df5b3bc36eb20ff\",\"title\":\"Automatic Caption Generation of Retinal Diseases with Self-trained RNN Merge Model\",\"url\":\"https://www.semanticscholar.org/paper/ee22142fb6788e2bb3b695e73df5b3bc36eb20ff\",\"venue\":\"ACSS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145656512\",\"name\":\"C. Xu\"},{\"authorId\":\"48933740\",\"name\":\"Q. Li\"},{\"authorId\":\"3040563\",\"name\":\"Dezheng Zhang\"},{\"authorId\":\"9071205\",\"name\":\"Yonghong Xie\"},{\"authorId\":\"2441414\",\"name\":\"X. Li\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.116\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eee77aae5e2bae2a7645669a2653a77b522831e1\",\"title\":\"Deep successor feature learning for text generation\",\"url\":\"https://www.semanticscholar.org/paper/eee77aae5e2bae2a7645669a2653a77b522831e1\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35282114\",\"name\":\"Chandramani Chaudhary\"},{\"authorId\":\"80968785\",\"name\":\"Poonam Goyal\"},{\"authorId\":\"153089272\",\"name\":\"Dhanashree Nellayi Prasad\"},{\"authorId\":\"152828944\",\"name\":\"Y. P. Chen\"}],\"doi\":\"10.1109/TMM.2019.2937181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77f5755926a0691efebf51c3b48fc71f306d70a9\",\"title\":\"Enhancing the Quality of Image Tagging Using a Visio-Textual Knowledge Base\",\"url\":\"https://www.semanticscholar.org/paper/77f5755926a0691efebf51c3b48fc71f306d70a9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1710.02534\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83d66c1f808962536a68418587b691f30221c5a1\",\"title\":\"Contrastive Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/83d66c1f808962536a68418587b691f30221c5a1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3321318\",\"name\":\"W. Liu\"},{\"authorId\":\"2263674\",\"name\":\"Yidong Li\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/ACCESS.2018.2886597\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40c97ba0f8c50cae18151901c0ea2504bba4e79b\",\"title\":\"An Attribute-Based High-Level Image Representation for Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/40c97ba0f8c50cae18151901c0ea2504bba4e79b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35664579\",\"name\":\"Sahil Chelaramani\"},{\"authorId\":\"35391990\",\"name\":\"Vamsidhar Muthireddy\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/ICCVW.2017.347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6259824432274c8c01ad837b74354a5415e0c00f\",\"title\":\"An Interactive Tour Guide for a Heritage Site\",\"url\":\"https://www.semanticscholar.org/paper/6259824432274c8c01ad837b74354a5415e0c00f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1707.01961\",\"authors\":[{\"authorId\":\"2988239\",\"name\":\"Fenglong Ma\"},{\"authorId\":\"1776163\",\"name\":\"Radha Chitta\"},{\"authorId\":\"35022908\",\"name\":\"S. Kataria\"},{\"authorId\":\"143860023\",\"name\":\"J. Zhou\"},{\"authorId\":\"40327196\",\"name\":\"Palghat Ramesh\"},{\"authorId\":\"48789476\",\"name\":\"T. Sun\"},{\"authorId\":\"144407304\",\"name\":\"Jing Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a373298d9906e70819b3115b5352e39683916e8\",\"title\":\"Long-Term Memory Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4a373298d9906e70819b3115b5352e39683916e8\",\"venue\":\"SML@IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35466168\",\"name\":\"Jian Han Lim\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1109/ICIP.2019.8803004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae7bdb4c9b55080ba781b4737730127c80d04cca\",\"title\":\"Mask Captioning Network\",\"url\":\"https://www.semanticscholar.org/paper/ae7bdb4c9b55080ba781b4737730127c80d04cca\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2008.02980\",\"authors\":[{\"authorId\":\"2896521\",\"name\":\"Ajoy Mondal\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/ICDAR.2019.00210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed0fdc574d304ea7cb890de445e3537569a5e1dc\",\"title\":\"Textual Description for Mathematical Equations\",\"url\":\"https://www.semanticscholar.org/paper/ed0fdc574d304ea7cb890de445e3537569a5e1dc\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723672\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"145402398\",\"name\":\"Pengxu Wei\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/ICME.2017.8019525\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4b5bc8ee9632d7ff2f23e92295189dad9522864\",\"title\":\"Keyword-driven image captioning via Context-dependent Bilateral LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e4b5bc8ee9632d7ff2f23e92295189dad9522864\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"Lorenzo Baraldi\"},{\"authorId\":\"145518528\",\"name\":\"G. Serra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"title\":\"1 Paying More A ention to Saliency : Image Captioning with Saliency and Context A ention\",\"url\":\"https://www.semanticscholar.org/paper/96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405709193\",\"name\":\"Gonzalo Vaca-Castano\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/J.CVIU.2019.02.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0efecabff90401ea60cc5bca791d00f5113fa73\",\"title\":\"Holistic object detection and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0efecabff90401ea60cc5bca791d00f5113fa73\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2988239\",\"name\":\"Fenglong Ma\"},{\"authorId\":\"1776163\",\"name\":\"Radha Chitta\"},{\"authorId\":\"35022908\",\"name\":\"S. Kataria\"},{\"authorId\":\"143860023\",\"name\":\"J. Zhou\"},{\"authorId\":\"144257976\",\"name\":\"P. Ramesh\"},{\"authorId\":\"48789476\",\"name\":\"T. Sun\"},{\"authorId\":\"144407304\",\"name\":\"Jing Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92dd33d0fcaace4293661c87b8fbe4085ec904d1\",\"title\":\"C L ] 6 J ul 2 01 7 Long-Term Memory Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/92dd33d0fcaace4293661c87b8fbe4085ec904d1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115277997\",\"name\":\"J. P. P\\u00e9rez\"}],\"doi\":\"10.4995/THESIS/10251/116834\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4e845ade89998417faec32c136e314e04921138\",\"title\":\"A Probabilistic Formulation of Keyword Spotting\",\"url\":\"https://www.semanticscholar.org/paper/f4e845ade89998417faec32c136e314e04921138\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1611.05321\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cc23e554d98522b377d227dc78e9382a0ed35e5\",\"title\":\"Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8cc23e554d98522b377d227dc78e9382a0ed35e5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"title\":\"When an Image Tells a Story: The Role of Visual and Semantic Information for Generating Paragraph Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":\"10.1007/978-3-030-58523-5_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f692df9ca116884860d580902fa642370bd1be5d\",\"title\":\"Learning to Generate Grounded Visual Captions Without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/f692df9ca116884860d580902fa642370bd1be5d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b32459b8ebed74efed3d29fa6703fff855ea365\",\"title\":\"Task Focused Robotic Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7b32459b8ebed74efed3d29fa6703fff855ea365\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1813915\",\"name\":\"S. Liu\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1145/3240508.3240667\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"849642b4701ac11c035326069f707f23a51a6f1a\",\"title\":\"SibNet: Sibling Convolutional Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/849642b4701ac11c035326069f707f23a51a6f1a\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2007.04239\",\"authors\":[{\"authorId\":\"25098419\",\"name\":\"Zaid Alyafeai\"},{\"authorId\":\"1752627730\",\"name\":\"Maged S. Al-shaibani\"},{\"authorId\":\"72137044\",\"name\":\"I. Ahmad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1801e35a15ded88a68cae1ce721d309445d7044\",\"title\":\"A Survey on Transfer Learning in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/d1801e35a15ded88a68cae1ce721d309445d7044\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576152870\",\"name\":\"Xiaopeng Gong\"},{\"authorId\":\"1752239\",\"name\":\"Xiabi Liu\"},{\"authorId\":\"152998528\",\"name\":\"Yushuo Li\"},{\"authorId\":\"1471524979\",\"name\":\"Huiyu Li\"}],\"doi\":\"10.1016/j.imavis.2020.103973\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e87977613880444a029137a11ca04675a4cacb48\",\"title\":\"A novel co-attention computation block for deep learning based image co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e87977613880444a029137a11ca04675a4cacb48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46336997\",\"name\":\"J. Su\"},{\"authorId\":\"2268783\",\"name\":\"Chenghua Lin\"},{\"authorId\":\"48993818\",\"name\":\"M. Zhou\"},{\"authorId\":\"2457312\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"13036580\",\"name\":\"Haoyu Lv\"}],\"doi\":\"10.18653/v1/W18-6702\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fdb4e6aded4580d9109759240d51cb413e332102\",\"title\":\"Generating Description for Sequential Images with Local-Object Attention Conditioned on Global Semantic Context\",\"url\":\"https://www.semanticscholar.org/paper/fdb4e6aded4580d9109759240d51cb413e332102\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390775558\",\"name\":\"Huizhao Wang\"},{\"authorId\":\"8540458\",\"name\":\"Guanfeng Liu\"},{\"authorId\":\"71078115\",\"name\":\"Y. Zhao\"},{\"authorId\":\"133730578\",\"name\":\"Bolong Zheng\"},{\"authorId\":\"46737566\",\"name\":\"Pengpeng Zhao\"},{\"authorId\":\"144297777\",\"name\":\"Kai Zheng\"}],\"doi\":\"10.1109/ICDM.2019.00071\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71d7bfc4007d93a952bde4677ec5de3b7b9df518\",\"title\":\"DMFP: A Dynamic Multi-faceted Fine-Grained Preference Model for Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/71d7bfc4007d93a952bde4677ec5de3b7b9df518\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"1810.06245\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"58d16e23e1192be4acaf6a29c1f5995817146554\",\"title\":\"Bringing back simplicity and lightliness into neural image captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d16e23e1192be4acaf6a29c1f5995817146554\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1438623667\",\"name\":\"Khaled Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/CSCI49370.2019.00055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d4a2308f7ce78cf0a28dcf5873348baccc036ce\",\"title\":\"Image Captioning with Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/1d4a2308f7ce78cf0a28dcf5873348baccc036ce\",\"venue\":\"2019 International Conference on Computational Science and Computational Intelligence (CSCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46447554\",\"name\":\"Xiaodong Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1109/ACCESS.2019.2917979\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"title\":\"Cascade Semantic Fusion for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2719746\",\"name\":\"Parag Jain\"},{\"authorId\":\"49774944\",\"name\":\"P. Agrawal\"},{\"authorId\":\"1746093\",\"name\":\"A. Mishra\"},{\"authorId\":\"3026786\",\"name\":\"M. Sukhwani\"},{\"authorId\":\"2039596\",\"name\":\"Anirban Laha\"},{\"authorId\":\"145590185\",\"name\":\"K. Sankaranarayanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b551c5893504f581a76a4dd8a423f18a07b6681c\",\"title\":\"Generation from Sequence of Independent Short Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/b551c5893504f581a76a4dd8a423f18a07b6681c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"47666390\",\"name\":\"H. Chen\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/s12559-018-9581-x\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"title\":\"Neural Image Caption Generation with Weighted Training and Reference\",\"url\":\"https://www.semanticscholar.org/paper/848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"venue\":\"Cognitive Computation\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9741677\",\"name\":\"Senmao Ye\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"}],\"doi\":\"10.1109/TIP.2018.2855406\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"title\":\"Attentive Linear Transformation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.10061\",\"authors\":[{\"authorId\":\"145759966\",\"name\":\"Amir Sadeghian\"},{\"authorId\":\"29836452\",\"name\":\"Ferdinand Legros\"},{\"authorId\":\"49158553\",\"name\":\"Maxime Voisin\"},{\"authorId\":\"11138817\",\"name\":\"Ricky Vesel\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1007/978-3-030-01252-6_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e36e6fbd7b33e37b9b68eab8d50ef49840987ea\",\"title\":\"CAR-Net: Clairvoyant Attentive Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/3e36e6fbd7b33e37b9b68eab8d50ef49840987ea\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"L. Wang\"},{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1007/s11280-018-0601-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"021d345baad22d5d81fec99572edbf1bfec55e7c\",\"title\":\"An emotion-based responding model for natural language conversation\",\"url\":\"https://www.semanticscholar.org/paper/021d345baad22d5d81fec99572edbf1bfec55e7c\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1904.09544\",\"authors\":[{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1016/j.neucom.2018.10.059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dfb603674cc927ba65f056a54738734cbb348b2\",\"title\":\"3G structure for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/7dfb603674cc927ba65f056a54738734cbb348b2\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"46321465\",\"name\":\"Sheng Tang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"4303531\",\"name\":\"Lixi Deng\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TMM.2017.2751140\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"title\":\"GLA: Global\\u2013Local Attention for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49813626\",\"name\":\"Y. Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eecfaf49500434d91970b24831081d5d2c68697e\",\"title\":\"Sequence to Sequence Model for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eecfaf49500434d91970b24831081d5d2c68697e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49693266\",\"name\":\"L. Yue\"},{\"authorId\":\"145460246\",\"name\":\"Xin Miao\"},{\"authorId\":\"3127895\",\"name\":\"P. Wang\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86b6afc667bb14ff4d69e7a5e8bb2454a6bbd2cd\",\"title\":\"Attentional Alignment Networks\",\"url\":\"https://www.semanticscholar.org/paper/86b6afc667bb14ff4d69e7a5e8bb2454a6bbd2cd\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1807.03514\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1109/ICIP.2018.8451083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdab688a49bb873d36ae638c647d6ca9e3d75d18\",\"title\":\"Topic-Guided Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fdab688a49bb873d36ae638c647d6ca9e3d75d18\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145801638\",\"name\":\"J. Kittler\"},{\"authorId\":\"1685743\",\"name\":\"J. Mitchell\"},{\"authorId\":\"1693267\",\"name\":\"M. Naor\"}],\"doi\":\"10.1007/978-3-319-68560-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d28d83d1cead0f5d6a2ac75cfaf1139f5b93977\",\"title\":\"Image Analysis and Processing - ICIAP 2017\",\"url\":\"https://www.semanticscholar.org/paper/3d28d83d1cead0f5d6a2ac75cfaf1139f5b93977\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.1007/978-3-030-01237-3_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"title\":\"NNEval: Neural Network Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"3261071\",\"name\":\"M. Shah\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":\"10.1109/CVPR.2019.00438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f500cc63c446a2c897122008e3d9295cad21bd\",\"title\":\"Pay Attention! - Robustifying a Deep Visuomotor Policy Through Task-Focused Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/83f500cc63c446a2c897122008e3d9295cad21bd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6159653\",\"name\":\"K. Thapa\"}],\"doi\":\"10.18122/td/1446/boisestate\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2fc77c798afc1f9db50674fd9aec52e5444d14c\",\"title\":\"Detecting Saliency by Combining Speech and Object Detection in Indoor Environments\",\"url\":\"https://www.semanticscholar.org/paper/c2fc77c798afc1f9db50674fd9aec52e5444d14c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2019.2916757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"title\":\"CAM-RNN: Co-Attention Model Based RNN for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49658047\",\"name\":\"Haifang Qin\"},{\"authorId\":\"3493754\",\"name\":\"Weixiang Hong\"},{\"authorId\":\"1761842\",\"name\":\"Wei-Chih Hung\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ea2fb93e755ac510b8d0e496ee62a3d77c1b438\",\"title\":\"A Top-Down Unified Framework for Instance-level Human Parsing\",\"url\":\"https://www.semanticscholar.org/paper/9ea2fb93e755ac510b8d0e496ee62a3d77c1b438\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22066021\",\"name\":\"Xishan Zhang\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"2069818\",\"name\":\"D. Zhang\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2017.662\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b0b706fc94b35a1eddd830685e07870315b9565\",\"title\":\"Task-Driven Dynamic Fusion: Reducing Ambiguity in Video Description\",\"url\":\"https://www.semanticscholar.org/paper/3b0b706fc94b35a1eddd830685e07870315b9565\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144654777\",\"name\":\"Ke Bai\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.1609/AAAI.V34I05.6249\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"826db2e5f340a90fc9672279f9e921b596aba4b7\",\"title\":\"Sequence Generation with Optimal-Transport-Enhanced Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/826db2e5f340a90fc9672279f9e921b596aba4b7\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1910.02974\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICRA40945.2020.9196653\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe6f2a08cb8911d52533a413b071638d0463f10a\",\"title\":\"SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability\",\"url\":\"https://www.semanticscholar.org/paper/fe6f2a08cb8911d52533a413b071638d0463f10a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958420\",\"name\":\"Tianyi Wang\"},{\"authorId\":\"47539594\",\"name\":\"Jiang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1007/978-3-030-00776-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c50c91875767ec7c6391d99d30838d90275a0f1b\",\"title\":\"Collaborative Detection and Caption Network\",\"url\":\"https://www.semanticscholar.org/paper/c50c91875767ec7c6391d99d30838d90275a0f1b\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113519586\",\"name\":\"T. X. Dang\"},{\"authorId\":\"31704596\",\"name\":\"A. Oh\"},{\"authorId\":\"9483271\",\"name\":\"In-Seop Na\"},{\"authorId\":\"2183069\",\"name\":\"S. Kim\"}],\"doi\":\"10.1145/3310986.3311002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"title\":\"The Role of Attention Mechanism and Multi-Feature in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"venue\":\"ICMLSC 2019\",\"year\":2019},{\"arxivId\":\"1804.00819\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/CVPR.2018.00911\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"35ed258aede3df17ee20a6635364cb5fd2461049\",\"title\":\"End-to-End Dense Video Captioning with Masked Transformer\",\"url\":\"https://www.semanticscholar.org/paper/35ed258aede3df17ee20a6635364cb5fd2461049\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1856671082\",\"name\":\"Shengjia Chen\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1145/3340531.3411948\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3428bac9141f6db961fc4665db1cbc9a196152da\",\"title\":\"Image Captioning with Internal and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3428bac9141f6db961fc4665db1cbc9a196152da\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1434552260\",\"name\":\"S. Selvam\"},{\"authorId\":\"145848804\",\"name\":\"Deepak Mishra\"}],\"doi\":\"10.1007/978-3-030-34869-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8e2ee629f3c4f7e5c055ede29f84af66bf4b955\",\"title\":\"Multi-scale Attention Aided Multi-Resolution Network for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/a8e2ee629f3c4f7e5c055ede29f84af66bf4b955\",\"venue\":\"PReMI\",\"year\":2019},{\"arxivId\":\"1804.00887\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dc2c3be0796f65154d2106ed4442889c84546df\",\"title\":\"Learning to Guide Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3dc2c3be0796f65154d2106ed4442889c84546df\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1905.03466\",\"authors\":[{\"authorId\":\"144529125\",\"name\":\"Kai Su\"},{\"authorId\":\"2223692\",\"name\":\"Dongdong Yu\"},{\"authorId\":\"3414892\",\"name\":\"Z. Xu\"},{\"authorId\":\"1735299\",\"name\":\"X. Geng\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00582\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a4879ab3ae5a506bc836c905bb7ae86c3556b9a\",\"title\":\"Multi-Person Pose Estimation With Enhanced Channel-Wise and Spatial Information\",\"url\":\"https://www.semanticscholar.org/paper/6a4879ab3ae5a506bc836c905bb7ae86c3556b9a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924571\",\"name\":\"Jing Wang\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413753\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"021d50ba5ae1c66e9175428f546976798126dd9f\",\"title\":\"Multimodal Attention with Image Text Spatial Relationship for OCR-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/021d50ba5ae1c66e9175428f546976798126dd9f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3313556\",\"name\":\"Jinna Lv\"},{\"authorId\":\"1699037\",\"name\":\"Bin Wu\"}],\"doi\":\"10.1007/978-3-030-05716-9_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ad27de4fe1b86b7e01ccf7bb0fbff99cc02ecb8\",\"title\":\"Spatio-Temporal Attention Model Based on Multi-view for Social Relation Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5ad27de4fe1b86b7e01ccf7bb0fbff99cc02ecb8\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145865760\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3240508.3240527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81b3cfd55ca84802cdcc971410e633ed40e04980\",\"title\":\"Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/81b3cfd55ca84802cdcc971410e633ed40e04980\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387016\",\"name\":\"Ziwei Yang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"50219447\",\"name\":\"Zheng Wang\"}],\"doi\":\"10.1145/3123266.3123327\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"abc2e6431a7092fb11418b79ca1c41a76b811ea0\",\"title\":\"Catching the Temporal Regions-of-Interest for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/abc2e6431a7092fb11418b79ca1c41a76b811ea0\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49701439\",\"name\":\"Van-Khanh Tran\"},{\"authorId\":\"145184546\",\"name\":\"L. Nguyen\"}],\"doi\":\"10.1016/j.neucom.2018.09.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35b7b10d5d26876ce517b91a6c90be78e57375a3\",\"title\":\"Gating mechanism based Natural Language Generation for spoken dialogue systems\",\"url\":\"https://www.semanticscholar.org/paper/35b7b10d5d26876ce517b91a6c90be78e57375a3\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TCSVT.2018.2864148\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"title\":\"Action Recognition With Spatio\\u2013Temporal Visual Attention on Skeleton Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1909.02072\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00921\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"title\":\"Large-Scale Tag-Based Font Retrieval With Generative Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1805.02459\",\"authors\":[{\"authorId\":\"48986542\",\"name\":\"L. Jin\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"49243317\",\"name\":\"K. Li\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":\"10.1109/TIP.2018.2883522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e59e88ec6c3ad81feecee7645a6cfd80c04b2688\",\"title\":\"Deep Ordinal Hashing With Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/e59e88ec6c3ad81feecee7645a6cfd80c04b2688\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"78507285\",\"name\":\"Zhiping Zhou\"},{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/s11042-019-08165-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"title\":\"An image retrieval method based on semantic matching with multiple positional representations\",\"url\":\"https://www.semanticscholar.org/paper/0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"46867445\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9305704\",\"name\":\"Xiaosheng Yu\"}],\"doi\":\"10.1155/2020/3062706\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"title\":\"An Overview of Image Caption Generation Methods\",\"url\":\"https://www.semanticscholar.org/paper/4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"2011.04349\",\"authors\":[{\"authorId\":\"2007739187\",\"name\":\"Hieu Trong Phung\"},{\"authorId\":\"39722350\",\"name\":\"A. Vu\"},{\"authorId\":\"49035142\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2007743298\",\"name\":\"Lam Thanh Do\"},{\"authorId\":\"2007740386\",\"name\":\"Giang Nam Ngo\"},{\"authorId\":\"34505180\",\"name\":\"T. T. Tran\"},{\"authorId\":\"2007738281\",\"name\":\"N. C. L. P. Vietnam\"},{\"authorId\":\"89934810\",\"name\":\"Hanoi\"},{\"authorId\":\"2007739185\",\"name\":\"Vietnam. Hanoi University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"67001972\",\"name\":\"H\\u00e0 N\\u1ed9i\"},{\"authorId\":\"4601368\",\"name\":\"V. Nam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7fa8e15dcab4be4fecdaa6669186162037c8f87\",\"title\":\"MAGNeto: An Efficient Deep Learning Method for the Extractive Tags Summarization Problem\",\"url\":\"https://www.semanticscholar.org/paper/c7fa8e15dcab4be4fecdaa6669186162037c8f87\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.13151\",\"authors\":[{\"authorId\":\"8010189\",\"name\":\"Xinjie Fan\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1471411319\",\"name\":\"Zhendong Wang\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa950171b25c05466d9d3cc58dff3b9ea9882e4a\",\"title\":\"Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/aa950171b25c05466d9d3cc58dff3b9ea9882e4a\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1710.06303\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2168767\",\"name\":\"Umanga Bista\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1748257\",\"name\":\"Achim Rettinger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"631a1571d1a073369ec7c98e196de07e263ae130\",\"title\":\"Describing Natural Images Containing Novel Objects with Knowledge Guided Assitance\",\"url\":\"https://www.semanticscholar.org/paper/631a1571d1a073369ec7c98e196de07e263ae130\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9104886\",\"name\":\"Yuefeng Liu\"},{\"authorId\":\"3049407\",\"name\":\"G. Zhao\"},{\"authorId\":\"32716995\",\"name\":\"Xiyuan Peng\"},{\"authorId\":\"145850271\",\"name\":\"Cong Hu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e749d46798efd2e398dab45fe6277e4f1ffbafea\",\"title\":\"Lithium-ion Battery Remaining Useful Life Prediction with Long Short-term Memory Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/e749d46798efd2e398dab45fe6277e4f1ffbafea\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34153289\",\"name\":\"Anqi Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3226037\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f164313e63d5c6d0a5f4b55fd0ffcc25c436bc14\",\"title\":\"Image Captioning with Affective Guiding and Selective Attention\",\"url\":\"https://www.semanticscholar.org/paper/f164313e63d5c6d0a5f4b55fd0ffcc25c436bc14\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.03918\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00271\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"05106b86ec45914d1136719d311078182d437872\",\"title\":\"Hierarchy Parsing for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/05106b86ec45914d1136719d311078182d437872\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2915033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"title\":\"Deep Hierarchical Encoder\\u2013Decoder Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93366346\",\"name\":\"C. Wu\"},{\"authorId\":\"2601342\",\"name\":\"Chih-Yang Lin\"},{\"authorId\":\"1492122868\",\"name\":\"Phanuvich Hirunsirisombut\"},{\"authorId\":\"39259570\",\"name\":\"Hui-Fuang Ng\"},{\"authorId\":\"2215094\",\"name\":\"T. Shih\"}],\"doi\":\"10.1109/ISPACS48206.2019.8986381\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7238f61f50a8e4eef895f81a7b0a293d7ea63daa\",\"title\":\"Searching ROI for Object Detection based on CNN\",\"url\":\"https://www.semanticscholar.org/paper/7238f61f50a8e4eef895f81a7b0a293d7ea63daa\",\"venue\":\"2019 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)\",\"year\":2019},{\"arxivId\":\"1612.00234\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"}],\"doi\":\"10.1162/tacl_a_00013\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5a732016c3f74dc7d78899bf33cf25df03ef46b4\",\"title\":\"Video Captioning with Multi-Faceted Attention\",\"url\":\"https://www.semanticscholar.org/paper/5a732016c3f74dc7d78899bf33cf25df03ef46b4\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":\"2004.14638\",\"authors\":[{\"authorId\":\"7475040\",\"name\":\"S. Tan\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"144393479\",\"name\":\"D. Guo\"},{\"authorId\":\"2323566\",\"name\":\"Fu-Chun Sun\"}],\"doi\":\"10.15607/rss.2020.xvi.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be6f591cfa15a23a13ea09b336f794601ba5eeca\",\"title\":\"Towards Embodied Scene Description\",\"url\":\"https://www.semanticscholar.org/paper/be6f591cfa15a23a13ea09b336f794601ba5eeca\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":\"2004.10966\",\"authors\":[{\"authorId\":\"1389550960\",\"name\":\"Tasmia Tasrin\"},{\"authorId\":\"1381931976\",\"name\":\"Md Sultan Al Nahian\"},{\"authorId\":\"34442699\",\"name\":\"B. Harrison\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"title\":\"Visual Question Answering Using Semantic Information from Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/32b2ed6a8eba971cdcd343af0dc5171636a268b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"49ac61eed8301f41da85e0053be3be790293faac\",\"title\":\"Recurrent Highway Networks with Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49ac61eed8301f41da85e0053be3be790293faac\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1145/3239576.3239580\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"title\":\"Video Captioning using Hierarchical Multi-Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"venue\":\"ICAIP '18\",\"year\":2018},{\"arxivId\":\"2010.01288\",\"authors\":[{\"authorId\":\"144407296\",\"name\":\"J. Gao\"},{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"2721708\",\"name\":\"P. Yu\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8405576136062ea661febeeedbc5076235d5eb42\",\"title\":\"Unsupervised Cross-lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8405576136062ea661febeeedbc5076235d5eb42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92716077\",\"name\":\"Shaokang Yang\"},{\"authorId\":\"122218340\",\"name\":\"J. Niu\"},{\"authorId\":\"1809483\",\"name\":\"Jiyan Wu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"}],\"doi\":\"10.1007/978-3-030-60248-2_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"title\":\"Automatic Medical Image Report Generation with Multi-view and Multi-modal Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"venue\":\"ICA3PP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46507431\",\"name\":\"H. Wang\"},{\"authorId\":\"18083732\",\"name\":\"H. Jia\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144344681\",\"name\":\"Y. Xia\"}],\"doi\":\"10.1109/JBHI.2019.2928369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4baf5daed4a0d1a905ebc96de5311eac0b96264\",\"title\":\"Thorax-Net: An Attention Regularized Deep Neural Network for Classification of Thoracic Diseases on Chest Radiography\",\"url\":\"https://www.semanticscholar.org/paper/f4baf5daed4a0d1a905ebc96de5311eac0b96264\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35514628\",\"name\":\"Sanyi Zhang\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"39389412\",\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TCSVT.2019.2902268\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf71e9e41ccdf0fcf4c1809e94a1de920913bfff\",\"title\":\"Task-Aware Attention Model for Clothing Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cf71e9e41ccdf0fcf4c1809e94a1de920913bfff\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101726081\",\"name\":\"S. Rawat\"},{\"authorId\":\"1992911636\",\"name\":\"Kartikeyan Singh Rawat\"},{\"authorId\":\"1381574702\",\"name\":\"Rahul Nijhawan\"}],\"doi\":\"10.1109/ICSSIT48917.2020.9214109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c73865aa2634a5e6b0099fe49221d1e56a2b875\",\"title\":\"A Novel Convolutional Neural Network-Gated Recurrent Unit approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0c73865aa2634a5e6b0099fe49221d1e56a2b875\",\"venue\":\"2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"144675299\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"title\":\"The Fashion IQ Dataset: Retrieving Images by Combining Side Information and Relative Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.04613\",\"authors\":[{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2181925\",\"name\":\"Mingkun Yang\"},{\"authorId\":\"10344582\",\"name\":\"Pengyuan Lyu\"},{\"authorId\":\"9510649\",\"name\":\"Yongchao Xu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ACCESS.2018.2878899\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4285cd81d5d5c91f6322bade859364827c404f21\",\"title\":\"Integrating Scene Text and Visual Appearance for Fine-Grained Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/4285cd81d5d5c91f6322bade859364827c404f21\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1901.05127\",\"authors\":[{\"authorId\":\"144779803\",\"name\":\"Y. Yao\"},{\"authorId\":\"40363985\",\"name\":\"Jianqiang Ren\"},{\"authorId\":\"65863521\",\"name\":\"Xuansong Xie\"},{\"authorId\":\"40474857\",\"name\":\"Weidong Liu\"},{\"authorId\":\"1715826\",\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/CVPR.2019.00156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85f309e0958a70231c993c4b353fb6412cbcb7bb\",\"title\":\"Attention-Aware Multi-Stroke Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/85f309e0958a70231c993c4b353fb6412cbcb7bb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1809.04835\",\"authors\":[{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"144326612\",\"name\":\"P. Li\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"2960930\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1145/3240876.3240900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dec04588b73efb1192d1778b2b818842ccd242e7\",\"title\":\"Image captioning based on deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/dec04588b73efb1192d1778b2b818842ccd242e7\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":\"1708.00634\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/ICCV.2017.289\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2cbdd5f24c2d6a4f33734636cc220f0825042f0\",\"title\":\"Dual-Glance Model for Deciphering Social Relationships\",\"url\":\"https://www.semanticscholar.org/paper/f2cbdd5f24c2d6a4f33734636cc220f0825042f0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1908.02127\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"145851264\",\"name\":\"Wei Luo\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"133921bb5e559de464c0078f5fa67409aca27917\",\"title\":\"Aligning Linguistic Words and Visual Semantic Units for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/133921bb5e559de464c0078f5fa67409aca27917\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"}],\"doi\":\"10.1109/TGRS.2019.2951636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a86714cb7ac711054244aeea51a55715e679ebb\",\"title\":\"Sound Active Attention Framework for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2a86714cb7ac711054244aeea51a55715e679ebb\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2020.2969791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"title\":\"Multimedia Intelligence: When Multimedia Meets Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3071906\",\"name\":\"Anna Fariha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"001dc49f7f3348841b4086f966bfe4e9dfadf03e\",\"title\":\"Automatic image captioning using multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/001dc49f7f3348841b4086f966bfe4e9dfadf03e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134881509\",\"name\":\"Xiucong Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e75b28c77c83b3281541b6b9a0222de615ab78b\",\"title\":\"Image Description Generation in Chinese Based on Keywords Guidance\",\"url\":\"https://www.semanticscholar.org/paper/7e75b28c77c83b3281541b6b9a0222de615ab78b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"}],\"doi\":\"10.1145/3240508.3240583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"title\":\"Look Deeper See Richer: Depth-aware Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39786961\",\"name\":\"Jingqiang Chen\"},{\"authorId\":\"143632630\",\"name\":\"H. Zhuge\"}],\"doi\":\"10.18653/v1/D18-1438\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a52cb3d840d7250a87fc9be92be1abaa377d82\",\"title\":\"Abstractive Text-Image Summarization Using Multi-Modal Attentional Hierarchical RNN\",\"url\":\"https://www.semanticscholar.org/paper/f8a52cb3d840d7250a87fc9be92be1abaa377d82\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1908.02943\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"},{\"authorId\":\"119899233\",\"name\":\"Len Hamey\"}],\"doi\":\"10.1007/978-3-030-29908-8_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d236d1415ac9a52ec599f0c100e15589cfceefd9\",\"title\":\"Towards Generating Stylized Image Captions via Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/d236d1415ac9a52ec599f0c100e15589cfceefd9\",\"venue\":\"PRICAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153389909\",\"name\":\"J. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11b46d998c2642e672fd6414750e8a3c1d08d2c7\",\"title\":\"Vision to keywords : automatic image annotation by filling the semantic gap\",\"url\":\"https://www.semanticscholar.org/paper/11b46d998c2642e672fd6414750e8a3c1d08d2c7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2914388\",\"name\":\"S. Chen\"},{\"authorId\":\"47780682\",\"name\":\"B. Wang\"},{\"authorId\":\"51121938\",\"name\":\"Xiuli Tan\"},{\"authorId\":\"2510651\",\"name\":\"Xuelong Hu\"}],\"doi\":\"10.1109/TCYB.2018.2879859\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b4340ed442a9c741c716583c674809bee13af30\",\"title\":\"Embedding Attention and Residual Network for Accurate Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/4b4340ed442a9c741c716583c674809bee13af30\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":\"1611.06607\",\"authors\":[{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.356\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a7011346ce939e3251915e92ae2f252e4c7f777\",\"title\":\"A Hierarchical Approach for Generating Descriptive Image Paragraphs\",\"url\":\"https://www.semanticscholar.org/paper/3a7011346ce939e3251915e92ae2f252e4c7f777\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.07102\",\"authors\":[{\"authorId\":\"8135633\",\"name\":\"Xuwang Yin\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":\"10.18653/v1/D17-1017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cc6ba3dfd6bf1f6257b2e4651f4cae355284286\",\"title\":\"Obj2Text: Generating Visually Descriptive Language from Object Layouts\",\"url\":\"https://www.semanticscholar.org/paper/2cc6ba3dfd6bf1f6257b2e4651f4cae355284286\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60af58a2435fe758fe9a172f2009efbb89584f58\",\"title\":\"Temporal-Difference Learning With Sampling Baseline for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/60af58a2435fe758fe9a172f2009efbb89584f58\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50581334\",\"name\":\"Y. Chen\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1007/s11042-018-6228-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"title\":\"Looking deeper and transferring attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1909.08453\",\"authors\":[{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"7533195\",\"name\":\"Desen Zhou\"},{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"2332078\",\"name\":\"Rongjie Li\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/ICCV.2019.00956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"title\":\"Pose-Aware Multi-Level Feature Network for Human Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/1273b8f7bd7e93039329c4beeaf29082abfd74f2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.13977\",\"authors\":[{\"authorId\":\"1602300910\",\"name\":\"Rodrigo de Medrano\"},{\"authorId\":\"2151784\",\"name\":\"J. Aznarte\"}],\"doi\":\"10.1016/j.asoc.2020.106615\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ba84438c0c4b88ece7cc07773e5fc4c15ef01ae\",\"title\":\"A Spatio-Temporal Spot-Forecasting Framework forUrban Traffic Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0ba84438c0c4b88ece7cc07773e5fc4c15ef01ae\",\"venue\":\"Appl. Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49287373\",\"name\":\"Lele Xu\"},{\"authorId\":\"47001996\",\"name\":\"Yu-xiang Li\"},{\"authorId\":\"2341356\",\"name\":\"Jinzhong Xu\"},{\"authorId\":\"46846090\",\"name\":\"Lili Guo\"}],\"doi\":\"10.1016/j.compag.2020.105281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f1981d60b797050daea8a2c44add7fdd28f36ca\",\"title\":\"Two-level attention and score consistency network for plant segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5f1981d60b797050daea8a2c44add7fdd28f36ca\",\"venue\":\"Comput. Electron. Agric.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900967\",\"name\":\"U. Zia\"},{\"authorId\":\"145759322\",\"name\":\"M. M. Riaz\"},{\"authorId\":\"144683577\",\"name\":\"A. Ghafoor\"},{\"authorId\":\"145602758\",\"name\":\"Seyyed Salehi Seyyed Ali\"}],\"doi\":\"10.1007/s00521-019-04587-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"title\":\"Topic sensitive image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1903.06586\",\"authors\":[{\"authorId\":\"40613617\",\"name\":\"Xiang Li\"},{\"authorId\":\"2405376\",\"name\":\"Wenhai Wang\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"},{\"authorId\":null,\"name\":\"Jian Yang\"}],\"doi\":\"10.1109/CVPR.2019.00060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb8cf663a71bf31f59557a35d36aaf8c465b50af\",\"title\":\"Selective Kernel Networks\",\"url\":\"https://www.semanticscholar.org/paper/fb8cf663a71bf31f59557a35d36aaf8c465b50af\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151497541\",\"name\":\"X. Meng\"},{\"authorId\":\"151474857\",\"name\":\"Hao Kong\"},{\"authorId\":\"151486196\",\"name\":\"D. Tang\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"}],\"doi\":\"10.1109/ICME.2019.00229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95ddec4b0ab0024da1e80b66b0a29e0102c0b8fe\",\"title\":\"Multimodal Image Captioning Through Combining Reinforced Cross Entropy Loss and Stochastic Deprecation\",\"url\":\"https://www.semanticscholar.org/paper/95ddec4b0ab0024da1e80b66b0a29e0102c0b8fe\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121104319\",\"name\":\"Rehab Alahmadi\"},{\"authorId\":\"1695172\",\"name\":\"C. H. Park\"},{\"authorId\":\"36266636\",\"name\":\"J. Hahn\"}],\"doi\":\"10.1117/12.2523174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"title\":\"Sequence-to-sequence image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"venue\":\"International Conference on Machine Vision\",\"year\":2019},{\"arxivId\":\"1909.06814\",\"authors\":[{\"authorId\":\"41019330\",\"name\":\"Leshem Choshen\"},{\"authorId\":\"2769805\",\"name\":\"Omri Abend\"}],\"doi\":\"10.18653/v1/K19-1028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68755920089b78a99ee400bc8eb03ee387e2fcc2\",\"title\":\"Automatically Extracting Challenge Sets for Non local Phenomena in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/68755920089b78a99ee400bc8eb03ee387e2fcc2\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1811.08513\",\"authors\":[{\"authorId\":\"47136049\",\"name\":\"Naofumi Tomita\"},{\"authorId\":\"11119215\",\"name\":\"Behnaz Abdollahi\"},{\"authorId\":\"144026731\",\"name\":\"Jason Wei\"},{\"authorId\":\"39126167\",\"name\":\"B. Ren\"},{\"authorId\":\"3583138\",\"name\":\"A. Suriawinata\"},{\"authorId\":\"145945685\",\"name\":\"Saeed Hassanpour\"}],\"doi\":\"10.1001/jamanetworkopen.2019.14645\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c905336040178313b5ade3da6531246bf94107\",\"title\":\"Attention-Based Deep Neural Networks for Detection of Cancerous and Precancerous Esophagus Tissue on Histopathological Slides\",\"url\":\"https://www.semanticscholar.org/paper/79c905336040178313b5ade3da6531246bf94107\",\"venue\":\"JAMA network open\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1505428993\",\"name\":\"Xiaowei Jia\"},{\"authorId\":\"2533995\",\"name\":\"Ankush Khandelwal\"},{\"authorId\":\"2580238\",\"name\":\"D. Mulla\"},{\"authorId\":\"119329451\",\"name\":\"Philip G. Pardey\"},{\"authorId\":\"152535947\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1111/agec.12531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b059884891e2b9636afb6e30ccfa6cb447567ca\",\"title\":\"Bringing automated, remote\\u2010sensed, machine learning methods to monitoring crop landscapes at scale\",\"url\":\"https://www.semanticscholar.org/paper/7b059884891e2b9636afb6e30ccfa6cb447567ca\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.02880\",\"authors\":[{\"authorId\":\"9719114\",\"name\":\"Zachary E. Ross\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"},{\"authorId\":\"145114940\",\"name\":\"Men-Andrin Meier\"},{\"authorId\":\"4173721\",\"name\":\"E. Hauksson\"},{\"authorId\":\"2704565\",\"name\":\"T. Heaton\"}],\"doi\":\"10.1029/2018JB016674\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45ee9f90183ad294f1afea054b6953f20d29ae54\",\"title\":\"PhaseLink: A Deep Learning Approach to Seismic Phase Association\",\"url\":\"https://www.semanticscholar.org/paper/45ee9f90183ad294f1afea054b6953f20d29ae54\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"}],\"doi\":\"10.1007/978-3-030-29516-5_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"422910cd883a39a42e40d6630997c95cb1864d44\",\"title\":\"Anticipating Next Goal for Robot Plan Prediction\",\"url\":\"https://www.semanticscholar.org/paper/422910cd883a39a42e40d6630997c95cb1864d44\",\"venue\":\"IntelliSys\",\"year\":2019},{\"arxivId\":\"2011.01385\",\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"123275544\",\"name\":\"Jian Zhang\"},{\"authorId\":\"47506551\",\"name\":\"Qiang Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"title\":\"Dual Attention on Pyramid Feature Maps for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10787\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"40474876\",\"name\":\"Wei Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00425\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"580fd9a601314ea32dc85ec98267b411dd3465cf\",\"title\":\"Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/580fd9a601314ea32dc85ec98267b411dd3465cf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51099451\",\"name\":\"Feifei Kou\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"},{\"authorId\":\"72278010\",\"name\":\"Yijiang He\"},{\"authorId\":\"8544817\",\"name\":\"Lingfei Ye\"}],\"doi\":\"10.1016/J.TRIT.2016.12.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44b2424483328e00cf96f1e5f4dab333d51e642\",\"title\":\"Social network search based on semantic analysis and learning\",\"url\":\"https://www.semanticscholar.org/paper/c44b2424483328e00cf96f1e5f4dab333d51e642\",\"venue\":\"CAAI Trans. Intell. Technol.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48986542\",\"name\":\"L. Jin\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"1993658042\",\"name\":\"Y. Pan\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"}],\"doi\":\"10.1145/3394171.3414022\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3481a5795ee234df36ca259b15cfeb6d39b96fa4\",\"title\":\"Weakly-Supervised Image Hashing through Masked Visual-Semantic Graph-based Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/3481a5795ee234df36ca259b15cfeb6d39b96fa4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.01295\",\"authors\":[{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"2268783\",\"name\":\"Chenghua Lin\"},{\"authorId\":\"1510708415\",\"name\":\"Mian Zhou\"},{\"authorId\":\"49892954\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"13036580\",\"name\":\"Haoyu Lv\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"91c21f11bdcf89ae18b7fc805c114fa8f27f72ef\",\"title\":\"Generating Descriptions for Sequential Images with Local-Object Attention and Global Semantic Context Modelling\",\"url\":\"https://www.semanticscholar.org/paper/91c21f11bdcf89ae18b7fc805c114fa8f27f72ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414742\",\"name\":\"Kun Fu\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TPAMI.2016.2642953\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"title\":\"Aligning Where to See and What to Tell: Image Captioning with Region-Based Attention and Scene-Specific Contexts\",\"url\":\"https://www.semanticscholar.org/paper/afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.neucom.2018.02.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a24f013cbae0f349c54aaf958dca944d561a6efd\",\"title\":\"VD-SAN: Visual-Densely Semantic Attention Network for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a24f013cbae0f349c54aaf958dca944d561a6efd\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1816530\",\"name\":\"S. Shi\"},{\"authorId\":\"38898636\",\"name\":\"Min Zhang\"},{\"authorId\":\"1783406\",\"name\":\"Yiqun Liu\"},{\"authorId\":\"8093158\",\"name\":\"S. Ma\"}],\"doi\":\"10.1145/3269206.3271710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722ee4b096779f7a790bdba04c0f552df4a94b34\",\"title\":\"Attention-based Adaptive Model to Unify Warm and Cold Starts Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/722ee4b096779f7a790bdba04c0f552df4a94b34\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1805.08298\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2a2818ec251d947acd9c74c2040337e656946bc\",\"title\":\"Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/e2a2818ec251d947acd9c74c2040337e656946bc\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26994223\",\"name\":\"Yunbin Tu\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"2011768695\",\"name\":\"Junjun Guo\"},{\"authorId\":\"2409659\",\"name\":\"Shengxiang Gao\"},{\"authorId\":\"121854326\",\"name\":\"Zhengtao Yu\"}],\"doi\":\"10.1016/j.patcog.2020.107702\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6686fadf7f7ef2283cc9286095db281f8520ec04\",\"title\":\"Enhancing the alignment between target words and corresponding frames for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/6686fadf7f7ef2283cc9286095db281f8520ec04\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9127406\",\"name\":\"Fengkai Ke\"}],\"doi\":\"10.1109/ACCESS.2020.3008171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e09a1612dcbc069549d95820829ab0e9b5ac5d3a\",\"title\":\"An Efficient and Accurate DDPG-Based Recurrent Attention Model for Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/e09a1612dcbc069549d95820829ab0e9b5ac5d3a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"Andrea Apicella\"},{\"authorId\":\"13851143\",\"name\":\"Anna Corazza\"},{\"authorId\":\"34675913\",\"name\":\"Francesco Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.1109/WETICE.2017.47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a6f970f6801b07d0dd12d836a49bde5b0433d69\",\"title\":\"Integrating a Priori Probabilistic Knowledge into Classification for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/5a6f970f6801b07d0dd12d836a49bde5b0433d69\",\"venue\":\"2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)\",\"year\":2017},{\"arxivId\":\"1708.02478\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2018.2851077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d78c47093fbf3d85225fd502674aba4a29b3987\",\"title\":\"From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d78c47093fbf3d85225fd502674aba4a29b3987\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1811.09789\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9347ee91bf90129582e7ed414d23ad3495180235\",\"title\":\"Senti-Attend: Image Captioning using Sentiment and Attention\",\"url\":\"https://www.semanticscholar.org/paper/9347ee91bf90129582e7ed414d23ad3495180235\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-319-69005-6_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"title\":\"Topic-Specific Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"venue\":\"CCL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288466\",\"name\":\"Xian-Hua Zeng\"},{\"authorId\":\"145780928\",\"name\":\"B. Liu\"},{\"authorId\":\"40318021\",\"name\":\"M. Zhou\"}],\"doi\":\"10.1007/s11390-018-1874-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0243850576e364368c3f743012e78165d8bf249\",\"title\":\"Understanding and Generating Ultrasound Image Description\",\"url\":\"https://www.semanticscholar.org/paper/f0243850576e364368c3f743012e78165d8bf249\",\"venue\":\"Journal of Computer Science and Technology\",\"year\":2018},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/DICTA.2018.8615788\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"title\":\"Size-Invariant Attention Accuracy Metric for Image Captioning with High-Resolution Residual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dan Shiebler Drew Linsley\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a23fe7786f969de21be8541e87259a4d0807a47\",\"title\":\"L EARNING WHAT AND WHERE TO ATTEND\",\"url\":\"https://www.semanticscholar.org/paper/8a23fe7786f969de21be8541e87259a4d0807a47\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49297476\",\"name\":\"Bo Zheng\"},{\"authorId\":\"50778635\",\"name\":\"JinSong Hu\"}],\"doi\":\"10.5755/J01.ITC.48.4.23149\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aff57246fc77c3d22ca072be4cd22a3e987a5206\",\"title\":\"AANMF: Attribute-Aware Attentional Neural Matrix Factorization\",\"url\":\"https://www.semanticscholar.org/paper/aff57246fc77c3d22ca072be4cd22a3e987a5206\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"3141085\",\"name\":\"V. K\\u0131l\\u0131\\u00e7\"}],\"doi\":\"10.23919/ELECO47770.2019.8990630\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"94b442f133b1c11ccb6fb22affb797818745c4b7\",\"title\":\"A New Image Captioning Approach for Visually Impaired People\",\"url\":\"https://www.semanticscholar.org/paper/94b442f133b1c11ccb6fb22affb797818745c4b7\",\"venue\":\"2019 11th International Conference on Electrical and Electronics Engineering (ELECO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8804979\",\"name\":\"Siddhesh Khandelwal\"}],\"doi\":\"10.14288/1.0384602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0217b35a52d1e6b29ab734fe8b637ddad66cbe89\",\"title\":\"Enforcing structure in visual attention\",\"url\":\"https://www.semanticscholar.org/paper/0217b35a52d1e6b29ab734fe8b637ddad66cbe89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"14898006\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"145947071\",\"name\":\"Jing Qin\"}],\"doi\":\"10.1109/TNNLS.2019.2933439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"title\":\"Exploring Duality in Visual Question-Driven Top-Down Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ming-Jen Huang\"},{\"authorId\":\"2028457\",\"name\":\"Chun-Fang Huang\"},{\"authorId\":null,\"name\":\"Chiching Wei\"}],\"doi\":\"10.5121/csit.2020.100917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"157526b8b428cf220bb97b10f6a99230e06ab115\",\"title\":\"DOCPRO: A Framework for Building Document Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/157526b8b428cf220bb97b10f6a99230e06ab115\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.07300\",\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"title\":\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1910.07482\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37f371fe04f3dc38df7f27f43277ba15d3637890\",\"title\":\"Imperial College London Submission to VATEX Video Captioning Task\",\"url\":\"https://www.semanticscholar.org/paper/37f371fe04f3dc38df7f27f43277ba15d3637890\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13303789\",\"name\":\"T. Ishihara\"},{\"authorId\":\"1831467\",\"name\":\"Kento Morita\"},{\"authorId\":\"6834768\",\"name\":\"Nobu C. Shirai\"},{\"authorId\":\"1687449\",\"name\":\"T. Wakabayashi\"},{\"authorId\":\"1744332\",\"name\":\"W. Ohyama\"}],\"doi\":\"10.1007/978-3-030-41299-9_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcfadfb5bfb3daabf3915fb228a9aa4661f5b7c8\",\"title\":\"Chart-Type Classification Using Convolutional Neural Network for Scholarly Figures\",\"url\":\"https://www.semanticscholar.org/paper/dcfadfb5bfb3daabf3915fb228a9aa4661f5b7c8\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Moses Soh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53e9d718ec981850cfc6110385ac42ca2da2f612\",\"title\":\"Learning Cnn Lstm Architectures For Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/53e9d718ec981850cfc6110385ac42ca2da2f612\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397053973\",\"name\":\"Mohammad Alsharid\"},{\"authorId\":\"37050393\",\"name\":\"Harshita Sharma\"},{\"authorId\":\"7599395\",\"name\":\"L. Drukker\"},{\"authorId\":\"49240796\",\"name\":\"P. Chatelain\"},{\"authorId\":\"2635802\",\"name\":\"A. Papageorghiou\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-32251-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8893d5425d82ac8ae44a61f8a82b0d975c5dec12\",\"title\":\"Captioning Ultrasound Images Automatically\",\"url\":\"https://www.semanticscholar.org/paper/8893d5425d82ac8ae44a61f8a82b0d975c5dec12\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05608\",\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":\"10.24963/ijcai.2019/496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18403a06a67b7060645e137a36ad15122ee2c2f9\",\"title\":\"Image Captioning with Compositional Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/18403a06a67b7060645e137a36ad15122ee2c2f9\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2004.09705\",\"authors\":[{\"authorId\":\"9148340\",\"name\":\"F. Sado\"},{\"authorId\":\"1780187\",\"name\":\"C. K. Loo\"},{\"authorId\":\"2991958\",\"name\":\"Matthias Kerzel\"},{\"authorId\":\"1736513\",\"name\":\"S. Wermter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"694b71bab2d4a9a5fae87644fa5552f949eb65b1\",\"title\":\"Explainable Goal-Driven Agents and Robots - A Comprehensive Review and New Framework\",\"url\":\"https://www.semanticscholar.org/paper/694b71bab2d4a9a5fae87644fa5552f949eb65b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"title\":\"VisualNews : A Large Multi-source News Image Dataset\",\"url\":\"https://www.semanticscholar.org/paper/7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1907.07653\",\"authors\":[{\"authorId\":\"47493211\",\"name\":\"P. Rathnayaka\"},{\"authorId\":\"51428583\",\"name\":\"Supun Abeysinghe\"},{\"authorId\":\"51437913\",\"name\":\"Chamod Samarajeewa\"},{\"authorId\":\"51433418\",\"name\":\"Isura Manchanayake\"},{\"authorId\":\"67144683\",\"name\":\"Malaka J. Walpola\"},{\"authorId\":\"32861512\",\"name\":\"Rashmika Nawaratne\"},{\"authorId\":\"2432601\",\"name\":\"T. Bandaragoda\"},{\"authorId\":\"143775049\",\"name\":\"D. Alahakoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33ea6fdf14c770e396d63c4b13d1fe1cee64061a\",\"title\":\"Gated Recurrent Neural Network Approach for Multilabel Emotion Detection in Microblogs\",\"url\":\"https://www.semanticscholar.org/paper/33ea6fdf14c770e396d63c4b13d1fe1cee64061a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9432180\",\"name\":\"R. Kumar\"}],\"doi\":\"10.1007/s42979-020-00135-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b3a8a857467fd389d835f4f6c9fcf5777ed026a\",\"title\":\"Visual Linguistic Model and Its Applications in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9b3a8a857467fd389d835f4f6c9fcf5777ed026a\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978802390\",\"name\":\"Haolei Pei\"},{\"authorId\":\"8559954\",\"name\":\"Q. Chen\"},{\"authorId\":\"13257164\",\"name\":\"J. Wang\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"1680030\",\"name\":\"Yubo Jia\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206815\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"title\":\"Visual Relational Reasoning for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1906.00283\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"122175026\",\"name\":\"P\\u00e9ter Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"title\":\"Learning to Generate Grounded Image Captions without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.03023\",\"authors\":[{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"40974715\",\"name\":\"Bhargav Kanuparthi\"},{\"authorId\":\"51922896\",\"name\":\"Giancarlo Kerg\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"3168518\",\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f44f56c754cbd5e99e26d7fcad9d83d67d97cf1\",\"title\":\"h-detach: Modifying the LSTM Gradient Towards Better Optimization\",\"url\":\"https://www.semanticscholar.org/paper/5f44f56c754cbd5e99e26d7fcad9d83d67d97cf1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.24963/ijcai.2019/877\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"title\":\"Deep Learning for Video Captioning: A Review\",\"url\":\"https://www.semanticscholar.org/paper/eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2012.02339\",\"authors\":[{\"authorId\":\"2031911881\",\"name\":\"Edwin G. Ng\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"title\":\"Understanding Guided Image Captioning Performance across Domains\",\"url\":\"https://www.semanticscholar.org/paper/0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37498905\",\"name\":\"L. Li\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1145/3240508.3240649\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cd3c70f203be43112425346812a3d9a6f8cd8a0c\",\"title\":\"Attentive Recurrent Neural Network for Weak-supervised Multi-label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/cd3c70f203be43112425346812a3d9a6f8cd8a0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1912.00271\",\"authors\":[{\"authorId\":\"2164604\",\"name\":\"Shervin Minaee\"},{\"authorId\":\"1938271\",\"name\":\"AmirAli Abdolrashidi\"},{\"authorId\":null,\"name\":\"Hang Su\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"47844941\",\"name\":\"D. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1d206ec41d0a3667643a9e3d358e6a5a75040a0\",\"title\":\"Biometric Recognition Using Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/a1d206ec41d0a3667643a9e3d358e6a5a75040a0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8772234\",\"name\":\"Hyeryun Park\"},{\"authorId\":\"113066066\",\"name\":\"Kyungmo Kim\"},{\"authorId\":\"72062486\",\"name\":\"J. Yoon\"},{\"authorId\":\"31171717\",\"name\":\"Seongkeun Park\"},{\"authorId\":\"153439158\",\"name\":\"Jinwook Choi\"}],\"doi\":\"10.18653/v1/2020.acl-srw.14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b85f64b0a7c8eabd11476fa870b14b4ec696166\",\"title\":\"Feature Difference Makes Sense: A medical image captioning model exploiting feature difference and tag information\",\"url\":\"https://www.semanticscholar.org/paper/3b85f64b0a7c8eabd11476fa870b14b4ec696166\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1909.00121\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"145468578\",\"name\":\"Ke Lin\"},{\"authorId\":\"1772128\",\"name\":\"A. Maye\"},{\"authorId\":\"47786863\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3389/frobt.2020.475767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"304f94dbe2ed228309e86298766ad24d9b6c6747\",\"title\":\"A Semantics-Assisted Video Captioning Model Trained With Scheduled Sampling\",\"url\":\"https://www.semanticscholar.org/paper/304f94dbe2ed228309e86298766ad24d9b6c6747\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"1605.09553\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"title\":\"Attention Correctness in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151901\",\"name\":\"Bernd Huber\"},{\"authorId\":\"1801452\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"66648221\",\"name\":\"Bill Dolan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c34787b4708b34742774ba3abba8ace39c6b9052\",\"title\":\"Input Image : Smile Intensity Generated Responses : Input Question : Input\",\"url\":\"https://www.semanticscholar.org/paper/c34787b4708b34742774ba3abba8ace39c6b9052\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101574342\",\"name\":\"Laokulrat Natsuda\"},{\"authorId\":\"72456985\",\"name\":\"Okazaki Naoaki\"},{\"authorId\":\"72028078\",\"name\":\"Nakayama Hideki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dc7c33475b545271d1de726fd88bb68dfb7e11b\",\"title\":\"Generating Video Description using RNN with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/5dc7c33475b545271d1de726fd88bb68dfb7e11b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1811.00185\",\"authors\":[{\"authorId\":\"50811366\",\"name\":\"Haojie Pan\"},{\"authorId\":\"4645572\",\"name\":\"Junpei Zhou\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49420788\",\"name\":\"Y. Liu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144346838\",\"name\":\"Min Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c682ff7a573082c5b69880c4bf84cdd464b70ae5\",\"title\":\"Dial2Desc: End-to-end Dialogue Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/c682ff7a573082c5b69880c4bf84cdd464b70ae5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19268185\",\"name\":\"Niange Yu\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"38524079\",\"name\":\"Binheng Song\"},{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"39665190\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2018.2889922\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"title\":\"Topic-Oriented Image Captioning Based on Order-Embedding\",\"url\":\"https://www.semanticscholar.org/paper/d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15281703\",\"name\":\"Zejian Chen\"},{\"authorId\":\"3293035\",\"name\":\"Wufeng Xue\"},{\"authorId\":\"48470103\",\"name\":\"Tianfu Wang\"},{\"authorId\":\"145410044\",\"name\":\"Dong Ni\"}],\"doi\":\"10.1145/3364836.3364862\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ebdf3f3f8347358f980bcecd12de82fae51e222\",\"title\":\"Cardiac Motion Scoring Based on CNN with Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/8ebdf3f3f8347358f980bcecd12de82fae51e222\",\"venue\":\"ISICDM 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51132438\",\"name\":\"Shou-tao Xu\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1007/978-3-030-26763-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e161da916ceb238c2b40ee196a24605e3bf3fef\",\"title\":\"Improving Object Detection by Deep Networks with Class-Related Features\",\"url\":\"https://www.semanticscholar.org/paper/3e161da916ceb238c2b40ee196a24605e3bf3fef\",\"venue\":\"ICIC\",\"year\":2019},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.07094\",\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\"},{\"authorId\":\"1801452\",\"name\":\"D. McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":\"10.1109/ICCV.2019.00769\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e1e1feac96004866052787115ea08a4dcdd888b9\",\"title\":\"Unpaired Image-to-Speech Synthesis With Multimodal Information Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/e1e1feac96004866052787115ea08a4dcdd888b9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.03855\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"title\":\"Dense Relational Image Captioning via Multi-task Triple-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05684\",\"authors\":[{\"authorId\":\"46662193\",\"name\":\"V. Mittal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd6df4febb7135007077f835f9c44d12514aa522\",\"title\":\"AttnGrounder: Talking to Cars with Attention\",\"url\":\"https://www.semanticscholar.org/paper/dd6df4febb7135007077f835f9c44d12514aa522\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153135442\",\"name\":\"G. Bhatt\"},{\"authorId\":\"8943291\",\"name\":\"P. Jha\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a136590c8f7e3b86420fbca4a8ca3f2142a5f638\",\"title\":\"Representation learning using step-based deep multi-modal autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/a136590c8f7e3b86420fbca4a8ca3f2142a5f638\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51349878\",\"name\":\"Y. C. Yoon\"},{\"authorId\":\"49591454\",\"name\":\"SoYoung Park\"},{\"authorId\":\"14966100\",\"name\":\"Soo Park\"},{\"authorId\":\"153803012\",\"name\":\"H. Lim\"}],\"doi\":\"10.4218/ETRIJ.2018-0621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"title\":\"Image classification and captioning model considering a CAM\\u2010based disagreement loss\",\"url\":\"https://www.semanticscholar.org/paper/ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.05717\",\"authors\":[{\"authorId\":\"145676181\",\"name\":\"H. Wei\"},{\"authorId\":\"144586903\",\"name\":\"Nan Xu\"},{\"authorId\":\"3364661\",\"name\":\"Huichu Zhang\"},{\"authorId\":\"22698655\",\"name\":\"Guanjie Zheng\"},{\"authorId\":\"41018873\",\"name\":\"Xinshi Zang\"},{\"authorId\":\"3532743\",\"name\":\"C. Chen\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"1743564\",\"name\":\"Yanmin Zhu\"},{\"authorId\":\"145264199\",\"name\":\"K. Xu\"},{\"authorId\":\"1717163\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3357384.3357902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40968cf84b03ba9643278cb6c7c878e4accdb8cb\",\"title\":\"CoLight: Learning Network-level Cooperation for Traffic Signal Control\",\"url\":\"https://www.semanticscholar.org/paper/40968cf84b03ba9643278cb6c7c878e4accdb8cb\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"}],\"doi\":\"10.1016/j.cviu.2017.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1e2e32f29cf7d23881e98dfe018d9049bdb070d\",\"title\":\"Image Understanding using vision and reasoning through Scene Description Graph\",\"url\":\"https://www.semanticscholar.org/paper/e1e2e32f29cf7d23881e98dfe018d9049bdb070d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1803.02563\",\"authors\":[{\"authorId\":\"39453466\",\"name\":\"T. Zhang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144102268\",\"name\":\"Tong Shen\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TMM.2019.2914870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd8398e82e0c0cc4276a1694fd333214ede337ea\",\"title\":\"Decoupled Spatial Neural Attention for Weakly Supervised Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/cd8398e82e0c0cc4276a1694fd333214ede337ea\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1801.00470\",\"authors\":[{\"authorId\":\"26418979\",\"name\":\"Ankan Kumar Bhunia\"},{\"authorId\":\"9202067\",\"name\":\"Aishik Konwer\"},{\"authorId\":\"9195713\",\"name\":\"A. Bhowmick\"},{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"},{\"authorId\":\"65727619\",\"name\":\"U. Pal\"}],\"doi\":\"10.1016/j.patcog.2018.07.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c84808abb24660caff6f315ff3939d9a871ad21f\",\"title\":\"Script Identification in Natural Scene Image and Video Frame using Attention based Convolutional-LSTM Network\",\"url\":\"https://www.semanticscholar.org/paper/c84808abb24660caff6f315ff3939d9a871ad21f\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"144493052\",\"name\":\"Z. Zhao\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"2577617\",\"name\":\"Yueying He\"}],\"doi\":\"10.1016/j.asoc.2018.08.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b406f291ed520ab09e91e06d37b9beae1e10186d\",\"title\":\"Deep multi-view representation learning for social images\",\"url\":\"https://www.semanticscholar.org/paper/b406f291ed520ab09e91e06d37b9beae1e10186d\",\"venue\":\"Appl. Soft Comput.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1808.03457\",\"authors\":[{\"authorId\":\"3403352\",\"name\":\"Zhiwen Shao\"},{\"authorId\":\"1771215\",\"name\":\"Zhilei Liu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"},{\"authorId\":\"8452947\",\"name\":\"L. Ma\"}],\"doi\":\"10.1109/TAFFC.2019.2948635\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ae15677f5561561fc7203f21e100751bf112ce84\",\"title\":\"Facial Action Unit Detection Using Attention and Relation Learning\",\"url\":\"https://www.semanticscholar.org/paper/ae15677f5561561fc7203f21e100751bf112ce84\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"2462591\",\"name\":\"Ruifan Li\"}],\"doi\":\"10.24963/ijcai.2018/592\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"555e65623326de1b9c32bd22d482071920a6e4f1\",\"title\":\"Show and Tell More: Topic-Oriented Multi-Sentence Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/555e65623326de1b9c32bd22d482071920a6e4f1\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8307724\",\"name\":\"Subba Reddy Oota\"},{\"authorId\":\"52007799\",\"name\":\"Vijay Rowtula\"},{\"authorId\":\"48232521\",\"name\":\"M. Gupta\"},{\"authorId\":\"1769530\",\"name\":\"R. Bapi\"}],\"doi\":\"10.1109/IJCNN.2019.8852339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64ea40c601ba4cdcb09bcd8e163abe82a4763250\",\"title\":\"StepEncog: A Convolutional LSTM Autoencoder for Near-Perfect fMRI Encoding\",\"url\":\"https://www.semanticscholar.org/paper/64ea40c601ba4cdcb09bcd8e163abe82a4763250\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47591102\",\"name\":\"F. Chen\"},{\"authorId\":\"152566316\",\"name\":\"Songxian Xie\"},{\"authorId\":\"48570095\",\"name\":\"Xinyi Li\"},{\"authorId\":\"98482203\",\"name\":\"S. Li\"},{\"authorId\":\"1762106\",\"name\":\"Jintao Tang\"},{\"authorId\":\"1749687\",\"name\":\"Ting Wang\"}],\"doi\":\"10.1109/ICMEW.2019.00083\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"beaee074a9548022527c2a5a45a64861df7784ea\",\"title\":\"What Topics Do Images Say: A Neural Image Captioning Model with Topic Representation\",\"url\":\"https://www.semanticscholar.org/paper/beaee074a9548022527c2a5a45a64861df7784ea\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47136049\",\"name\":\"Naofumi Tomita\"},{\"authorId\":\"11119215\",\"name\":\"Behnaz Abdollahi\"},{\"authorId\":\"144026731\",\"name\":\"Jason Wei\"},{\"authorId\":\"145715498\",\"name\":\"Bing Ren\"},{\"authorId\":\"3583138\",\"name\":\"A. Suriawinata\"},{\"authorId\":\"145945685\",\"name\":\"Saeed Hassanpour\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5334f1ecdf444c919574abff9ea55dfbc2848a3f\",\"title\":\"Finding a Needle in the Haystack: Attention-Based Classification of High Resolution Microscopy Images\",\"url\":\"https://www.semanticscholar.org/paper/5334f1ecdf444c919574abff9ea55dfbc2848a3f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"66622154\",\"name\":\"Ray Ptucha\"}],\"doi\":\"10.1007/s10044-018-00770-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"title\":\"Understanding temporal structure for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2552746\",\"name\":\"L. Zhang\"},{\"authorId\":\"144625807\",\"name\":\"V. Singh\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1846624\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/WACV.2019.00017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"941f459f674a5ebc05c9570a3cd97dc80d2ef203\",\"title\":\"Cascade Attention Machine for Occluded Landmark Detection in 2D X-Ray Angiography\",\"url\":\"https://www.semanticscholar.org/paper/941f459f674a5ebc05c9570a3cd97dc80d2ef203\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49035023\",\"name\":\"T. Nguyen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"title\":\"Automatic Video Captioning using Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/64eac8b653194e2d479c2bf28d8f2bd2bfb9f53c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144469308\",\"name\":\"Jian Wang\"},{\"authorId\":\"145534714\",\"name\":\"Jie Feng\"}],\"doi\":\"10.1109/ACCESS.2020.3018546\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"123361e4769f2f8a17742197aa52cc676a4caa9a\",\"title\":\"Hybrid Attention Distribution and Factorized Embedding Matrix in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123361e4769f2f8a17742197aa52cc676a4caa9a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":null,\"name\":\"Lei Zhu\"}],\"doi\":\"10.1109/ICCV.2017.394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ae53b5837f6e6ca975dcb7af53ef51ac820e3a7\",\"title\":\"Leveraging Weak Semantic Relevance for Complex Video Event Classification\",\"url\":\"https://www.semanticscholar.org/paper/6ae53b5837f6e6ca975dcb7af53ef51ac820e3a7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"3201522\",\"name\":\"Yuanhao Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s11042-017-5443-x\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a7012729f5cd9fc40aedf26bec8665e91a5179d1\",\"title\":\"CNN-RNN: a large-scale hierarchical image classification framework\",\"url\":\"https://www.semanticscholar.org/paper/a7012729f5cd9fc40aedf26bec8665e91a5179d1\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"49865085\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-20876-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"title\":\"Multivariate Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186804\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"46948270\",\"name\":\"Ziyi Li\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.1016/j.neucom.2018.08.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"299c4aebcc81dd311f5632f3eec5f8a3bd17a226\",\"title\":\"Image captioning with triple-attention and stack parallel LSTM\",\"url\":\"https://www.semanticscholar.org/paper/299c4aebcc81dd311f5632f3eec5f8a3bd17a226\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"456983805a8781d6429bed1ed66dc9f3902767af\",\"title\":\"Seeing with Humans : Gaze-Assisted Neural Image\",\"url\":\"https://www.semanticscholar.org/paper/456983805a8781d6429bed1ed66dc9f3902767af\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1812.06663\",\"authors\":[{\"authorId\":\"144994529\",\"name\":\"Keke Tang\"},{\"authorId\":\"40960551\",\"name\":\"Guodong Wei\"},{\"authorId\":\"14936414\",\"name\":\"Runnan Chen\"},{\"authorId\":\"145254045\",\"name\":\"Jie Zhu\"},{\"authorId\":\"49336608\",\"name\":\"Wenping Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68bb9f985aa04f2ab069a1e87ee3651b951e083e\",\"title\":\"Attending Category Disentangled Global Context for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/68bb9f985aa04f2ab069a1e87ee3651b951e083e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255213\",\"name\":\"Z. Zhang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"47337540\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"2597292\",\"name\":\"Chuanqi Tan\"}],\"doi\":\"10.1109/TCSVT.2019.2936526\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"title\":\"Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153344447\",\"name\":\"Bruce McIntosh\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/cvpr42600.2020.00996\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b990461318a506822182a689b0e13d5e9465f0dc\",\"title\":\"Visual-Textual Capsule Routing for Text-Based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b990461318a506822182a689b0e13d5e9465f0dc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238568\",\"name\":\"M. Liu\"},{\"authorId\":\"1485768948\",\"name\":\"Lingjun Li\"},{\"authorId\":\"146896370\",\"name\":\"H. Hu\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"153307124\",\"name\":\"J. Tian\"}],\"doi\":\"10.1016/j.ipm.2019.102178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4ba3a265763677dfb68567aa6b62cd5fe4a633b\",\"title\":\"Image caption generation with dual attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e4ba3a265763677dfb68567aa6b62cd5fe4a633b\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2006.03744\",\"authors\":[{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"},{\"authorId\":\"46429484\",\"name\":\"F. Wang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"461420c80d3bdc156e5db7af13264a955a6a2010\",\"title\":\"Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/461420c80d3bdc156e5db7af13264a955a6a2010\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.07583\",\"authors\":[{\"authorId\":\"1388780256\",\"name\":\"Yaser Alwatter\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"}],\"doi\":\"10.22215/etd/2019-13929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48795928eb87d1e8a038063b3aebee180e424d04\",\"title\":\"Inverse Visual Question Answering with Multi-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/48795928eb87d1e8a038063b3aebee180e424d04\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":\"10.1145/3357384.3358000\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"title\":\"Adapting Visual Question Answering Models for Enhancing Multimodal Community Q&A Platforms\",\"url\":\"https://www.semanticscholar.org/paper/6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1910.03487\",\"authors\":[{\"authorId\":\"73062870\",\"name\":\"Nikolaos Malandrakis\"},{\"authorId\":\"98920799\",\"name\":\"Minmin Shen\"},{\"authorId\":\"2057019\",\"name\":\"Anuj Goyal\"},{\"authorId\":\"150296031\",\"name\":\"Shuyang Gao\"},{\"authorId\":\"14214710\",\"name\":\"Abhishek Sethi\"},{\"authorId\":\"47851995\",\"name\":\"A. Metallinou\"}],\"doi\":\"10.18653/v1/D19-5609\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed75f9326acf7a116ce3fbc9dd5177408f1a6825\",\"title\":\"Controlled Text Generation for Data Augmentation in Intelligent Artificial Agents\",\"url\":\"https://www.semanticscholar.org/paper/ed75f9326acf7a116ce3fbc9dd5177408f1a6825\",\"venue\":\"NGT@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1908.05407\",\"authors\":[{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3343031.3350996\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1056e6e84d52cf45017aad544fa0406441abda0\",\"title\":\"Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards\",\"url\":\"https://www.semanticscholar.org/paper/c1056e6e84d52cf45017aad544fa0406441abda0\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1874882\",\"name\":\"X. Wang\"},{\"authorId\":\"46867976\",\"name\":\"Y. Zhang\"},{\"authorId\":\"153757329\",\"name\":\"Z. Guo\"},{\"authorId\":\"46276201\",\"name\":\"J. Li\"}],\"doi\":\"10.1007/978-3-030-37446-4_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e57d5231f97aae78f155a3fa36edd40dae8161a5\",\"title\":\"A Computational Framework Towards Medical Image Explanation\",\"url\":\"https://www.semanticscholar.org/paper/e57d5231f97aae78f155a3fa36edd40dae8161a5\",\"venue\":\"KR4HC/ProHealth/TEAAM@AIME\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2017.766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"401cb8e62b915a7af0bd18776548896559566ce0\",\"title\":\"ViP-CNN: Visual Phrase Guided Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/401cb8e62b915a7af0bd18776548896559566ce0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1810.05866\",\"authors\":[{\"authorId\":null,\"name\":\"Fan Yang\"},{\"authorId\":\"145829312\",\"name\":\"Ke Yan\"},{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"2642975\",\"name\":\"Huizhu Jia\"},{\"authorId\":\"145037181\",\"name\":\"X. Xie\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1016/j.patcog.2018.08.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1821b905cec8acac9f81f030260aa614ff1d7a2\",\"title\":\"Attention Driven Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/f1821b905cec8acac9f81f030260aa614ff1d7a2\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582309\",\"name\":\"Kongming Liang\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.24963/ijcai.2017/313\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02428c771564125ed1e38d87b6c6dfa9fe6ca65d\",\"title\":\"Incomplete Attribute Learning with auxiliary labels\",\"url\":\"https://www.semanticscholar.org/paper/02428c771564125ed1e38d87b6c6dfa9fe6ca65d\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"3256307\",\"name\":\"M. A. A. K. Jalwana\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.1109/IVCNZ51579.2020.9290719\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b88b5bc5fe9af08df2d953b1c14c6f5cacd9564\",\"title\":\"Leveraging Linguistically-aware Object Relations and NASNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8b88b5bc5fe9af08df2d953b1c14c6f5cacd9564\",\"venue\":\"2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)\",\"year\":2020},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":\"1909.02218\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"2061528\",\"name\":\"Wenqing Chu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2018.2859820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96f0908cc138aceb2d5e0180c440e5adc711d855\",\"title\":\"A Better Way to Attend: Attention With Trees for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/96f0908cc138aceb2d5e0180c440e5adc711d855\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1908.06354\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"title\":\"A Fast and Accurate One-Stage Approach to Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4634604\",\"name\":\"Xinyuan Qi\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"46584851\",\"name\":\"J. Wang\"},{\"authorId\":null,\"name\":\"Chao Zhang\"}],\"doi\":\"10.1007/978-3-030-03338-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c828c5700dbd26d351d9b222db1c826ba4e81c\",\"title\":\"The Accurate Guidance for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e0c828c5700dbd26d351d9b222db1c826ba4e81c\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38896551\",\"name\":\"G. Guo\"},{\"authorId\":\"87022362\",\"name\":\"Yuan Meng\"},{\"authorId\":\"1739818\",\"name\":\"Yongfeng Zhang\"},{\"authorId\":\"71428050\",\"name\":\"C. Han\"},{\"authorId\":\"48514094\",\"name\":\"Yanjie Li\"}],\"doi\":\"10.1109/ACCESS.2019.2900396\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73d4d5ba44c66d103edc4f0a0df9d3af8f923cd6\",\"title\":\"Visual Semantic Image Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/73d4d5ba44c66d103edc4f0a0df9d3af8f923cd6\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s12559-019-09656-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"title\":\"Image Captioning with Memorized Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"venue\":\"Cognitive Computation\",\"year\":2019},{\"arxivId\":\"1907.03240\",\"authors\":[{\"authorId\":\"38921864\",\"name\":\"J. Li\"},{\"authorId\":\"21184593\",\"name\":\"Haizhou Shi\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3343031.3350918\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b2bb2ce93f2a48f998b6ca1e4364e8f2707e3e6\",\"title\":\"Informative Visual Storytelling with Cross-modal Rules\",\"url\":\"https://www.semanticscholar.org/paper/1b2bb2ce93f2a48f998b6ca1e4364e8f2707e3e6\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46608477\",\"name\":\"Ningning Guo\"},{\"authorId\":\"31833173\",\"name\":\"H. Liu\"},{\"authorId\":\"47420475\",\"name\":\"Linhua Jiang\"}],\"doi\":\"10.1109/ICARM.2019.8834066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02ac11a09db5d0f8a52d428e6d9ab64dba0535cf\",\"title\":\"Attention-based Visual-Audio Fusion for Video Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/02ac11a09db5d0f8a52d428e6d9ab64dba0535cf\",\"venue\":\"2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651496\",\"name\":\"Chengxi Li\"},{\"authorId\":\"153194886\",\"name\":\"Sagar Gandhi\"},{\"authorId\":\"35066258\",\"name\":\"B. Harrison\"}],\"doi\":\"10.1145/3337722.3341870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79b31c51375fdfe87d854d238d2bfb4696fd71cf\",\"title\":\"End-to-end let's play commentary generation using multi-modal video representations\",\"url\":\"https://www.semanticscholar.org/paper/79b31c51375fdfe87d854d238d2bfb4696fd71cf\",\"venue\":\"FDG\",\"year\":2019},{\"arxivId\":\"1906.08876\",\"authors\":[{\"authorId\":\"3038511\",\"name\":\"Sanqiang Zhao\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P19-1650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"title\":\"Informative Image Captioning with External Sources of Information\",\"url\":\"https://www.semanticscholar.org/paper/68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"2841633\",\"name\":\"Hyunmin Lee\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.18653/v1/N19-1011\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c4798919e74411d87f7745840e45b8bcf61128ff\",\"title\":\"AudioCaps: Generating Captions for Audios in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/c4798919e74411d87f7745840e45b8bcf61128ff\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"144513168\",\"name\":\"L. Gong\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1142/s146902682050011x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81b1a0d8ca4ab3b9807164866de7e5dca73651dd\",\"title\":\"Spatial Relational Attention Using Fully Convolutional Networks for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/81b1a0d8ca4ab3b9807164866de7e5dca73651dd\",\"venue\":\"Int. J. Comput. Intell. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123275\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"159d16cdc48135632c2d5790e5baaf8d0631f510\",\"title\":\"StructCap: Structured Semantic Embedding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/159d16cdc48135632c2d5790e5baaf8d0631f510\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774112\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"Changyin Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"789c76749a15614d97ac8f4ec18b3ce7d80a2d28\",\"title\":\"Explorer Multiplicative LSTM for sequence modelling\",\"url\":\"https://www.semanticscholar.org/paper/789c76749a15614d97ac8f4ec18b3ce7d80a2d28\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2664328\",\"name\":\"Haizhou Zhao\"},{\"authorId\":\"145221280\",\"name\":\"Yi Du\"},{\"authorId\":\"49404104\",\"name\":\"Hangyu Li\"},{\"authorId\":\"3109707\",\"name\":\"Q. Qian\"},{\"authorId\":\"144751955\",\"name\":\"Hao Zhou\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"2774294\",\"name\":\"J. Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27db6405eb83709918d75b87fe80ba5acc36277f\",\"title\":\"SG 01 at the NTCIR-13 STC-2 Task\",\"url\":\"https://www.semanticscholar.org/paper/27db6405eb83709918d75b87fe80ba5acc36277f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145102294\",\"name\":\"Moreira de Souza\"},{\"authorId\":\"123900281\",\"name\":\"Fillipe Dias\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"title\":\"Semantic Description of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8a75bcb25a8ba707924b0403f9d65d25d1e1e1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2018.2811621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a17310abb249ce8fce8f409709b5395da32e0a6\",\"title\":\"Bundled Object Context for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/8a17310abb249ce8fce8f409709b5395da32e0a6\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ruchitesh Malukani\"},{\"authorId\":null,\"name\":\"Nihaal Subhash\"},{\"authorId\":null,\"name\":\"Chhaya Zala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eefe9fe0b57b079d779d7c82162db4570b60bc3\",\"title\":\"Deep Learning Model Implementation in Web-Based Application for Automatic Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/0eefe9fe0b57b079d779d7c82162db4570b60bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1605.07912\",\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"title\":\"Encode, Review, and Decode: Reviewer Module for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39603708\",\"name\":\"Q. Truong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb40b0100214511fb1d3672a2cf6005e41bf63ce\",\"title\":\"Generation for Recommender Systems\",\"url\":\"https://www.semanticscholar.org/paper/eb40b0100214511fb1d3672a2cf6005e41bf63ce\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073332\",\"name\":\"J. Li\"},{\"authorId\":\"1923156\",\"name\":\"P. Yao\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"49039585\",\"name\":\"Wei-Cun Zhang\"}],\"doi\":\"10.3390/APP9163260\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"title\":\"Boosted Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52366010\",\"name\":\"Zhi-bin Guan\"},{\"authorId\":\"49600007\",\"name\":\"Kang Liu\"},{\"authorId\":\"47009350\",\"name\":\"Yan Ma\"},{\"authorId\":\"144222488\",\"name\":\"Xu Qian\"},{\"authorId\":\"35260608\",\"name\":\"Tongkai Ji\"}],\"doi\":\"10.3390/sym10110626\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"title\":\"Sequential Dual Attention: Coarse-to-Fine-Grained Hierarchical Generation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"venue\":\"Symmetry\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116567136\",\"name\":\"Vasiliki Kougia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b493fecc32759e614ab5f30c6c1fc05147fcb84\",\"title\":\"\\u201c Medical Image Labeling and Report Generation \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/7b493fecc32759e614ab5f30c6c1fc05147fcb84\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66511580\",\"name\":\"Mirza Muhammad Ali Baig\"},{\"authorId\":\"67307335\",\"name\":\"Mian Ihtisham Shah\"},{\"authorId\":\"9223428\",\"name\":\"Muhammad Abdullah Wajahat\"},{\"authorId\":\"2384836\",\"name\":\"Nauman Zafar\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/DICTA.2018.8615810\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"title\":\"Image Caption Generator with Novel Object Injection\",\"url\":\"https://www.semanticscholar.org/paper/d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"133686034\",\"name\":\"An-ran Zhang\"},{\"authorId\":\"49693266\",\"name\":\"L. Yue\"},{\"authorId\":\"49927595\",\"name\":\"J. Shen\"},{\"authorId\":\"35550884\",\"name\":\"F. Zhu\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"2321103\",\"name\":\"Xian-Bin Cao\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1109/ICCV.2019.00581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0a51a1b4541e4644f7b42b1bc3f5d07ee046015\",\"title\":\"Attentional Neural Fields for Crowd Counting\",\"url\":\"https://www.semanticscholar.org/paper/a0a51a1b4541e4644f7b42b1bc3f5d07ee046015\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66290737\",\"name\":\"Qiongjie Cui\"},{\"authorId\":\"2775306\",\"name\":\"Huaijiang Sun\"},{\"authorId\":\"47002562\",\"name\":\"Y. Li\"},{\"authorId\":\"47389993\",\"name\":\"Yue Kong\"}],\"doi\":\"10.24963/ijcai.2019/99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f183293be5807197a7b2259dc808929d833ec2b7\",\"title\":\"A Deep Bi-directional Attention Network for Human Motion Recovery\",\"url\":\"https://www.semanticscholar.org/paper/f183293be5807197a7b2259dc808929d833ec2b7\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31696860\",\"name\":\"Shurong Sheng\"},{\"authorId\":\"35301620\",\"name\":\"Katrien Laenen\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1007/978-3-030-15719-7_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d75b686c7d32680f5e5aeeefaffff6dab06d31ee\",\"title\":\"Can Image Captioning Help Passage Retrieval in Multimodal Question Answering?\",\"url\":\"https://www.semanticscholar.org/paper/d75b686c7d32680f5e5aeeefaffff6dab06d31ee\",\"venue\":\"ECIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91337137\",\"name\":\"B. Zhang\"},{\"authorId\":\"1805285\",\"name\":\"A. Davoodi\"},{\"authorId\":\"1943030\",\"name\":\"Y. Hu\"}],\"doi\":\"10.1109/COINS49042.2020.9191636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58e9c3d7b8e3080c20b52123a16925dac104554e\",\"title\":\"CHaPR: Efficient Inference of CNNs via Channel Pruning\",\"url\":\"https://www.semanticscholar.org/paper/58e9c3d7b8e3080c20b52123a16925dac104554e\",\"venue\":\"2020 International Conference on Omni-layer Intelligent Systems (COINS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2881052\",\"name\":\"Amin Javari\"},{\"authorId\":\"51002202\",\"name\":\"Z. He\"},{\"authorId\":\"12318198\",\"name\":\"Zi-jie Huang\"},{\"authorId\":\"144175955\",\"name\":\"Jeetu Raj\"},{\"authorId\":\"143922493\",\"name\":\"K. Chang\"}],\"doi\":\"10.1145/3366423.3380182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c675c2056d1e759f5dfca394c77d228d2d4478c\",\"title\":\"Weakly Supervised Attention for Hashtag Recommendation using Graph Data\",\"url\":\"https://www.semanticscholar.org/paper/8c675c2056d1e759f5dfca394c77d228d2d4478c\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994707\",\"name\":\"X. Gao\"},{\"authorId\":\"1695158\",\"name\":\"Tingting Mu\"},{\"authorId\":\"1723263\",\"name\":\"J. Y. Goulermas\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"}],\"doi\":\"10.1016/j.ins.2017.08.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40a2215a06506fc4068cd70d5cdd045bf8950678\",\"title\":\"Attention driven multi-modal similarity learning\",\"url\":\"https://www.semanticscholar.org/paper/40a2215a06506fc4068cd70d5cdd045bf8950678\",\"venue\":\"Inf. Sci.\",\"year\":2018},{\"arxivId\":\"2004.10258\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1491357190\",\"name\":\"Yang Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f882bc53ded32b2a32b291078c9454d82f6f108b\",\"title\":\"ParaCNN: Visual Paragraph Generation via Adversarial Twin Contextual CNNs\",\"url\":\"https://www.semanticscholar.org/paper/f882bc53ded32b2a32b291078c9454d82f6f108b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"46700004\",\"name\":\"J. Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TMM.2019.2951226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"837a513a43c7bcce903edbacbfc507cba6451e21\",\"title\":\"Show, Tell, and Polish: Ruminant Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/837a513a43c7bcce903edbacbfc507cba6451e21\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40526720\",\"name\":\"Pengtao Xie\"}],\"doi\":\"10.1184/R1/7553468.V1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"04f11687c7b918501c1a24195d8336936adf194d\",\"title\":\"Diversity-Promoting and Large-Scale Machine Learning for Healthcare\",\"url\":\"https://www.semanticscholar.org/paper/04f11687c7b918501c1a24195d8336936adf194d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2003.11743\",\"authors\":[{\"authorId\":\"1491233100\",\"name\":\"Pranav Agarwal\"},{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"1594025086\",\"name\":\"V. Panagiotou\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b430a5384c82beb6102106fbea0a134425a08c23\",\"title\":\"Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models\",\"url\":\"https://www.semanticscholar.org/paper/b430a5384c82beb6102106fbea0a134425a08c23\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47528138\",\"name\":\"W. Zhang\"},{\"authorId\":\"9313849\",\"name\":\"Zepeng Wang\"},{\"authorId\":\"97807745\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICMEW.2019.00092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05e36e7b2f82baa59327164d17b01203bd58af69\",\"title\":\"Personalized Image Recommendation with Photo Importance and user-item Interactive Attention\",\"url\":\"https://www.semanticscholar.org/paper/05e36e7b2f82baa59327164d17b01203bd58af69\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2706292\",\"name\":\"Xianhua Zeng\"},{\"authorId\":\"145117241\",\"name\":\"L. Wen\"},{\"authorId\":\"115986457\",\"name\":\"Yang Xu\"},{\"authorId\":\"1893927760\",\"name\":\"Conghui Ji\"}],\"doi\":\"10.1016/j.cmpb.2020.105700\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbe08984fe9bb669e11e73b8fb14c9d43ab57017\",\"title\":\"Generating diagnostic report for medical image by high-middle-level visual information incorporation on double deep learning models\",\"url\":\"https://www.semanticscholar.org/paper/cbe08984fe9bb669e11e73b8fb14c9d43ab57017\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2988239\",\"name\":\"Fenglong Ma\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1995400\",\"name\":\"Houping Xiao\"},{\"authorId\":\"1776163\",\"name\":\"Radha Chitta\"},{\"authorId\":\"143860023\",\"name\":\"J. Zhou\"},{\"authorId\":\"144407304\",\"name\":\"Jing Gao\"}],\"doi\":\"10.1145/3269206.3271701\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31636b4259d611573ad1b94eb685dcc6cad73f3f\",\"title\":\"KAME: Knowledge-based Attention Model for Diagnosis Prediction in Healthcare\",\"url\":\"https://www.semanticscholar.org/paper/31636b4259d611573ad1b94eb685dcc6cad73f3f\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145471480\",\"name\":\"Yunmeng Feng\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46446912\",\"name\":\"X. Zhang\"},{\"authorId\":\"7521170\",\"name\":\"Chuanfu Xu\"},{\"authorId\":\"2243533\",\"name\":\"Zhenghua Wang\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1145/3302425.3302464\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"title\":\"AttResNet: Attention-based ResNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1802.02305\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/TIP.2018.2814344\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f97e9818a8055668f9db7967b076dd036d25c417\",\"title\":\"Self-Supervised Video Hashing With Hierarchical Binary Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/f97e9818a8055668f9db7967b076dd036d25c417\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1906.02792\",\"authors\":[{\"authorId\":\"74480447\",\"name\":\"Manjot Bilkhu\"},{\"authorId\":\"14506569\",\"name\":\"S. Wang\"},{\"authorId\":\"70060571\",\"name\":\"Tushar Dobhal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2cb203f6b09a3bf734c705c999da706b7a7c031\",\"title\":\"Attention is all you need for Videos: Self-attention based Video Summarization using Universal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/b2cb203f6b09a3bf734c705c999da706b7a7c031\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.05994\",\"authors\":[{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9827221\",\"name\":\"J. Li\"},{\"authorId\":\"1661029011\",\"name\":\"Hao Fu\"},{\"authorId\":\"14768555\",\"name\":\"Yuh-Chen Lin\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144286907\",\"name\":\"Qian Yang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e64c6228919810fbd3796563b20ef2813ffa8d54\",\"title\":\"Improving Text Generation with Student-Forcing Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/e64c6228919810fbd3796563b20ef2813ffa8d54\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"Andrea Apicella\"},{\"authorId\":\"13851143\",\"name\":\"Anna Corazza\"},{\"authorId\":\"34675913\",\"name\":\"Francesco Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.1007/978-3-319-68560-1_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ee6951d8cdb9c2ee5d56d2b3f40296256164d3\",\"title\":\"Exploiting Context Information for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/e7ee6951d8cdb9c2ee5d56d2b3f40296256164d3\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":\"1809.08264\",\"authors\":[{\"authorId\":\"5829939\",\"name\":\"Suo Qiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88e855f236a9b013a25b0067d7081bd2c38a019a\",\"title\":\"Global Weighted Average Pooling Bridges Pixel-level Localization and Image-level Classification\",\"url\":\"https://www.semanticscholar.org/paper/88e855f236a9b013a25b0067d7081bd2c38a019a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6ba4e10d06d9842765a4350bf5abbd3dd095045c\",\"title\":\"Filtering : Multimedia Recommendation with Item-and Component-Level A ention\",\"url\":\"https://www.semanticscholar.org/paper/6ba4e10d06d9842765a4350bf5abbd3dd095045c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152758697\",\"name\":\"Feiran Huang\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"8419850\",\"name\":\"Z. Zhao\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1109/TIP.2018.2882225\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6807368ab0c87a9cfbb34237704c7019b404a21\",\"title\":\"Bi-Directional Spatial-Semantic Attention Networks for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/d6807368ab0c87a9cfbb34237704c7019b404a21\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39232438\",\"name\":\"C. Liu\"},{\"authorId\":\"40203750\",\"name\":\"F. Sun\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"49451531\",\"name\":\"F. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2e5ae83f9f44b606898b1795906de5464ac3482e\",\"title\":\"WEOTAWEO 2 LSTM WEO 1 Encoding WSS 1 WSS 2 WSSTB Decoding Attention Cell\",\"url\":\"https://www.semanticscholar.org/paper/2e5ae83f9f44b606898b1795906de5464ac3482e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146549267\",\"name\":\"D. Shen\"},{\"authorId\":\"46999618\",\"name\":\"T. Liu\"},{\"authorId\":\"1698185\",\"name\":\"T. Peters\"},{\"authorId\":\"1700330\",\"name\":\"L. Staib\"},{\"authorId\":\"1381802974\",\"name\":\"C. Essert\"},{\"authorId\":\"152856580\",\"name\":\"S. Zhou\"},{\"authorId\":\"144931047\",\"name\":\"P. Yap\"},{\"authorId\":\"1390686262\",\"name\":\"A. Khan\"}],\"doi\":\"10.1007/978-3-030-32251-9\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e694128239c44b596a143f066f3da05c8cfc551d\",\"title\":\"Medical Image Computing and Computer Assisted Intervention \\u2013 MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13\\u201317, 2019, Proceedings, Part IV\",\"url\":\"https://www.semanticscholar.org/paper/e694128239c44b596a143f066f3da05c8cfc551d\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"39494411\",\"name\":\"Lei Wang\"},{\"authorId\":\"2834810\",\"name\":\"Peiyu Guo\"}],\"doi\":\"10.1109/icis46139.2019.8940218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7344b254af85b53c5e989579b1d18fbf946c03de\",\"title\":\"Slot based Image Captioning with WGAN\",\"url\":\"https://www.semanticscholar.org/paper/7344b254af85b53c5e989579b1d18fbf946c03de\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429704\",\"name\":\"D. Zhang\"},{\"authorId\":\"46721598\",\"name\":\"Bo Ni\"},{\"authorId\":\"40552330\",\"name\":\"Qiyu Zhi\"},{\"authorId\":\"34780317\",\"name\":\"T. Plummer\"},{\"authorId\":\"144836952\",\"name\":\"Q. Li\"},{\"authorId\":\"152514378\",\"name\":\"Hao Zheng\"},{\"authorId\":\"1694209\",\"name\":\"Qingkai Zeng\"},{\"authorId\":\"49890108\",\"name\":\"Y. Zhang\"},{\"authorId\":\"46314882\",\"name\":\"Dong Wang\"}],\"doi\":\"10.1145/3341161.3342885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1535fbc22dbe34edb1078e0447f5d664c26878df\",\"title\":\"Through The Eyes of A Poet: Classical Poetry Recommendation with Visual Input on Social Media\",\"url\":\"https://www.semanticscholar.org/paper/1535fbc22dbe34edb1078e0447f5d664c26878df\",\"venue\":\"2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952857\",\"name\":\"K. Zheng\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"2478555\",\"name\":\"Shaopeng Lu\"},{\"authorId\":\"40457369\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-00776-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"title\":\"Multiple-Level Feature-Based Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"}],\"doi\":\"10.1016/J.NEUCOM.2018.06.096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"title\":\"Fused GRU with semantic-temporal attention for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1909.06627\",\"authors\":[{\"authorId\":\"143698377\",\"name\":\"C. Shi\"},{\"authorId\":\"50017230\",\"name\":\"Xiaotian Han\"},{\"authorId\":\"47237200\",\"name\":\"Lipei Song\"},{\"authorId\":\"144129720\",\"name\":\"Xiao Wang\"},{\"authorId\":\"3210262\",\"name\":\"Senzhang Wang\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/tkde.2019.2941938\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06125751f531d4d1e3c8b5b794c9fa7b4339f720\",\"title\":\"Deep Collaborative Filtering with Multi-Aspect Information in Heterogeneous Networks\",\"url\":\"https://www.semanticscholar.org/paper/06125751f531d4d1e3c8b5b794c9fa7b4339f720\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ACCESS.2019.2942000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"801827592d18c4e6170d88f8345465de4a8db7ca\",\"title\":\"Video Captioning With Adaptive Attention and Mixed Loss Optimization\",\"url\":\"https://www.semanticscholar.org/paper/801827592d18c4e6170d88f8345465de4a8db7ca\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yongzhuang Wang\"},{\"authorId\":\"49746133\",\"name\":\"Yangmei Shen\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICIP.2019.8803418\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93368542c1774e2cbd12187a4ccc2c882c791d94\",\"title\":\"Adaptive Hard Example Mining for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93368542c1774e2cbd12187a4ccc2c882c791d94\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49408473\",\"name\":\"Wenhui Jiang\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"}],\"doi\":\"10.1007/s11042-017-5087-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"676600ed722d4739d669715c16a1ed2fc117b3d4\",\"title\":\"Weakly supervised detection with decoupled attention-based deep representation\",\"url\":\"https://www.semanticscholar.org/paper/676600ed722d4739d669715c16a1ed2fc117b3d4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32438821\",\"name\":\"T. Praveen\"},{\"authorId\":\"2840480\",\"name\":\"J. Jothi\"}],\"doi\":\"10.1007/978-981-15-5243-4_77\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"544e5f86bc98b56f638e69b3d019a6a7af19aa70\",\"title\":\"Enhancing Image Caption Quality with Pre-post Image Injections\",\"url\":\"https://www.semanticscholar.org/paper/544e5f86bc98b56f638e69b3d019a6a7af19aa70\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1909.11128\",\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":\"10.1109/ICRA40945.2020.9197552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c8d46f66ac2b8a7019776ecdff99b1a594e65b\",\"title\":\"Accept Synthetic Objects as Real: End-to-End Training of Attentive Deep Visuomotor Policies for Manipulation in Clutter\",\"url\":\"https://www.semanticscholar.org/paper/79c8d46f66ac2b8a7019776ecdff99b1a594e65b\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403352\",\"name\":\"Zhiwen Shao\"},{\"authorId\":\"1771215\",\"name\":\"Zhilei Liu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"},{\"authorId\":\"8452947\",\"name\":\"L. Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9bce7bd7909f1c75dbeb44900d374bc89072df0\",\"title\":\"Weakly-Supervised Attention and Relation Learning for Facial Action Unit Detection\",\"url\":\"https://www.semanticscholar.org/paper/f9bce7bd7909f1c75dbeb44900d374bc89072df0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702778\",\"name\":\"H. Zhang\"},{\"authorId\":\"2913523\",\"name\":\"Diedie Qiu\"},{\"authorId\":\"50477983\",\"name\":\"R. Wu\"},{\"authorId\":\"103624776\",\"name\":\"Dong-Hong Ji\"},{\"authorId\":\"49461429\",\"name\":\"Guangli Li\"},{\"authorId\":\"9201022\",\"name\":\"Zhenyu Niu\"},{\"authorId\":\"50289773\",\"name\":\"Tao Li\"}],\"doi\":\"10.1007/S00500-019-03973-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f7104056642c03263508957f20505a1dbba03ce\",\"title\":\"Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images\",\"url\":\"https://www.semanticscholar.org/paper/7f7104056642c03263508957f20505a1dbba03ce\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":\"1707.08364\",\"authors\":[{\"authorId\":\"40028657\",\"name\":\"Ali Sharifi Boroujerdi\"},{\"authorId\":\"152839172\",\"name\":\"M. Khanian\"},{\"authorId\":\"8778956\",\"name\":\"M. Breu\\u00df\"}],\"doi\":\"10.1109/SITIS.2017.27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cafa1f108063ea6ab11c587ba74f91f13d2ba50\",\"title\":\"Deep Interactive Region Segmentation and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8cafa1f108063ea6ab11c587ba74f91f13d2ba50\",\"venue\":\"2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528369\",\"name\":\"Huiqing Wang\"},{\"authorId\":\"153000348\",\"name\":\"Yue Ma\"},{\"authorId\":\"11922502\",\"name\":\"Chun-lin Dong\"},{\"authorId\":\"48161954\",\"name\":\"Chunsheng Li\"},{\"authorId\":\"71563165\",\"name\":\"J. Wang\"},{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"}],\"doi\":\"10.3389/fgene.2019.00967\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d72c2353562d8abd15a1d168c48437339aaa0c4\",\"title\":\"CL-PMI: A Precursor MicroRNA Identification Method Based on Convolutional and Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/0d72c2353562d8abd15a1d168c48437339aaa0c4\",\"venue\":\"Front. Genet.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121400055\",\"name\":\"Tze How Dickson Neoh\"},{\"authorId\":\"145902615\",\"name\":\"K. S. M. Sahari\"},{\"authorId\":\"32059177\",\"name\":\"Y. C. Hou\"},{\"authorId\":\"1629255173\",\"name\":\"Omar Gumaan Saleh Basubeit\"}],\"doi\":\"10.1109/CRC.2019.00030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caf1176584bcda0ae7edb224a83c493c79d821bd\",\"title\":\"Recognizing Malaysia Traffic Signs with Pre-Trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/caf1176584bcda0ae7edb224a83c493c79d821bd\",\"venue\":\"2019 4th International Conference on Control, Robotics and Cybernetics (CRC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"1848462\",\"name\":\"Yarong Han\"},{\"authorId\":\"144530696\",\"name\":\"Li Wan\"},{\"authorId\":\"144025048\",\"name\":\"Xing Zhou\"},{\"authorId\":\"144975798\",\"name\":\"Min Deng\"}],\"doi\":\"10.1080/01431161.2019.1594439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"title\":\"Geospatial relation captioning for high-spatial-resolution images by using an attention-based neural network\",\"url\":\"https://www.semanticscholar.org/paper/baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.00003\",\"authors\":[{\"authorId\":\"153135442\",\"name\":\"G. Bhatt\"},{\"authorId\":\"8943291\",\"name\":\"P. Jha\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1109/ACPR.2017.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f62d3dad8c644828cea7f496a2815ed1038e161\",\"title\":\"Common Representation Learning Using Step-Based Correlation Multi-modal CNN\",\"url\":\"https://www.semanticscholar.org/paper/4f62d3dad8c644828cea7f496a2815ed1038e161\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1706.02430\",\"authors\":[{\"authorId\":\"143932857\",\"name\":\"Zhongliang Yang\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"},{\"authorId\":\"19283055\",\"name\":\"S. Rehman\"},{\"authorId\":\"1731776\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1007/978-3-319-71589-6_10\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e8fa2e242369dcf50ab5cd1745b29bfc51aadf2a\",\"title\":\"Image Captioning with Object Detection and Localization\",\"url\":\"https://www.semanticscholar.org/paper/e8fa2e242369dcf50ab5cd1745b29bfc51aadf2a\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40228165\",\"name\":\"A. Hani\"},{\"authorId\":\"2821832\",\"name\":\"Najiba Tagougui\"},{\"authorId\":\"2139481\",\"name\":\"M. Kherallah\"}],\"doi\":\"10.1109/ACIT47987.2019.8990998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82ecd67c8425c9756c873df42a6dadba2db04945\",\"title\":\"Image Caption Generation Using A Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/82ecd67c8425c9756c873df42a6dadba2db04945\",\"venue\":\"2019 International Arab Conference on Information Technology (ACIT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/MMUL.2018.112135923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da8f9211ea60755bb40811bb92de76be389566c6\",\"title\":\"Image and Video Captioning with Augmented Neural Architectures\",\"url\":\"https://www.semanticscholar.org/paper/da8f9211ea60755bb40811bb92de76be389566c6\",\"venue\":\"IEEE MultiMedia\",\"year\":2018},{\"arxivId\":\"2002.04355\",\"authors\":[{\"authorId\":\"1471439125\",\"name\":\"\\u015eeymanur Akt\\u0131\"},{\"authorId\":\"1471431070\",\"name\":\"G\\u00f6zde Ay\\u015fe Tataro\\u011flu\"},{\"authorId\":\"32365318\",\"name\":\"H. K. Ekenel\"}],\"doi\":\"10.1109/IPTA.2019.8936070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41a8954131f313d8526b2f8fc0506405ec519819\",\"title\":\"Vision-based Fight Detection from Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/41a8954131f313d8526b2f8fc0506405ec519819\",\"venue\":\"2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"46232306\",\"name\":\"Zehan Zhang\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/s00371-018-1565-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6a788c65190959c1390d0ba8065d755c78d200a\",\"title\":\"Modeling coverage with semantic embedding for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/d6a788c65190959c1390d0ba8065d755c78d200a\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1017/S1351324918000116\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"title\":\"The role of image representations in vision to language tasks\",\"url\":\"https://www.semanticscholar.org/paper/2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"9099786\",\"name\":\"Jinxing Yu\"},{\"authorId\":\"30593001\",\"name\":\"Ming-ming Sun\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"}],\"doi\":\"10.1145/3366423.3380080\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1a496faaf4fe8e726cbbe7fb90af9631d8108793\",\"title\":\"Improved Touch-screen Inputting Using Sequence-level Prediction Generation\",\"url\":\"https://www.semanticscholar.org/paper/1a496faaf4fe8e726cbbe7fb90af9631d8108793\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1905.08110\",\"authors\":[{\"authorId\":\"47904580\",\"name\":\"Yiyu Wang\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"title\":\"Image Captioning based on Deep Learning Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3126686.3126714\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"title\":\"Image Caption with Synchronous Cross-Attention\",\"url\":\"https://www.semanticscholar.org/paper/b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TMM.2019.2894964\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb722f44a88a5138c26fcc4b0299ca5a6cf729ac\",\"title\":\"Attend and Imagine: Multi-Label Image Classification With Visual Attention and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fb722f44a88a5138c26fcc4b0299ca5a6cf729ac\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1612.01033\",\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.1109/ICCV.2017.140\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"title\":\"Areas of Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2007.08617\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-58523-5_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"432921b7a2c782cedc2a7d87b6194b906e31086d\",\"title\":\"Preserving Semantic Neighborhoods for Robust Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/432921b7a2c782cedc2a7d87b6194b906e31086d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.05881\",\"authors\":[{\"authorId\":\"115003962\",\"name\":\"Marko Smilevski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"401915cc8ac773e69223df42768083d53e10aa8d\",\"title\":\"Applying recent advances in Visual Question Answering to Record Linkage\",\"url\":\"https://www.semanticscholar.org/paper/401915cc8ac773e69223df42768083d53e10aa8d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150213872\",\"name\":\"M. Hemalatha.\"},{\"authorId\":\"143783787\",\"name\":\"C. C. Sekhar\"}],\"doi\":\"10.1109/WACV45572.2020.9093344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"509b25d45c6f5e3cafa48395c941611364e22efc\",\"title\":\"Domain-Specific Semantics Guided Approach to Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/509b25d45c6f5e3cafa48395c941611364e22efc\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3291925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a437bb550d1df02188e4b145e01675551da36336\",\"title\":\"Show, Reward, and Tell\",\"url\":\"https://www.semanticscholar.org/paper/a437bb550d1df02188e4b145e01675551da36336\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"df40d057b584de2cf74123a2ef4274de582d6b03\",\"title\":\"Detailed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df40d057b584de2cf74123a2ef4274de582d6b03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134654394\",\"name\":\"Ren C. Luo\"},{\"authorId\":\"34373093\",\"name\":\"Yu-Ting Hsu\"},{\"authorId\":\"123191934\",\"name\":\"Yu-Cheng Wen\"},{\"authorId\":\"151486060\",\"name\":\"Huan-Jun Ye\"}],\"doi\":\"10.1109/ICPHYS.2019.8780171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f10ee8e986c7e1a3f85c28b3e34eb8d5ffcb14ae\",\"title\":\"Visual Image Caption Generation for Service Robotics and Industrial Applications\",\"url\":\"https://www.semanticscholar.org/paper/f10ee8e986c7e1a3f85c28b3e34eb8d5ffcb14ae\",\"venue\":\"2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134654394\",\"name\":\"Ren C. Luo\"},{\"authorId\":\"34373093\",\"name\":\"Yu-Ting Hsu\"},{\"authorId\":\"151486060\",\"name\":\"Huan-Jun Ye\"}],\"doi\":\"10.1109/ISIE.2019.8781144\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02695dca78cfe5c6c4fc7e4659b7ecac2b793bbc\",\"title\":\"Multi-Modal Human-Aware Image Caption System for Intelligent Service Robotics Applications\",\"url\":\"https://www.semanticscholar.org/paper/02695dca78cfe5c6c4fc7e4659b7ecac2b793bbc\",\"venue\":\"2019 IEEE 28th International Symposium on Industrial Electronics (ISIE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d69f69e84c57d92914c03cf028ad8cf0cfe29140\",\"title\":\"Natural Language Description of Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/d69f69e84c57d92914c03cf028ad8cf0cfe29140\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1612.03557\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"afbff808f4a4c6eafcce3858451b9b1a508ecba3\",\"title\":\"Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/afbff808f4a4c6eafcce3858451b9b1a508ecba3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1708.09666\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1145/3078971.3079000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"title\":\"Generating Video Descriptions with Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"title\":\"Generalization to new compositions of known entities in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.05557\",\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e70af721dbf04ab8aacc138d75c808588612289b\",\"title\":\"Phrase-based Image Captioning with Hierarchical LSTM Model\",\"url\":\"https://www.semanticscholar.org/paper/e70af721dbf04ab8aacc138d75c808588612289b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"102853472\",\"name\":\"Jichang Guo\"},{\"authorId\":\"48278008\",\"name\":\"Yan-Wei Pang\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffbff2edb9994ceac5d7b08d0049424974d20eae\",\"title\":\"CNN Region featuresInput image Guided loss SGA SGA Class semantic features Semantic embedding label Attention features Attention features Embedded loss Softm\",\"url\":\"https://www.semanticscholar.org/paper/ffbff2edb9994ceac5d7b08d0049424974d20eae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-019-10045-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f15f92647a02e526c02c1b61bf8bcc5d6b206e99\",\"title\":\"Adaptive Syncretic Attention for Constrained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f15f92647a02e526c02c1b61bf8bcc5d6b206e99\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29395577\",\"name\":\"M. Pap\"},{\"authorId\":\"153827762\",\"name\":\"L. Nagy\"},{\"authorId\":\"24044289\",\"name\":\"D\\u00e1niel Fekete\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4d1174fbff092b74dc4e2d36af4d25d916f43fa\",\"title\":\"Improving E-Learning Material Quality With the Aid of Deep Learning and Workflow Management\",\"url\":\"https://www.semanticscholar.org/paper/f4d1174fbff092b74dc4e2d36af4d25d916f43fa\",\"venue\":\"ICAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3336495\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"715fe60a8615d283c70d12db13857d8948baebca\",\"title\":\"Pseudo-3D Attention Transfer Network with Content-aware Strategy for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/715fe60a8615d283c70d12db13857d8948baebca\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1809.10093\",\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"676d624c7b8642acde0bc70e06b462e93fd83e64\",\"title\":\"Pay attention! - Robustifying a Deep Visuomotor Policy through Task-Focused Attention\",\"url\":\"https://www.semanticscholar.org/paper/676d624c7b8642acde0bc70e06b462e93fd83e64\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738607561\",\"name\":\"S. Nikiforova\"},{\"authorId\":\"2398266\",\"name\":\"Tejaswini Deoskar\"},{\"authorId\":\"2129425\",\"name\":\"D. Paperno\"},{\"authorId\":\"2021738\",\"name\":\"Y. Winter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"569459a9b1ca74bbf4b74908c30dc583d78b59ab\",\"title\":\"Geo-Aware Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/569459a9b1ca74bbf4b74908c30dc583d78b59ab\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410146205\",\"name\":\"Ali Al-Dulaimi\"},{\"authorId\":\"1410519911\",\"name\":\"A. Mohammadi\"},{\"authorId\":\"144762775\",\"name\":\"A. Asif\"}],\"doi\":\"10.36001/PHMCONF.2020.V12I1.1155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36bcecc5538ad3e194b018ab0dcc571e3f0b068a\",\"title\":\"The Noisy Multipath Parallel Hybrid Model for Remaining Useful Life Estimation (NMPM)\",\"url\":\"https://www.semanticscholar.org/paper/36bcecc5538ad3e194b018ab0dcc571e3f0b068a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wadalkar Shruti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"472faa9c5fbc81dac9ee5405446dd8403415ac3a\",\"title\":\"International Journal of Innovative Technology and Exploring Engineering (IJITEE)\",\"url\":\"https://www.semanticscholar.org/paper/472faa9c5fbc81dac9ee5405446dd8403415ac3a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/CRV.2017.51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6718f2feea2d16b894b738551c38871c8afee11b\",\"title\":\"Towards a Knowledge-Based Approach for Generating Video Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6718f2feea2d16b894b738551c38871c8afee11b\",\"venue\":\"2017 14th Conference on Computer and Robot Vision (CRV)\",\"year\":2017},{\"arxivId\":\"1810.10126\",\"authors\":[{\"authorId\":\"1678662\",\"name\":\"Yang Li\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"3422911\",\"name\":\"S. Si\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31b3b0a526683048f69e703d5f098aea0e8a0ce0\",\"title\":\"Area Attention\",\"url\":\"https://www.semanticscholar.org/paper/31b3b0a526683048f69e703d5f098aea0e8a0ce0\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-36718-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"title\":\"SACIC: A Semantics-Aware Convolutional Image Captioner Using Multi-level Pervasive Attention\",\"url\":\"https://www.semanticscholar.org/paper/9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47277026\",\"name\":\"Sayantan Mitra\"},{\"authorId\":\"144231505\",\"name\":\"Mohammed Hasanuzzaman\"},{\"authorId\":\"145470045\",\"name\":\"S. Saha\"},{\"authorId\":\"144315616\",\"name\":\"A. Way\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0389a3b0fcdb4c244628e603ffaff620f6575bfc\",\"title\":\"Incorporating Deep Visual Features into Multiobjective based Multi-view Search Results Clustering\",\"url\":\"https://www.semanticscholar.org/paper/0389a3b0fcdb4c244628e603ffaff620f6575bfc\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"30076791\",\"name\":\"Zhilong Zhou\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9d94b2d61b0b3e06751cccad5e400102ca147c1\",\"title\":\"Cumulative Nets for Edge Detection\",\"url\":\"https://www.semanticscholar.org/paper/e9d94b2d61b0b3e06751cccad5e400102ca147c1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22359702\",\"name\":\"Mhd Wesam Al Nabki\"},{\"authorId\":\"143836787\",\"name\":\"E. Fidalgo\"},{\"authorId\":\"144699677\",\"name\":\"E. Alegre\"},{\"authorId\":\"1403354730\",\"name\":\"Laura Fern\\u00e1ndez-Robles\"}],\"doi\":\"10.1016/J.ESWA.2019.01.029\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad7d77a3cd336228348f00bc2fa129a6dfd9d8f7\",\"title\":\"ToRank: Identifying the most influential suspicious domains in the Tor network\",\"url\":\"https://www.semanticscholar.org/paper/ad7d77a3cd336228348f00bc2fa129a6dfd9d8f7\",\"venue\":\"Expert Syst. Appl.\",\"year\":2019},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1610.02947\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.347\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3dc37dab102a0465098111b7ccf6f95b736397f2\",\"title\":\"End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3dc37dab102a0465098111b7ccf6f95b736397f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033092\",\"name\":\"X. Liu\"},{\"authorId\":\"116740128\",\"name\":\"Hongchen Tan\"},{\"authorId\":\"49144260\",\"name\":\"Xin Tong\"},{\"authorId\":\"1839803\",\"name\":\"J. Cao\"},{\"authorId\":\"13297323\",\"name\":\"Jun Zhou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.07.063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfe9065ce9f22822607e82234551e0c5262ae394\",\"title\":\"Feature preserving GAN and multi-scale feature enhancement for domain adaption person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/cfe9065ce9f22822607e82234551e0c5262ae394\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410146205\",\"name\":\"Ali Al-Dulaimi\"},{\"authorId\":\"36447058\",\"name\":\"Soheil Zabihi\"},{\"authorId\":\"144762775\",\"name\":\"A. Asif\"},{\"authorId\":\"1571262930\",\"name\":\"Arash Mohammed\"}],\"doi\":\"10.1115/1.4045491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"910a0b0b59a777c230e211d8158c80ad639ea212\",\"title\":\"NBLSTM: Noisy and Hybrid Convolutional Neural Network and BLSTM-Based Deep Architecture for Remaining Useful Life Estimation\",\"url\":\"https://www.semanticscholar.org/paper/910a0b0b59a777c230e211d8158c80ad639ea212\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453279481\",\"name\":\"Gonzalo Vaca Castano\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4a851ad57feec3140b574c85851c436dacad8e70\",\"title\":\"Understanding images and videos using context\",\"url\":\"https://www.semanticscholar.org/paper/4a851ad57feec3140b574c85851c436dacad8e70\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.03803\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1145/3240508.3240640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d64f52b94977b71976327eeb3db702b246ee39ce\",\"title\":\"Decoupled Novel Object Captioner\",\"url\":\"https://www.semanticscholar.org/paper/d64f52b94977b71976327eeb3db702b246ee39ce\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1911.04365\",\"authors\":[{\"authorId\":\"9457831\",\"name\":\"J. He\"},{\"authorId\":\"1405953764\",\"name\":\"Quan-Jie Cao\"},{\"authorId\":\"39844955\",\"name\":\"L. Zhang\"},{\"authorId\":\"93970041\",\"name\":\"Hui Tao\"}],\"doi\":\"10.1109/ACCESS.2020.2982571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"587e1359d0a54ecf24e2577357abe79d0cd00ab2\",\"title\":\"Conditionally Learn to Pay Attention for Sequential Visual Task\",\"url\":\"https://www.semanticscholar.org/paper/587e1359d0a54ecf24e2577357abe79d0cd00ab2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027665370\",\"name\":\"Thangarajah Akilan\"},{\"authorId\":\"2038526974\",\"name\":\"Amitha Thiagarajan\"},{\"authorId\":\"72044655\",\"name\":\"B. Venkatesan\"},{\"authorId\":\"2038525344\",\"name\":\"Sowmiya Thirumeni\"},{\"authorId\":\"2038525856\",\"name\":\"Sanjana Gurusamy Chandrasekaran\"}],\"doi\":\"10.1109/SMC42975.2020.9283183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"203191bfd3900917f8580b56509ffd8321675b26\",\"title\":\"Quantifying the Impact of Complementary Visual and Textual Cues Under Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/203191bfd3900917f8580b56509ffd8321675b26\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"2004.12274\",\"authors\":[{\"authorId\":\"29860450\",\"name\":\"Baoyu Jing\"},{\"authorId\":\"1905077\",\"name\":\"Zeya Wang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/P19-1657\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"title\":\"Show, Describe and Conclude: On Exploiting the Structure Information of Chest X-ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1828728685\",\"name\":\"Moustapha Cheikh\"},{\"authorId\":\"1727395\",\"name\":\"M. Zrigui\"}],\"doi\":\"10.1007/978-3-030-53552-0_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"76a1a4aab4cf9eab7899d585481c6db59a4aa198\",\"title\":\"Active Learning Based Framework for Image Captioning Corpus Creation\",\"url\":\"https://www.semanticscholar.org/paper/76a1a4aab4cf9eab7899d585481c6db59a4aa198\",\"venue\":\"LION\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.image.2018.06.002\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f20d5a6f10c269582bd00fd4733bb0066faee302\",\"title\":\"Modeling visual and word-conditional semantic attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f20d5a6f10c269582bd00fd4733bb0066faee302\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46174228\",\"name\":\"Sidra Shabir\"},{\"authorId\":\"49854677\",\"name\":\"Syed Yasser Arafat\"}],\"doi\":\"10.1109/ICPESG.2018.8384519\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"title\":\"An image conveys a message: A brief survey on image description generation\",\"url\":\"https://www.semanticscholar.org/paper/4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"venue\":\"2018 1st International Conference on Power, Energy and Smart Grid (ICPESG)\",\"year\":2018},{\"arxivId\":\"1805.05062\",\"authors\":[{\"authorId\":\"46183659\",\"name\":\"Maha Elbayad\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.18653/v1/P18-1195\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db3340742a56a4bbb9d7ee8dba1958fb132a3c0a\",\"title\":\"Token-level and sequence-level loss smoothing for RNN language models\",\"url\":\"https://www.semanticscholar.org/paper/db3340742a56a4bbb9d7ee8dba1958fb132a3c0a\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"143890943\",\"name\":\"Wenqiang Yan\"},{\"authorId\":\"3120119\",\"name\":\"J. Gao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"39903187\",\"name\":\"J. Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bac495af48328fcdf53992057ca95eb7b0dd6ad6\",\"title\":\"General question module Word level ( a ) Hierarchical pyramid utterance encoder bother\",\"url\":\"https://www.semanticscholar.org/paper/bac495af48328fcdf53992057ca95eb7b0dd6ad6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783874\",\"name\":\"T. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144751998\",\"name\":\"C. He\"}],\"doi\":\"10.1007/s11063-019-09979-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a54a18073b4b4a788e106d540d26817c8c898a63\",\"title\":\"Image Caption with Endogenous\\u2013Exogenous Attention\",\"url\":\"https://www.semanticscholar.org/paper/a54a18073b4b4a788e106d540d26817c8c898a63\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1708.09667\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3123266.3123420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6199348281e14a5a127b539f5cdb92fcddbac17\",\"title\":\"Video Captioning with Guidance of Multimodal Latent Topics\",\"url\":\"https://www.semanticscholar.org/paper/a6199348281e14a5a127b539f5cdb92fcddbac17\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235164\",\"name\":\"J. Wu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144084568\",\"name\":\"Yi Wu\"}],\"doi\":\"10.1145/3271485\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"744d79cfe0b38b2e674c7425dea67492d4f14807\",\"title\":\"Image Captioning via Semantic Guidance Attention and Consensus Selection Strategy\",\"url\":\"https://www.semanticscholar.org/paper/744d79cfe0b38b2e674c7425dea67492d4f14807\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"2008.11990\",\"authors\":[{\"authorId\":\"1392630568\",\"name\":\"Yatin Nandwani\"},{\"authorId\":\"88740553\",\"name\":\"Deepanshu Jindal\"},{\"authorId\":\"2674444\",\"name\":\"Mausam\"},{\"authorId\":\"35108153\",\"name\":\"Parag Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51c62d63c6204deecb24a1d3f9ea8e0a42d23817\",\"title\":\"Neural Learning of One-of-Many Solutions for Combinatorial Problems in Structured Output Spaces\",\"url\":\"https://www.semanticscholar.org/paper/51c62d63c6204deecb24a1d3f9ea8e0a42d23817\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1611.06949\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"title\":\"Dense Captioning with Joint Inference and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-018-9807-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ea4f967ed643d12d74cb1cddbb9b1849fa3e892\",\"title\":\"Image Captioning with Text-Based Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8ea4f967ed643d12d74cb1cddbb9b1849fa3e892\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49668182\",\"name\":\"Maysa M. G. Macedo\"},{\"authorId\":\"30740328\",\"name\":\"D\\u00e1rio A. B. Oliveira\"}],\"doi\":\"10.1117/12.2512661\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c670d1cfe4afabee4daa18291dc1d95419f6b737\",\"title\":\"Exploring features towards semantic characterization of lung nodules in computed tomography images\",\"url\":\"https://www.semanticscholar.org/paper/c670d1cfe4afabee4daa18291dc1d95419f6b737\",\"venue\":\"Medical Imaging\",\"year\":2019},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72830312\",\"name\":\"Kyle Tilbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2236d403bcaa87ec0faf630f0d1a421ac6873f62\",\"title\":\"Word Embeddings for Domain Specific Semantic Relatedness\",\"url\":\"https://www.semanticscholar.org/paper/2236d403bcaa87ec0faf630f0d1a421ac6873f62\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2369400\",\"name\":\"Huiying Ren\"},{\"authorId\":\"35205045\",\"name\":\"Erol Cromwell\"},{\"authorId\":\"2550797\",\"name\":\"B. Kravitz\"},{\"authorId\":\"71912904\",\"name\":\"Xingyuan Chen\"}],\"doi\":\"10.5194/hess-2019-196-supplement\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9ba60fd4827722b8e84f82585239120918aae68\",\"title\":\"Using Deep Learning to Fill Spatio-Temporal Data Gaps in Hydrological Monitoring Networks\",\"url\":\"https://www.semanticscholar.org/paper/a9ba60fd4827722b8e84f82585239120918aae68\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.12585\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"145558281\",\"name\":\"Kai Lei\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.24963/ijcai.2019/708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"title\":\"Exploring and Distilling Cross-Modal Information for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97636424\",\"name\":\"G. Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144303230\",\"name\":\"Ping Liu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICCV.2019.00902\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"title\":\"Entangled Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01fe0c5f0d033141a29f4958f15520798022bbe7\",\"title\":\"ULTRA-CONTEXT: MAXIMIZING THE CONTEXT FOR BETTER IMAGE CAPTION GENERATION\",\"url\":\"https://www.semanticscholar.org/paper/01fe0c5f0d033141a29f4958f15520798022bbe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1624658620\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"1429199889\",\"name\":\"Shaozu Yuan\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"711be95a04da16c93b6bc880169532b68cdca37a\",\"title\":\"Hierarchical Attention-Based Fusion for Image Caption With Multi-Grained Rewards\",\"url\":\"https://www.semanticscholar.org/paper/711be95a04da16c93b6bc880169532b68cdca37a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"title\":\"VisualNews : Benchmark and Challenges in Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.12344\",\"authors\":[{\"authorId\":\"145927744\",\"name\":\"Liang Zhao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13a0023f890af535dd3b7488fde9a4bde2f55bc8\",\"title\":\"Learning Good Representation via Continuous Attention\",\"url\":\"https://www.semanticscholar.org/paper/13a0023f890af535dd3b7488fde9a4bde2f55bc8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.10419\",\"authors\":[{\"authorId\":\"2164604\",\"name\":\"Shervin Minaee\"},{\"authorId\":\"40791823\",\"name\":\"Y. Wang\"},{\"authorId\":\"50999537\",\"name\":\"Alp Aygar\"},{\"authorId\":\"3036744\",\"name\":\"S. Chung\"},{\"authorId\":\"8416385\",\"name\":\"X. Wang\"},{\"authorId\":\"2376478\",\"name\":\"Y. Lui\"},{\"authorId\":\"2977875\",\"name\":\"E. Fieremans\"},{\"authorId\":\"145718573\",\"name\":\"S. Flanagan\"},{\"authorId\":\"31781069\",\"name\":\"J. Rath\"}],\"doi\":\"10.1109/TMI.2019.2905917\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"442190ea079d34e80ed4e89554f84df1a2c06b9f\",\"title\":\"MTBI Identification From Diffusion MR Images Using Bag of Adversarial Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/442190ea079d34e80ed4e89554f84df1a2c06b9f\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2019},{\"arxivId\":\"2003.03749\",\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1109/CVPR42600.2020.01090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96485bda4f4118da249cc8a898230281ac8040a7\",\"title\":\"Better Captioning With Sequence-Level Exploration\",\"url\":\"https://www.semanticscholar.org/paper/96485bda4f4118da249cc8a898230281ac8040a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66290737\",\"name\":\"Qiongjie Cui\"},{\"authorId\":\"2775306\",\"name\":\"Huaijiang Sun\"},{\"authorId\":\"51099754\",\"name\":\"Y. Li\"},{\"authorId\":\"1383119655\",\"name\":\"Yue Kong\"}],\"doi\":\"10.1007/s00521-019-04543-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f732f2d967808cf61d6c81cf5c6306cdb75f753c\",\"title\":\"Efficient human motion recovery using bidirectional attention network\",\"url\":\"https://www.semanticscholar.org/paper/f732f2d967808cf61d6c81cf5c6306cdb75f753c\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40977598\",\"name\":\"Martino Mensio\"},{\"authorId\":\"2972920\",\"name\":\"E. Bastianelli\"},{\"authorId\":\"3174114\",\"name\":\"Ilaria Tiddi\"},{\"authorId\":\"145971067\",\"name\":\"G. Rizzo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e59ae2d94adc58850b4421b5ad4f61bcc1e2571b\",\"title\":\"Mitigating Bias in Deep Nets with Knowledge Bases: the Case of Natural Language Understanding for Robots\",\"url\":\"https://www.semanticscholar.org/paper/e59ae2d94adc58850b4421b5ad4f61bcc1e2571b\",\"venue\":\"AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yiqi Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25102a9c3f6aab9d2b1c990f8a917872dabcaae9\",\"title\":\"Attention-based skin lesion recognition\",\"url\":\"https://www.semanticscholar.org/paper/25102a9c3f6aab9d2b1c990f8a917872dabcaae9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9560397\",\"name\":\"J. Liang\"}],\"doi\":\"10.26153/TSW/1388\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38718ca63f03ced65f2809baa2978415a94066b5\",\"title\":\"Evolutionary neural architecture search for deep learning\",\"url\":\"https://www.semanticscholar.org/paper/38718ca63f03ced65f2809baa2978415a94066b5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48017049\",\"name\":\"H. Wang\"},{\"authorId\":\"48440873\",\"name\":\"Jun Feng\"},{\"authorId\":\"2476328\",\"name\":\"Zizhao Zhang\"},{\"authorId\":\"143729223\",\"name\":\"H. Su\"},{\"authorId\":null,\"name\":\"Lei Cui\"},{\"authorId\":\"144533684\",\"name\":\"H. He\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"}],\"doi\":\"10.1016/j.patcog.2018.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddfd26eaf89a941c412589b3fae5dcc3abcfb226\",\"title\":\"Breast mass classification via deeply integrating the contextual information from multi-view data\",\"url\":\"https://www.semanticscholar.org/paper/ddfd26eaf89a941c412589b3fae5dcc3abcfb226\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39491387\",\"name\":\"J. Zhou\"},{\"authorId\":\"21576252\",\"name\":\"Jiangbo Ai\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"}],\"doi\":\"10.1109/TIP.2018.2855422\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd3d94fac6a282414406716040b10c1746634ecd\",\"title\":\"Video Captioning by Adversarial LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fd3d94fac6a282414406716040b10c1746634ecd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1801.08186\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"title\":\"MAttNet: Modular Attention Network for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144792753\",\"name\":\"Y. Qin\"},{\"authorId\":\"151046769\",\"name\":\"Jiajun Du\"},{\"authorId\":\"48379418\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0c0ac3bb66203c32be81193fabeee44c3585582\",\"title\":\"Look Back and Predict Forward in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0c0ac3bb66203c32be81193fabeee44c3585582\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.11475\",\"authors\":[{\"authorId\":\"1713961937\",\"name\":\"Junxu Cao\"},{\"authorId\":\"1819450790\",\"name\":\"Qi Chen\"},{\"authorId\":\"145505204\",\"name\":\"J. Guo\"},{\"authorId\":\"1899368\",\"name\":\"Ruichao Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bee737b3ab65b750dc5b00f6c8aa6d79c01079a2\",\"title\":\"Attention-guided Context Feature Pyramid Network for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/bee737b3ab65b750dc5b00f6c8aa6d79c01079a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"49728738\",\"name\":\"T. Serre\"}],\"doi\":\"10.1111/nyas.14320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"title\":\"Beyond the feedforward sweep: feedback computations in the visual cortex\",\"url\":\"https://www.semanticscholar.org/paper/83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"venue\":\"Annals of the New York Academy of Sciences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1654172122\",\"name\":\"Shreyasi Charu\"},{\"authorId\":\"91170072\",\"name\":\"S. Mishra\"},{\"authorId\":\"34383888\",\"name\":\"T. Gandhi\"}],\"doi\":\"10.1109/AISP48273.2020.9073009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"712ee361721ce88105f9705b178a1a94f5a3fca4\",\"title\":\"Vision to Language: Captioning Images using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/712ee361721ce88105f9705b178a1a94f5a3fca4\",\"venue\":\"2020 International Conference on Artificial Intelligence and Signal Processing (AISP)\",\"year\":2020},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1799121\",\"name\":\"K. Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/ACCESS.2020.3042484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"832aafb4989c24211a8377f82228c31f7a90ef81\",\"title\":\"Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap\",\"url\":\"https://www.semanticscholar.org/paper/832aafb4989c24211a8377f82228c31f7a90ef81\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49530191\",\"name\":\"S. Bhattacharya\"},{\"authorId\":\"2757153\",\"name\":\"Rajeev Agrawal\"},{\"authorId\":\"1812598\",\"name\":\"Neal Wagner\"}],\"doi\":\"10.1145/3281375.3281405\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a84b972b385109fc9eb76522de8344a5d495763\",\"title\":\"Application of deep learning and geo-knowledge bases to scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/7a84b972b385109fc9eb76522de8344a5d495763\",\"venue\":\"MEDES\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3265845.3265851\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"title\":\"Sports Video Captioning by Attentive Motion Representation based Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"venue\":\"MMSports@MM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3180068\",\"name\":\"D. C. Wyld\"},{\"authorId\":\"1805607\",\"name\":\"D. Nagamalai\"}],\"doi\":\"10.5121/csit.2018.80600\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb3f306c2529c5aea9b10dbe47c9269e04574e00\",\"title\":\"Computer Science & Information Technology\",\"url\":\"https://www.semanticscholar.org/paper/eb3f306c2529c5aea9b10dbe47c9269e04574e00\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34692779\",\"name\":\"K. Chang\"},{\"authorId\":\"10421443\",\"name\":\"Kung-Hung Lu\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"}],\"doi\":\"10.1109/ICCV.2017.380\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"title\":\"Aesthetic Critiques Generation for Photos\",\"url\":\"https://www.semanticscholar.org/paper/c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47075011\",\"name\":\"Cheng Wang\"},{\"authorId\":\"1688587\",\"name\":\"Haojin Yang\"},{\"authorId\":\"1708312\",\"name\":\"C. Meinel\"}],\"doi\":\"10.1145/3115432\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0fe69c9ebf4ede1eb8e2ec233b632031173dd8cb\",\"title\":\"Image Captioning with Deep Bidirectional LSTMs and Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/0fe69c9ebf4ede1eb8e2ec233b632031173dd8cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"2009.09809\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b67759f193e2c39877723424df0b3d5f91c0bf0b\",\"title\":\"Multi-Modal Reasoning Graph for Scene-Text Based Fine-Grained Image Classification and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b67759f193e2c39877723424df0b3d5f91c0bf0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15565853\",\"name\":\"Y. Wu\"},{\"authorId\":\"1697925\",\"name\":\"Kun Chen\"},{\"authorId\":\"1515440027\",\"name\":\"Ziyue Wang\"},{\"authorId\":\"1391222888\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"3151799\",\"name\":\"Fudong Nian\"},{\"authorId\":\"2319426\",\"name\":\"Shengchen Li\"},{\"authorId\":\"50425717\",\"name\":\"Xi Shao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"33dcbaa50f22fa82d26f174300fd67600c58b90a\",\"title\":\"AUDIO CAPTIONING BASED ON TRANSFORMER AND PRE-TRAINING FOR 2020 DCASE AUDIO CAPTIONING CHALLENGE Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/33dcbaa50f22fa82d26f174300fd67600c58b90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1707.05501\",\"authors\":[{\"authorId\":\"2719746\",\"name\":\"Parag Jain\"},{\"authorId\":\"7421228\",\"name\":\"Priyanka Agrawal\"},{\"authorId\":\"1746093\",\"name\":\"A. Mishra\"},{\"authorId\":\"3026786\",\"name\":\"M. Sukhwani\"},{\"authorId\":\"2039596\",\"name\":\"Anirban Laha\"},{\"authorId\":\"145590185\",\"name\":\"K. Sankaranarayanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3740df4c6e7144e2c1bc441e18fa4a996c9d57b9\",\"title\":\"Story Generation from Sequence of Independent Short Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/3740df4c6e7144e2c1bc441e18fa4a996c9d57b9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921534\",\"name\":\"Philip Kinghorn\"},{\"authorId\":\"41204462\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.neucom.2017.07.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"title\":\"A region-based image caption generator with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1901.04140\",\"authors\":[{\"authorId\":\"3112540\",\"name\":\"Xuehui Sun\"},{\"authorId\":\"2519795\",\"name\":\"Zihan Zhou\"},{\"authorId\":\"65858577\",\"name\":\"Yuda Fan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"38152bcfbf7fe3bbf51bd70c378fc74dff126109\",\"title\":\"Image Based Review Text Generation with Emotional Guidance\",\"url\":\"https://www.semanticscholar.org/paper/38152bcfbf7fe3bbf51bd70c378fc74dff126109\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"}],\"doi\":\"10.1109/CVPR.2018.00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2115fe369b3a6b859c6992ba023d5c11b1689801\",\"title\":\"GroupCap: Group-Based Image Captioning with Structured Relevance and Diversity Constraints\",\"url\":\"https://www.semanticscholar.org/paper/2115fe369b3a6b859c6992ba023d5c11b1689801\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"title\":\"Image Input OR Video Hierarchical LSTMs with Adaptive Attention ( hLSTMat ) Feature Extraction Generated Captions Losses\",\"url\":\"https://www.semanticscholar.org/paper/e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47829872\",\"name\":\"Fangfang Yang\"},{\"authorId\":\"32705896\",\"name\":\"Xiangbao Song\"},{\"authorId\":\"49613445\",\"name\":\"Fan Xu\"},{\"authorId\":\"145690550\",\"name\":\"Kwok-Leung Tsui\"}],\"doi\":\"10.1109/ACCESS.2019.2912803\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2da9039a4075b82e0f60fc0e678d243fca37192e\",\"title\":\"State-of-Charge Estimation of Lithium-Ion Batteries via Long Short-Term Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/2da9039a4075b82e0f60fc0e678d243fca37192e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1905.07075\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"123813779\",\"name\":\"Lucas Van Bramer\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"418003534843f0fdda7dfb1d41c35bef683b1dad\",\"title\":\"Deep Unified Multimodal Embeddings for Understanding both Content and Users in Social Media Networks\",\"url\":\"https://www.semanticscholar.org/paper/418003534843f0fdda7dfb1d41c35bef683b1dad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120383870\",\"name\":\"Yuhao Tang\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"143698886\",\"name\":\"Hongjie Jia\"},{\"authorId\":\"3309006\",\"name\":\"Heping Song\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/access.2019.2911714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d77867dace136e48ffadb912507e2518e867d673\",\"title\":\"An Emotion-Embedded Visual Attention Model for Dimensional Emotion Context Learning\",\"url\":\"https://www.semanticscholar.org/paper/d77867dace136e48ffadb912507e2518e867d673\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103839060\",\"name\":\"Ariyo Oluwasanmi\"},{\"authorId\":\"32593111\",\"name\":\"Muhammad Umar Aftab\"},{\"authorId\":\"30511154\",\"name\":\"Eatedal Alabdulkreem\"},{\"authorId\":\"1395577736\",\"name\":\"Bulbula Kumeda\"},{\"authorId\":\"46352756\",\"name\":\"Edward Y. Baagyere\"},{\"authorId\":\"152179239\",\"name\":\"Zhiquang Qin\"}],\"doi\":\"10.1109/ACCESS.2019.2931223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfe95e9dca1f07db5f0672c65943f22aace00e04\",\"title\":\"CaptionNet: Automatic End-to-End Siamese Difference Captioning Model With Attention\",\"url\":\"https://www.semanticscholar.org/paper/cfe95e9dca1f07db5f0672c65943f22aace00e04\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147063407\",\"name\":\"Jo\\u00e3o Carlos Silva Ferreira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9214671afab8a30d57109d4c5e0df99e4c4b3e14\",\"title\":\"Live web prototypes from hand-drawn mockups\",\"url\":\"https://www.semanticscholar.org/paper/9214671afab8a30d57109d4c5e0df99e4c4b3e14\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.02282\",\"authors\":[{\"authorId\":\"48702134\",\"name\":\"J. Schneider\"},{\"authorId\":\"30022391\",\"name\":\"Marcus Basalla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73cebb07969d99391edfad66537c42272b46dfc6\",\"title\":\"Creativity of Deep Learning: Conceptualization and Assessment\",\"url\":\"https://www.semanticscholar.org/paper/73cebb07969d99391edfad66537c42272b46dfc6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34020906\",\"name\":\"A. Apicella\"},{\"authorId\":\"13851143\",\"name\":\"A. Corazza\"},{\"authorId\":\"34675913\",\"name\":\"F. Isgr\\u00f2\"},{\"authorId\":\"1830773\",\"name\":\"Giuseppe Vettigli\"}],\"doi\":\"10.3390/info9100252\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e08dcf5e8fb1e5a59408c267af64145ce2e9daeb\",\"title\":\"Integration of Context Information through Probabilistic Ontological Knowledge into Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/e08dcf5e8fb1e5a59408c267af64145ce2e9daeb\",\"venue\":\"Inf.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1903.10658\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICCV.2019.01042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"title\":\"Unpaired Image Captioning via Scene Graph Alignments\",\"url\":\"https://www.semanticscholar.org/paper/f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144137447\",\"name\":\"Tao Zhou\"},{\"authorId\":\"1391051492\",\"name\":\"Y. Quan\"}],\"doi\":\"10.1109/IJCNN.2019.8852118\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"title\":\"Image Captioning Based On Sentence-Level And Word-Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3240508.3240614\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"392589e60f203b19b1d314ff1005182a668c594b\",\"title\":\"Learning Joint Multimodal Representation with Adversarial Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/392589e60f203b19b1d314ff1005182a668c594b\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692551\",\"name\":\"L. Chen\"},{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"144291579\",\"name\":\"Zibin Zheng\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1145/3269206.3271759\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d0a1644d52cfbf494c3886913e6e237cdfa419f\",\"title\":\"Heterogeneous Neural Attentive Factorization Machine for Rating Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0d0a1644d52cfbf494c3886913e6e237cdfa419f\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1803.11439\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"144188763\",\"name\":\"Jian Yao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00834\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"title\":\"Regularizing RNNs for Caption Generation by Reconstructing the Past with the Present\",\"url\":\"https://www.semanticscholar.org/paper/85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Yuxiao Chen\"},{\"authorId\":null,\"name\":\"Han Guo\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/BigData.2018.8622513\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d77731d2b2e0c8be5bf2d247974029f769064529\",\"title\":\"You Type a Few Words and We Do the Rest: Image Recommendation for Social Multimedia Posts\",\"url\":\"https://www.semanticscholar.org/paper/d77731d2b2e0c8be5bf2d247974029f769064529\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"}],\"doi\":\"10.1145/3123266.3130143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dee363341b1b9d9aae382b0b1157fd82c1511b85\",\"title\":\"Social Multimedia Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dee363341b1b9d9aae382b0b1157fd82c1511b85\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51065291\",\"name\":\"Dagmawi Moges\"},{\"authorId\":\"144956396\",\"name\":\"H. Qu\"},{\"authorId\":\"51066540\",\"name\":\"Mingsheng Fu\"}],\"doi\":\"10.1145/3373419.3373430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"473c1a96516a02cca3738af68c808f7d8ff4bead\",\"title\":\"Multi-Head Bidirectional Attention for MRC\",\"url\":\"https://www.semanticscholar.org/paper/473c1a96516a02cca3738af68c808f7d8ff4bead\",\"venue\":\"ICAIP 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97713340\",\"name\":\"X. Liu\"},{\"authorId\":\"1943870\",\"name\":\"Weibin Liu\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f55a588eef043cbb72ee548714d623b573c21e9b\",\"title\":\"Image Caption Generation with Local Semantic Information and Global Information\",\"url\":\"https://www.semanticscholar.org/paper/f55a588eef043cbb72ee548714d623b573c21e9b\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9358850\",\"name\":\"Ruifan Li\"},{\"authorId\":\"4189987\",\"name\":\"Haoyu Liang\"},{\"authorId\":\"46571714\",\"name\":\"Yihui Shi\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1016/j.neucom.2020.02.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f85b7e09e60315d725b316ffc813d20535b21b2\",\"title\":\"Dual-CNN: A Convolutional language decoder for paragraph image captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f85b7e09e60315d725b316ffc813d20535b21b2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1007/978-3-030-20876-9_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d03fbd355ca9879e436d19e77b8d23a70cb192a\",\"title\":\"Dynamic Gated Graph Neural Networks for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/3d03fbd355ca9879e436d19e77b8d23a70cb192a\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1909.13516\",\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"1380223985\",\"name\":\"Jingdong Shu\"},{\"authorId\":\"34296085\",\"name\":\"Yulei Sui\"},{\"authorId\":\"1747560\",\"name\":\"Guandong Xu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"97569165\",\"name\":\"Jian Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/ASE.2019.00012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0998353a6a342143c08e152650c0146adc61d94b\",\"title\":\"Multi-modal Attention Network Learning for Semantic Source Code Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0998353a6a342143c08e152650c0146adc61d94b\",\"venue\":\"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\"year\":2019},{\"arxivId\":\"1811.08728\",\"authors\":[{\"authorId\":\"47368376\",\"name\":\"C. Wilms\"},{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"}],\"doi\":\"10.1007/978-3-030-20890-5_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25e8b5844118fcace64890e9b7efc5940d230f9c\",\"title\":\"AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects\",\"url\":\"https://www.semanticscholar.org/paper/25e8b5844118fcace64890e9b7efc5940d230f9c\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":\"10.18653/v1/W19-8668\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c6b67838d895f08a177634f553b5dfc669f44c5\",\"title\":\"What goes into a word: generating image descriptions with top-down spatial knowledge\",\"url\":\"https://www.semanticscholar.org/paper/7c6b67838d895f08a177634f553b5dfc669f44c5\",\"venue\":\"INLG\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"144493052\",\"name\":\"Z. Zhao\"},{\"authorId\":\"2577617\",\"name\":\"Yueying He\"}],\"doi\":\"10.1016/j.knosys.2018.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"title\":\"From content to links: Social image embedding with deep multimodal model\",\"url\":\"https://www.semanticscholar.org/paper/31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"venue\":\"Knowl. Based Syst.\",\"year\":2018},{\"arxivId\":\"1803.01457\",\"authors\":[{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"47527850\",\"name\":\"W. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1007/978-3-030-01261-8_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"title\":\"Less Is More: Picking Informative Frames for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1402383926\",\"name\":\"D. Pastor-Escuredo\"},{\"authorId\":\"118974449\",\"name\":\"J. C. del \\u00c1lamo\"}],\"doi\":\"10.3389/fphy.2020.00031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5960d76a7124891e469fccf8ee575205a2bbb910\",\"title\":\"How Computation Is Helping Unravel the Dynamics of Morphogenesis\",\"url\":\"https://www.semanticscholar.org/paper/5960d76a7124891e469fccf8ee575205a2bbb910\",\"venue\":\"Frontiers in Physics\",\"year\":2020},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Yuxiao Chen\"},{\"authorId\":null,\"name\":\"Han Guo\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3184558.3186346\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1bb6bf3de3101863b03fd6ce643a68bc30fa256\",\"title\":\"When E-commerce Meets Social Media: Identifying Business on WeChat Moment Using Bilateral-Attention LSTM\",\"url\":\"https://www.semanticscholar.org/paper/f1bb6bf3de3101863b03fd6ce643a68bc30fa256\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"49403723\",\"name\":\"H. Li\"},{\"authorId\":\"102696161\",\"name\":\"Rui Wang\"},{\"authorId\":\"38865491\",\"name\":\"Xiaohui Hu\"}],\"doi\":\"10.1109/ICTAI50040.2020.00119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f9791def36fd6e2e701b0d5d5c44063a9da473\",\"title\":\"Enhanced soft attention mechanism with an inception-like module for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9791def36fd6e2e701b0d5d5c44063a9da473\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1879303113\",\"name\":\"Depeng Wang\"},{\"authorId\":\"7690231\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"1877859275\",\"name\":\"Yuanen Zhou\"},{\"authorId\":\"1390610633\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"152318056\",\"name\":\"L. Wu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/icmew46912.2020.9106007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61cc97db488acc841cc31ffe046957829c366b53\",\"title\":\"A Text-Guided Graph Structure for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/61cc97db488acc841cc31ffe046957829c366b53\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"2004.13846\",\"authors\":[{\"authorId\":\"1661218221\",\"name\":\"Kenya Sakka\"},{\"authorId\":\"1943224\",\"name\":\"K. Nakayama\"},{\"authorId\":\"1661219175\",\"name\":\"Nisei Kimura\"},{\"authorId\":\"6937940\",\"name\":\"T. Inoue\"},{\"authorId\":\"1715282\",\"name\":\"Yusuke Iwasawa\"},{\"authorId\":\"152962999\",\"name\":\"R. Yamaguchi\"},{\"authorId\":\"1661217362\",\"name\":\"Yosimasa Kawazoe\"},{\"authorId\":\"1765631\",\"name\":\"K. Ohe\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.1007/978-3-030-53352-6_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59dfb5b3c4ebd14e0e3128d421ec40cd99b3a2e7\",\"title\":\"Character-level Japanese Text Generation with Attention Mechanism for Chest Radiography Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/59dfb5b3c4ebd14e0e3128d421ec40cd99b3a2e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"134473682\",\"name\":\"Mingwen Shao\"},{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"}],\"doi\":\"10.1016/j.neucom.2019.12.073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50260b547a481a95a2346759da8dba9366e89348\",\"title\":\"Multi-Attention Generative Adversarial Network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/50260b547a481a95a2346759da8dba9366e89348\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1802.00924\",\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3136755.3136801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"title\":\"Multimodal sentiment analysis with word-level fusion and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":\"1707.02485\",\"authors\":[{\"authorId\":\"2476328\",\"name\":\"Zizhao Zhang\"},{\"authorId\":\"1877955\",\"name\":\"Yuanpu Xie\"},{\"authorId\":\"2082604\",\"name\":\"F. Xing\"},{\"authorId\":\"46671753\",\"name\":\"M. McGough\"},{\"authorId\":\"144890162\",\"name\":\"L. Yang\"}],\"doi\":\"10.1109/CVPR.2017.378\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4a3df5823d32075ef2227cc3671aff24a8d8634\",\"title\":\"MDNet: A Semantically and Visually Interpretable Medical Image Diagnosis Network\",\"url\":\"https://www.semanticscholar.org/paper/a4a3df5823d32075ef2227cc3671aff24a8d8634\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18111246\",\"name\":\"Bogdan Mazoure\"},{\"authorId\":\"33554869\",\"name\":\"Thang Doan\"},{\"authorId\":\"2238154\",\"name\":\"S. Ray\"}],\"doi\":\"10.18653/v1/W18-6240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b852a4e5026ab962050a0ef23a6892e06abb152\",\"title\":\"EmojiGAN: learning emojis distributions with a generative model\",\"url\":\"https://www.semanticscholar.org/paper/2b852a4e5026ab962050a0ef23a6892e06abb152\",\"venue\":\"WASSA@EMNLP\",\"year\":2018},{\"arxivId\":\"1810.12686\",\"authors\":[{\"authorId\":\"81493694\",\"name\":\"Guy Tevet\"},{\"authorId\":\"81272781\",\"name\":\"Gavriel Habib\"},{\"authorId\":\"3103343\",\"name\":\"Vered Shwartz\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"}],\"doi\":\"10.18653/v1/N19-1233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c253dc6d35df2bc5932fecdfa9169a8e663dc31\",\"title\":\"Evaluating Text GANs as Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2c253dc6d35df2bc5932fecdfa9169a8e663dc31\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.05021\",\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"143890941\",\"name\":\"Wenqiang Yan\"},{\"authorId\":\"3120119\",\"name\":\"J. Gao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49387520\",\"name\":\"J. Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/BigData.2018.8622245\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd54d2e50639e0b237d5ff8db195106d6bb3d42e\",\"title\":\"Improved Dynamic Memory Network for Dialogue Act Classification with Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/fd54d2e50639e0b237d5ff8db195106d6bb3d42e\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.398\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"venue\":\"ICCV 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.3233/IA-170033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"title\":\"Attentive models in vision: Computing saliency maps in the deep learning era\",\"url\":\"https://www.semanticscholar.org/paper/9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"venue\":\"Intelligenza Artificiale\",\"year\":2018},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3c3633d08316fe527b7836b4038359538088fa8e\",\"title\":\"Visual Sentiment Analysis by Attending on Local Image Regions\",\"url\":\"https://www.semanticscholar.org/paper/3c3633d08316fe527b7836b4038359538088fa8e\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9377628\",\"name\":\"S. Sehgal\"},{\"authorId\":\"47231598\",\"name\":\"J. Sharma\"},{\"authorId\":\"1961030572\",\"name\":\"Natasha Chaudhary\"}],\"doi\":\"10.1109/ICRITO48877.2020.9197977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"787415b2e7d11dfc895e78221cb044085620d830\",\"title\":\"Generating Image Captions based on Deep Learning and Natural language Processing\",\"url\":\"https://www.semanticscholar.org/paper/787415b2e7d11dfc895e78221cb044085620d830\",\"venue\":\"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2873524\",\"name\":\"Z. Ma\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"150347046\",\"name\":\"Yangyang Cheng\"},{\"authorId\":\"51000590\",\"name\":\"Xinrui Zhu\"}],\"doi\":\"10.1109/ICME.2019.00225\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"daad11aee75bcf597602e654c33a12de61343dda\",\"title\":\"Image-to-Tree: A Tree-Structured Decoder for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/daad11aee75bcf597602e654c33a12de61343dda\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1910.11033\",\"authors\":[{\"authorId\":\"73659073\",\"name\":\"T. Hascoet\"},{\"authorId\":\"12658654\",\"name\":\"Xue-jiao Deng\"},{\"authorId\":\"46932377\",\"name\":\"K. Tai\"},{\"authorId\":\"14425978\",\"name\":\"M. Sugiyama\"},{\"authorId\":\"48715900\",\"name\":\"Y. Adachi\"},{\"authorId\":\"47046257\",\"name\":\"S. Nakamura\"},{\"authorId\":\"1678564\",\"name\":\"Y. Ariki\"},{\"authorId\":\"49604548\",\"name\":\"T. Hayashi\"},{\"authorId\":\"1388661285\",\"name\":\"Tetusya Takiguchi\"}],\"doi\":\"10.1109/ICCVW.2019.00519\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94705d9bc8580c3d0c64000689c3389dae6e2755\",\"title\":\"Assisting human experts in the interpretation of their visual process: A case study on assessing copper surface adhesive potency\",\"url\":\"https://www.semanticscholar.org/paper/94705d9bc8580c3d0c64000689c3389dae6e2755\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"49713266\",\"name\":\"Fan Jia\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2017.656\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca738cb87bb49495e20be72adffce37bb8990368\",\"title\":\"Diverse Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/ca738cb87bb49495e20be72adffce37bb8990368\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1908.00249\",\"authors\":[{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.24963/ijcai.2019/132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"title\":\"Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Huang\"},{\"authorId\":\"51231229\",\"name\":\"Fengqi Yan\"},{\"authorId\":\"40515617\",\"name\":\"W. Xu\"},{\"authorId\":\"1716059\",\"name\":\"M. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2947134\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12e9fb63e5b46b241fed3ab2e9d95219db80e056\",\"title\":\"Multi-Attention and Incorporating Background Information Model for Chest X-Ray Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/12e9fb63e5b46b241fed3ab2e9d95219db80e056\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1711.06475\",\"authors\":[{\"authorId\":\"3165417\",\"name\":\"J. Wu\"},{\"authorId\":\"145565491\",\"name\":\"He Zheng\"},{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"47003565\",\"name\":\"Yixin Li\"},{\"authorId\":\"50736086\",\"name\":\"Baoming Yan\"},{\"authorId\":\"143978866\",\"name\":\"R. Liang\"},{\"authorId\":\"46314609\",\"name\":\"Wenjia Wang\"},{\"authorId\":\"14547213\",\"name\":\"Shipei Zhou\"},{\"authorId\":\"33344887\",\"name\":\"Guosen Lin\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"36637369\",\"name\":\"Y. Wang\"},{\"authorId\":\"47904050\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ff40f0760bd8d3c46d72147b0f5b0d4aee2a24f\",\"title\":\"AI Challenger : A Large-scale Dataset for Going Deeper in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3ff40f0760bd8d3c46d72147b0f5b0d4aee2a24f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab7048d6fd8ea5b6daa060aa9996554bd4058f09\",\"title\":\"Areas of Attention for Image Captioning \\u2014 Supplementary Material \\u2014\",\"url\":\"https://www.semanticscholar.org/paper/ab7048d6fd8ea5b6daa060aa9996554bd4058f09\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af258688503b48c1028680c67eb12cb351e9830a\",\"title\":\"Visual grounding of spatial relations in recurrent neural language models\",\"url\":\"https://www.semanticscholar.org/paper/af258688503b48c1028680c67eb12cb351e9830a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"}],\"doi\":\"10.1109/BigMM.2018.8499357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"title\":\"Video Captioning with Semantic Guiding\",\"url\":\"https://www.semanticscholar.org/paper/ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1712.02051\",\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"49490596\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d190282ed59639b16e726a3237938b53976077\",\"title\":\"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d190282ed59639b16e726a3237938b53976077\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ramin M. Hasani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6adb6c9115433ee96f57a3a4a5a325a985887acd\",\"title\":\"Interpretable Recurrent Neural Networks in Continuous-time Control Environments\",\"url\":\"https://www.semanticscholar.org/paper/6adb6c9115433ee96f57a3a4a5a325a985887acd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32730921\",\"name\":\"J. Wang\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"4634604\",\"name\":\"Xinyuan Qi\"}],\"doi\":\"10.1117/12.2284665\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aca34f9dfdd471e64c0cb7aaa88a2cdf64df66ad\",\"title\":\"Supervised guiding long-short term memory for image caption generation based on object classes\",\"url\":\"https://www.semanticscholar.org/paper/aca34f9dfdd471e64c0cb7aaa88a2cdf64df66ad\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49908183\",\"name\":\"R. Wang\"},{\"authorId\":\"3069541\",\"name\":\"Toru Wakahara\"}],\"doi\":\"10.1145/3342999.3343004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7a57277acde8c881403be006f7c0b1462c571dc\",\"title\":\"Practice in Caption Generation with Keras: The Design and Evaluation for Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/d7a57277acde8c881403be006f7c0b1462c571dc\",\"venue\":\"ICDLT 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/978-3-030-00563-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"title\":\"Attend to Knowledge: Memory-Enhanced Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145082091\",\"name\":\"Jianbo Zheng\"},{\"authorId\":\"1747615\",\"name\":\"Teng-Yok Lee\"},{\"authorId\":\"48931599\",\"name\":\"Chen Feng\"},{\"authorId\":\"113778242\",\"name\":\"Xiaohua Lit\"},{\"authorId\":\"7969330\",\"name\":\"Ziming Zhang\"}],\"doi\":\"10.1109/ICPR.2018.8545607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d399b86d4c67472fd65e9466359a43ef2f914f97\",\"title\":\"Robust Attentional Pooling via Feature Selection\",\"url\":\"https://www.semanticscholar.org/paper/d399b86d4c67472fd65e9466359a43ef2f914f97\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3456884\",\"name\":\"T. Thomas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43c5be1f64e0135fb3d6e43a9c33caaaa58f7213\",\"title\":\"The Emotional Impact of Audio - Visual Stimuli\",\"url\":\"https://www.semanticscholar.org/paper/43c5be1f64e0135fb3d6e43a9c33caaaa58f7213\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151901\",\"name\":\"B. Huber\"},{\"authorId\":\"1801452\",\"name\":\"D. McDuff\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":\"10.1145/3173574.3173851\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58da24cf5db383781a9803a4dbe97e443c8a3b29\",\"title\":\"Emotional Dialogue Generation using Image-Grounded Language Models\",\"url\":\"https://www.semanticscholar.org/paper/58da24cf5db383781a9803a4dbe97e443c8a3b29\",\"venue\":\"CHI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145093155\",\"name\":\"Min Xu\"},{\"authorId\":\"1677510167\",\"name\":\"Lingxiang Wu\"},{\"authorId\":\"121134294\",\"name\":\"S. Qian\"},{\"authorId\":\"3061725\",\"name\":\"Jianwei Cui\"}],\"doi\":\"10.1145/3381858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"238611bc2a79d64271a2238cf164bcfde3e5cb13\",\"title\":\"Image to Modern Chinese Poetry Creation via a Constrained Topic-aware Model\",\"url\":\"https://www.semanticscholar.org/paper/238611bc2a79d64271a2238cf164bcfde3e5cb13\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1007/978-3-030-37731-1_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"title\":\"Image Captioning Based on Visual and Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.06426\",\"authors\":[{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"143979421\",\"name\":\"F. Xu\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"title\":\"Tell-the-difference: Fine-grained Visual Descriptor via a Discriminating Referee\",\"url\":\"https://www.semanticscholar.org/paper/dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1906.03502\",\"authors\":[{\"authorId\":\"145837171\",\"name\":\"V. Kurmi\"},{\"authorId\":\"32661123\",\"name\":\"S. Kumar\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/CVPR.2019.00058\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"763dc34af43b4d00b8a625ade38d6e314478ecc5\",\"title\":\"Attending to Discriminative Certainty for Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/763dc34af43b4d00b8a625ade38d6e314478ecc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.08473\",\"authors\":[{\"authorId\":\"143672100\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"32878737\",\"name\":\"M. Kato\"},{\"authorId\":\"1740865\",\"name\":\"M. Yoshikawa\"}],\"doi\":\"10.1145/3240508.3240587\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99e56f1fd88d967aab6be2a51f3633697e2df667\",\"title\":\"Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/99e56f1fd88d967aab6be2a51f3633697e2df667\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47421395\",\"name\":\"Shuai Yu\"},{\"authorId\":null,\"name\":\"Lei Shen\"},{\"authorId\":\"145417170\",\"name\":\"P. Zhu\"},{\"authorId\":\"50762864\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/IJCNN.2018.8489304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63962166a606c3f7be2e2b4d51ac8468386eb3a6\",\"title\":\"ACJIS: A Novel Attentive Cross Approach For Joint Intent Detection And Slot Filling\",\"url\":\"https://www.semanticscholar.org/paper/63962166a606c3f7be2e2b4d51ac8468386eb3a6\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3384975\",\"name\":\"W. Ren\"},{\"authorId\":\"1774000\",\"name\":\"Jiandong Tian\"},{\"authorId\":\"92735257\",\"name\":\"Q. Wang\"},{\"authorId\":\"1684088\",\"name\":\"Y. Tang\"}],\"doi\":\"10.1109/LSP.2020.2970345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5605ab3bec98389243fcd9c03b4d3450e3e2054\",\"title\":\"Dually Connected Deraining Net Using Pixel-Wise Attention\",\"url\":\"https://www.semanticscholar.org/paper/b5605ab3bec98389243fcd9c03b4d3450e3e2054\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"1791344388\",\"name\":\"Lei Ji\"},{\"authorId\":\"1783553\",\"name\":\"Zhen-dong Niu\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3394171.3413498\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de4eabc5a672e5c3c1b3acbfa724cd8c85169c8c\",\"title\":\"Learning Semantic Concepts and Temporal Alignment for Narrated Video Procedural Captioning\",\"url\":\"https://www.semanticscholar.org/paper/de4eabc5a672e5c3c1b3acbfa724cd8c85169c8c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49168719\",\"name\":\"C. Yin\"},{\"authorId\":\"39835284\",\"name\":\"B. Qian\"},{\"authorId\":\"39791510\",\"name\":\"Jishang Wei\"},{\"authorId\":\"4185657\",\"name\":\"X. Li\"},{\"authorId\":\"1491248835\",\"name\":\"X. Zhang\"},{\"authorId\":\"48514123\",\"name\":\"Y. Li\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"}],\"doi\":\"10.1109/ICDM.2019.00083\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b19f5a65e327868bf31a85fc03752b58e09d0d03\",\"title\":\"Automatic Generation of Medical Imaging Diagnostic Report with Hierarchical Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b19f5a65e327868bf31a85fc03752b58e09d0d03\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1810.04101\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"2120874\",\"name\":\"Tobias Domhan\"},{\"authorId\":\"2521764\",\"name\":\"F. Hieber\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"title\":\"Image Captioning as Neural Machine Translation Task in SOCKEYE\",\"url\":\"https://www.semanticscholar.org/paper/d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934466\",\"name\":\"Junwei Zhou\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2710247\",\"name\":\"Jizhong Han\"},{\"authorId\":\"144553025\",\"name\":\"S. Hu\"},{\"authorId\":\"2755326\",\"name\":\"Hongchao Gao\"}],\"doi\":\"10.1109/BigMM.2018.8499060\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"title\":\"Spatial- Temporal Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1912.00759\",\"authors\":[{\"authorId\":\"1438951250\",\"name\":\"A. M. Sudoso\"},{\"authorId\":\"2549848\",\"name\":\"V. Piccialli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21fb6bab91a745ddc278930f9cb6775dfbaf7b6e\",\"title\":\"Non-Intrusive Load Monitoring with an Attention-based Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/21fb6bab91a745ddc278930f9cb6775dfbaf7b6e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9455885\",\"name\":\"Ankit Rathi\"}],\"doi\":\"10.1109/ICCECE48148.2020.9223087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a93629ec132628e86ff7ab6cd21099f5968d58bf\",\"title\":\"Deep learning apporach for image captioning in Hindi language\",\"url\":\"https://www.semanticscholar.org/paper/a93629ec132628e86ff7ab6cd21099f5968d58bf\",\"venue\":\"2020 International Conference on Computer, Electrical & Communication Engineering (ICCECE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104586310\",\"name\":\"Xiancheng Xie\"},{\"authorId\":\"33629364\",\"name\":\"Y. Xiong\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"8497959\",\"name\":\"Kangan Li\"},{\"authorId\":\"48692260\",\"name\":\"Suhua Zhang\"},{\"authorId\":\"8247706\",\"name\":\"Yangyong Zhu\"}],\"doi\":\"10.1007/978-3-030-18590-9_64\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43636059d91353bead413923c1bf5bfac5c4cdd6\",\"title\":\"Attention-Based Abnormal-Aware Fusion Network for Radiology Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/43636059d91353bead413923c1bf5bfac5c4cdd6\",\"venue\":\"DASFAA\",\"year\":2019},{\"arxivId\":\"1609.03976\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7876f448942e2658c3911c42b32ced10f85a4800\",\"title\":\"Multimodal Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/7876f448942e2658c3911c42b32ced10f85a4800\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1703.06233\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.57\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"title\":\"Recurrent Models for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"4303531\",\"name\":\"Lixi Deng\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7d1a7dae43b630d61d19d6cf139824380f2cf42f\",\"title\":\"Image Caption with Global-Local Attention\",\"url\":\"https://www.semanticscholar.org/paper/7d1a7dae43b630d61d19d6cf139824380f2cf42f\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1702.07191\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5075fa79da6cd7b81e5d3dc24161217ef86368\",\"title\":\"ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/da5075fa79da6cd7b81e5d3dc24161217ef86368\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"1768065\",\"name\":\"Yusuke Miyao\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1145/3123266.3127898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2e0e08e4d4c722d0f54f5a124ca28a67d74ce3e\",\"title\":\"MANet: A Modal Attention Network for Describing Videos\",\"url\":\"https://www.semanticscholar.org/paper/b2e0e08e4d4c722d0f54f5a124ca28a67d74ce3e\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/ISM.2018.00021\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"title\":\"Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":\"1903.05942\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"title\":\"Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning\",\"url\":\"https://www.semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3431037\",\"name\":\"J. Qi\"}],\"doi\":\"10.1109/TMM.2018.2877885\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7032cff8767425ab69c8f430a4869e5fd9a97eb5\",\"title\":\"Show and Tell in the Loop: Cross-Modal Circular Correlation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7032cff8767425ab69c8f430a4869e5fd9a97eb5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49776272\",\"name\":\"Pengfei Cao\"},{\"authorId\":\"47087612\",\"name\":\"Z. Yang\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"},{\"authorId\":\"145629787\",\"name\":\"Y. Liang\"},{\"authorId\":\"1717198\",\"name\":\"M. Yang\"},{\"authorId\":\"144479376\",\"name\":\"Renchu Guan\"}],\"doi\":\"10.1007/s11063-018-09973-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"16efc1a4c7cdf8bc6d49cc326542e1fe1c88456b\",\"title\":\"Image Captioning with Bidirectional Semantic Attention-Based Guiding of Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/16efc1a4c7cdf8bc6d49cc326542e1fe1c88456b\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3863922\",\"name\":\"C. Yan\"},{\"authorId\":\"26994223\",\"name\":\"Yunbin Tu\"},{\"authorId\":\"48631703\",\"name\":\"Xingzheng Wang\"},{\"authorId\":\"5094646\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145922541\",\"name\":\"Xinhong Hao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"}],\"doi\":\"10.1109/TMM.2019.2924576\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fcd73e0c09f35bfeb7d0db7426d50d3610bf46d\",\"title\":\"STAT: Spatial-Temporal Attention Mechanism for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1fcd73e0c09f35bfeb7d0db7426d50d3610bf46d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"145414746\",\"name\":\"Kun Fu\"},{\"authorId\":\"143900006\",\"name\":\"Lei Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"title\":\"Image Captioning with Partially Rewarded Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41134094\",\"name\":\"V. Batra\"},{\"authorId\":\"1704133\",\"name\":\"Yulan He\"},{\"authorId\":\"1737941\",\"name\":\"George Vogiatzis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7395112e0b27733ed4fe2bcdb04252efc8d5dfdf\",\"title\":\"Neural Caption Generation for News Images\",\"url\":\"https://www.semanticscholar.org/paper/7395112e0b27733ed4fe2bcdb04252efc8d5dfdf\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1707.07250\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D17-1115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"title\":\"Tensor Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3241910\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"title\":\"Images2Poem: Generating Chinese Poetry from Image Streams\",\"url\":\"https://www.semanticscholar.org/paper/c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1909.05316\",\"authors\":[{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.1609/AAAI.V34I05.6305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"title\":\"What Makes A Good Story? Designing Composite Rewards for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41048842\",\"name\":\"Tonmoay Deb\"},{\"authorId\":\"152359104\",\"name\":\"M. Ali\"},{\"authorId\":\"152398205\",\"name\":\"S. Bhowmik\"},{\"authorId\":\"1972671\",\"name\":\"A. Firoze\"},{\"authorId\":\"152242250\",\"name\":\"Syed Shahir Ahmed\"},{\"authorId\":\"1395633906\",\"name\":\"Muhammad Abeer Tahmeed\"},{\"authorId\":\"145057622\",\"name\":\"N. Rahman\"},{\"authorId\":\"1732925\",\"name\":\"Rashedur M. Rahman\"}],\"doi\":\"10.3233/JIFS-179351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40ba4d6ebb66673bea62b1889f6fcde139f4b816\",\"title\":\"Oboyob: A sequential-semantic Bengali image captioning engine\",\"url\":\"https://www.semanticscholar.org/paper/40ba4d6ebb66673bea62b1889f6fcde139f4b816\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1807.10854\",\"authors\":[{\"authorId\":\"51151229\",\"name\":\"Daniel W. Otter\"},{\"authorId\":\"51149804\",\"name\":\"J. R. Medina\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/tnnls.2020.2979670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"title\":\"A Survey of the Usages of Deep Learning in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414749\",\"name\":\"Kun Fu\"},{\"authorId\":\"3068555\",\"name\":\"Jin Li\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/TNNLS.2018.2813306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"title\":\"Image-Text Surgery: Efficient Concept Learning in Image Captioning by Generating Pseudopairs\",\"url\":\"https://www.semanticscholar.org/paper/f5fd76a48726d0cea93aa2201d3ba3d2c5903007\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1905.10515\",\"authors\":[{\"authorId\":\"2153067\",\"name\":\"Baohua Sun\"},{\"authorId\":\"144890162\",\"name\":\"L. Yang\"},{\"authorId\":\"144485124\",\"name\":\"M. Lin\"},{\"authorId\":\"50674008\",\"name\":\"C. Young\"},{\"authorId\":\"46195424\",\"name\":\"P. Dong\"},{\"authorId\":\"47528094\",\"name\":\"Wenhan Zhang\"},{\"authorId\":\"35287113\",\"name\":\"Jason Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70471f7d38c875e6e2912737729043e67272c326\",\"title\":\"SuperCaptioning: Image Captioning Using Two-dimensional Word Embedding\",\"url\":\"https://www.semanticscholar.org/paper/70471f7d38c875e6e2912737729043e67272c326\",\"venue\":\"BigMine@KDD\",\"year\":2019},{\"arxivId\":\"1809.03864\",\"authors\":[{\"authorId\":\"8252176\",\"name\":\"Ramin M. Hasani\"},{\"authorId\":\"2056330\",\"name\":\"Alexander Amini\"},{\"authorId\":\"39083616\",\"name\":\"M. Lechner\"},{\"authorId\":\"2324381\",\"name\":\"F. Naser\"},{\"authorId\":\"1787208\",\"name\":\"R. Grosu\"},{\"authorId\":\"145944286\",\"name\":\"D. Rus\"}],\"doi\":\"10.1109/IJCNN.2019.8851954\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6d098f7505ccc7c26251592af45daadb2b4f656\",\"title\":\"Response Characterization for Auditing Cell Dynamics in Long Short-term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/a6d098f7505ccc7c26251592af45daadb2b4f656\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410146205\",\"name\":\"Ali Al-Dulaimi\"},{\"authorId\":\"36447058\",\"name\":\"Soheil Zabihi\"},{\"authorId\":\"144762775\",\"name\":\"A. Asif\"},{\"authorId\":\"1725399\",\"name\":\"Arash Mohammadi\"}],\"doi\":\"10.1016/J.COMPIND.2019.02.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdb79fb59382b1642cd058ab2eb04e8f9b227ef6\",\"title\":\"A multimodal and hybrid deep neural network model for Remaining Useful Life estimation\",\"url\":\"https://www.semanticscholar.org/paper/fdb79fb59382b1642cd058ab2eb04e8f9b227ef6\",\"venue\":\"Comput. Ind.\",\"year\":2019},{\"arxivId\":\"1704.01518\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2017.447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db2fecc8b1bd175d39687eb471360707a5fddb03\",\"title\":\"Generating Descriptions with Grounded and Co-referenced People\",\"url\":\"https://www.semanticscholar.org/paper/db2fecc8b1bd175d39687eb471360707a5fddb03\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Moises Diaz\"},{\"authorId\":null,\"name\":\"Momina Moetesum\"},{\"authorId\":null,\"name\":\"Imran Siddiqi\"},{\"authorId\":null,\"name\":\"Gennaro Vessio\"}],\"doi\":\"10.1016/j.eswa.2020.114405\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c306530ee9b28dea30299d80f2ae10f296eff86e\",\"title\":\"Sequence-based dynamic handwriting analysis for Parkinson\\u2019s disease detection with one-dimensional convolutions and BiGRUs\",\"url\":\"https://www.semanticscholar.org/paper/c306530ee9b28dea30299d80f2ae10f296eff86e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2019.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"title\":\"Cross-Modality Personalization for Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115936677\",\"name\":\"S. Lee\"},{\"authorId\":\"3482047\",\"name\":\"Sooyoung Cha\"},{\"authorId\":\"1811564819\",\"name\":\"Dain Lee\"},{\"authorId\":\"39476651\",\"name\":\"Hakjoo Oh\"}],\"doi\":\"10.1145/3395363.3397346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"595f6eafb6d8811f123a43037a2a44d21d54b938\",\"title\":\"Effective white-box testing of deep neural networks with adaptive neuron-selection strategy\",\"url\":\"https://www.semanticscholar.org/paper/595f6eafb6d8811f123a43037a2a44d21d54b938\",\"venue\":\"ISSTA\",\"year\":2020},{\"arxivId\":\"2012.02033\",\"authors\":[{\"authorId\":\"152332057\",\"name\":\"Baohua Sun\"},{\"authorId\":\"1999579263\",\"name\":\"Michael Lin\"},{\"authorId\":\"1505825326\",\"name\":\"Hao Sha\"},{\"authorId\":\"1986616718\",\"name\":\"Lin Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"title\":\"SuperOCR: A Conversion from Optical Character Recognition to Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.03891\",\"authors\":[{\"authorId\":\"46331862\",\"name\":\"M. Liu\"},{\"authorId\":\"1870030432\",\"name\":\"Weiwei Fang\"},{\"authorId\":\"144053756\",\"name\":\"X. Ma\"},{\"authorId\":\"39533577\",\"name\":\"W. Xu\"},{\"authorId\":\"70359268\",\"name\":\"Naixue Xiong\"},{\"authorId\":\"46304750\",\"name\":\"Y. Ding\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27da3ecb1adaf4c58a25de88910bf849dea9bb0a\",\"title\":\"Channel Pruning Guided by Spatial and Channel Attention for DNNs in Intelligent Edge Computing\",\"url\":\"https://www.semanticscholar.org/paper/27da3ecb1adaf4c58a25de88910bf849dea9bb0a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34588610\",\"name\":\"S. Heller\"},{\"authorId\":\"35564381\",\"name\":\"Mahnaz Parian\"},{\"authorId\":\"145779317\",\"name\":\"R. Gasser\"},{\"authorId\":\"1738591580\",\"name\":\"Loris Sauter\"},{\"authorId\":\"145717652\",\"name\":\"H. Schuldt\"}],\"doi\":\"10.1145/3379172.3391715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7d6daa1f3349d29ae267dddf5d537b17194a88e\",\"title\":\"Interactive Lifelog Retrieval with vitrivr\",\"url\":\"https://www.semanticscholar.org/paper/b7d6daa1f3349d29ae267dddf5d537b17194a88e\",\"venue\":\"LSC@ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":\"2002.11701\",\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":\"10.1145/3366423.3380137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a842fe8c25348627764462a57f0cd43d8cef103b\",\"title\":\"CLARA: Clinical Report Auto-completion\",\"url\":\"https://www.semanticscholar.org/paper/a842fe8c25348627764462a57f0cd43d8cef103b\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1912.11872\",\"authors\":[{\"authorId\":\"153040576\",\"name\":\"T. Mei\"},{\"authorId\":\"101586660\",\"name\":\"W. Zhang\"},{\"authorId\":\"48577275\",\"name\":\"Ting Yao\"}],\"doi\":\"10.1017/ATSIP.2020.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"title\":\"Vision and Language: from Visual Perception to Content Creation\",\"url\":\"https://www.semanticscholar.org/paper/3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.10941\",\"authors\":[{\"authorId\":\"150319570\",\"name\":\"Tae Jun Ham\"},{\"authorId\":\"5079259\",\"name\":\"S. J. Jung\"},{\"authorId\":\"15319292\",\"name\":\"Seonghak Kim\"},{\"authorId\":\"3072985\",\"name\":\"Young H. Oh\"},{\"authorId\":\"1504704369\",\"name\":\"Yeonhong Park\"},{\"authorId\":\"11977680\",\"name\":\"Yongchan Song\"},{\"authorId\":\"2951798\",\"name\":\"Junghun Park\"},{\"authorId\":\"153311118\",\"name\":\"Sang-Hee Lee\"},{\"authorId\":\"144341935\",\"name\":\"K. Park\"},{\"authorId\":\"3091593\",\"name\":\"J. Lee\"},{\"authorId\":\"2850552\",\"name\":\"Deog-Kyoon Jeong\"}],\"doi\":\"10.1109/HPCA47549.2020.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3c6c635b9cfd8890c7244d3db4be53d45944963\",\"title\":\"A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation\",\"url\":\"https://www.semanticscholar.org/paper/d3c6c635b9cfd8890c7244d3db4be53d45944963\",\"venue\":\"2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123284890\",\"name\":\"Thomas\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"},{\"authorId\":null,\"name\":\"Dr. Raymond Ptucha\"},{\"authorId\":null,\"name\":\". Andres Kwasinski\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4749597cb3138932fd3e08798b491a5356b755be\",\"title\":\"The Emotional Impact of Audio-Visual Stimuli By , Titus Pallithottathu\",\"url\":\"https://www.semanticscholar.org/paper/4749597cb3138932fd3e08798b491a5356b755be\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.10889\",\"authors\":[{\"authorId\":\"39547281\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"23590685\",\"name\":\"Jinkun Cao\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-01249-6_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"544016b1d49a951de728d27a9b1183fabba000ec\",\"title\":\"Pairwise Body-Part Attention for Recognizing Human-Object Interactions\",\"url\":\"https://www.semanticscholar.org/paper/544016b1d49a951de728d27a9b1183fabba000ec\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1802.10240\",\"authors\":[{\"authorId\":\"3174935\",\"name\":\"Wenshan Wang\"},{\"authorId\":\"4456978\",\"name\":\"S. Yang\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2985995\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1049/iet-cvi.2019.0361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2f950677e6a42beb234e507b3022964980b6556\",\"title\":\"Neural Aesthetic Image Reviewer\",\"url\":\"https://www.semanticscholar.org/paper/e2f950677e6a42beb234e507b3022964980b6556\",\"venue\":\"IET Comput. Vis.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145959949\",\"name\":\"J. Serrano\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"title\":\"Boosting image captioning with an attentional mechanism = Boosting image captioning using diverse beam search\",\"url\":\"https://www.semanticscholar.org/paper/e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1903.10869\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fda87f56010b1e8d05a52a166fdb2750b4dec39b\",\"title\":\"V2CNet: A Deep Learning Framework to Translate Videos to Commands for Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/fda87f56010b1e8d05a52a166fdb2750b4dec39b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49770170\",\"name\":\"C. Xu\"},{\"authorId\":\"33538504\",\"name\":\"Gengming Zhu\"},{\"authorId\":\"40367854\",\"name\":\"Lixin Wang\"}],\"doi\":\"10.1145/3318299.3318375\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"798f1e5ca775fd0186c82786865859cebba52d84\",\"title\":\"Image Captioning Based on Automatic Constraint Loss\",\"url\":\"https://www.semanticscholar.org/paper/798f1e5ca775fd0186c82786865859cebba52d84\",\"venue\":\"ICMLC '19\",\"year\":2019},{\"arxivId\":\"1904.06861\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/CVPR.2019.00646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"title\":\"Self-Critical N-Step Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dee5c6c65684f91bfe212f44b79383f69f4d84c\",\"title\":\"EasyChair Preprint No 1046 Image Caption Generation With Adaptive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/9dee5c6c65684f91bfe212f44b79383f69f4d84c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1399665441\",\"name\":\"Nayak\"},{\"authorId\":\"73154260\",\"name\":\"Alok Sharma\"}],\"doi\":\"10.1007/978-3-030-29908-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b418a836dfe86710364aa35fa1ee78993146693b\",\"title\":\"PRICAI 2019: Trends in Artificial Intelligence: 16th Pacific Rim International Conference on Artificial Intelligence, Cuvu, Yanuca Island, Fiji, August 26\\u201330, 2019, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/b418a836dfe86710364aa35fa1ee78993146693b\",\"venue\":\"PRICAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122865911\",\"name\":\"Mie Mie Aung\"},{\"authorId\":\"145750914\",\"name\":\"Myint San\"},{\"authorId\":\"3169864\",\"name\":\"Phyu Phyu Khaing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45505889a0cf75a830545080d6b8b57cc2e2525f\",\"title\":\"Natural Language Description Generation for Image using Deep Learning Architecture\",\"url\":\"https://www.semanticscholar.org/paper/45505889a0cf75a830545080d6b8b57cc2e2525f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"144934447\",\"name\":\"M. Dom\\u00ednguez\"},{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/CVPRW.2017.274\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"477d58ad32e0e54c40da135fb8db28b23ad0ffd0\",\"title\":\"Temporally Steered Gaussian Attention for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/477d58ad32e0e54c40da135fb8db28b23ad0ffd0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134518946\",\"name\":\"Nanxing Li\"},{\"authorId\":\"50678073\",\"name\":\"Bei Liu\"},{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1145/3323873.3325050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"title\":\"Emotion Reinforced Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1016/j.sigpro.2017.12.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"title\":\"Recurrent attention network using spatial-temporal relations for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727651\",\"name\":\"Ariyo Oluwasanmi\"},{\"authorId\":\"4043033\",\"name\":\"E. Frimpong\"},{\"authorId\":\"32593111\",\"name\":\"Muhammad Umar Aftab\"},{\"authorId\":\"46352756\",\"name\":\"Edward Y. Baagyere\"},{\"authorId\":\"152179239\",\"name\":\"Zhiquang Qin\"},{\"authorId\":\"1470727785\",\"name\":\"Kifayat Ullah\"}],\"doi\":\"10.1109/ACCESS.2019.2957513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"78396f9e33eaada2a84dc12a59a3deceac05c526\",\"title\":\"Fully Convolutional CaptionNet: Siamese Difference Captioning Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/78396f9e33eaada2a84dc12a59a3deceac05c526\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49141242\",\"name\":\"Mengdi Li\"},{\"authorId\":\"49254862\",\"name\":\"K. Mu\"},{\"authorId\":\"143741620\",\"name\":\"Ping Zhong\"},{\"authorId\":\"47808650\",\"name\":\"Juan Wen\"},{\"authorId\":\"9095768\",\"name\":\"Yiming Xue\"}],\"doi\":\"10.1016/J.SIGPRO.2019.06.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f305742b4868e1bea04bf401dcb2acc9c97c813\",\"title\":\"Generating steganographic image description by dynamic synonym substitution\",\"url\":\"https://www.semanticscholar.org/paper/0f305742b4868e1bea04bf401dcb2acc9c97c813\",\"venue\":\"Signal Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"93768847\",\"name\":\"Xinghan Wang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00984\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"title\":\"Learning Temporal Co-Attention Models for Unsupervised Video Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.11888\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"1796254\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.24963/ijcai.2020/88\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"884be34dd5d2ea78940da96d2813be7768933857\",\"title\":\"SBAT: Video Captioning with Sparse Boundary-Aware Transformer\",\"url\":\"https://www.semanticscholar.org/paper/884be34dd5d2ea78940da96d2813be7768933857\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2734498\",\"name\":\"N. Laokulrat\"},{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"8058716\",\"name\":\"Noriki Nishida\"},{\"authorId\":\"7412686\",\"name\":\"Raphael Shu\"},{\"authorId\":\"35257737\",\"name\":\"Yo Ehara\"},{\"authorId\":\"1764004\",\"name\":\"N. Okazaki\"},{\"authorId\":\"1768065\",\"name\":\"Yusuke Miyao\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf05e710dae791f82cc639a09dbe5ec66fed2008\",\"title\":\"Generating Video Description using Sequence-to-sequence Model with Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf05e710dae791f82cc639a09dbe5ec66fed2008\",\"venue\":\"COLING\",\"year\":2016},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6402703b62325865d00da1f58dbbcaf9a2bc417d\",\"title\":\"Twin Networks: Matching the Future for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/6402703b62325865d00da1f58dbbcaf9a2bc417d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2910007\",\"name\":\"J. Guo\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f67d8ee105634fc614005b7c7b2e212e9da2fcc4\",\"title\":\"Stacked Semantic-Guided Attention Model for Fine-Grained Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/f67d8ee105634fc614005b7c7b2e212e9da2fcc4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546292\",\"name\":\"Justin Sybrandt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e5ddb01ac11bd32770e81baede3c96a4ca7dde1\",\"title\":\"Exploiting Latent Features of Text and Graphs\",\"url\":\"https://www.semanticscholar.org/paper/7e5ddb01ac11bd32770e81baede3c96a4ca7dde1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38139853\",\"name\":\"Xiaowei Jia\"},{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"40574362\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1145/3292500.3330957\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f02aadfe438e7456172cbf058754e9ebf7bb8110\",\"title\":\"Towards Robust and Discriminative Sequential Data Learning: When and How to Perform Adversarial Training?\",\"url\":\"https://www.semanticscholar.org/paper/f02aadfe438e7456172cbf058754e9ebf7bb8110\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543226\",\"name\":\"Xiaoxiao Liu\"},{\"authorId\":\"40096492\",\"name\":\"Q. Xu\"},{\"authorId\":null,\"name\":\"Ning Wang\"}],\"doi\":\"10.1007/s00371-018-1566-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f79c03f977d1c9acb71d87301272682422b0b14f\",\"title\":\"A survey on deep neural network-based image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79c03f977d1c9acb71d87301272682422b0b14f\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":\"1903.10663\",\"authors\":[{\"authorId\":\"100707516\",\"name\":\"HeeJae Jun\"},{\"authorId\":\"9726578\",\"name\":\"ByungSoo Ko\"},{\"authorId\":\"2268229\",\"name\":\"Youngjoon Kim\"},{\"authorId\":\"6160148\",\"name\":\"Insik Kim\"},{\"authorId\":\"2744147\",\"name\":\"Jongtack Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"529b3f7560a68bb6981594ebd6c809dca14fecc8\",\"title\":\"Combination of Multiple Global Descriptors for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/529b3f7560a68bb6981594ebd6c809dca14fecc8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1801.10121\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"title\":\"Image Captioning at Will: A Versatile Scheme for Effectively Injecting Sentiments into Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.00832\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"50031872\",\"name\":\"Yunsheng Ma\"},{\"authorId\":\"37989322\",\"name\":\"Y. Gu\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"151185822\",\"name\":\"Runbo Hu\"},{\"authorId\":\"144626314\",\"name\":\"Hua Chai\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1609/AAAI.V34I01.5364\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"title\":\"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144485517\",\"name\":\"Yu Qin\"},{\"authorId\":\"37288413\",\"name\":\"Y. Yang\"}],\"doi\":\"10.18653/v1/P19-1038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39799605dab71edba1417cd4bd632679b1813b34\",\"title\":\"What You Say and How You Say It Matters: Predicting Stock Volatility Using Verbal and Vocal Cues\",\"url\":\"https://www.semanticscholar.org/paper/39799605dab71edba1417cd4bd632679b1813b34\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2012.09058\",\"authors\":[{\"authorId\":\"38286801\",\"name\":\"Massimiliano Mancini\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5937e2ee2c35da2b511c06a3ff3ea637e01835a\",\"title\":\"Towards Recognizing New Semantic Concepts in New Visual Domains\",\"url\":\"https://www.semanticscholar.org/paper/f5937e2ee2c35da2b511c06a3ff3ea637e01835a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.12794\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f472b819ce521337c01e4ebf91714f93413d9997\",\"title\":\"Fashion IQ: A New Dataset towards Retrieving Images by Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/f472b819ce521337c01e4ebf91714f93413d9997\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.08195\",\"authors\":[{\"authorId\":\"29860450\",\"name\":\"Baoyu Jing\"},{\"authorId\":\"40526720\",\"name\":\"Pengtao Xie\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/P18-1240\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5d45cc9a3a2fc064eccc0c915dbdf73cce559ce7\",\"title\":\"On the Automatic Generation of Medical Imaging Reports\",\"url\":\"https://www.semanticscholar.org/paper/5d45cc9a3a2fc064eccc0c915dbdf73cce559ce7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"39943835\",\"name\":\"Gui-Song Xia\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"2872774\",\"name\":\"W. Dong\"}],\"doi\":\"10.1016/J.PATREC.2017.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390d0bb977b7473b8b76d045875c767d743de943\",\"title\":\"Image Caption Generation with Part of Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/390d0bb977b7473b8b76d045875c767d743de943\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1708.02043\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.18653/v1/W17-3506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"title\":\"What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?\",\"url\":\"https://www.semanticscholar.org/paper/3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3439095\",\"name\":\"A. Karine\"},{\"authorId\":\"3423479\",\"name\":\"T. Napol\\u00e9on\"},{\"authorId\":\"71535849\",\"name\":\"Jean-Yves Mulot\"},{\"authorId\":\"15510140\",\"name\":\"Y. Auffret\"}],\"doi\":\"10.1109/IPTA50016.2020.9286702\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"894aaccaec6be9de6cc1fa465653ee70b9d258aa\",\"title\":\"Video Seals Recognition using Transfer Learning of Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/894aaccaec6be9de6cc1fa465653ee70b9d258aa\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70998383\",\"name\":\"Renbao Lian\"},{\"authorId\":\"2653046\",\"name\":\"W. Wang\"},{\"authorId\":\"1976773157\",\"name\":\"Nadir Mustafa\"},{\"authorId\":\"1574219909\",\"name\":\"Liqin Huang\"}],\"doi\":\"10.1109/JSTARS.2020.3023549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1edc24f33923bbe3d3e43135340ad373e172c16a\",\"title\":\"Road Extraction Methods in High-Resolution Remote Sensing Images: A Comprehensive Review\",\"url\":\"https://www.semanticscholar.org/paper/1edc24f33923bbe3d3e43135340ad373e172c16a\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":\"2003.03669\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58601-0_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"title\":\"Adaptive Offline Quintuplet Loss for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.13662\",\"authors\":[{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"2858764\",\"name\":\"V. Sheng\"},{\"authorId\":\"50062143\",\"name\":\"Zhengtian Wu\"},{\"authorId\":\"3176996\",\"name\":\"Qiming Fu\"},{\"authorId\":\"31189660\",\"name\":\"B. Fu\"}],\"doi\":\"10.1109/ISC2.2018.8656664\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cd5965a2045f37f1383350aa8dcea42df7e298f1\",\"title\":\"Coarse to Fine: Multi-label Image Classification with Global/Local Attention\",\"url\":\"https://www.semanticscholar.org/paper/cd5965a2045f37f1383350aa8dcea42df7e298f1\",\"venue\":\"2018 IEEE International Smart Cities Conference (ISC2)\",\"year\":2018},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1478298061\",\"name\":\"Navid Ghassemi\"},{\"authorId\":\"65856946\",\"name\":\"A. Shoeibi\"},{\"authorId\":\"145843889\",\"name\":\"M. Rouhani\"}],\"doi\":\"10.1016/j.bspc.2019.101678\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d0abcbe11275a93c2fa1e896d06effa8d01c786\",\"title\":\"Deep neural network with generative adversarial networks pre-training for brain tumor classification based on MR images\",\"url\":\"https://www.semanticscholar.org/paper/5d0abcbe11275a93c2fa1e896d06effa8d01c786\",\"venue\":\"Biomed. Signal Process. Control.\",\"year\":2020},{\"arxivId\":\"2001.05876\",\"authors\":[{\"authorId\":\"46659203\",\"name\":\"L. Wang\"},{\"authorId\":\"1486057423\",\"name\":\"Zechen Bai\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1609/aaai.v34i07.6898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85079d64d6fdd0ba5318fda119d152f2d2946391\",\"title\":\"Show, Recall, and Tell: Image Captioning with Recall Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/85079d64d6fdd0ba5318fda119d152f2d2946391\",\"venue\":\"AAAI\",\"year\":2020}],\"corpusId\":3120635,\"doi\":\"10.1109/CVPR.2016.503\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":105,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"references\":[{\"arxivId\":\"1312.6110\",\"authors\":[{\"authorId\":\"34312504\",\"name\":\"Y. Tang\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ca6cccbfcf3df972a470c7fe18f7eaed9420cd6\",\"title\":\"Learning Generative Models with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/0ca6cccbfcf3df972a470c7fe18f7eaed9420cd6\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Mao\"},{\"authorId\":null,\"name\":\"W Xu\"},{\"authorId\":null,\"name\":\"Y Yang\"},{\"authorId\":null,\"name\":\"J Wang\"},{\"authorId\":null,\"name\":\"A Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deep captioning with multimodal recurrent neural networks (mrnn ). arXiv preprint arXiv:1412\",\"url\":\"\",\"venue\":\"Deep captioning with multimodal recurrent neural networks (mrnn ). arXiv preprint arXiv:1412\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Tieleman\"},{\"authorId\":null,\"name\":\"G. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Lecture 6.5 - rmsprop, coursera: Neural networks for machine learning\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1411.5328\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1679794\",\"name\":\"V. Jagadeesh\"},{\"authorId\":\"3221010\",\"name\":\"Robinson Piramuthu\"}],\"doi\":\"10.1109/CVPR.2015.7298756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a404b56cb1afc8383d44dd1e217642802474649b\",\"title\":\"ConceptLearner: Discovering visual concepts from weakly labeled image collections\",\"url\":\"https://www.semanticscholar.org/paper/a404b56cb1afc8383d44dd1e217642802474649b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1109.3737\",\"authors\":[{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":\"10.1162/NECO_a_00312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72829d537f0ec8b1cc0ced2f278bb56ce89f1b0c\",\"title\":\"Learning Where to Attend with Deep Architectures for Image Tracking\",\"url\":\"https://www.semanticscholar.org/paper/72829d537f0ec8b1cc0ced2f278bb56ce89f1b0c\",\"venue\":\"Neural Computation\",\"year\":2012},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2015.7298730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4048de57777afb4873fdd01b18f0976b903bf87\",\"title\":\"On the relationship between visual attributes and convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/c4048de57777afb4873fdd01b18f0976b903bf87\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3\",\"title\":\"Learning to combine foveal glimpses with a third-order Boltzmann machine\",\"url\":\"https://www.semanticscholar.org/paper/0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2273845\",\"name\":\"Michael W. Spratling\"},{\"authorId\":\"145546235\",\"name\":\"M. Johnson\"}],\"doi\":\"10.1162/089892904322984526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fb8f4f91472d5e0ef91963849709f74b172fbe3\",\"title\":\"A Feedback Model of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/0fb8f4f91472d5e0ef91963849709f74b172fbe3\",\"venue\":\"Journal of Cognitive Neuroscience\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3f6a4556769e819242d669d073b895f1e45a706f\",\"title\":\"Image Description using Visual Dependency Representations\",\"url\":\"https://www.semanticscholar.org/paper/3f6a4556769e819242d669d073b895f1e45a706f\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1502.04623\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"title\":\"DRAW: A Recurrent Neural Network For Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e6f47c4b2109e7824cd475336c3676faf9b113e\",\"title\":\"Baby Talk : Understanding and Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6e6f47c4b2109e7824cd475336c3676faf9b113e\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1312.4894\",\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"145266091\",\"name\":\"Thomas Leung\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b049d8cfea6c3bed377090e0e7fa677d282a361\",\"title\":\"Deep Convolutional Ranking for Multilabel Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/3b049d8cfea6c3bed377090e0e7fa677d282a361\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-10593-2_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"title\":\"Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections\",\"url\":\"https://www.semanticscholar.org/paper/fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1412.7755\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7845f1d3e796b5704d4bd37a945e0cf3fb8bbf1f\",\"title\":\"Multiple Object Recognition with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7845f1d3e796b5704d4bd37a945e0cf3fb8bbf1f\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1504.06692\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"144287022\",\"name\":\"Xu Wei\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"152924551\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb847564774394c484e701437dbcffbf040ff3cc\",\"title\":\"Learning Like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images\",\"url\":\"https://www.semanticscholar.org/paper/eb847564774394c484e701437dbcffbf040ff3cc\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":\"1412.8419\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"015d25f66514ce0a966300944201d45968a104ba\",\"title\":\"Simple Image Description Generator via a Linear Phrase-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/015d25f66514ce0a966300944201d45968a104ba\",\"venue\":\"ICLR\",\"year\":2015}],\"title\":\"Image Captioning with Semantic Attention\",\"topics\":[{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Exploit (computer security)\",\"topicId\":\"439222\",\"url\":\"https://www.semanticscholar.org/topic/439222\"},{\"topic\":\"Feedback\",\"topicId\":\"242\",\"url\":\"https://www.semanticscholar.org/topic/242\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Bottom-up proteomics\",\"topicId\":\"3514303\",\"url\":\"https://www.semanticscholar.org/topic/3514303\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"GiST\",\"topicId\":\"737974\",\"url\":\"https://www.semanticscholar.org/topic/737974\"},{\"topic\":\"Random neural network\",\"topicId\":\"136146\",\"url\":\"https://www.semanticscholar.org/topic/136146\"}],\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}\n"